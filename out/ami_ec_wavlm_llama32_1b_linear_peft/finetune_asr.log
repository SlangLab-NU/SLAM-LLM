[2025-02-17 16:27:56,268][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 1, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 1, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False, 'test_flag': True}
[2025-02-17 16:27:56,268][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-17 16:27:56,268][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'ami_ec_wavlm_llama32_1b_linear_peft'}
[2025-02-17 16:27:56,268][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_ec_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2025-02-17_16-27-55.txt', 'log_interval': 5}
[2025-02-17 16:28:15,674][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-17 16:28:20,789][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-17 16:28:20,791][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-17 16:28:20,793][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-17 16:28:20,794][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-17 16:28:23,453][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-17 16:28:23,455][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-17 16:28:23,455][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-17 16:28:23,574][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-17 16:28:23,576][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-17 16:28:23,662][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-17 16:28:23,662][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2025-02-17 16:28:23,663][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-17 16:28:23,666][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2025-02-17 16:28:25,414][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-17 16:28:26,717][root][INFO] - --> Training Set Length = 107898
[2025-02-17 16:28:26,832][root][INFO] - --> Validation Set Length = 8351
[2025-02-17 16:28:26,832][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-17 16:28:26,833][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-17 16:28:28,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:28,895][root][INFO] - Training Epoch: 1/2, step 0/107898 completed (loss: 3.0186076164245605, acc: 0.5)
[2025-02-17 16:28:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:29,240][root][INFO] - Training Epoch: 1/2, step 1/107898 completed (loss: 8.255044937133789, acc: 0.1666666716337204)
[2025-02-17 16:28:29,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:29,568][root][INFO] - Training Epoch: 1/2, step 2/107898 completed (loss: 7.43020486831665, acc: 0.0)
[2025-02-17 16:28:29,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:30,037][root][INFO] - Training Epoch: 1/2, step 3/107898 completed (loss: 2.5532708168029785, acc: 0.6666666865348816)
[2025-02-17 16:28:30,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:30,340][root][INFO] - Training Epoch: 1/2, step 4/107898 completed (loss: 10.002933502197266, acc: 0.0)
[2025-02-17 16:28:30,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:30,642][root][INFO] - Training Epoch: 1/2, step 5/107898 completed (loss: 6.788373947143555, acc: 0.0)
[2025-02-17 16:28:30,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:31,009][root][INFO] - Training Epoch: 1/2, step 6/107898 completed (loss: 3.8484482765197754, acc: 0.4000000059604645)
[2025-02-17 16:28:31,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:31,367][root][INFO] - Training Epoch: 1/2, step 7/107898 completed (loss: 2.805820941925049, acc: 0.7037037014961243)
[2025-02-17 16:28:31,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:31,784][root][INFO] - Training Epoch: 1/2, step 8/107898 completed (loss: 1.6534172296524048, acc: 0.7407407164573669)
[2025-02-17 16:28:31,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:32,164][root][INFO] - Training Epoch: 1/2, step 9/107898 completed (loss: 1.8160206079483032, acc: 0.7200000286102295)
[2025-02-17 16:28:32,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:32,528][root][INFO] - Training Epoch: 1/2, step 10/107898 completed (loss: 3.3079497814178467, acc: 0.5)
[2025-02-17 16:28:32,660][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:32,889][root][INFO] - Training Epoch: 1/2, step 11/107898 completed (loss: 2.276681900024414, acc: 0.5789473652839661)
[2025-02-17 16:28:33,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:33,225][root][INFO] - Training Epoch: 1/2, step 12/107898 completed (loss: 2.252293348312378, acc: 0.8181818127632141)
[2025-02-17 16:28:33,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:33,574][root][INFO] - Training Epoch: 1/2, step 13/107898 completed (loss: 4.958630084991455, acc: 0.2857142984867096)
[2025-02-17 16:28:33,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:33,999][root][INFO] - Training Epoch: 1/2, step 14/107898 completed (loss: 2.3587512969970703, acc: 0.529411792755127)
[2025-02-17 16:28:34,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:34,354][root][INFO] - Training Epoch: 1/2, step 15/107898 completed (loss: 1.4132626056671143, acc: 0.7333333492279053)
[2025-02-17 16:28:34,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:34,713][root][INFO] - Training Epoch: 1/2, step 16/107898 completed (loss: 2.087310314178467, acc: 0.7333333492279053)
[2025-02-17 16:28:34,839][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:35,062][root][INFO] - Training Epoch: 1/2, step 17/107898 completed (loss: 3.7954108715057373, acc: 0.5)
[2025-02-17 16:28:35,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:35,389][root][INFO] - Training Epoch: 1/2, step 18/107898 completed (loss: 7.909713268280029, acc: 0.0)
[2025-02-17 16:28:35,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:35,696][root][INFO] - Training Epoch: 1/2, step 19/107898 completed (loss: 2.6467161178588867, acc: 0.6666666865348816)
[2025-02-17 16:28:35,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:36,022][root][INFO] - Training Epoch: 1/2, step 20/107898 completed (loss: 2.807607650756836, acc: 0.6000000238418579)
[2025-02-17 16:28:36,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:36,337][root][INFO] - Training Epoch: 1/2, step 21/107898 completed (loss: 4.0252885818481445, acc: 0.5)
[2025-02-17 16:28:36,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:36,668][root][INFO] - Training Epoch: 1/2, step 22/107898 completed (loss: 3.0470290184020996, acc: 0.6000000238418579)
[2025-02-17 16:28:36,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:37,030][root][INFO] - Training Epoch: 1/2, step 23/107898 completed (loss: 8.832015037536621, acc: 0.0)
[2025-02-17 16:28:37,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:37,365][root][INFO] - Training Epoch: 1/2, step 24/107898 completed (loss: 2.8657631874084473, acc: 0.529411792755127)
[2025-02-17 16:28:37,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:37,779][root][INFO] - Training Epoch: 1/2, step 25/107898 completed (loss: 5.788084030151367, acc: 0.0)
[2025-02-17 16:28:37,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:38,118][root][INFO] - Training Epoch: 1/2, step 26/107898 completed (loss: 5.3232421875, acc: 0.0)
[2025-02-17 16:28:38,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:38,455][root][INFO] - Training Epoch: 1/2, step 27/107898 completed (loss: 7.7739081382751465, acc: 0.0)
[2025-02-17 16:28:38,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:38,801][root][INFO] - Training Epoch: 1/2, step 28/107898 completed (loss: 4.042644500732422, acc: 0.3333333432674408)
[2025-02-17 16:28:38,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:39,170][root][INFO] - Training Epoch: 1/2, step 29/107898 completed (loss: 2.0394368171691895, acc: 0.6000000238418579)
[2025-02-17 16:28:39,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:39,525][root][INFO] - Training Epoch: 1/2, step 30/107898 completed (loss: 2.173410177230835, acc: 0.7272727489471436)
[2025-02-17 16:28:39,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:39,854][root][INFO] - Training Epoch: 1/2, step 31/107898 completed (loss: 3.444577693939209, acc: 0.4000000059604645)
[2025-02-17 16:28:39,974][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:40,228][root][INFO] - Training Epoch: 1/2, step 32/107898 completed (loss: 2.3710520267486572, acc: 0.6521739363670349)
[2025-02-17 16:28:40,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:40,572][root][INFO] - Training Epoch: 1/2, step 33/107898 completed (loss: 6.685047149658203, acc: 0.25)
[2025-02-17 16:28:40,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:40,935][root][INFO] - Training Epoch: 1/2, step 34/107898 completed (loss: 4.122760772705078, acc: 0.20000000298023224)
[2025-02-17 16:28:41,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:41,261][root][INFO] - Training Epoch: 1/2, step 35/107898 completed (loss: 6.247374534606934, acc: 0.20000000298023224)
[2025-02-17 16:28:41,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:41,617][root][INFO] - Training Epoch: 1/2, step 36/107898 completed (loss: 2.2213430404663086, acc: 0.4545454680919647)
[2025-02-17 16:28:41,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:41,962][root][INFO] - Training Epoch: 1/2, step 37/107898 completed (loss: 2.7355594635009766, acc: 0.5)
[2025-02-17 16:28:42,069][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:42,283][root][INFO] - Training Epoch: 1/2, step 38/107898 completed (loss: 1.7239131927490234, acc: 0.6153846383094788)
[2025-02-17 16:28:42,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:42,602][root][INFO] - Training Epoch: 1/2, step 39/107898 completed (loss: 9.644201278686523, acc: 0.0)
[2025-02-17 16:28:42,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:42,917][root][INFO] - Training Epoch: 1/2, step 40/107898 completed (loss: 5.915209770202637, acc: 0.0)
[2025-02-17 16:28:43,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:43,228][root][INFO] - Training Epoch: 1/2, step 41/107898 completed (loss: 10.782958984375, acc: 0.0)
[2025-02-17 16:28:43,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:43,556][root][INFO] - Training Epoch: 1/2, step 42/107898 completed (loss: 1.6834990978240967, acc: 0.5882353186607361)
[2025-02-17 16:28:43,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:43,907][root][INFO] - Training Epoch: 1/2, step 43/107898 completed (loss: 8.100184440612793, acc: 0.0)
[2025-02-17 16:28:44,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:44,242][root][INFO] - Training Epoch: 1/2, step 44/107898 completed (loss: 4.791460990905762, acc: 0.4000000059604645)
[2025-02-17 16:28:44,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:44,562][root][INFO] - Training Epoch: 1/2, step 45/107898 completed (loss: 2.0106427669525146, acc: 0.7272727489471436)
[2025-02-17 16:28:44,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:44,883][root][INFO] - Training Epoch: 1/2, step 46/107898 completed (loss: 2.836700677871704, acc: 0.6363636255264282)
[2025-02-17 16:28:44,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:45,177][root][INFO] - Training Epoch: 1/2, step 47/107898 completed (loss: 9.251535415649414, acc: 0.0)
[2025-02-17 16:28:45,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:45,500][root][INFO] - Training Epoch: 1/2, step 48/107898 completed (loss: 2.4404189586639404, acc: 0.6764705777168274)
[2025-02-17 16:28:45,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:45,814][root][INFO] - Training Epoch: 1/2, step 49/107898 completed (loss: 1.477877140045166, acc: 0.7272727489471436)
[2025-02-17 16:28:45,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:46,146][root][INFO] - Training Epoch: 1/2, step 50/107898 completed (loss: 4.742873668670654, acc: 0.42105263471603394)
[2025-02-17 16:28:46,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:46,444][root][INFO] - Training Epoch: 1/2, step 51/107898 completed (loss: 7.859074115753174, acc: 0.0)
[2025-02-17 16:28:46,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:46,759][root][INFO] - Training Epoch: 1/2, step 52/107898 completed (loss: 3.16782546043396, acc: 0.4166666567325592)
[2025-02-17 16:28:46,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:47,081][root][INFO] - Training Epoch: 1/2, step 53/107898 completed (loss: 2.937830924987793, acc: 0.5588235259056091)
[2025-02-17 16:28:47,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:47,383][root][INFO] - Training Epoch: 1/2, step 54/107898 completed (loss: 3.5007054805755615, acc: 0.5454545617103577)
[2025-02-17 16:28:47,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:47,701][root][INFO] - Training Epoch: 1/2, step 55/107898 completed (loss: 2.108935594558716, acc: 0.4285714328289032)
[2025-02-17 16:28:47,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:48,016][root][INFO] - Training Epoch: 1/2, step 56/107898 completed (loss: 2.180359125137329, acc: 0.5)
[2025-02-17 16:28:48,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:48,331][root][INFO] - Training Epoch: 1/2, step 57/107898 completed (loss: 1.141207218170166, acc: 0.625)
[2025-02-17 16:28:48,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:48,619][root][INFO] - Training Epoch: 1/2, step 58/107898 completed (loss: 2.6395761966705322, acc: 0.692307710647583)
[2025-02-17 16:28:48,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:48,913][root][INFO] - Training Epoch: 1/2, step 59/107898 completed (loss: 7.253211498260498, acc: 0.0)
[2025-02-17 16:28:49,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:49,230][root][INFO] - Training Epoch: 1/2, step 60/107898 completed (loss: 4.887439250946045, acc: 0.25)
[2025-02-17 16:28:49,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:49,546][root][INFO] - Training Epoch: 1/2, step 61/107898 completed (loss: 3.03115177154541, acc: 0.5333333611488342)
[2025-02-17 16:28:49,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:49,868][root][INFO] - Training Epoch: 1/2, step 62/107898 completed (loss: 1.5202507972717285, acc: 0.8181818127632141)
[2025-02-17 16:28:50,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:50,253][root][INFO] - Training Epoch: 1/2, step 63/107898 completed (loss: 8.252882957458496, acc: 0.0)
[2025-02-17 16:28:50,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:50,601][root][INFO] - Training Epoch: 1/2, step 64/107898 completed (loss: 4.414432525634766, acc: 0.4000000059604645)
[2025-02-17 16:28:50,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:50,966][root][INFO] - Training Epoch: 1/2, step 65/107898 completed (loss: 2.4590578079223633, acc: 0.6666666865348816)
[2025-02-17 16:28:51,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:51,292][root][INFO] - Training Epoch: 1/2, step 66/107898 completed (loss: 3.2245118618011475, acc: 0.3636363744735718)
[2025-02-17 16:28:51,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:51,617][root][INFO] - Training Epoch: 1/2, step 67/107898 completed (loss: 0.8891868591308594, acc: 0.8260869383811951)
[2025-02-17 16:28:51,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:51,910][root][INFO] - Training Epoch: 1/2, step 68/107898 completed (loss: 3.2960832118988037, acc: 0.5)
[2025-02-17 16:28:52,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:52,249][root][INFO] - Training Epoch: 1/2, step 69/107898 completed (loss: 1.0440107583999634, acc: 0.8387096524238586)
[2025-02-17 16:28:52,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:52,572][root][INFO] - Training Epoch: 1/2, step 70/107898 completed (loss: 2.099743604660034, acc: 0.6071428656578064)
[2025-02-17 16:28:52,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:52,870][root][INFO] - Training Epoch: 1/2, step 71/107898 completed (loss: 5.170403003692627, acc: 0.0)
[2025-02-17 16:28:52,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:53,172][root][INFO] - Training Epoch: 1/2, step 72/107898 completed (loss: 1.455842137336731, acc: 0.8333333134651184)
[2025-02-17 16:28:53,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:53,506][root][INFO] - Training Epoch: 1/2, step 73/107898 completed (loss: 3.272825002670288, acc: 0.3333333432674408)
[2025-02-17 16:28:53,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:53,893][root][INFO] - Training Epoch: 1/2, step 74/107898 completed (loss: 1.645450234413147, acc: 0.800000011920929)
[2025-02-17 16:28:54,056][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:54,295][root][INFO] - Training Epoch: 1/2, step 75/107898 completed (loss: 2.2652676105499268, acc: 0.692307710647583)
[2025-02-17 16:28:54,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:54,655][root][INFO] - Training Epoch: 1/2, step 76/107898 completed (loss: 2.0660712718963623, acc: 0.800000011920929)
[2025-02-17 16:28:54,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:55,014][root][INFO] - Training Epoch: 1/2, step 77/107898 completed (loss: 4.209298610687256, acc: 0.5)
[2025-02-17 16:28:55,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:55,304][root][INFO] - Training Epoch: 1/2, step 78/107898 completed (loss: 5.418291091918945, acc: 0.0)
[2025-02-17 16:28:55,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:55,628][root][INFO] - Training Epoch: 1/2, step 79/107898 completed (loss: 5.925883769989014, acc: 0.20000000298023224)
[2025-02-17 16:28:55,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:55,940][root][INFO] - Training Epoch: 1/2, step 80/107898 completed (loss: 1.7989104986190796, acc: 0.6000000238418579)
[2025-02-17 16:28:56,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:56,230][root][INFO] - Training Epoch: 1/2, step 81/107898 completed (loss: 5.056497573852539, acc: 0.0)
[2025-02-17 16:28:56,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:56,562][root][INFO] - Training Epoch: 1/2, step 82/107898 completed (loss: 1.8158562183380127, acc: 0.75)
[2025-02-17 16:28:56,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:56,919][root][INFO] - Training Epoch: 1/2, step 83/107898 completed (loss: 0.5812321901321411, acc: 0.949999988079071)
[2025-02-17 16:28:57,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:57,238][root][INFO] - Training Epoch: 1/2, step 84/107898 completed (loss: 1.2362422943115234, acc: 0.6666666865348816)
[2025-02-17 16:28:57,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:57,575][root][INFO] - Training Epoch: 1/2, step 85/107898 completed (loss: 2.079030752182007, acc: 0.6111111044883728)
[2025-02-17 16:28:57,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:57,898][root][INFO] - Training Epoch: 1/2, step 86/107898 completed (loss: 1.6182228326797485, acc: 0.7777777910232544)
[2025-02-17 16:28:57,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:58,214][root][INFO] - Training Epoch: 1/2, step 87/107898 completed (loss: 1.8749041557312012, acc: 0.75)
[2025-02-17 16:28:58,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:58,545][root][INFO] - Training Epoch: 1/2, step 88/107898 completed (loss: 2.5093908309936523, acc: 0.5833333134651184)
[2025-02-17 16:28:58,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:58,925][root][INFO] - Training Epoch: 1/2, step 89/107898 completed (loss: 1.024161696434021, acc: 0.75)
[2025-02-17 16:28:59,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:59,262][root][INFO] - Training Epoch: 1/2, step 90/107898 completed (loss: 1.7404017448425293, acc: 0.8888888955116272)
[2025-02-17 16:28:59,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:59,589][root][INFO] - Training Epoch: 1/2, step 91/107898 completed (loss: 8.234930038452148, acc: 0.25)
[2025-02-17 16:28:59,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:28:59,953][root][INFO] - Training Epoch: 1/2, step 92/107898 completed (loss: 3.6404905319213867, acc: 0.5)
[2025-02-17 16:29:00,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:00,284][root][INFO] - Training Epoch: 1/2, step 93/107898 completed (loss: 0.5643802285194397, acc: 0.8823529481887817)
[2025-02-17 16:29:00,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:00,611][root][INFO] - Training Epoch: 1/2, step 94/107898 completed (loss: 3.1524412631988525, acc: 0.0)
[2025-02-17 16:29:00,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:00,961][root][INFO] - Training Epoch: 1/2, step 95/107898 completed (loss: 4.757067680358887, acc: 0.3333333432674408)
[2025-02-17 16:29:01,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:01,295][root][INFO] - Training Epoch: 1/2, step 96/107898 completed (loss: 3.29597544670105, acc: 0.46666666865348816)
[2025-02-17 16:29:01,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:01,624][root][INFO] - Training Epoch: 1/2, step 97/107898 completed (loss: 4.337167739868164, acc: 0.5)
[2025-02-17 16:29:01,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:01,915][root][INFO] - Training Epoch: 1/2, step 98/107898 completed (loss: 4.454709529876709, acc: 0.5)
[2025-02-17 16:29:02,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:02,235][root][INFO] - Training Epoch: 1/2, step 99/107898 completed (loss: 1.043522834777832, acc: 0.7692307829856873)
[2025-02-17 16:29:02,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:02,527][root][INFO] - Training Epoch: 1/2, step 100/107898 completed (loss: 3.521148443222046, acc: 0.6666666865348816)
[2025-02-17 16:29:02,656][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:02,884][root][INFO] - Training Epoch: 1/2, step 101/107898 completed (loss: 2.3030877113342285, acc: 0.0)
[2025-02-17 16:29:03,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:03,249][root][INFO] - Training Epoch: 1/2, step 102/107898 completed (loss: 1.7094491720199585, acc: 0.625)
[2025-02-17 16:29:03,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:03,579][root][INFO] - Training Epoch: 1/2, step 103/107898 completed (loss: 4.15989351272583, acc: 0.6666666865348816)
[2025-02-17 16:29:03,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:03,939][root][INFO] - Training Epoch: 1/2, step 104/107898 completed (loss: 2.611910104751587, acc: 0.3333333432674408)
[2025-02-17 16:29:04,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:04,326][root][INFO] - Training Epoch: 1/2, step 105/107898 completed (loss: 0.8695874810218811, acc: 0.7931034564971924)
[2025-02-17 16:29:04,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:04,673][root][INFO] - Training Epoch: 1/2, step 106/107898 completed (loss: 2.4706718921661377, acc: 0.6857143044471741)
[2025-02-17 16:29:04,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:05,026][root][INFO] - Training Epoch: 1/2, step 107/107898 completed (loss: 2.6450092792510986, acc: 0.5)
[2025-02-17 16:29:05,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:05,363][root][INFO] - Training Epoch: 1/2, step 108/107898 completed (loss: 1.1928436756134033, acc: 0.75)
[2025-02-17 16:29:05,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:05,713][root][INFO] - Training Epoch: 1/2, step 109/107898 completed (loss: 0.1394093632698059, acc: 1.0)
[2025-02-17 16:29:05,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:06,075][root][INFO] - Training Epoch: 1/2, step 110/107898 completed (loss: 1.9289395809173584, acc: 0.800000011920929)
[2025-02-17 16:29:06,171][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:06,390][root][INFO] - Training Epoch: 1/2, step 111/107898 completed (loss: 1.977983832359314, acc: 0.5)
[2025-02-17 16:29:06,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:06,719][root][INFO] - Training Epoch: 1/2, step 112/107898 completed (loss: 1.5596015453338623, acc: 0.6499999761581421)
[2025-02-17 16:29:06,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:07,046][root][INFO] - Training Epoch: 1/2, step 113/107898 completed (loss: 0.9973809123039246, acc: 0.7222222089767456)
[2025-02-17 16:29:07,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:07,359][root][INFO] - Training Epoch: 1/2, step 114/107898 completed (loss: 2.8303651809692383, acc: 0.6666666865348816)
[2025-02-17 16:29:07,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:07,693][root][INFO] - Training Epoch: 1/2, step 115/107898 completed (loss: 1.6460299491882324, acc: 0.5)
[2025-02-17 16:29:07,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:08,051][root][INFO] - Training Epoch: 1/2, step 116/107898 completed (loss: 2.8740525245666504, acc: 0.375)
[2025-02-17 16:29:08,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:08,393][root][INFO] - Training Epoch: 1/2, step 117/107898 completed (loss: 0.26803073287010193, acc: 0.95652174949646)
[2025-02-17 16:29:08,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:08,732][root][INFO] - Training Epoch: 1/2, step 118/107898 completed (loss: 1.3763924837112427, acc: 0.8461538553237915)
[2025-02-17 16:29:08,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:09,096][root][INFO] - Training Epoch: 1/2, step 119/107898 completed (loss: 2.8500664234161377, acc: 0.5555555820465088)
[2025-02-17 16:29:09,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:09,424][root][INFO] - Training Epoch: 1/2, step 120/107898 completed (loss: 1.9930692911148071, acc: 0.6666666865348816)
[2025-02-17 16:29:09,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:09,746][root][INFO] - Training Epoch: 1/2, step 121/107898 completed (loss: 0.4786720871925354, acc: 0.8888888955116272)
[2025-02-17 16:29:09,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:10,053][root][INFO] - Training Epoch: 1/2, step 122/107898 completed (loss: 6.244940757751465, acc: 0.0)
[2025-02-17 16:29:10,157][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:10,376][root][INFO] - Training Epoch: 1/2, step 123/107898 completed (loss: 0.9051567316055298, acc: 0.8571428656578064)
[2025-02-17 16:29:10,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:10,689][root][INFO] - Training Epoch: 1/2, step 124/107898 completed (loss: 7.161552429199219, acc: 0.0)
[2025-02-17 16:29:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:11,042][root][INFO] - Training Epoch: 1/2, step 125/107898 completed (loss: 1.7434377670288086, acc: 0.5)
[2025-02-17 16:29:11,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:11,365][root][INFO] - Training Epoch: 1/2, step 126/107898 completed (loss: 4.467616081237793, acc: 0.09090909361839294)
[2025-02-17 16:29:11,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:11,704][root][INFO] - Training Epoch: 1/2, step 127/107898 completed (loss: 1.1253310441970825, acc: 0.6666666865348816)
[2025-02-17 16:29:11,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:12,059][root][INFO] - Training Epoch: 1/2, step 128/107898 completed (loss: 3.9998040199279785, acc: 0.2857142984867096)
[2025-02-17 16:29:12,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:12,398][root][INFO] - Training Epoch: 1/2, step 129/107898 completed (loss: 0.37870997190475464, acc: 1.0)
[2025-02-17 16:29:12,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:12,727][root][INFO] - Training Epoch: 1/2, step 130/107898 completed (loss: 1.0316154956817627, acc: 0.782608687877655)
[2025-02-17 16:29:12,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:13,050][root][INFO] - Training Epoch: 1/2, step 131/107898 completed (loss: 1.8093935251235962, acc: 0.7333333492279053)
[2025-02-17 16:29:13,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:13,376][root][INFO] - Training Epoch: 1/2, step 132/107898 completed (loss: 2.0523149967193604, acc: 0.5)
[2025-02-17 16:29:13,475][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:13,691][root][INFO] - Training Epoch: 1/2, step 133/107898 completed (loss: 2.229804754257202, acc: 0.6666666865348816)
[2025-02-17 16:29:13,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:14,068][root][INFO] - Training Epoch: 1/2, step 134/107898 completed (loss: 2.7936418056488037, acc: 0.5384615659713745)
[2025-02-17 16:29:14,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:14,421][root][INFO] - Training Epoch: 1/2, step 135/107898 completed (loss: 1.9669872522354126, acc: 0.6666666865348816)
[2025-02-17 16:29:14,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:14,751][root][INFO] - Training Epoch: 1/2, step 136/107898 completed (loss: 1.6000972986221313, acc: 0.6666666865348816)
[2025-02-17 16:29:14,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:15,065][root][INFO] - Training Epoch: 1/2, step 137/107898 completed (loss: 1.38942551612854, acc: 0.5)
[2025-02-17 16:29:15,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:15,387][root][INFO] - Training Epoch: 1/2, step 138/107898 completed (loss: 3.9647891521453857, acc: 0.4444444477558136)
[2025-02-17 16:29:15,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:15,713][root][INFO] - Training Epoch: 1/2, step 139/107898 completed (loss: 2.158684253692627, acc: 0.6499999761581421)
[2025-02-17 16:29:15,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:16,070][root][INFO] - Training Epoch: 1/2, step 140/107898 completed (loss: 1.6893879175186157, acc: 0.7142857313156128)
[2025-02-17 16:29:16,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:16,363][root][INFO] - Training Epoch: 1/2, step 141/107898 completed (loss: 2.4279842376708984, acc: 0.3333333432674408)
[2025-02-17 16:29:16,492][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:16,715][root][INFO] - Training Epoch: 1/2, step 142/107898 completed (loss: 1.5161972045898438, acc: 0.6428571343421936)
[2025-02-17 16:29:16,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:17,044][root][INFO] - Training Epoch: 1/2, step 143/107898 completed (loss: 3.2914512157440186, acc: 0.5)
[2025-02-17 16:29:17,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:17,378][root][INFO] - Training Epoch: 1/2, step 144/107898 completed (loss: 0.47329479455947876, acc: 1.0)
[2025-02-17 16:29:17,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:17,733][root][INFO] - Training Epoch: 1/2, step 145/107898 completed (loss: 1.8431507349014282, acc: 0.6000000238418579)
[2025-02-17 16:29:17,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:18,072][root][INFO] - Training Epoch: 1/2, step 146/107898 completed (loss: 5.273465156555176, acc: 0.5)
[2025-02-17 16:29:18,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:18,387][root][INFO] - Training Epoch: 1/2, step 147/107898 completed (loss: 1.0634095668792725, acc: 0.5)
[2025-02-17 16:29:18,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:18,714][root][INFO] - Training Epoch: 1/2, step 148/107898 completed (loss: 2.3202412128448486, acc: 0.5714285969734192)
[2025-02-17 16:29:18,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:19,079][root][INFO] - Training Epoch: 1/2, step 149/107898 completed (loss: 1.1732438802719116, acc: 0.6666666865348816)
[2025-02-17 16:29:19,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:19,360][root][INFO] - Training Epoch: 1/2, step 150/107898 completed (loss: 1.4047647714614868, acc: 0.6666666865348816)
[2025-02-17 16:29:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:19,668][root][INFO] - Training Epoch: 1/2, step 151/107898 completed (loss: 0.22288848459720612, acc: 1.0)
[2025-02-17 16:29:19,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:20,021][root][INFO] - Training Epoch: 1/2, step 152/107898 completed (loss: 0.8782438039779663, acc: 0.7647058963775635)
[2025-02-17 16:29:20,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:20,413][root][INFO] - Training Epoch: 1/2, step 153/107898 completed (loss: 2.402021646499634, acc: 0.5)
[2025-02-17 16:29:20,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:20,798][root][INFO] - Training Epoch: 1/2, step 154/107898 completed (loss: 5.78696346282959, acc: 0.20000000298023224)
[2025-02-17 16:29:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:21,145][root][INFO] - Training Epoch: 1/2, step 155/107898 completed (loss: 0.6149445176124573, acc: 1.0)
[2025-02-17 16:29:21,242][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:21,471][root][INFO] - Training Epoch: 1/2, step 156/107898 completed (loss: 4.672585487365723, acc: 0.20000000298023224)
[2025-02-17 16:29:21,594][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:21,818][root][INFO] - Training Epoch: 1/2, step 157/107898 completed (loss: 4.339608192443848, acc: 0.4444444477558136)
[2025-02-17 16:29:21,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:22,143][root][INFO] - Training Epoch: 1/2, step 158/107898 completed (loss: 2.199470281600952, acc: 0.7333333492279053)
[2025-02-17 16:29:22,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:22,474][root][INFO] - Training Epoch: 1/2, step 159/107898 completed (loss: 0.9319210648536682, acc: 0.875)
[2025-02-17 16:29:22,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:22,790][root][INFO] - Training Epoch: 1/2, step 160/107898 completed (loss: 0.1490841656923294, acc: 1.0)
[2025-02-17 16:29:22,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:23,107][root][INFO] - Training Epoch: 1/2, step 161/107898 completed (loss: 3.766477584838867, acc: 0.3333333432674408)
[2025-02-17 16:29:23,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:23,416][root][INFO] - Training Epoch: 1/2, step 162/107898 completed (loss: 0.37295493483543396, acc: 0.8125)
[2025-02-17 16:29:23,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:23,723][root][INFO] - Training Epoch: 1/2, step 163/107898 completed (loss: 0.12972843647003174, acc: 1.0)
[2025-02-17 16:29:23,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:24,070][root][INFO] - Training Epoch: 1/2, step 164/107898 completed (loss: 0.07437682151794434, acc: 1.0)
[2025-02-17 16:29:24,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:24,395][root][INFO] - Training Epoch: 1/2, step 165/107898 completed (loss: 1.9797706604003906, acc: 0.25)
[2025-02-17 16:29:24,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:24,725][root][INFO] - Training Epoch: 1/2, step 166/107898 completed (loss: 0.9268364310264587, acc: 0.6666666865348816)
[2025-02-17 16:29:24,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:25,081][root][INFO] - Training Epoch: 1/2, step 167/107898 completed (loss: 1.678603172302246, acc: 0.7894737124443054)
[2025-02-17 16:29:25,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:25,402][root][INFO] - Training Epoch: 1/2, step 168/107898 completed (loss: 2.708157539367676, acc: 0.5454545617103577)
[2025-02-17 16:29:25,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:25,713][root][INFO] - Training Epoch: 1/2, step 169/107898 completed (loss: 2.5735766887664795, acc: 0.4000000059604645)
[2025-02-17 16:29:25,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:26,040][root][INFO] - Training Epoch: 1/2, step 170/107898 completed (loss: 2.9548511505126953, acc: 0.5)
[2025-02-17 16:29:26,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:26,388][root][INFO] - Training Epoch: 1/2, step 171/107898 completed (loss: 0.14112667739391327, acc: 1.0)
[2025-02-17 16:29:26,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:26,746][root][INFO] - Training Epoch: 1/2, step 172/107898 completed (loss: 0.5778511762619019, acc: 0.8571428656578064)
[2025-02-17 16:29:26,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:27,099][root][INFO] - Training Epoch: 1/2, step 173/107898 completed (loss: 0.5275182127952576, acc: 0.8571428656578064)
[2025-02-17 16:29:27,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:27,436][root][INFO] - Training Epoch: 1/2, step 174/107898 completed (loss: 1.8516136407852173, acc: 0.6896551847457886)
[2025-02-17 16:29:27,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:27,795][root][INFO] - Training Epoch: 1/2, step 175/107898 completed (loss: 0.1610129028558731, acc: 1.0)
[2025-02-17 16:29:27,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:28,157][root][INFO] - Training Epoch: 1/2, step 176/107898 completed (loss: 0.9380085468292236, acc: 0.8181818127632141)
[2025-02-17 16:29:28,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:28,509][root][INFO] - Training Epoch: 1/2, step 177/107898 completed (loss: 6.256937503814697, acc: 0.3333333432674408)
[2025-02-17 16:29:28,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:28,824][root][INFO] - Training Epoch: 1/2, step 178/107898 completed (loss: 0.5432223081588745, acc: 1.0)
[2025-02-17 16:29:28,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:29,186][root][INFO] - Training Epoch: 1/2, step 179/107898 completed (loss: 1.638226866722107, acc: 0.6842105388641357)
[2025-02-17 16:29:29,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:29,537][root][INFO] - Training Epoch: 1/2, step 180/107898 completed (loss: 0.4217318296432495, acc: 0.875)
[2025-02-17 16:29:29,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:29,849][root][INFO] - Training Epoch: 1/2, step 181/107898 completed (loss: 1.2381312847137451, acc: 0.8888888955116272)
[2025-02-17 16:29:29,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:30,191][root][INFO] - Training Epoch: 1/2, step 182/107898 completed (loss: 0.9333744049072266, acc: 0.8333333134651184)
[2025-02-17 16:29:30,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:30,486][root][INFO] - Training Epoch: 1/2, step 183/107898 completed (loss: 0.6054317951202393, acc: 0.800000011920929)
[2025-02-17 16:29:30,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:30,813][root][INFO] - Training Epoch: 1/2, step 184/107898 completed (loss: 1.6729233264923096, acc: 0.75)
[2025-02-17 16:29:30,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:31,161][root][INFO] - Training Epoch: 1/2, step 185/107898 completed (loss: 0.44483140110969543, acc: 0.8125)
[2025-02-17 16:29:31,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:31,509][root][INFO] - Training Epoch: 1/2, step 186/107898 completed (loss: 2.362516164779663, acc: 0.6666666865348816)
[2025-02-17 16:29:31,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:31,873][root][INFO] - Training Epoch: 1/2, step 187/107898 completed (loss: 1.2490187883377075, acc: 0.5)
[2025-02-17 16:29:32,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:32,221][root][INFO] - Training Epoch: 1/2, step 188/107898 completed (loss: 0.1253209114074707, acc: 1.0)
[2025-02-17 16:29:32,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:32,552][root][INFO] - Training Epoch: 1/2, step 189/107898 completed (loss: 1.03252375125885, acc: 0.800000011920929)
[2025-02-17 16:29:32,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:32,877][root][INFO] - Training Epoch: 1/2, step 190/107898 completed (loss: 1.5512559413909912, acc: 0.75)
[2025-02-17 16:29:32,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:33,205][root][INFO] - Training Epoch: 1/2, step 191/107898 completed (loss: 0.7285441756248474, acc: 0.7272727489471436)
[2025-02-17 16:29:33,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:33,553][root][INFO] - Training Epoch: 1/2, step 192/107898 completed (loss: 0.4622359871864319, acc: 0.8867924809455872)
[2025-02-17 16:29:33,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:33,913][root][INFO] - Training Epoch: 1/2, step 193/107898 completed (loss: 1.4528310298919678, acc: 0.6842105388641357)
[2025-02-17 16:29:33,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:34,221][root][INFO] - Training Epoch: 1/2, step 194/107898 completed (loss: 0.8829837441444397, acc: 0.7272727489471436)
[2025-02-17 16:29:34,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:34,520][root][INFO] - Training Epoch: 1/2, step 195/107898 completed (loss: 4.618692398071289, acc: 0.1111111119389534)
[2025-02-17 16:29:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:34,815][root][INFO] - Training Epoch: 1/2, step 196/107898 completed (loss: 2.881026029586792, acc: 0.5)
[2025-02-17 16:29:34,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:35,116][root][INFO] - Training Epoch: 1/2, step 197/107898 completed (loss: 0.6480968594551086, acc: 0.75)
[2025-02-17 16:29:35,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:35,419][root][INFO] - Training Epoch: 1/2, step 198/107898 completed (loss: 0.09017974138259888, acc: 1.0)
[2025-02-17 16:29:35,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:35,735][root][INFO] - Training Epoch: 1/2, step 199/107898 completed (loss: 2.256992816925049, acc: 0.5)
[2025-02-17 16:29:35,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:36,084][root][INFO] - Training Epoch: 1/2, step 200/107898 completed (loss: 0.9549512267112732, acc: 1.0)
[2025-02-17 16:29:36,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:36,416][root][INFO] - Training Epoch: 1/2, step 201/107898 completed (loss: 5.047313690185547, acc: 0.2857142984867096)
[2025-02-17 16:29:36,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:36,727][root][INFO] - Training Epoch: 1/2, step 202/107898 completed (loss: 1.4230177402496338, acc: 0.6000000238418579)
[2025-02-17 16:29:36,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:37,001][root][INFO] - Training Epoch: 1/2, step 203/107898 completed (loss: 0.8268022537231445, acc: 0.5)
[2025-02-17 16:29:37,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:37,298][root][INFO] - Training Epoch: 1/2, step 204/107898 completed (loss: 8.714895248413086, acc: 0.0)
[2025-02-17 16:29:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:37,597][root][INFO] - Training Epoch: 1/2, step 205/107898 completed (loss: 0.8966620564460754, acc: 0.6666666865348816)
[2025-02-17 16:29:37,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:37,937][root][INFO] - Training Epoch: 1/2, step 206/107898 completed (loss: 3.6963515281677246, acc: 0.5)
[2025-02-17 16:29:38,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:38,259][root][INFO] - Training Epoch: 1/2, step 207/107898 completed (loss: 1.4917048215866089, acc: 0.7272727489471436)
[2025-02-17 16:29:38,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:38,609][root][INFO] - Training Epoch: 1/2, step 208/107898 completed (loss: 1.5054771900177002, acc: 0.695652186870575)
[2025-02-17 16:29:38,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:38,931][root][INFO] - Training Epoch: 1/2, step 209/107898 completed (loss: 1.094952940940857, acc: 0.3333333432674408)
[2025-02-17 16:29:39,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:39,247][root][INFO] - Training Epoch: 1/2, step 210/107898 completed (loss: 0.5334838628768921, acc: 0.5)
[2025-02-17 16:29:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:39,619][root][INFO] - Training Epoch: 1/2, step 211/107898 completed (loss: 0.39321473240852356, acc: 0.8620689511299133)
[2025-02-17 16:29:39,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:40,004][root][INFO] - Training Epoch: 1/2, step 212/107898 completed (loss: 0.5015029311180115, acc: 0.8620689511299133)
[2025-02-17 16:29:40,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:40,341][root][INFO] - Training Epoch: 1/2, step 213/107898 completed (loss: 0.1859074980020523, acc: 1.0)
[2025-02-17 16:29:40,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:40,700][root][INFO] - Training Epoch: 1/2, step 214/107898 completed (loss: 0.7139925956726074, acc: 0.9047619104385376)
[2025-02-17 16:29:40,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:41,013][root][INFO] - Training Epoch: 1/2, step 215/107898 completed (loss: 0.27289944887161255, acc: 1.0)
[2025-02-17 16:29:41,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:41,314][root][INFO] - Training Epoch: 1/2, step 216/107898 completed (loss: 0.07592140883207321, acc: 1.0)
[2025-02-17 16:29:41,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:41,659][root][INFO] - Training Epoch: 1/2, step 217/107898 completed (loss: 2.418684244155884, acc: 0.5)
[2025-02-17 16:29:41,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:41,999][root][INFO] - Training Epoch: 1/2, step 218/107898 completed (loss: 1.605186104774475, acc: 0.6666666865348816)
[2025-02-17 16:29:42,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:42,324][root][INFO] - Training Epoch: 1/2, step 219/107898 completed (loss: 1.6100987195968628, acc: 0.692307710647583)
[2025-02-17 16:29:42,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:42,640][root][INFO] - Training Epoch: 1/2, step 220/107898 completed (loss: 1.735885739326477, acc: 0.5555555820465088)
[2025-02-17 16:29:42,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:42,974][root][INFO] - Training Epoch: 1/2, step 221/107898 completed (loss: 1.0252536535263062, acc: 0.75)
[2025-02-17 16:29:43,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:43,329][root][INFO] - Training Epoch: 1/2, step 222/107898 completed (loss: 0.7884421944618225, acc: 0.800000011920929)
[2025-02-17 16:29:43,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:43,628][root][INFO] - Training Epoch: 1/2, step 223/107898 completed (loss: 0.7871091365814209, acc: 0.6666666865348816)
[2025-02-17 16:29:43,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:43,943][root][INFO] - Training Epoch: 1/2, step 224/107898 completed (loss: 3.067932605743408, acc: 0.5)
[2025-02-17 16:29:44,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:44,260][root][INFO] - Training Epoch: 1/2, step 225/107898 completed (loss: 2.6905453205108643, acc: 0.625)
[2025-02-17 16:29:44,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:44,554][root][INFO] - Training Epoch: 1/2, step 226/107898 completed (loss: 1.4872032403945923, acc: 0.6666666865348816)
[2025-02-17 16:29:44,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:44,935][root][INFO] - Training Epoch: 1/2, step 227/107898 completed (loss: 5.848086357116699, acc: 0.125)
[2025-02-17 16:29:45,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:45,274][root][INFO] - Training Epoch: 1/2, step 228/107898 completed (loss: 1.4746453762054443, acc: 0.6000000238418579)
[2025-02-17 16:29:45,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:45,582][root][INFO] - Training Epoch: 1/2, step 229/107898 completed (loss: 0.40320199728012085, acc: 1.0)
[2025-02-17 16:29:45,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:45,928][root][INFO] - Training Epoch: 1/2, step 230/107898 completed (loss: 0.383401483297348, acc: 0.6666666865348816)
[2025-02-17 16:29:46,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:46,282][root][INFO] - Training Epoch: 1/2, step 231/107898 completed (loss: 0.4635758697986603, acc: 0.8695651888847351)
[2025-02-17 16:29:46,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:46,603][root][INFO] - Training Epoch: 1/2, step 232/107898 completed (loss: 3.8835675716400146, acc: 0.4285714328289032)
[2025-02-17 16:29:46,723][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:46,960][root][INFO] - Training Epoch: 1/2, step 233/107898 completed (loss: 1.9469003677368164, acc: 0.7368420958518982)
[2025-02-17 16:29:47,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:47,312][root][INFO] - Training Epoch: 1/2, step 234/107898 completed (loss: 2.097198963165283, acc: 0.5714285969734192)
[2025-02-17 16:29:47,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:47,626][root][INFO] - Training Epoch: 1/2, step 235/107898 completed (loss: 0.061510585248470306, acc: 1.0)
[2025-02-17 16:29:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:48,030][root][INFO] - Training Epoch: 1/2, step 236/107898 completed (loss: 1.8083921670913696, acc: 0.6666666865348816)
[2025-02-17 16:29:48,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:48,390][root][INFO] - Training Epoch: 1/2, step 237/107898 completed (loss: 3.885481119155884, acc: 0.125)
[2025-02-17 16:29:48,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:48,790][root][INFO] - Training Epoch: 1/2, step 238/107898 completed (loss: 4.385523319244385, acc: 0.3333333432674408)
[2025-02-17 16:29:48,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:49,128][root][INFO] - Training Epoch: 1/2, step 239/107898 completed (loss: 2.0502378940582275, acc: 0.6666666865348816)
[2025-02-17 16:29:49,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:49,483][root][INFO] - Training Epoch: 1/2, step 240/107898 completed (loss: 0.397869348526001, acc: 1.0)
[2025-02-17 16:29:49,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:49,804][root][INFO] - Training Epoch: 1/2, step 241/107898 completed (loss: 0.46142449975013733, acc: 1.0)
[2025-02-17 16:29:49,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:50,145][root][INFO] - Training Epoch: 1/2, step 242/107898 completed (loss: 1.3207621574401855, acc: 0.7692307829856873)
[2025-02-17 16:29:50,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:50,496][root][INFO] - Training Epoch: 1/2, step 243/107898 completed (loss: 0.7867159843444824, acc: 0.800000011920929)
[2025-02-17 16:29:50,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:50,842][root][INFO] - Training Epoch: 1/2, step 244/107898 completed (loss: 1.3493437767028809, acc: 0.7586206793785095)
[2025-02-17 16:29:51,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:51,250][root][INFO] - Training Epoch: 1/2, step 245/107898 completed (loss: 1.148255467414856, acc: 0.7333333492279053)
[2025-02-17 16:29:51,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:51,605][root][INFO] - Training Epoch: 1/2, step 246/107898 completed (loss: 0.43001440167427063, acc: 0.9333333373069763)
[2025-02-17 16:29:51,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:51,961][root][INFO] - Training Epoch: 1/2, step 247/107898 completed (loss: 2.913480281829834, acc: 0.3636363744735718)
[2025-02-17 16:29:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:52,292][root][INFO] - Training Epoch: 1/2, step 248/107898 completed (loss: 1.4231528043746948, acc: 0.5)
[2025-02-17 16:29:52,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:52,679][root][INFO] - Training Epoch: 1/2, step 249/107898 completed (loss: 2.000232458114624, acc: 0.6875)
[2025-02-17 16:29:52,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:53,017][root][INFO] - Training Epoch: 1/2, step 250/107898 completed (loss: 0.7932360172271729, acc: 0.6666666865348816)
[2025-02-17 16:29:53,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:53,360][root][INFO] - Training Epoch: 1/2, step 251/107898 completed (loss: 1.5273619890213013, acc: 0.625)
[2025-02-17 16:29:53,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:53,679][root][INFO] - Training Epoch: 1/2, step 252/107898 completed (loss: 1.4323995113372803, acc: 0.4285714328289032)
[2025-02-17 16:29:53,809][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:54,043][root][INFO] - Training Epoch: 1/2, step 253/107898 completed (loss: 3.2597591876983643, acc: 0.25)
[2025-02-17 16:29:54,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:54,454][root][INFO] - Training Epoch: 1/2, step 254/107898 completed (loss: 4.4035162925720215, acc: 0.2666666805744171)
[2025-02-17 16:29:54,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:54,762][root][INFO] - Training Epoch: 1/2, step 255/107898 completed (loss: 4.953120231628418, acc: 0.0)
[2025-02-17 16:29:54,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:55,102][root][INFO] - Training Epoch: 1/2, step 256/107898 completed (loss: 0.19290567934513092, acc: 1.0)
[2025-02-17 16:29:55,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:55,433][root][INFO] - Training Epoch: 1/2, step 257/107898 completed (loss: 1.1033658981323242, acc: 0.6000000238418579)
[2025-02-17 16:29:55,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:55,718][root][INFO] - Training Epoch: 1/2, step 258/107898 completed (loss: 0.1950903981924057, acc: 1.0)
[2025-02-17 16:29:55,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:56,072][root][INFO] - Training Epoch: 1/2, step 259/107898 completed (loss: 1.109413981437683, acc: 0.6666666865348816)
[2025-02-17 16:29:56,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:56,414][root][INFO] - Training Epoch: 1/2, step 260/107898 completed (loss: 3.1674423217773438, acc: 0.4838709533214569)
[2025-02-17 16:29:56,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:56,725][root][INFO] - Training Epoch: 1/2, step 261/107898 completed (loss: 2.489572286605835, acc: 0.7142857313156128)
[2025-02-17 16:29:56,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:57,011][root][INFO] - Training Epoch: 1/2, step 262/107898 completed (loss: 1.8148845434188843, acc: 0.5)
[2025-02-17 16:29:57,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:57,364][root][INFO] - Training Epoch: 1/2, step 263/107898 completed (loss: 2.777008295059204, acc: 0.4615384638309479)
[2025-02-17 16:29:57,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:57,678][root][INFO] - Training Epoch: 1/2, step 264/107898 completed (loss: 1.872288703918457, acc: 0.5)
[2025-02-17 16:29:57,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:58,038][root][INFO] - Training Epoch: 1/2, step 265/107898 completed (loss: 1.5934191942214966, acc: 0.7200000286102295)
[2025-02-17 16:29:58,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:58,374][root][INFO] - Training Epoch: 1/2, step 266/107898 completed (loss: 1.0373822450637817, acc: 0.8181818127632141)
[2025-02-17 16:29:58,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:58,717][root][INFO] - Training Epoch: 1/2, step 267/107898 completed (loss: 0.5368924140930176, acc: 0.875)
[2025-02-17 16:29:58,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:59,045][root][INFO] - Training Epoch: 1/2, step 268/107898 completed (loss: 2.945587635040283, acc: 0.6000000238418579)
[2025-02-17 16:29:59,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:59,387][root][INFO] - Training Epoch: 1/2, step 269/107898 completed (loss: 0.36233291029930115, acc: 1.0)
[2025-02-17 16:29:59,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:29:59,729][root][INFO] - Training Epoch: 1/2, step 270/107898 completed (loss: 0.24642671644687653, acc: 1.0)
[2025-02-17 16:29:59,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:00,061][root][INFO] - Training Epoch: 1/2, step 271/107898 completed (loss: 0.0636623427271843, acc: 1.0)
[2025-02-17 16:30:00,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:00,362][root][INFO] - Training Epoch: 1/2, step 272/107898 completed (loss: 0.28436279296875, acc: 1.0)
[2025-02-17 16:30:00,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:00,666][root][INFO] - Training Epoch: 1/2, step 273/107898 completed (loss: 4.578287124633789, acc: 0.4000000059604645)
[2025-02-17 16:30:00,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:00,982][root][INFO] - Training Epoch: 1/2, step 274/107898 completed (loss: 0.7942007780075073, acc: 0.8500000238418579)
[2025-02-17 16:30:01,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:01,342][root][INFO] - Training Epoch: 1/2, step 275/107898 completed (loss: 3.325775146484375, acc: 0.5)
[2025-02-17 16:30:01,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:01,649][root][INFO] - Training Epoch: 1/2, step 276/107898 completed (loss: 0.758463442325592, acc: 0.7692307829856873)
[2025-02-17 16:30:01,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:01,966][root][INFO] - Training Epoch: 1/2, step 277/107898 completed (loss: 3.7356905937194824, acc: 0.20000000298023224)
[2025-02-17 16:30:02,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:02,268][root][INFO] - Training Epoch: 1/2, step 278/107898 completed (loss: 0.2422880083322525, acc: 1.0)
[2025-02-17 16:30:02,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:02,581][root][INFO] - Training Epoch: 1/2, step 279/107898 completed (loss: 2.7951302528381348, acc: 0.7142857313156128)
[2025-02-17 16:30:02,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:02,843][root][INFO] - Training Epoch: 1/2, step 280/107898 completed (loss: 1.638763189315796, acc: 0.5)
[2025-02-17 16:30:02,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:03,155][root][INFO] - Training Epoch: 1/2, step 281/107898 completed (loss: 0.1928243339061737, acc: 1.0)
[2025-02-17 16:30:03,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:03,510][root][INFO] - Training Epoch: 1/2, step 282/107898 completed (loss: 1.2106555700302124, acc: 0.800000011920929)
[2025-02-17 16:30:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:03,851][root][INFO] - Training Epoch: 1/2, step 283/107898 completed (loss: 0.3064621388912201, acc: 1.0)
[2025-02-17 16:30:03,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:04,159][root][INFO] - Training Epoch: 1/2, step 284/107898 completed (loss: 1.8326168060302734, acc: 0.6000000238418579)
[2025-02-17 16:30:04,289][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:04,509][root][INFO] - Training Epoch: 1/2, step 285/107898 completed (loss: 0.6305027604103088, acc: 0.7857142686843872)
[2025-02-17 16:30:04,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:04,819][root][INFO] - Training Epoch: 1/2, step 286/107898 completed (loss: 1.4455606937408447, acc: 0.7272727489471436)
[2025-02-17 16:30:04,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:05,103][root][INFO] - Training Epoch: 1/2, step 287/107898 completed (loss: 1.7180449962615967, acc: 0.692307710647583)
[2025-02-17 16:30:05,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:05,408][root][INFO] - Training Epoch: 1/2, step 288/107898 completed (loss: 1.389984369277954, acc: 0.550000011920929)
[2025-02-17 16:30:05,511][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:05,715][root][INFO] - Training Epoch: 1/2, step 289/107898 completed (loss: 1.04513680934906, acc: 0.625)
[2025-02-17 16:30:05,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:06,019][root][INFO] - Training Epoch: 1/2, step 290/107898 completed (loss: 0.6083372235298157, acc: 0.9166666865348816)
[2025-02-17 16:30:06,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:06,331][root][INFO] - Training Epoch: 1/2, step 291/107898 completed (loss: 1.6473215818405151, acc: 0.6666666865348816)
[2025-02-17 16:30:06,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:06,644][root][INFO] - Training Epoch: 1/2, step 292/107898 completed (loss: 1.3533940315246582, acc: 0.7777777910232544)
[2025-02-17 16:30:06,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:06,943][root][INFO] - Training Epoch: 1/2, step 293/107898 completed (loss: 0.07941883057355881, acc: 1.0)
[2025-02-17 16:30:07,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:07,257][root][INFO] - Training Epoch: 1/2, step 294/107898 completed (loss: 3.509951114654541, acc: 0.5)
[2025-02-17 16:30:07,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:07,549][root][INFO] - Training Epoch: 1/2, step 295/107898 completed (loss: 1.0348269939422607, acc: 0.5)
[2025-02-17 16:30:07,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:07,849][root][INFO] - Training Epoch: 1/2, step 296/107898 completed (loss: 1.007129192352295, acc: 0.5)
[2025-02-17 16:30:07,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:08,158][root][INFO] - Training Epoch: 1/2, step 297/107898 completed (loss: 0.14820623397827148, acc: 1.0)
[2025-02-17 16:30:08,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:08,523][root][INFO] - Training Epoch: 1/2, step 298/107898 completed (loss: 0.32132741808891296, acc: 0.9487179517745972)
[2025-02-17 16:30:08,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:08,829][root][INFO] - Training Epoch: 1/2, step 299/107898 completed (loss: 3.6449134349823, acc: 0.6666666865348816)
[2025-02-17 16:30:08,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:09,152][root][INFO] - Training Epoch: 1/2, step 300/107898 completed (loss: 3.0752527713775635, acc: 0.25)
[2025-02-17 16:30:09,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:09,464][root][INFO] - Training Epoch: 1/2, step 301/107898 completed (loss: 0.0826282650232315, acc: 1.0)
[2025-02-17 16:30:09,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:09,789][root][INFO] - Training Epoch: 1/2, step 302/107898 completed (loss: 1.4172502756118774, acc: 0.5)
[2025-02-17 16:30:09,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:10,124][root][INFO] - Training Epoch: 1/2, step 303/107898 completed (loss: 0.476007878780365, acc: 1.0)
[2025-02-17 16:30:10,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:10,470][root][INFO] - Training Epoch: 1/2, step 304/107898 completed (loss: 1.626649022102356, acc: 0.6666666865348816)
[2025-02-17 16:30:10,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:10,822][root][INFO] - Training Epoch: 1/2, step 305/107898 completed (loss: 1.46453857421875, acc: 0.7142857313156128)
[2025-02-17 16:30:10,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:11,178][root][INFO] - Training Epoch: 1/2, step 306/107898 completed (loss: 0.8931882381439209, acc: 0.8285714387893677)
[2025-02-17 16:30:11,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:11,522][root][INFO] - Training Epoch: 1/2, step 307/107898 completed (loss: 0.056234393268823624, acc: 1.0)
[2025-02-17 16:30:11,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:11,863][root][INFO] - Training Epoch: 1/2, step 308/107898 completed (loss: 0.2113819271326065, acc: 1.0)
[2025-02-17 16:30:11,977][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:12,189][root][INFO] - Training Epoch: 1/2, step 309/107898 completed (loss: 0.8146824240684509, acc: 1.0)
[2025-02-17 16:30:12,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:12,527][root][INFO] - Training Epoch: 1/2, step 310/107898 completed (loss: 0.20919732749462128, acc: 1.0)
[2025-02-17 16:30:12,637][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:12,857][root][INFO] - Training Epoch: 1/2, step 311/107898 completed (loss: 1.9284635782241821, acc: 0.6666666865348816)
[2025-02-17 16:30:12,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:13,161][root][INFO] - Training Epoch: 1/2, step 312/107898 completed (loss: 0.0177394300699234, acc: 1.0)
[2025-02-17 16:30:13,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:13,462][root][INFO] - Training Epoch: 1/2, step 313/107898 completed (loss: 4.628235340118408, acc: 0.6666666865348816)
[2025-02-17 16:30:13,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:13,777][root][INFO] - Training Epoch: 1/2, step 314/107898 completed (loss: 1.6975865364074707, acc: 0.7333333492279053)
[2025-02-17 16:30:13,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:14,060][root][INFO] - Training Epoch: 1/2, step 315/107898 completed (loss: 2.0154457092285156, acc: 0.6666666865348816)
[2025-02-17 16:30:14,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:14,356][root][INFO] - Training Epoch: 1/2, step 316/107898 completed (loss: 1.5294179916381836, acc: 0.6666666865348816)
[2025-02-17 16:30:14,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:14,687][root][INFO] - Training Epoch: 1/2, step 317/107898 completed (loss: 2.5968735218048096, acc: 0.6666666865348816)
[2025-02-17 16:30:14,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:14,981][root][INFO] - Training Epoch: 1/2, step 318/107898 completed (loss: 1.7427250146865845, acc: 0.75)
[2025-02-17 16:30:15,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:15,335][root][INFO] - Training Epoch: 1/2, step 319/107898 completed (loss: 0.7553704977035522, acc: 0.8181818127632141)
[2025-02-17 16:30:15,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:15,653][root][INFO] - Training Epoch: 1/2, step 320/107898 completed (loss: 1.505563497543335, acc: 0.75)
[2025-02-17 16:30:15,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:15,951][root][INFO] - Training Epoch: 1/2, step 321/107898 completed (loss: 0.23002025485038757, acc: 1.0)
[2025-02-17 16:30:16,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:16,284][root][INFO] - Training Epoch: 1/2, step 322/107898 completed (loss: 1.0397145748138428, acc: 0.800000011920929)
[2025-02-17 16:30:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:16,594][root][INFO] - Training Epoch: 1/2, step 323/107898 completed (loss: 0.08039498329162598, acc: 1.0)
[2025-02-17 16:30:16,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:16,951][root][INFO] - Training Epoch: 1/2, step 324/107898 completed (loss: 2.1575729846954346, acc: 0.0)
[2025-02-17 16:30:17,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:17,287][root][INFO] - Training Epoch: 1/2, step 325/107898 completed (loss: 1.0483434200286865, acc: 0.8695651888847351)
[2025-02-17 16:30:17,394][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:17,611][root][INFO] - Training Epoch: 1/2, step 326/107898 completed (loss: 4.757124900817871, acc: 0.2222222238779068)
[2025-02-17 16:30:17,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:17,924][root][INFO] - Training Epoch: 1/2, step 327/107898 completed (loss: 0.20008060336112976, acc: 1.0)
[2025-02-17 16:30:18,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:18,228][root][INFO] - Training Epoch: 1/2, step 328/107898 completed (loss: 0.7114468812942505, acc: 1.0)
[2025-02-17 16:30:18,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:18,550][root][INFO] - Training Epoch: 1/2, step 329/107898 completed (loss: 0.13225941359996796, acc: 0.949999988079071)
[2025-02-17 16:30:18,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:18,893][root][INFO] - Training Epoch: 1/2, step 330/107898 completed (loss: 1.1896032094955444, acc: 0.5)
[2025-02-17 16:30:19,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:19,236][root][INFO] - Training Epoch: 1/2, step 331/107898 completed (loss: 0.9184996485710144, acc: 0.5)
[2025-02-17 16:30:19,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:19,571][root][INFO] - Training Epoch: 1/2, step 332/107898 completed (loss: 0.9504464268684387, acc: 0.8260869383811951)
[2025-02-17 16:30:19,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:19,906][root][INFO] - Training Epoch: 1/2, step 333/107898 completed (loss: 1.4374313354492188, acc: 0.6969696879386902)
[2025-02-17 16:30:20,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:20,242][root][INFO] - Training Epoch: 1/2, step 334/107898 completed (loss: 0.45329269766807556, acc: 0.75)
[2025-02-17 16:30:20,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:20,540][root][INFO] - Training Epoch: 1/2, step 335/107898 completed (loss: 3.068683385848999, acc: 0.5)
[2025-02-17 16:30:20,651][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:20,865][root][INFO] - Training Epoch: 1/2, step 336/107898 completed (loss: 0.9927989840507507, acc: 0.8500000238418579)
[2025-02-17 16:30:20,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:21,200][root][INFO] - Training Epoch: 1/2, step 337/107898 completed (loss: 0.5824017524719238, acc: 0.9375)
[2025-02-17 16:30:21,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:21,546][root][INFO] - Training Epoch: 1/2, step 338/107898 completed (loss: 0.010921222157776356, acc: 1.0)
[2025-02-17 16:30:21,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:21,883][root][INFO] - Training Epoch: 1/2, step 339/107898 completed (loss: 0.33172473311424255, acc: 0.8333333134651184)
[2025-02-17 16:30:21,974][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:22,200][root][INFO] - Training Epoch: 1/2, step 340/107898 completed (loss: 3.802910327911377, acc: 0.5)
[2025-02-17 16:30:22,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:22,502][root][INFO] - Training Epoch: 1/2, step 341/107898 completed (loss: 0.735483705997467, acc: 0.8333333134651184)
[2025-02-17 16:30:22,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:22,865][root][INFO] - Training Epoch: 1/2, step 342/107898 completed (loss: 3.0526061058044434, acc: 0.3913043439388275)
[2025-02-17 16:30:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:23,165][root][INFO] - Training Epoch: 1/2, step 343/107898 completed (loss: 1.4714463949203491, acc: 0.5555555820465088)
[2025-02-17 16:30:23,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:23,474][root][INFO] - Training Epoch: 1/2, step 344/107898 completed (loss: 2.1575000286102295, acc: 0.6153846383094788)
[2025-02-17 16:30:23,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:23,846][root][INFO] - Training Epoch: 1/2, step 345/107898 completed (loss: 1.234563946723938, acc: 0.6666666865348816)
[2025-02-17 16:30:23,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:24,192][root][INFO] - Training Epoch: 1/2, step 346/107898 completed (loss: 1.5242711305618286, acc: 0.7307692170143127)
[2025-02-17 16:30:24,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:24,540][root][INFO] - Training Epoch: 1/2, step 347/107898 completed (loss: 0.3976782560348511, acc: 0.8181818127632141)
[2025-02-17 16:30:24,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:24,892][root][INFO] - Training Epoch: 1/2, step 348/107898 completed (loss: 1.125766396522522, acc: 0.8260869383811951)
[2025-02-17 16:30:25,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:25,204][root][INFO] - Training Epoch: 1/2, step 349/107898 completed (loss: 1.217750906944275, acc: 0.6000000238418579)
[2025-02-17 16:30:25,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:25,458][root][INFO] - Training Epoch: 1/2, step 350/107898 completed (loss: 2.9069223403930664, acc: 0.5)
[2025-02-17 16:30:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:25,767][root][INFO] - Training Epoch: 1/2, step 351/107898 completed (loss: 4.9224958419799805, acc: 0.0)
[2025-02-17 16:30:25,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:26,065][root][INFO] - Training Epoch: 1/2, step 352/107898 completed (loss: 0.727566123008728, acc: 0.8461538553237915)
[2025-02-17 16:30:26,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:26,388][root][INFO] - Training Epoch: 1/2, step 353/107898 completed (loss: 2.6666524410247803, acc: 0.6666666865348816)
[2025-02-17 16:30:26,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:26,689][root][INFO] - Training Epoch: 1/2, step 354/107898 completed (loss: 1.9556816816329956, acc: 0.5555555820465088)
[2025-02-17 16:30:26,762][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:26,974][root][INFO] - Training Epoch: 1/2, step 355/107898 completed (loss: 0.007188455667346716, acc: 1.0)
[2025-02-17 16:30:27,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:27,295][root][INFO] - Training Epoch: 1/2, step 356/107898 completed (loss: 5.756645679473877, acc: 0.1428571492433548)
[2025-02-17 16:30:27,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:27,616][root][INFO] - Training Epoch: 1/2, step 357/107898 completed (loss: 1.3938795328140259, acc: 0.6666666865348816)
[2025-02-17 16:30:27,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:27,919][root][INFO] - Training Epoch: 1/2, step 358/107898 completed (loss: 2.8119096755981445, acc: 0.6666666865348816)
[2025-02-17 16:30:28,050][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:28,270][root][INFO] - Training Epoch: 1/2, step 359/107898 completed (loss: 1.0817545652389526, acc: 0.8999999761581421)
[2025-02-17 16:30:28,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:28,593][root][INFO] - Training Epoch: 1/2, step 360/107898 completed (loss: 1.8302785158157349, acc: 0.5909090638160706)
[2025-02-17 16:30:28,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:28,895][root][INFO] - Training Epoch: 1/2, step 361/107898 completed (loss: 1.8398795127868652, acc: 0.5625)
[2025-02-17 16:30:28,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:29,222][root][INFO] - Training Epoch: 1/2, step 362/107898 completed (loss: 0.012494522146880627, acc: 1.0)
[2025-02-17 16:30:29,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:29,547][root][INFO] - Training Epoch: 1/2, step 363/107898 completed (loss: 2.2930755615234375, acc: 0.5862069129943848)
[2025-02-17 16:30:29,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:29,907][root][INFO] - Training Epoch: 1/2, step 364/107898 completed (loss: 2.60861873626709, acc: 0.5428571701049805)
[2025-02-17 16:30:30,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:30,250][root][INFO] - Training Epoch: 1/2, step 365/107898 completed (loss: 0.1836983859539032, acc: 1.0)
[2025-02-17 16:30:30,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:30,590][root][INFO] - Training Epoch: 1/2, step 366/107898 completed (loss: 0.3316709101200104, acc: 1.0)
[2025-02-17 16:30:30,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:30,927][root][INFO] - Training Epoch: 1/2, step 367/107898 completed (loss: 1.6116820573806763, acc: 0.7209302186965942)
[2025-02-17 16:30:31,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:31,276][root][INFO] - Training Epoch: 1/2, step 368/107898 completed (loss: 0.9494211673736572, acc: 0.8148148059844971)
[2025-02-17 16:30:31,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:31,601][root][INFO] - Training Epoch: 1/2, step 369/107898 completed (loss: 1.880429744720459, acc: 0.6666666865348816)
[2025-02-17 16:30:31,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:31,946][root][INFO] - Training Epoch: 1/2, step 370/107898 completed (loss: 1.259717583656311, acc: 0.8333333134651184)
[2025-02-17 16:30:32,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:32,261][root][INFO] - Training Epoch: 1/2, step 371/107898 completed (loss: 1.3580371141433716, acc: 0.5714285969734192)
[2025-02-17 16:30:32,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:32,556][root][INFO] - Training Epoch: 1/2, step 372/107898 completed (loss: 3.983680248260498, acc: 0.5)
[2025-02-17 16:30:32,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:32,872][root][INFO] - Training Epoch: 1/2, step 373/107898 completed (loss: 3.3319971561431885, acc: 0.5)
[2025-02-17 16:30:32,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:33,216][root][INFO] - Training Epoch: 1/2, step 374/107898 completed (loss: 0.26067304611206055, acc: 0.9230769276618958)
[2025-02-17 16:30:33,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:33,556][root][INFO] - Training Epoch: 1/2, step 375/107898 completed (loss: 0.5915195345878601, acc: 0.6666666865348816)
[2025-02-17 16:30:33,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:33,843][root][INFO] - Training Epoch: 1/2, step 376/107898 completed (loss: 0.0306260883808136, acc: 1.0)
[2025-02-17 16:30:33,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:34,155][root][INFO] - Training Epoch: 1/2, step 377/107898 completed (loss: 0.39557456970214844, acc: 1.0)
[2025-02-17 16:30:34,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:34,477][root][INFO] - Training Epoch: 1/2, step 378/107898 completed (loss: 4.715099811553955, acc: 0.2083333283662796)
[2025-02-17 16:30:34,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:34,800][root][INFO] - Training Epoch: 1/2, step 379/107898 completed (loss: 0.8800720572471619, acc: 0.7083333134651184)
[2025-02-17 16:30:34,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:35,096][root][INFO] - Training Epoch: 1/2, step 380/107898 completed (loss: 2.258133888244629, acc: 0.5)
[2025-02-17 16:30:35,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:35,425][root][INFO] - Training Epoch: 1/2, step 381/107898 completed (loss: 1.214034914970398, acc: 0.75)
[2025-02-17 16:30:35,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:35,735][root][INFO] - Training Epoch: 1/2, step 382/107898 completed (loss: 1.289910078048706, acc: 0.6666666865348816)
[2025-02-17 16:30:35,839][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:36,076][root][INFO] - Training Epoch: 1/2, step 383/107898 completed (loss: 1.213268518447876, acc: 0.6363636255264282)
[2025-02-17 16:30:36,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:36,371][root][INFO] - Training Epoch: 1/2, step 384/107898 completed (loss: 0.20579881966114044, acc: 0.9285714030265808)
[2025-02-17 16:30:36,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:36,738][root][INFO] - Training Epoch: 1/2, step 385/107898 completed (loss: 2.0839717388153076, acc: 0.6666666865348816)
[2025-02-17 16:30:36,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:37,067][root][INFO] - Training Epoch: 1/2, step 386/107898 completed (loss: 2.2566771507263184, acc: 0.6153846383094788)
[2025-02-17 16:30:37,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:37,418][root][INFO] - Training Epoch: 1/2, step 387/107898 completed (loss: 4.286598205566406, acc: 0.0)
[2025-02-17 16:30:37,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:37,739][root][INFO] - Training Epoch: 1/2, step 388/107898 completed (loss: 0.730835497379303, acc: 1.0)
[2025-02-17 16:30:37,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:38,049][root][INFO] - Training Epoch: 1/2, step 389/107898 completed (loss: 2.0117053985595703, acc: 0.3333333432674408)
[2025-02-17 16:30:38,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:38,377][root][INFO] - Training Epoch: 1/2, step 390/107898 completed (loss: 1.8195509910583496, acc: 0.6666666865348816)
[2025-02-17 16:30:38,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:38,657][root][INFO] - Training Epoch: 1/2, step 391/107898 completed (loss: 4.5251970291137695, acc: 0.0714285746216774)
[2025-02-17 16:30:38,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:38,960][root][INFO] - Training Epoch: 1/2, step 392/107898 completed (loss: 0.41947221755981445, acc: 1.0)
[2025-02-17 16:30:39,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:39,316][root][INFO] - Training Epoch: 1/2, step 393/107898 completed (loss: 1.8271526098251343, acc: 0.3333333432674408)
[2025-02-17 16:30:39,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:39,659][root][INFO] - Training Epoch: 1/2, step 394/107898 completed (loss: 3.8023204803466797, acc: 0.3333333432674408)
[2025-02-17 16:30:39,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:40,020][root][INFO] - Training Epoch: 1/2, step 395/107898 completed (loss: 0.9996423721313477, acc: 0.7777777910232544)
[2025-02-17 16:30:40,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:40,355][root][INFO] - Training Epoch: 1/2, step 396/107898 completed (loss: 0.8773418068885803, acc: 0.807692289352417)
[2025-02-17 16:30:40,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:40,656][root][INFO] - Training Epoch: 1/2, step 397/107898 completed (loss: 0.8154548406600952, acc: 0.761904776096344)
[2025-02-17 16:30:40,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:40,999][root][INFO] - Training Epoch: 1/2, step 398/107898 completed (loss: 3.505828619003296, acc: 0.5)
[2025-02-17 16:30:41,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:41,330][root][INFO] - Training Epoch: 1/2, step 399/107898 completed (loss: 2.769671678543091, acc: 0.4285714328289032)
[2025-02-17 16:30:41,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:41,657][root][INFO] - Training Epoch: 1/2, step 400/107898 completed (loss: 1.8722472190856934, acc: 0.8125)
[2025-02-17 16:30:41,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:41,990][root][INFO] - Training Epoch: 1/2, step 401/107898 completed (loss: 2.1052534580230713, acc: 0.5)
[2025-02-17 16:30:42,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:42,313][root][INFO] - Training Epoch: 1/2, step 402/107898 completed (loss: 0.7351003289222717, acc: 0.9230769276618958)
[2025-02-17 16:30:42,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:42,611][root][INFO] - Training Epoch: 1/2, step 403/107898 completed (loss: 0.5434924364089966, acc: 0.8636363744735718)
[2025-02-17 16:30:42,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:42,912][root][INFO] - Training Epoch: 1/2, step 404/107898 completed (loss: 2.402909517288208, acc: 0.6666666865348816)
[2025-02-17 16:30:43,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:43,236][root][INFO] - Training Epoch: 1/2, step 405/107898 completed (loss: 0.005878751166164875, acc: 1.0)
[2025-02-17 16:30:43,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:43,547][root][INFO] - Training Epoch: 1/2, step 406/107898 completed (loss: 0.05021323263645172, acc: 1.0)
[2025-02-17 16:30:43,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:43,851][root][INFO] - Training Epoch: 1/2, step 407/107898 completed (loss: 0.05509783327579498, acc: 1.0)
[2025-02-17 16:30:43,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:44,183][root][INFO] - Training Epoch: 1/2, step 408/107898 completed (loss: 0.38036680221557617, acc: 1.0)
[2025-02-17 16:30:44,280][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:44,510][root][INFO] - Training Epoch: 1/2, step 409/107898 completed (loss: 2.558838367462158, acc: 0.3333333432674408)
[2025-02-17 16:30:44,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:44,841][root][INFO] - Training Epoch: 1/2, step 410/107898 completed (loss: 0.04548785462975502, acc: 1.0)
[2025-02-17 16:30:44,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:45,159][root][INFO] - Training Epoch: 1/2, step 411/107898 completed (loss: 0.4160103499889374, acc: 0.95652174949646)
[2025-02-17 16:30:45,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:45,534][root][INFO] - Training Epoch: 1/2, step 412/107898 completed (loss: 2.4697325229644775, acc: 0.5185185074806213)
[2025-02-17 16:30:45,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:45,892][root][INFO] - Training Epoch: 1/2, step 413/107898 completed (loss: 0.5111104846000671, acc: 0.800000011920929)
[2025-02-17 16:30:46,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:46,229][root][INFO] - Training Epoch: 1/2, step 414/107898 completed (loss: 1.556175708770752, acc: 0.6000000238418579)
[2025-02-17 16:30:46,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:46,587][root][INFO] - Training Epoch: 1/2, step 415/107898 completed (loss: 3.001347780227661, acc: 0.4285714328289032)
[2025-02-17 16:30:46,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:46,900][root][INFO] - Training Epoch: 1/2, step 416/107898 completed (loss: 2.0477800369262695, acc: 0.5)
[2025-02-17 16:30:47,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:47,251][root][INFO] - Training Epoch: 1/2, step 417/107898 completed (loss: 0.4463168680667877, acc: 1.0)
[2025-02-17 16:30:47,358][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:47,591][root][INFO] - Training Epoch: 1/2, step 418/107898 completed (loss: 1.8287408351898193, acc: 0.75)
[2025-02-17 16:30:47,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:47,884][root][INFO] - Training Epoch: 1/2, step 419/107898 completed (loss: 1.5070791244506836, acc: 0.8260869383811951)
[2025-02-17 16:30:48,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:48,267][root][INFO] - Training Epoch: 1/2, step 420/107898 completed (loss: 1.8025703430175781, acc: 0.6666666865348816)
[2025-02-17 16:30:48,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:48,608][root][INFO] - Training Epoch: 1/2, step 421/107898 completed (loss: 6.25149393081665, acc: 0.10000000149011612)
[2025-02-17 16:30:48,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:48,981][root][INFO] - Training Epoch: 1/2, step 422/107898 completed (loss: 1.6118055582046509, acc: 0.6000000238418579)
[2025-02-17 16:30:49,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:49,317][root][INFO] - Training Epoch: 1/2, step 423/107898 completed (loss: 0.46340182423591614, acc: 0.8823529481887817)
[2025-02-17 16:30:49,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:49,636][root][INFO] - Training Epoch: 1/2, step 424/107898 completed (loss: 0.5611341595649719, acc: 0.7777777910232544)
[2025-02-17 16:30:49,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:49,999][root][INFO] - Training Epoch: 1/2, step 425/107898 completed (loss: 2.964596748352051, acc: 0.4444444477558136)
[2025-02-17 16:30:50,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:50,355][root][INFO] - Training Epoch: 1/2, step 426/107898 completed (loss: 0.7601210474967957, acc: 0.9166666865348816)
[2025-02-17 16:30:50,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:50,689][root][INFO] - Training Epoch: 1/2, step 427/107898 completed (loss: 2.285710096359253, acc: 0.5789473652839661)
[2025-02-17 16:30:50,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:51,040][root][INFO] - Training Epoch: 1/2, step 428/107898 completed (loss: 1.1895760297775269, acc: 0.5)
[2025-02-17 16:30:51,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:51,423][root][INFO] - Training Epoch: 1/2, step 429/107898 completed (loss: 1.4574090242385864, acc: 0.7857142686843872)
[2025-02-17 16:30:51,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:51,728][root][INFO] - Training Epoch: 1/2, step 430/107898 completed (loss: 2.9112906455993652, acc: 0.5)
[2025-02-17 16:30:51,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:52,038][root][INFO] - Training Epoch: 1/2, step 431/107898 completed (loss: 2.003526210784912, acc: 0.7200000286102295)
[2025-02-17 16:30:52,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:52,393][root][INFO] - Training Epoch: 1/2, step 432/107898 completed (loss: 0.00947361346334219, acc: 1.0)
[2025-02-17 16:30:52,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:52,723][root][INFO] - Training Epoch: 1/2, step 433/107898 completed (loss: 3.578380584716797, acc: 0.3333333432674408)
[2025-02-17 16:30:52,813][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:53,042][root][INFO] - Training Epoch: 1/2, step 434/107898 completed (loss: 0.01602770760655403, acc: 1.0)
[2025-02-17 16:30:53,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:53,356][root][INFO] - Training Epoch: 1/2, step 435/107898 completed (loss: 0.49167600274086, acc: 0.8571428656578064)
[2025-02-17 16:30:53,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:53,678][root][INFO] - Training Epoch: 1/2, step 436/107898 completed (loss: 0.479566752910614, acc: 0.800000011920929)
[2025-02-17 16:30:53,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:53,990][root][INFO] - Training Epoch: 1/2, step 437/107898 completed (loss: 3.909156322479248, acc: 0.0)
[2025-02-17 16:30:54,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:54,348][root][INFO] - Training Epoch: 1/2, step 438/107898 completed (loss: 2.417387008666992, acc: 0.5)
[2025-02-17 16:30:54,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:54,670][root][INFO] - Training Epoch: 1/2, step 439/107898 completed (loss: 0.013642426580190659, acc: 1.0)
[2025-02-17 16:30:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:54,997][root][INFO] - Training Epoch: 1/2, step 440/107898 completed (loss: 2.5606462955474854, acc: 0.5)
[2025-02-17 16:30:55,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:55,334][root][INFO] - Training Epoch: 1/2, step 441/107898 completed (loss: 4.27393102645874, acc: 0.47999998927116394)
[2025-02-17 16:30:55,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:55,671][root][INFO] - Training Epoch: 1/2, step 442/107898 completed (loss: 0.5103539824485779, acc: 0.8529411554336548)
[2025-02-17 16:30:55,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:56,020][root][INFO] - Training Epoch: 1/2, step 443/107898 completed (loss: 3.0077426433563232, acc: 0.5)
[2025-02-17 16:30:56,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:56,355][root][INFO] - Training Epoch: 1/2, step 444/107898 completed (loss: 0.5403836369514465, acc: 0.800000011920929)
[2025-02-17 16:30:56,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:56,693][root][INFO] - Training Epoch: 1/2, step 445/107898 completed (loss: 0.8574416637420654, acc: 0.8148148059844971)
[2025-02-17 16:30:56,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:56,991][root][INFO] - Training Epoch: 1/2, step 446/107898 completed (loss: 1.8220211267471313, acc: 0.7894737124443054)
[2025-02-17 16:30:57,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:57,332][root][INFO] - Training Epoch: 1/2, step 447/107898 completed (loss: 0.12944799661636353, acc: 1.0)
[2025-02-17 16:30:57,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:57,673][root][INFO] - Training Epoch: 1/2, step 448/107898 completed (loss: 2.407583475112915, acc: 0.5625)
[2025-02-17 16:30:57,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:57,990][root][INFO] - Training Epoch: 1/2, step 449/107898 completed (loss: 2.365635395050049, acc: 0.4285714328289032)
[2025-02-17 16:30:58,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:58,264][root][INFO] - Training Epoch: 1/2, step 450/107898 completed (loss: 0.600967526435852, acc: 0.9047619104385376)
[2025-02-17 16:30:58,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:58,584][root][INFO] - Training Epoch: 1/2, step 451/107898 completed (loss: 1.42765474319458, acc: 0.7058823704719543)
[2025-02-17 16:30:58,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:58,894][root][INFO] - Training Epoch: 1/2, step 452/107898 completed (loss: 0.9882054328918457, acc: 0.5)
[2025-02-17 16:30:58,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:59,196][root][INFO] - Training Epoch: 1/2, step 453/107898 completed (loss: 0.04381997883319855, acc: 1.0)
[2025-02-17 16:30:59,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:59,550][root][INFO] - Training Epoch: 1/2, step 454/107898 completed (loss: 2.3159091472625732, acc: 0.5384615659713745)
[2025-02-17 16:30:59,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:30:59,885][root][INFO] - Training Epoch: 1/2, step 455/107898 completed (loss: 0.2895633280277252, acc: 1.0)
[2025-02-17 16:30:59,971][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:00,205][root][INFO] - Training Epoch: 1/2, step 456/107898 completed (loss: 0.056402210146188736, acc: 1.0)
[2025-02-17 16:31:00,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:00,529][root][INFO] - Training Epoch: 1/2, step 457/107898 completed (loss: 2.363110065460205, acc: 0.529411792755127)
[2025-02-17 16:31:00,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:00,874][root][INFO] - Training Epoch: 1/2, step 458/107898 completed (loss: 1.4832614660263062, acc: 0.5)
[2025-02-17 16:31:00,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:01,181][root][INFO] - Training Epoch: 1/2, step 459/107898 completed (loss: 0.025308050215244293, acc: 1.0)
[2025-02-17 16:31:01,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:01,499][root][INFO] - Training Epoch: 1/2, step 460/107898 completed (loss: 0.1665816456079483, acc: 1.0)
[2025-02-17 16:31:01,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:01,882][root][INFO] - Training Epoch: 1/2, step 461/107898 completed (loss: 0.9557716250419617, acc: 0.8500000238418579)
[2025-02-17 16:31:02,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:02,244][root][INFO] - Training Epoch: 1/2, step 462/107898 completed (loss: 2.2074337005615234, acc: 0.5)
[2025-02-17 16:31:02,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:02,612][root][INFO] - Training Epoch: 1/2, step 463/107898 completed (loss: 0.47716256976127625, acc: 0.8947368264198303)
[2025-02-17 16:31:02,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:02,990][root][INFO] - Training Epoch: 1/2, step 464/107898 completed (loss: 2.630598783493042, acc: 0.25)
[2025-02-17 16:31:03,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:03,365][root][INFO] - Training Epoch: 1/2, step 465/107898 completed (loss: 0.7869285941123962, acc: 0.7777777910232544)
[2025-02-17 16:31:03,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:03,750][root][INFO] - Training Epoch: 1/2, step 466/107898 completed (loss: 1.084712028503418, acc: 0.8333333134651184)
[2025-02-17 16:31:03,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:04,082][root][INFO] - Training Epoch: 1/2, step 467/107898 completed (loss: 0.033849604427814484, acc: 1.0)
[2025-02-17 16:31:04,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:04,403][root][INFO] - Training Epoch: 1/2, step 468/107898 completed (loss: 1.454671025276184, acc: 0.6666666865348816)
[2025-02-17 16:31:04,503][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:04,746][root][INFO] - Training Epoch: 1/2, step 469/107898 completed (loss: 0.845975935459137, acc: 1.0)
[2025-02-17 16:31:04,872][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:05,097][root][INFO] - Training Epoch: 1/2, step 470/107898 completed (loss: 0.4113851487636566, acc: 0.9285714030265808)
[2025-02-17 16:31:05,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:05,409][root][INFO] - Training Epoch: 1/2, step 471/107898 completed (loss: 0.015286123380064964, acc: 1.0)
[2025-02-17 16:31:05,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:05,717][root][INFO] - Training Epoch: 1/2, step 472/107898 completed (loss: 0.015106123872101307, acc: 1.0)
[2025-02-17 16:31:05,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:06,079][root][INFO] - Training Epoch: 1/2, step 473/107898 completed (loss: 0.030367450788617134, acc: 1.0)
[2025-02-17 16:31:06,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:06,404][root][INFO] - Training Epoch: 1/2, step 474/107898 completed (loss: 1.848620891571045, acc: 0.5)
[2025-02-17 16:31:06,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:06,715][root][INFO] - Training Epoch: 1/2, step 475/107898 completed (loss: 4.212271213531494, acc: 0.3076923191547394)
[2025-02-17 16:31:06,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:07,009][root][INFO] - Training Epoch: 1/2, step 476/107898 completed (loss: 1.5441336631774902, acc: 0.5)
[2025-02-17 16:31:07,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:07,314][root][INFO] - Training Epoch: 1/2, step 477/107898 completed (loss: 1.7004436254501343, acc: 0.625)
[2025-02-17 16:31:07,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:07,631][root][INFO] - Training Epoch: 1/2, step 478/107898 completed (loss: 0.013540808111429214, acc: 1.0)
[2025-02-17 16:31:07,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:07,960][root][INFO] - Training Epoch: 1/2, step 479/107898 completed (loss: 4.641019821166992, acc: 0.3333333432674408)
[2025-02-17 16:31:08,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:08,302][root][INFO] - Training Epoch: 1/2, step 480/107898 completed (loss: 1.463418960571289, acc: 0.7142857313156128)
[2025-02-17 16:31:08,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:08,617][root][INFO] - Training Epoch: 1/2, step 481/107898 completed (loss: 1.1558653116226196, acc: 0.5)
[2025-02-17 16:31:08,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:08,900][root][INFO] - Training Epoch: 1/2, step 482/107898 completed (loss: 1.893233060836792, acc: 0.6842105388641357)
[2025-02-17 16:31:09,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:09,216][root][INFO] - Training Epoch: 1/2, step 483/107898 completed (loss: 2.892340660095215, acc: 0.6666666865348816)
[2025-02-17 16:31:09,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:09,573][root][INFO] - Training Epoch: 1/2, step 484/107898 completed (loss: 0.4202537536621094, acc: 0.9166666865348816)
[2025-02-17 16:31:09,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:09,912][root][INFO] - Training Epoch: 1/2, step 485/107898 completed (loss: 0.0372622050344944, acc: 1.0)
[2025-02-17 16:31:10,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:10,210][root][INFO] - Training Epoch: 1/2, step 486/107898 completed (loss: 0.09903384000062943, acc: 1.0)
[2025-02-17 16:31:10,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:10,537][root][INFO] - Training Epoch: 1/2, step 487/107898 completed (loss: 0.4183749258518219, acc: 0.7272727489471436)
[2025-02-17 16:31:10,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:10,863][root][INFO] - Training Epoch: 1/2, step 488/107898 completed (loss: 3.611570358276367, acc: 0.4000000059604645)
[2025-02-17 16:31:10,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:11,190][root][INFO] - Training Epoch: 1/2, step 489/107898 completed (loss: 0.37715330719947815, acc: 1.0)
[2025-02-17 16:31:11,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:11,498][root][INFO] - Training Epoch: 1/2, step 490/107898 completed (loss: 0.4533552825450897, acc: 0.9090909361839294)
[2025-02-17 16:31:11,577][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:11,799][root][INFO] - Training Epoch: 1/2, step 491/107898 completed (loss: 0.27350297570228577, acc: 1.0)
[2025-02-17 16:31:11,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:12,110][root][INFO] - Training Epoch: 1/2, step 492/107898 completed (loss: 0.6648941040039062, acc: 0.75)
[2025-02-17 16:31:12,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:12,419][root][INFO] - Training Epoch: 1/2, step 493/107898 completed (loss: 1.6163721084594727, acc: 0.625)
[2025-02-17 16:31:12,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:12,707][root][INFO] - Training Epoch: 1/2, step 494/107898 completed (loss: 1.8062081336975098, acc: 0.6470588445663452)
[2025-02-17 16:31:12,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:13,027][root][INFO] - Training Epoch: 1/2, step 495/107898 completed (loss: 1.0906665325164795, acc: 0.8125)
[2025-02-17 16:31:13,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:13,342][root][INFO] - Training Epoch: 1/2, step 496/107898 completed (loss: 0.12269426137208939, acc: 1.0)
[2025-02-17 16:31:13,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:13,690][root][INFO] - Training Epoch: 1/2, step 497/107898 completed (loss: 1.5828778743743896, acc: 0.7368420958518982)
[2025-02-17 16:31:13,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:14,050][root][INFO] - Training Epoch: 1/2, step 498/107898 completed (loss: 2.3238205909729004, acc: 0.4375)
[2025-02-17 16:31:14,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:14,359][root][INFO] - Training Epoch: 1/2, step 499/107898 completed (loss: 0.02328423038125038, acc: 1.0)
[2025-02-17 16:31:14,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:14,698][root][INFO] - Training Epoch: 1/2, step 500/107898 completed (loss: 3.2360916137695312, acc: 0.5)
[2025-02-17 16:31:14,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:15,041][root][INFO] - Training Epoch: 1/2, step 501/107898 completed (loss: 1.223031759262085, acc: 0.692307710647583)
[2025-02-17 16:31:15,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:15,379][root][INFO] - Training Epoch: 1/2, step 502/107898 completed (loss: 0.7430229187011719, acc: 0.8148148059844971)
[2025-02-17 16:31:15,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:15,694][root][INFO] - Training Epoch: 1/2, step 503/107898 completed (loss: 1.3201121091842651, acc: 0.5714285969734192)
[2025-02-17 16:31:15,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:16,013][root][INFO] - Training Epoch: 1/2, step 504/107898 completed (loss: 0.011577914468944073, acc: 1.0)
[2025-02-17 16:31:16,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:16,333][root][INFO] - Training Epoch: 1/2, step 505/107898 completed (loss: 0.5383284091949463, acc: 0.9166666865348816)
[2025-02-17 16:31:16,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:16,627][root][INFO] - Training Epoch: 1/2, step 506/107898 completed (loss: 0.10659974813461304, acc: 1.0)
[2025-02-17 16:31:16,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:16,928][root][INFO] - Training Epoch: 1/2, step 507/107898 completed (loss: 0.6069440245628357, acc: 0.800000011920929)
[2025-02-17 16:31:17,036][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:17,247][root][INFO] - Training Epoch: 1/2, step 508/107898 completed (loss: 0.21243789792060852, acc: 1.0)
[2025-02-17 16:31:17,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:17,568][root][INFO] - Training Epoch: 1/2, step 509/107898 completed (loss: 0.8353193998336792, acc: 0.9047619104385376)
[2025-02-17 16:31:17,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:17,883][root][INFO] - Training Epoch: 1/2, step 510/107898 completed (loss: 1.008548378944397, acc: 0.8484848737716675)
[2025-02-17 16:31:17,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:18,178][root][INFO] - Training Epoch: 1/2, step 511/107898 completed (loss: 1.0744134187698364, acc: 0.7142857313156128)
[2025-02-17 16:31:18,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:18,495][root][INFO] - Training Epoch: 1/2, step 512/107898 completed (loss: 0.940471351146698, acc: 0.7916666865348816)
[2025-02-17 16:31:18,569][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:18,782][root][INFO] - Training Epoch: 1/2, step 513/107898 completed (loss: 1.2209476232528687, acc: 0.5)
[2025-02-17 16:31:18,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:19,077][root][INFO] - Training Epoch: 1/2, step 514/107898 completed (loss: 1.2521175146102905, acc: 0.625)
[2025-02-17 16:31:19,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:19,373][root][INFO] - Training Epoch: 1/2, step 515/107898 completed (loss: 0.008408918045461178, acc: 1.0)
[2025-02-17 16:31:19,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:19,674][root][INFO] - Training Epoch: 1/2, step 516/107898 completed (loss: 0.018635084852576256, acc: 1.0)
[2025-02-17 16:31:19,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:19,954][root][INFO] - Training Epoch: 1/2, step 517/107898 completed (loss: 1.806037425994873, acc: 0.5333333611488342)
[2025-02-17 16:31:20,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:20,247][root][INFO] - Training Epoch: 1/2, step 518/107898 completed (loss: 0.005182916298508644, acc: 1.0)
[2025-02-17 16:31:20,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:20,516][root][INFO] - Training Epoch: 1/2, step 519/107898 completed (loss: 1.4557032585144043, acc: 0.7586206793785095)
[2025-02-17 16:31:20,596][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:20,815][root][INFO] - Training Epoch: 1/2, step 520/107898 completed (loss: 0.11865602433681488, acc: 1.0)
[2025-02-17 16:31:20,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:21,108][root][INFO] - Training Epoch: 1/2, step 521/107898 completed (loss: 2.6164138317108154, acc: 0.5)
[2025-02-17 16:31:21,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:21,389][root][INFO] - Training Epoch: 1/2, step 522/107898 completed (loss: 0.8914152979850769, acc: 0.875)
[2025-02-17 16:31:21,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:21,708][root][INFO] - Training Epoch: 1/2, step 523/107898 completed (loss: 1.1250746250152588, acc: 0.7878788113594055)
[2025-02-17 16:31:21,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:22,038][root][INFO] - Training Epoch: 1/2, step 524/107898 completed (loss: 7.172520160675049, acc: 0.0)
[2025-02-17 16:31:22,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:22,355][root][INFO] - Training Epoch: 1/2, step 525/107898 completed (loss: 1.7524899244308472, acc: 0.6666666865348816)
[2025-02-17 16:31:22,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:22,662][root][INFO] - Training Epoch: 1/2, step 526/107898 completed (loss: 0.01464824564754963, acc: 1.0)
[2025-02-17 16:31:22,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:22,970][root][INFO] - Training Epoch: 1/2, step 527/107898 completed (loss: 1.5130715370178223, acc: 0.5)
[2025-02-17 16:31:23,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:23,301][root][INFO] - Training Epoch: 1/2, step 528/107898 completed (loss: 3.8452200889587402, acc: 0.10000000149011612)
[2025-02-17 16:31:23,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:23,603][root][INFO] - Training Epoch: 1/2, step 529/107898 completed (loss: 1.5533394813537598, acc: 0.6153846383094788)
[2025-02-17 16:31:23,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:23,952][root][INFO] - Training Epoch: 1/2, step 530/107898 completed (loss: 2.665479898452759, acc: 0.6666666865348816)
[2025-02-17 16:31:24,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:24,255][root][INFO] - Training Epoch: 1/2, step 531/107898 completed (loss: 0.005224752705544233, acc: 1.0)
[2025-02-17 16:31:24,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:24,550][root][INFO] - Training Epoch: 1/2, step 532/107898 completed (loss: 0.004555511754006147, acc: 1.0)
[2025-02-17 16:31:24,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:24,854][root][INFO] - Training Epoch: 1/2, step 533/107898 completed (loss: 0.08570593595504761, acc: 1.0)
[2025-02-17 16:31:24,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:25,175][root][INFO] - Training Epoch: 1/2, step 534/107898 completed (loss: 1.1866828203201294, acc: 0.7083333134651184)
[2025-02-17 16:31:25,250][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:25,463][root][INFO] - Training Epoch: 1/2, step 535/107898 completed (loss: 0.1357855200767517, acc: 1.0)
[2025-02-17 16:31:25,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:25,756][root][INFO] - Training Epoch: 1/2, step 536/107898 completed (loss: 0.40602749586105347, acc: 0.8888888955116272)
[2025-02-17 16:31:25,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:26,054][root][INFO] - Training Epoch: 1/2, step 537/107898 completed (loss: 3.4640285968780518, acc: 0.4000000059604645)
[2025-02-17 16:31:26,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:26,361][root][INFO] - Training Epoch: 1/2, step 538/107898 completed (loss: 2.4045841693878174, acc: 0.6666666865348816)
[2025-02-17 16:31:26,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:26,656][root][INFO] - Training Epoch: 1/2, step 539/107898 completed (loss: 0.6005109548568726, acc: 0.9130434989929199)
[2025-02-17 16:31:26,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:26,951][root][INFO] - Training Epoch: 1/2, step 540/107898 completed (loss: 2.3843188285827637, acc: 0.625)
[2025-02-17 16:31:27,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:27,269][root][INFO] - Training Epoch: 1/2, step 541/107898 completed (loss: 1.2076621055603027, acc: 0.75)
[2025-02-17 16:31:27,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:27,560][root][INFO] - Training Epoch: 1/2, step 542/107898 completed (loss: 1.018526554107666, acc: 1.0)
[2025-02-17 16:31:27,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:27,890][root][INFO] - Training Epoch: 1/2, step 543/107898 completed (loss: 2.649808168411255, acc: 0.5909090638160706)
[2025-02-17 16:31:27,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:28,220][root][INFO] - Training Epoch: 1/2, step 544/107898 completed (loss: 0.015320012345910072, acc: 1.0)
[2025-02-17 16:31:28,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:28,527][root][INFO] - Training Epoch: 1/2, step 545/107898 completed (loss: 0.004899646155536175, acc: 1.0)
[2025-02-17 16:31:28,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:28,879][root][INFO] - Training Epoch: 1/2, step 546/107898 completed (loss: 1.1105830669403076, acc: 0.8214285969734192)
[2025-02-17 16:31:28,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:29,209][root][INFO] - Training Epoch: 1/2, step 547/107898 completed (loss: 0.8986631035804749, acc: 0.8181818127632141)
[2025-02-17 16:31:29,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:29,517][root][INFO] - Training Epoch: 1/2, step 548/107898 completed (loss: 0.029081281274557114, acc: 1.0)
[2025-02-17 16:31:29,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:29,837][root][INFO] - Training Epoch: 1/2, step 549/107898 completed (loss: 0.20652836561203003, acc: 1.0)
[2025-02-17 16:31:29,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:30,208][root][INFO] - Training Epoch: 1/2, step 550/107898 completed (loss: 0.0713639110326767, acc: 1.0)
[2025-02-17 16:31:30,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:30,543][root][INFO] - Training Epoch: 1/2, step 551/107898 completed (loss: 1.1123262643814087, acc: 0.75)
[2025-02-17 16:31:30,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:30,856][root][INFO] - Training Epoch: 1/2, step 552/107898 completed (loss: 2.5172321796417236, acc: 0.4444444477558136)
[2025-02-17 16:31:30,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:31,190][root][INFO] - Training Epoch: 1/2, step 553/107898 completed (loss: 1.0808039903640747, acc: 0.692307710647583)
[2025-02-17 16:31:31,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:31,513][root][INFO] - Training Epoch: 1/2, step 554/107898 completed (loss: 1.4602082967758179, acc: 0.7692307829856873)
[2025-02-17 16:31:31,627][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:31,845][root][INFO] - Training Epoch: 1/2, step 555/107898 completed (loss: 0.9328830242156982, acc: 0.8125)
[2025-02-17 16:31:31,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:32,138][root][INFO] - Training Epoch: 1/2, step 556/107898 completed (loss: 0.41959497332572937, acc: 1.0)
[2025-02-17 16:31:32,242][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:32,466][root][INFO] - Training Epoch: 1/2, step 557/107898 completed (loss: 1.1429980993270874, acc: 0.5)
[2025-02-17 16:31:32,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:32,779][root][INFO] - Training Epoch: 1/2, step 558/107898 completed (loss: 1.5765361785888672, acc: 0.5)
[2025-02-17 16:31:32,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:33,088][root][INFO] - Training Epoch: 1/2, step 559/107898 completed (loss: 1.601825475692749, acc: 0.699999988079071)
[2025-02-17 16:31:33,171][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:33,359][root][INFO] - Training Epoch: 1/2, step 560/107898 completed (loss: 0.013184435665607452, acc: 1.0)
[2025-02-17 16:31:33,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:33,668][root][INFO] - Training Epoch: 1/2, step 561/107898 completed (loss: 0.04896035045385361, acc: 1.0)
[2025-02-17 16:31:33,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:34,002][root][INFO] - Training Epoch: 1/2, step 562/107898 completed (loss: 0.008526228368282318, acc: 1.0)
[2025-02-17 16:31:34,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:34,317][root][INFO] - Training Epoch: 1/2, step 563/107898 completed (loss: 1.0010801553726196, acc: 0.5)
[2025-02-17 16:31:34,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:34,640][root][INFO] - Training Epoch: 1/2, step 564/107898 completed (loss: 2.724323272705078, acc: 0.5333333611488342)
[2025-02-17 16:31:34,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:34,962][root][INFO] - Training Epoch: 1/2, step 565/107898 completed (loss: 0.24848872423171997, acc: 0.8888888955116272)
[2025-02-17 16:31:35,062][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:35,277][root][INFO] - Training Epoch: 1/2, step 566/107898 completed (loss: 4.459848403930664, acc: 0.25)
[2025-02-17 16:31:35,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:35,586][root][INFO] - Training Epoch: 1/2, step 567/107898 completed (loss: 0.09319364279508591, acc: 1.0)
[2025-02-17 16:31:35,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:35,964][root][INFO] - Training Epoch: 1/2, step 568/107898 completed (loss: 0.8487676382064819, acc: 0.7272727489471436)
[2025-02-17 16:31:36,046][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:36,263][root][INFO] - Training Epoch: 1/2, step 569/107898 completed (loss: 1.9956440925598145, acc: 0.5)
[2025-02-17 16:31:36,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:36,565][root][INFO] - Training Epoch: 1/2, step 570/107898 completed (loss: 1.5032680034637451, acc: 0.6666666865348816)
[2025-02-17 16:31:36,678][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:36,853][root][INFO] - Training Epoch: 1/2, step 571/107898 completed (loss: 1.830025553703308, acc: 0.4545454680919647)
[2025-02-17 16:31:36,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:37,198][root][INFO] - Training Epoch: 1/2, step 572/107898 completed (loss: 1.7785896062850952, acc: 0.6666666865348816)
[2025-02-17 16:31:37,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:37,566][root][INFO] - Training Epoch: 1/2, step 573/107898 completed (loss: 3.282191514968872, acc: 0.4444444477558136)
[2025-02-17 16:31:37,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:37,879][root][INFO] - Training Epoch: 1/2, step 574/107898 completed (loss: 2.4419338703155518, acc: 0.6666666865348816)
[2025-02-17 16:31:38,032][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:38,262][root][INFO] - Training Epoch: 1/2, step 575/107898 completed (loss: 1.0342097282409668, acc: 0.875)
[2025-02-17 16:31:38,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:38,612][root][INFO] - Training Epoch: 1/2, step 576/107898 completed (loss: 1.1666227579116821, acc: 0.8461538553237915)
[2025-02-17 16:31:38,694][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:38,913][root][INFO] - Training Epoch: 1/2, step 577/107898 completed (loss: 1.0921499729156494, acc: 0.8181818127632141)
[2025-02-17 16:31:39,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:39,266][root][INFO] - Training Epoch: 1/2, step 578/107898 completed (loss: 0.39539995789527893, acc: 0.8965517282485962)
[2025-02-17 16:31:39,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:39,608][root][INFO] - Training Epoch: 1/2, step 579/107898 completed (loss: 0.8560784459114075, acc: 0.807692289352417)
[2025-02-17 16:31:39,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:39,920][root][INFO] - Training Epoch: 1/2, step 580/107898 completed (loss: 0.2551276981830597, acc: 1.0)
[2025-02-17 16:31:40,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:40,281][root][INFO] - Training Epoch: 1/2, step 581/107898 completed (loss: 1.576809287071228, acc: 0.6785714030265808)
[2025-02-17 16:31:40,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:40,578][root][INFO] - Training Epoch: 1/2, step 582/107898 completed (loss: 0.8859637379646301, acc: 0.7222222089767456)
[2025-02-17 16:31:40,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:40,920][root][INFO] - Training Epoch: 1/2, step 583/107898 completed (loss: 3.818242073059082, acc: 0.3333333432674408)
[2025-02-17 16:31:41,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:41,242][root][INFO] - Training Epoch: 1/2, step 584/107898 completed (loss: 0.8201454877853394, acc: 0.75)
[2025-02-17 16:31:41,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:41,556][root][INFO] - Training Epoch: 1/2, step 585/107898 completed (loss: 1.3472349643707275, acc: 0.699999988079071)
[2025-02-17 16:31:41,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:41,904][root][INFO] - Training Epoch: 1/2, step 586/107898 completed (loss: 4.0526580810546875, acc: 0.3333333432674408)
[2025-02-17 16:31:41,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:42,219][root][INFO] - Training Epoch: 1/2, step 587/107898 completed (loss: 0.16613569855690002, acc: 1.0)
[2025-02-17 16:31:42,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:42,510][root][INFO] - Training Epoch: 1/2, step 588/107898 completed (loss: 0.7663344740867615, acc: 0.6666666865348816)
[2025-02-17 16:31:42,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:42,857][root][INFO] - Training Epoch: 1/2, step 589/107898 completed (loss: 0.031230201944708824, acc: 1.0)
[2025-02-17 16:31:42,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:43,202][root][INFO] - Training Epoch: 1/2, step 590/107898 completed (loss: 0.6792568564414978, acc: 0.8333333134651184)
[2025-02-17 16:31:43,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:43,485][root][INFO] - Training Epoch: 1/2, step 591/107898 completed (loss: 0.01824149116873741, acc: 1.0)
[2025-02-17 16:31:43,596][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:43,809][root][INFO] - Training Epoch: 1/2, step 592/107898 completed (loss: 3.0360002517700195, acc: 0.5)
[2025-02-17 16:31:43,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:44,109][root][INFO] - Training Epoch: 1/2, step 593/107898 completed (loss: 1.0944117307662964, acc: 0.7857142686843872)
[2025-02-17 16:31:44,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:44,408][root][INFO] - Training Epoch: 1/2, step 594/107898 completed (loss: 3.850876808166504, acc: 0.0)
[2025-02-17 16:31:44,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:44,712][root][INFO] - Training Epoch: 1/2, step 595/107898 completed (loss: 0.06270511448383331, acc: 1.0)
[2025-02-17 16:31:44,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:45,054][root][INFO] - Training Epoch: 1/2, step 596/107898 completed (loss: 1.0076658725738525, acc: 0.6000000238418579)
[2025-02-17 16:31:45,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:45,398][root][INFO] - Training Epoch: 1/2, step 597/107898 completed (loss: 0.21829381585121155, acc: 1.0)
[2025-02-17 16:31:45,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:45,718][root][INFO] - Training Epoch: 1/2, step 598/107898 completed (loss: 0.38375452160835266, acc: 1.0)
[2025-02-17 16:31:45,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:46,015][root][INFO] - Training Epoch: 1/2, step 599/107898 completed (loss: 0.0325830839574337, acc: 1.0)
[2025-02-17 16:31:46,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:46,307][root][INFO] - Training Epoch: 1/2, step 600/107898 completed (loss: 0.029267622157931328, acc: 1.0)
[2025-02-17 16:31:46,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:46,649][root][INFO] - Training Epoch: 1/2, step 601/107898 completed (loss: 1.4641162157058716, acc: 0.5)
[2025-02-17 16:31:46,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:47,012][root][INFO] - Training Epoch: 1/2, step 602/107898 completed (loss: 1.58255136013031, acc: 0.761904776096344)
[2025-02-17 16:31:47,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:47,360][root][INFO] - Training Epoch: 1/2, step 603/107898 completed (loss: 0.9977120161056519, acc: 0.7222222089767456)
[2025-02-17 16:31:47,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:47,673][root][INFO] - Training Epoch: 1/2, step 604/107898 completed (loss: 0.05450050160288811, acc: 1.0)
[2025-02-17 16:31:47,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:48,029][root][INFO] - Training Epoch: 1/2, step 605/107898 completed (loss: 1.0166635513305664, acc: 0.7407407164573669)
[2025-02-17 16:31:48,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:48,361][root][INFO] - Training Epoch: 1/2, step 606/107898 completed (loss: 1.2345370054244995, acc: 0.7272727489471436)
[2025-02-17 16:31:48,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:48,671][root][INFO] - Training Epoch: 1/2, step 607/107898 completed (loss: 4.149986267089844, acc: 0.375)
[2025-02-17 16:31:48,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:49,011][root][INFO] - Training Epoch: 1/2, step 608/107898 completed (loss: 0.2651525139808655, acc: 0.9333333373069763)
[2025-02-17 16:31:49,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:49,343][root][INFO] - Training Epoch: 1/2, step 609/107898 completed (loss: 0.8775314688682556, acc: 0.8333333134651184)
[2025-02-17 16:31:49,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:49,660][root][INFO] - Training Epoch: 1/2, step 610/107898 completed (loss: 0.6491901278495789, acc: 0.8333333134651184)
[2025-02-17 16:31:49,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:50,002][root][INFO] - Training Epoch: 1/2, step 611/107898 completed (loss: 0.09544169157743454, acc: 1.0)
[2025-02-17 16:31:50,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:50,332][root][INFO] - Training Epoch: 1/2, step 612/107898 completed (loss: 1.4798072576522827, acc: 0.7407407164573669)
[2025-02-17 16:31:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:50,698][root][INFO] - Training Epoch: 1/2, step 613/107898 completed (loss: 1.997628092765808, acc: 0.5555555820465088)
[2025-02-17 16:31:50,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:51,058][root][INFO] - Training Epoch: 1/2, step 614/107898 completed (loss: 1.779520869255066, acc: 0.6666666865348816)
[2025-02-17 16:31:51,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:51,378][root][INFO] - Training Epoch: 1/2, step 615/107898 completed (loss: 0.05814047530293465, acc: 1.0)
[2025-02-17 16:31:51,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:51,703][root][INFO] - Training Epoch: 1/2, step 616/107898 completed (loss: 1.1498262882232666, acc: 0.5)
[2025-02-17 16:31:51,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:52,030][root][INFO] - Training Epoch: 1/2, step 617/107898 completed (loss: 2.197800636291504, acc: 0.5555555820465088)
[2025-02-17 16:31:52,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:52,340][root][INFO] - Training Epoch: 1/2, step 618/107898 completed (loss: 0.015742354094982147, acc: 1.0)
[2025-02-17 16:31:52,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:52,682][root][INFO] - Training Epoch: 1/2, step 619/107898 completed (loss: 1.979363203048706, acc: 0.5714285969734192)
[2025-02-17 16:31:52,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:53,022][root][INFO] - Training Epoch: 1/2, step 620/107898 completed (loss: 0.8598675727844238, acc: 0.75)
[2025-02-17 16:31:53,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:53,351][root][INFO] - Training Epoch: 1/2, step 621/107898 completed (loss: 3.3603410720825195, acc: 0.3333333432674408)
[2025-02-17 16:31:53,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:53,664][root][INFO] - Training Epoch: 1/2, step 622/107898 completed (loss: 0.019471026957035065, acc: 1.0)
[2025-02-17 16:31:53,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:53,969][root][INFO] - Training Epoch: 1/2, step 623/107898 completed (loss: 0.8850016593933105, acc: 0.7647058963775635)
[2025-02-17 16:31:54,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:54,273][root][INFO] - Training Epoch: 1/2, step 624/107898 completed (loss: 1.9696811437606812, acc: 0.6666666865348816)
[2025-02-17 16:31:54,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:54,589][root][INFO] - Training Epoch: 1/2, step 625/107898 completed (loss: 0.21512506902217865, acc: 0.9166666865348816)
[2025-02-17 16:31:54,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:54,895][root][INFO] - Training Epoch: 1/2, step 626/107898 completed (loss: 5.03289794921875, acc: 0.3125)
[2025-02-17 16:31:54,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:55,200][root][INFO] - Training Epoch: 1/2, step 627/107898 completed (loss: 0.2902667820453644, acc: 1.0)
[2025-02-17 16:31:55,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:55,498][root][INFO] - Training Epoch: 1/2, step 628/107898 completed (loss: 4.9931416511535645, acc: 0.1071428582072258)
[2025-02-17 16:31:55,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:55,802][root][INFO] - Training Epoch: 1/2, step 629/107898 completed (loss: 0.30169546604156494, acc: 1.0)
[2025-02-17 16:31:55,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:56,069][root][INFO] - Training Epoch: 1/2, step 630/107898 completed (loss: 1.2009459733963013, acc: 0.7333333492279053)
[2025-02-17 16:31:56,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:56,397][root][INFO] - Training Epoch: 1/2, step 631/107898 completed (loss: 0.4687871038913727, acc: 1.0)
[2025-02-17 16:31:56,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:56,754][root][INFO] - Training Epoch: 1/2, step 632/107898 completed (loss: 0.16807681322097778, acc: 1.0)
[2025-02-17 16:31:56,832][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:57,058][root][INFO] - Training Epoch: 1/2, step 633/107898 completed (loss: 2.391508102416992, acc: 0.6666666865348816)
[2025-02-17 16:31:57,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:57,413][root][INFO] - Training Epoch: 1/2, step 634/107898 completed (loss: 2.1577954292297363, acc: 0.625)
[2025-02-17 16:31:57,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:57,728][root][INFO] - Training Epoch: 1/2, step 635/107898 completed (loss: 2.2912533283233643, acc: 0.6190476417541504)
[2025-02-17 16:31:57,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:58,049][root][INFO] - Training Epoch: 1/2, step 636/107898 completed (loss: 1.167762041091919, acc: 0.7692307829856873)
[2025-02-17 16:31:58,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:58,373][root][INFO] - Training Epoch: 1/2, step 637/107898 completed (loss: 0.1066822037100792, acc: 1.0)
[2025-02-17 16:31:58,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:58,714][root][INFO] - Training Epoch: 1/2, step 638/107898 completed (loss: 2.5099730491638184, acc: 0.6000000238418579)
[2025-02-17 16:31:58,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:59,055][root][INFO] - Training Epoch: 1/2, step 639/107898 completed (loss: 0.23660458624362946, acc: 0.9473684430122375)
[2025-02-17 16:31:59,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:59,412][root][INFO] - Training Epoch: 1/2, step 640/107898 completed (loss: 5.298373699188232, acc: 0.1666666716337204)
[2025-02-17 16:31:59,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:31:59,720][root][INFO] - Training Epoch: 1/2, step 641/107898 completed (loss: 4.686877250671387, acc: 0.29411765933036804)
[2025-02-17 16:31:59,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:00,056][root][INFO] - Training Epoch: 1/2, step 642/107898 completed (loss: 1.1220703125, acc: 0.7837837934494019)
[2025-02-17 16:32:00,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:00,403][root][INFO] - Training Epoch: 1/2, step 643/107898 completed (loss: 0.2922914922237396, acc: 1.0)
[2025-02-17 16:32:00,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:00,700][root][INFO] - Training Epoch: 1/2, step 644/107898 completed (loss: 2.348334312438965, acc: 0.4444444477558136)
[2025-02-17 16:32:00,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:01,052][root][INFO] - Training Epoch: 1/2, step 645/107898 completed (loss: 0.4017498791217804, acc: 0.9230769276618958)
[2025-02-17 16:32:01,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:01,409][root][INFO] - Training Epoch: 1/2, step 646/107898 completed (loss: 0.7524571418762207, acc: 0.8620689511299133)
[2025-02-17 16:32:01,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:01,744][root][INFO] - Training Epoch: 1/2, step 647/107898 completed (loss: 2.4645111560821533, acc: 0.75)
[2025-02-17 16:32:01,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:02,093][root][INFO] - Training Epoch: 1/2, step 648/107898 completed (loss: 1.3160597085952759, acc: 0.8181818127632141)
[2025-02-17 16:32:02,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:02,441][root][INFO] - Training Epoch: 1/2, step 649/107898 completed (loss: 3.9398813247680664, acc: 0.4117647111415863)
[2025-02-17 16:32:02,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:02,733][root][INFO] - Training Epoch: 1/2, step 650/107898 completed (loss: 4.898828506469727, acc: 0.3333333432674408)
[2025-02-17 16:32:02,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:03,071][root][INFO] - Training Epoch: 1/2, step 651/107898 completed (loss: 1.9365180730819702, acc: 0.5909090638160706)
[2025-02-17 16:32:03,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:03,412][root][INFO] - Training Epoch: 1/2, step 652/107898 completed (loss: 0.6991848349571228, acc: 0.8888888955116272)
[2025-02-17 16:32:03,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:03,755][root][INFO] - Training Epoch: 1/2, step 653/107898 completed (loss: 5.176614761352539, acc: 0.3333333432674408)
[2025-02-17 16:32:03,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:04,040][root][INFO] - Training Epoch: 1/2, step 654/107898 completed (loss: 0.0702483132481575, acc: 1.0)
[2025-02-17 16:32:04,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:04,324][root][INFO] - Training Epoch: 1/2, step 655/107898 completed (loss: 1.1339162588119507, acc: 0.800000011920929)
[2025-02-17 16:32:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:04,620][root][INFO] - Training Epoch: 1/2, step 656/107898 completed (loss: 1.8459445238113403, acc: 0.6666666865348816)
[2025-02-17 16:32:04,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:04,930][root][INFO] - Training Epoch: 1/2, step 657/107898 completed (loss: 0.5057435631752014, acc: 0.9166666865348816)
[2025-02-17 16:32:05,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:05,247][root][INFO] - Training Epoch: 1/2, step 658/107898 completed (loss: 0.6253906488418579, acc: 0.8571428656578064)
[2025-02-17 16:32:05,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:05,546][root][INFO] - Training Epoch: 1/2, step 659/107898 completed (loss: 0.036911603063344955, acc: 1.0)
[2025-02-17 16:32:05,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:05,846][root][INFO] - Training Epoch: 1/2, step 660/107898 completed (loss: 4.407744407653809, acc: 0.095238097012043)
[2025-02-17 16:32:05,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:06,162][root][INFO] - Training Epoch: 1/2, step 661/107898 completed (loss: 0.7625911831855774, acc: 0.8181818127632141)
[2025-02-17 16:32:06,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:06,460][root][INFO] - Training Epoch: 1/2, step 662/107898 completed (loss: 0.1812860518693924, acc: 0.9333333373069763)
[2025-02-17 16:32:06,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:06,760][root][INFO] - Training Epoch: 1/2, step 663/107898 completed (loss: 5.018504619598389, acc: 0.3333333432674408)
[2025-02-17 16:32:06,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:07,067][root][INFO] - Training Epoch: 1/2, step 664/107898 completed (loss: 2.808001756668091, acc: 0.5)
[2025-02-17 16:32:07,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:07,381][root][INFO] - Training Epoch: 1/2, step 665/107898 completed (loss: 1.713618516921997, acc: 0.625)
[2025-02-17 16:32:07,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:07,682][root][INFO] - Training Epoch: 1/2, step 666/107898 completed (loss: 0.5104105472564697, acc: 0.8965517282485962)
[2025-02-17 16:32:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:07,977][root][INFO] - Training Epoch: 1/2, step 667/107898 completed (loss: 1.2920970916748047, acc: 0.800000011920929)
[2025-02-17 16:32:08,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:08,291][root][INFO] - Training Epoch: 1/2, step 668/107898 completed (loss: 1.7374377250671387, acc: 0.7333333492279053)
[2025-02-17 16:32:08,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:08,586][root][INFO] - Training Epoch: 1/2, step 669/107898 completed (loss: 0.44446495175361633, acc: 0.875)
[2025-02-17 16:32:08,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:08,881][root][INFO] - Training Epoch: 1/2, step 670/107898 completed (loss: 4.116988658905029, acc: 0.3333333432674408)
[2025-02-17 16:32:08,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:09,181][root][INFO] - Training Epoch: 1/2, step 671/107898 completed (loss: 4.567188262939453, acc: 0.125)
[2025-02-17 16:32:09,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:09,512][root][INFO] - Training Epoch: 1/2, step 672/107898 completed (loss: 0.7894635796546936, acc: 0.8461538553237915)
[2025-02-17 16:32:09,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:09,854][root][INFO] - Training Epoch: 1/2, step 673/107898 completed (loss: 0.03631384298205376, acc: 1.0)
[2025-02-17 16:32:09,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:10,178][root][INFO] - Training Epoch: 1/2, step 674/107898 completed (loss: 0.061457693576812744, acc: 1.0)
[2025-02-17 16:32:10,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:10,526][root][INFO] - Training Epoch: 1/2, step 675/107898 completed (loss: 4.476556301116943, acc: 0.20000000298023224)
[2025-02-17 16:32:10,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:10,863][root][INFO] - Training Epoch: 1/2, step 676/107898 completed (loss: 0.16362403333187103, acc: 1.0)
[2025-02-17 16:32:10,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:11,184][root][INFO] - Training Epoch: 1/2, step 677/107898 completed (loss: 1.0988341569900513, acc: 0.8181818127632141)
[2025-02-17 16:32:11,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:11,517][root][INFO] - Training Epoch: 1/2, step 678/107898 completed (loss: 1.0486783981323242, acc: 0.9200000166893005)
[2025-02-17 16:32:11,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:11,852][root][INFO] - Training Epoch: 1/2, step 679/107898 completed (loss: 4.541126728057861, acc: 0.3529411852359772)
[2025-02-17 16:32:11,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:12,189][root][INFO] - Training Epoch: 1/2, step 680/107898 completed (loss: 0.8499161601066589, acc: 0.8571428656578064)
[2025-02-17 16:32:12,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:12,504][root][INFO] - Training Epoch: 1/2, step 681/107898 completed (loss: 2.7026755809783936, acc: 0.5714285969734192)
[2025-02-17 16:32:12,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:12,811][root][INFO] - Training Epoch: 1/2, step 682/107898 completed (loss: 3.523861885070801, acc: 0.3333333432674408)
[2025-02-17 16:32:12,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:13,111][root][INFO] - Training Epoch: 1/2, step 683/107898 completed (loss: 0.6515005826950073, acc: 0.8787878751754761)
[2025-02-17 16:32:13,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:13,483][root][INFO] - Training Epoch: 1/2, step 684/107898 completed (loss: 0.7701508402824402, acc: 0.8148148059844971)
[2025-02-17 16:32:13,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:13,791][root][INFO] - Training Epoch: 1/2, step 685/107898 completed (loss: 2.439662218093872, acc: 0.20000000298023224)
[2025-02-17 16:32:13,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:14,113][root][INFO] - Training Epoch: 1/2, step 686/107898 completed (loss: 0.1931914985179901, acc: 1.0)
[2025-02-17 16:32:14,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:14,431][root][INFO] - Training Epoch: 1/2, step 687/107898 completed (loss: 3.0775558948516846, acc: 0.3333333432674408)
[2025-02-17 16:32:14,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:14,744][root][INFO] - Training Epoch: 1/2, step 688/107898 completed (loss: 3.6809165477752686, acc: 0.3636363744735718)
[2025-02-17 16:32:14,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:15,047][root][INFO] - Training Epoch: 1/2, step 689/107898 completed (loss: 0.2870222330093384, acc: 1.0)
[2025-02-17 16:32:15,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:15,384][root][INFO] - Training Epoch: 1/2, step 690/107898 completed (loss: 0.4263559579849243, acc: 0.8333333134651184)
[2025-02-17 16:32:15,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:15,722][root][INFO] - Training Epoch: 1/2, step 691/107898 completed (loss: 5.681180000305176, acc: 0.0)
[2025-02-17 16:32:15,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:16,059][root][INFO] - Training Epoch: 1/2, step 692/107898 completed (loss: 2.9962382316589355, acc: 0.4285714328289032)
[2025-02-17 16:32:16,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:16,362][root][INFO] - Training Epoch: 1/2, step 693/107898 completed (loss: 2.2858850955963135, acc: 0.4285714328289032)
[2025-02-17 16:32:16,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:16,652][root][INFO] - Training Epoch: 1/2, step 694/107898 completed (loss: 2.659775495529175, acc: 0.6666666865348816)
[2025-02-17 16:32:16,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:16,954][root][INFO] - Training Epoch: 1/2, step 695/107898 completed (loss: 0.8282904028892517, acc: 0.8461538553237915)
[2025-02-17 16:32:17,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:17,329][root][INFO] - Training Epoch: 1/2, step 696/107898 completed (loss: 0.1400044560432434, acc: 1.0)
[2025-02-17 16:32:17,466][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:17,693][root][INFO] - Training Epoch: 1/2, step 697/107898 completed (loss: 0.10000578314065933, acc: 1.0)
[2025-02-17 16:32:17,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:18,022][root][INFO] - Training Epoch: 1/2, step 698/107898 completed (loss: 0.06456325948238373, acc: 1.0)
[2025-02-17 16:32:18,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:18,357][root][INFO] - Training Epoch: 1/2, step 699/107898 completed (loss: 0.4713648557662964, acc: 0.8888888955116272)
[2025-02-17 16:32:18,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:18,677][root][INFO] - Training Epoch: 1/2, step 700/107898 completed (loss: 1.5123796463012695, acc: 0.6842105388641357)
[2025-02-17 16:32:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:18,991][root][INFO] - Training Epoch: 1/2, step 701/107898 completed (loss: 1.287789225578308, acc: 0.7692307829856873)
[2025-02-17 16:32:19,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:19,272][root][INFO] - Training Epoch: 1/2, step 702/107898 completed (loss: 0.3453843295574188, acc: 1.0)
[2025-02-17 16:32:19,349][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:19,567][root][INFO] - Training Epoch: 1/2, step 703/107898 completed (loss: 0.19541390240192413, acc: 1.0)
[2025-02-17 16:32:19,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:19,959][root][INFO] - Training Epoch: 1/2, step 704/107898 completed (loss: 0.5281216502189636, acc: 1.0)
[2025-02-17 16:32:20,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:20,305][root][INFO] - Training Epoch: 1/2, step 705/107898 completed (loss: 2.9661407470703125, acc: 0.6666666865348816)
[2025-02-17 16:32:20,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:20,654][root][INFO] - Training Epoch: 1/2, step 706/107898 completed (loss: 0.1693759560585022, acc: 1.0)
[2025-02-17 16:32:20,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:21,002][root][INFO] - Training Epoch: 1/2, step 707/107898 completed (loss: 5.332278728485107, acc: 0.5)
[2025-02-17 16:32:21,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:21,305][root][INFO] - Training Epoch: 1/2, step 708/107898 completed (loss: 0.8948438763618469, acc: 0.5)
[2025-02-17 16:32:21,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:21,667][root][INFO] - Training Epoch: 1/2, step 709/107898 completed (loss: 0.17835164070129395, acc: 1.0)
[2025-02-17 16:32:21,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:21,993][root][INFO] - Training Epoch: 1/2, step 710/107898 completed (loss: 3.3168907165527344, acc: 0.5)
[2025-02-17 16:32:22,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:22,334][root][INFO] - Training Epoch: 1/2, step 711/107898 completed (loss: 3.389108657836914, acc: 0.15789473056793213)
[2025-02-17 16:32:22,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:22,661][root][INFO] - Training Epoch: 1/2, step 712/107898 completed (loss: 1.937447428703308, acc: 0.7083333134651184)
[2025-02-17 16:32:22,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:22,998][root][INFO] - Training Epoch: 1/2, step 713/107898 completed (loss: 1.4848942756652832, acc: 0.75)
[2025-02-17 16:32:23,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:23,315][root][INFO] - Training Epoch: 1/2, step 714/107898 completed (loss: 1.1761506795883179, acc: 0.6666666865348816)
[2025-02-17 16:32:23,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:23,649][root][INFO] - Training Epoch: 1/2, step 715/107898 completed (loss: 3.5535459518432617, acc: 0.3636363744735718)
[2025-02-17 16:32:23,774][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:23,998][root][INFO] - Training Epoch: 1/2, step 716/107898 completed (loss: 0.7966775298118591, acc: 0.8333333134651184)
[2025-02-17 16:32:24,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:24,334][root][INFO] - Training Epoch: 1/2, step 717/107898 completed (loss: 1.8899036645889282, acc: 0.6315789222717285)
[2025-02-17 16:32:24,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:24,643][root][INFO] - Training Epoch: 1/2, step 718/107898 completed (loss: 2.5151286125183105, acc: 0.5)
[2025-02-17 16:32:24,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:24,967][root][INFO] - Training Epoch: 1/2, step 719/107898 completed (loss: 1.9000903367996216, acc: 0.5555555820465088)
[2025-02-17 16:32:25,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:25,300][root][INFO] - Training Epoch: 1/2, step 720/107898 completed (loss: 0.8384880423545837, acc: 0.8333333134651184)
[2025-02-17 16:32:25,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:25,597][root][INFO] - Training Epoch: 1/2, step 721/107898 completed (loss: 2.3651585578918457, acc: 0.5714285969734192)
[2025-02-17 16:32:25,685][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:25,912][root][INFO] - Training Epoch: 1/2, step 722/107898 completed (loss: 0.27183160185813904, acc: 0.9090909361839294)
[2025-02-17 16:32:26,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:26,235][root][INFO] - Training Epoch: 1/2, step 723/107898 completed (loss: 2.98595929145813, acc: 0.4166666567325592)
[2025-02-17 16:32:26,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:26,498][root][INFO] - Training Epoch: 1/2, step 724/107898 completed (loss: 2.3929853439331055, acc: 0.4000000059604645)
[2025-02-17 16:32:26,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:26,820][root][INFO] - Training Epoch: 1/2, step 725/107898 completed (loss: 1.1387799978256226, acc: 0.8461538553237915)
[2025-02-17 16:32:26,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:27,137][root][INFO] - Training Epoch: 1/2, step 726/107898 completed (loss: 0.9329748749732971, acc: 1.0)
[2025-02-17 16:32:27,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:27,452][root][INFO] - Training Epoch: 1/2, step 727/107898 completed (loss: 2.7910213470458984, acc: 0.0)
[2025-02-17 16:32:27,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:27,781][root][INFO] - Training Epoch: 1/2, step 728/107898 completed (loss: 0.6418799161911011, acc: 0.75)
[2025-02-17 16:32:27,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:28,148][root][INFO] - Training Epoch: 1/2, step 729/107898 completed (loss: 0.04514806345105171, acc: 1.0)
[2025-02-17 16:32:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:28,490][root][INFO] - Training Epoch: 1/2, step 730/107898 completed (loss: 0.7861944437026978, acc: 0.8421052694320679)
[2025-02-17 16:32:28,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:28,803][root][INFO] - Training Epoch: 1/2, step 731/107898 completed (loss: 1.2291597127914429, acc: 0.7142857313156128)
[2025-02-17 16:32:28,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:29,134][root][INFO] - Training Epoch: 1/2, step 732/107898 completed (loss: 0.11899495869874954, acc: 0.9285714030265808)
[2025-02-17 16:32:29,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:29,470][root][INFO] - Training Epoch: 1/2, step 733/107898 completed (loss: 1.439935564994812, acc: 0.7857142686843872)
[2025-02-17 16:32:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:29,810][root][INFO] - Training Epoch: 1/2, step 734/107898 completed (loss: 0.01532371249049902, acc: 1.0)
[2025-02-17 16:32:29,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:30,183][root][INFO] - Training Epoch: 1/2, step 735/107898 completed (loss: 1.6443378925323486, acc: 0.5)
[2025-02-17 16:32:30,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:30,506][root][INFO] - Training Epoch: 1/2, step 736/107898 completed (loss: 0.5819424986839294, acc: 0.875)
[2025-02-17 16:32:30,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:30,858][root][INFO] - Training Epoch: 1/2, step 737/107898 completed (loss: 0.4832702875137329, acc: 0.8461538553237915)
[2025-02-17 16:32:30,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:31,231][root][INFO] - Training Epoch: 1/2, step 738/107898 completed (loss: 2.124130964279175, acc: 0.6000000238418579)
[2025-02-17 16:32:31,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:31,578][root][INFO] - Training Epoch: 1/2, step 739/107898 completed (loss: 1.2828634977340698, acc: 0.8148148059844971)
[2025-02-17 16:32:31,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:31,937][root][INFO] - Training Epoch: 1/2, step 740/107898 completed (loss: 0.016375429928302765, acc: 1.0)
[2025-02-17 16:32:32,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:32,308][root][INFO] - Training Epoch: 1/2, step 741/107898 completed (loss: 0.15745756030082703, acc: 0.8571428656578064)
[2025-02-17 16:32:32,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:32,686][root][INFO] - Training Epoch: 1/2, step 742/107898 completed (loss: 6.030158519744873, acc: 0.25)
[2025-02-17 16:32:32,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:33,042][root][INFO] - Training Epoch: 1/2, step 743/107898 completed (loss: 1.6666946411132812, acc: 0.5)
[2025-02-17 16:32:33,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:33,365][root][INFO] - Training Epoch: 1/2, step 744/107898 completed (loss: 3.3548293113708496, acc: 0.625)
[2025-02-17 16:32:33,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:33,689][root][INFO] - Training Epoch: 1/2, step 745/107898 completed (loss: 0.6306491494178772, acc: 0.8333333134651184)
[2025-02-17 16:32:33,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:34,038][root][INFO] - Training Epoch: 1/2, step 746/107898 completed (loss: 2.6857898235321045, acc: 0.5)
[2025-02-17 16:32:34,124][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:34,355][root][INFO] - Training Epoch: 1/2, step 747/107898 completed (loss: 0.5572230219841003, acc: 0.8333333134651184)
[2025-02-17 16:32:34,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:34,718][root][INFO] - Training Epoch: 1/2, step 748/107898 completed (loss: 0.5795865654945374, acc: 0.9230769276618958)
[2025-02-17 16:32:34,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:35,079][root][INFO] - Training Epoch: 1/2, step 749/107898 completed (loss: 0.2902561128139496, acc: 0.95652174949646)
[2025-02-17 16:32:35,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:35,438][root][INFO] - Training Epoch: 1/2, step 750/107898 completed (loss: 0.0985485315322876, acc: 1.0)
[2025-02-17 16:32:35,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:35,745][root][INFO] - Training Epoch: 1/2, step 751/107898 completed (loss: 0.3304496109485626, acc: 0.8333333134651184)
[2025-02-17 16:32:35,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:36,072][root][INFO] - Training Epoch: 1/2, step 752/107898 completed (loss: 0.11091279238462448, acc: 1.0)
[2025-02-17 16:32:36,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:36,374][root][INFO] - Training Epoch: 1/2, step 753/107898 completed (loss: 0.5224320292472839, acc: 0.800000011920929)
[2025-02-17 16:32:36,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:36,686][root][INFO] - Training Epoch: 1/2, step 754/107898 completed (loss: 1.1286853551864624, acc: 0.75)
[2025-02-17 16:32:36,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:37,032][root][INFO] - Training Epoch: 1/2, step 755/107898 completed (loss: 0.699472963809967, acc: 0.8709677457809448)
[2025-02-17 16:32:37,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:37,409][root][INFO] - Training Epoch: 1/2, step 756/107898 completed (loss: 2.557823657989502, acc: 0.6153846383094788)
[2025-02-17 16:32:37,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:37,716][root][INFO] - Training Epoch: 1/2, step 757/107898 completed (loss: 0.03359054774045944, acc: 1.0)
[2025-02-17 16:32:37,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:38,082][root][INFO] - Training Epoch: 1/2, step 758/107898 completed (loss: 0.09596751630306244, acc: 1.0)
[2025-02-17 16:32:38,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:38,423][root][INFO] - Training Epoch: 1/2, step 759/107898 completed (loss: 0.571363091468811, acc: 0.9333333373069763)
[2025-02-17 16:32:38,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:38,728][root][INFO] - Training Epoch: 1/2, step 760/107898 completed (loss: 0.7961438894271851, acc: 0.8500000238418579)
[2025-02-17 16:32:38,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:39,041][root][INFO] - Training Epoch: 1/2, step 761/107898 completed (loss: 3.482107400894165, acc: 0.27272728085517883)
[2025-02-17 16:32:39,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:39,336][root][INFO] - Training Epoch: 1/2, step 762/107898 completed (loss: 1.1594856977462769, acc: 0.8823529481887817)
[2025-02-17 16:32:39,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:39,646][root][INFO] - Training Epoch: 1/2, step 763/107898 completed (loss: 1.0186320543289185, acc: 0.75)
[2025-02-17 16:32:39,759][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:39,967][root][INFO] - Training Epoch: 1/2, step 764/107898 completed (loss: 1.6566009521484375, acc: 0.75)
[2025-02-17 16:32:40,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:40,302][root][INFO] - Training Epoch: 1/2, step 765/107898 completed (loss: 2.2185895442962646, acc: 0.5555555820465088)
[2025-02-17 16:32:40,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:40,603][root][INFO] - Training Epoch: 1/2, step 766/107898 completed (loss: 4.543809413909912, acc: 0.5)
[2025-02-17 16:32:40,687][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:40,908][root][INFO] - Training Epoch: 1/2, step 767/107898 completed (loss: 0.7289177775382996, acc: 0.8571428656578064)
[2025-02-17 16:32:41,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:41,229][root][INFO] - Training Epoch: 1/2, step 768/107898 completed (loss: 0.6733803153038025, acc: 0.7727272510528564)
[2025-02-17 16:32:41,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:41,521][root][INFO] - Training Epoch: 1/2, step 769/107898 completed (loss: 1.7270872592926025, acc: 0.75)
[2025-02-17 16:32:41,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:41,817][root][INFO] - Training Epoch: 1/2, step 770/107898 completed (loss: 0.03206579387187958, acc: 1.0)
[2025-02-17 16:32:41,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:42,103][root][INFO] - Training Epoch: 1/2, step 771/107898 completed (loss: 1.1468826532363892, acc: 0.800000011920929)
[2025-02-17 16:32:42,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:42,400][root][INFO] - Training Epoch: 1/2, step 772/107898 completed (loss: 0.06326334923505783, acc: 1.0)
[2025-02-17 16:32:42,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:42,709][root][INFO] - Training Epoch: 1/2, step 773/107898 completed (loss: 4.754155158996582, acc: 0.5)
[2025-02-17 16:32:42,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:43,016][root][INFO] - Training Epoch: 1/2, step 774/107898 completed (loss: 1.3449037075042725, acc: 0.7777777910232544)
[2025-02-17 16:32:43,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:43,327][root][INFO] - Training Epoch: 1/2, step 775/107898 completed (loss: 0.7876210808753967, acc: 0.8214285969734192)
[2025-02-17 16:32:43,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:43,633][root][INFO] - Training Epoch: 1/2, step 776/107898 completed (loss: 0.3156639039516449, acc: 0.9523809552192688)
[2025-02-17 16:32:43,736][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:43,949][root][INFO] - Training Epoch: 1/2, step 777/107898 completed (loss: 3.770142078399658, acc: 0.25)
[2025-02-17 16:32:44,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:44,249][root][INFO] - Training Epoch: 1/2, step 778/107898 completed (loss: 2.316408157348633, acc: 0.5)
[2025-02-17 16:32:44,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:44,562][root][INFO] - Training Epoch: 1/2, step 779/107898 completed (loss: 1.6218196153640747, acc: 0.6428571343421936)
[2025-02-17 16:32:44,637][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:44,879][root][INFO] - Training Epoch: 1/2, step 780/107898 completed (loss: 1.7793124914169312, acc: 0.5)
[2025-02-17 16:32:44,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:45,218][root][INFO] - Training Epoch: 1/2, step 781/107898 completed (loss: 2.9663360118865967, acc: 0.5625)
[2025-02-17 16:32:45,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:45,495][root][INFO] - Training Epoch: 1/2, step 782/107898 completed (loss: 0.05246412754058838, acc: 1.0)
[2025-02-17 16:32:45,586][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:45,804][root][INFO] - Training Epoch: 1/2, step 783/107898 completed (loss: 0.9033492207527161, acc: 0.5)
[2025-02-17 16:32:45,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:46,122][root][INFO] - Training Epoch: 1/2, step 784/107898 completed (loss: 0.5009241700172424, acc: 0.9069767594337463)
[2025-02-17 16:32:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:46,468][root][INFO] - Training Epoch: 1/2, step 785/107898 completed (loss: 4.539797306060791, acc: 0.3333333432674408)
[2025-02-17 16:32:46,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:46,837][root][INFO] - Training Epoch: 1/2, step 786/107898 completed (loss: 0.4843626916408539, acc: 0.9599999785423279)
[2025-02-17 16:32:46,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:47,197][root][INFO] - Training Epoch: 1/2, step 787/107898 completed (loss: 2.3724451065063477, acc: 0.5)
[2025-02-17 16:32:47,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:47,588][root][INFO] - Training Epoch: 1/2, step 788/107898 completed (loss: 1.965956449508667, acc: 0.6818181872367859)
[2025-02-17 16:32:47,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:47,880][root][INFO] - Training Epoch: 1/2, step 789/107898 completed (loss: 1.1445716619491577, acc: 0.7058823704719543)
[2025-02-17 16:32:48,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:48,251][root][INFO] - Training Epoch: 1/2, step 790/107898 completed (loss: 1.4002381563186646, acc: 0.7142857313156128)
[2025-02-17 16:32:48,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:48,586][root][INFO] - Training Epoch: 1/2, step 791/107898 completed (loss: 1.248256802558899, acc: 0.6666666865348816)
[2025-02-17 16:32:48,687][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:48,922][root][INFO] - Training Epoch: 1/2, step 792/107898 completed (loss: 0.5876773595809937, acc: 0.8999999761581421)
[2025-02-17 16:32:49,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:49,328][root][INFO] - Training Epoch: 1/2, step 793/107898 completed (loss: 1.3628509044647217, acc: 0.7692307829856873)
[2025-02-17 16:32:49,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:49,682][root][INFO] - Training Epoch: 1/2, step 794/107898 completed (loss: 2.90287709236145, acc: 0.6666666865348816)
[2025-02-17 16:32:49,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:50,008][root][INFO] - Training Epoch: 1/2, step 795/107898 completed (loss: 4.196966648101807, acc: 0.0)
[2025-02-17 16:32:50,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:50,357][root][INFO] - Training Epoch: 1/2, step 796/107898 completed (loss: 1.914712905883789, acc: 0.6071428656578064)
[2025-02-17 16:32:50,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:50,685][root][INFO] - Training Epoch: 1/2, step 797/107898 completed (loss: 0.8698773384094238, acc: 0.7142857313156128)
[2025-02-17 16:32:50,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:51,065][root][INFO] - Training Epoch: 1/2, step 798/107898 completed (loss: 1.0047104358673096, acc: 0.75)
[2025-02-17 16:32:51,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:51,448][root][INFO] - Training Epoch: 1/2, step 799/107898 completed (loss: 1.9639500379562378, acc: 0.6666666865348816)
[2025-02-17 16:32:51,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:51,775][root][INFO] - Training Epoch: 1/2, step 800/107898 completed (loss: 0.47498753666877747, acc: 0.9090909361839294)
[2025-02-17 16:32:51,863][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:52,084][root][INFO] - Training Epoch: 1/2, step 801/107898 completed (loss: 0.9518296718597412, acc: 0.6666666865348816)
[2025-02-17 16:32:52,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:52,389][root][INFO] - Training Epoch: 1/2, step 802/107898 completed (loss: 1.329369068145752, acc: 0.8333333134651184)
[2025-02-17 16:32:52,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:52,703][root][INFO] - Training Epoch: 1/2, step 803/107898 completed (loss: 5.631321907043457, acc: 0.20000000298023224)
[2025-02-17 16:32:52,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:53,041][root][INFO] - Training Epoch: 1/2, step 804/107898 completed (loss: 2.072800636291504, acc: 0.6153846383094788)
[2025-02-17 16:32:53,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:53,393][root][INFO] - Training Epoch: 1/2, step 805/107898 completed (loss: 2.032813310623169, acc: 0.5)
[2025-02-17 16:32:53,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:53,755][root][INFO] - Training Epoch: 1/2, step 806/107898 completed (loss: 1.435953974723816, acc: 0.7142857313156128)
[2025-02-17 16:32:53,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:54,111][root][INFO] - Training Epoch: 1/2, step 807/107898 completed (loss: 1.4181410074234009, acc: 0.6666666865348816)
[2025-02-17 16:32:54,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:54,429][root][INFO] - Training Epoch: 1/2, step 808/107898 completed (loss: 0.8742821216583252, acc: 0.7368420958518982)
[2025-02-17 16:32:54,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:54,778][root][INFO] - Training Epoch: 1/2, step 809/107898 completed (loss: 1.2027695178985596, acc: 0.7317073345184326)
[2025-02-17 16:32:54,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:55,114][root][INFO] - Training Epoch: 1/2, step 810/107898 completed (loss: 1.6808677911758423, acc: 0.6388888955116272)
[2025-02-17 16:32:55,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:55,393][root][INFO] - Training Epoch: 1/2, step 811/107898 completed (loss: 2.496379852294922, acc: 0.5384615659713745)
[2025-02-17 16:32:55,503][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:55,698][root][INFO] - Training Epoch: 1/2, step 812/107898 completed (loss: 0.8650150299072266, acc: 0.5)
[2025-02-17 16:32:55,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:56,022][root][INFO] - Training Epoch: 1/2, step 813/107898 completed (loss: 0.10187066346406937, acc: 1.0)
[2025-02-17 16:32:56,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:56,351][root][INFO] - Training Epoch: 1/2, step 814/107898 completed (loss: 2.4620866775512695, acc: 0.523809552192688)
[2025-02-17 16:32:56,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:56,709][root][INFO] - Training Epoch: 1/2, step 815/107898 completed (loss: 1.7236261367797852, acc: 0.5789473652839661)
[2025-02-17 16:32:56,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:56,995][root][INFO] - Training Epoch: 1/2, step 816/107898 completed (loss: 1.00226891040802, acc: 0.6666666865348816)
[2025-02-17 16:32:57,061][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:57,247][root][INFO] - Training Epoch: 1/2, step 817/107898 completed (loss: 0.11117547750473022, acc: 1.0)
[2025-02-17 16:32:57,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:57,531][root][INFO] - Training Epoch: 1/2, step 818/107898 completed (loss: 3.7233309745788574, acc: 0.625)
[2025-02-17 16:32:57,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:57,883][root][INFO] - Training Epoch: 1/2, step 819/107898 completed (loss: 3.256324052810669, acc: 0.5)
[2025-02-17 16:32:57,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:58,206][root][INFO] - Training Epoch: 1/2, step 820/107898 completed (loss: 3.8351144790649414, acc: 0.3333333432674408)
[2025-02-17 16:32:58,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:58,492][root][INFO] - Training Epoch: 1/2, step 821/107898 completed (loss: 1.3527230024337769, acc: 0.7142857313156128)
[2025-02-17 16:32:58,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:58,839][root][INFO] - Training Epoch: 1/2, step 822/107898 completed (loss: 1.1853879690170288, acc: 0.7777777910232544)
[2025-02-17 16:32:58,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:59,163][root][INFO] - Training Epoch: 1/2, step 823/107898 completed (loss: 2.0803277492523193, acc: 0.5)
[2025-02-17 16:32:59,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:59,518][root][INFO] - Training Epoch: 1/2, step 824/107898 completed (loss: 1.6553601026535034, acc: 0.75)
[2025-02-17 16:32:59,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:32:59,835][root][INFO] - Training Epoch: 1/2, step 825/107898 completed (loss: 0.574324369430542, acc: 0.8620689511299133)
[2025-02-17 16:32:59,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:00,239][root][INFO] - Training Epoch: 1/2, step 826/107898 completed (loss: 1.8446624279022217, acc: 0.625)
[2025-02-17 16:33:00,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:00,616][root][INFO] - Training Epoch: 1/2, step 827/107898 completed (loss: 0.3122565448284149, acc: 0.9130434989929199)
[2025-02-17 16:33:00,736][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:00,951][root][INFO] - Training Epoch: 1/2, step 828/107898 completed (loss: 1.5338366031646729, acc: 0.6000000238418579)
[2025-02-17 16:33:01,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:01,272][root][INFO] - Training Epoch: 1/2, step 829/107898 completed (loss: 0.4882459342479706, acc: 0.9285714030265808)
[2025-02-17 16:33:01,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:01,566][root][INFO] - Training Epoch: 1/2, step 830/107898 completed (loss: 0.25842341780662537, acc: 1.0)
[2025-02-17 16:33:01,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:01,932][root][INFO] - Training Epoch: 1/2, step 831/107898 completed (loss: 1.1006532907485962, acc: 0.782608687877655)
[2025-02-17 16:33:02,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:02,256][root][INFO] - Training Epoch: 1/2, step 832/107898 completed (loss: 2.364811897277832, acc: 0.3333333432674408)
[2025-02-17 16:33:02,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:02,584][root][INFO] - Training Epoch: 1/2, step 833/107898 completed (loss: 1.7201355695724487, acc: 0.6538461446762085)
[2025-02-17 16:33:02,696][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:02,928][root][INFO] - Training Epoch: 1/2, step 834/107898 completed (loss: 1.517977237701416, acc: 0.6666666865348816)
[2025-02-17 16:33:03,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:03,221][root][INFO] - Training Epoch: 1/2, step 835/107898 completed (loss: 1.0927852392196655, acc: 0.5)
[2025-02-17 16:33:03,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:03,516][root][INFO] - Training Epoch: 1/2, step 836/107898 completed (loss: 0.2692154347896576, acc: 0.8888888955116272)
[2025-02-17 16:33:03,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:03,823][root][INFO] - Training Epoch: 1/2, step 837/107898 completed (loss: 2.018751382827759, acc: 0.6000000238418579)
[2025-02-17 16:33:03,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:04,145][root][INFO] - Training Epoch: 1/2, step 838/107898 completed (loss: 1.1995441913604736, acc: 0.699999988079071)
[2025-02-17 16:33:04,257][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:04,492][root][INFO] - Training Epoch: 1/2, step 839/107898 completed (loss: 0.9207307696342468, acc: 0.800000011920929)
[2025-02-17 16:33:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:04,850][root][INFO] - Training Epoch: 1/2, step 840/107898 completed (loss: 1.8599505424499512, acc: 0.5)
[2025-02-17 16:33:04,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:05,145][root][INFO] - Training Epoch: 1/2, step 841/107898 completed (loss: 2.798400402069092, acc: 0.7142857313156128)
[2025-02-17 16:33:05,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:05,438][root][INFO] - Training Epoch: 1/2, step 842/107898 completed (loss: 0.0714094415307045, acc: 1.0)
[2025-02-17 16:33:05,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:05,755][root][INFO] - Training Epoch: 1/2, step 843/107898 completed (loss: 0.17151221632957458, acc: 1.0)
[2025-02-17 16:33:05,863][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:06,120][root][INFO] - Training Epoch: 1/2, step 844/107898 completed (loss: 0.642578125, acc: 0.8235294222831726)
[2025-02-17 16:33:06,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:06,445][root][INFO] - Training Epoch: 1/2, step 845/107898 completed (loss: 1.458036184310913, acc: 1.0)
[2025-02-17 16:33:06,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:06,783][root][INFO] - Training Epoch: 1/2, step 846/107898 completed (loss: 2.8521852493286133, acc: 0.625)
[2025-02-17 16:33:06,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:07,117][root][INFO] - Training Epoch: 1/2, step 847/107898 completed (loss: 3.2334744930267334, acc: 0.2800000011920929)
[2025-02-17 16:33:07,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:07,468][root][INFO] - Training Epoch: 1/2, step 848/107898 completed (loss: 2.01277494430542, acc: 0.6875)
[2025-02-17 16:33:07,564][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:07,793][root][INFO] - Training Epoch: 1/2, step 849/107898 completed (loss: 2.037000894546509, acc: 0.0)
[2025-02-17 16:33:07,905][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:08,146][root][INFO] - Training Epoch: 1/2, step 850/107898 completed (loss: 2.4652373790740967, acc: 0.6363636255264282)
[2025-02-17 16:33:08,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:08,468][root][INFO] - Training Epoch: 1/2, step 851/107898 completed (loss: 0.29933467507362366, acc: 1.0)
[2025-02-17 16:33:08,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:08,785][root][INFO] - Training Epoch: 1/2, step 852/107898 completed (loss: 1.5726169347763062, acc: 0.782608687877655)
[2025-02-17 16:33:08,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:09,094][root][INFO] - Training Epoch: 1/2, step 853/107898 completed (loss: 0.4557757079601288, acc: 0.800000011920929)
[2025-02-17 16:33:09,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:09,380][root][INFO] - Training Epoch: 1/2, step 854/107898 completed (loss: 2.198936939239502, acc: 0.375)
[2025-02-17 16:33:09,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:09,732][root][INFO] - Training Epoch: 1/2, step 855/107898 completed (loss: 0.7791826725006104, acc: 0.7368420958518982)
[2025-02-17 16:33:09,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:10,067][root][INFO] - Training Epoch: 1/2, step 856/107898 completed (loss: 1.9127140045166016, acc: 0.6666666865348816)
[2025-02-17 16:33:10,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:10,370][root][INFO] - Training Epoch: 1/2, step 857/107898 completed (loss: 2.1482596397399902, acc: 0.5)
[2025-02-17 16:33:10,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:10,687][root][INFO] - Training Epoch: 1/2, step 858/107898 completed (loss: 0.6118356585502625, acc: 0.8333333134651184)
[2025-02-17 16:33:10,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:11,013][root][INFO] - Training Epoch: 1/2, step 859/107898 completed (loss: 0.8679794073104858, acc: 0.8125)
[2025-02-17 16:33:11,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:11,393][root][INFO] - Training Epoch: 1/2, step 860/107898 completed (loss: 1.8748213052749634, acc: 0.529411792755127)
[2025-02-17 16:33:11,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:11,727][root][INFO] - Training Epoch: 1/2, step 861/107898 completed (loss: 0.5176756978034973, acc: 1.0)
[2025-02-17 16:33:11,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:12,032][root][INFO] - Training Epoch: 1/2, step 862/107898 completed (loss: 3.5591678619384766, acc: 0.6666666865348816)
[2025-02-17 16:33:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:12,377][root][INFO] - Training Epoch: 1/2, step 863/107898 completed (loss: 3.2126734256744385, acc: 0.5)
[2025-02-17 16:33:12,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:12,762][root][INFO] - Training Epoch: 1/2, step 864/107898 completed (loss: 0.2914700210094452, acc: 0.8999999761581421)
[2025-02-17 16:33:12,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:13,099][root][INFO] - Training Epoch: 1/2, step 865/107898 completed (loss: 4.242041110992432, acc: 0.3333333432674408)
[2025-02-17 16:33:13,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:13,455][root][INFO] - Training Epoch: 1/2, step 866/107898 completed (loss: 1.7164554595947266, acc: 0.6000000238418579)
[2025-02-17 16:33:13,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:13,802][root][INFO] - Training Epoch: 1/2, step 867/107898 completed (loss: 1.2222946882247925, acc: 0.5454545617103577)
[2025-02-17 16:33:13,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:14,096][root][INFO] - Training Epoch: 1/2, step 868/107898 completed (loss: 1.671613335609436, acc: 0.6000000238418579)
[2025-02-17 16:33:14,189][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:14,408][root][INFO] - Training Epoch: 1/2, step 869/107898 completed (loss: 4.843458652496338, acc: 0.14705882966518402)
[2025-02-17 16:33:14,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:14,686][root][INFO] - Training Epoch: 1/2, step 870/107898 completed (loss: 3.6370162963867188, acc: 0.4000000059604645)
[2025-02-17 16:33:14,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:15,045][root][INFO] - Training Epoch: 1/2, step 871/107898 completed (loss: 2.3211829662323, acc: 0.43478259444236755)
[2025-02-17 16:33:15,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:15,388][root][INFO] - Training Epoch: 1/2, step 872/107898 completed (loss: 0.5805187821388245, acc: 0.8947368264198303)
[2025-02-17 16:33:15,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:15,706][root][INFO] - Training Epoch: 1/2, step 873/107898 completed (loss: 0.8211082816123962, acc: 0.7857142686843872)
[2025-02-17 16:33:15,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:16,059][root][INFO] - Training Epoch: 1/2, step 874/107898 completed (loss: 0.29796671867370605, acc: 1.0)
[2025-02-17 16:33:16,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:16,395][root][INFO] - Training Epoch: 1/2, step 875/107898 completed (loss: 2.2051517963409424, acc: 0.4000000059604645)
[2025-02-17 16:33:16,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:16,688][root][INFO] - Training Epoch: 1/2, step 876/107898 completed (loss: 0.2770850658416748, acc: 1.0)
[2025-02-17 16:33:16,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:16,987][root][INFO] - Training Epoch: 1/2, step 877/107898 completed (loss: 0.12896332144737244, acc: 1.0)
[2025-02-17 16:33:17,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:17,331][root][INFO] - Training Epoch: 1/2, step 878/107898 completed (loss: 3.3398869037628174, acc: 0.25)
[2025-02-17 16:33:17,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:17,646][root][INFO] - Training Epoch: 1/2, step 879/107898 completed (loss: 2.1037845611572266, acc: 0.6315789222717285)
[2025-02-17 16:33:17,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:17,967][root][INFO] - Training Epoch: 1/2, step 880/107898 completed (loss: 1.666975736618042, acc: 0.5)
[2025-02-17 16:33:18,064][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:18,288][root][INFO] - Training Epoch: 1/2, step 881/107898 completed (loss: 0.6757776737213135, acc: 0.8666666746139526)
[2025-02-17 16:33:18,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:18,583][root][INFO] - Training Epoch: 1/2, step 882/107898 completed (loss: 0.720257043838501, acc: 0.8333333134651184)
[2025-02-17 16:33:18,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:18,897][root][INFO] - Training Epoch: 1/2, step 883/107898 completed (loss: 0.23396944999694824, acc: 1.0)
[2025-02-17 16:33:19,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:19,255][root][INFO] - Training Epoch: 1/2, step 884/107898 completed (loss: 0.3718256652355194, acc: 0.9375)
[2025-02-17 16:33:19,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:19,589][root][INFO] - Training Epoch: 1/2, step 885/107898 completed (loss: 0.3079407513141632, acc: 1.0)
[2025-02-17 16:33:19,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:19,946][root][INFO] - Training Epoch: 1/2, step 886/107898 completed (loss: 0.6862133741378784, acc: 0.8709677457809448)
[2025-02-17 16:33:20,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:20,281][root][INFO] - Training Epoch: 1/2, step 887/107898 completed (loss: 1.5357551574707031, acc: 0.774193525314331)
[2025-02-17 16:33:20,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:20,619][root][INFO] - Training Epoch: 1/2, step 888/107898 completed (loss: 0.6268123388290405, acc: 0.800000011920929)
[2025-02-17 16:33:20,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:20,953][root][INFO] - Training Epoch: 1/2, step 889/107898 completed (loss: 3.8064820766448975, acc: 0.27272728085517883)
[2025-02-17 16:33:21,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:21,284][root][INFO] - Training Epoch: 1/2, step 890/107898 completed (loss: 0.8603202700614929, acc: 0.8275862336158752)
[2025-02-17 16:33:21,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:21,597][root][INFO] - Training Epoch: 1/2, step 891/107898 completed (loss: 2.0641167163848877, acc: 0.7777777910232544)
[2025-02-17 16:33:21,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:21,915][root][INFO] - Training Epoch: 1/2, step 892/107898 completed (loss: 0.8470556735992432, acc: 0.8333333134651184)
[2025-02-17 16:33:22,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:22,258][root][INFO] - Training Epoch: 1/2, step 893/107898 completed (loss: 0.702410101890564, acc: 0.800000011920929)
[2025-02-17 16:33:22,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:22,571][root][INFO] - Training Epoch: 1/2, step 894/107898 completed (loss: 1.5776705741882324, acc: 0.75)
[2025-02-17 16:33:22,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:22,910][root][INFO] - Training Epoch: 1/2, step 895/107898 completed (loss: 1.1786975860595703, acc: 0.8333333134651184)
[2025-02-17 16:33:23,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:23,240][root][INFO] - Training Epoch: 1/2, step 896/107898 completed (loss: 1.2904713153839111, acc: 0.5)
[2025-02-17 16:33:23,326][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:23,546][root][INFO] - Training Epoch: 1/2, step 897/107898 completed (loss: 0.7756055593490601, acc: 0.7142857313156128)
[2025-02-17 16:33:23,660][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:23,896][root][INFO] - Training Epoch: 1/2, step 898/107898 completed (loss: 2.2863268852233887, acc: 0.0)
[2025-02-17 16:33:24,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:24,251][root][INFO] - Training Epoch: 1/2, step 899/107898 completed (loss: 0.7283878922462463, acc: 0.75)
[2025-02-17 16:33:24,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:24,586][root][INFO] - Training Epoch: 1/2, step 900/107898 completed (loss: 2.8524434566497803, acc: 0.25)
[2025-02-17 16:33:24,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:24,874][root][INFO] - Training Epoch: 1/2, step 901/107898 completed (loss: 3.798105478286743, acc: 0.3333333432674408)
[2025-02-17 16:33:24,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:25,211][root][INFO] - Training Epoch: 1/2, step 902/107898 completed (loss: 1.335402250289917, acc: 0.7272727489471436)
[2025-02-17 16:33:25,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:25,495][root][INFO] - Training Epoch: 1/2, step 903/107898 completed (loss: 1.545750617980957, acc: 0.5625)
[2025-02-17 16:33:25,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:25,785][root][INFO] - Training Epoch: 1/2, step 904/107898 completed (loss: 3.7091662883758545, acc: 0.3333333432674408)
[2025-02-17 16:33:25,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:26,134][root][INFO] - Training Epoch: 1/2, step 905/107898 completed (loss: 3.062692642211914, acc: 0.4285714328289032)
[2025-02-17 16:33:26,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:26,414][root][INFO] - Training Epoch: 1/2, step 906/107898 completed (loss: 1.5337082147598267, acc: 0.5789473652839661)
[2025-02-17 16:33:26,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:26,707][root][INFO] - Training Epoch: 1/2, step 907/107898 completed (loss: 1.8118221759796143, acc: 0.800000011920929)
[2025-02-17 16:33:26,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:27,006][root][INFO] - Training Epoch: 1/2, step 908/107898 completed (loss: 1.5932822227478027, acc: 0.692307710647583)
[2025-02-17 16:33:27,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:27,318][root][INFO] - Training Epoch: 1/2, step 909/107898 completed (loss: 0.36992427706718445, acc: 0.9090909361839294)
[2025-02-17 16:33:27,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:27,629][root][INFO] - Training Epoch: 1/2, step 910/107898 completed (loss: 0.2639690041542053, acc: 1.0)
[2025-02-17 16:33:27,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:27,939][root][INFO] - Training Epoch: 1/2, step 911/107898 completed (loss: 0.13464167714118958, acc: 1.0)
[2025-02-17 16:33:28,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:28,302][root][INFO] - Training Epoch: 1/2, step 912/107898 completed (loss: 2.7572975158691406, acc: 0.5555555820465088)
[2025-02-17 16:33:28,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:28,643][root][INFO] - Training Epoch: 1/2, step 913/107898 completed (loss: 1.177713394165039, acc: 0.6666666865348816)
[2025-02-17 16:33:28,737][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:28,955][root][INFO] - Training Epoch: 1/2, step 914/107898 completed (loss: 1.5098741054534912, acc: 0.8461538553237915)
[2025-02-17 16:33:29,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:29,309][root][INFO] - Training Epoch: 1/2, step 915/107898 completed (loss: 2.1429219245910645, acc: 0.6666666865348816)
[2025-02-17 16:33:29,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:29,627][root][INFO] - Training Epoch: 1/2, step 916/107898 completed (loss: 2.329223155975342, acc: 0.6666666865348816)
[2025-02-17 16:33:29,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:29,977][root][INFO] - Training Epoch: 1/2, step 917/107898 completed (loss: 3.8571689128875732, acc: 0.2916666567325592)
[2025-02-17 16:33:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:30,296][root][INFO] - Training Epoch: 1/2, step 918/107898 completed (loss: 0.5802571773529053, acc: 1.0)
[2025-02-17 16:33:30,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:30,592][root][INFO] - Training Epoch: 1/2, step 919/107898 completed (loss: 0.4535287022590637, acc: 0.8947368264198303)
[2025-02-17 16:33:30,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:30,918][root][INFO] - Training Epoch: 1/2, step 920/107898 completed (loss: 0.7116734385490417, acc: 0.8461538553237915)
[2025-02-17 16:33:31,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:31,250][root][INFO] - Training Epoch: 1/2, step 921/107898 completed (loss: 0.07044665515422821, acc: 1.0)
[2025-02-17 16:33:31,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:31,558][root][INFO] - Training Epoch: 1/2, step 922/107898 completed (loss: 1.9736454486846924, acc: 0.625)
[2025-02-17 16:33:31,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:31,879][root][INFO] - Training Epoch: 1/2, step 923/107898 completed (loss: 1.219340443611145, acc: 0.8235294222831726)
[2025-02-17 16:33:31,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:32,223][root][INFO] - Training Epoch: 1/2, step 924/107898 completed (loss: 1.1289865970611572, acc: 0.8125)
[2025-02-17 16:33:32,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:32,570][root][INFO] - Training Epoch: 1/2, step 925/107898 completed (loss: 0.11785659193992615, acc: 1.0)
[2025-02-17 16:33:32,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:32,903][root][INFO] - Training Epoch: 1/2, step 926/107898 completed (loss: 0.17561836540699005, acc: 1.0)
[2025-02-17 16:33:33,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:33,250][root][INFO] - Training Epoch: 1/2, step 927/107898 completed (loss: 4.189846515655518, acc: 0.3076923191547394)
[2025-02-17 16:33:33,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:33,551][root][INFO] - Training Epoch: 1/2, step 928/107898 completed (loss: 2.3825671672821045, acc: 0.6666666865348816)
[2025-02-17 16:33:33,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:33,886][root][INFO] - Training Epoch: 1/2, step 929/107898 completed (loss: 0.0799020305275917, acc: 1.0)
[2025-02-17 16:33:33,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:34,235][root][INFO] - Training Epoch: 1/2, step 930/107898 completed (loss: 3.562098741531372, acc: 0.3333333432674408)
[2025-02-17 16:33:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:34,601][root][INFO] - Training Epoch: 1/2, step 931/107898 completed (loss: 1.0638511180877686, acc: 0.8214285969734192)
[2025-02-17 16:33:34,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:34,921][root][INFO] - Training Epoch: 1/2, step 932/107898 completed (loss: 0.039545781910419464, acc: 1.0)
[2025-02-17 16:33:35,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:35,261][root][INFO] - Training Epoch: 1/2, step 933/107898 completed (loss: 1.8686221837997437, acc: 0.6666666865348816)
[2025-02-17 16:33:35,373][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:35,582][root][INFO] - Training Epoch: 1/2, step 934/107898 completed (loss: 1.3283188343048096, acc: 0.8571428656578064)
[2025-02-17 16:33:35,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:35,856][root][INFO] - Training Epoch: 1/2, step 935/107898 completed (loss: 0.029928170144557953, acc: 1.0)
[2025-02-17 16:33:35,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:36,209][root][INFO] - Training Epoch: 1/2, step 936/107898 completed (loss: 0.7854421138763428, acc: 0.625)
[2025-02-17 16:33:36,321][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:36,553][root][INFO] - Training Epoch: 1/2, step 937/107898 completed (loss: 0.5220818519592285, acc: 0.8484848737716675)
[2025-02-17 16:33:36,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:36,895][root][INFO] - Training Epoch: 1/2, step 938/107898 completed (loss: 0.10918884724378586, acc: 1.0)
[2025-02-17 16:33:36,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:37,191][root][INFO] - Training Epoch: 1/2, step 939/107898 completed (loss: 0.01684732176363468, acc: 1.0)
[2025-02-17 16:33:37,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:37,487][root][INFO] - Training Epoch: 1/2, step 940/107898 completed (loss: 1.4283430576324463, acc: 0.5)
[2025-02-17 16:33:37,577][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:37,803][root][INFO] - Training Epoch: 1/2, step 941/107898 completed (loss: 0.4375450909137726, acc: 0.8571428656578064)
[2025-02-17 16:33:37,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:38,100][root][INFO] - Training Epoch: 1/2, step 942/107898 completed (loss: 2.168454885482788, acc: 0.6363636255264282)
[2025-02-17 16:33:38,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:38,383][root][INFO] - Training Epoch: 1/2, step 943/107898 completed (loss: 1.22062349319458, acc: 0.7368420958518982)
[2025-02-17 16:33:38,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:38,689][root][INFO] - Training Epoch: 1/2, step 944/107898 completed (loss: 0.44852709770202637, acc: 0.8888888955116272)
[2025-02-17 16:33:38,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:39,015][root][INFO] - Training Epoch: 1/2, step 945/107898 completed (loss: 0.9137933254241943, acc: 0.8846153616905212)
[2025-02-17 16:33:39,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:39,301][root][INFO] - Training Epoch: 1/2, step 946/107898 completed (loss: 1.1082066297531128, acc: 0.8181818127632141)
[2025-02-17 16:33:39,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:39,586][root][INFO] - Training Epoch: 1/2, step 947/107898 completed (loss: 2.663609743118286, acc: 0.5)
[2025-02-17 16:33:39,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:39,901][root][INFO] - Training Epoch: 1/2, step 948/107898 completed (loss: 3.39573073387146, acc: 0.3333333432674408)
[2025-02-17 16:33:39,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:40,208][root][INFO] - Training Epoch: 1/2, step 949/107898 completed (loss: 0.5626168251037598, acc: 0.8333333134651184)
[2025-02-17 16:33:40,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:40,519][root][INFO] - Training Epoch: 1/2, step 950/107898 completed (loss: 3.2181365489959717, acc: 0.5)
[2025-02-17 16:33:40,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:40,851][root][INFO] - Training Epoch: 1/2, step 951/107898 completed (loss: 0.4402282238006592, acc: 0.8999999761581421)
[2025-02-17 16:33:40,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:41,170][root][INFO] - Training Epoch: 1/2, step 952/107898 completed (loss: 0.6864141225814819, acc: 0.8500000238418579)
[2025-02-17 16:33:41,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:41,434][root][INFO] - Training Epoch: 1/2, step 953/107898 completed (loss: 1.8739022016525269, acc: 0.5714285969734192)
[2025-02-17 16:33:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:41,724][root][INFO] - Training Epoch: 1/2, step 954/107898 completed (loss: 3.3282995223999023, acc: 0.3125)
[2025-02-17 16:33:41,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:42,019][root][INFO] - Training Epoch: 1/2, step 955/107898 completed (loss: 1.537750244140625, acc: 0.7142857313156128)
[2025-02-17 16:33:42,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:42,326][root][INFO] - Training Epoch: 1/2, step 956/107898 completed (loss: 0.3258451819419861, acc: 0.8999999761581421)
[2025-02-17 16:33:42,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:42,655][root][INFO] - Training Epoch: 1/2, step 957/107898 completed (loss: 0.6277633309364319, acc: 0.8333333134651184)
[2025-02-17 16:33:42,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:42,944][root][INFO] - Training Epoch: 1/2, step 958/107898 completed (loss: 1.9536864757537842, acc: 0.5882353186607361)
[2025-02-17 16:33:43,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:43,244][root][INFO] - Training Epoch: 1/2, step 959/107898 completed (loss: 0.9981260299682617, acc: 0.7916666865348816)
[2025-02-17 16:33:43,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:43,531][root][INFO] - Training Epoch: 1/2, step 960/107898 completed (loss: 2.323514223098755, acc: 0.5)
[2025-02-17 16:33:43,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:43,826][root][INFO] - Training Epoch: 1/2, step 961/107898 completed (loss: 1.5366270542144775, acc: 0.5)
[2025-02-17 16:33:43,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:44,160][root][INFO] - Training Epoch: 1/2, step 962/107898 completed (loss: 2.7309956550598145, acc: 0.0)
[2025-02-17 16:33:44,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:44,508][root][INFO] - Training Epoch: 1/2, step 963/107898 completed (loss: 3.034998893737793, acc: 0.4545454680919647)
[2025-02-17 16:33:44,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:44,858][root][INFO] - Training Epoch: 1/2, step 964/107898 completed (loss: 2.489132881164551, acc: 0.2222222238779068)
[2025-02-17 16:33:44,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:45,144][root][INFO] - Training Epoch: 1/2, step 965/107898 completed (loss: 5.32977294921875, acc: 0.0)
[2025-02-17 16:33:45,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:45,417][root][INFO] - Training Epoch: 1/2, step 966/107898 completed (loss: 1.5622456073760986, acc: 0.75)
[2025-02-17 16:33:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:45,714][root][INFO] - Training Epoch: 1/2, step 967/107898 completed (loss: 0.37728485465049744, acc: 0.800000011920929)
[2025-02-17 16:33:45,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:46,015][root][INFO] - Training Epoch: 1/2, step 968/107898 completed (loss: 0.10468257963657379, acc: 1.0)
[2025-02-17 16:33:46,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:46,315][root][INFO] - Training Epoch: 1/2, step 969/107898 completed (loss: 1.2931805849075317, acc: 0.75)
[2025-02-17 16:33:46,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:46,606][root][INFO] - Training Epoch: 1/2, step 970/107898 completed (loss: 0.06600099056959152, acc: 1.0)
[2025-02-17 16:33:46,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:46,907][root][INFO] - Training Epoch: 1/2, step 971/107898 completed (loss: 1.3327455520629883, acc: 0.3333333432674408)
[2025-02-17 16:33:46,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:47,148][root][INFO] - Training Epoch: 1/2, step 972/107898 completed (loss: 0.9129104614257812, acc: 0.5)
[2025-02-17 16:33:47,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:47,442][root][INFO] - Training Epoch: 1/2, step 973/107898 completed (loss: 0.30606409907341003, acc: 0.9166666865348816)
[2025-02-17 16:33:47,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:47,788][root][INFO] - Training Epoch: 1/2, step 974/107898 completed (loss: 0.15706488490104675, acc: 1.0)
[2025-02-17 16:33:47,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:48,120][root][INFO] - Training Epoch: 1/2, step 975/107898 completed (loss: 1.080302119255066, acc: 0.8421052694320679)
[2025-02-17 16:33:48,228][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:48,453][root][INFO] - Training Epoch: 1/2, step 976/107898 completed (loss: 0.10196763277053833, acc: 1.0)
[2025-02-17 16:33:48,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:48,757][root][INFO] - Training Epoch: 1/2, step 977/107898 completed (loss: 1.820075511932373, acc: 0.5)
[2025-02-17 16:33:48,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:49,080][root][INFO] - Training Epoch: 1/2, step 978/107898 completed (loss: 1.7013417482376099, acc: 0.5)
[2025-02-17 16:33:49,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:49,363][root][INFO] - Training Epoch: 1/2, step 979/107898 completed (loss: 5.399824619293213, acc: 0.0)
[2025-02-17 16:33:49,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:49,657][root][INFO] - Training Epoch: 1/2, step 980/107898 completed (loss: 0.47435328364372253, acc: 1.0)
[2025-02-17 16:33:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:49,985][root][INFO] - Training Epoch: 1/2, step 981/107898 completed (loss: 0.623192548751831, acc: 0.7777777910232544)
[2025-02-17 16:33:50,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:50,326][root][INFO] - Training Epoch: 1/2, step 982/107898 completed (loss: 4.290923595428467, acc: 0.375)
[2025-02-17 16:33:50,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:50,628][root][INFO] - Training Epoch: 1/2, step 983/107898 completed (loss: 1.641461968421936, acc: 0.7027027010917664)
[2025-02-17 16:33:50,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:50,949][root][INFO] - Training Epoch: 1/2, step 984/107898 completed (loss: 1.2934610843658447, acc: 0.5)
[2025-02-17 16:33:51,055][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:51,272][root][INFO] - Training Epoch: 1/2, step 985/107898 completed (loss: 0.4331831634044647, acc: 0.875)
[2025-02-17 16:33:51,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:51,558][root][INFO] - Training Epoch: 1/2, step 986/107898 completed (loss: 0.7691544890403748, acc: 0.8275862336158752)
[2025-02-17 16:33:51,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:51,850][root][INFO] - Training Epoch: 1/2, step 987/107898 completed (loss: 0.6786726117134094, acc: 0.6666666865348816)
[2025-02-17 16:33:51,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:52,167][root][INFO] - Training Epoch: 1/2, step 988/107898 completed (loss: 3.112295150756836, acc: 0.4166666567325592)
[2025-02-17 16:33:52,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:52,507][root][INFO] - Training Epoch: 1/2, step 989/107898 completed (loss: 3.767425298690796, acc: 0.4285714328289032)
[2025-02-17 16:33:52,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:52,851][root][INFO] - Training Epoch: 1/2, step 990/107898 completed (loss: 0.2561503052711487, acc: 0.8846153616905212)
[2025-02-17 16:33:52,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:53,196][root][INFO] - Training Epoch: 1/2, step 991/107898 completed (loss: 1.3990360498428345, acc: 0.695652186870575)
[2025-02-17 16:33:53,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:53,493][root][INFO] - Training Epoch: 1/2, step 992/107898 completed (loss: 5.863946437835693, acc: 0.05882352963089943)
[2025-02-17 16:33:53,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:53,840][root][INFO] - Training Epoch: 1/2, step 993/107898 completed (loss: 3.211545705795288, acc: 0.23076923191547394)
[2025-02-17 16:33:53,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:54,152][root][INFO] - Training Epoch: 1/2, step 994/107898 completed (loss: 1.1472253799438477, acc: 0.8461538553237915)
[2025-02-17 16:33:54,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:54,427][root][INFO] - Training Epoch: 1/2, step 995/107898 completed (loss: 3.355785846710205, acc: 0.5)
[2025-02-17 16:33:54,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:54,754][root][INFO] - Training Epoch: 1/2, step 996/107898 completed (loss: 2.1516013145446777, acc: 0.5454545617103577)
[2025-02-17 16:33:54,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:55,049][root][INFO] - Training Epoch: 1/2, step 997/107898 completed (loss: 1.6067684888839722, acc: 0.7142857313156128)
[2025-02-17 16:33:55,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:55,324][root][INFO] - Training Epoch: 1/2, step 998/107898 completed (loss: 0.2992713451385498, acc: 0.9090909361839294)
[2025-02-17 16:33:55,394][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:55,621][root][INFO] - Training Epoch: 1/2, step 999/107898 completed (loss: 1.6375491619110107, acc: 0.699999988079071)
[2025-02-17 16:33:55,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:55,984][root][INFO] - Training Epoch: 1/2, step 1000/107898 completed (loss: 0.24693356454372406, acc: 0.9259259104728699)
[2025-02-17 16:33:56,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:56,339][root][INFO] - Training Epoch: 1/2, step 1001/107898 completed (loss: 0.2587016224861145, acc: 0.9200000166893005)
[2025-02-17 16:33:56,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:56,680][root][INFO] - Training Epoch: 1/2, step 1002/107898 completed (loss: 0.6480876803398132, acc: 0.8333333134651184)
[2025-02-17 16:33:56,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:57,010][root][INFO] - Training Epoch: 1/2, step 1003/107898 completed (loss: 2.4199113845825195, acc: 0.5)
[2025-02-17 16:33:57,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:57,301][root][INFO] - Training Epoch: 1/2, step 1004/107898 completed (loss: 0.21684488654136658, acc: 1.0)
[2025-02-17 16:33:57,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:57,650][root][INFO] - Training Epoch: 1/2, step 1005/107898 completed (loss: 2.750715494155884, acc: 0.6000000238418579)
[2025-02-17 16:33:57,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:57,970][root][INFO] - Training Epoch: 1/2, step 1006/107898 completed (loss: 2.8613946437835693, acc: 0.6666666865348816)
[2025-02-17 16:33:58,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:58,305][root][INFO] - Training Epoch: 1/2, step 1007/107898 completed (loss: 0.5418006181716919, acc: 0.5)
[2025-02-17 16:33:58,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:58,626][root][INFO] - Training Epoch: 1/2, step 1008/107898 completed (loss: 0.36714890599250793, acc: 0.8333333134651184)
[2025-02-17 16:33:58,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:59,053][root][INFO] - Training Epoch: 1/2, step 1009/107898 completed (loss: 1.0113741159439087, acc: 0.8571428656578064)
[2025-02-17 16:33:59,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:59,417][root][INFO] - Training Epoch: 1/2, step 1010/107898 completed (loss: 1.6269524097442627, acc: 0.8333333134651184)
[2025-02-17 16:33:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:33:59,724][root][INFO] - Training Epoch: 1/2, step 1011/107898 completed (loss: 2.8398072719573975, acc: 0.6666666865348816)
[2025-02-17 16:33:59,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:00,092][root][INFO] - Training Epoch: 1/2, step 1012/107898 completed (loss: 0.705954909324646, acc: 0.8125)
[2025-02-17 16:34:00,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:00,411][root][INFO] - Training Epoch: 1/2, step 1013/107898 completed (loss: 2.1575305461883545, acc: 0.5)
[2025-02-17 16:34:00,492][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:00,723][root][INFO] - Training Epoch: 1/2, step 1014/107898 completed (loss: 1.0947507619857788, acc: 0.5)
[2025-02-17 16:34:00,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:01,091][root][INFO] - Training Epoch: 1/2, step 1015/107898 completed (loss: 0.05757904797792435, acc: 1.0)
[2025-02-17 16:34:01,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:01,407][root][INFO] - Training Epoch: 1/2, step 1016/107898 completed (loss: 2.248566150665283, acc: 0.0)
[2025-02-17 16:34:01,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:01,770][root][INFO] - Training Epoch: 1/2, step 1017/107898 completed (loss: 0.07278481125831604, acc: 1.0)
[2025-02-17 16:34:01,863][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:02,087][root][INFO] - Training Epoch: 1/2, step 1018/107898 completed (loss: 1.5348601341247559, acc: 0.800000011920929)
[2025-02-17 16:34:02,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:02,433][root][INFO] - Training Epoch: 1/2, step 1019/107898 completed (loss: 2.0613362789154053, acc: 0.6666666865348816)
[2025-02-17 16:34:02,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:02,766][root][INFO] - Training Epoch: 1/2, step 1020/107898 completed (loss: 2.3653221130371094, acc: 0.6666666865348816)
[2025-02-17 16:34:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:03,066][root][INFO] - Training Epoch: 1/2, step 1021/107898 completed (loss: 1.144053339958191, acc: 0.8888888955116272)
[2025-02-17 16:34:03,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:03,376][root][INFO] - Training Epoch: 1/2, step 1022/107898 completed (loss: 1.1533738374710083, acc: 0.8333333134651184)
[2025-02-17 16:34:03,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:03,696][root][INFO] - Training Epoch: 1/2, step 1023/107898 completed (loss: 0.01283338014036417, acc: 1.0)
[2025-02-17 16:34:03,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:04,059][root][INFO] - Training Epoch: 1/2, step 1024/107898 completed (loss: 1.4915201663970947, acc: 0.675000011920929)
[2025-02-17 16:34:04,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:04,399][root][INFO] - Training Epoch: 1/2, step 1025/107898 completed (loss: 0.19645264744758606, acc: 1.0)
[2025-02-17 16:34:04,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:04,734][root][INFO] - Training Epoch: 1/2, step 1026/107898 completed (loss: 0.04468381404876709, acc: 1.0)
[2025-02-17 16:34:04,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:05,056][root][INFO] - Training Epoch: 1/2, step 1027/107898 completed (loss: 0.853860080242157, acc: 0.8571428656578064)
[2025-02-17 16:34:05,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:05,383][root][INFO] - Training Epoch: 1/2, step 1028/107898 completed (loss: 0.020231079310178757, acc: 1.0)
[2025-02-17 16:34:05,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:05,728][root][INFO] - Training Epoch: 1/2, step 1029/107898 completed (loss: 1.90218186378479, acc: 0.6875)
[2025-02-17 16:34:05,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:06,061][root][INFO] - Training Epoch: 1/2, step 1030/107898 completed (loss: 0.8348110914230347, acc: 0.7878788113594055)
[2025-02-17 16:34:06,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:06,327][root][INFO] - Training Epoch: 1/2, step 1031/107898 completed (loss: 0.03769349306821823, acc: 1.0)
[2025-02-17 16:34:06,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:06,607][root][INFO] - Training Epoch: 1/2, step 1032/107898 completed (loss: 2.5751428604125977, acc: 0.5)
[2025-02-17 16:34:06,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:06,928][root][INFO] - Training Epoch: 1/2, step 1033/107898 completed (loss: 0.022985165938735008, acc: 1.0)
[2025-02-17 16:34:07,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:07,228][root][INFO] - Training Epoch: 1/2, step 1034/107898 completed (loss: 1.2789727449417114, acc: 0.807692289352417)
[2025-02-17 16:34:07,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:07,520][root][INFO] - Training Epoch: 1/2, step 1035/107898 completed (loss: 0.5400003790855408, acc: 0.6666666865348816)
[2025-02-17 16:34:07,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:07,870][root][INFO] - Training Epoch: 1/2, step 1036/107898 completed (loss: 0.011301961727440357, acc: 1.0)
[2025-02-17 16:34:07,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:08,193][root][INFO] - Training Epoch: 1/2, step 1037/107898 completed (loss: 0.7552716135978699, acc: 0.5)
[2025-02-17 16:34:08,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:08,513][root][INFO] - Training Epoch: 1/2, step 1038/107898 completed (loss: 1.2808274030685425, acc: 0.800000011920929)
[2025-02-17 16:34:08,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:08,787][root][INFO] - Training Epoch: 1/2, step 1039/107898 completed (loss: 1.902958631515503, acc: 0.7333333492279053)
[2025-02-17 16:34:08,896][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:09,130][root][INFO] - Training Epoch: 1/2, step 1040/107898 completed (loss: 1.368330717086792, acc: 0.5)
[2025-02-17 16:34:09,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:09,455][root][INFO] - Training Epoch: 1/2, step 1041/107898 completed (loss: 0.4133063554763794, acc: 0.8888888955116272)
[2025-02-17 16:34:09,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:09,770][root][INFO] - Training Epoch: 1/2, step 1042/107898 completed (loss: 1.8394235372543335, acc: 0.6499999761581421)
[2025-02-17 16:34:09,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:10,124][root][INFO] - Training Epoch: 1/2, step 1043/107898 completed (loss: 0.056850891560316086, acc: 1.0)
[2025-02-17 16:34:10,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:10,455][root][INFO] - Training Epoch: 1/2, step 1044/107898 completed (loss: 0.6101099252700806, acc: 0.8947368264198303)
[2025-02-17 16:34:10,545][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:10,768][root][INFO] - Training Epoch: 1/2, step 1045/107898 completed (loss: 2.0045583248138428, acc: 0.3333333432674408)
[2025-02-17 16:34:10,882][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:11,126][root][INFO] - Training Epoch: 1/2, step 1046/107898 completed (loss: 0.07527081668376923, acc: 1.0)
[2025-02-17 16:34:11,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:11,447][root][INFO] - Training Epoch: 1/2, step 1047/107898 completed (loss: 2.945018768310547, acc: 0.5)
[2025-02-17 16:34:11,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:11,755][root][INFO] - Training Epoch: 1/2, step 1048/107898 completed (loss: 0.9150006771087646, acc: 0.75)
[2025-02-17 16:34:11,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:12,062][root][INFO] - Training Epoch: 1/2, step 1049/107898 completed (loss: 0.5921304821968079, acc: 0.6666666865348816)
[2025-02-17 16:34:12,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:12,364][root][INFO] - Training Epoch: 1/2, step 1050/107898 completed (loss: 0.4821140170097351, acc: 0.8999999761581421)
[2025-02-17 16:34:12,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:12,687][root][INFO] - Training Epoch: 1/2, step 1051/107898 completed (loss: 4.660548686981201, acc: 0.30000001192092896)
[2025-02-17 16:34:12,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:13,003][root][INFO] - Training Epoch: 1/2, step 1052/107898 completed (loss: 0.09844375401735306, acc: 1.0)
[2025-02-17 16:34:13,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:13,355][root][INFO] - Training Epoch: 1/2, step 1053/107898 completed (loss: 0.5122107863426208, acc: 0.8500000238418579)
[2025-02-17 16:34:13,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:13,684][root][INFO] - Training Epoch: 1/2, step 1054/107898 completed (loss: 1.5825669765472412, acc: 0.4000000059604645)
[2025-02-17 16:34:13,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:14,037][root][INFO] - Training Epoch: 1/2, step 1055/107898 completed (loss: 0.20482280850410461, acc: 1.0)
[2025-02-17 16:34:14,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:14,385][root][INFO] - Training Epoch: 1/2, step 1056/107898 completed (loss: 1.6585828065872192, acc: 0.6666666865348816)
[2025-02-17 16:34:14,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:14,742][root][INFO] - Training Epoch: 1/2, step 1057/107898 completed (loss: 1.162163257598877, acc: 0.7692307829856873)
[2025-02-17 16:34:14,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:15,072][root][INFO] - Training Epoch: 1/2, step 1058/107898 completed (loss: 0.061659909784793854, acc: 1.0)
[2025-02-17 16:34:15,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:15,401][root][INFO] - Training Epoch: 1/2, step 1059/107898 completed (loss: 0.38076773285865784, acc: 1.0)
[2025-02-17 16:34:15,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:15,736][root][INFO] - Training Epoch: 1/2, step 1060/107898 completed (loss: 1.0011080503463745, acc: 0.8461538553237915)
[2025-02-17 16:34:15,816][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:16,035][root][INFO] - Training Epoch: 1/2, step 1061/107898 completed (loss: 2.7876853942871094, acc: 0.5)
[2025-02-17 16:34:16,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:16,326][root][INFO] - Training Epoch: 1/2, step 1062/107898 completed (loss: 0.21292205154895782, acc: 1.0)
[2025-02-17 16:34:16,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:16,596][root][INFO] - Training Epoch: 1/2, step 1063/107898 completed (loss: 1.0487816333770752, acc: 0.8947368264198303)
[2025-02-17 16:34:16,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:16,892][root][INFO] - Training Epoch: 1/2, step 1064/107898 completed (loss: 1.6185892820358276, acc: 0.5714285969734192)
[2025-02-17 16:34:17,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:17,244][root][INFO] - Training Epoch: 1/2, step 1065/107898 completed (loss: 1.2885736227035522, acc: 0.800000011920929)
[2025-02-17 16:34:17,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:17,569][root][INFO] - Training Epoch: 1/2, step 1066/107898 completed (loss: 1.9875296354293823, acc: 0.692307710647583)
[2025-02-17 16:34:17,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:17,906][root][INFO] - Training Epoch: 1/2, step 1067/107898 completed (loss: 0.04333443567156792, acc: 1.0)
[2025-02-17 16:34:17,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:18,211][root][INFO] - Training Epoch: 1/2, step 1068/107898 completed (loss: 3.0216825008392334, acc: 0.3571428656578064)
[2025-02-17 16:34:18,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:18,498][root][INFO] - Training Epoch: 1/2, step 1069/107898 completed (loss: 2.5857744216918945, acc: 0.75)
[2025-02-17 16:34:18,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:18,838][root][INFO] - Training Epoch: 1/2, step 1070/107898 completed (loss: 0.6816604137420654, acc: 0.800000011920929)
[2025-02-17 16:34:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:19,143][root][INFO] - Training Epoch: 1/2, step 1071/107898 completed (loss: 6.626006126403809, acc: 0.25)
[2025-02-17 16:34:19,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:19,484][root][INFO] - Training Epoch: 1/2, step 1072/107898 completed (loss: 3.635164260864258, acc: 0.5)
[2025-02-17 16:34:19,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:19,835][root][INFO] - Training Epoch: 1/2, step 1073/107898 completed (loss: 0.1600354164838791, acc: 0.9642857313156128)
[2025-02-17 16:34:19,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:20,125][root][INFO] - Training Epoch: 1/2, step 1074/107898 completed (loss: 2.5105249881744385, acc: 0.5454545617103577)
[2025-02-17 16:34:20,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:20,485][root][INFO] - Training Epoch: 1/2, step 1075/107898 completed (loss: 0.5362454056739807, acc: 0.8799999952316284)
[2025-02-17 16:34:20,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:20,791][root][INFO] - Training Epoch: 1/2, step 1076/107898 completed (loss: 0.11813868582248688, acc: 1.0)
[2025-02-17 16:34:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:21,123][root][INFO] - Training Epoch: 1/2, step 1077/107898 completed (loss: 1.5284351110458374, acc: 0.75)
[2025-02-17 16:34:21,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:21,427][root][INFO] - Training Epoch: 1/2, step 1078/107898 completed (loss: 0.9131531715393066, acc: 0.8571428656578064)
[2025-02-17 16:34:21,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:21,704][root][INFO] - Training Epoch: 1/2, step 1079/107898 completed (loss: 2.736867904663086, acc: 0.5)
[2025-02-17 16:34:21,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:22,005][root][INFO] - Training Epoch: 1/2, step 1080/107898 completed (loss: 2.4329428672790527, acc: 0.5)
[2025-02-17 16:34:22,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:22,317][root][INFO] - Training Epoch: 1/2, step 1081/107898 completed (loss: 0.745547890663147, acc: 0.7777777910232544)
[2025-02-17 16:34:22,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:22,607][root][INFO] - Training Epoch: 1/2, step 1082/107898 completed (loss: 0.3863941431045532, acc: 1.0)
[2025-02-17 16:34:22,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:22,905][root][INFO] - Training Epoch: 1/2, step 1083/107898 completed (loss: 3.2995166778564453, acc: 0.5714285969734192)
[2025-02-17 16:34:23,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:23,238][root][INFO] - Training Epoch: 1/2, step 1084/107898 completed (loss: 1.7028475999832153, acc: 0.7272727489471436)
[2025-02-17 16:34:23,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:23,564][root][INFO] - Training Epoch: 1/2, step 1085/107898 completed (loss: 2.2590103149414062, acc: 0.6000000238418579)
[2025-02-17 16:34:23,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:23,888][root][INFO] - Training Epoch: 1/2, step 1086/107898 completed (loss: 3.072559356689453, acc: 0.20000000298023224)
[2025-02-17 16:34:24,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:24,220][root][INFO] - Training Epoch: 1/2, step 1087/107898 completed (loss: 0.3104499578475952, acc: 0.8888888955116272)
[2025-02-17 16:34:24,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:24,517][root][INFO] - Training Epoch: 1/2, step 1088/107898 completed (loss: 0.6887542009353638, acc: 0.8275862336158752)
[2025-02-17 16:34:24,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:24,849][root][INFO] - Training Epoch: 1/2, step 1089/107898 completed (loss: 2.8541171550750732, acc: 0.4615384638309479)
[2025-02-17 16:34:24,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:25,166][root][INFO] - Training Epoch: 1/2, step 1090/107898 completed (loss: 6.2954325675964355, acc: 0.5)
[2025-02-17 16:34:25,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:25,510][root][INFO] - Training Epoch: 1/2, step 1091/107898 completed (loss: 0.8930646777153015, acc: 0.8333333134651184)
[2025-02-17 16:34:25,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:25,848][root][INFO] - Training Epoch: 1/2, step 1092/107898 completed (loss: 0.3408068120479584, acc: 0.9375)
[2025-02-17 16:34:25,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:26,201][root][INFO] - Training Epoch: 1/2, step 1093/107898 completed (loss: 1.342515230178833, acc: 0.692307710647583)
[2025-02-17 16:34:26,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:26,522][root][INFO] - Training Epoch: 1/2, step 1094/107898 completed (loss: 0.3345607817173004, acc: 1.0)
[2025-02-17 16:34:26,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:26,840][root][INFO] - Training Epoch: 1/2, step 1095/107898 completed (loss: 0.5858986973762512, acc: 0.8666666746139526)
[2025-02-17 16:34:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:27,155][root][INFO] - Training Epoch: 1/2, step 1096/107898 completed (loss: 0.7191513180732727, acc: 0.8518518805503845)
[2025-02-17 16:34:27,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:27,446][root][INFO] - Training Epoch: 1/2, step 1097/107898 completed (loss: 5.6359758377075195, acc: 0.5)
[2025-02-17 16:34:27,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:27,753][root][INFO] - Training Epoch: 1/2, step 1098/107898 completed (loss: 2.7727410793304443, acc: 0.1428571492433548)
[2025-02-17 16:34:27,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:28,072][root][INFO] - Training Epoch: 1/2, step 1099/107898 completed (loss: 0.2603406608104706, acc: 1.0)
[2025-02-17 16:34:28,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:28,364][root][INFO] - Training Epoch: 1/2, step 1100/107898 completed (loss: 1.0406540632247925, acc: 0.7666666507720947)
[2025-02-17 16:34:28,475][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:28,724][root][INFO] - Training Epoch: 1/2, step 1101/107898 completed (loss: 1.2161271572113037, acc: 0.5)
[2025-02-17 16:34:28,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:29,041][root][INFO] - Training Epoch: 1/2, step 1102/107898 completed (loss: 1.148010015487671, acc: 0.7368420958518982)
[2025-02-17 16:34:29,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:29,332][root][INFO] - Training Epoch: 1/2, step 1103/107898 completed (loss: 0.9663848280906677, acc: 0.800000011920929)
[2025-02-17 16:34:29,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:29,623][root][INFO] - Training Epoch: 1/2, step 1104/107898 completed (loss: 2.515136480331421, acc: 0.6666666865348816)
[2025-02-17 16:34:29,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:29,919][root][INFO] - Training Epoch: 1/2, step 1105/107898 completed (loss: 1.8198641538619995, acc: 0.6190476417541504)
[2025-02-17 16:34:30,005][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:30,246][root][INFO] - Training Epoch: 1/2, step 1106/107898 completed (loss: 0.7512556314468384, acc: 0.75)
[2025-02-17 16:34:30,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:30,576][root][INFO] - Training Epoch: 1/2, step 1107/107898 completed (loss: 1.1821662187576294, acc: 0.800000011920929)
[2025-02-17 16:34:30,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:30,894][root][INFO] - Training Epoch: 1/2, step 1108/107898 completed (loss: 0.20078299939632416, acc: 0.9444444179534912)
[2025-02-17 16:34:30,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:31,188][root][INFO] - Training Epoch: 1/2, step 1109/107898 completed (loss: 0.8627759218215942, acc: 1.0)
[2025-02-17 16:34:31,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:31,491][root][INFO] - Training Epoch: 1/2, step 1110/107898 completed (loss: 0.43503355979919434, acc: 1.0)
[2025-02-17 16:34:31,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:31,788][root][INFO] - Training Epoch: 1/2, step 1111/107898 completed (loss: 1.4534482955932617, acc: 0.75)
[2025-02-17 16:34:31,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:32,095][root][INFO] - Training Epoch: 1/2, step 1112/107898 completed (loss: 2.816711187362671, acc: 0.4166666567325592)
[2025-02-17 16:34:32,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:32,417][root][INFO] - Training Epoch: 1/2, step 1113/107898 completed (loss: 0.9288206696510315, acc: 0.7647058963775635)
[2025-02-17 16:34:32,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:32,722][root][INFO] - Training Epoch: 1/2, step 1114/107898 completed (loss: 1.3608648777008057, acc: 0.5)
[2025-02-17 16:34:32,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:33,047][root][INFO] - Training Epoch: 1/2, step 1115/107898 completed (loss: 0.07139561325311661, acc: 1.0)
[2025-02-17 16:34:33,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:33,371][root][INFO] - Training Epoch: 1/2, step 1116/107898 completed (loss: 0.8623603582382202, acc: 0.8571428656578064)
[2025-02-17 16:34:33,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:33,672][root][INFO] - Training Epoch: 1/2, step 1117/107898 completed (loss: 2.5926406383514404, acc: 0.6666666865348816)
[2025-02-17 16:34:33,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:33,971][root][INFO] - Training Epoch: 1/2, step 1118/107898 completed (loss: 2.8892624378204346, acc: 0.4166666567325592)
[2025-02-17 16:34:34,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:34,263][root][INFO] - Training Epoch: 1/2, step 1119/107898 completed (loss: 0.10927091538906097, acc: 1.0)
[2025-02-17 16:34:34,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:34,555][root][INFO] - Training Epoch: 1/2, step 1120/107898 completed (loss: 1.4592013359069824, acc: 0.6666666865348816)
[2025-02-17 16:34:34,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:34,877][root][INFO] - Training Epoch: 1/2, step 1121/107898 completed (loss: 0.5079464316368103, acc: 0.9230769276618958)
[2025-02-17 16:34:34,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:35,192][root][INFO] - Training Epoch: 1/2, step 1122/107898 completed (loss: 0.18435831367969513, acc: 1.0)
[2025-02-17 16:34:35,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:35,529][root][INFO] - Training Epoch: 1/2, step 1123/107898 completed (loss: 0.03503808379173279, acc: 1.0)
[2025-02-17 16:34:35,611][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:35,829][root][INFO] - Training Epoch: 1/2, step 1124/107898 completed (loss: 1.6581439971923828, acc: 0.7777777910232544)
[2025-02-17 16:34:35,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:36,177][root][INFO] - Training Epoch: 1/2, step 1125/107898 completed (loss: 0.14362718164920807, acc: 1.0)
[2025-02-17 16:34:36,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:36,517][root][INFO] - Training Epoch: 1/2, step 1126/107898 completed (loss: 0.9945512413978577, acc: 0.8888888955116272)
[2025-02-17 16:34:36,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:36,827][root][INFO] - Training Epoch: 1/2, step 1127/107898 completed (loss: 0.3739866316318512, acc: 1.0)
[2025-02-17 16:34:36,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:37,122][root][INFO] - Training Epoch: 1/2, step 1128/107898 completed (loss: 2.9925646781921387, acc: 0.4285714328289032)
[2025-02-17 16:34:37,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:37,423][root][INFO] - Training Epoch: 1/2, step 1129/107898 completed (loss: 1.0169422626495361, acc: 0.800000011920929)
[2025-02-17 16:34:37,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:37,751][root][INFO] - Training Epoch: 1/2, step 1130/107898 completed (loss: 0.5729868412017822, acc: 0.8888888955116272)
[2025-02-17 16:34:37,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:38,062][root][INFO] - Training Epoch: 1/2, step 1131/107898 completed (loss: 1.4675865173339844, acc: 0.6666666865348816)
[2025-02-17 16:34:38,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:38,359][root][INFO] - Training Epoch: 1/2, step 1132/107898 completed (loss: 0.07534909248352051, acc: 1.0)
[2025-02-17 16:34:38,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:38,661][root][INFO] - Training Epoch: 1/2, step 1133/107898 completed (loss: 0.35800546407699585, acc: 1.0)
[2025-02-17 16:34:38,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:38,981][root][INFO] - Training Epoch: 1/2, step 1134/107898 completed (loss: 2.4868392944335938, acc: 0.5)
[2025-02-17 16:34:39,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:39,290][root][INFO] - Training Epoch: 1/2, step 1135/107898 completed (loss: 2.0889363288879395, acc: 0.3333333432674408)
[2025-02-17 16:34:39,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:39,599][root][INFO] - Training Epoch: 1/2, step 1136/107898 completed (loss: 2.0501537322998047, acc: 0.5384615659713745)
[2025-02-17 16:34:39,693][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:39,930][root][INFO] - Training Epoch: 1/2, step 1137/107898 completed (loss: 0.1766100525856018, acc: 1.0)
[2025-02-17 16:34:40,050][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:40,283][root][INFO] - Training Epoch: 1/2, step 1138/107898 completed (loss: 4.031085968017578, acc: 0.32258063554763794)
[2025-02-17 16:34:40,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:40,600][root][INFO] - Training Epoch: 1/2, step 1139/107898 completed (loss: 1.2321910858154297, acc: 0.6666666865348816)
[2025-02-17 16:34:40,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:40,891][root][INFO] - Training Epoch: 1/2, step 1140/107898 completed (loss: 0.04837024584412575, acc: 1.0)
[2025-02-17 16:34:40,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:41,200][root][INFO] - Training Epoch: 1/2, step 1141/107898 completed (loss: 0.6243717670440674, acc: 0.8399999737739563)
[2025-02-17 16:34:41,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:41,499][root][INFO] - Training Epoch: 1/2, step 1142/107898 completed (loss: 2.510469913482666, acc: 0.5555555820465088)
[2025-02-17 16:34:41,586][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:41,800][root][INFO] - Training Epoch: 1/2, step 1143/107898 completed (loss: 3.791489839553833, acc: 0.23076923191547394)
[2025-02-17 16:34:41,882][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:42,100][root][INFO] - Training Epoch: 1/2, step 1144/107898 completed (loss: 0.499942809343338, acc: 0.8333333134651184)
[2025-02-17 16:34:42,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:42,420][root][INFO] - Training Epoch: 1/2, step 1145/107898 completed (loss: 1.309516429901123, acc: 0.7647058963775635)
[2025-02-17 16:34:42,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:42,708][root][INFO] - Training Epoch: 1/2, step 1146/107898 completed (loss: 1.8219943046569824, acc: 0.7692307829856873)
[2025-02-17 16:34:42,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:42,971][root][INFO] - Training Epoch: 1/2, step 1147/107898 completed (loss: 0.11786149442195892, acc: 1.0)
[2025-02-17 16:34:43,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:43,264][root][INFO] - Training Epoch: 1/2, step 1148/107898 completed (loss: 1.753523826599121, acc: 0.6875)
[2025-02-17 16:34:43,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:43,573][root][INFO] - Training Epoch: 1/2, step 1149/107898 completed (loss: 2.3236234188079834, acc: 0.625)
[2025-02-17 16:34:43,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:43,909][root][INFO] - Training Epoch: 1/2, step 1150/107898 completed (loss: 1.9877535104751587, acc: 0.3333333432674408)
[2025-02-17 16:34:44,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:44,230][root][INFO] - Training Epoch: 1/2, step 1151/107898 completed (loss: 1.8177005052566528, acc: 0.6363636255264282)
[2025-02-17 16:34:44,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:44,539][root][INFO] - Training Epoch: 1/2, step 1152/107898 completed (loss: 0.11480290442705154, acc: 1.0)
[2025-02-17 16:34:44,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:44,906][root][INFO] - Training Epoch: 1/2, step 1153/107898 completed (loss: 0.4825044572353363, acc: 0.930232584476471)
[2025-02-17 16:34:45,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:45,239][root][INFO] - Training Epoch: 1/2, step 1154/107898 completed (loss: 0.9388993978500366, acc: 0.800000011920929)
[2025-02-17 16:34:45,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:45,574][root][INFO] - Training Epoch: 1/2, step 1155/107898 completed (loss: 2.7017691135406494, acc: 0.5454545617103577)
[2025-02-17 16:34:45,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:45,867][root][INFO] - Training Epoch: 1/2, step 1156/107898 completed (loss: 2.258174419403076, acc: 0.5833333134651184)
[2025-02-17 16:34:45,953][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:46,169][root][INFO] - Training Epoch: 1/2, step 1157/107898 completed (loss: 1.3901164531707764, acc: 0.5)
[2025-02-17 16:34:46,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:46,471][root][INFO] - Training Epoch: 1/2, step 1158/107898 completed (loss: 2.024853229522705, acc: 0.692307710647583)
[2025-02-17 16:34:46,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:46,760][root][INFO] - Training Epoch: 1/2, step 1159/107898 completed (loss: 3.7007038593292236, acc: 0.3333333432674408)
[2025-02-17 16:34:46,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:47,071][root][INFO] - Training Epoch: 1/2, step 1160/107898 completed (loss: 1.3829618692398071, acc: 0.75)
[2025-02-17 16:34:47,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:47,350][root][INFO] - Training Epoch: 1/2, step 1161/107898 completed (loss: 3.4023940563201904, acc: 0.4000000059604645)
[2025-02-17 16:34:47,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:47,653][root][INFO] - Training Epoch: 1/2, step 1162/107898 completed (loss: 0.5695682764053345, acc: 0.8260869383811951)
[2025-02-17 16:34:47,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:47,947][root][INFO] - Training Epoch: 1/2, step 1163/107898 completed (loss: 0.6352798938751221, acc: 0.699999988079071)
[2025-02-17 16:34:48,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:48,244][root][INFO] - Training Epoch: 1/2, step 1164/107898 completed (loss: 2.2156341075897217, acc: 0.6666666865348816)
[2025-02-17 16:34:48,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:48,548][root][INFO] - Training Epoch: 1/2, step 1165/107898 completed (loss: 1.155988097190857, acc: 0.800000011920929)
[2025-02-17 16:34:48,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:48,846][root][INFO] - Training Epoch: 1/2, step 1166/107898 completed (loss: 0.3086651861667633, acc: 0.8823529481887817)
[2025-02-17 16:34:48,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:49,162][root][INFO] - Training Epoch: 1/2, step 1167/107898 completed (loss: 0.8847090601921082, acc: 0.8571428656578064)
[2025-02-17 16:34:49,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:49,463][root][INFO] - Training Epoch: 1/2, step 1168/107898 completed (loss: 0.5472797751426697, acc: 1.0)
[2025-02-17 16:34:49,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:49,764][root][INFO] - Training Epoch: 1/2, step 1169/107898 completed (loss: 0.045473385602235794, acc: 1.0)
[2025-02-17 16:34:49,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:50,061][root][INFO] - Training Epoch: 1/2, step 1170/107898 completed (loss: 1.1561311483383179, acc: 0.7272727489471436)
[2025-02-17 16:34:50,157][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:50,384][root][INFO] - Training Epoch: 1/2, step 1171/107898 completed (loss: 4.161085605621338, acc: 0.125)
[2025-02-17 16:34:50,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:50,668][root][INFO] - Training Epoch: 1/2, step 1172/107898 completed (loss: 0.014218427240848541, acc: 1.0)
[2025-02-17 16:34:50,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:50,957][root][INFO] - Training Epoch: 1/2, step 1173/107898 completed (loss: 1.281915545463562, acc: 0.800000011920929)
[2025-02-17 16:34:51,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:51,250][root][INFO] - Training Epoch: 1/2, step 1174/107898 completed (loss: 1.3598531484603882, acc: 0.800000011920929)
[2025-02-17 16:34:51,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:51,549][root][INFO] - Training Epoch: 1/2, step 1175/107898 completed (loss: 0.34869635105133057, acc: 0.875)
[2025-02-17 16:34:51,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:51,866][root][INFO] - Training Epoch: 1/2, step 1176/107898 completed (loss: 0.21541061997413635, acc: 0.9230769276618958)
[2025-02-17 16:34:51,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:52,157][root][INFO] - Training Epoch: 1/2, step 1177/107898 completed (loss: 0.40198779106140137, acc: 1.0)
[2025-02-17 16:34:52,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:52,484][root][INFO] - Training Epoch: 1/2, step 1178/107898 completed (loss: 1.0723800659179688, acc: 0.5)
[2025-02-17 16:34:52,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:52,816][root][INFO] - Training Epoch: 1/2, step 1179/107898 completed (loss: 3.2393906116485596, acc: 0.2800000011920929)
[2025-02-17 16:34:52,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:53,118][root][INFO] - Training Epoch: 1/2, step 1180/107898 completed (loss: 2.4103198051452637, acc: 0.5454545617103577)
[2025-02-17 16:34:53,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:53,442][root][INFO] - Training Epoch: 1/2, step 1181/107898 completed (loss: 1.6408004760742188, acc: 0.5)
[2025-02-17 16:34:53,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:53,746][root][INFO] - Training Epoch: 1/2, step 1182/107898 completed (loss: 0.019366955384612083, acc: 1.0)
[2025-02-17 16:34:53,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:54,060][root][INFO] - Training Epoch: 1/2, step 1183/107898 completed (loss: 1.5411226749420166, acc: 0.699999988079071)
[2025-02-17 16:34:54,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:54,366][root][INFO] - Training Epoch: 1/2, step 1184/107898 completed (loss: 1.707448959350586, acc: 0.7058823704719543)
[2025-02-17 16:34:54,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:54,671][root][INFO] - Training Epoch: 1/2, step 1185/107898 completed (loss: 0.18369163572788239, acc: 1.0)
[2025-02-17 16:34:54,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:54,995][root][INFO] - Training Epoch: 1/2, step 1186/107898 completed (loss: 0.0988038182258606, acc: 1.0)
[2025-02-17 16:34:55,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:55,306][root][INFO] - Training Epoch: 1/2, step 1187/107898 completed (loss: 0.27110493183135986, acc: 0.9583333134651184)
[2025-02-17 16:34:55,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:55,609][root][INFO] - Training Epoch: 1/2, step 1188/107898 completed (loss: 0.05624824017286301, acc: 1.0)
[2025-02-17 16:34:55,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:55,904][root][INFO] - Training Epoch: 1/2, step 1189/107898 completed (loss: 0.7981316447257996, acc: 1.0)
[2025-02-17 16:34:55,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:56,201][root][INFO] - Training Epoch: 1/2, step 1190/107898 completed (loss: 2.998298168182373, acc: 0.4000000059604645)
[2025-02-17 16:34:56,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:56,503][root][INFO] - Training Epoch: 1/2, step 1191/107898 completed (loss: 4.530639171600342, acc: 0.3333333432674408)
[2025-02-17 16:34:56,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:56,802][root][INFO] - Training Epoch: 1/2, step 1192/107898 completed (loss: 1.471469521522522, acc: 0.6875)
[2025-02-17 16:34:56,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:57,102][root][INFO] - Training Epoch: 1/2, step 1193/107898 completed (loss: 0.8006443977355957, acc: 0.8235294222831726)
[2025-02-17 16:34:57,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:57,396][root][INFO] - Training Epoch: 1/2, step 1194/107898 completed (loss: 4.2637104988098145, acc: 0.22727273404598236)
[2025-02-17 16:34:57,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:57,734][root][INFO] - Training Epoch: 1/2, step 1195/107898 completed (loss: 0.45247766375541687, acc: 0.9411764740943909)
[2025-02-17 16:34:57,814][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:58,039][root][INFO] - Training Epoch: 1/2, step 1196/107898 completed (loss: 0.4711473882198334, acc: 1.0)
[2025-02-17 16:34:58,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:58,362][root][INFO] - Training Epoch: 1/2, step 1197/107898 completed (loss: 0.8640021085739136, acc: 0.7894737124443054)
[2025-02-17 16:34:58,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:58,653][root][INFO] - Training Epoch: 1/2, step 1198/107898 completed (loss: 0.08141306787729263, acc: 1.0)
[2025-02-17 16:34:58,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:58,976][root][INFO] - Training Epoch: 1/2, step 1199/107898 completed (loss: 1.5654876232147217, acc: 0.6818181872367859)
[2025-02-17 16:34:59,055][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:59,286][root][INFO] - Training Epoch: 1/2, step 1200/107898 completed (loss: 2.1796512603759766, acc: 0.625)
[2025-02-17 16:34:59,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:59,559][root][INFO] - Training Epoch: 1/2, step 1201/107898 completed (loss: 3.006049156188965, acc: 0.4615384638309479)
[2025-02-17 16:34:59,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:34:59,937][root][INFO] - Training Epoch: 1/2, step 1202/107898 completed (loss: 1.9084726572036743, acc: 0.7777777910232544)
[2025-02-17 16:35:00,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:00,327][root][INFO] - Training Epoch: 1/2, step 1203/107898 completed (loss: 0.46871882677078247, acc: 1.0)
[2025-02-17 16:35:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:00,646][root][INFO] - Training Epoch: 1/2, step 1204/107898 completed (loss: 0.8735520243644714, acc: 0.8333333134651184)
[2025-02-17 16:35:00,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:00,925][root][INFO] - Training Epoch: 1/2, step 1205/107898 completed (loss: 0.14414829015731812, acc: 1.0)
[2025-02-17 16:35:01,055][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:01,279][root][INFO] - Training Epoch: 1/2, step 1206/107898 completed (loss: 0.1369493007659912, acc: 1.0)
[2025-02-17 16:35:01,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:01,574][root][INFO] - Training Epoch: 1/2, step 1207/107898 completed (loss: 0.006417736876755953, acc: 1.0)
[2025-02-17 16:35:01,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:01,887][root][INFO] - Training Epoch: 1/2, step 1208/107898 completed (loss: 0.1577521115541458, acc: 0.9090909361839294)
[2025-02-17 16:35:01,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:02,235][root][INFO] - Training Epoch: 1/2, step 1209/107898 completed (loss: 0.4960692822933197, acc: 0.8888888955116272)
[2025-02-17 16:35:02,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:02,550][root][INFO] - Training Epoch: 1/2, step 1210/107898 completed (loss: 1.8308851718902588, acc: 0.75)
[2025-02-17 16:35:02,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:02,874][root][INFO] - Training Epoch: 1/2, step 1211/107898 completed (loss: 4.122461795806885, acc: 0.25)
[2025-02-17 16:35:02,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:03,206][root][INFO] - Training Epoch: 1/2, step 1212/107898 completed (loss: 0.7748092412948608, acc: 0.8709677457809448)
[2025-02-17 16:35:03,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:03,525][root][INFO] - Training Epoch: 1/2, step 1213/107898 completed (loss: 1.625885009765625, acc: 0.4285714328289032)
[2025-02-17 16:35:03,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:03,918][root][INFO] - Training Epoch: 1/2, step 1214/107898 completed (loss: 0.7826008200645447, acc: 0.9032257795333862)
[2025-02-17 16:35:04,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:04,224][root][INFO] - Training Epoch: 1/2, step 1215/107898 completed (loss: 0.0032494973856955767, acc: 1.0)
[2025-02-17 16:35:04,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:04,521][root][INFO] - Training Epoch: 1/2, step 1216/107898 completed (loss: 1.482574462890625, acc: 0.6666666865348816)
[2025-02-17 16:35:04,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:04,858][root][INFO] - Training Epoch: 1/2, step 1217/107898 completed (loss: 0.49447062611579895, acc: 0.7142857313156128)
[2025-02-17 16:35:04,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:05,195][root][INFO] - Training Epoch: 1/2, step 1218/107898 completed (loss: 1.140918254852295, acc: 0.6875)
[2025-02-17 16:35:05,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:05,500][root][INFO] - Training Epoch: 1/2, step 1219/107898 completed (loss: 0.4868561029434204, acc: 0.875)
[2025-02-17 16:35:05,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:05,877][root][INFO] - Training Epoch: 1/2, step 1220/107898 completed (loss: 1.834601640701294, acc: 0.7142857313156128)
[2025-02-17 16:35:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:06,223][root][INFO] - Training Epoch: 1/2, step 1221/107898 completed (loss: 3.5705068111419678, acc: 0.5)
[2025-02-17 16:35:06,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:06,576][root][INFO] - Training Epoch: 1/2, step 1222/107898 completed (loss: 1.489768147468567, acc: 0.7941176295280457)
[2025-02-17 16:35:06,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:06,904][root][INFO] - Training Epoch: 1/2, step 1223/107898 completed (loss: 0.023654641583561897, acc: 1.0)
[2025-02-17 16:35:07,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:07,259][root][INFO] - Training Epoch: 1/2, step 1224/107898 completed (loss: 4.227865695953369, acc: 0.375)
[2025-02-17 16:35:07,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:07,588][root][INFO] - Training Epoch: 1/2, step 1225/107898 completed (loss: 0.07983997464179993, acc: 1.0)
[2025-02-17 16:35:07,671][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:07,882][root][INFO] - Training Epoch: 1/2, step 1226/107898 completed (loss: 0.5299017429351807, acc: 1.0)
[2025-02-17 16:35:07,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:08,180][root][INFO] - Training Epoch: 1/2, step 1227/107898 completed (loss: 0.15302155911922455, acc: 1.0)
[2025-02-17 16:35:08,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:08,490][root][INFO] - Training Epoch: 1/2, step 1228/107898 completed (loss: 3.498494863510132, acc: 0.529411792755127)
[2025-02-17 16:35:08,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:08,840][root][INFO] - Training Epoch: 1/2, step 1229/107898 completed (loss: 0.7322262525558472, acc: 0.5)
[2025-02-17 16:35:08,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:09,173][root][INFO] - Training Epoch: 1/2, step 1230/107898 completed (loss: 4.040627479553223, acc: 0.23076923191547394)
[2025-02-17 16:35:09,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:09,488][root][INFO] - Training Epoch: 1/2, step 1231/107898 completed (loss: 0.8418445587158203, acc: 0.7272727489471436)
[2025-02-17 16:35:09,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:09,824][root][INFO] - Training Epoch: 1/2, step 1232/107898 completed (loss: 4.721032619476318, acc: 0.11764705926179886)
[2025-02-17 16:35:09,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:10,128][root][INFO] - Training Epoch: 1/2, step 1233/107898 completed (loss: 1.0764354467391968, acc: 0.8333333134651184)
[2025-02-17 16:35:10,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:10,447][root][INFO] - Training Epoch: 1/2, step 1234/107898 completed (loss: 0.021947309374809265, acc: 1.0)
[2025-02-17 16:35:10,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:10,745][root][INFO] - Training Epoch: 1/2, step 1235/107898 completed (loss: 0.0030032906215637922, acc: 1.0)
[2025-02-17 16:35:10,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:11,077][root][INFO] - Training Epoch: 1/2, step 1236/107898 completed (loss: 0.7347650527954102, acc: 0.8571428656578064)
[2025-02-17 16:35:11,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:11,380][root][INFO] - Training Epoch: 1/2, step 1237/107898 completed (loss: 0.008565951138734818, acc: 1.0)
[2025-02-17 16:35:11,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:11,700][root][INFO] - Training Epoch: 1/2, step 1238/107898 completed (loss: 0.28373318910598755, acc: 1.0)
[2025-02-17 16:35:11,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:11,986][root][INFO] - Training Epoch: 1/2, step 1239/107898 completed (loss: 2.2285776138305664, acc: 0.5333333611488342)
[2025-02-17 16:35:12,069][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:12,293][root][INFO] - Training Epoch: 1/2, step 1240/107898 completed (loss: 7.077672481536865, acc: 0.125)
[2025-02-17 16:35:12,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:12,586][root][INFO] - Training Epoch: 1/2, step 1241/107898 completed (loss: 0.016475237905979156, acc: 1.0)
[2025-02-17 16:35:12,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:12,875][root][INFO] - Training Epoch: 1/2, step 1242/107898 completed (loss: 1.0465044975280762, acc: 0.9090909361839294)
[2025-02-17 16:35:12,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:13,186][root][INFO] - Training Epoch: 1/2, step 1243/107898 completed (loss: 1.5914337635040283, acc: 0.75)
[2025-02-17 16:35:13,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:13,486][root][INFO] - Training Epoch: 1/2, step 1244/107898 completed (loss: 0.28592178225517273, acc: 1.0)
[2025-02-17 16:35:13,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:13,837][root][INFO] - Training Epoch: 1/2, step 1245/107898 completed (loss: 0.8611250519752502, acc: 0.8846153616905212)
[2025-02-17 16:35:13,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:14,136][root][INFO] - Training Epoch: 1/2, step 1246/107898 completed (loss: 0.3842495083808899, acc: 0.9090909361839294)
[2025-02-17 16:35:14,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:14,436][root][INFO] - Training Epoch: 1/2, step 1247/107898 completed (loss: 0.6182745099067688, acc: 0.8799999952316284)
[2025-02-17 16:35:14,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:14,746][root][INFO] - Training Epoch: 1/2, step 1248/107898 completed (loss: 0.26845014095306396, acc: 0.9473684430122375)
[2025-02-17 16:35:14,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:15,053][root][INFO] - Training Epoch: 1/2, step 1249/107898 completed (loss: 3.6431009769439697, acc: 0.5)
[2025-02-17 16:35:15,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:15,360][root][INFO] - Training Epoch: 1/2, step 1250/107898 completed (loss: 1.3046976327896118, acc: 0.6666666865348816)
[2025-02-17 16:35:15,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:15,686][root][INFO] - Training Epoch: 1/2, step 1251/107898 completed (loss: 1.0270782709121704, acc: 0.800000011920929)
[2025-02-17 16:35:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:16,010][root][INFO] - Training Epoch: 1/2, step 1252/107898 completed (loss: 0.31037434935569763, acc: 0.9090909361839294)
[2025-02-17 16:35:16,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:16,351][root][INFO] - Training Epoch: 1/2, step 1253/107898 completed (loss: 0.7082177400588989, acc: 0.8333333134651184)
[2025-02-17 16:35:16,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:16,674][root][INFO] - Training Epoch: 1/2, step 1254/107898 completed (loss: 0.6137060523033142, acc: 0.875)
[2025-02-17 16:35:16,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:16,991][root][INFO] - Training Epoch: 1/2, step 1255/107898 completed (loss: 1.122087001800537, acc: 0.5)
[2025-02-17 16:35:17,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:17,299][root][INFO] - Training Epoch: 1/2, step 1256/107898 completed (loss: 1.689873456954956, acc: 0.699999988079071)
[2025-02-17 16:35:17,385][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:17,605][root][INFO] - Training Epoch: 1/2, step 1257/107898 completed (loss: 1.5676630735397339, acc: 0.7142857313156128)
[2025-02-17 16:35:17,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:17,929][root][INFO] - Training Epoch: 1/2, step 1258/107898 completed (loss: 0.5158520340919495, acc: 0.8571428656578064)
[2025-02-17 16:35:18,043][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:18,279][root][INFO] - Training Epoch: 1/2, step 1259/107898 completed (loss: 2.1982200145721436, acc: 0.5)
[2025-02-17 16:35:18,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:18,628][root][INFO] - Training Epoch: 1/2, step 1260/107898 completed (loss: 0.3902120292186737, acc: 0.9166666865348816)
[2025-02-17 16:35:18,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:18,921][root][INFO] - Training Epoch: 1/2, step 1261/107898 completed (loss: 4.351475238800049, acc: 0.2857142984867096)
[2025-02-17 16:35:18,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:19,205][root][INFO] - Training Epoch: 1/2, step 1262/107898 completed (loss: 0.7293075919151306, acc: 0.5)
[2025-02-17 16:35:19,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:19,509][root][INFO] - Training Epoch: 1/2, step 1263/107898 completed (loss: 0.02497355081140995, acc: 1.0)
[2025-02-17 16:35:19,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:19,859][root][INFO] - Training Epoch: 1/2, step 1264/107898 completed (loss: 0.4731239974498749, acc: 0.9411764740943909)
[2025-02-17 16:35:19,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:20,194][root][INFO] - Training Epoch: 1/2, step 1265/107898 completed (loss: 0.1413334608078003, acc: 1.0)
[2025-02-17 16:35:20,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:20,513][root][INFO] - Training Epoch: 1/2, step 1266/107898 completed (loss: 0.7830995321273804, acc: 0.7777777910232544)
[2025-02-17 16:35:20,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:20,828][root][INFO] - Training Epoch: 1/2, step 1267/107898 completed (loss: 1.5080208778381348, acc: 0.5)
[2025-02-17 16:35:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:21,134][root][INFO] - Training Epoch: 1/2, step 1268/107898 completed (loss: 0.45071694254875183, acc: 0.9230769276618958)
[2025-02-17 16:35:21,204][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:21,410][root][INFO] - Training Epoch: 1/2, step 1269/107898 completed (loss: 3.7066590785980225, acc: 0.2857142984867096)
[2025-02-17 16:35:21,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:21,698][root][INFO] - Training Epoch: 1/2, step 1270/107898 completed (loss: 2.9916868209838867, acc: 0.3333333432674408)
[2025-02-17 16:35:21,849][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:22,072][root][INFO] - Training Epoch: 1/2, step 1271/107898 completed (loss: 1.408915400505066, acc: 0.761904776096344)
[2025-02-17 16:35:22,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:22,372][root][INFO] - Training Epoch: 1/2, step 1272/107898 completed (loss: 1.0451757907867432, acc: 0.8181818127632141)
[2025-02-17 16:35:22,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:22,680][root][INFO] - Training Epoch: 1/2, step 1273/107898 completed (loss: 0.8445238471031189, acc: 0.8461538553237915)
[2025-02-17 16:35:22,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:23,001][root][INFO] - Training Epoch: 1/2, step 1274/107898 completed (loss: 0.016334272921085358, acc: 1.0)
[2025-02-17 16:35:23,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:23,325][root][INFO] - Training Epoch: 1/2, step 1275/107898 completed (loss: 0.34455931186676025, acc: 0.9230769276618958)
[2025-02-17 16:35:23,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:23,642][root][INFO] - Training Epoch: 1/2, step 1276/107898 completed (loss: 1.7058615684509277, acc: 0.625)
[2025-02-17 16:35:23,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:23,966][root][INFO] - Training Epoch: 1/2, step 1277/107898 completed (loss: 2.1763105392456055, acc: 0.5862069129943848)
[2025-02-17 16:35:24,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:24,284][root][INFO] - Training Epoch: 1/2, step 1278/107898 completed (loss: 1.9548763036727905, acc: 0.6666666865348816)
[2025-02-17 16:35:24,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:24,592][root][INFO] - Training Epoch: 1/2, step 1279/107898 completed (loss: 1.6707758903503418, acc: 0.6666666865348816)
[2025-02-17 16:35:24,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:24,920][root][INFO] - Training Epoch: 1/2, step 1280/107898 completed (loss: 2.3888633251190186, acc: 0.523809552192688)
[2025-02-17 16:35:25,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:25,249][root][INFO] - Training Epoch: 1/2, step 1281/107898 completed (loss: 0.4010680615901947, acc: 1.0)
[2025-02-17 16:35:25,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:25,554][root][INFO] - Training Epoch: 1/2, step 1282/107898 completed (loss: 0.26524418592453003, acc: 1.0)
[2025-02-17 16:35:25,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:25,904][root][INFO] - Training Epoch: 1/2, step 1283/107898 completed (loss: 0.9134237766265869, acc: 0.7777777910232544)
[2025-02-17 16:35:25,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:26,177][root][INFO] - Training Epoch: 1/2, step 1284/107898 completed (loss: 1.1913211345672607, acc: 0.7857142686843872)
[2025-02-17 16:35:26,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:26,464][root][INFO] - Training Epoch: 1/2, step 1285/107898 completed (loss: 0.277149498462677, acc: 1.0)
[2025-02-17 16:35:26,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:26,769][root][INFO] - Training Epoch: 1/2, step 1286/107898 completed (loss: 1.0718704462051392, acc: 0.8125)
[2025-02-17 16:35:26,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:27,082][root][INFO] - Training Epoch: 1/2, step 1287/107898 completed (loss: 3.8245127201080322, acc: 0.5)
[2025-02-17 16:35:27,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:27,427][root][INFO] - Training Epoch: 1/2, step 1288/107898 completed (loss: 0.921002209186554, acc: 0.9210526347160339)
[2025-02-17 16:35:27,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:27,720][root][INFO] - Training Epoch: 1/2, step 1289/107898 completed (loss: 0.6367156505584717, acc: 0.9230769276618958)
[2025-02-17 16:35:27,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:28,017][root][INFO] - Training Epoch: 1/2, step 1290/107898 completed (loss: 0.5732191205024719, acc: 0.9444444179534912)
[2025-02-17 16:35:28,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:28,324][root][INFO] - Training Epoch: 1/2, step 1291/107898 completed (loss: 1.433621883392334, acc: 0.7222222089767456)
[2025-02-17 16:35:28,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:28,659][root][INFO] - Training Epoch: 1/2, step 1292/107898 completed (loss: 0.1881023496389389, acc: 1.0)
[2025-02-17 16:35:28,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:28,997][root][INFO] - Training Epoch: 1/2, step 1293/107898 completed (loss: 1.0099061727523804, acc: 0.8181818127632141)
[2025-02-17 16:35:29,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:29,303][root][INFO] - Training Epoch: 1/2, step 1294/107898 completed (loss: 1.9305367469787598, acc: 0.6666666865348816)
[2025-02-17 16:35:29,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:29,627][root][INFO] - Training Epoch: 1/2, step 1295/107898 completed (loss: 5.298490047454834, acc: 0.1764705926179886)
[2025-02-17 16:35:29,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:29,912][root][INFO] - Training Epoch: 1/2, step 1296/107898 completed (loss: 1.8456839323043823, acc: 0.6666666865348816)
[2025-02-17 16:35:29,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:30,171][root][INFO] - Training Epoch: 1/2, step 1297/107898 completed (loss: 4.304591178894043, acc: 0.0)
[2025-02-17 16:35:30,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:30,460][root][INFO] - Training Epoch: 1/2, step 1298/107898 completed (loss: 0.628057599067688, acc: 1.0)
[2025-02-17 16:35:30,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:30,755][root][INFO] - Training Epoch: 1/2, step 1299/107898 completed (loss: 1.3558049201965332, acc: 0.8666666746139526)
[2025-02-17 16:35:30,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:31,088][root][INFO] - Training Epoch: 1/2, step 1300/107898 completed (loss: 1.944821834564209, acc: 0.5)
[2025-02-17 16:35:31,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:31,386][root][INFO] - Training Epoch: 1/2, step 1301/107898 completed (loss: 1.2392152547836304, acc: 0.6666666865348816)
[2025-02-17 16:35:31,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:31,686][root][INFO] - Training Epoch: 1/2, step 1302/107898 completed (loss: 1.8583431243896484, acc: 0.6666666865348816)
[2025-02-17 16:35:31,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:32,010][root][INFO] - Training Epoch: 1/2, step 1303/107898 completed (loss: 0.30211272835731506, acc: 0.9411764740943909)
[2025-02-17 16:35:32,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:32,314][root][INFO] - Training Epoch: 1/2, step 1304/107898 completed (loss: 0.5225295424461365, acc: 0.875)
[2025-02-17 16:35:32,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:32,627][root][INFO] - Training Epoch: 1/2, step 1305/107898 completed (loss: 3.388514995574951, acc: 0.375)
[2025-02-17 16:35:32,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:32,917][root][INFO] - Training Epoch: 1/2, step 1306/107898 completed (loss: 0.10335901379585266, acc: 1.0)
[2025-02-17 16:35:33,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:33,221][root][INFO] - Training Epoch: 1/2, step 1307/107898 completed (loss: 0.8796657919883728, acc: 0.875)
[2025-02-17 16:35:33,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:33,523][root][INFO] - Training Epoch: 1/2, step 1308/107898 completed (loss: 2.6059911251068115, acc: 0.5)
[2025-02-17 16:35:33,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:33,859][root][INFO] - Training Epoch: 1/2, step 1309/107898 completed (loss: 1.3675838708877563, acc: 0.6666666865348816)
[2025-02-17 16:35:33,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:34,183][root][INFO] - Training Epoch: 1/2, step 1310/107898 completed (loss: 2.397681474685669, acc: 0.5)
[2025-02-17 16:35:34,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:34,490][root][INFO] - Training Epoch: 1/2, step 1311/107898 completed (loss: 0.5731015205383301, acc: 1.0)
[2025-02-17 16:35:34,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:34,775][root][INFO] - Training Epoch: 1/2, step 1312/107898 completed (loss: 1.3086236715316772, acc: 0.6000000238418579)
[2025-02-17 16:35:34,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:35,078][root][INFO] - Training Epoch: 1/2, step 1313/107898 completed (loss: 0.9533475637435913, acc: 0.8571428656578064)
[2025-02-17 16:35:35,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:35,375][root][INFO] - Training Epoch: 1/2, step 1314/107898 completed (loss: 0.040288835763931274, acc: 1.0)
[2025-02-17 16:35:35,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:35,734][root][INFO] - Training Epoch: 1/2, step 1315/107898 completed (loss: 3.1915643215179443, acc: 0.4285714328289032)
[2025-02-17 16:35:35,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:36,055][root][INFO] - Training Epoch: 1/2, step 1316/107898 completed (loss: 2.8911399841308594, acc: 0.4444444477558136)
[2025-02-17 16:35:36,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:36,393][root][INFO] - Training Epoch: 1/2, step 1317/107898 completed (loss: 5.376668453216553, acc: 0.0)
[2025-02-17 16:35:36,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:36,725][root][INFO] - Training Epoch: 1/2, step 1318/107898 completed (loss: 0.179934561252594, acc: 1.0)
[2025-02-17 16:35:36,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:37,035][root][INFO] - Training Epoch: 1/2, step 1319/107898 completed (loss: 0.13560618460178375, acc: 1.0)
[2025-02-17 16:35:37,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:37,321][root][INFO] - Training Epoch: 1/2, step 1320/107898 completed (loss: 1.1752722263336182, acc: 0.800000011920929)
[2025-02-17 16:35:37,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:37,621][root][INFO] - Training Epoch: 1/2, step 1321/107898 completed (loss: 1.0255564451217651, acc: 0.7058823704719543)
[2025-02-17 16:35:37,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:37,931][root][INFO] - Training Epoch: 1/2, step 1322/107898 completed (loss: 0.1338718980550766, acc: 1.0)
[2025-02-17 16:35:38,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:38,228][root][INFO] - Training Epoch: 1/2, step 1323/107898 completed (loss: 0.7384284734725952, acc: 0.800000011920929)
[2025-02-17 16:35:38,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:38,544][root][INFO] - Training Epoch: 1/2, step 1324/107898 completed (loss: 0.6941234469413757, acc: 0.8500000238418579)
[2025-02-17 16:35:38,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:38,842][root][INFO] - Training Epoch: 1/2, step 1325/107898 completed (loss: 5.848659515380859, acc: 0.0)
[2025-02-17 16:35:38,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:39,153][root][INFO] - Training Epoch: 1/2, step 1326/107898 completed (loss: 0.9850839376449585, acc: 0.692307710647583)
[2025-02-17 16:35:39,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:39,472][root][INFO] - Training Epoch: 1/2, step 1327/107898 completed (loss: 1.4724879264831543, acc: 0.75)
[2025-02-17 16:35:39,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:39,878][root][INFO] - Training Epoch: 1/2, step 1328/107898 completed (loss: 0.9004895091056824, acc: 0.7777777910232544)
[2025-02-17 16:35:39,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:40,205][root][INFO] - Training Epoch: 1/2, step 1329/107898 completed (loss: 1.2451351881027222, acc: 0.6315789222717285)
[2025-02-17 16:35:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:40,504][root][INFO] - Training Epoch: 1/2, step 1330/107898 completed (loss: 1.1516833305358887, acc: 0.5)
[2025-02-17 16:35:40,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:40,812][root][INFO] - Training Epoch: 1/2, step 1331/107898 completed (loss: 0.691552460193634, acc: 0.800000011920929)
[2025-02-17 16:35:40,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:41,104][root][INFO] - Training Epoch: 1/2, step 1332/107898 completed (loss: 2.4417011737823486, acc: 0.5)
[2025-02-17 16:35:41,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:41,413][root][INFO] - Training Epoch: 1/2, step 1333/107898 completed (loss: 4.521460056304932, acc: 0.1666666716337204)
[2025-02-17 16:35:41,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:41,713][root][INFO] - Training Epoch: 1/2, step 1334/107898 completed (loss: 1.0242154598236084, acc: 0.7142857313156128)
[2025-02-17 16:35:41,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:42,045][root][INFO] - Training Epoch: 1/2, step 1335/107898 completed (loss: 0.7690263390541077, acc: 0.7692307829856873)
[2025-02-17 16:35:42,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:42,390][root][INFO] - Training Epoch: 1/2, step 1336/107898 completed (loss: 0.30149513483047485, acc: 0.931034505367279)
[2025-02-17 16:35:42,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:42,670][root][INFO] - Training Epoch: 1/2, step 1337/107898 completed (loss: 1.1656550168991089, acc: 0.5)
[2025-02-17 16:35:42,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:42,966][root][INFO] - Training Epoch: 1/2, step 1338/107898 completed (loss: 3.688122272491455, acc: 0.2857142984867096)
[2025-02-17 16:35:43,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:43,275][root][INFO] - Training Epoch: 1/2, step 1339/107898 completed (loss: 2.08998966217041, acc: 0.6521739363670349)
[2025-02-17 16:35:43,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:43,589][root][INFO] - Training Epoch: 1/2, step 1340/107898 completed (loss: 1.50918710231781, acc: 0.7142857313156128)
[2025-02-17 16:35:43,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:43,918][root][INFO] - Training Epoch: 1/2, step 1341/107898 completed (loss: 2.2274720668792725, acc: 0.6315789222717285)
[2025-02-17 16:35:44,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:44,260][root][INFO] - Training Epoch: 1/2, step 1342/107898 completed (loss: 0.19830380380153656, acc: 1.0)
[2025-02-17 16:35:44,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:44,581][root][INFO] - Training Epoch: 1/2, step 1343/107898 completed (loss: 1.432403564453125, acc: 0.75)
[2025-02-17 16:35:44,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:44,888][root][INFO] - Training Epoch: 1/2, step 1344/107898 completed (loss: 1.7619398832321167, acc: 0.75)
[2025-02-17 16:35:44,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:45,208][root][INFO] - Training Epoch: 1/2, step 1345/107898 completed (loss: 0.0665178894996643, acc: 1.0)
[2025-02-17 16:35:45,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:45,557][root][INFO] - Training Epoch: 1/2, step 1346/107898 completed (loss: 2.1597862243652344, acc: 0.5454545617103577)
[2025-02-17 16:35:45,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:45,841][root][INFO] - Training Epoch: 1/2, step 1347/107898 completed (loss: 1.7118399143218994, acc: 0.5)
[2025-02-17 16:35:45,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:46,132][root][INFO] - Training Epoch: 1/2, step 1348/107898 completed (loss: 0.5332902669906616, acc: 1.0)
[2025-02-17 16:35:46,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:46,441][root][INFO] - Training Epoch: 1/2, step 1349/107898 completed (loss: 0.31940072774887085, acc: 0.9166666865348816)
[2025-02-17 16:35:46,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:46,737][root][INFO] - Training Epoch: 1/2, step 1350/107898 completed (loss: 1.7416019439697266, acc: 0.699999988079071)
[2025-02-17 16:35:46,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:47,063][root][INFO] - Training Epoch: 1/2, step 1351/107898 completed (loss: 3.2572829723358154, acc: 0.2857142984867096)
[2025-02-17 16:35:47,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:47,368][root][INFO] - Training Epoch: 1/2, step 1352/107898 completed (loss: 0.4322724938392639, acc: 0.800000011920929)
[2025-02-17 16:35:47,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:47,672][root][INFO] - Training Epoch: 1/2, step 1353/107898 completed (loss: 1.1818273067474365, acc: 0.75)
[2025-02-17 16:35:47,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:47,977][root][INFO] - Training Epoch: 1/2, step 1354/107898 completed (loss: 0.06679870933294296, acc: 1.0)
[2025-02-17 16:35:48,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:48,313][root][INFO] - Training Epoch: 1/2, step 1355/107898 completed (loss: 0.35448694229125977, acc: 0.9285714030265808)
[2025-02-17 16:35:48,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:48,588][root][INFO] - Training Epoch: 1/2, step 1356/107898 completed (loss: 1.3026056289672852, acc: 0.6470588445663452)
[2025-02-17 16:35:48,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:48,949][root][INFO] - Training Epoch: 1/2, step 1357/107898 completed (loss: 1.2800970077514648, acc: 0.6666666865348816)
[2025-02-17 16:35:49,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:49,304][root][INFO] - Training Epoch: 1/2, step 1358/107898 completed (loss: 2.653076648712158, acc: 0.7272727489471436)
[2025-02-17 16:35:49,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:49,667][root][INFO] - Training Epoch: 1/2, step 1359/107898 completed (loss: 0.954872190952301, acc: 0.7599999904632568)
[2025-02-17 16:35:49,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:49,994][root][INFO] - Training Epoch: 1/2, step 1360/107898 completed (loss: 0.15706145763397217, acc: 1.0)
[2025-02-17 16:35:50,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:50,299][root][INFO] - Training Epoch: 1/2, step 1361/107898 completed (loss: 1.770994782447815, acc: 0.6470588445663452)
[2025-02-17 16:35:50,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:50,684][root][INFO] - Training Epoch: 1/2, step 1362/107898 completed (loss: 1.0546640157699585, acc: 0.8461538553237915)
[2025-02-17 16:35:50,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:51,008][root][INFO] - Training Epoch: 1/2, step 1363/107898 completed (loss: 1.3756966590881348, acc: 0.5555555820465088)
[2025-02-17 16:35:51,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:51,365][root][INFO] - Training Epoch: 1/2, step 1364/107898 completed (loss: 1.643524169921875, acc: 0.75)
[2025-02-17 16:35:51,503][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:51,720][root][INFO] - Training Epoch: 1/2, step 1365/107898 completed (loss: 0.7660362124443054, acc: 0.8823529481887817)
[2025-02-17 16:35:51,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:52,100][root][INFO] - Training Epoch: 1/2, step 1366/107898 completed (loss: 0.023773731663823128, acc: 1.0)
[2025-02-17 16:35:52,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:52,462][root][INFO] - Training Epoch: 1/2, step 1367/107898 completed (loss: 1.8138856887817383, acc: 0.5)
[2025-02-17 16:35:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:52,786][root][INFO] - Training Epoch: 1/2, step 1368/107898 completed (loss: 4.050384044647217, acc: 0.1818181872367859)
[2025-02-17 16:35:52,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:53,092][root][INFO] - Training Epoch: 1/2, step 1369/107898 completed (loss: 0.06763631850481033, acc: 1.0)
[2025-02-17 16:35:53,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:53,368][root][INFO] - Training Epoch: 1/2, step 1370/107898 completed (loss: 5.462032318115234, acc: 0.2083333283662796)
[2025-02-17 16:35:53,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:53,661][root][INFO] - Training Epoch: 1/2, step 1371/107898 completed (loss: 0.7775210738182068, acc: 0.6666666865348816)
[2025-02-17 16:35:53,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:53,951][root][INFO] - Training Epoch: 1/2, step 1372/107898 completed (loss: 0.6183669567108154, acc: 0.5)
[2025-02-17 16:35:54,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:54,253][root][INFO] - Training Epoch: 1/2, step 1373/107898 completed (loss: 1.882921576499939, acc: 0.6666666865348816)
[2025-02-17 16:35:54,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:54,609][root][INFO] - Training Epoch: 1/2, step 1374/107898 completed (loss: 2.841146945953369, acc: 0.5714285969734192)
[2025-02-17 16:35:54,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:54,979][root][INFO] - Training Epoch: 1/2, step 1375/107898 completed (loss: 3.065599203109741, acc: 0.4444444477558136)
[2025-02-17 16:35:55,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:55,314][root][INFO] - Training Epoch: 1/2, step 1376/107898 completed (loss: 2.08089017868042, acc: 0.5)
[2025-02-17 16:35:55,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:55,639][root][INFO] - Training Epoch: 1/2, step 1377/107898 completed (loss: 0.2599306106567383, acc: 1.0)
[2025-02-17 16:35:55,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:55,989][root][INFO] - Training Epoch: 1/2, step 1378/107898 completed (loss: 1.750485897064209, acc: 0.692307710647583)
[2025-02-17 16:35:56,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:56,339][root][INFO] - Training Epoch: 1/2, step 1379/107898 completed (loss: 1.705827236175537, acc: 0.875)
[2025-02-17 16:35:56,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:56,665][root][INFO] - Training Epoch: 1/2, step 1380/107898 completed (loss: 0.7928133606910706, acc: 1.0)
[2025-02-17 16:35:56,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:57,010][root][INFO] - Training Epoch: 1/2, step 1381/107898 completed (loss: 0.1998981535434723, acc: 1.0)
[2025-02-17 16:35:57,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:57,322][root][INFO] - Training Epoch: 1/2, step 1382/107898 completed (loss: 1.4562989473342896, acc: 0.8181818127632141)
[2025-02-17 16:35:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:57,615][root][INFO] - Training Epoch: 1/2, step 1383/107898 completed (loss: 4.384650707244873, acc: 0.3333333432674408)
[2025-02-17 16:35:57,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:57,946][root][INFO] - Training Epoch: 1/2, step 1384/107898 completed (loss: 3.3979008197784424, acc: 0.4000000059604645)
[2025-02-17 16:35:58,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:58,251][root][INFO] - Training Epoch: 1/2, step 1385/107898 completed (loss: 0.4239247739315033, acc: 0.5)
[2025-02-17 16:35:58,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:58,575][root][INFO] - Training Epoch: 1/2, step 1386/107898 completed (loss: 2.596017837524414, acc: 0.800000011920929)
[2025-02-17 16:35:58,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:58,930][root][INFO] - Training Epoch: 1/2, step 1387/107898 completed (loss: 1.0841963291168213, acc: 0.6666666865348816)
[2025-02-17 16:35:59,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:59,292][root][INFO] - Training Epoch: 1/2, step 1388/107898 completed (loss: 1.1997108459472656, acc: 0.7837837934494019)
[2025-02-17 16:35:59,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:59,639][root][INFO] - Training Epoch: 1/2, step 1389/107898 completed (loss: 0.3818608522415161, acc: 1.0)
[2025-02-17 16:35:59,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:35:59,960][root][INFO] - Training Epoch: 1/2, step 1390/107898 completed (loss: 0.010392419062554836, acc: 1.0)
[2025-02-17 16:36:00,061][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:00,291][root][INFO] - Training Epoch: 1/2, step 1391/107898 completed (loss: 0.3627392053604126, acc: 1.0)
[2025-02-17 16:36:00,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:00,621][root][INFO] - Training Epoch: 1/2, step 1392/107898 completed (loss: 0.47781091928482056, acc: 0.9230769276618958)
[2025-02-17 16:36:00,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:00,931][root][INFO] - Training Epoch: 1/2, step 1393/107898 completed (loss: 0.8696947693824768, acc: 0.7857142686843872)
[2025-02-17 16:36:01,034][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:01,273][root][INFO] - Training Epoch: 1/2, step 1394/107898 completed (loss: 0.0040660155937075615, acc: 1.0)
[2025-02-17 16:36:01,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:01,608][root][INFO] - Training Epoch: 1/2, step 1395/107898 completed (loss: 0.6302610039710999, acc: 0.8571428656578064)
[2025-02-17 16:36:01,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:01,933][root][INFO] - Training Epoch: 1/2, step 1396/107898 completed (loss: 0.85588538646698, acc: 0.8333333134651184)
[2025-02-17 16:36:02,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:02,244][root][INFO] - Training Epoch: 1/2, step 1397/107898 completed (loss: 1.889345407485962, acc: 0.625)
[2025-02-17 16:36:02,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:02,587][root][INFO] - Training Epoch: 1/2, step 1398/107898 completed (loss: 0.005556996446102858, acc: 1.0)
[2025-02-17 16:36:02,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:02,942][root][INFO] - Training Epoch: 1/2, step 1399/107898 completed (loss: 3.1660172939300537, acc: 0.1875)
[2025-02-17 16:36:03,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:03,267][root][INFO] - Training Epoch: 1/2, step 1400/107898 completed (loss: 1.6064810752868652, acc: 0.75)
[2025-02-17 16:36:03,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:03,582][root][INFO] - Training Epoch: 1/2, step 1401/107898 completed (loss: 0.8395978212356567, acc: 0.5)
[2025-02-17 16:36:03,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:03,866][root][INFO] - Training Epoch: 1/2, step 1402/107898 completed (loss: 1.2962337732315063, acc: 0.8333333134651184)
[2025-02-17 16:36:03,942][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:04,161][root][INFO] - Training Epoch: 1/2, step 1403/107898 completed (loss: 2.719212532043457, acc: 0.3333333432674408)
[2025-02-17 16:36:04,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:04,461][root][INFO] - Training Epoch: 1/2, step 1404/107898 completed (loss: 4.338212490081787, acc: 0.31578946113586426)
[2025-02-17 16:36:04,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:04,790][root][INFO] - Training Epoch: 1/2, step 1405/107898 completed (loss: 0.9469964504241943, acc: 0.8518518805503845)
[2025-02-17 16:36:04,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:05,083][root][INFO] - Training Epoch: 1/2, step 1406/107898 completed (loss: 1.3381081819534302, acc: 0.6000000238418579)
[2025-02-17 16:36:05,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:05,377][root][INFO] - Training Epoch: 1/2, step 1407/107898 completed (loss: 0.584885835647583, acc: 0.875)
[2025-02-17 16:36:05,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:05,718][root][INFO] - Training Epoch: 1/2, step 1408/107898 completed (loss: 1.8975372314453125, acc: 0.5652173757553101)
[2025-02-17 16:36:05,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:06,049][root][INFO] - Training Epoch: 1/2, step 1409/107898 completed (loss: 0.6418703198432922, acc: 0.8947368264198303)
[2025-02-17 16:36:06,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:06,347][root][INFO] - Training Epoch: 1/2, step 1410/107898 completed (loss: 0.019987745210528374, acc: 1.0)
[2025-02-17 16:36:06,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:06,719][root][INFO] - Training Epoch: 1/2, step 1411/107898 completed (loss: 1.2408982515335083, acc: 0.6666666865348816)
[2025-02-17 16:36:06,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:07,014][root][INFO] - Training Epoch: 1/2, step 1412/107898 completed (loss: 0.3895900249481201, acc: 0.8947368264198303)
[2025-02-17 16:36:07,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:07,292][root][INFO] - Training Epoch: 1/2, step 1413/107898 completed (loss: 0.028369326144456863, acc: 1.0)
[2025-02-17 16:36:07,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:07,563][root][INFO] - Training Epoch: 1/2, step 1414/107898 completed (loss: 2.195000410079956, acc: 0.3333333432674408)
[2025-02-17 16:36:07,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:07,859][root][INFO] - Training Epoch: 1/2, step 1415/107898 completed (loss: 0.9650110006332397, acc: 0.800000011920929)
[2025-02-17 16:36:07,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:08,219][root][INFO] - Training Epoch: 1/2, step 1416/107898 completed (loss: 4.990250587463379, acc: 0.23529411852359772)
[2025-02-17 16:36:08,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:08,543][root][INFO] - Training Epoch: 1/2, step 1417/107898 completed (loss: 2.145519971847534, acc: 0.5714285969734192)
[2025-02-17 16:36:08,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:08,885][root][INFO] - Training Epoch: 1/2, step 1418/107898 completed (loss: 1.9905099868774414, acc: 0.699999988079071)
[2025-02-17 16:36:09,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:09,231][root][INFO] - Training Epoch: 1/2, step 1419/107898 completed (loss: 1.3836308717727661, acc: 0.6521739363670349)
[2025-02-17 16:36:09,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:09,574][root][INFO] - Training Epoch: 1/2, step 1420/107898 completed (loss: 4.916810989379883, acc: 0.3333333432674408)
[2025-02-17 16:36:09,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:09,912][root][INFO] - Training Epoch: 1/2, step 1421/107898 completed (loss: 1.7010256052017212, acc: 0.7857142686843872)
[2025-02-17 16:36:10,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:10,223][root][INFO] - Training Epoch: 1/2, step 1422/107898 completed (loss: 0.5077052712440491, acc: 0.5)
[2025-02-17 16:36:10,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:10,518][root][INFO] - Training Epoch: 1/2, step 1423/107898 completed (loss: 0.3629128634929657, acc: 0.9166666865348816)
[2025-02-17 16:36:10,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:10,873][root][INFO] - Training Epoch: 1/2, step 1424/107898 completed (loss: 1.7273133993148804, acc: 0.3333333432674408)
[2025-02-17 16:36:10,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:11,222][root][INFO] - Training Epoch: 1/2, step 1425/107898 completed (loss: 1.9931015968322754, acc: 0.5833333134651184)
[2025-02-17 16:36:11,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:11,596][root][INFO] - Training Epoch: 1/2, step 1426/107898 completed (loss: 2.9640729427337646, acc: 0.6666666865348816)
[2025-02-17 16:36:11,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:11,932][root][INFO] - Training Epoch: 1/2, step 1427/107898 completed (loss: 1.267166256904602, acc: 0.800000011920929)
[2025-02-17 16:36:12,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:12,252][root][INFO] - Training Epoch: 1/2, step 1428/107898 completed (loss: 0.22208409011363983, acc: 1.0)
[2025-02-17 16:36:12,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:12,588][root][INFO] - Training Epoch: 1/2, step 1429/107898 completed (loss: 0.8234899640083313, acc: 1.0)
[2025-02-17 16:36:12,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:12,914][root][INFO] - Training Epoch: 1/2, step 1430/107898 completed (loss: 0.06781948357820511, acc: 1.0)
[2025-02-17 16:36:13,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:13,257][root][INFO] - Training Epoch: 1/2, step 1431/107898 completed (loss: 0.4836074113845825, acc: 1.0)
[2025-02-17 16:36:13,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:13,586][root][INFO] - Training Epoch: 1/2, step 1432/107898 completed (loss: 3.2341361045837402, acc: 0.3461538553237915)
[2025-02-17 16:36:13,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:13,903][root][INFO] - Training Epoch: 1/2, step 1433/107898 completed (loss: 1.3009551763534546, acc: 0.7894737124443054)
[2025-02-17 16:36:14,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:14,250][root][INFO] - Training Epoch: 1/2, step 1434/107898 completed (loss: 0.969543993473053, acc: 0.7142857313156128)
[2025-02-17 16:36:14,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:14,561][root][INFO] - Training Epoch: 1/2, step 1435/107898 completed (loss: 0.0913587138056755, acc: 1.0)
[2025-02-17 16:36:14,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:14,928][root][INFO] - Training Epoch: 1/2, step 1436/107898 completed (loss: 0.9785794019699097, acc: 0.8888888955116272)
[2025-02-17 16:36:15,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:15,267][root][INFO] - Training Epoch: 1/2, step 1437/107898 completed (loss: 0.6197184920310974, acc: 0.800000011920929)
[2025-02-17 16:36:15,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:15,583][root][INFO] - Training Epoch: 1/2, step 1438/107898 completed (loss: 2.694751739501953, acc: 0.25)
[2025-02-17 16:36:15,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:15,900][root][INFO] - Training Epoch: 1/2, step 1439/107898 completed (loss: 0.23407702147960663, acc: 0.8947368264198303)
[2025-02-17 16:36:15,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:16,203][root][INFO] - Training Epoch: 1/2, step 1440/107898 completed (loss: 1.0679301023483276, acc: 0.75)
[2025-02-17 16:36:16,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:16,549][root][INFO] - Training Epoch: 1/2, step 1441/107898 completed (loss: 0.09637331962585449, acc: 1.0)
[2025-02-17 16:36:16,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:16,857][root][INFO] - Training Epoch: 1/2, step 1442/107898 completed (loss: 0.5109179615974426, acc: 0.9411764740943909)
[2025-02-17 16:36:16,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:17,151][root][INFO] - Training Epoch: 1/2, step 1443/107898 completed (loss: 0.08879780024290085, acc: 1.0)
[2025-02-17 16:36:17,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:17,438][root][INFO] - Training Epoch: 1/2, step 1444/107898 completed (loss: 0.24366435408592224, acc: 0.95652174949646)
[2025-02-17 16:36:17,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:17,788][root][INFO] - Training Epoch: 1/2, step 1445/107898 completed (loss: 1.8584554195404053, acc: 0.7096773982048035)
[2025-02-17 16:36:17,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:18,139][root][INFO] - Training Epoch: 1/2, step 1446/107898 completed (loss: 0.6885919570922852, acc: 0.8787878751754761)
[2025-02-17 16:36:18,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:18,462][root][INFO] - Training Epoch: 1/2, step 1447/107898 completed (loss: 0.7448418140411377, acc: 0.6666666865348816)
[2025-02-17 16:36:18,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:18,765][root][INFO] - Training Epoch: 1/2, step 1448/107898 completed (loss: 2.859041929244995, acc: 0.5)
[2025-02-17 16:36:18,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:19,126][root][INFO] - Training Epoch: 1/2, step 1449/107898 completed (loss: 0.29756125807762146, acc: 0.6666666865348816)
[2025-02-17 16:36:19,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:19,424][root][INFO] - Training Epoch: 1/2, step 1450/107898 completed (loss: 1.270867109298706, acc: 0.6666666865348816)
[2025-02-17 16:36:19,492][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:19,704][root][INFO] - Training Epoch: 1/2, step 1451/107898 completed (loss: 1.134522795677185, acc: 0.800000011920929)
[2025-02-17 16:36:19,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:20,023][root][INFO] - Training Epoch: 1/2, step 1452/107898 completed (loss: 0.4602260887622833, acc: 1.0)
[2025-02-17 16:36:20,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:20,376][root][INFO] - Training Epoch: 1/2, step 1453/107898 completed (loss: 1.8859097957611084, acc: 0.4000000059604645)
[2025-02-17 16:36:20,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:20,710][root][INFO] - Training Epoch: 1/2, step 1454/107898 completed (loss: 0.4403708875179291, acc: 0.800000011920929)
[2025-02-17 16:36:20,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:21,041][root][INFO] - Training Epoch: 1/2, step 1455/107898 completed (loss: 1.7579545974731445, acc: 0.6111111044883728)
[2025-02-17 16:36:21,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:21,370][root][INFO] - Training Epoch: 1/2, step 1456/107898 completed (loss: 3.385272264480591, acc: 0.4117647111415863)
[2025-02-17 16:36:21,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:21,732][root][INFO] - Training Epoch: 1/2, step 1457/107898 completed (loss: 0.6322434544563293, acc: 0.8399999737739563)
[2025-02-17 16:36:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:22,039][root][INFO] - Training Epoch: 1/2, step 1458/107898 completed (loss: 1.8828870058059692, acc: 0.7333333492279053)
[2025-02-17 16:36:22,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:22,348][root][INFO] - Training Epoch: 1/2, step 1459/107898 completed (loss: 0.2994833290576935, acc: 0.9583333134651184)
[2025-02-17 16:36:22,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:22,651][root][INFO] - Training Epoch: 1/2, step 1460/107898 completed (loss: 2.898794174194336, acc: 0.5263158082962036)
[2025-02-17 16:36:22,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:22,960][root][INFO] - Training Epoch: 1/2, step 1461/107898 completed (loss: 0.7068814039230347, acc: 0.8571428656578064)
[2025-02-17 16:36:23,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:23,300][root][INFO] - Training Epoch: 1/2, step 1462/107898 completed (loss: 1.1012043952941895, acc: 0.6000000238418579)
[2025-02-17 16:36:23,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:23,613][root][INFO] - Training Epoch: 1/2, step 1463/107898 completed (loss: 1.2191047668457031, acc: 0.7142857313156128)
[2025-02-17 16:36:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:23,907][root][INFO] - Training Epoch: 1/2, step 1464/107898 completed (loss: 1.2000272274017334, acc: 0.5)
[2025-02-17 16:36:24,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:24,257][root][INFO] - Training Epoch: 1/2, step 1465/107898 completed (loss: 1.4227241277694702, acc: 0.7142857313156128)
[2025-02-17 16:36:24,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:24,573][root][INFO] - Training Epoch: 1/2, step 1466/107898 completed (loss: 4.781765937805176, acc: 0.5)
[2025-02-17 16:36:24,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:24,841][root][INFO] - Training Epoch: 1/2, step 1467/107898 completed (loss: 1.8627722263336182, acc: 0.5714285969734192)
[2025-02-17 16:36:24,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:25,210][root][INFO] - Training Epoch: 1/2, step 1468/107898 completed (loss: 2.7841296195983887, acc: 0.3571428656578064)
[2025-02-17 16:36:25,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:25,539][root][INFO] - Training Epoch: 1/2, step 1469/107898 completed (loss: 0.10589933395385742, acc: 1.0)
[2025-02-17 16:36:25,634][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:25,856][root][INFO] - Training Epoch: 1/2, step 1470/107898 completed (loss: 0.9454495906829834, acc: 0.8888888955116272)
[2025-02-17 16:36:25,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:26,161][root][INFO] - Training Epoch: 1/2, step 1471/107898 completed (loss: 0.6802686452865601, acc: 0.8999999761581421)
[2025-02-17 16:36:26,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:26,509][root][INFO] - Training Epoch: 1/2, step 1472/107898 completed (loss: 0.8109462857246399, acc: 0.8947368264198303)
[2025-02-17 16:36:26,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:26,891][root][INFO] - Training Epoch: 1/2, step 1473/107898 completed (loss: 0.9711159467697144, acc: 0.6666666865348816)
[2025-02-17 16:36:26,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:27,194][root][INFO] - Training Epoch: 1/2, step 1474/107898 completed (loss: 3.8389480113983154, acc: 0.375)
[2025-02-17 16:36:27,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:27,503][root][INFO] - Training Epoch: 1/2, step 1475/107898 completed (loss: 0.5509796142578125, acc: 0.8571428656578064)
[2025-02-17 16:36:27,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:27,788][root][INFO] - Training Epoch: 1/2, step 1476/107898 completed (loss: 1.7216315269470215, acc: 0.7272727489471436)
[2025-02-17 16:36:27,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:28,074][root][INFO] - Training Epoch: 1/2, step 1477/107898 completed (loss: 0.1416545808315277, acc: 1.0)
[2025-02-17 16:36:28,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:28,412][root][INFO] - Training Epoch: 1/2, step 1478/107898 completed (loss: 0.5013008117675781, acc: 1.0)
[2025-02-17 16:36:28,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:28,770][root][INFO] - Training Epoch: 1/2, step 1479/107898 completed (loss: 1.0682893991470337, acc: 0.800000011920929)
[2025-02-17 16:36:28,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:29,115][root][INFO] - Training Epoch: 1/2, step 1480/107898 completed (loss: 2.0905187129974365, acc: 0.5)
[2025-02-17 16:36:29,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:29,447][root][INFO] - Training Epoch: 1/2, step 1481/107898 completed (loss: 2.453502893447876, acc: 0.6666666865348816)
[2025-02-17 16:36:29,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:29,761][root][INFO] - Training Epoch: 1/2, step 1482/107898 completed (loss: 0.781627357006073, acc: 0.90625)
[2025-02-17 16:36:29,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:30,088][root][INFO] - Training Epoch: 1/2, step 1483/107898 completed (loss: 0.6079515218734741, acc: 0.8500000238418579)
[2025-02-17 16:36:30,171][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:30,396][root][INFO] - Training Epoch: 1/2, step 1484/107898 completed (loss: 5.323323726654053, acc: 0.25)
[2025-02-17 16:36:30,466][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:30,689][root][INFO] - Training Epoch: 1/2, step 1485/107898 completed (loss: 2.29628324508667, acc: 0.6000000238418579)
[2025-02-17 16:36:30,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:31,043][root][INFO] - Training Epoch: 1/2, step 1486/107898 completed (loss: 0.8134815096855164, acc: 0.8333333134651184)
[2025-02-17 16:36:31,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:31,357][root][INFO] - Training Epoch: 1/2, step 1487/107898 completed (loss: 2.6828577518463135, acc: 0.2857142984867096)
[2025-02-17 16:36:31,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:31,617][root][INFO] - Training Epoch: 1/2, step 1488/107898 completed (loss: 0.028879059478640556, acc: 1.0)
[2025-02-17 16:36:31,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:31,965][root][INFO] - Training Epoch: 1/2, step 1489/107898 completed (loss: 0.7347217798233032, acc: 0.8620689511299133)
[2025-02-17 16:36:32,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:32,315][root][INFO] - Training Epoch: 1/2, step 1490/107898 completed (loss: 0.5995564460754395, acc: 0.75)
[2025-02-17 16:36:32,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:32,638][root][INFO] - Training Epoch: 1/2, step 1491/107898 completed (loss: 1.7293189764022827, acc: 0.6428571343421936)
[2025-02-17 16:36:32,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:32,936][root][INFO] - Training Epoch: 1/2, step 1492/107898 completed (loss: 1.577025294303894, acc: 0.6363636255264282)
[2025-02-17 16:36:33,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:33,235][root][INFO] - Training Epoch: 1/2, step 1493/107898 completed (loss: 1.9059644937515259, acc: 0.7037037014961243)
[2025-02-17 16:36:33,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:33,542][root][INFO] - Training Epoch: 1/2, step 1494/107898 completed (loss: 0.8291974067687988, acc: 0.8518518805503845)
[2025-02-17 16:36:33,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:33,876][root][INFO] - Training Epoch: 1/2, step 1495/107898 completed (loss: 0.29472115635871887, acc: 1.0)
[2025-02-17 16:36:33,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:34,223][root][INFO] - Training Epoch: 1/2, step 1496/107898 completed (loss: 1.097601056098938, acc: 0.7142857313156128)
[2025-02-17 16:36:34,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:34,538][root][INFO] - Training Epoch: 1/2, step 1497/107898 completed (loss: 1.1616575717926025, acc: 0.699999988079071)
[2025-02-17 16:36:34,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:34,873][root][INFO] - Training Epoch: 1/2, step 1498/107898 completed (loss: 4.578306198120117, acc: 0.27272728085517883)
[2025-02-17 16:36:34,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:35,209][root][INFO] - Training Epoch: 1/2, step 1499/107898 completed (loss: 1.1102124452590942, acc: 0.8421052694320679)
[2025-02-17 16:36:35,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:35,495][root][INFO] - Training Epoch: 1/2, step 1500/107898 completed (loss: 1.3003979921340942, acc: 0.8125)
[2025-02-17 16:36:35,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:35,778][root][INFO] - Training Epoch: 1/2, step 1501/107898 completed (loss: 0.01558024249970913, acc: 1.0)
[2025-02-17 16:36:35,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:36,061][root][INFO] - Training Epoch: 1/2, step 1502/107898 completed (loss: 1.9512616395950317, acc: 0.6666666865348816)
[2025-02-17 16:36:36,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:36,383][root][INFO] - Training Epoch: 1/2, step 1503/107898 completed (loss: 3.188394546508789, acc: 0.0)
[2025-02-17 16:36:36,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:36,712][root][INFO] - Training Epoch: 1/2, step 1504/107898 completed (loss: 0.8450170755386353, acc: 0.9090909361839294)
[2025-02-17 16:36:36,809][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:37,031][root][INFO] - Training Epoch: 1/2, step 1505/107898 completed (loss: 2.7313015460968018, acc: 0.0)
[2025-02-17 16:36:37,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:37,324][root][INFO] - Training Epoch: 1/2, step 1506/107898 completed (loss: 0.44333598017692566, acc: 0.800000011920929)
[2025-02-17 16:36:37,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:37,617][root][INFO] - Training Epoch: 1/2, step 1507/107898 completed (loss: 0.4465909004211426, acc: 0.8333333134651184)
[2025-02-17 16:36:37,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:37,923][root][INFO] - Training Epoch: 1/2, step 1508/107898 completed (loss: 0.45603179931640625, acc: 0.8333333134651184)
[2025-02-17 16:36:37,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:38,200][root][INFO] - Training Epoch: 1/2, step 1509/107898 completed (loss: 0.4644930362701416, acc: 0.8571428656578064)
[2025-02-17 16:36:38,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:38,502][root][INFO] - Training Epoch: 1/2, step 1510/107898 completed (loss: 1.4834799766540527, acc: 0.6666666865348816)
[2025-02-17 16:36:38,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:38,831][root][INFO] - Training Epoch: 1/2, step 1511/107898 completed (loss: 0.023457642644643784, acc: 1.0)
[2025-02-17 16:36:38,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:39,157][root][INFO] - Training Epoch: 1/2, step 1512/107898 completed (loss: 1.8441574573516846, acc: 0.6800000071525574)
[2025-02-17 16:36:39,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:39,447][root][INFO] - Training Epoch: 1/2, step 1513/107898 completed (loss: 2.5518641471862793, acc: 0.5)
[2025-02-17 16:36:39,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:39,763][root][INFO] - Training Epoch: 1/2, step 1514/107898 completed (loss: 0.6191235184669495, acc: 0.9166666865348816)
[2025-02-17 16:36:39,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:40,104][root][INFO] - Training Epoch: 1/2, step 1515/107898 completed (loss: 0.5257929563522339, acc: 0.800000011920929)
[2025-02-17 16:36:40,215][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:40,452][root][INFO] - Training Epoch: 1/2, step 1516/107898 completed (loss: 2.677795171737671, acc: 0.6666666865348816)
[2025-02-17 16:36:40,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:40,809][root][INFO] - Training Epoch: 1/2, step 1517/107898 completed (loss: 1.2077884674072266, acc: 0.5)
[2025-02-17 16:36:40,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:41,134][root][INFO] - Training Epoch: 1/2, step 1518/107898 completed (loss: 1.6777331829071045, acc: 0.5)
[2025-02-17 16:36:41,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:41,445][root][INFO] - Training Epoch: 1/2, step 1519/107898 completed (loss: 1.0071239471435547, acc: 0.7142857313156128)
[2025-02-17 16:36:41,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:41,792][root][INFO] - Training Epoch: 1/2, step 1520/107898 completed (loss: 1.3858081102371216, acc: 0.800000011920929)
[2025-02-17 16:36:41,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:42,104][root][INFO] - Training Epoch: 1/2, step 1521/107898 completed (loss: 1.4552645683288574, acc: 0.5)
[2025-02-17 16:36:42,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:42,419][root][INFO] - Training Epoch: 1/2, step 1522/107898 completed (loss: 0.037889331579208374, acc: 1.0)
[2025-02-17 16:36:42,525][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:42,740][root][INFO] - Training Epoch: 1/2, step 1523/107898 completed (loss: 0.7407295107841492, acc: 0.8636363744735718)
[2025-02-17 16:36:42,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:43,045][root][INFO] - Training Epoch: 1/2, step 1524/107898 completed (loss: 0.3399626314640045, acc: 1.0)
[2025-02-17 16:36:43,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:43,348][root][INFO] - Training Epoch: 1/2, step 1525/107898 completed (loss: 0.21232493221759796, acc: 0.9411764740943909)
[2025-02-17 16:36:43,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:43,655][root][INFO] - Training Epoch: 1/2, step 1526/107898 completed (loss: 0.6682007312774658, acc: 0.5)
[2025-02-17 16:36:43,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:43,992][root][INFO] - Training Epoch: 1/2, step 1527/107898 completed (loss: 0.840930700302124, acc: 0.8333333134651184)
[2025-02-17 16:36:44,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:44,297][root][INFO] - Training Epoch: 1/2, step 1528/107898 completed (loss: 0.2902439832687378, acc: 0.9411764740943909)
[2025-02-17 16:36:44,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:44,610][root][INFO] - Training Epoch: 1/2, step 1529/107898 completed (loss: 0.10317927598953247, acc: 1.0)
[2025-02-17 16:36:44,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:44,923][root][INFO] - Training Epoch: 1/2, step 1530/107898 completed (loss: 0.023075440898537636, acc: 1.0)
[2025-02-17 16:36:45,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:45,227][root][INFO] - Training Epoch: 1/2, step 1531/107898 completed (loss: 2.2766149044036865, acc: 0.5)
[2025-02-17 16:36:45,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:45,541][root][INFO] - Training Epoch: 1/2, step 1532/107898 completed (loss: 2.0556418895721436, acc: 0.6363636255264282)
[2025-02-17 16:36:45,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:45,828][root][INFO] - Training Epoch: 1/2, step 1533/107898 completed (loss: 0.01168083120137453, acc: 1.0)
[2025-02-17 16:36:45,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:46,121][root][INFO] - Training Epoch: 1/2, step 1534/107898 completed (loss: 0.8179357051849365, acc: 0.75)
[2025-02-17 16:36:46,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:46,459][root][INFO] - Training Epoch: 1/2, step 1535/107898 completed (loss: 3.446267604827881, acc: 0.38461539149284363)
[2025-02-17 16:36:46,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:46,766][root][INFO] - Training Epoch: 1/2, step 1536/107898 completed (loss: 3.5408504009246826, acc: 0.5555555820465088)
[2025-02-17 16:36:46,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:47,060][root][INFO] - Training Epoch: 1/2, step 1537/107898 completed (loss: 0.052692268043756485, acc: 1.0)
[2025-02-17 16:36:47,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:47,406][root][INFO] - Training Epoch: 1/2, step 1538/107898 completed (loss: 1.1042835712432861, acc: 0.75)
[2025-02-17 16:36:47,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:47,695][root][INFO] - Training Epoch: 1/2, step 1539/107898 completed (loss: 0.23099327087402344, acc: 1.0)
[2025-02-17 16:36:47,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:48,028][root][INFO] - Training Epoch: 1/2, step 1540/107898 completed (loss: 1.2121782302856445, acc: 0.695652186870575)
[2025-02-17 16:36:48,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:48,327][root][INFO] - Training Epoch: 1/2, step 1541/107898 completed (loss: 2.651927947998047, acc: 0.5714285969734192)
[2025-02-17 16:36:48,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:48,623][root][INFO] - Training Epoch: 1/2, step 1542/107898 completed (loss: 0.6297279596328735, acc: 0.7777777910232544)
[2025-02-17 16:36:48,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:48,921][root][INFO] - Training Epoch: 1/2, step 1543/107898 completed (loss: 0.30037420988082886, acc: 0.9090909361839294)
[2025-02-17 16:36:49,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:49,285][root][INFO] - Training Epoch: 1/2, step 1544/107898 completed (loss: 0.04818260669708252, acc: 1.0)
[2025-02-17 16:36:49,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:49,613][root][INFO] - Training Epoch: 1/2, step 1545/107898 completed (loss: 0.7929167747497559, acc: 0.9166666865348816)
[2025-02-17 16:36:49,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:49,932][root][INFO] - Training Epoch: 1/2, step 1546/107898 completed (loss: 0.086514912545681, acc: 1.0)
[2025-02-17 16:36:50,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:50,297][root][INFO] - Training Epoch: 1/2, step 1547/107898 completed (loss: 0.34879449009895325, acc: 0.9285714030265808)
[2025-02-17 16:36:50,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:50,619][root][INFO] - Training Epoch: 1/2, step 1548/107898 completed (loss: 1.4597216844558716, acc: 0.5)
[2025-02-17 16:36:50,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:50,952][root][INFO] - Training Epoch: 1/2, step 1549/107898 completed (loss: 1.2279492616653442, acc: 0.7586206793785095)
[2025-02-17 16:36:51,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:51,300][root][INFO] - Training Epoch: 1/2, step 1550/107898 completed (loss: 0.7360554337501526, acc: 0.8333333134651184)
[2025-02-17 16:36:51,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:51,635][root][INFO] - Training Epoch: 1/2, step 1551/107898 completed (loss: 0.4152580201625824, acc: 0.8333333134651184)
[2025-02-17 16:36:51,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:51,970][root][INFO] - Training Epoch: 1/2, step 1552/107898 completed (loss: 0.17046456038951874, acc: 0.970588207244873)
[2025-02-17 16:36:52,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:52,309][root][INFO] - Training Epoch: 1/2, step 1553/107898 completed (loss: 0.20158135890960693, acc: 0.9411764740943909)
[2025-02-17 16:36:52,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:52,611][root][INFO] - Training Epoch: 1/2, step 1554/107898 completed (loss: 2.0352301597595215, acc: 0.3333333432674408)
[2025-02-17 16:36:52,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:52,943][root][INFO] - Training Epoch: 1/2, step 1555/107898 completed (loss: 0.012668115086853504, acc: 1.0)
[2025-02-17 16:36:53,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:53,258][root][INFO] - Training Epoch: 1/2, step 1556/107898 completed (loss: 2.630058526992798, acc: 0.6666666865348816)
[2025-02-17 16:36:53,383][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:53,618][root][INFO] - Training Epoch: 1/2, step 1557/107898 completed (loss: 2.707770824432373, acc: 0.5454545617103577)
[2025-02-17 16:36:53,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:53,962][root][INFO] - Training Epoch: 1/2, step 1558/107898 completed (loss: 3.4695634841918945, acc: 0.25)
[2025-02-17 16:36:54,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:54,257][root][INFO] - Training Epoch: 1/2, step 1559/107898 completed (loss: 0.6158658862113953, acc: 0.8999999761581421)
[2025-02-17 16:36:54,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:54,554][root][INFO] - Training Epoch: 1/2, step 1560/107898 completed (loss: 0.18635614216327667, acc: 1.0)
[2025-02-17 16:36:54,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:54,850][root][INFO] - Training Epoch: 1/2, step 1561/107898 completed (loss: 3.565614938735962, acc: 0.3636363744735718)
[2025-02-17 16:36:54,942][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:55,168][root][INFO] - Training Epoch: 1/2, step 1562/107898 completed (loss: 0.2238398641347885, acc: 0.9333333373069763)
[2025-02-17 16:36:55,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:55,491][root][INFO] - Training Epoch: 1/2, step 1563/107898 completed (loss: 4.686450958251953, acc: 0.3333333432674408)
[2025-02-17 16:36:55,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:55,799][root][INFO] - Training Epoch: 1/2, step 1564/107898 completed (loss: 0.6125493049621582, acc: 0.8571428656578064)
[2025-02-17 16:36:55,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:56,099][root][INFO] - Training Epoch: 1/2, step 1565/107898 completed (loss: 0.08506190031766891, acc: 1.0)
[2025-02-17 16:36:56,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:56,400][root][INFO] - Training Epoch: 1/2, step 1566/107898 completed (loss: 0.38424912095069885, acc: 1.0)
[2025-02-17 16:36:56,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:56,704][root][INFO] - Training Epoch: 1/2, step 1567/107898 completed (loss: 0.10365398973226547, acc: 1.0)
[2025-02-17 16:36:56,772][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:56,994][root][INFO] - Training Epoch: 1/2, step 1568/107898 completed (loss: 0.6105879545211792, acc: 0.75)
[2025-02-17 16:36:57,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:57,325][root][INFO] - Training Epoch: 1/2, step 1569/107898 completed (loss: 0.6827832460403442, acc: 0.8095238208770752)
[2025-02-17 16:36:57,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:57,648][root][INFO] - Training Epoch: 1/2, step 1570/107898 completed (loss: 0.7191775441169739, acc: 0.9285714030265808)
[2025-02-17 16:36:57,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:57,989][root][INFO] - Training Epoch: 1/2, step 1571/107898 completed (loss: 1.4194735288619995, acc: 0.75)
[2025-02-17 16:36:58,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:58,337][root][INFO] - Training Epoch: 1/2, step 1572/107898 completed (loss: 0.23672077059745789, acc: 1.0)
[2025-02-17 16:36:58,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:58,661][root][INFO] - Training Epoch: 1/2, step 1573/107898 completed (loss: 1.8269330263137817, acc: 0.6315789222717285)
[2025-02-17 16:36:58,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:59,012][root][INFO] - Training Epoch: 1/2, step 1574/107898 completed (loss: 0.015436106361448765, acc: 1.0)
[2025-02-17 16:36:59,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:59,347][root][INFO] - Training Epoch: 1/2, step 1575/107898 completed (loss: 1.3924243450164795, acc: 0.8666666746139526)
[2025-02-17 16:36:59,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:36:59,690][root][INFO] - Training Epoch: 1/2, step 1576/107898 completed (loss: 4.73287296295166, acc: 0.25)
[2025-02-17 16:36:59,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:00,037][root][INFO] - Training Epoch: 1/2, step 1577/107898 completed (loss: 0.10454361140727997, acc: 1.0)
[2025-02-17 16:37:00,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:00,385][root][INFO] - Training Epoch: 1/2, step 1578/107898 completed (loss: 0.5249940752983093, acc: 0.800000011920929)
[2025-02-17 16:37:00,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:00,756][root][INFO] - Training Epoch: 1/2, step 1579/107898 completed (loss: 0.6643134355545044, acc: 0.9285714030265808)
[2025-02-17 16:37:00,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:01,073][root][INFO] - Training Epoch: 1/2, step 1580/107898 completed (loss: 0.1788042038679123, acc: 1.0)
[2025-02-17 16:37:01,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:01,366][root][INFO] - Training Epoch: 1/2, step 1581/107898 completed (loss: 1.2472153902053833, acc: 0.75)
[2025-02-17 16:37:01,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:01,673][root][INFO] - Training Epoch: 1/2, step 1582/107898 completed (loss: 0.2395641803741455, acc: 0.9166666865348816)
[2025-02-17 16:37:01,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:01,964][root][INFO] - Training Epoch: 1/2, step 1583/107898 completed (loss: 0.6135464310646057, acc: 0.8333333134651184)
[2025-02-17 16:37:02,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:02,284][root][INFO] - Training Epoch: 1/2, step 1584/107898 completed (loss: 0.8523227572441101, acc: 0.5)
[2025-02-17 16:37:02,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:02,610][root][INFO] - Training Epoch: 1/2, step 1585/107898 completed (loss: 0.9580753445625305, acc: 0.7142857313156128)
[2025-02-17 16:37:02,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:02,915][root][INFO] - Training Epoch: 1/2, step 1586/107898 completed (loss: 0.5418914556503296, acc: 1.0)
[2025-02-17 16:37:02,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:03,188][root][INFO] - Training Epoch: 1/2, step 1587/107898 completed (loss: 0.8471425771713257, acc: 0.5)
[2025-02-17 16:37:03,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:03,478][root][INFO] - Training Epoch: 1/2, step 1588/107898 completed (loss: 2.5105435848236084, acc: 0.6666666865348816)
[2025-02-17 16:37:03,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:03,774][root][INFO] - Training Epoch: 1/2, step 1589/107898 completed (loss: 0.011150483973324299, acc: 1.0)
[2025-02-17 16:37:03,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:04,044][root][INFO] - Training Epoch: 1/2, step 1590/107898 completed (loss: 0.04855884239077568, acc: 1.0)
[2025-02-17 16:37:04,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:04,375][root][INFO] - Training Epoch: 1/2, step 1591/107898 completed (loss: 0.5706284642219543, acc: 0.9166666865348816)
[2025-02-17 16:37:04,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:04,728][root][INFO] - Training Epoch: 1/2, step 1592/107898 completed (loss: 0.8823791146278381, acc: 0.8620689511299133)
[2025-02-17 16:37:04,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:05,038][root][INFO] - Training Epoch: 1/2, step 1593/107898 completed (loss: 0.02956489846110344, acc: 1.0)
[2025-02-17 16:37:05,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:05,369][root][INFO] - Training Epoch: 1/2, step 1594/107898 completed (loss: 0.9235013723373413, acc: 0.800000011920929)
[2025-02-17 16:37:05,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:05,672][root][INFO] - Training Epoch: 1/2, step 1595/107898 completed (loss: 2.2703418731689453, acc: 0.6000000238418579)
[2025-02-17 16:37:05,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:06,003][root][INFO] - Training Epoch: 1/2, step 1596/107898 completed (loss: 3.0545475482940674, acc: 0.3571428656578064)
[2025-02-17 16:37:06,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:06,315][root][INFO] - Training Epoch: 1/2, step 1597/107898 completed (loss: 0.3030585050582886, acc: 1.0)
[2025-02-17 16:37:06,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:06,613][root][INFO] - Training Epoch: 1/2, step 1598/107898 completed (loss: 0.024506382644176483, acc: 1.0)
[2025-02-17 16:37:06,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:06,920][root][INFO] - Training Epoch: 1/2, step 1599/107898 completed (loss: 0.44591477513313293, acc: 0.9200000166893005)
[2025-02-17 16:37:07,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:07,219][root][INFO] - Training Epoch: 1/2, step 1600/107898 completed (loss: 0.051401443779468536, acc: 1.0)
[2025-02-17 16:37:07,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:07,522][root][INFO] - Training Epoch: 1/2, step 1601/107898 completed (loss: 1.4535118341445923, acc: 0.7142857313156128)
[2025-02-17 16:37:07,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:07,918][root][INFO] - Training Epoch: 1/2, step 1602/107898 completed (loss: 1.9233312606811523, acc: 0.7142857313156128)
[2025-02-17 16:37:08,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:08,270][root][INFO] - Training Epoch: 1/2, step 1603/107898 completed (loss: 1.0415548086166382, acc: 0.6666666865348816)
[2025-02-17 16:37:08,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:08,598][root][INFO] - Training Epoch: 1/2, step 1604/107898 completed (loss: 1.3839964866638184, acc: 0.7083333134651184)
[2025-02-17 16:37:08,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:08,930][root][INFO] - Training Epoch: 1/2, step 1605/107898 completed (loss: 4.284897327423096, acc: 0.27272728085517883)
[2025-02-17 16:37:09,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:09,239][root][INFO] - Training Epoch: 1/2, step 1606/107898 completed (loss: 0.286568820476532, acc: 1.0)
[2025-02-17 16:37:09,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:09,539][root][INFO] - Training Epoch: 1/2, step 1607/107898 completed (loss: 0.018458863720297813, acc: 1.0)
[2025-02-17 16:37:09,637][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:09,860][root][INFO] - Training Epoch: 1/2, step 1608/107898 completed (loss: 1.8523372411727905, acc: 0.5)
[2025-02-17 16:37:09,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:10,214][root][INFO] - Training Epoch: 1/2, step 1609/107898 completed (loss: 1.6798763275146484, acc: 0.5)
[2025-02-17 16:37:10,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:10,544][root][INFO] - Training Epoch: 1/2, step 1610/107898 completed (loss: 0.01688447967171669, acc: 1.0)
[2025-02-17 16:37:10,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:10,888][root][INFO] - Training Epoch: 1/2, step 1611/107898 completed (loss: 0.05149298161268234, acc: 1.0)
[2025-02-17 16:37:10,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:11,202][root][INFO] - Training Epoch: 1/2, step 1612/107898 completed (loss: 1.7635599374771118, acc: 0.6000000238418579)
[2025-02-17 16:37:11,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:11,561][root][INFO] - Training Epoch: 1/2, step 1613/107898 completed (loss: 5.772515296936035, acc: 0.25)
[2025-02-17 16:37:11,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:11,893][root][INFO] - Training Epoch: 1/2, step 1614/107898 completed (loss: 3.4871983528137207, acc: 0.5)
[2025-02-17 16:37:11,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:12,207][root][INFO] - Training Epoch: 1/2, step 1615/107898 completed (loss: 1.4323108196258545, acc: 0.75)
[2025-02-17 16:37:12,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:12,474][root][INFO] - Training Epoch: 1/2, step 1616/107898 completed (loss: 1.2623003721237183, acc: 0.6666666865348816)
[2025-02-17 16:37:12,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:12,869][root][INFO] - Training Epoch: 1/2, step 1617/107898 completed (loss: 0.9723433256149292, acc: 0.75)
[2025-02-17 16:37:12,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:13,234][root][INFO] - Training Epoch: 1/2, step 1618/107898 completed (loss: 1.590619444847107, acc: 0.692307710647583)
[2025-02-17 16:37:13,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:13,598][root][INFO] - Training Epoch: 1/2, step 1619/107898 completed (loss: 0.7305810451507568, acc: 0.8666666746139526)
[2025-02-17 16:37:13,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:13,949][root][INFO] - Training Epoch: 1/2, step 1620/107898 completed (loss: 0.8796862363815308, acc: 0.8571428656578064)
[2025-02-17 16:37:14,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:14,260][root][INFO] - Training Epoch: 1/2, step 1621/107898 completed (loss: 0.6165354251861572, acc: 0.8333333134651184)
[2025-02-17 16:37:14,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:14,572][root][INFO] - Training Epoch: 1/2, step 1622/107898 completed (loss: 0.4308278262615204, acc: 0.8333333134651184)
[2025-02-17 16:37:14,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:14,883][root][INFO] - Training Epoch: 1/2, step 1623/107898 completed (loss: 0.327239453792572, acc: 1.0)
[2025-02-17 16:37:14,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:15,173][root][INFO] - Training Epoch: 1/2, step 1624/107898 completed (loss: 0.9647515416145325, acc: 0.6666666865348816)
[2025-02-17 16:37:15,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:15,461][root][INFO] - Training Epoch: 1/2, step 1625/107898 completed (loss: 5.032135486602783, acc: 0.5)
[2025-02-17 16:37:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:15,760][root][INFO] - Training Epoch: 1/2, step 1626/107898 completed (loss: 1.7142151594161987, acc: 0.25)
[2025-02-17 16:37:15,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:16,055][root][INFO] - Training Epoch: 1/2, step 1627/107898 completed (loss: 0.8782748579978943, acc: 0.8181818127632141)
[2025-02-17 16:37:16,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:16,409][root][INFO] - Training Epoch: 1/2, step 1628/107898 completed (loss: 6.593046188354492, acc: 0.5)
[2025-02-17 16:37:16,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:16,725][root][INFO] - Training Epoch: 1/2, step 1629/107898 completed (loss: 0.5350949168205261, acc: 0.8461538553237915)
[2025-02-17 16:37:16,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:17,012][root][INFO] - Training Epoch: 1/2, step 1630/107898 completed (loss: 5.396538734436035, acc: 0.4000000059604645)
[2025-02-17 16:37:17,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:17,307][root][INFO] - Training Epoch: 1/2, step 1631/107898 completed (loss: 1.9153213500976562, acc: 0.7272727489471436)
[2025-02-17 16:37:17,385][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:17,663][root][INFO] - Training Epoch: 1/2, step 1632/107898 completed (loss: 0.11578287929296494, acc: 1.0)
[2025-02-17 16:37:17,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:18,020][root][INFO] - Training Epoch: 1/2, step 1633/107898 completed (loss: 0.9727712869644165, acc: 0.8421052694320679)
[2025-02-17 16:37:18,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:18,377][root][INFO] - Training Epoch: 1/2, step 1634/107898 completed (loss: 1.779824137687683, acc: 0.7179487347602844)
[2025-02-17 16:37:18,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:18,674][root][INFO] - Training Epoch: 1/2, step 1635/107898 completed (loss: 1.703532099723816, acc: 0.6666666865348816)
[2025-02-17 16:37:18,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:18,982][root][INFO] - Training Epoch: 1/2, step 1636/107898 completed (loss: 0.12812277674674988, acc: 1.0)
[2025-02-17 16:37:19,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:19,345][root][INFO] - Training Epoch: 1/2, step 1637/107898 completed (loss: 1.9964741468429565, acc: 0.6190476417541504)
[2025-02-17 16:37:19,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:19,697][root][INFO] - Training Epoch: 1/2, step 1638/107898 completed (loss: 1.2022455930709839, acc: 0.5)
[2025-02-17 16:37:19,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:20,024][root][INFO] - Training Epoch: 1/2, step 1639/107898 completed (loss: 0.8257176876068115, acc: 0.8181818127632141)
[2025-02-17 16:37:20,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:20,349][root][INFO] - Training Epoch: 1/2, step 1640/107898 completed (loss: 0.6575323343276978, acc: 0.9047619104385376)
[2025-02-17 16:37:20,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:20,700][root][INFO] - Training Epoch: 1/2, step 1641/107898 completed (loss: 2.7277400493621826, acc: 0.5)
[2025-02-17 16:37:20,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:21,058][root][INFO] - Training Epoch: 1/2, step 1642/107898 completed (loss: 1.0563253164291382, acc: 0.8695651888847351)
[2025-02-17 16:37:21,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:21,411][root][INFO] - Training Epoch: 1/2, step 1643/107898 completed (loss: 1.9226120710372925, acc: 0.5)
[2025-02-17 16:37:21,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:21,715][root][INFO] - Training Epoch: 1/2, step 1644/107898 completed (loss: 0.4952501356601715, acc: 0.6666666865348816)
[2025-02-17 16:37:21,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:22,027][root][INFO] - Training Epoch: 1/2, step 1645/107898 completed (loss: 2.4353606700897217, acc: 0.7142857313156128)
[2025-02-17 16:37:22,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:22,320][root][INFO] - Training Epoch: 1/2, step 1646/107898 completed (loss: 0.15179632604122162, acc: 1.0)
[2025-02-17 16:37:22,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:22,677][root][INFO] - Training Epoch: 1/2, step 1647/107898 completed (loss: 0.8669625520706177, acc: 0.8999999761581421)
[2025-02-17 16:37:22,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:23,021][root][INFO] - Training Epoch: 1/2, step 1648/107898 completed (loss: 1.403201699256897, acc: 0.7727272510528564)
[2025-02-17 16:37:23,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:23,363][root][INFO] - Training Epoch: 1/2, step 1649/107898 completed (loss: 0.45220446586608887, acc: 0.5)
[2025-02-17 16:37:23,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:23,691][root][INFO] - Training Epoch: 1/2, step 1650/107898 completed (loss: 1.3376773595809937, acc: 0.6842105388641357)
[2025-02-17 16:37:23,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:23,999][root][INFO] - Training Epoch: 1/2, step 1651/107898 completed (loss: 0.4995141625404358, acc: 0.8571428656578064)
[2025-02-17 16:37:24,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:24,295][root][INFO] - Training Epoch: 1/2, step 1652/107898 completed (loss: 0.9398284554481506, acc: 0.5)
[2025-02-17 16:37:24,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:24,677][root][INFO] - Training Epoch: 1/2, step 1653/107898 completed (loss: 0.017022637650370598, acc: 1.0)
[2025-02-17 16:37:24,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:25,034][root][INFO] - Training Epoch: 1/2, step 1654/107898 completed (loss: 1.7945278882980347, acc: 0.6666666865348816)
[2025-02-17 16:37:25,124][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:25,354][root][INFO] - Training Epoch: 1/2, step 1655/107898 completed (loss: 1.6457606554031372, acc: 0.5)
[2025-02-17 16:37:25,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:25,673][root][INFO] - Training Epoch: 1/2, step 1656/107898 completed (loss: 1.6677345037460327, acc: 0.7272727489471436)
[2025-02-17 16:37:25,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:25,991][root][INFO] - Training Epoch: 1/2, step 1657/107898 completed (loss: 1.9042584896087646, acc: 0.4000000059604645)
[2025-02-17 16:37:26,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:26,294][root][INFO] - Training Epoch: 1/2, step 1658/107898 completed (loss: 0.19763554632663727, acc: 1.0)
[2025-02-17 16:37:26,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:26,600][root][INFO] - Training Epoch: 1/2, step 1659/107898 completed (loss: 0.5097854733467102, acc: 0.8999999761581421)
[2025-02-17 16:37:26,687][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:26,910][root][INFO] - Training Epoch: 1/2, step 1660/107898 completed (loss: 0.432036429643631, acc: 0.8571428656578064)
[2025-02-17 16:37:27,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:27,192][root][INFO] - Training Epoch: 1/2, step 1661/107898 completed (loss: 2.239769458770752, acc: 0.5)
[2025-02-17 16:37:27,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:27,528][root][INFO] - Training Epoch: 1/2, step 1662/107898 completed (loss: 0.5126926302909851, acc: 0.8571428656578064)
[2025-02-17 16:37:27,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:27,838][root][INFO] - Training Epoch: 1/2, step 1663/107898 completed (loss: 0.2679457664489746, acc: 1.0)
[2025-02-17 16:37:27,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:28,165][root][INFO] - Training Epoch: 1/2, step 1664/107898 completed (loss: 0.1519932597875595, acc: 0.9411764740943909)
[2025-02-17 16:37:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:28,492][root][INFO] - Training Epoch: 1/2, step 1665/107898 completed (loss: 1.0547878742218018, acc: 0.5)
[2025-02-17 16:37:28,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:28,796][root][INFO] - Training Epoch: 1/2, step 1666/107898 completed (loss: 0.5718566179275513, acc: 1.0)
[2025-02-17 16:37:28,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:29,093][root][INFO] - Training Epoch: 1/2, step 1667/107898 completed (loss: 2.225393295288086, acc: 0.6842105388641357)
[2025-02-17 16:37:29,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:29,388][root][INFO] - Training Epoch: 1/2, step 1668/107898 completed (loss: 0.562820553779602, acc: 0.5)
[2025-02-17 16:37:29,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:29,708][root][INFO] - Training Epoch: 1/2, step 1669/107898 completed (loss: 0.6092645525932312, acc: 0.800000011920929)
[2025-02-17 16:37:29,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:30,013][root][INFO] - Training Epoch: 1/2, step 1670/107898 completed (loss: 1.5996761322021484, acc: 0.6666666865348816)
[2025-02-17 16:37:30,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:30,310][root][INFO] - Training Epoch: 1/2, step 1671/107898 completed (loss: 1.3804081678390503, acc: 0.75)
[2025-02-17 16:37:30,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:30,707][root][INFO] - Training Epoch: 1/2, step 1672/107898 completed (loss: 0.024308737367391586, acc: 1.0)
[2025-02-17 16:37:30,822][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:31,065][root][INFO] - Training Epoch: 1/2, step 1673/107898 completed (loss: 0.6642836928367615, acc: 0.75)
[2025-02-17 16:37:31,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:31,390][root][INFO] - Training Epoch: 1/2, step 1674/107898 completed (loss: 2.987238645553589, acc: 0.5)
[2025-02-17 16:37:31,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:31,716][root][INFO] - Training Epoch: 1/2, step 1675/107898 completed (loss: 0.5203835368156433, acc: 0.6666666865348816)
[2025-02-17 16:37:31,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:32,040][root][INFO] - Training Epoch: 1/2, step 1676/107898 completed (loss: 1.2550331354141235, acc: 0.6428571343421936)
[2025-02-17 16:37:32,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:32,361][root][INFO] - Training Epoch: 1/2, step 1677/107898 completed (loss: 0.9732707738876343, acc: 0.8095238208770752)
[2025-02-17 16:37:32,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:32,656][root][INFO] - Training Epoch: 1/2, step 1678/107898 completed (loss: 0.9030615091323853, acc: 0.9090909361839294)
[2025-02-17 16:37:32,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:32,966][root][INFO] - Training Epoch: 1/2, step 1679/107898 completed (loss: 1.1361324787139893, acc: 0.75)
[2025-02-17 16:37:33,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:33,315][root][INFO] - Training Epoch: 1/2, step 1680/107898 completed (loss: 0.16511067748069763, acc: 1.0)
[2025-02-17 16:37:33,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:33,636][root][INFO] - Training Epoch: 1/2, step 1681/107898 completed (loss: 0.2398054599761963, acc: 1.0)
[2025-02-17 16:37:33,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:33,964][root][INFO] - Training Epoch: 1/2, step 1682/107898 completed (loss: 0.16073764860630035, acc: 1.0)
[2025-02-17 16:37:34,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:34,317][root][INFO] - Training Epoch: 1/2, step 1683/107898 completed (loss: 5.146374225616455, acc: 0.5)
[2025-02-17 16:37:34,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:34,643][root][INFO] - Training Epoch: 1/2, step 1684/107898 completed (loss: 0.3768238425254822, acc: 0.875)
[2025-02-17 16:37:34,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:34,973][root][INFO] - Training Epoch: 1/2, step 1685/107898 completed (loss: 0.8776063323020935, acc: 0.7692307829856873)
[2025-02-17 16:37:35,046][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:35,256][root][INFO] - Training Epoch: 1/2, step 1686/107898 completed (loss: 0.8690136671066284, acc: 0.5)
[2025-02-17 16:37:35,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:35,585][root][INFO] - Training Epoch: 1/2, step 1687/107898 completed (loss: 0.7280105948448181, acc: 0.8999999761581421)
[2025-02-17 16:37:35,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:35,887][root][INFO] - Training Epoch: 1/2, step 1688/107898 completed (loss: 0.022595610469579697, acc: 1.0)
[2025-02-17 16:37:35,965][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:36,151][root][INFO] - Training Epoch: 1/2, step 1689/107898 completed (loss: 1.9579579830169678, acc: 0.699999988079071)
[2025-02-17 16:37:36,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:36,451][root][INFO] - Training Epoch: 1/2, step 1690/107898 completed (loss: 2.1575980186462402, acc: 0.75)
[2025-02-17 16:37:36,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:36,765][root][INFO] - Training Epoch: 1/2, step 1691/107898 completed (loss: 1.5866929292678833, acc: 0.7368420958518982)
[2025-02-17 16:37:36,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:37,096][root][INFO] - Training Epoch: 1/2, step 1692/107898 completed (loss: 0.4948621094226837, acc: 0.9166666865348816)
[2025-02-17 16:37:37,185][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:37,404][root][INFO] - Training Epoch: 1/2, step 1693/107898 completed (loss: 0.014095445163547993, acc: 1.0)
[2025-02-17 16:37:37,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:37,739][root][INFO] - Training Epoch: 1/2, step 1694/107898 completed (loss: 0.6923589110374451, acc: 0.9130434989929199)
[2025-02-17 16:37:37,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:38,072][root][INFO] - Training Epoch: 1/2, step 1695/107898 completed (loss: 0.6050388813018799, acc: 0.8636363744735718)
[2025-02-17 16:37:38,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:38,378][root][INFO] - Training Epoch: 1/2, step 1696/107898 completed (loss: 0.6412058472633362, acc: 0.5)
[2025-02-17 16:37:38,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:38,680][root][INFO] - Training Epoch: 1/2, step 1697/107898 completed (loss: 0.964181125164032, acc: 0.6666666865348816)
[2025-02-17 16:37:38,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:38,981][root][INFO] - Training Epoch: 1/2, step 1698/107898 completed (loss: 0.770000159740448, acc: 0.6666666865348816)
[2025-02-17 16:37:39,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:39,316][root][INFO] - Training Epoch: 1/2, step 1699/107898 completed (loss: 0.8919156789779663, acc: 0.7878788113594055)
[2025-02-17 16:37:39,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:39,667][root][INFO] - Training Epoch: 1/2, step 1700/107898 completed (loss: 1.2202019691467285, acc: 0.8181818127632141)
[2025-02-17 16:37:39,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:39,997][root][INFO] - Training Epoch: 1/2, step 1701/107898 completed (loss: 1.0036554336547852, acc: 0.5)
[2025-02-17 16:37:40,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:40,335][root][INFO] - Training Epoch: 1/2, step 1702/107898 completed (loss: 0.20291651785373688, acc: 1.0)
[2025-02-17 16:37:40,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:40,629][root][INFO] - Training Epoch: 1/2, step 1703/107898 completed (loss: 0.014480924233794212, acc: 1.0)
[2025-02-17 16:37:40,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:40,918][root][INFO] - Training Epoch: 1/2, step 1704/107898 completed (loss: 3.109135150909424, acc: 0.4285714328289032)
[2025-02-17 16:37:41,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:41,227][root][INFO] - Training Epoch: 1/2, step 1705/107898 completed (loss: 1.3254855871200562, acc: 0.7368420958518982)
[2025-02-17 16:37:41,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:41,554][root][INFO] - Training Epoch: 1/2, step 1706/107898 completed (loss: 0.39796149730682373, acc: 0.9166666865348816)
[2025-02-17 16:37:41,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:41,886][root][INFO] - Training Epoch: 1/2, step 1707/107898 completed (loss: 1.5798368453979492, acc: 0.6666666865348816)
[2025-02-17 16:37:41,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:42,210][root][INFO] - Training Epoch: 1/2, step 1708/107898 completed (loss: 0.18163661658763885, acc: 1.0)
[2025-02-17 16:37:42,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:42,541][root][INFO] - Training Epoch: 1/2, step 1709/107898 completed (loss: 0.9377381801605225, acc: 0.9333333373069763)
[2025-02-17 16:37:42,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:42,883][root][INFO] - Training Epoch: 1/2, step 1710/107898 completed (loss: 2.446377754211426, acc: 0.5833333134651184)
[2025-02-17 16:37:42,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:43,191][root][INFO] - Training Epoch: 1/2, step 1711/107898 completed (loss: 1.4255346059799194, acc: 0.6666666865348816)
[2025-02-17 16:37:43,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:43,482][root][INFO] - Training Epoch: 1/2, step 1712/107898 completed (loss: 1.9575649499893188, acc: 0.75)
[2025-02-17 16:37:43,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:43,783][root][INFO] - Training Epoch: 1/2, step 1713/107898 completed (loss: 0.027282288298010826, acc: 1.0)
[2025-02-17 16:37:43,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:44,096][root][INFO] - Training Epoch: 1/2, step 1714/107898 completed (loss: 1.170377254486084, acc: 0.7692307829856873)
[2025-02-17 16:37:44,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:44,390][root][INFO] - Training Epoch: 1/2, step 1715/107898 completed (loss: 0.07974882423877716, acc: 1.0)
[2025-02-17 16:37:44,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:44,703][root][INFO] - Training Epoch: 1/2, step 1716/107898 completed (loss: 1.05491304397583, acc: 0.875)
[2025-02-17 16:37:44,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:45,019][root][INFO] - Training Epoch: 1/2, step 1717/107898 completed (loss: 1.2686151266098022, acc: 0.6666666865348816)
[2025-02-17 16:37:45,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:45,359][root][INFO] - Training Epoch: 1/2, step 1718/107898 completed (loss: 1.6436660289764404, acc: 0.5)
[2025-02-17 16:37:45,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:45,684][root][INFO] - Training Epoch: 1/2, step 1719/107898 completed (loss: 2.3621387481689453, acc: 0.6315789222717285)
[2025-02-17 16:37:45,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:46,041][root][INFO] - Training Epoch: 1/2, step 1720/107898 completed (loss: 1.633427381515503, acc: 0.6363636255264282)
[2025-02-17 16:37:46,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:46,355][root][INFO] - Training Epoch: 1/2, step 1721/107898 completed (loss: 1.6466647386550903, acc: 0.8181818127632141)
[2025-02-17 16:37:46,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:46,705][root][INFO] - Training Epoch: 1/2, step 1722/107898 completed (loss: 2.5644242763519287, acc: 0.6363636255264282)
[2025-02-17 16:37:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:47,032][root][INFO] - Training Epoch: 1/2, step 1723/107898 completed (loss: 0.6649300456047058, acc: 0.800000011920929)
[2025-02-17 16:37:47,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:47,413][root][INFO] - Training Epoch: 1/2, step 1724/107898 completed (loss: 1.4466520547866821, acc: 0.6666666865348816)
[2025-02-17 16:37:47,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:47,747][root][INFO] - Training Epoch: 1/2, step 1725/107898 completed (loss: 0.24599190056324005, acc: 1.0)
[2025-02-17 16:37:47,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:48,068][root][INFO] - Training Epoch: 1/2, step 1726/107898 completed (loss: 0.8425794839859009, acc: 0.9090909361839294)
[2025-02-17 16:37:48,171][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:48,401][root][INFO] - Training Epoch: 1/2, step 1727/107898 completed (loss: 0.6788521409034729, acc: 0.5)
[2025-02-17 16:37:48,492][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:48,712][root][INFO] - Training Epoch: 1/2, step 1728/107898 completed (loss: 0.01703663356602192, acc: 1.0)
[2025-02-17 16:37:48,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:49,002][root][INFO] - Training Epoch: 1/2, step 1729/107898 completed (loss: 0.6829988956451416, acc: 0.6666666865348816)
[2025-02-17 16:37:49,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:49,299][root][INFO] - Training Epoch: 1/2, step 1730/107898 completed (loss: 1.963266134262085, acc: 0.5555555820465088)
[2025-02-17 16:37:49,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:49,596][root][INFO] - Training Epoch: 1/2, step 1731/107898 completed (loss: 1.3995823860168457, acc: 0.7777777910232544)
[2025-02-17 16:37:49,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:49,918][root][INFO] - Training Epoch: 1/2, step 1732/107898 completed (loss: 0.20290061831474304, acc: 1.0)
[2025-02-17 16:37:50,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:50,275][root][INFO] - Training Epoch: 1/2, step 1733/107898 completed (loss: 0.23264750838279724, acc: 0.9090909361839294)
[2025-02-17 16:37:50,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:50,579][root][INFO] - Training Epoch: 1/2, step 1734/107898 completed (loss: 1.1698710918426514, acc: 0.5)
[2025-02-17 16:37:50,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:50,936][root][INFO] - Training Epoch: 1/2, step 1735/107898 completed (loss: 1.0066179037094116, acc: 0.8461538553237915)
[2025-02-17 16:37:51,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:51,256][root][INFO] - Training Epoch: 1/2, step 1736/107898 completed (loss: 2.4641406536102295, acc: 0.3333333432674408)
[2025-02-17 16:37:51,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:51,618][root][INFO] - Training Epoch: 1/2, step 1737/107898 completed (loss: 1.1905851364135742, acc: 0.807692289352417)
[2025-02-17 16:37:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:51,962][root][INFO] - Training Epoch: 1/2, step 1738/107898 completed (loss: 0.033710163086652756, acc: 1.0)
[2025-02-17 16:37:52,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:52,298][root][INFO] - Training Epoch: 1/2, step 1739/107898 completed (loss: 0.9849129915237427, acc: 0.800000011920929)
[2025-02-17 16:37:52,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:52,623][root][INFO] - Training Epoch: 1/2, step 1740/107898 completed (loss: 2.4845285415649414, acc: 0.0)
[2025-02-17 16:37:52,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:52,962][root][INFO] - Training Epoch: 1/2, step 1741/107898 completed (loss: 1.589706301689148, acc: 0.8333333134651184)
[2025-02-17 16:37:53,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:53,304][root][INFO] - Training Epoch: 1/2, step 1742/107898 completed (loss: 2.8456878662109375, acc: 0.0)
[2025-02-17 16:37:53,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:53,633][root][INFO] - Training Epoch: 1/2, step 1743/107898 completed (loss: 0.23527386784553528, acc: 1.0)
[2025-02-17 16:37:53,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:53,962][root][INFO] - Training Epoch: 1/2, step 1744/107898 completed (loss: 0.6901862025260925, acc: 0.875)
[2025-02-17 16:37:54,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:54,337][root][INFO] - Training Epoch: 1/2, step 1745/107898 completed (loss: 0.36460238695144653, acc: 0.9090909361839294)
[2025-02-17 16:37:54,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:54,674][root][INFO] - Training Epoch: 1/2, step 1746/107898 completed (loss: 0.8938548564910889, acc: 0.8333333134651184)
[2025-02-17 16:37:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:55,011][root][INFO] - Training Epoch: 1/2, step 1747/107898 completed (loss: 3.11501407623291, acc: 0.4375)
[2025-02-17 16:37:55,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:55,358][root][INFO] - Training Epoch: 1/2, step 1748/107898 completed (loss: 1.2711795568466187, acc: 0.4000000059604645)
[2025-02-17 16:37:55,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:55,691][root][INFO] - Training Epoch: 1/2, step 1749/107898 completed (loss: 0.882684588432312, acc: 0.699999988079071)
[2025-02-17 16:37:55,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:56,019][root][INFO] - Training Epoch: 1/2, step 1750/107898 completed (loss: 0.5791872143745422, acc: 0.8333333134651184)
[2025-02-17 16:37:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:56,320][root][INFO] - Training Epoch: 1/2, step 1751/107898 completed (loss: 3.8845877647399902, acc: 0.4000000059604645)
[2025-02-17 16:37:56,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:56,619][root][INFO] - Training Epoch: 1/2, step 1752/107898 completed (loss: 0.6953374147415161, acc: 0.5)
[2025-02-17 16:37:56,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:56,973][root][INFO] - Training Epoch: 1/2, step 1753/107898 completed (loss: 0.2086455374956131, acc: 1.0)
[2025-02-17 16:37:57,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:57,347][root][INFO] - Training Epoch: 1/2, step 1754/107898 completed (loss: 0.36343780159950256, acc: 1.0)
[2025-02-17 16:37:57,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:57,695][root][INFO] - Training Epoch: 1/2, step 1755/107898 completed (loss: 0.3147412836551666, acc: 0.8500000238418579)
[2025-02-17 16:37:57,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:58,101][root][INFO] - Training Epoch: 1/2, step 1756/107898 completed (loss: 3.09464693069458, acc: 0.4000000059604645)
[2025-02-17 16:37:58,186][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:58,417][root][INFO] - Training Epoch: 1/2, step 1757/107898 completed (loss: 0.0045918733812868595, acc: 1.0)
[2025-02-17 16:37:58,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:58,764][root][INFO] - Training Epoch: 1/2, step 1758/107898 completed (loss: 0.7419686317443848, acc: 0.8333333134651184)
[2025-02-17 16:37:58,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:59,105][root][INFO] - Training Epoch: 1/2, step 1759/107898 completed (loss: 4.981845378875732, acc: 0.3333333432674408)
[2025-02-17 16:37:59,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:59,412][root][INFO] - Training Epoch: 1/2, step 1760/107898 completed (loss: 0.013794798403978348, acc: 1.0)
[2025-02-17 16:37:59,509][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:37:59,797][root][INFO] - Training Epoch: 1/2, step 1761/107898 completed (loss: 1.4487850666046143, acc: 0.7142857313156128)
[2025-02-17 16:37:59,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:00,191][root][INFO] - Training Epoch: 1/2, step 1762/107898 completed (loss: 0.2064184546470642, acc: 0.9375)
[2025-02-17 16:38:00,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:00,542][root][INFO] - Training Epoch: 1/2, step 1763/107898 completed (loss: 2.276378631591797, acc: 0.5)
[2025-02-17 16:38:00,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:00,870][root][INFO] - Training Epoch: 1/2, step 1764/107898 completed (loss: 0.026106424629688263, acc: 1.0)
[2025-02-17 16:38:00,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:01,220][root][INFO] - Training Epoch: 1/2, step 1765/107898 completed (loss: 1.1186985969543457, acc: 0.8571428656578064)
[2025-02-17 16:38:01,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:01,577][root][INFO] - Training Epoch: 1/2, step 1766/107898 completed (loss: 1.9890708923339844, acc: 0.5789473652839661)
[2025-02-17 16:38:01,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:01,920][root][INFO] - Training Epoch: 1/2, step 1767/107898 completed (loss: 0.895293116569519, acc: 0.800000011920929)
[2025-02-17 16:38:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:02,240][root][INFO] - Training Epoch: 1/2, step 1768/107898 completed (loss: 0.7940940856933594, acc: 0.774193525314331)
[2025-02-17 16:38:02,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:02,541][root][INFO] - Training Epoch: 1/2, step 1769/107898 completed (loss: 0.1848280280828476, acc: 1.0)
[2025-02-17 16:38:02,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:02,861][root][INFO] - Training Epoch: 1/2, step 1770/107898 completed (loss: 0.31513336300849915, acc: 1.0)
[2025-02-17 16:38:02,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:03,213][root][INFO] - Training Epoch: 1/2, step 1771/107898 completed (loss: 1.0092642307281494, acc: 0.8275862336158752)
[2025-02-17 16:38:03,289][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:03,506][root][INFO] - Training Epoch: 1/2, step 1772/107898 completed (loss: 0.09704570472240448, acc: 1.0)
[2025-02-17 16:38:03,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:03,792][root][INFO] - Training Epoch: 1/2, step 1773/107898 completed (loss: 0.1785883754491806, acc: 1.0)
[2025-02-17 16:38:03,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:04,067][root][INFO] - Training Epoch: 1/2, step 1774/107898 completed (loss: 4.250428676605225, acc: 0.3333333432674408)
[2025-02-17 16:38:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:04,352][root][INFO] - Training Epoch: 1/2, step 1775/107898 completed (loss: 2.2479896545410156, acc: 0.5)
[2025-02-17 16:38:04,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:04,650][root][INFO] - Training Epoch: 1/2, step 1776/107898 completed (loss: 1.3295162916183472, acc: 0.8666666746139526)
[2025-02-17 16:38:04,731][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:04,921][root][INFO] - Training Epoch: 1/2, step 1777/107898 completed (loss: 0.786963939666748, acc: 0.8260869383811951)
[2025-02-17 16:38:05,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:05,241][root][INFO] - Training Epoch: 1/2, step 1778/107898 completed (loss: 0.8781368732452393, acc: 0.8888888955116272)
[2025-02-17 16:38:05,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:05,558][root][INFO] - Training Epoch: 1/2, step 1779/107898 completed (loss: 0.5432567596435547, acc: 0.8947368264198303)
[2025-02-17 16:38:05,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:05,932][root][INFO] - Training Epoch: 1/2, step 1780/107898 completed (loss: 2.8394110202789307, acc: 0.6666666865348816)
[2025-02-17 16:38:06,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:06,263][root][INFO] - Training Epoch: 1/2, step 1781/107898 completed (loss: 0.9562434554100037, acc: 0.7142857313156128)
[2025-02-17 16:38:06,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:06,625][root][INFO] - Training Epoch: 1/2, step 1782/107898 completed (loss: 2.2839410305023193, acc: 0.5)
[2025-02-17 16:38:06,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:06,941][root][INFO] - Training Epoch: 1/2, step 1783/107898 completed (loss: 0.1449490487575531, acc: 1.0)
[2025-02-17 16:38:07,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:07,295][root][INFO] - Training Epoch: 1/2, step 1784/107898 completed (loss: 2.1582252979278564, acc: 0.5806451439857483)
[2025-02-17 16:38:07,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:07,614][root][INFO] - Training Epoch: 1/2, step 1785/107898 completed (loss: 0.7864352464675903, acc: 0.7777777910232544)
[2025-02-17 16:38:07,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:07,934][root][INFO] - Training Epoch: 1/2, step 1786/107898 completed (loss: 1.2741734981536865, acc: 0.6666666865348816)
[2025-02-17 16:38:08,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:08,230][root][INFO] - Training Epoch: 1/2, step 1787/107898 completed (loss: 0.4492027759552002, acc: 1.0)
[2025-02-17 16:38:08,321][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:08,542][root][INFO] - Training Epoch: 1/2, step 1788/107898 completed (loss: 1.4075241088867188, acc: 0.6000000238418579)
[2025-02-17 16:38:08,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:08,928][root][INFO] - Training Epoch: 1/2, step 1789/107898 completed (loss: 1.278427243232727, acc: 0.6875)
[2025-02-17 16:38:09,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:09,252][root][INFO] - Training Epoch: 1/2, step 1790/107898 completed (loss: 2.578803539276123, acc: 0.5)
[2025-02-17 16:38:09,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:09,559][root][INFO] - Training Epoch: 1/2, step 1791/107898 completed (loss: 1.0923537015914917, acc: 0.3333333432674408)
[2025-02-17 16:38:09,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:09,899][root][INFO] - Training Epoch: 1/2, step 1792/107898 completed (loss: 2.1530356407165527, acc: 0.6000000238418579)
[2025-02-17 16:38:09,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:10,214][root][INFO] - Training Epoch: 1/2, step 1793/107898 completed (loss: 0.01708185486495495, acc: 1.0)
[2025-02-17 16:38:10,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:10,531][root][INFO] - Training Epoch: 1/2, step 1794/107898 completed (loss: 0.8268364071846008, acc: 0.6666666865348816)
[2025-02-17 16:38:10,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:10,841][root][INFO] - Training Epoch: 1/2, step 1795/107898 completed (loss: 0.04470133036375046, acc: 1.0)
[2025-02-17 16:38:10,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:11,146][root][INFO] - Training Epoch: 1/2, step 1796/107898 completed (loss: 2.828005790710449, acc: 0.5)
[2025-02-17 16:38:11,228][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:11,454][root][INFO] - Training Epoch: 1/2, step 1797/107898 completed (loss: 0.3512303829193115, acc: 0.75)
[2025-02-17 16:38:11,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:11,753][root][INFO] - Training Epoch: 1/2, step 1798/107898 completed (loss: 0.032640211284160614, acc: 1.0)
[2025-02-17 16:38:11,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:12,088][root][INFO] - Training Epoch: 1/2, step 1799/107898 completed (loss: 0.4800713360309601, acc: 1.0)
[2025-02-17 16:38:12,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:12,448][root][INFO] - Training Epoch: 1/2, step 1800/107898 completed (loss: 0.06284917145967484, acc: 1.0)
[2025-02-17 16:38:12,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:12,776][root][INFO] - Training Epoch: 1/2, step 1801/107898 completed (loss: 1.578570008277893, acc: 0.7894737124443054)
[2025-02-17 16:38:12,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:13,124][root][INFO] - Training Epoch: 1/2, step 1802/107898 completed (loss: 0.6474323272705078, acc: 0.9130434989929199)
[2025-02-17 16:38:13,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:13,428][root][INFO] - Training Epoch: 1/2, step 1803/107898 completed (loss: 1.8330167531967163, acc: 0.6666666865348816)
[2025-02-17 16:38:13,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:13,741][root][INFO] - Training Epoch: 1/2, step 1804/107898 completed (loss: 1.3167191743850708, acc: 0.6666666865348816)
[2025-02-17 16:38:13,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:14,053][root][INFO] - Training Epoch: 1/2, step 1805/107898 completed (loss: 1.1079965829849243, acc: 0.6666666865348816)
[2025-02-17 16:38:14,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:14,395][root][INFO] - Training Epoch: 1/2, step 1806/107898 completed (loss: 0.6841489672660828, acc: 0.8684210777282715)
[2025-02-17 16:38:14,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:14,692][root][INFO] - Training Epoch: 1/2, step 1807/107898 completed (loss: 0.5066103339195251, acc: 0.875)
[2025-02-17 16:38:14,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:15,022][root][INFO] - Training Epoch: 1/2, step 1808/107898 completed (loss: 0.34828540682792664, acc: 0.8571428656578064)
[2025-02-17 16:38:15,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:15,351][root][INFO] - Training Epoch: 1/2, step 1809/107898 completed (loss: 0.8748748302459717, acc: 0.8636363744735718)
[2025-02-17 16:38:15,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:15,712][root][INFO] - Training Epoch: 1/2, step 1810/107898 completed (loss: 1.1013166904449463, acc: 0.8333333134651184)
[2025-02-17 16:38:15,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:16,075][root][INFO] - Training Epoch: 1/2, step 1811/107898 completed (loss: 0.02811005711555481, acc: 1.0)
[2025-02-17 16:38:16,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:16,443][root][INFO] - Training Epoch: 1/2, step 1812/107898 completed (loss: 0.4062035381793976, acc: 0.6666666865348816)
[2025-02-17 16:38:16,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:16,773][root][INFO] - Training Epoch: 1/2, step 1813/107898 completed (loss: 0.5897707939147949, acc: 1.0)
[2025-02-17 16:38:16,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:17,104][root][INFO] - Training Epoch: 1/2, step 1814/107898 completed (loss: 4.498330116271973, acc: 0.20000000298023224)
[2025-02-17 16:38:17,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:17,418][root][INFO] - Training Epoch: 1/2, step 1815/107898 completed (loss: 0.16743941605091095, acc: 1.0)
[2025-02-17 16:38:17,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:17,729][root][INFO] - Training Epoch: 1/2, step 1816/107898 completed (loss: 1.7934191226959229, acc: 0.6000000238418579)
[2025-02-17 16:38:17,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:18,033][root][INFO] - Training Epoch: 1/2, step 1817/107898 completed (loss: 2.451538324356079, acc: 0.5714285969734192)
[2025-02-17 16:38:18,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:18,350][root][INFO] - Training Epoch: 1/2, step 1818/107898 completed (loss: 0.8692424297332764, acc: 0.8461538553237915)
[2025-02-17 16:38:18,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:18,657][root][INFO] - Training Epoch: 1/2, step 1819/107898 completed (loss: 1.3755587339401245, acc: 0.75)
[2025-02-17 16:38:18,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:18,974][root][INFO] - Training Epoch: 1/2, step 1820/107898 completed (loss: 1.3726352453231812, acc: 0.8333333134651184)
[2025-02-17 16:38:19,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:19,274][root][INFO] - Training Epoch: 1/2, step 1821/107898 completed (loss: 0.1606539487838745, acc: 1.0)
[2025-02-17 16:38:19,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:19,570][root][INFO] - Training Epoch: 1/2, step 1822/107898 completed (loss: 0.04444872960448265, acc: 1.0)
[2025-02-17 16:38:19,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:19,912][root][INFO] - Training Epoch: 1/2, step 1823/107898 completed (loss: 0.8653682470321655, acc: 0.800000011920929)
[2025-02-17 16:38:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:20,267][root][INFO] - Training Epoch: 1/2, step 1824/107898 completed (loss: 0.16617275774478912, acc: 0.9411764740943909)
[2025-02-17 16:38:20,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:20,604][root][INFO] - Training Epoch: 1/2, step 1825/107898 completed (loss: 1.8699551820755005, acc: 0.5714285969734192)
[2025-02-17 16:38:20,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:20,969][root][INFO] - Training Epoch: 1/2, step 1826/107898 completed (loss: 0.1847597360610962, acc: 0.9523809552192688)
[2025-02-17 16:38:21,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:21,309][root][INFO] - Training Epoch: 1/2, step 1827/107898 completed (loss: 3.0132830142974854, acc: 0.5)
[2025-02-17 16:38:21,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:21,615][root][INFO] - Training Epoch: 1/2, step 1828/107898 completed (loss: 0.7530129551887512, acc: 0.8500000238418579)
[2025-02-17 16:38:21,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:21,929][root][INFO] - Training Epoch: 1/2, step 1829/107898 completed (loss: 3.9048476219177246, acc: 0.375)
[2025-02-17 16:38:22,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:22,255][root][INFO] - Training Epoch: 1/2, step 1830/107898 completed (loss: 5.085724830627441, acc: 0.5)
[2025-02-17 16:38:22,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:22,571][root][INFO] - Training Epoch: 1/2, step 1831/107898 completed (loss: 0.4265385568141937, acc: 0.8947368264198303)
[2025-02-17 16:38:22,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:22,908][root][INFO] - Training Epoch: 1/2, step 1832/107898 completed (loss: 0.09268269687891006, acc: 1.0)
[2025-02-17 16:38:23,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:23,230][root][INFO] - Training Epoch: 1/2, step 1833/107898 completed (loss: 1.5592288970947266, acc: 0.71875)
[2025-02-17 16:38:23,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:23,511][root][INFO] - Training Epoch: 1/2, step 1834/107898 completed (loss: 0.1456836611032486, acc: 1.0)
[2025-02-17 16:38:23,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:23,808][root][INFO] - Training Epoch: 1/2, step 1835/107898 completed (loss: 0.14656543731689453, acc: 1.0)
[2025-02-17 16:38:23,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:24,104][root][INFO] - Training Epoch: 1/2, step 1836/107898 completed (loss: 0.034405678510665894, acc: 1.0)
[2025-02-17 16:38:24,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:24,441][root][INFO] - Training Epoch: 1/2, step 1837/107898 completed (loss: 2.360497236251831, acc: 0.5833333134651184)
[2025-02-17 16:38:24,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:24,743][root][INFO] - Training Epoch: 1/2, step 1838/107898 completed (loss: 2.886575222015381, acc: 0.5)
[2025-02-17 16:38:24,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:25,040][root][INFO] - Training Epoch: 1/2, step 1839/107898 completed (loss: 1.5426493883132935, acc: 0.7368420958518982)
[2025-02-17 16:38:25,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:25,347][root][INFO] - Training Epoch: 1/2, step 1840/107898 completed (loss: 0.11425456404685974, acc: 1.0)
[2025-02-17 16:38:25,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:25,652][root][INFO] - Training Epoch: 1/2, step 1841/107898 completed (loss: 1.130739688873291, acc: 0.75)
[2025-02-17 16:38:25,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:25,942][root][INFO] - Training Epoch: 1/2, step 1842/107898 completed (loss: 0.012188054621219635, acc: 1.0)
[2025-02-17 16:38:26,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:26,271][root][INFO] - Training Epoch: 1/2, step 1843/107898 completed (loss: 1.3787904977798462, acc: 0.800000011920929)
[2025-02-17 16:38:26,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:26,569][root][INFO] - Training Epoch: 1/2, step 1844/107898 completed (loss: 0.6867907047271729, acc: 0.75)
[2025-02-17 16:38:26,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:26,876][root][INFO] - Training Epoch: 1/2, step 1845/107898 completed (loss: 0.9775572419166565, acc: 0.8235294222831726)
[2025-02-17 16:38:26,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:27,178][root][INFO] - Training Epoch: 1/2, step 1846/107898 completed (loss: 0.059455506503582, acc: 1.0)
[2025-02-17 16:38:27,259][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:27,467][root][INFO] - Training Epoch: 1/2, step 1847/107898 completed (loss: 0.06879531592130661, acc: 1.0)
[2025-02-17 16:38:27,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:27,765][root][INFO] - Training Epoch: 1/2, step 1848/107898 completed (loss: 2.073423385620117, acc: 0.4615384638309479)
[2025-02-17 16:38:27,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:28,059][root][INFO] - Training Epoch: 1/2, step 1849/107898 completed (loss: 0.5251579284667969, acc: 1.0)
[2025-02-17 16:38:28,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:28,373][root][INFO] - Training Epoch: 1/2, step 1850/107898 completed (loss: 0.14208906888961792, acc: 1.0)
[2025-02-17 16:38:28,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:28,665][root][INFO] - Training Epoch: 1/2, step 1851/107898 completed (loss: 1.3947492837905884, acc: 0.7333333492279053)
[2025-02-17 16:38:28,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:28,957][root][INFO] - Training Epoch: 1/2, step 1852/107898 completed (loss: 1.7434265613555908, acc: 0.692307710647583)
[2025-02-17 16:38:29,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:29,248][root][INFO] - Training Epoch: 1/2, step 1853/107898 completed (loss: 4.5886101722717285, acc: 0.3333333432674408)
[2025-02-17 16:38:29,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:29,563][root][INFO] - Training Epoch: 1/2, step 1854/107898 completed (loss: 1.3852359056472778, acc: 0.75)
[2025-02-17 16:38:29,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:29,874][root][INFO] - Training Epoch: 1/2, step 1855/107898 completed (loss: 0.2534331977367401, acc: 0.9090909361839294)
[2025-02-17 16:38:29,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:30,201][root][INFO] - Training Epoch: 1/2, step 1856/107898 completed (loss: 0.20284390449523926, acc: 1.0)
[2025-02-17 16:38:30,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:30,544][root][INFO] - Training Epoch: 1/2, step 1857/107898 completed (loss: 2.2234222888946533, acc: 0.6666666865348816)
[2025-02-17 16:38:30,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:30,896][root][INFO] - Training Epoch: 1/2, step 1858/107898 completed (loss: 2.7256247997283936, acc: 0.5333333611488342)
[2025-02-17 16:38:31,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:31,234][root][INFO] - Training Epoch: 1/2, step 1859/107898 completed (loss: 1.243154764175415, acc: 0.6666666865348816)
[2025-02-17 16:38:31,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:31,573][root][INFO] - Training Epoch: 1/2, step 1860/107898 completed (loss: 0.2764606177806854, acc: 0.9090909361839294)
[2025-02-17 16:38:31,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:31,863][root][INFO] - Training Epoch: 1/2, step 1861/107898 completed (loss: 4.521565914154053, acc: 0.6666666865348816)
[2025-02-17 16:38:31,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:32,193][root][INFO] - Training Epoch: 1/2, step 1862/107898 completed (loss: 1.1077061891555786, acc: 0.7586206793785095)
[2025-02-17 16:38:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:32,540][root][INFO] - Training Epoch: 1/2, step 1863/107898 completed (loss: 1.5654792785644531, acc: 0.0)
[2025-02-17 16:38:32,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:32,880][root][INFO] - Training Epoch: 1/2, step 1864/107898 completed (loss: 0.7285828590393066, acc: 0.8620689511299133)
[2025-02-17 16:38:32,959][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:33,187][root][INFO] - Training Epoch: 1/2, step 1865/107898 completed (loss: 0.7984447479248047, acc: 0.7272727489471436)
[2025-02-17 16:38:33,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:33,515][root][INFO] - Training Epoch: 1/2, step 1866/107898 completed (loss: 0.009006710723042488, acc: 1.0)
[2025-02-17 16:38:33,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:33,818][root][INFO] - Training Epoch: 1/2, step 1867/107898 completed (loss: 0.13067802786827087, acc: 1.0)
[2025-02-17 16:38:33,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:34,122][root][INFO] - Training Epoch: 1/2, step 1868/107898 completed (loss: 0.19677764177322388, acc: 0.9090909361839294)
[2025-02-17 16:38:34,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:34,431][root][INFO] - Training Epoch: 1/2, step 1869/107898 completed (loss: 1.7525490522384644, acc: 0.5)
[2025-02-17 16:38:34,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:34,724][root][INFO] - Training Epoch: 1/2, step 1870/107898 completed (loss: 1.3284642696380615, acc: 0.6666666865348816)
[2025-02-17 16:38:34,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:35,021][root][INFO] - Training Epoch: 1/2, step 1871/107898 completed (loss: 1.2810832262039185, acc: 0.8181818127632141)
[2025-02-17 16:38:35,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:35,376][root][INFO] - Training Epoch: 1/2, step 1872/107898 completed (loss: 2.0708537101745605, acc: 0.6842105388641357)
[2025-02-17 16:38:35,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:35,682][root][INFO] - Training Epoch: 1/2, step 1873/107898 completed (loss: 0.009089047089219093, acc: 1.0)
[2025-02-17 16:38:35,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:36,032][root][INFO] - Training Epoch: 1/2, step 1874/107898 completed (loss: 0.7828595638275146, acc: 0.8666666746139526)
[2025-02-17 16:38:36,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:36,367][root][INFO] - Training Epoch: 1/2, step 1875/107898 completed (loss: 4.012880802154541, acc: 0.3333333432674408)
[2025-02-17 16:38:36,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:36,731][root][INFO] - Training Epoch: 1/2, step 1876/107898 completed (loss: 4.539783954620361, acc: 0.3333333432674408)
[2025-02-17 16:38:36,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:37,058][root][INFO] - Training Epoch: 1/2, step 1877/107898 completed (loss: 0.06101255118846893, acc: 1.0)
[2025-02-17 16:38:37,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:37,373][root][INFO] - Training Epoch: 1/2, step 1878/107898 completed (loss: 0.152835875749588, acc: 1.0)
[2025-02-17 16:38:37,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:37,704][root][INFO] - Training Epoch: 1/2, step 1879/107898 completed (loss: 0.18624858558177948, acc: 1.0)
[2025-02-17 16:38:37,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:38,024][root][INFO] - Training Epoch: 1/2, step 1880/107898 completed (loss: 0.10626435279846191, acc: 1.0)
[2025-02-17 16:38:38,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:38,353][root][INFO] - Training Epoch: 1/2, step 1881/107898 completed (loss: 0.26835623383522034, acc: 0.95652174949646)
[2025-02-17 16:38:38,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:38,652][root][INFO] - Training Epoch: 1/2, step 1882/107898 completed (loss: 0.7679383754730225, acc: 0.8846153616905212)
[2025-02-17 16:38:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:38,985][root][INFO] - Training Epoch: 1/2, step 1883/107898 completed (loss: 0.925010085105896, acc: 0.8163265585899353)
[2025-02-17 16:38:39,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:39,270][root][INFO] - Training Epoch: 1/2, step 1884/107898 completed (loss: 1.3189213275909424, acc: 0.7857142686843872)
[2025-02-17 16:38:39,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:39,568][root][INFO] - Training Epoch: 1/2, step 1885/107898 completed (loss: 0.041703708469867706, acc: 1.0)
[2025-02-17 16:38:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:39,914][root][INFO] - Training Epoch: 1/2, step 1886/107898 completed (loss: 0.35201624035835266, acc: 0.930232584476471)
[2025-02-17 16:38:39,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:40,204][root][INFO] - Training Epoch: 1/2, step 1887/107898 completed (loss: 2.440605878829956, acc: 0.5)
[2025-02-17 16:38:40,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:40,496][root][INFO] - Training Epoch: 1/2, step 1888/107898 completed (loss: 0.3335169851779938, acc: 0.875)
[2025-02-17 16:38:40,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:40,843][root][INFO] - Training Epoch: 1/2, step 1889/107898 completed (loss: 1.15853750705719, acc: 0.75)
[2025-02-17 16:38:40,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:41,189][root][INFO] - Training Epoch: 1/2, step 1890/107898 completed (loss: 0.8674073815345764, acc: 0.8571428656578064)
[2025-02-17 16:38:41,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:41,550][root][INFO] - Training Epoch: 1/2, step 1891/107898 completed (loss: 0.5611413717269897, acc: 0.8846153616905212)
[2025-02-17 16:38:41,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:41,880][root][INFO] - Training Epoch: 1/2, step 1892/107898 completed (loss: 0.5929756760597229, acc: 0.8571428656578064)
[2025-02-17 16:38:41,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:42,222][root][INFO] - Training Epoch: 1/2, step 1893/107898 completed (loss: 1.2106399536132812, acc: 0.5)
[2025-02-17 16:38:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:42,539][root][INFO] - Training Epoch: 1/2, step 1894/107898 completed (loss: 0.794009268283844, acc: 0.8421052694320679)
[2025-02-17 16:38:42,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:42,864][root][INFO] - Training Epoch: 1/2, step 1895/107898 completed (loss: 0.9060319066047668, acc: 0.75)
[2025-02-17 16:38:42,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:43,191][root][INFO] - Training Epoch: 1/2, step 1896/107898 completed (loss: 0.4902021288871765, acc: 0.8500000238418579)
[2025-02-17 16:38:43,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:43,489][root][INFO] - Training Epoch: 1/2, step 1897/107898 completed (loss: 2.209859609603882, acc: 0.0)
[2025-02-17 16:38:43,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:43,802][root][INFO] - Training Epoch: 1/2, step 1898/107898 completed (loss: 1.7303733825683594, acc: 0.6666666865348816)
[2025-02-17 16:38:43,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:44,153][root][INFO] - Training Epoch: 1/2, step 1899/107898 completed (loss: 1.0500699281692505, acc: 0.7647058963775635)
[2025-02-17 16:38:44,254][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:44,485][root][INFO] - Training Epoch: 1/2, step 1900/107898 completed (loss: 1.058945655822754, acc: 0.8235294222831726)
[2025-02-17 16:38:44,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:44,855][root][INFO] - Training Epoch: 1/2, step 1901/107898 completed (loss: 4.841105937957764, acc: 0.1666666716337204)
[2025-02-17 16:38:44,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:45,186][root][INFO] - Training Epoch: 1/2, step 1902/107898 completed (loss: 1.5094538927078247, acc: 0.6666666865348816)
[2025-02-17 16:38:45,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:45,488][root][INFO] - Training Epoch: 1/2, step 1903/107898 completed (loss: 7.02004861831665, acc: 0.5)
[2025-02-17 16:38:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:45,808][root][INFO] - Training Epoch: 1/2, step 1904/107898 completed (loss: 1.7333897352218628, acc: 0.7142857313156128)
[2025-02-17 16:38:45,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:46,111][root][INFO] - Training Epoch: 1/2, step 1905/107898 completed (loss: 2.5582101345062256, acc: 0.6666666865348816)
[2025-02-17 16:38:46,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:46,468][root][INFO] - Training Epoch: 1/2, step 1906/107898 completed (loss: 0.6091336607933044, acc: 0.8999999761581421)
[2025-02-17 16:38:46,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:46,852][root][INFO] - Training Epoch: 1/2, step 1907/107898 completed (loss: 1.2018500566482544, acc: 0.7916666865348816)
[2025-02-17 16:38:46,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:47,188][root][INFO] - Training Epoch: 1/2, step 1908/107898 completed (loss: 1.003021001815796, acc: 0.6666666865348816)
[2025-02-17 16:38:47,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:47,512][root][INFO] - Training Epoch: 1/2, step 1909/107898 completed (loss: 1.4393750429153442, acc: 0.6666666865348816)
[2025-02-17 16:38:47,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:47,836][root][INFO] - Training Epoch: 1/2, step 1910/107898 completed (loss: 0.6799044013023376, acc: 0.8333333134651184)
[2025-02-17 16:38:47,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:48,137][root][INFO] - Training Epoch: 1/2, step 1911/107898 completed (loss: 0.385632187128067, acc: 1.0)
[2025-02-17 16:38:48,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:48,467][root][INFO] - Training Epoch: 1/2, step 1912/107898 completed (loss: 1.998777985572815, acc: 0.5)
[2025-02-17 16:38:48,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:48,791][root][INFO] - Training Epoch: 1/2, step 1913/107898 completed (loss: 2.1767213344573975, acc: 0.6190476417541504)
[2025-02-17 16:38:48,896][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:49,126][root][INFO] - Training Epoch: 1/2, step 1914/107898 completed (loss: 1.1280620098114014, acc: 0.692307710647583)
[2025-02-17 16:38:49,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:49,440][root][INFO] - Training Epoch: 1/2, step 1915/107898 completed (loss: 0.44062018394470215, acc: 0.9130434989929199)
[2025-02-17 16:38:49,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:49,747][root][INFO] - Training Epoch: 1/2, step 1916/107898 completed (loss: 0.6210013031959534, acc: 0.6666666865348816)
[2025-02-17 16:38:49,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:50,076][root][INFO] - Training Epoch: 1/2, step 1917/107898 completed (loss: 0.9394371509552002, acc: 0.5)
[2025-02-17 16:38:50,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:50,433][root][INFO] - Training Epoch: 1/2, step 1918/107898 completed (loss: 1.052008867263794, acc: 0.5)
[2025-02-17 16:38:50,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:50,755][root][INFO] - Training Epoch: 1/2, step 1919/107898 completed (loss: 2.8054487705230713, acc: 0.5)
[2025-02-17 16:38:50,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:51,109][root][INFO] - Training Epoch: 1/2, step 1920/107898 completed (loss: 1.0309144258499146, acc: 0.8500000238418579)
[2025-02-17 16:38:51,204][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:51,399][root][INFO] - Training Epoch: 1/2, step 1921/107898 completed (loss: 0.6341986060142517, acc: 0.8717948794364929)
[2025-02-17 16:38:51,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:51,694][root][INFO] - Training Epoch: 1/2, step 1922/107898 completed (loss: 0.5355868935585022, acc: 1.0)
[2025-02-17 16:38:51,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:52,031][root][INFO] - Training Epoch: 1/2, step 1923/107898 completed (loss: 1.3405524492263794, acc: 0.6666666865348816)
[2025-02-17 16:38:52,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:52,359][root][INFO] - Training Epoch: 1/2, step 1924/107898 completed (loss: 1.384704351425171, acc: 0.625)
[2025-02-17 16:38:52,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:52,709][root][INFO] - Training Epoch: 1/2, step 1925/107898 completed (loss: 2.8026132583618164, acc: 0.3636363744735718)
[2025-02-17 16:38:52,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:53,021][root][INFO] - Training Epoch: 1/2, step 1926/107898 completed (loss: 1.4959989786148071, acc: 0.6000000238418579)
[2025-02-17 16:38:53,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:53,324][root][INFO] - Training Epoch: 1/2, step 1927/107898 completed (loss: 0.22321945428848267, acc: 0.875)
[2025-02-17 16:38:53,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:53,616][root][INFO] - Training Epoch: 1/2, step 1928/107898 completed (loss: 0.03147250786423683, acc: 1.0)
[2025-02-17 16:38:53,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:53,912][root][INFO] - Training Epoch: 1/2, step 1929/107898 completed (loss: 1.135714054107666, acc: 0.8666666746139526)
[2025-02-17 16:38:54,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:54,263][root][INFO] - Training Epoch: 1/2, step 1930/107898 completed (loss: 0.4702414572238922, acc: 0.8999999761581421)
[2025-02-17 16:38:54,349][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:54,568][root][INFO] - Training Epoch: 1/2, step 1931/107898 completed (loss: 0.12823541462421417, acc: 1.0)
[2025-02-17 16:38:54,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:54,922][root][INFO] - Training Epoch: 1/2, step 1932/107898 completed (loss: 0.25062257051467896, acc: 0.9333333373069763)
[2025-02-17 16:38:55,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:55,240][root][INFO] - Training Epoch: 1/2, step 1933/107898 completed (loss: 0.6356284618377686, acc: 0.75)
[2025-02-17 16:38:55,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:55,543][root][INFO] - Training Epoch: 1/2, step 1934/107898 completed (loss: 0.4658404290676117, acc: 0.6666666865348816)
[2025-02-17 16:38:55,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:55,832][root][INFO] - Training Epoch: 1/2, step 1935/107898 completed (loss: 0.07092621922492981, acc: 1.0)
[2025-02-17 16:38:55,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:56,119][root][INFO] - Training Epoch: 1/2, step 1936/107898 completed (loss: 1.1353167295455933, acc: 0.7857142686843872)
[2025-02-17 16:38:56,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:56,405][root][INFO] - Training Epoch: 1/2, step 1937/107898 completed (loss: 1.1322236061096191, acc: 0.7666666507720947)
[2025-02-17 16:38:56,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:56,701][root][INFO] - Training Epoch: 1/2, step 1938/107898 completed (loss: 0.539701521396637, acc: 0.9230769276618958)
[2025-02-17 16:38:56,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:57,059][root][INFO] - Training Epoch: 1/2, step 1939/107898 completed (loss: 2.1868765354156494, acc: 0.8333333134651184)
[2025-02-17 16:38:57,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:57,415][root][INFO] - Training Epoch: 1/2, step 1940/107898 completed (loss: 1.9523423910140991, acc: 0.6111111044883728)
[2025-02-17 16:38:57,511][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:57,733][root][INFO] - Training Epoch: 1/2, step 1941/107898 completed (loss: 0.12190474569797516, acc: 1.0)
[2025-02-17 16:38:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:58,086][root][INFO] - Training Epoch: 1/2, step 1942/107898 completed (loss: 0.3787565529346466, acc: 0.9090909361839294)
[2025-02-17 16:38:58,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:58,397][root][INFO] - Training Epoch: 1/2, step 1943/107898 completed (loss: 4.219487190246582, acc: 0.25)
[2025-02-17 16:38:58,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:58,747][root][INFO] - Training Epoch: 1/2, step 1944/107898 completed (loss: 2.6142072677612305, acc: 0.5)
[2025-02-17 16:38:58,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:59,088][root][INFO] - Training Epoch: 1/2, step 1945/107898 completed (loss: 0.5554671883583069, acc: 0.8275862336158752)
[2025-02-17 16:38:59,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:59,455][root][INFO] - Training Epoch: 1/2, step 1946/107898 completed (loss: 0.11478568613529205, acc: 1.0)
[2025-02-17 16:38:59,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:38:59,860][root][INFO] - Training Epoch: 1/2, step 1947/107898 completed (loss: 2.0516769886016846, acc: 0.5)
[2025-02-17 16:38:59,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:00,125][root][INFO] - Training Epoch: 1/2, step 1948/107898 completed (loss: 0.746692419052124, acc: 0.9090909361839294)
[2025-02-17 16:39:00,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:00,468][root][INFO] - Training Epoch: 1/2, step 1949/107898 completed (loss: 1.2384287118911743, acc: 0.800000011920929)
[2025-02-17 16:39:00,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:00,802][root][INFO] - Training Epoch: 1/2, step 1950/107898 completed (loss: 0.11940380185842514, acc: 1.0)
[2025-02-17 16:39:00,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:01,117][root][INFO] - Training Epoch: 1/2, step 1951/107898 completed (loss: 1.928635597229004, acc: 0.800000011920929)
[2025-02-17 16:39:01,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:01,442][root][INFO] - Training Epoch: 1/2, step 1952/107898 completed (loss: 0.8458535075187683, acc: 0.0)
[2025-02-17 16:39:01,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:01,752][root][INFO] - Training Epoch: 1/2, step 1953/107898 completed (loss: 2.7415943145751953, acc: 0.5)
[2025-02-17 16:39:01,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:02,119][root][INFO] - Training Epoch: 1/2, step 1954/107898 completed (loss: 0.026621662080287933, acc: 1.0)
[2025-02-17 16:39:02,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:02,510][root][INFO] - Training Epoch: 1/2, step 1955/107898 completed (loss: 1.6504508256912231, acc: 0.6666666865348816)
[2025-02-17 16:39:02,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:02,802][root][INFO] - Training Epoch: 1/2, step 1956/107898 completed (loss: 0.47335827350616455, acc: 1.0)
[2025-02-17 16:39:02,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:03,163][root][INFO] - Training Epoch: 1/2, step 1957/107898 completed (loss: 3.5399796962738037, acc: 0.5)
[2025-02-17 16:39:03,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:03,490][root][INFO] - Training Epoch: 1/2, step 1958/107898 completed (loss: 0.8627557754516602, acc: 0.8571428656578064)
[2025-02-17 16:39:03,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:03,874][root][INFO] - Training Epoch: 1/2, step 1959/107898 completed (loss: 1.405128002166748, acc: 0.6666666865348816)
[2025-02-17 16:39:03,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:04,208][root][INFO] - Training Epoch: 1/2, step 1960/107898 completed (loss: 0.9220991134643555, acc: 0.6666666865348816)
[2025-02-17 16:39:04,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:04,512][root][INFO] - Training Epoch: 1/2, step 1961/107898 completed (loss: 0.9026061296463013, acc: 0.7142857313156128)
[2025-02-17 16:39:04,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:04,822][root][INFO] - Training Epoch: 1/2, step 1962/107898 completed (loss: 0.6882219910621643, acc: 0.9130434989929199)
[2025-02-17 16:39:04,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:05,134][root][INFO] - Training Epoch: 1/2, step 1963/107898 completed (loss: 2.0554845333099365, acc: 0.7692307829856873)
[2025-02-17 16:39:05,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:05,470][root][INFO] - Training Epoch: 1/2, step 1964/107898 completed (loss: 0.05179484933614731, acc: 1.0)
[2025-02-17 16:39:05,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:05,788][root][INFO] - Training Epoch: 1/2, step 1965/107898 completed (loss: 1.2515283823013306, acc: 0.800000011920929)
[2025-02-17 16:39:05,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:06,134][root][INFO] - Training Epoch: 1/2, step 1966/107898 completed (loss: 2.010921001434326, acc: 0.6428571343421936)
[2025-02-17 16:39:06,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:06,497][root][INFO] - Training Epoch: 1/2, step 1967/107898 completed (loss: 0.7482013702392578, acc: 0.8387096524238586)
[2025-02-17 16:39:06,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:06,817][root][INFO] - Training Epoch: 1/2, step 1968/107898 completed (loss: 3.49348521232605, acc: 0.4000000059604645)
[2025-02-17 16:39:06,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:07,162][root][INFO] - Training Epoch: 1/2, step 1969/107898 completed (loss: 0.7975733280181885, acc: 0.7777777910232544)
[2025-02-17 16:39:07,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:07,509][root][INFO] - Training Epoch: 1/2, step 1970/107898 completed (loss: 0.43465033173561096, acc: 0.9090909361839294)
[2025-02-17 16:39:07,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:07,836][root][INFO] - Training Epoch: 1/2, step 1971/107898 completed (loss: 2.624371290206909, acc: 0.5)
[2025-02-17 16:39:07,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:08,150][root][INFO] - Training Epoch: 1/2, step 1972/107898 completed (loss: 1.538946509361267, acc: 0.6666666865348816)
[2025-02-17 16:39:08,250][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:08,488][root][INFO] - Training Epoch: 1/2, step 1973/107898 completed (loss: 0.01765665039420128, acc: 1.0)
[2025-02-17 16:39:08,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:08,807][root][INFO] - Training Epoch: 1/2, step 1974/107898 completed (loss: 3.5269057750701904, acc: 0.25)
[2025-02-17 16:39:08,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:09,143][root][INFO] - Training Epoch: 1/2, step 1975/107898 completed (loss: 0.21902181208133698, acc: 1.0)
[2025-02-17 16:39:09,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:09,440][root][INFO] - Training Epoch: 1/2, step 1976/107898 completed (loss: 0.09524233639240265, acc: 1.0)
[2025-02-17 16:39:09,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:09,797][root][INFO] - Training Epoch: 1/2, step 1977/107898 completed (loss: 1.293927788734436, acc: 0.7857142686843872)
[2025-02-17 16:39:09,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:10,165][root][INFO] - Training Epoch: 1/2, step 1978/107898 completed (loss: 1.4251188039779663, acc: 0.6666666865348816)
[2025-02-17 16:39:10,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:10,474][root][INFO] - Training Epoch: 1/2, step 1979/107898 completed (loss: 1.1541293859481812, acc: 0.807692289352417)
[2025-02-17 16:39:10,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:10,768][root][INFO] - Training Epoch: 1/2, step 1980/107898 completed (loss: 0.07644940912723541, acc: 1.0)
[2025-02-17 16:39:10,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:11,078][root][INFO] - Training Epoch: 1/2, step 1981/107898 completed (loss: 1.8996973037719727, acc: 0.6666666865348816)
[2025-02-17 16:39:11,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:11,372][root][INFO] - Training Epoch: 1/2, step 1982/107898 completed (loss: 4.133025169372559, acc: 0.3333333432674408)
[2025-02-17 16:39:11,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:11,702][root][INFO] - Training Epoch: 1/2, step 1983/107898 completed (loss: 1.3201628923416138, acc: 0.7142857313156128)
[2025-02-17 16:39:11,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:12,004][root][INFO] - Training Epoch: 1/2, step 1984/107898 completed (loss: 0.06852810829877853, acc: 1.0)
[2025-02-17 16:39:12,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:12,320][root][INFO] - Training Epoch: 1/2, step 1985/107898 completed (loss: 0.38723304867744446, acc: 0.9259259104728699)
[2025-02-17 16:39:12,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:12,607][root][INFO] - Training Epoch: 1/2, step 1986/107898 completed (loss: 2.9795327186584473, acc: 0.5)
[2025-02-17 16:39:12,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:12,935][root][INFO] - Training Epoch: 1/2, step 1987/107898 completed (loss: 2.0175747871398926, acc: 0.5)
[2025-02-17 16:39:13,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:13,241][root][INFO] - Training Epoch: 1/2, step 1988/107898 completed (loss: 2.1803932189941406, acc: 0.75)
[2025-02-17 16:39:13,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:13,553][root][INFO] - Training Epoch: 1/2, step 1989/107898 completed (loss: 0.12920454144477844, acc: 1.0)
[2025-02-17 16:39:13,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:13,896][root][INFO] - Training Epoch: 1/2, step 1990/107898 completed (loss: 0.6388952136039734, acc: 1.0)
[2025-02-17 16:39:14,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:14,237][root][INFO] - Training Epoch: 1/2, step 1991/107898 completed (loss: 0.7130467891693115, acc: 0.800000011920929)
[2025-02-17 16:39:14,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:14,540][root][INFO] - Training Epoch: 1/2, step 1992/107898 completed (loss: 0.014249565079808235, acc: 1.0)
[2025-02-17 16:39:14,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:14,847][root][INFO] - Training Epoch: 1/2, step 1993/107898 completed (loss: 1.4339022636413574, acc: 0.692307710647583)
[2025-02-17 16:39:14,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:15,190][root][INFO] - Training Epoch: 1/2, step 1994/107898 completed (loss: 1.649348258972168, acc: 0.7857142686843872)
[2025-02-17 16:39:15,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:15,516][root][INFO] - Training Epoch: 1/2, step 1995/107898 completed (loss: 1.5828953981399536, acc: 0.695652186870575)
[2025-02-17 16:39:15,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:15,882][root][INFO] - Training Epoch: 1/2, step 1996/107898 completed (loss: 0.6655001044273376, acc: 0.8571428656578064)
[2025-02-17 16:39:15,977][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:16,199][root][INFO] - Training Epoch: 1/2, step 1997/107898 completed (loss: 0.047373607754707336, acc: 1.0)
[2025-02-17 16:39:16,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:16,502][root][INFO] - Training Epoch: 1/2, step 1998/107898 completed (loss: 1.8207672834396362, acc: 0.4285714328289032)
[2025-02-17 16:39:16,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:16,859][root][INFO] - Training Epoch: 1/2, step 1999/107898 completed (loss: 0.01118134893476963, acc: 1.0)
[2025-02-17 16:39:16,971][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:17,207][root][INFO] - Training Epoch: 1/2, step 2000/107898 completed (loss: 2.134223222732544, acc: 0.6666666865348816)
[2025-02-17 16:39:17,321][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:17,558][root][INFO] - Training Epoch: 1/2, step 2001/107898 completed (loss: 0.008316488936543465, acc: 1.0)
[2025-02-17 16:39:17,678][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:17,916][root][INFO] - Training Epoch: 1/2, step 2002/107898 completed (loss: 0.6384068131446838, acc: 0.8666666746139526)
[2025-02-17 16:39:18,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:18,252][root][INFO] - Training Epoch: 1/2, step 2003/107898 completed (loss: 1.2256767749786377, acc: 0.7368420958518982)
[2025-02-17 16:39:18,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:18,574][root][INFO] - Training Epoch: 1/2, step 2004/107898 completed (loss: 0.6610795259475708, acc: 0.8823529481887817)
[2025-02-17 16:39:18,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:18,876][root][INFO] - Training Epoch: 1/2, step 2005/107898 completed (loss: 0.5281808376312256, acc: 0.875)
[2025-02-17 16:39:18,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:19,171][root][INFO] - Training Epoch: 1/2, step 2006/107898 completed (loss: 0.9081559777259827, acc: 0.8333333134651184)
[2025-02-17 16:39:19,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:19,465][root][INFO] - Training Epoch: 1/2, step 2007/107898 completed (loss: 0.6152963638305664, acc: 0.875)
[2025-02-17 16:39:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:19,763][root][INFO] - Training Epoch: 1/2, step 2008/107898 completed (loss: 0.03463936224579811, acc: 1.0)
[2025-02-17 16:39:19,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:20,061][root][INFO] - Training Epoch: 1/2, step 2009/107898 completed (loss: 1.0520238876342773, acc: 0.6666666865348816)
[2025-02-17 16:39:20,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:20,358][root][INFO] - Training Epoch: 1/2, step 2010/107898 completed (loss: 4.08557653427124, acc: 0.5)
[2025-02-17 16:39:20,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:20,666][root][INFO] - Training Epoch: 1/2, step 2011/107898 completed (loss: 0.9388877153396606, acc: 0.8571428656578064)
[2025-02-17 16:39:20,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:20,986][root][INFO] - Training Epoch: 1/2, step 2012/107898 completed (loss: 0.41050782799720764, acc: 0.9473684430122375)
[2025-02-17 16:39:21,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:21,282][root][INFO] - Training Epoch: 1/2, step 2013/107898 completed (loss: 0.2290153056383133, acc: 0.9130434989929199)
[2025-02-17 16:39:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:21,595][root][INFO] - Training Epoch: 1/2, step 2014/107898 completed (loss: 0.26618877053260803, acc: 0.9545454382896423)
[2025-02-17 16:39:21,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:21,893][root][INFO] - Training Epoch: 1/2, step 2015/107898 completed (loss: 0.10170776396989822, acc: 1.0)
[2025-02-17 16:39:21,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:22,191][root][INFO] - Training Epoch: 1/2, step 2016/107898 completed (loss: 0.9293899536132812, acc: 0.0)
[2025-02-17 16:39:22,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:22,488][root][INFO] - Training Epoch: 1/2, step 2017/107898 completed (loss: 0.0491100512444973, acc: 1.0)
[2025-02-17 16:39:22,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:22,779][root][INFO] - Training Epoch: 1/2, step 2018/107898 completed (loss: 0.7032707333564758, acc: 0.8333333134651184)
[2025-02-17 16:39:22,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:23,070][root][INFO] - Training Epoch: 1/2, step 2019/107898 completed (loss: 0.4107535183429718, acc: 1.0)
[2025-02-17 16:39:23,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:23,360][root][INFO] - Training Epoch: 1/2, step 2020/107898 completed (loss: 0.018126871436834335, acc: 1.0)
[2025-02-17 16:39:23,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:23,651][root][INFO] - Training Epoch: 1/2, step 2021/107898 completed (loss: 0.6524838805198669, acc: 1.0)
[2025-02-17 16:39:23,731][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:23,950][root][INFO] - Training Epoch: 1/2, step 2022/107898 completed (loss: 0.22563019394874573, acc: 0.9090909361839294)
[2025-02-17 16:39:24,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:24,303][root][INFO] - Training Epoch: 1/2, step 2023/107898 completed (loss: 1.8691670894622803, acc: 0.6829268336296082)
[2025-02-17 16:39:24,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:24,584][root][INFO] - Training Epoch: 1/2, step 2024/107898 completed (loss: 0.22566106915473938, acc: 1.0)
[2025-02-17 16:39:24,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:24,881][root][INFO] - Training Epoch: 1/2, step 2025/107898 completed (loss: 0.06858495622873306, acc: 1.0)
[2025-02-17 16:39:24,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:25,180][root][INFO] - Training Epoch: 1/2, step 2026/107898 completed (loss: 1.3045016527175903, acc: 0.75)
[2025-02-17 16:39:25,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:25,512][root][INFO] - Training Epoch: 1/2, step 2027/107898 completed (loss: 1.3856488466262817, acc: 0.6666666865348816)
[2025-02-17 16:39:25,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:25,846][root][INFO] - Training Epoch: 1/2, step 2028/107898 completed (loss: 1.6100364923477173, acc: 0.7083333134651184)
[2025-02-17 16:39:25,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:26,176][root][INFO] - Training Epoch: 1/2, step 2029/107898 completed (loss: 0.06671717017889023, acc: 1.0)
[2025-02-17 16:39:26,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:26,508][root][INFO] - Training Epoch: 1/2, step 2030/107898 completed (loss: 0.24574197828769684, acc: 1.0)
[2025-02-17 16:39:26,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:26,814][root][INFO] - Training Epoch: 1/2, step 2031/107898 completed (loss: 0.9907314777374268, acc: 0.6666666865348816)
[2025-02-17 16:39:26,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:27,171][root][INFO] - Training Epoch: 1/2, step 2032/107898 completed (loss: 4.602423191070557, acc: 0.2222222238779068)
[2025-02-17 16:39:27,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:27,496][root][INFO] - Training Epoch: 1/2, step 2033/107898 completed (loss: 4.295690059661865, acc: 0.5)
[2025-02-17 16:39:27,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:27,818][root][INFO] - Training Epoch: 1/2, step 2034/107898 completed (loss: 0.1986096054315567, acc: 0.8181818127632141)
[2025-02-17 16:39:27,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:28,147][root][INFO] - Training Epoch: 1/2, step 2035/107898 completed (loss: 1.4584765434265137, acc: 0.6153846383094788)
[2025-02-17 16:39:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:28,475][root][INFO] - Training Epoch: 1/2, step 2036/107898 completed (loss: 2.7596051692962646, acc: 0.6000000238418579)
[2025-02-17 16:39:28,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:28,800][root][INFO] - Training Epoch: 1/2, step 2037/107898 completed (loss: 0.05089334398508072, acc: 1.0)
[2025-02-17 16:39:28,887][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:29,104][root][INFO] - Training Epoch: 1/2, step 2038/107898 completed (loss: 2.185168504714966, acc: 0.5652173757553101)
[2025-02-17 16:39:29,195][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:29,415][root][INFO] - Training Epoch: 1/2, step 2039/107898 completed (loss: 0.9701628088951111, acc: 0.6666666865348816)
[2025-02-17 16:39:29,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:29,716][root][INFO] - Training Epoch: 1/2, step 2040/107898 completed (loss: 1.7958678007125854, acc: 0.6399999856948853)
[2025-02-17 16:39:29,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:30,065][root][INFO] - Training Epoch: 1/2, step 2041/107898 completed (loss: 0.6128484606742859, acc: 0.8846153616905212)
[2025-02-17 16:39:30,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:30,394][root][INFO] - Training Epoch: 1/2, step 2042/107898 completed (loss: 1.6242692470550537, acc: 0.6842105388641357)
[2025-02-17 16:39:30,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:30,709][root][INFO] - Training Epoch: 1/2, step 2043/107898 completed (loss: 0.7638702392578125, acc: 0.800000011920929)
[2025-02-17 16:39:30,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:31,007][root][INFO] - Training Epoch: 1/2, step 2044/107898 completed (loss: 0.9942389130592346, acc: 0.8181818127632141)
[2025-02-17 16:39:31,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:31,332][root][INFO] - Training Epoch: 1/2, step 2045/107898 completed (loss: 0.4587264060974121, acc: 1.0)
[2025-02-17 16:39:31,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:31,630][root][INFO] - Training Epoch: 1/2, step 2046/107898 completed (loss: 2.935635566711426, acc: 0.5555555820465088)
[2025-02-17 16:39:31,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:31,899][root][INFO] - Training Epoch: 1/2, step 2047/107898 completed (loss: 0.5524536967277527, acc: 0.8571428656578064)
[2025-02-17 16:39:31,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:32,205][root][INFO] - Training Epoch: 1/2, step 2048/107898 completed (loss: 0.034551434218883514, acc: 1.0)
[2025-02-17 16:39:32,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:32,567][root][INFO] - Training Epoch: 1/2, step 2049/107898 completed (loss: 0.5657926201820374, acc: 0.9285714030265808)
[2025-02-17 16:39:32,656][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:32,866][root][INFO] - Training Epoch: 1/2, step 2050/107898 completed (loss: 0.6832945942878723, acc: 0.9285714030265808)
[2025-02-17 16:39:32,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:33,212][root][INFO] - Training Epoch: 1/2, step 2051/107898 completed (loss: 0.05744315683841705, acc: 1.0)
[2025-02-17 16:39:33,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:33,550][root][INFO] - Training Epoch: 1/2, step 2052/107898 completed (loss: 0.7428363561630249, acc: 0.8518518805503845)
[2025-02-17 16:39:33,671][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:33,894][root][INFO] - Training Epoch: 1/2, step 2053/107898 completed (loss: 0.4305669367313385, acc: 0.9230769276618958)
[2025-02-17 16:39:33,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:34,196][root][INFO] - Training Epoch: 1/2, step 2054/107898 completed (loss: 0.18411965668201447, acc: 0.95652174949646)
[2025-02-17 16:39:34,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:34,484][root][INFO] - Training Epoch: 1/2, step 2055/107898 completed (loss: 0.4176020920276642, acc: 0.8666666746139526)
[2025-02-17 16:39:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:34,821][root][INFO] - Training Epoch: 1/2, step 2056/107898 completed (loss: 0.5516721606254578, acc: 0.8947368264198303)
[2025-02-17 16:39:34,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:35,130][root][INFO] - Training Epoch: 1/2, step 2057/107898 completed (loss: 0.6851348876953125, acc: 0.8666666746139526)
[2025-02-17 16:39:35,250][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:35,514][root][INFO] - Training Epoch: 1/2, step 2058/107898 completed (loss: 0.11452478170394897, acc: 1.0)
[2025-02-17 16:39:35,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:35,880][root][INFO] - Training Epoch: 1/2, step 2059/107898 completed (loss: 1.8009116649627686, acc: 0.6129032373428345)
[2025-02-17 16:39:35,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:36,228][root][INFO] - Training Epoch: 1/2, step 2060/107898 completed (loss: 0.9369122982025146, acc: 0.7222222089767456)
[2025-02-17 16:39:36,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:36,554][root][INFO] - Training Epoch: 1/2, step 2061/107898 completed (loss: 1.1880024671554565, acc: 0.7777777910232544)
[2025-02-17 16:39:36,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:36,891][root][INFO] - Training Epoch: 1/2, step 2062/107898 completed (loss: 0.5945712924003601, acc: 0.8947368264198303)
[2025-02-17 16:39:36,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:37,212][root][INFO] - Training Epoch: 1/2, step 2063/107898 completed (loss: 0.6180495023727417, acc: 0.84375)
[2025-02-17 16:39:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:37,563][root][INFO] - Training Epoch: 1/2, step 2064/107898 completed (loss: 0.49541428685188293, acc: 0.9333333373069763)
[2025-02-17 16:39:37,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:37,889][root][INFO] - Training Epoch: 1/2, step 2065/107898 completed (loss: 1.0130603313446045, acc: 0.6666666865348816)
[2025-02-17 16:39:37,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:38,234][root][INFO] - Training Epoch: 1/2, step 2066/107898 completed (loss: 2.774425506591797, acc: 0.5)
[2025-02-17 16:39:38,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:38,586][root][INFO] - Training Epoch: 1/2, step 2067/107898 completed (loss: 0.5490670204162598, acc: 0.5)
[2025-02-17 16:39:38,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:38,923][root][INFO] - Training Epoch: 1/2, step 2068/107898 completed (loss: 1.2340846061706543, acc: 0.6000000238418579)
[2025-02-17 16:39:39,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:39,229][root][INFO] - Training Epoch: 1/2, step 2069/107898 completed (loss: 1.316680669784546, acc: 0.6666666865348816)
[2025-02-17 16:39:39,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:39,550][root][INFO] - Training Epoch: 1/2, step 2070/107898 completed (loss: 1.843430757522583, acc: 0.800000011920929)
[2025-02-17 16:39:39,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:39,856][root][INFO] - Training Epoch: 1/2, step 2071/107898 completed (loss: 0.09402219951152802, acc: 1.0)
[2025-02-17 16:39:39,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:40,154][root][INFO] - Training Epoch: 1/2, step 2072/107898 completed (loss: 0.2724418640136719, acc: 1.0)
[2025-02-17 16:39:40,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:40,499][root][INFO] - Training Epoch: 1/2, step 2073/107898 completed (loss: 0.4140027165412903, acc: 0.939393937587738)
[2025-02-17 16:39:40,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:40,810][root][INFO] - Training Epoch: 1/2, step 2074/107898 completed (loss: 0.013028081506490707, acc: 1.0)
[2025-02-17 16:39:40,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:41,148][root][INFO] - Training Epoch: 1/2, step 2075/107898 completed (loss: 0.5543660521507263, acc: 0.8260869383811951)
[2025-02-17 16:39:41,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:41,461][root][INFO] - Training Epoch: 1/2, step 2076/107898 completed (loss: 0.4146690368652344, acc: 0.8799999952316284)
[2025-02-17 16:39:41,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:41,749][root][INFO] - Training Epoch: 1/2, step 2077/107898 completed (loss: 0.9039168357849121, acc: 0.8125)
[2025-02-17 16:39:41,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:42,040][root][INFO] - Training Epoch: 1/2, step 2078/107898 completed (loss: 0.18420016765594482, acc: 1.0)
[2025-02-17 16:39:42,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:42,332][root][INFO] - Training Epoch: 1/2, step 2079/107898 completed (loss: 0.4758860468864441, acc: 0.9473684430122375)
[2025-02-17 16:39:42,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:42,640][root][INFO] - Training Epoch: 1/2, step 2080/107898 completed (loss: 1.7494268417358398, acc: 0.5)
[2025-02-17 16:39:42,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:42,931][root][INFO] - Training Epoch: 1/2, step 2081/107898 completed (loss: 0.9778454303741455, acc: 0.0)
[2025-02-17 16:39:43,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:43,225][root][INFO] - Training Epoch: 1/2, step 2082/107898 completed (loss: 1.9241803884506226, acc: 0.5)
[2025-02-17 16:39:43,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:43,524][root][INFO] - Training Epoch: 1/2, step 2083/107898 completed (loss: 3.3738057613372803, acc: 0.3333333432674408)
[2025-02-17 16:39:43,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:43,821][root][INFO] - Training Epoch: 1/2, step 2084/107898 completed (loss: 0.022036857903003693, acc: 1.0)
[2025-02-17 16:39:43,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:44,146][root][INFO] - Training Epoch: 1/2, step 2085/107898 completed (loss: 0.014313743449747562, acc: 1.0)
[2025-02-17 16:39:44,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:44,471][root][INFO] - Training Epoch: 1/2, step 2086/107898 completed (loss: 1.409898042678833, acc: 0.6428571343421936)
[2025-02-17 16:39:44,585][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:44,816][root][INFO] - Training Epoch: 1/2, step 2087/107898 completed (loss: 0.14168110489845276, acc: 1.0)
[2025-02-17 16:39:44,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:45,147][root][INFO] - Training Epoch: 1/2, step 2088/107898 completed (loss: 0.04541808366775513, acc: 1.0)
[2025-02-17 16:39:45,250][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:45,480][root][INFO] - Training Epoch: 1/2, step 2089/107898 completed (loss: 5.606132507324219, acc: 0.25)
[2025-02-17 16:39:45,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:45,781][root][INFO] - Training Epoch: 1/2, step 2090/107898 completed (loss: 2.1432600021362305, acc: 0.3333333432674408)
[2025-02-17 16:39:45,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:46,068][root][INFO] - Training Epoch: 1/2, step 2091/107898 completed (loss: 0.3215099573135376, acc: 1.0)
[2025-02-17 16:39:46,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:46,355][root][INFO] - Training Epoch: 1/2, step 2092/107898 completed (loss: 0.0059774694964289665, acc: 1.0)
[2025-02-17 16:39:46,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:46,664][root][INFO] - Training Epoch: 1/2, step 2093/107898 completed (loss: 0.29573890566825867, acc: 0.9230769276618958)
[2025-02-17 16:39:46,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:46,967][root][INFO] - Training Epoch: 1/2, step 2094/107898 completed (loss: 0.2840239703655243, acc: 0.8888888955116272)
[2025-02-17 16:39:47,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:47,252][root][INFO] - Training Epoch: 1/2, step 2095/107898 completed (loss: 0.9397855997085571, acc: 0.5)
[2025-02-17 16:39:47,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:47,577][root][INFO] - Training Epoch: 1/2, step 2096/107898 completed (loss: 0.016032062470912933, acc: 1.0)
[2025-02-17 16:39:47,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:47,896][root][INFO] - Training Epoch: 1/2, step 2097/107898 completed (loss: 2.140230655670166, acc: 0.7333333492279053)
[2025-02-17 16:39:47,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:48,244][root][INFO] - Training Epoch: 1/2, step 2098/107898 completed (loss: 0.09409674257040024, acc: 1.0)
[2025-02-17 16:39:48,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:48,585][root][INFO] - Training Epoch: 1/2, step 2099/107898 completed (loss: 0.8795261383056641, acc: 0.9230769276618958)
[2025-02-17 16:39:48,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:48,880][root][INFO] - Training Epoch: 1/2, step 2100/107898 completed (loss: 0.016518859192728996, acc: 1.0)
[2025-02-17 16:39:48,957][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:49,173][root][INFO] - Training Epoch: 1/2, step 2101/107898 completed (loss: 0.069551981985569, acc: 1.0)
[2025-02-17 16:39:49,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:49,496][root][INFO] - Training Epoch: 1/2, step 2102/107898 completed (loss: 0.8272059559822083, acc: 0.8571428656578064)
[2025-02-17 16:39:49,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:49,804][root][INFO] - Training Epoch: 1/2, step 2103/107898 completed (loss: 0.4770251214504242, acc: 0.9166666865348816)
[2025-02-17 16:39:49,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:50,096][root][INFO] - Training Epoch: 1/2, step 2104/107898 completed (loss: 3.7430145740509033, acc: 0.1666666716337204)
[2025-02-17 16:39:50,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:50,369][root][INFO] - Training Epoch: 1/2, step 2105/107898 completed (loss: 1.2135051488876343, acc: 0.7142857313156128)
[2025-02-17 16:39:50,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:50,658][root][INFO] - Training Epoch: 1/2, step 2106/107898 completed (loss: 0.47627973556518555, acc: 1.0)
[2025-02-17 16:39:50,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:50,996][root][INFO] - Training Epoch: 1/2, step 2107/107898 completed (loss: 0.8090877532958984, acc: 0.8947368264198303)
[2025-02-17 16:39:51,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:51,313][root][INFO] - Training Epoch: 1/2, step 2108/107898 completed (loss: 0.28990206122398376, acc: 0.9444444179534912)
[2025-02-17 16:39:51,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:51,652][root][INFO] - Training Epoch: 1/2, step 2109/107898 completed (loss: 0.024750854820013046, acc: 1.0)
[2025-02-17 16:39:51,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:51,967][root][INFO] - Training Epoch: 1/2, step 2110/107898 completed (loss: 0.0047582173720002174, acc: 1.0)
[2025-02-17 16:39:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:52,287][root][INFO] - Training Epoch: 1/2, step 2111/107898 completed (loss: 1.3876608610153198, acc: 0.5)
[2025-02-17 16:39:52,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:52,611][root][INFO] - Training Epoch: 1/2, step 2112/107898 completed (loss: 0.8586483597755432, acc: 0.8148148059844971)
[2025-02-17 16:39:52,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:52,925][root][INFO] - Training Epoch: 1/2, step 2113/107898 completed (loss: 0.1599217802286148, acc: 1.0)
[2025-02-17 16:39:53,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:53,236][root][INFO] - Training Epoch: 1/2, step 2114/107898 completed (loss: 6.756421089172363, acc: 0.25)
[2025-02-17 16:39:53,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:53,553][root][INFO] - Training Epoch: 1/2, step 2115/107898 completed (loss: 0.25039204955101013, acc: 0.9130434989929199)
[2025-02-17 16:39:53,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:53,838][root][INFO] - Training Epoch: 1/2, step 2116/107898 completed (loss: 0.32827162742614746, acc: 0.9473684430122375)
[2025-02-17 16:39:53,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:54,185][root][INFO] - Training Epoch: 1/2, step 2117/107898 completed (loss: 0.20672698318958282, acc: 0.8999999761581421)
[2025-02-17 16:39:54,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:54,512][root][INFO] - Training Epoch: 1/2, step 2118/107898 completed (loss: 0.7247024774551392, acc: 0.8571428656578064)
[2025-02-17 16:39:54,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:54,822][root][INFO] - Training Epoch: 1/2, step 2119/107898 completed (loss: 0.7385724186897278, acc: 0.8333333134651184)
[2025-02-17 16:39:54,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:55,126][root][INFO] - Training Epoch: 1/2, step 2120/107898 completed (loss: 0.7886068820953369, acc: 0.75)
[2025-02-17 16:39:55,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:55,429][root][INFO] - Training Epoch: 1/2, step 2121/107898 completed (loss: 0.8298611044883728, acc: 0.7857142686843872)
[2025-02-17 16:39:55,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:55,743][root][INFO] - Training Epoch: 1/2, step 2122/107898 completed (loss: 3.024627447128296, acc: 0.25)
[2025-02-17 16:39:55,846][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:56,095][root][INFO] - Training Epoch: 1/2, step 2123/107898 completed (loss: 0.13645313680171967, acc: 1.0)
[2025-02-17 16:39:56,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:56,424][root][INFO] - Training Epoch: 1/2, step 2124/107898 completed (loss: 2.1178712844848633, acc: 0.6666666865348816)
[2025-02-17 16:39:56,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:56,770][root][INFO] - Training Epoch: 1/2, step 2125/107898 completed (loss: 0.8614199161529541, acc: 0.7666666507720947)
[2025-02-17 16:39:56,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:57,128][root][INFO] - Training Epoch: 1/2, step 2126/107898 completed (loss: 0.19235549867153168, acc: 1.0)
[2025-02-17 16:39:57,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:57,446][root][INFO] - Training Epoch: 1/2, step 2127/107898 completed (loss: 1.1611268520355225, acc: 0.7272727489471436)
[2025-02-17 16:39:57,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:57,768][root][INFO] - Training Epoch: 1/2, step 2128/107898 completed (loss: 0.7284337878227234, acc: 0.6666666865348816)
[2025-02-17 16:39:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:58,083][root][INFO] - Training Epoch: 1/2, step 2129/107898 completed (loss: 0.00907127559185028, acc: 1.0)
[2025-02-17 16:39:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:58,443][root][INFO] - Training Epoch: 1/2, step 2130/107898 completed (loss: 1.9768822193145752, acc: 0.7058823704719543)
[2025-02-17 16:39:58,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:58,780][root][INFO] - Training Epoch: 1/2, step 2131/107898 completed (loss: 0.1941850483417511, acc: 1.0)
[2025-02-17 16:39:58,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:59,114][root][INFO] - Training Epoch: 1/2, step 2132/107898 completed (loss: 2.392969846725464, acc: 0.5)
[2025-02-17 16:39:59,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:59,429][root][INFO] - Training Epoch: 1/2, step 2133/107898 completed (loss: 3.0627784729003906, acc: 0.4444444477558136)
[2025-02-17 16:39:59,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:59,683][root][INFO] - Training Epoch: 1/2, step 2134/107898 completed (loss: 3.6012136936187744, acc: 0.1428571492433548)
[2025-02-17 16:39:59,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:39:59,964][root][INFO] - Training Epoch: 1/2, step 2135/107898 completed (loss: 1.1427608728408813, acc: 1.0)
[2025-02-17 16:40:00,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:00,273][root][INFO] - Training Epoch: 1/2, step 2136/107898 completed (loss: 0.9262570142745972, acc: 0.782608687877655)
[2025-02-17 16:40:00,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:00,640][root][INFO] - Training Epoch: 1/2, step 2137/107898 completed (loss: 0.5846768617630005, acc: 0.8571428656578064)
[2025-02-17 16:40:00,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:00,983][root][INFO] - Training Epoch: 1/2, step 2138/107898 completed (loss: 1.3699101209640503, acc: 0.6666666865348816)
[2025-02-17 16:40:01,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:01,319][root][INFO] - Training Epoch: 1/2, step 2139/107898 completed (loss: 0.08207428455352783, acc: 1.0)
[2025-02-17 16:40:01,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:01,677][root][INFO] - Training Epoch: 1/2, step 2140/107898 completed (loss: 0.47834065556526184, acc: 0.8421052694320679)
[2025-02-17 16:40:01,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:02,010][root][INFO] - Training Epoch: 1/2, step 2141/107898 completed (loss: 1.563701868057251, acc: 1.0)
[2025-02-17 16:40:02,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:02,364][root][INFO] - Training Epoch: 1/2, step 2142/107898 completed (loss: 0.5582918524742126, acc: 0.9166666865348816)
[2025-02-17 16:40:02,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:02,679][root][INFO] - Training Epoch: 1/2, step 2143/107898 completed (loss: 1.6023505926132202, acc: 0.75)
[2025-02-17 16:40:02,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:03,021][root][INFO] - Training Epoch: 1/2, step 2144/107898 completed (loss: 1.0841964483261108, acc: 0.7894737124443054)
[2025-02-17 16:40:03,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:03,344][root][INFO] - Training Epoch: 1/2, step 2145/107898 completed (loss: 0.9065344929695129, acc: 0.800000011920929)
[2025-02-17 16:40:03,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:03,663][root][INFO] - Training Epoch: 1/2, step 2146/107898 completed (loss: 3.2217648029327393, acc: 0.20000000298023224)
[2025-02-17 16:40:03,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:03,998][root][INFO] - Training Epoch: 1/2, step 2147/107898 completed (loss: 0.3883795440196991, acc: 0.8928571343421936)
[2025-02-17 16:40:04,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:04,352][root][INFO] - Training Epoch: 1/2, step 2148/107898 completed (loss: 0.05858123302459717, acc: 1.0)
[2025-02-17 16:40:04,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:04,682][root][INFO] - Training Epoch: 1/2, step 2149/107898 completed (loss: 3.1436142921447754, acc: 0.2857142984867096)
[2025-02-17 16:40:04,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:05,030][root][INFO] - Training Epoch: 1/2, step 2150/107898 completed (loss: 1.0977351665496826, acc: 0.7307692170143127)
[2025-02-17 16:40:05,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:05,339][root][INFO] - Training Epoch: 1/2, step 2151/107898 completed (loss: 1.5772104263305664, acc: 0.6666666865348816)
[2025-02-17 16:40:05,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:05,633][root][INFO] - Training Epoch: 1/2, step 2152/107898 completed (loss: 2.830811023712158, acc: 0.4285714328289032)
[2025-02-17 16:40:05,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:05,965][root][INFO] - Training Epoch: 1/2, step 2153/107898 completed (loss: 0.5235870480537415, acc: 0.8947368264198303)
[2025-02-17 16:40:06,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:06,295][root][INFO] - Training Epoch: 1/2, step 2154/107898 completed (loss: 1.3549885749816895, acc: 0.7692307829856873)
[2025-02-17 16:40:06,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:06,592][root][INFO] - Training Epoch: 1/2, step 2155/107898 completed (loss: 2.1625564098358154, acc: 0.695652186870575)
[2025-02-17 16:40:06,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:06,873][root][INFO] - Training Epoch: 1/2, step 2156/107898 completed (loss: 0.6832640171051025, acc: 0.6666666865348816)
[2025-02-17 16:40:06,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:07,195][root][INFO] - Training Epoch: 1/2, step 2157/107898 completed (loss: 1.0307655334472656, acc: 0.7954545617103577)
[2025-02-17 16:40:07,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:07,509][root][INFO] - Training Epoch: 1/2, step 2158/107898 completed (loss: 0.48886609077453613, acc: 1.0)
[2025-02-17 16:40:07,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:07,817][root][INFO] - Training Epoch: 1/2, step 2159/107898 completed (loss: 1.0654247999191284, acc: 0.8518518805503845)
[2025-02-17 16:40:07,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:08,168][root][INFO] - Training Epoch: 1/2, step 2160/107898 completed (loss: 1.642930269241333, acc: 0.7333333492279053)
[2025-02-17 16:40:08,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:08,491][root][INFO] - Training Epoch: 1/2, step 2161/107898 completed (loss: 0.05414080247282982, acc: 1.0)
[2025-02-17 16:40:08,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:08,802][root][INFO] - Training Epoch: 1/2, step 2162/107898 completed (loss: 1.9803974628448486, acc: 0.5714285969734192)
[2025-02-17 16:40:08,887][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:09,105][root][INFO] - Training Epoch: 1/2, step 2163/107898 completed (loss: 1.133705496788025, acc: 0.692307710647583)
[2025-02-17 16:40:09,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:09,411][root][INFO] - Training Epoch: 1/2, step 2164/107898 completed (loss: 0.08553940057754517, acc: 1.0)
[2025-02-17 16:40:09,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:09,705][root][INFO] - Training Epoch: 1/2, step 2165/107898 completed (loss: 0.13902735710144043, acc: 1.0)
[2025-02-17 16:40:09,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:10,036][root][INFO] - Training Epoch: 1/2, step 2166/107898 completed (loss: 1.1439918279647827, acc: 0.7692307829856873)
[2025-02-17 16:40:10,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:10,346][root][INFO] - Training Epoch: 1/2, step 2167/107898 completed (loss: 1.488002061843872, acc: 0.8666666746139526)
[2025-02-17 16:40:10,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:10,652][root][INFO] - Training Epoch: 1/2, step 2168/107898 completed (loss: 0.1701776534318924, acc: 1.0)
[2025-02-17 16:40:10,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:10,980][root][INFO] - Training Epoch: 1/2, step 2169/107898 completed (loss: 2.804845094680786, acc: 0.4444444477558136)
[2025-02-17 16:40:11,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:11,322][root][INFO] - Training Epoch: 1/2, step 2170/107898 completed (loss: 3.3109989166259766, acc: 0.0)
[2025-02-17 16:40:11,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:11,650][root][INFO] - Training Epoch: 1/2, step 2171/107898 completed (loss: 0.1103227436542511, acc: 1.0)
[2025-02-17 16:40:11,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:11,987][root][INFO] - Training Epoch: 1/2, step 2172/107898 completed (loss: 1.80788254737854, acc: 0.625)
[2025-02-17 16:40:12,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:12,292][root][INFO] - Training Epoch: 1/2, step 2173/107898 completed (loss: 1.759289264678955, acc: 0.5)
[2025-02-17 16:40:12,394][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:12,626][root][INFO] - Training Epoch: 1/2, step 2174/107898 completed (loss: 1.5402435064315796, acc: 0.6363636255264282)
[2025-02-17 16:40:12,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:12,950][root][INFO] - Training Epoch: 1/2, step 2175/107898 completed (loss: 1.0569756031036377, acc: 0.7727272510528564)
[2025-02-17 16:40:13,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:13,240][root][INFO] - Training Epoch: 1/2, step 2176/107898 completed (loss: 1.90854811668396, acc: 0.6000000238418579)
[2025-02-17 16:40:13,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:13,541][root][INFO] - Training Epoch: 1/2, step 2177/107898 completed (loss: 3.1858956813812256, acc: 0.5)
[2025-02-17 16:40:13,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:13,849][root][INFO] - Training Epoch: 1/2, step 2178/107898 completed (loss: 0.13413351774215698, acc: 1.0)
[2025-02-17 16:40:13,925][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:14,137][root][INFO] - Training Epoch: 1/2, step 2179/107898 completed (loss: 1.28920316696167, acc: 0.6666666865348816)
[2025-02-17 16:40:14,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:14,432][root][INFO] - Training Epoch: 1/2, step 2180/107898 completed (loss: 1.6749683618545532, acc: 0.6111111044883728)
[2025-02-17 16:40:14,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:14,783][root][INFO] - Training Epoch: 1/2, step 2181/107898 completed (loss: 1.2777252197265625, acc: 0.699999988079071)
[2025-02-17 16:40:14,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:15,161][root][INFO] - Training Epoch: 1/2, step 2182/107898 completed (loss: 2.402954339981079, acc: 0.3333333432674408)
[2025-02-17 16:40:15,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:15,479][root][INFO] - Training Epoch: 1/2, step 2183/107898 completed (loss: 0.5972569584846497, acc: 0.8823529481887817)
[2025-02-17 16:40:15,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:15,763][root][INFO] - Training Epoch: 1/2, step 2184/107898 completed (loss: 0.17132502794265747, acc: 1.0)
[2025-02-17 16:40:15,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:16,056][root][INFO] - Training Epoch: 1/2, step 2185/107898 completed (loss: 0.6443824768066406, acc: 0.8999999761581421)
[2025-02-17 16:40:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:16,413][root][INFO] - Training Epoch: 1/2, step 2186/107898 completed (loss: 1.3296351432800293, acc: 0.6000000238418579)
[2025-02-17 16:40:16,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:16,702][root][INFO] - Training Epoch: 1/2, step 2187/107898 completed (loss: 1.7570297718048096, acc: 0.6470588445663452)
[2025-02-17 16:40:16,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:16,988][root][INFO] - Training Epoch: 1/2, step 2188/107898 completed (loss: 0.1478441059589386, acc: 1.0)
[2025-02-17 16:40:17,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:17,306][root][INFO] - Training Epoch: 1/2, step 2189/107898 completed (loss: 0.27496108412742615, acc: 0.9411764740943909)
[2025-02-17 16:40:17,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:17,613][root][INFO] - Training Epoch: 1/2, step 2190/107898 completed (loss: 4.477217674255371, acc: 0.22727273404598236)
[2025-02-17 16:40:17,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:17,913][root][INFO] - Training Epoch: 1/2, step 2191/107898 completed (loss: 0.008462817408144474, acc: 1.0)
[2025-02-17 16:40:18,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:18,211][root][INFO] - Training Epoch: 1/2, step 2192/107898 completed (loss: 0.4857012927532196, acc: 0.8666666746139526)
[2025-02-17 16:40:18,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:18,555][root][INFO] - Training Epoch: 1/2, step 2193/107898 completed (loss: 0.4243670403957367, acc: 0.9130434989929199)
[2025-02-17 16:40:18,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:18,923][root][INFO] - Training Epoch: 1/2, step 2194/107898 completed (loss: 0.5237406492233276, acc: 0.5)
[2025-02-17 16:40:19,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:19,282][root][INFO] - Training Epoch: 1/2, step 2195/107898 completed (loss: 1.443413257598877, acc: 0.5)
[2025-02-17 16:40:19,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:19,598][root][INFO] - Training Epoch: 1/2, step 2196/107898 completed (loss: 0.2878386378288269, acc: 0.6666666865348816)
[2025-02-17 16:40:19,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:19,938][root][INFO] - Training Epoch: 1/2, step 2197/107898 completed (loss: 1.5046697854995728, acc: 0.75)
[2025-02-17 16:40:20,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:20,265][root][INFO] - Training Epoch: 1/2, step 2198/107898 completed (loss: 0.6192523837089539, acc: 1.0)
[2025-02-17 16:40:20,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:20,589][root][INFO] - Training Epoch: 1/2, step 2199/107898 completed (loss: 0.2738681137561798, acc: 0.9333333373069763)
[2025-02-17 16:40:20,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:20,877][root][INFO] - Training Epoch: 1/2, step 2200/107898 completed (loss: 1.134714126586914, acc: 0.8333333134651184)
[2025-02-17 16:40:20,959][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:21,179][root][INFO] - Training Epoch: 1/2, step 2201/107898 completed (loss: 0.36056557297706604, acc: 0.8888888955116272)
[2025-02-17 16:40:21,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:21,542][root][INFO] - Training Epoch: 1/2, step 2202/107898 completed (loss: 0.5230206847190857, acc: 0.9583333134651184)
[2025-02-17 16:40:21,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:21,860][root][INFO] - Training Epoch: 1/2, step 2203/107898 completed (loss: 0.7067081332206726, acc: 0.8333333134651184)
[2025-02-17 16:40:21,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:22,209][root][INFO] - Training Epoch: 1/2, step 2204/107898 completed (loss: 1.2729195356369019, acc: 0.7777777910232544)
[2025-02-17 16:40:22,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:22,558][root][INFO] - Training Epoch: 1/2, step 2205/107898 completed (loss: 0.09902042150497437, acc: 1.0)
[2025-02-17 16:40:22,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:22,885][root][INFO] - Training Epoch: 1/2, step 2206/107898 completed (loss: 0.5788178443908691, acc: 1.0)
[2025-02-17 16:40:22,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:23,218][root][INFO] - Training Epoch: 1/2, step 2207/107898 completed (loss: 1.5098286867141724, acc: 0.7272727489471436)
[2025-02-17 16:40:23,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:23,520][root][INFO] - Training Epoch: 1/2, step 2208/107898 completed (loss: 0.016029715538024902, acc: 1.0)
[2025-02-17 16:40:23,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:23,876][root][INFO] - Training Epoch: 1/2, step 2209/107898 completed (loss: 1.04888117313385, acc: 0.8571428656578064)
[2025-02-17 16:40:23,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:24,246][root][INFO] - Training Epoch: 1/2, step 2210/107898 completed (loss: 1.4315658807754517, acc: 0.6666666865348816)
[2025-02-17 16:40:24,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:24,605][root][INFO] - Training Epoch: 1/2, step 2211/107898 completed (loss: 0.2518765330314636, acc: 1.0)
[2025-02-17 16:40:24,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:24,938][root][INFO] - Training Epoch: 1/2, step 2212/107898 completed (loss: 0.14477179944515228, acc: 1.0)
[2025-02-17 16:40:25,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:25,296][root][INFO] - Training Epoch: 1/2, step 2213/107898 completed (loss: 0.6661816835403442, acc: 0.8333333134651184)
[2025-02-17 16:40:25,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:25,647][root][INFO] - Training Epoch: 1/2, step 2214/107898 completed (loss: 1.16623854637146, acc: 0.7407407164573669)
[2025-02-17 16:40:25,751][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:25,982][root][INFO] - Training Epoch: 1/2, step 2215/107898 completed (loss: 3.1514523029327393, acc: 0.5)
[2025-02-17 16:40:26,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:26,287][root][INFO] - Training Epoch: 1/2, step 2216/107898 completed (loss: 1.1517237424850464, acc: 0.5)
[2025-02-17 16:40:26,373][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:26,595][root][INFO] - Training Epoch: 1/2, step 2217/107898 completed (loss: 1.9523532390594482, acc: 0.5)
[2025-02-17 16:40:26,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:26,941][root][INFO] - Training Epoch: 1/2, step 2218/107898 completed (loss: 0.12243068963289261, acc: 0.9545454382896423)
[2025-02-17 16:40:27,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:27,253][root][INFO] - Training Epoch: 1/2, step 2219/107898 completed (loss: 1.2218831777572632, acc: 0.800000011920929)
[2025-02-17 16:40:27,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:27,599][root][INFO] - Training Epoch: 1/2, step 2220/107898 completed (loss: 1.1341747045516968, acc: 0.800000011920929)
[2025-02-17 16:40:27,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:27,922][root][INFO] - Training Epoch: 1/2, step 2221/107898 completed (loss: 0.1296999156475067, acc: 0.9411764740943909)
[2025-02-17 16:40:28,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:28,204][root][INFO] - Training Epoch: 1/2, step 2222/107898 completed (loss: 0.26108959317207336, acc: 0.9285714030265808)
[2025-02-17 16:40:28,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:28,500][root][INFO] - Training Epoch: 1/2, step 2223/107898 completed (loss: 0.11201059073209763, acc: 1.0)
[2025-02-17 16:40:28,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:28,828][root][INFO] - Training Epoch: 1/2, step 2224/107898 completed (loss: 1.526228427886963, acc: 0.6470588445663452)
[2025-02-17 16:40:28,912][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:29,134][root][INFO] - Training Epoch: 1/2, step 2225/107898 completed (loss: 0.7066108584403992, acc: 0.8636363744735718)
[2025-02-17 16:40:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:29,428][root][INFO] - Training Epoch: 1/2, step 2226/107898 completed (loss: 0.4590892493724823, acc: 0.9411764740943909)
[2025-02-17 16:40:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:29,775][root][INFO] - Training Epoch: 1/2, step 2227/107898 completed (loss: 1.1783498525619507, acc: 0.761904776096344)
[2025-02-17 16:40:29,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:30,092][root][INFO] - Training Epoch: 1/2, step 2228/107898 completed (loss: 1.5335856676101685, acc: 0.6000000238418579)
[2025-02-17 16:40:30,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:30,383][root][INFO] - Training Epoch: 1/2, step 2229/107898 completed (loss: 0.24046079814434052, acc: 1.0)
[2025-02-17 16:40:30,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:30,648][root][INFO] - Training Epoch: 1/2, step 2230/107898 completed (loss: 2.5601108074188232, acc: 0.0)
[2025-02-17 16:40:30,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:30,969][root][INFO] - Training Epoch: 1/2, step 2231/107898 completed (loss: 0.3966503143310547, acc: 1.0)
[2025-02-17 16:40:31,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:31,261][root][INFO] - Training Epoch: 1/2, step 2232/107898 completed (loss: 0.6194804906845093, acc: 0.7857142686843872)
[2025-02-17 16:40:31,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:31,579][root][INFO] - Training Epoch: 1/2, step 2233/107898 completed (loss: 0.6376366019248962, acc: 0.8888888955116272)
[2025-02-17 16:40:31,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:31,879][root][INFO] - Training Epoch: 1/2, step 2234/107898 completed (loss: 0.3273339569568634, acc: 0.875)
[2025-02-17 16:40:31,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:32,210][root][INFO] - Training Epoch: 1/2, step 2235/107898 completed (loss: 1.4130984544754028, acc: 0.8333333134651184)
[2025-02-17 16:40:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:32,537][root][INFO] - Training Epoch: 1/2, step 2236/107898 completed (loss: 0.42598268389701843, acc: 0.8461538553237915)
[2025-02-17 16:40:32,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:32,868][root][INFO] - Training Epoch: 1/2, step 2237/107898 completed (loss: 1.0595086812973022, acc: 0.5)
[2025-02-17 16:40:32,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:33,196][root][INFO] - Training Epoch: 1/2, step 2238/107898 completed (loss: 0.27038612961769104, acc: 0.949999988079071)
[2025-02-17 16:40:33,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:33,516][root][INFO] - Training Epoch: 1/2, step 2239/107898 completed (loss: 1.0417708158493042, acc: 0.8461538553237915)
[2025-02-17 16:40:33,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:33,823][root][INFO] - Training Epoch: 1/2, step 2240/107898 completed (loss: 0.09650853276252747, acc: 1.0)
[2025-02-17 16:40:33,905][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:34,120][root][INFO] - Training Epoch: 1/2, step 2241/107898 completed (loss: 1.103900671005249, acc: 0.7058823704719543)
[2025-02-17 16:40:34,206][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:34,378][root][INFO] - Training Epoch: 1/2, step 2242/107898 completed (loss: 1.091835379600525, acc: 0.8823529481887817)
[2025-02-17 16:40:34,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:34,664][root][INFO] - Training Epoch: 1/2, step 2243/107898 completed (loss: 0.11624882370233536, acc: 1.0)
[2025-02-17 16:40:34,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:35,011][root][INFO] - Training Epoch: 1/2, step 2244/107898 completed (loss: 0.8181883096694946, acc: 0.8387096524238586)
[2025-02-17 16:40:35,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:35,348][root][INFO] - Training Epoch: 1/2, step 2245/107898 completed (loss: 1.2518483400344849, acc: 0.800000011920929)
[2025-02-17 16:40:35,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:35,659][root][INFO] - Training Epoch: 1/2, step 2246/107898 completed (loss: 0.7223842740058899, acc: 0.8333333134651184)
[2025-02-17 16:40:35,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:35,964][root][INFO] - Training Epoch: 1/2, step 2247/107898 completed (loss: 2.958660125732422, acc: 0.6666666865348816)
[2025-02-17 16:40:36,034][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:36,240][root][INFO] - Training Epoch: 1/2, step 2248/107898 completed (loss: 3.2962911128997803, acc: 0.5)
[2025-02-17 16:40:36,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:36,551][root][INFO] - Training Epoch: 1/2, step 2249/107898 completed (loss: 3.4708240032196045, acc: 0.3333333432674408)
[2025-02-17 16:40:36,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:36,895][root][INFO] - Training Epoch: 1/2, step 2250/107898 completed (loss: 0.1417626589536667, acc: 1.0)
[2025-02-17 16:40:36,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:37,205][root][INFO] - Training Epoch: 1/2, step 2251/107898 completed (loss: 2.652505397796631, acc: 0.5185185074806213)
[2025-02-17 16:40:37,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:37,511][root][INFO] - Training Epoch: 1/2, step 2252/107898 completed (loss: 5.416845798492432, acc: 0.25)
[2025-02-17 16:40:37,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:37,846][root][INFO] - Training Epoch: 1/2, step 2253/107898 completed (loss: 0.28238600492477417, acc: 0.9375)
[2025-02-17 16:40:37,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:38,149][root][INFO] - Training Epoch: 1/2, step 2254/107898 completed (loss: 0.8632708191871643, acc: 0.8571428656578064)
[2025-02-17 16:40:38,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:38,445][root][INFO] - Training Epoch: 1/2, step 2255/107898 completed (loss: 3.0221331119537354, acc: 0.5)
[2025-02-17 16:40:38,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:38,804][root][INFO] - Training Epoch: 1/2, step 2256/107898 completed (loss: 1.3490585088729858, acc: 0.7083333134651184)
[2025-02-17 16:40:38,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:39,161][root][INFO] - Training Epoch: 1/2, step 2257/107898 completed (loss: 0.31002116203308105, acc: 1.0)
[2025-02-17 16:40:39,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:39,522][root][INFO] - Training Epoch: 1/2, step 2258/107898 completed (loss: 5.265000820159912, acc: 0.25)
[2025-02-17 16:40:39,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:39,841][root][INFO] - Training Epoch: 1/2, step 2259/107898 completed (loss: 0.9741911888122559, acc: 0.800000011920929)
[2025-02-17 16:40:39,950][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:40,186][root][INFO] - Training Epoch: 1/2, step 2260/107898 completed (loss: 1.7655583620071411, acc: 0.75)
[2025-02-17 16:40:40,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:40,517][root][INFO] - Training Epoch: 1/2, step 2261/107898 completed (loss: 2.2231974601745605, acc: 0.5833333134651184)
[2025-02-17 16:40:40,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:40,830][root][INFO] - Training Epoch: 1/2, step 2262/107898 completed (loss: 2.0035650730133057, acc: 0.7142857313156128)
[2025-02-17 16:40:40,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:41,146][root][INFO] - Training Epoch: 1/2, step 2263/107898 completed (loss: 1.3038347959518433, acc: 0.7692307829856873)
[2025-02-17 16:40:41,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:41,456][root][INFO] - Training Epoch: 1/2, step 2264/107898 completed (loss: 1.0040092468261719, acc: 0.761904776096344)
[2025-02-17 16:40:41,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:41,765][root][INFO] - Training Epoch: 1/2, step 2265/107898 completed (loss: 0.2836700975894928, acc: 1.0)
[2025-02-17 16:40:41,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:42,051][root][INFO] - Training Epoch: 1/2, step 2266/107898 completed (loss: 0.0728064477443695, acc: 1.0)
[2025-02-17 16:40:42,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:42,336][root][INFO] - Training Epoch: 1/2, step 2267/107898 completed (loss: 0.5264058709144592, acc: 1.0)
[2025-02-17 16:40:42,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:42,632][root][INFO] - Training Epoch: 1/2, step 2268/107898 completed (loss: 0.6072049140930176, acc: 0.8500000238418579)
[2025-02-17 16:40:42,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:42,972][root][INFO] - Training Epoch: 1/2, step 2269/107898 completed (loss: 1.1537915468215942, acc: 0.8571428656578064)
[2025-02-17 16:40:43,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:43,316][root][INFO] - Training Epoch: 1/2, step 2270/107898 completed (loss: 1.4913016557693481, acc: 0.7272727489471436)
[2025-02-17 16:40:43,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:43,618][root][INFO] - Training Epoch: 1/2, step 2271/107898 completed (loss: 1.0516620874404907, acc: 0.8799999952316284)
[2025-02-17 16:40:43,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:43,925][root][INFO] - Training Epoch: 1/2, step 2272/107898 completed (loss: 0.5014820098876953, acc: 0.8888888955116272)
[2025-02-17 16:40:44,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:44,240][root][INFO] - Training Epoch: 1/2, step 2273/107898 completed (loss: 2.5158045291900635, acc: 0.529411792755127)
[2025-02-17 16:40:44,321][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:44,559][root][INFO] - Training Epoch: 1/2, step 2274/107898 completed (loss: 0.2923247814178467, acc: 1.0)
[2025-02-17 16:40:44,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:44,919][root][INFO] - Training Epoch: 1/2, step 2275/107898 completed (loss: 1.0742435455322266, acc: 0.7857142686843872)
[2025-02-17 16:40:45,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:45,283][root][INFO] - Training Epoch: 1/2, step 2276/107898 completed (loss: 2.266331434249878, acc: 0.6666666865348816)
[2025-02-17 16:40:45,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:45,624][root][INFO] - Training Epoch: 1/2, step 2277/107898 completed (loss: 0.591667115688324, acc: 1.0)
[2025-02-17 16:40:45,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:45,985][root][INFO] - Training Epoch: 1/2, step 2278/107898 completed (loss: 0.65947026014328, acc: 0.8181818127632141)
[2025-02-17 16:40:46,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:46,292][root][INFO] - Training Epoch: 1/2, step 2279/107898 completed (loss: 0.2699868679046631, acc: 0.9166666865348816)
[2025-02-17 16:40:46,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:46,586][root][INFO] - Training Epoch: 1/2, step 2280/107898 completed (loss: 0.4902366101741791, acc: 0.9375)
[2025-02-17 16:40:46,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:46,892][root][INFO] - Training Epoch: 1/2, step 2281/107898 completed (loss: 1.5911214351654053, acc: 0.75)
[2025-02-17 16:40:47,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:47,241][root][INFO] - Training Epoch: 1/2, step 2282/107898 completed (loss: 1.0492810010910034, acc: 0.7692307829856873)
[2025-02-17 16:40:47,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:47,588][root][INFO] - Training Epoch: 1/2, step 2283/107898 completed (loss: 0.11159598082304001, acc: 1.0)
[2025-02-17 16:40:47,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:47,917][root][INFO] - Training Epoch: 1/2, step 2284/107898 completed (loss: 2.177966594696045, acc: 0.800000011920929)
[2025-02-17 16:40:48,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:48,285][root][INFO] - Training Epoch: 1/2, step 2285/107898 completed (loss: 0.1487143635749817, acc: 1.0)
[2025-02-17 16:40:48,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:48,628][root][INFO] - Training Epoch: 1/2, step 2286/107898 completed (loss: 1.0128324031829834, acc: 0.9166666865348816)
[2025-02-17 16:40:48,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:48,918][root][INFO] - Training Epoch: 1/2, step 2287/107898 completed (loss: 0.006932656280696392, acc: 1.0)
[2025-02-17 16:40:48,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:49,214][root][INFO] - Training Epoch: 1/2, step 2288/107898 completed (loss: 0.22577768564224243, acc: 1.0)
[2025-02-17 16:40:49,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:49,500][root][INFO] - Training Epoch: 1/2, step 2289/107898 completed (loss: 2.2413406372070312, acc: 0.692307710647583)
[2025-02-17 16:40:49,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:49,783][root][INFO] - Training Epoch: 1/2, step 2290/107898 completed (loss: 2.9125027656555176, acc: 0.4000000059604645)
[2025-02-17 16:40:49,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:50,092][root][INFO] - Training Epoch: 1/2, step 2291/107898 completed (loss: 0.5316860675811768, acc: 0.8999999761581421)
[2025-02-17 16:40:50,186][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:50,416][root][INFO] - Training Epoch: 1/2, step 2292/107898 completed (loss: 0.15015996992588043, acc: 1.0)
[2025-02-17 16:40:50,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:50,731][root][INFO] - Training Epoch: 1/2, step 2293/107898 completed (loss: 1.0975768566131592, acc: 0.692307710647583)
[2025-02-17 16:40:50,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:51,062][root][INFO] - Training Epoch: 1/2, step 2294/107898 completed (loss: 2.034566879272461, acc: 0.75)
[2025-02-17 16:40:51,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:51,395][root][INFO] - Training Epoch: 1/2, step 2295/107898 completed (loss: 1.6268688440322876, acc: 0.6666666865348816)
[2025-02-17 16:40:51,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:51,710][root][INFO] - Training Epoch: 1/2, step 2296/107898 completed (loss: 0.6789547204971313, acc: 0.75)
[2025-02-17 16:40:51,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:52,018][root][INFO] - Training Epoch: 1/2, step 2297/107898 completed (loss: 1.1285929679870605, acc: 0.7272727489471436)
[2025-02-17 16:40:52,124][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:52,356][root][INFO] - Training Epoch: 1/2, step 2298/107898 completed (loss: 0.18253962695598602, acc: 0.875)
[2025-02-17 16:40:52,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:52,672][root][INFO] - Training Epoch: 1/2, step 2299/107898 completed (loss: 0.7572423815727234, acc: 0.75)
[2025-02-17 16:40:52,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:53,038][root][INFO] - Training Epoch: 1/2, step 2300/107898 completed (loss: 0.7767785787582397, acc: 0.8125)
[2025-02-17 16:40:53,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:53,372][root][INFO] - Training Epoch: 1/2, step 2301/107898 completed (loss: 2.2369956970214844, acc: 0.625)
[2025-02-17 16:40:53,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:53,732][root][INFO] - Training Epoch: 1/2, step 2302/107898 completed (loss: 3.1896374225616455, acc: 0.3333333432674408)
[2025-02-17 16:40:53,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:54,095][root][INFO] - Training Epoch: 1/2, step 2303/107898 completed (loss: 2.9808509349823, acc: 0.5)
[2025-02-17 16:40:54,212][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:54,440][root][INFO] - Training Epoch: 1/2, step 2304/107898 completed (loss: 3.1108736991882324, acc: 0.44999998807907104)
[2025-02-17 16:40:54,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:54,769][root][INFO] - Training Epoch: 1/2, step 2305/107898 completed (loss: 0.007387863006442785, acc: 1.0)
[2025-02-17 16:40:54,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:55,078][root][INFO] - Training Epoch: 1/2, step 2306/107898 completed (loss: 0.5244780778884888, acc: 0.8461538553237915)
[2025-02-17 16:40:55,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:55,346][root][INFO] - Training Epoch: 1/2, step 2307/107898 completed (loss: 0.8394050598144531, acc: 0.8571428656578064)
[2025-02-17 16:40:55,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:55,665][root][INFO] - Training Epoch: 1/2, step 2308/107898 completed (loss: 0.6968169808387756, acc: 0.800000011920929)
[2025-02-17 16:40:55,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:56,007][root][INFO] - Training Epoch: 1/2, step 2309/107898 completed (loss: 0.1000586748123169, acc: 1.0)
[2025-02-17 16:40:56,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:56,312][root][INFO] - Training Epoch: 1/2, step 2310/107898 completed (loss: 1.971981406211853, acc: 0.5333333611488342)
[2025-02-17 16:40:56,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:56,659][root][INFO] - Training Epoch: 1/2, step 2311/107898 completed (loss: 1.533979058265686, acc: 0.699999988079071)
[2025-02-17 16:40:56,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:57,020][root][INFO] - Training Epoch: 1/2, step 2312/107898 completed (loss: 0.7858779430389404, acc: 0.6666666865348816)
[2025-02-17 16:40:57,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:57,337][root][INFO] - Training Epoch: 1/2, step 2313/107898 completed (loss: 0.5482652187347412, acc: 0.8333333134651184)
[2025-02-17 16:40:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:57,663][root][INFO] - Training Epoch: 1/2, step 2314/107898 completed (loss: 2.1463463306427, acc: 0.5)
[2025-02-17 16:40:57,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:58,003][root][INFO] - Training Epoch: 1/2, step 2315/107898 completed (loss: 0.7033258676528931, acc: 0.75)
[2025-02-17 16:40:58,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:58,325][root][INFO] - Training Epoch: 1/2, step 2316/107898 completed (loss: 0.1947774738073349, acc: 0.9333333373069763)
[2025-02-17 16:40:58,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:58,633][root][INFO] - Training Epoch: 1/2, step 2317/107898 completed (loss: 0.3748387098312378, acc: 0.8999999761581421)
[2025-02-17 16:40:58,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:58,977][root][INFO] - Training Epoch: 1/2, step 2318/107898 completed (loss: 1.2551575899124146, acc: 0.75)
[2025-02-17 16:40:59,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:59,272][root][INFO] - Training Epoch: 1/2, step 2319/107898 completed (loss: 0.6838034391403198, acc: 0.8148148059844971)
[2025-02-17 16:40:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:59,564][root][INFO] - Training Epoch: 1/2, step 2320/107898 completed (loss: 0.018512627109885216, acc: 1.0)
[2025-02-17 16:40:59,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:40:59,908][root][INFO] - Training Epoch: 1/2, step 2321/107898 completed (loss: 0.034478481858968735, acc: 1.0)
[2025-02-17 16:41:00,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:00,230][root][INFO] - Training Epoch: 1/2, step 2322/107898 completed (loss: 1.122863531112671, acc: 0.5)
[2025-02-17 16:41:00,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:00,542][root][INFO] - Training Epoch: 1/2, step 2323/107898 completed (loss: 2.4395971298217773, acc: 0.6315789222717285)
[2025-02-17 16:41:00,635][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:00,865][root][INFO] - Training Epoch: 1/2, step 2324/107898 completed (loss: 1.2517269849777222, acc: 0.6666666865348816)
[2025-02-17 16:41:00,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:01,147][root][INFO] - Training Epoch: 1/2, step 2325/107898 completed (loss: 0.016821501776576042, acc: 1.0)
[2025-02-17 16:41:01,254][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:01,467][root][INFO] - Training Epoch: 1/2, step 2326/107898 completed (loss: 1.129507303237915, acc: 0.8196721076965332)
[2025-02-17 16:41:01,596][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:01,837][root][INFO] - Training Epoch: 1/2, step 2327/107898 completed (loss: 0.8269328474998474, acc: 0.7647058963775635)
[2025-02-17 16:41:01,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:02,199][root][INFO] - Training Epoch: 1/2, step 2328/107898 completed (loss: 2.3307220935821533, acc: 0.6666666865348816)
[2025-02-17 16:41:02,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:02,532][root][INFO] - Training Epoch: 1/2, step 2329/107898 completed (loss: 2.491037130355835, acc: 0.3333333432674408)
[2025-02-17 16:41:02,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:02,856][root][INFO] - Training Epoch: 1/2, step 2330/107898 completed (loss: 1.6053690910339355, acc: 0.6666666865348816)
[2025-02-17 16:41:02,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:03,159][root][INFO] - Training Epoch: 1/2, step 2331/107898 completed (loss: 1.9713956117630005, acc: 0.6666666865348816)
[2025-02-17 16:41:03,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:03,469][root][INFO] - Training Epoch: 1/2, step 2332/107898 completed (loss: 0.698617160320282, acc: 1.0)
[2025-02-17 16:41:03,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:03,782][root][INFO] - Training Epoch: 1/2, step 2333/107898 completed (loss: 2.2499020099639893, acc: 0.4615384638309479)
[2025-02-17 16:41:03,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:04,130][root][INFO] - Training Epoch: 1/2, step 2334/107898 completed (loss: 1.3588603734970093, acc: 0.875)
[2025-02-17 16:41:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:04,480][root][INFO] - Training Epoch: 1/2, step 2335/107898 completed (loss: 0.22272150218486786, acc: 0.9714285731315613)
[2025-02-17 16:41:04,586][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:04,811][root][INFO] - Training Epoch: 1/2, step 2336/107898 completed (loss: 1.0593690872192383, acc: 1.0)
[2025-02-17 16:41:04,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:05,102][root][INFO] - Training Epoch: 1/2, step 2337/107898 completed (loss: 1.232321858406067, acc: 0.6666666865348816)
[2025-02-17 16:41:05,209][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:05,445][root][INFO] - Training Epoch: 1/2, step 2338/107898 completed (loss: 1.738791823387146, acc: 0.6666666865348816)
[2025-02-17 16:41:05,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:05,771][root][INFO] - Training Epoch: 1/2, step 2339/107898 completed (loss: 0.022541290149092674, acc: 1.0)
[2025-02-17 16:41:05,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:06,076][root][INFO] - Training Epoch: 1/2, step 2340/107898 completed (loss: 0.2719884514808655, acc: 0.9230769276618958)
[2025-02-17 16:41:06,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:06,368][root][INFO] - Training Epoch: 1/2, step 2341/107898 completed (loss: 1.23995840549469, acc: 0.6666666865348816)
[2025-02-17 16:41:06,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:06,668][root][INFO] - Training Epoch: 1/2, step 2342/107898 completed (loss: 0.4498274624347687, acc: 0.8461538553237915)
[2025-02-17 16:41:06,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:06,985][root][INFO] - Training Epoch: 1/2, step 2343/107898 completed (loss: 0.384321004152298, acc: 0.875)
[2025-02-17 16:41:07,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:07,270][root][INFO] - Training Epoch: 1/2, step 2344/107898 completed (loss: 0.6977012157440186, acc: 1.0)
[2025-02-17 16:41:07,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:07,583][root][INFO] - Training Epoch: 1/2, step 2345/107898 completed (loss: 2.6715219020843506, acc: 0.44999998807907104)
[2025-02-17 16:41:07,660][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:07,867][root][INFO] - Training Epoch: 1/2, step 2346/107898 completed (loss: 0.31606918573379517, acc: 1.0)
[2025-02-17 16:41:07,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:08,140][root][INFO] - Training Epoch: 1/2, step 2347/107898 completed (loss: 2.0229642391204834, acc: 0.6538461446762085)
[2025-02-17 16:41:08,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:08,483][root][INFO] - Training Epoch: 1/2, step 2348/107898 completed (loss: 5.734626770019531, acc: 0.4285714328289032)
[2025-02-17 16:41:08,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:08,774][root][INFO] - Training Epoch: 1/2, step 2349/107898 completed (loss: 1.4254610538482666, acc: 0.699999988079071)
[2025-02-17 16:41:08,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:09,079][root][INFO] - Training Epoch: 1/2, step 2350/107898 completed (loss: 0.2506116032600403, acc: 0.9090909361839294)
[2025-02-17 16:41:09,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:09,365][root][INFO] - Training Epoch: 1/2, step 2351/107898 completed (loss: 0.2026485651731491, acc: 1.0)
[2025-02-17 16:41:09,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:09,706][root][INFO] - Training Epoch: 1/2, step 2352/107898 completed (loss: 0.5283386707305908, acc: 0.8399999737739563)
[2025-02-17 16:41:09,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:10,049][root][INFO] - Training Epoch: 1/2, step 2353/107898 completed (loss: 0.6095213890075684, acc: 0.8399999737739563)
[2025-02-17 16:41:10,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:10,384][root][INFO] - Training Epoch: 1/2, step 2354/107898 completed (loss: 0.3821144998073578, acc: 0.6666666865348816)
[2025-02-17 16:41:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:10,719][root][INFO] - Training Epoch: 1/2, step 2355/107898 completed (loss: 1.802234411239624, acc: 0.692307710647583)
[2025-02-17 16:41:10,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:11,010][root][INFO] - Training Epoch: 1/2, step 2356/107898 completed (loss: 1.1339709758758545, acc: 0.5)
[2025-02-17 16:41:11,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:11,310][root][INFO] - Training Epoch: 1/2, step 2357/107898 completed (loss: 0.40296778082847595, acc: 1.0)
[2025-02-17 16:41:11,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:11,618][root][INFO] - Training Epoch: 1/2, step 2358/107898 completed (loss: 0.05930881202220917, acc: 1.0)
[2025-02-17 16:41:11,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:11,925][root][INFO] - Training Epoch: 1/2, step 2359/107898 completed (loss: 0.9903161525726318, acc: 0.807692289352417)
[2025-02-17 16:41:12,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:12,257][root][INFO] - Training Epoch: 1/2, step 2360/107898 completed (loss: 0.026445463299751282, acc: 1.0)
[2025-02-17 16:41:12,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:12,592][root][INFO] - Training Epoch: 1/2, step 2361/107898 completed (loss: 1.586496114730835, acc: 0.7647058963775635)
[2025-02-17 16:41:12,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:12,932][root][INFO] - Training Epoch: 1/2, step 2362/107898 completed (loss: 0.3930419683456421, acc: 0.9200000166893005)
[2025-02-17 16:41:13,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:13,264][root][INFO] - Training Epoch: 1/2, step 2363/107898 completed (loss: 0.27657103538513184, acc: 0.9090909361839294)
[2025-02-17 16:41:13,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:13,628][root][INFO] - Training Epoch: 1/2, step 2364/107898 completed (loss: 0.005935627035796642, acc: 1.0)
[2025-02-17 16:41:13,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:13,953][root][INFO] - Training Epoch: 1/2, step 2365/107898 completed (loss: 0.09958194941282272, acc: 1.0)
[2025-02-17 16:41:14,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:14,269][root][INFO] - Training Epoch: 1/2, step 2366/107898 completed (loss: 0.8898060321807861, acc: 0.5)
[2025-02-17 16:41:14,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:14,583][root][INFO] - Training Epoch: 1/2, step 2367/107898 completed (loss: 0.1586146354675293, acc: 1.0)
[2025-02-17 16:41:14,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:14,944][root][INFO] - Training Epoch: 1/2, step 2368/107898 completed (loss: 0.7618240714073181, acc: 0.761904776096344)
[2025-02-17 16:41:15,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:15,229][root][INFO] - Training Epoch: 1/2, step 2369/107898 completed (loss: 5.471017360687256, acc: 0.3333333432674408)
[2025-02-17 16:41:15,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:15,536][root][INFO] - Training Epoch: 1/2, step 2370/107898 completed (loss: 0.08732485771179199, acc: 1.0)
[2025-02-17 16:41:15,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:15,840][root][INFO] - Training Epoch: 1/2, step 2371/107898 completed (loss: 1.4781787395477295, acc: 0.0)
[2025-02-17 16:41:15,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:16,091][root][INFO] - Training Epoch: 1/2, step 2372/107898 completed (loss: 1.0731278657913208, acc: 0.75)
[2025-02-17 16:41:16,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:16,402][root][INFO] - Training Epoch: 1/2, step 2373/107898 completed (loss: 0.08994314074516296, acc: 1.0)
[2025-02-17 16:41:16,525][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:16,777][root][INFO] - Training Epoch: 1/2, step 2374/107898 completed (loss: 1.1614240407943726, acc: 0.7142857313156128)
[2025-02-17 16:41:16,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:17,158][root][INFO] - Training Epoch: 1/2, step 2375/107898 completed (loss: 5.773675441741943, acc: 0.20000000298023224)
[2025-02-17 16:41:17,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:17,504][root][INFO] - Training Epoch: 1/2, step 2376/107898 completed (loss: 2.8992040157318115, acc: 0.5)
[2025-02-17 16:41:17,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:17,841][root][INFO] - Training Epoch: 1/2, step 2377/107898 completed (loss: 0.13422437012195587, acc: 0.96875)
[2025-02-17 16:41:17,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:18,171][root][INFO] - Training Epoch: 1/2, step 2378/107898 completed (loss: 0.8304370045661926, acc: 0.800000011920929)
[2025-02-17 16:41:18,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:18,527][root][INFO] - Training Epoch: 1/2, step 2379/107898 completed (loss: 0.018787408247590065, acc: 1.0)
[2025-02-17 16:41:18,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:18,858][root][INFO] - Training Epoch: 1/2, step 2380/107898 completed (loss: 0.8980809450149536, acc: 0.8235294222831726)
[2025-02-17 16:41:18,947][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:19,177][root][INFO] - Training Epoch: 1/2, step 2381/107898 completed (loss: 4.533401012420654, acc: 0.3333333432674408)
[2025-02-17 16:41:19,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:19,513][root][INFO] - Training Epoch: 1/2, step 2382/107898 completed (loss: 1.0842015743255615, acc: 0.8461538553237915)
[2025-02-17 16:41:19,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:19,841][root][INFO] - Training Epoch: 1/2, step 2383/107898 completed (loss: 0.36500152945518494, acc: 0.8888888955116272)
[2025-02-17 16:41:19,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:20,143][root][INFO] - Training Epoch: 1/2, step 2384/107898 completed (loss: 0.06526496261358261, acc: 1.0)
[2025-02-17 16:41:20,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:20,465][root][INFO] - Training Epoch: 1/2, step 2385/107898 completed (loss: 2.4518582820892334, acc: 0.5625)
[2025-02-17 16:41:20,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:20,787][root][INFO] - Training Epoch: 1/2, step 2386/107898 completed (loss: 0.3204863965511322, acc: 1.0)
[2025-02-17 16:41:20,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:21,056][root][INFO] - Training Epoch: 1/2, step 2387/107898 completed (loss: 1.988232135772705, acc: 0.75)
[2025-02-17 16:41:21,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:21,331][root][INFO] - Training Epoch: 1/2, step 2388/107898 completed (loss: 5.000290870666504, acc: 0.6666666865348816)
[2025-02-17 16:41:21,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:21,625][root][INFO] - Training Epoch: 1/2, step 2389/107898 completed (loss: 1.7666534185409546, acc: 0.7058823704719543)
[2025-02-17 16:41:21,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:21,918][root][INFO] - Training Epoch: 1/2, step 2390/107898 completed (loss: 1.0034185647964478, acc: 0.6666666865348816)
[2025-02-17 16:41:22,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:22,223][root][INFO] - Training Epoch: 1/2, step 2391/107898 completed (loss: 1.0733953714370728, acc: 0.8333333134651184)
[2025-02-17 16:41:22,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:22,531][root][INFO] - Training Epoch: 1/2, step 2392/107898 completed (loss: 1.7343432903289795, acc: 0.6153846383094788)
[2025-02-17 16:41:22,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:22,828][root][INFO] - Training Epoch: 1/2, step 2393/107898 completed (loss: 0.17855221033096313, acc: 1.0)
[2025-02-17 16:41:22,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:23,148][root][INFO] - Training Epoch: 1/2, step 2394/107898 completed (loss: 1.0262256860733032, acc: 0.7647058963775635)
[2025-02-17 16:41:23,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:23,469][root][INFO] - Training Epoch: 1/2, step 2395/107898 completed (loss: 2.5601606369018555, acc: 0.4000000059604645)
[2025-02-17 16:41:23,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:23,781][root][INFO] - Training Epoch: 1/2, step 2396/107898 completed (loss: 0.9318599700927734, acc: 0.8181818127632141)
[2025-02-17 16:41:23,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:24,088][root][INFO] - Training Epoch: 1/2, step 2397/107898 completed (loss: 1.4896080493927002, acc: 0.5882353186607361)
[2025-02-17 16:41:24,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:24,377][root][INFO] - Training Epoch: 1/2, step 2398/107898 completed (loss: 0.8348313570022583, acc: 0.5)
[2025-02-17 16:41:24,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:24,674][root][INFO] - Training Epoch: 1/2, step 2399/107898 completed (loss: 1.214111328125, acc: 0.7647058963775635)
[2025-02-17 16:41:24,757][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:24,980][root][INFO] - Training Epoch: 1/2, step 2400/107898 completed (loss: 1.9184619188308716, acc: 0.8571428656578064)
[2025-02-17 16:41:25,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:25,328][root][INFO] - Training Epoch: 1/2, step 2401/107898 completed (loss: 0.6542363166809082, acc: 0.8999999761581421)
[2025-02-17 16:41:25,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:25,685][root][INFO] - Training Epoch: 1/2, step 2402/107898 completed (loss: 0.7538113594055176, acc: 0.8947368264198303)
[2025-02-17 16:41:25,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:25,981][root][INFO] - Training Epoch: 1/2, step 2403/107898 completed (loss: 0.2650775909423828, acc: 0.8947368264198303)
[2025-02-17 16:41:26,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:26,287][root][INFO] - Training Epoch: 1/2, step 2404/107898 completed (loss: 1.8243974447250366, acc: 0.75)
[2025-02-17 16:41:26,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:26,631][root][INFO] - Training Epoch: 1/2, step 2405/107898 completed (loss: 0.6805732250213623, acc: 0.8888888955116272)
[2025-02-17 16:41:26,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:26,959][root][INFO] - Training Epoch: 1/2, step 2406/107898 completed (loss: 2.693441867828369, acc: 0.25)
[2025-02-17 16:41:27,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:27,286][root][INFO] - Training Epoch: 1/2, step 2407/107898 completed (loss: 1.5367754697799683, acc: 0.7647058963775635)
[2025-02-17 16:41:27,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:27,605][root][INFO] - Training Epoch: 1/2, step 2408/107898 completed (loss: 0.9200283288955688, acc: 0.800000011920929)
[2025-02-17 16:41:27,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:27,943][root][INFO] - Training Epoch: 1/2, step 2409/107898 completed (loss: 0.7680983543395996, acc: 0.8571428656578064)
[2025-02-17 16:41:28,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:28,242][root][INFO] - Training Epoch: 1/2, step 2410/107898 completed (loss: 0.9048970341682434, acc: 0.800000011920929)
[2025-02-17 16:41:28,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:28,547][root][INFO] - Training Epoch: 1/2, step 2411/107898 completed (loss: 1.5392910242080688, acc: 0.5)
[2025-02-17 16:41:28,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:28,883][root][INFO] - Training Epoch: 1/2, step 2412/107898 completed (loss: 1.5097265243530273, acc: 0.6666666865348816)
[2025-02-17 16:41:28,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:29,207][root][INFO] - Training Epoch: 1/2, step 2413/107898 completed (loss: 0.8115805983543396, acc: 0.807692289352417)
[2025-02-17 16:41:29,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:29,532][root][INFO] - Training Epoch: 1/2, step 2414/107898 completed (loss: 1.4532041549682617, acc: 0.6666666865348816)
[2025-02-17 16:41:29,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:29,841][root][INFO] - Training Epoch: 1/2, step 2415/107898 completed (loss: 2.9965779781341553, acc: 0.5)
[2025-02-17 16:41:29,925][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:30,135][root][INFO] - Training Epoch: 1/2, step 2416/107898 completed (loss: 1.789954662322998, acc: 0.7272727489471436)
[2025-02-17 16:41:30,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:30,425][root][INFO] - Training Epoch: 1/2, step 2417/107898 completed (loss: 0.8008067607879639, acc: 0.5)
[2025-02-17 16:41:30,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:30,744][root][INFO] - Training Epoch: 1/2, step 2418/107898 completed (loss: 0.949958324432373, acc: 0.7058823704719543)
[2025-02-17 16:41:30,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:31,035][root][INFO] - Training Epoch: 1/2, step 2419/107898 completed (loss: 3.4042913913726807, acc: 0.1666666716337204)
[2025-02-17 16:41:31,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:31,331][root][INFO] - Training Epoch: 1/2, step 2420/107898 completed (loss: 0.19649764895439148, acc: 1.0)
[2025-02-17 16:41:31,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:31,643][root][INFO] - Training Epoch: 1/2, step 2421/107898 completed (loss: 1.0029650926589966, acc: 0.7727272510528564)
[2025-02-17 16:41:31,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:31,947][root][INFO] - Training Epoch: 1/2, step 2422/107898 completed (loss: 1.395719289779663, acc: 0.5)
[2025-02-17 16:41:32,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:32,253][root][INFO] - Training Epoch: 1/2, step 2423/107898 completed (loss: 0.016763759776949883, acc: 1.0)
[2025-02-17 16:41:32,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:32,548][root][INFO] - Training Epoch: 1/2, step 2424/107898 completed (loss: 2.1398861408233643, acc: 0.5)
[2025-02-17 16:41:32,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:32,841][root][INFO] - Training Epoch: 1/2, step 2425/107898 completed (loss: 0.07036571204662323, acc: 1.0)
[2025-02-17 16:41:32,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:33,166][root][INFO] - Training Epoch: 1/2, step 2426/107898 completed (loss: 0.4945327639579773, acc: 0.8571428656578064)
[2025-02-17 16:41:33,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:33,492][root][INFO] - Training Epoch: 1/2, step 2427/107898 completed (loss: 0.0848824754357338, acc: 1.0)
[2025-02-17 16:41:33,584][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:33,814][root][INFO] - Training Epoch: 1/2, step 2428/107898 completed (loss: 0.007036078721284866, acc: 1.0)
[2025-02-17 16:41:33,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:34,132][root][INFO] - Training Epoch: 1/2, step 2429/107898 completed (loss: 0.3528103828430176, acc: 0.8666666746139526)
[2025-02-17 16:41:34,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:34,480][root][INFO] - Training Epoch: 1/2, step 2430/107898 completed (loss: 1.006955623626709, acc: 0.625)
[2025-02-17 16:41:34,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:34,811][root][INFO] - Training Epoch: 1/2, step 2431/107898 completed (loss: 1.462500810623169, acc: 0.8181818127632141)
[2025-02-17 16:41:34,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:35,116][root][INFO] - Training Epoch: 1/2, step 2432/107898 completed (loss: 3.9652254581451416, acc: 0.3333333432674408)
[2025-02-17 16:41:35,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:35,427][root][INFO] - Training Epoch: 1/2, step 2433/107898 completed (loss: 1.1228275299072266, acc: 0.7272727489471436)
[2025-02-17 16:41:35,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:35,729][root][INFO] - Training Epoch: 1/2, step 2434/107898 completed (loss: 1.6463792324066162, acc: 0.7058823704719543)
[2025-02-17 16:41:35,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:36,032][root][INFO] - Training Epoch: 1/2, step 2435/107898 completed (loss: 2.0693132877349854, acc: 0.7142857313156128)
[2025-02-17 16:41:36,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:36,346][root][INFO] - Training Epoch: 1/2, step 2436/107898 completed (loss: 1.246176838874817, acc: 0.6666666865348816)
[2025-02-17 16:41:36,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:36,636][root][INFO] - Training Epoch: 1/2, step 2437/107898 completed (loss: 2.4766085147857666, acc: 0.5)
[2025-02-17 16:41:36,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:36,944][root][INFO] - Training Epoch: 1/2, step 2438/107898 completed (loss: 1.8424115180969238, acc: 0.5199999809265137)
[2025-02-17 16:41:37,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:37,238][root][INFO] - Training Epoch: 1/2, step 2439/107898 completed (loss: 1.0114728212356567, acc: 0.7692307829856873)
[2025-02-17 16:41:37,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:37,566][root][INFO] - Training Epoch: 1/2, step 2440/107898 completed (loss: 0.466728150844574, acc: 0.800000011920929)
[2025-02-17 16:41:37,656][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:37,875][root][INFO] - Training Epoch: 1/2, step 2441/107898 completed (loss: 0.6781442165374756, acc: 0.8999999761581421)
[2025-02-17 16:41:37,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:38,194][root][INFO] - Training Epoch: 1/2, step 2442/107898 completed (loss: 0.45738449692726135, acc: 0.800000011920929)
[2025-02-17 16:41:38,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:38,506][root][INFO] - Training Epoch: 1/2, step 2443/107898 completed (loss: 0.5179789066314697, acc: 0.8888888955116272)
[2025-02-17 16:41:38,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:38,853][root][INFO] - Training Epoch: 1/2, step 2444/107898 completed (loss: 2.042931079864502, acc: 0.699999988079071)
[2025-02-17 16:41:38,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:39,187][root][INFO] - Training Epoch: 1/2, step 2445/107898 completed (loss: 0.4308527410030365, acc: 0.9090909361839294)
[2025-02-17 16:41:39,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:39,495][root][INFO] - Training Epoch: 1/2, step 2446/107898 completed (loss: 0.9173539876937866, acc: 0.84375)
[2025-02-17 16:41:39,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:39,783][root][INFO] - Training Epoch: 1/2, step 2447/107898 completed (loss: 0.006488639395684004, acc: 1.0)
[2025-02-17 16:41:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:40,059][root][INFO] - Training Epoch: 1/2, step 2448/107898 completed (loss: 0.629978358745575, acc: 0.8666666746139526)
[2025-02-17 16:41:40,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:40,378][root][INFO] - Training Epoch: 1/2, step 2449/107898 completed (loss: 0.1983962059020996, acc: 0.9090909361839294)
[2025-02-17 16:41:40,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:40,666][root][INFO] - Training Epoch: 1/2, step 2450/107898 completed (loss: 0.4159792363643646, acc: 1.0)
[2025-02-17 16:41:40,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:40,975][root][INFO] - Training Epoch: 1/2, step 2451/107898 completed (loss: 0.014302445575594902, acc: 1.0)
[2025-02-17 16:41:41,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:41,319][root][INFO] - Training Epoch: 1/2, step 2452/107898 completed (loss: 0.7637237906455994, acc: 0.8571428656578064)
[2025-02-17 16:41:41,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:41,669][root][INFO] - Training Epoch: 1/2, step 2453/107898 completed (loss: 1.7828441858291626, acc: 0.625)
[2025-02-17 16:41:41,772][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:41,998][root][INFO] - Training Epoch: 1/2, step 2454/107898 completed (loss: 0.7471316456794739, acc: 0.8235294222831726)
[2025-02-17 16:41:42,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:42,322][root][INFO] - Training Epoch: 1/2, step 2455/107898 completed (loss: 1.041062355041504, acc: 0.8888888955116272)
[2025-02-17 16:41:42,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:42,615][root][INFO] - Training Epoch: 1/2, step 2456/107898 completed (loss: 1.2212893962860107, acc: 0.7777777910232544)
[2025-02-17 16:41:42,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:42,966][root][INFO] - Training Epoch: 1/2, step 2457/107898 completed (loss: 0.3096175193786621, acc: 1.0)
[2025-02-17 16:41:43,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:43,338][root][INFO] - Training Epoch: 1/2, step 2458/107898 completed (loss: 0.42381080985069275, acc: 0.9354838728904724)
[2025-02-17 16:41:43,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:43,654][root][INFO] - Training Epoch: 1/2, step 2459/107898 completed (loss: 2.1296045780181885, acc: 0.6000000238418579)
[2025-02-17 16:41:43,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:44,004][root][INFO] - Training Epoch: 1/2, step 2460/107898 completed (loss: 2.648233652114868, acc: 0.625)
[2025-02-17 16:41:44,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:44,322][root][INFO] - Training Epoch: 1/2, step 2461/107898 completed (loss: 2.180734872817993, acc: 0.5555555820465088)
[2025-02-17 16:41:44,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:44,627][root][INFO] - Training Epoch: 1/2, step 2462/107898 completed (loss: 3.075148582458496, acc: 0.4000000059604645)
[2025-02-17 16:41:44,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:44,938][root][INFO] - Training Epoch: 1/2, step 2463/107898 completed (loss: 2.1639225482940674, acc: 0.6551724076271057)
[2025-02-17 16:41:45,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:45,230][root][INFO] - Training Epoch: 1/2, step 2464/107898 completed (loss: 0.010226351208984852, acc: 1.0)
[2025-02-17 16:41:45,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:45,529][root][INFO] - Training Epoch: 1/2, step 2465/107898 completed (loss: 0.3818141222000122, acc: 0.8333333134651184)
[2025-02-17 16:41:45,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:45,887][root][INFO] - Training Epoch: 1/2, step 2466/107898 completed (loss: 1.931878924369812, acc: 0.5)
[2025-02-17 16:41:45,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:46,223][root][INFO] - Training Epoch: 1/2, step 2467/107898 completed (loss: 0.4547039568424225, acc: 1.0)
[2025-02-17 16:41:46,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:46,539][root][INFO] - Training Epoch: 1/2, step 2468/107898 completed (loss: 2.2191696166992188, acc: 0.5)
[2025-02-17 16:41:46,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:46,867][root][INFO] - Training Epoch: 1/2, step 2469/107898 completed (loss: 0.5957337021827698, acc: 0.8333333134651184)
[2025-02-17 16:41:46,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:47,188][root][INFO] - Training Epoch: 1/2, step 2470/107898 completed (loss: 0.5607203841209412, acc: 0.8571428656578064)
[2025-02-17 16:41:47,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:47,495][root][INFO] - Training Epoch: 1/2, step 2471/107898 completed (loss: 0.8976133465766907, acc: 0.75)
[2025-02-17 16:41:47,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:47,796][root][INFO] - Training Epoch: 1/2, step 2472/107898 completed (loss: 3.6256744861602783, acc: 0.5)
[2025-02-17 16:41:47,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:48,085][root][INFO] - Training Epoch: 1/2, step 2473/107898 completed (loss: 0.13854025304317474, acc: 1.0)
[2025-02-17 16:41:48,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:48,387][root][INFO] - Training Epoch: 1/2, step 2474/107898 completed (loss: 1.8459521532058716, acc: 0.3333333432674408)
[2025-02-17 16:41:48,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:48,692][root][INFO] - Training Epoch: 1/2, step 2475/107898 completed (loss: 0.18663431704044342, acc: 1.0)
[2025-02-17 16:41:48,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:49,013][root][INFO] - Training Epoch: 1/2, step 2476/107898 completed (loss: 0.22184056043624878, acc: 0.9523809552192688)
[2025-02-17 16:41:49,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:49,288][root][INFO] - Training Epoch: 1/2, step 2477/107898 completed (loss: 0.446668416261673, acc: 0.75)
[2025-02-17 16:41:49,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:49,597][root][INFO] - Training Epoch: 1/2, step 2478/107898 completed (loss: 0.8033348917961121, acc: 0.8571428656578064)
[2025-02-17 16:41:49,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:49,893][root][INFO] - Training Epoch: 1/2, step 2479/107898 completed (loss: 0.6174680590629578, acc: 0.8571428656578064)
[2025-02-17 16:41:49,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:50,207][root][INFO] - Training Epoch: 1/2, step 2480/107898 completed (loss: 0.3094283640384674, acc: 0.8947368264198303)
[2025-02-17 16:41:50,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:50,572][root][INFO] - Training Epoch: 1/2, step 2481/107898 completed (loss: 1.7831721305847168, acc: 0.5)
[2025-02-17 16:41:50,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:50,914][root][INFO] - Training Epoch: 1/2, step 2482/107898 completed (loss: 0.2830166220664978, acc: 0.9375)
[2025-02-17 16:41:51,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:51,268][root][INFO] - Training Epoch: 1/2, step 2483/107898 completed (loss: 0.28011831641197205, acc: 0.9473684430122375)
[2025-02-17 16:41:51,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:51,590][root][INFO] - Training Epoch: 1/2, step 2484/107898 completed (loss: 4.153565406799316, acc: 0.4000000059604645)
[2025-02-17 16:41:51,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:51,912][root][INFO] - Training Epoch: 1/2, step 2485/107898 completed (loss: 0.1398407518863678, acc: 0.9375)
[2025-02-17 16:41:52,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:52,256][root][INFO] - Training Epoch: 1/2, step 2486/107898 completed (loss: 0.8148598670959473, acc: 0.7777777910232544)
[2025-02-17 16:41:52,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:52,610][root][INFO] - Training Epoch: 1/2, step 2487/107898 completed (loss: 1.4891810417175293, acc: 0.6666666865348816)
[2025-02-17 16:41:52,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:52,925][root][INFO] - Training Epoch: 1/2, step 2488/107898 completed (loss: 0.08728300034999847, acc: 1.0)
[2025-02-17 16:41:53,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:53,199][root][INFO] - Training Epoch: 1/2, step 2489/107898 completed (loss: 0.04968172311782837, acc: 1.0)
[2025-02-17 16:41:53,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:53,488][root][INFO] - Training Epoch: 1/2, step 2490/107898 completed (loss: 0.5657249689102173, acc: 1.0)
[2025-02-17 16:41:53,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:53,805][root][INFO] - Training Epoch: 1/2, step 2491/107898 completed (loss: 0.7974286079406738, acc: 0.875)
[2025-02-17 16:41:53,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:54,110][root][INFO] - Training Epoch: 1/2, step 2492/107898 completed (loss: 2.4168508052825928, acc: 0.6666666865348816)
[2025-02-17 16:41:54,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:54,424][root][INFO] - Training Epoch: 1/2, step 2493/107898 completed (loss: 0.47982215881347656, acc: 0.8636363744735718)
[2025-02-17 16:41:54,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:54,718][root][INFO] - Training Epoch: 1/2, step 2494/107898 completed (loss: 2.416477680206299, acc: 0.5714285969734192)
[2025-02-17 16:41:54,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:55,088][root][INFO] - Training Epoch: 1/2, step 2495/107898 completed (loss: 0.27226948738098145, acc: 0.9677419066429138)
[2025-02-17 16:41:55,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:55,410][root][INFO] - Training Epoch: 1/2, step 2496/107898 completed (loss: 0.6124759912490845, acc: 0.8709677457809448)
[2025-02-17 16:41:55,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:55,705][root][INFO] - Training Epoch: 1/2, step 2497/107898 completed (loss: 0.2681194543838501, acc: 0.8823529481887817)
[2025-02-17 16:41:55,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:55,997][root][INFO] - Training Epoch: 1/2, step 2498/107898 completed (loss: 1.4416364431381226, acc: 0.6666666865348816)
[2025-02-17 16:41:56,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:56,299][root][INFO] - Training Epoch: 1/2, step 2499/107898 completed (loss: 0.7610110640525818, acc: 0.800000011920929)
[2025-02-17 16:41:56,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:56,587][root][INFO] - Training Epoch: 1/2, step 2500/107898 completed (loss: 2.7132668495178223, acc: 0.375)
[2025-02-17 16:41:56,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:56,886][root][INFO] - Training Epoch: 1/2, step 2501/107898 completed (loss: 1.401242971420288, acc: 0.8333333134651184)
[2025-02-17 16:41:56,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:57,197][root][INFO] - Training Epoch: 1/2, step 2502/107898 completed (loss: 0.38137581944465637, acc: 0.800000011920929)
[2025-02-17 16:41:57,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:57,490][root][INFO] - Training Epoch: 1/2, step 2503/107898 completed (loss: 0.40268298983573914, acc: 1.0)
[2025-02-17 16:41:57,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:57,801][root][INFO] - Training Epoch: 1/2, step 2504/107898 completed (loss: 1.2165265083312988, acc: 0.6800000071525574)
[2025-02-17 16:41:57,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:58,120][root][INFO] - Training Epoch: 1/2, step 2505/107898 completed (loss: 0.05667746067047119, acc: 1.0)
[2025-02-17 16:41:58,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:58,476][root][INFO] - Training Epoch: 1/2, step 2506/107898 completed (loss: 0.05293009802699089, acc: 1.0)
[2025-02-17 16:41:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:58,792][root][INFO] - Training Epoch: 1/2, step 2507/107898 completed (loss: 1.8966008424758911, acc: 0.625)
[2025-02-17 16:41:58,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:59,116][root][INFO] - Training Epoch: 1/2, step 2508/107898 completed (loss: 0.053579092025756836, acc: 1.0)
[2025-02-17 16:41:59,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:59,475][root][INFO] - Training Epoch: 1/2, step 2509/107898 completed (loss: 0.5539589524269104, acc: 0.9285714030265808)
[2025-02-17 16:41:59,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:41:59,789][root][INFO] - Training Epoch: 1/2, step 2510/107898 completed (loss: 0.31369489431381226, acc: 1.0)
[2025-02-17 16:41:59,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:00,110][root][INFO] - Training Epoch: 1/2, step 2511/107898 completed (loss: 0.4481987953186035, acc: 1.0)
[2025-02-17 16:42:00,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:00,439][root][INFO] - Training Epoch: 1/2, step 2512/107898 completed (loss: 1.0524674654006958, acc: 0.6666666865348816)
[2025-02-17 16:42:00,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:00,741][root][INFO] - Training Epoch: 1/2, step 2513/107898 completed (loss: 0.8745362162590027, acc: 0.6666666865348816)
[2025-02-17 16:42:00,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:01,074][root][INFO] - Training Epoch: 1/2, step 2514/107898 completed (loss: 0.7109863758087158, acc: 0.5)
[2025-02-17 16:42:01,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:01,406][root][INFO] - Training Epoch: 1/2, step 2515/107898 completed (loss: 2.9155526161193848, acc: 0.5)
[2025-02-17 16:42:01,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:01,760][root][INFO] - Training Epoch: 1/2, step 2516/107898 completed (loss: 0.2934730350971222, acc: 0.8571428656578064)
[2025-02-17 16:42:01,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:02,073][root][INFO] - Training Epoch: 1/2, step 2517/107898 completed (loss: 0.8374543190002441, acc: 0.875)
[2025-02-17 16:42:02,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:02,335][root][INFO] - Training Epoch: 1/2, step 2518/107898 completed (loss: 0.9785789251327515, acc: 0.75)
[2025-02-17 16:42:02,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:02,621][root][INFO] - Training Epoch: 1/2, step 2519/107898 completed (loss: 0.11945408582687378, acc: 1.0)
[2025-02-17 16:42:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:02,911][root][INFO] - Training Epoch: 1/2, step 2520/107898 completed (loss: 3.5521178245544434, acc: 0.6000000238418579)
[2025-02-17 16:42:02,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:03,206][root][INFO] - Training Epoch: 1/2, step 2521/107898 completed (loss: 0.05573024973273277, acc: 1.0)
[2025-02-17 16:42:03,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:03,512][root][INFO] - Training Epoch: 1/2, step 2522/107898 completed (loss: 0.020471464842557907, acc: 1.0)
[2025-02-17 16:42:03,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:03,816][root][INFO] - Training Epoch: 1/2, step 2523/107898 completed (loss: 0.06037464365363121, acc: 1.0)
[2025-02-17 16:42:03,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:04,121][root][INFO] - Training Epoch: 1/2, step 2524/107898 completed (loss: 0.8384174704551697, acc: 0.875)
[2025-02-17 16:42:04,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:04,445][root][INFO] - Training Epoch: 1/2, step 2525/107898 completed (loss: 0.8354953527450562, acc: 0.8260869383811951)
[2025-02-17 16:42:04,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:04,731][root][INFO] - Training Epoch: 1/2, step 2526/107898 completed (loss: 0.04528680816292763, acc: 1.0)
[2025-02-17 16:42:04,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:05,016][root][INFO] - Training Epoch: 1/2, step 2527/107898 completed (loss: 0.1891271471977234, acc: 0.9166666865348816)
[2025-02-17 16:42:05,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:05,310][root][INFO] - Training Epoch: 1/2, step 2528/107898 completed (loss: 0.21892088651657104, acc: 0.9090909361839294)
[2025-02-17 16:42:05,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:05,613][root][INFO] - Training Epoch: 1/2, step 2529/107898 completed (loss: 0.07741577178239822, acc: 1.0)
[2025-02-17 16:42:05,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:05,906][root][INFO] - Training Epoch: 1/2, step 2530/107898 completed (loss: 0.3622654676437378, acc: 0.9411764740943909)
[2025-02-17 16:42:05,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:06,201][root][INFO] - Training Epoch: 1/2, step 2531/107898 completed (loss: 0.342597633600235, acc: 0.6666666865348816)
[2025-02-17 16:42:06,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:06,576][root][INFO] - Training Epoch: 1/2, step 2532/107898 completed (loss: 0.6839938759803772, acc: 0.8636363744735718)
[2025-02-17 16:42:06,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:06,870][root][INFO] - Training Epoch: 1/2, step 2533/107898 completed (loss: 0.7497159242630005, acc: 0.5)
[2025-02-17 16:42:06,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:07,176][root][INFO] - Training Epoch: 1/2, step 2534/107898 completed (loss: 1.114893913269043, acc: 0.7142857313156128)
[2025-02-17 16:42:07,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:07,513][root][INFO] - Training Epoch: 1/2, step 2535/107898 completed (loss: 2.2703490257263184, acc: 0.5652173757553101)
[2025-02-17 16:42:07,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:07,838][root][INFO] - Training Epoch: 1/2, step 2536/107898 completed (loss: 0.011616632342338562, acc: 1.0)
[2025-02-17 16:42:07,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:08,156][root][INFO] - Training Epoch: 1/2, step 2537/107898 completed (loss: 0.884690523147583, acc: 0.7058823704719543)
[2025-02-17 16:42:08,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:08,478][root][INFO] - Training Epoch: 1/2, step 2538/107898 completed (loss: 0.08060429990291595, acc: 1.0)
[2025-02-17 16:42:08,570][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:08,834][root][INFO] - Training Epoch: 1/2, step 2539/107898 completed (loss: 0.500831663608551, acc: 1.0)
[2025-02-17 16:42:08,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:09,166][root][INFO] - Training Epoch: 1/2, step 2540/107898 completed (loss: 0.5070565938949585, acc: 0.9230769276618958)
[2025-02-17 16:42:09,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:09,475][root][INFO] - Training Epoch: 1/2, step 2541/107898 completed (loss: 0.6420686841011047, acc: 0.8928571343421936)
[2025-02-17 16:42:09,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:09,790][root][INFO] - Training Epoch: 1/2, step 2542/107898 completed (loss: 2.919685125350952, acc: 0.4848484992980957)
[2025-02-17 16:42:09,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:10,096][root][INFO] - Training Epoch: 1/2, step 2543/107898 completed (loss: 0.26573386788368225, acc: 0.9444444179534912)
[2025-02-17 16:42:10,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:10,393][root][INFO] - Training Epoch: 1/2, step 2544/107898 completed (loss: 0.1468031108379364, acc: 0.9375)
[2025-02-17 16:42:10,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:10,684][root][INFO] - Training Epoch: 1/2, step 2545/107898 completed (loss: 1.5217206478118896, acc: 0.5)
[2025-02-17 16:42:10,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:10,973][root][INFO] - Training Epoch: 1/2, step 2546/107898 completed (loss: 1.5404502153396606, acc: 0.6000000238418579)
[2025-02-17 16:42:11,062][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:11,282][root][INFO] - Training Epoch: 1/2, step 2547/107898 completed (loss: 1.2774826288223267, acc: 0.7586206793785095)
[2025-02-17 16:42:11,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:11,590][root][INFO] - Training Epoch: 1/2, step 2548/107898 completed (loss: 0.737995982170105, acc: 0.8999999761581421)
[2025-02-17 16:42:11,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:11,912][root][INFO] - Training Epoch: 1/2, step 2549/107898 completed (loss: 0.025862934067845345, acc: 1.0)
[2025-02-17 16:42:12,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:12,219][root][INFO] - Training Epoch: 1/2, step 2550/107898 completed (loss: 1.7588590383529663, acc: 0.0)
[2025-02-17 16:42:12,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:12,533][root][INFO] - Training Epoch: 1/2, step 2551/107898 completed (loss: 5.006551742553711, acc: 0.3333333432674408)
[2025-02-17 16:42:12,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:12,821][root][INFO] - Training Epoch: 1/2, step 2552/107898 completed (loss: 0.8500313758850098, acc: 0.9285714030265808)
[2025-02-17 16:42:12,947][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:13,167][root][INFO] - Training Epoch: 1/2, step 2553/107898 completed (loss: 0.4813070595264435, acc: 0.8918918967247009)
[2025-02-17 16:42:13,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:13,465][root][INFO] - Training Epoch: 1/2, step 2554/107898 completed (loss: 1.2455471754074097, acc: 0.75)
[2025-02-17 16:42:13,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:13,785][root][INFO] - Training Epoch: 1/2, step 2555/107898 completed (loss: 1.5113451480865479, acc: 0.6875)
[2025-02-17 16:42:13,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:14,081][root][INFO] - Training Epoch: 1/2, step 2556/107898 completed (loss: 0.8231959939002991, acc: 0.6666666865348816)
[2025-02-17 16:42:14,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:14,375][root][INFO] - Training Epoch: 1/2, step 2557/107898 completed (loss: 1.0646811723709106, acc: 0.8888888955116272)
[2025-02-17 16:42:14,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:14,671][root][INFO] - Training Epoch: 1/2, step 2558/107898 completed (loss: 1.3491779565811157, acc: 0.8695651888847351)
[2025-02-17 16:42:14,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:15,014][root][INFO] - Training Epoch: 1/2, step 2559/107898 completed (loss: 1.3529510498046875, acc: 0.75)
[2025-02-17 16:42:15,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:15,299][root][INFO] - Training Epoch: 1/2, step 2560/107898 completed (loss: 1.5132853984832764, acc: 0.5)
[2025-02-17 16:42:15,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:15,598][root][INFO] - Training Epoch: 1/2, step 2561/107898 completed (loss: 0.007036438211798668, acc: 1.0)
[2025-02-17 16:42:15,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:15,939][root][INFO] - Training Epoch: 1/2, step 2562/107898 completed (loss: 0.19825202226638794, acc: 1.0)
[2025-02-17 16:42:16,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:16,247][root][INFO] - Training Epoch: 1/2, step 2563/107898 completed (loss: 0.003916365560144186, acc: 1.0)
[2025-02-17 16:42:16,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:16,564][root][INFO] - Training Epoch: 1/2, step 2564/107898 completed (loss: 1.4560474157333374, acc: 0.7272727489471436)
[2025-02-17 16:42:16,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:16,863][root][INFO] - Training Epoch: 1/2, step 2565/107898 completed (loss: 0.017831163480877876, acc: 1.0)
[2025-02-17 16:42:16,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:17,191][root][INFO] - Training Epoch: 1/2, step 2566/107898 completed (loss: 1.6576603651046753, acc: 0.692307710647583)
[2025-02-17 16:42:17,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:17,519][root][INFO] - Training Epoch: 1/2, step 2567/107898 completed (loss: 0.14660164713859558, acc: 1.0)
[2025-02-17 16:42:17,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:17,852][root][INFO] - Training Epoch: 1/2, step 2568/107898 completed (loss: 0.22357861697673798, acc: 1.0)
[2025-02-17 16:42:17,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:18,136][root][INFO] - Training Epoch: 1/2, step 2569/107898 completed (loss: 0.5675914883613586, acc: 0.90625)
[2025-02-17 16:42:18,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:18,482][root][INFO] - Training Epoch: 1/2, step 2570/107898 completed (loss: 0.876725971698761, acc: 1.0)
[2025-02-17 16:42:18,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:18,831][root][INFO] - Training Epoch: 1/2, step 2571/107898 completed (loss: 0.6538038849830627, acc: 0.8399999737739563)
[2025-02-17 16:42:18,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:19,126][root][INFO] - Training Epoch: 1/2, step 2572/107898 completed (loss: 1.0049952268600464, acc: 0.7777777910232544)
[2025-02-17 16:42:19,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:19,440][root][INFO] - Training Epoch: 1/2, step 2573/107898 completed (loss: 2.1777799129486084, acc: 0.4285714328289032)
[2025-02-17 16:42:19,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:19,770][root][INFO] - Training Epoch: 1/2, step 2574/107898 completed (loss: 0.08692845702171326, acc: 1.0)
[2025-02-17 16:42:19,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:20,121][root][INFO] - Training Epoch: 1/2, step 2575/107898 completed (loss: 1.5531131029129028, acc: 0.6153846383094788)
[2025-02-17 16:42:20,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:20,440][root][INFO] - Training Epoch: 1/2, step 2576/107898 completed (loss: 1.172820806503296, acc: 0.9090909361839294)
[2025-02-17 16:42:20,525][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:20,749][root][INFO] - Training Epoch: 1/2, step 2577/107898 completed (loss: 0.2115868180990219, acc: 1.0)
[2025-02-17 16:42:20,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:21,066][root][INFO] - Training Epoch: 1/2, step 2578/107898 completed (loss: 0.10239467769861221, acc: 1.0)
[2025-02-17 16:42:21,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:21,392][root][INFO] - Training Epoch: 1/2, step 2579/107898 completed (loss: 1.3744481801986694, acc: 0.692307710647583)
[2025-02-17 16:42:21,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:21,723][root][INFO] - Training Epoch: 1/2, step 2580/107898 completed (loss: 1.1540093421936035, acc: 0.774193525314331)
[2025-02-17 16:42:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:22,038][root][INFO] - Training Epoch: 1/2, step 2581/107898 completed (loss: 0.38862699270248413, acc: 0.9285714030265808)
[2025-02-17 16:42:22,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:22,396][root][INFO] - Training Epoch: 1/2, step 2582/107898 completed (loss: 0.9350064396858215, acc: 0.8571428656578064)
[2025-02-17 16:42:22,483][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:22,703][root][INFO] - Training Epoch: 1/2, step 2583/107898 completed (loss: 1.0110069513320923, acc: 0.7777777910232544)
[2025-02-17 16:42:22,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:23,056][root][INFO] - Training Epoch: 1/2, step 2584/107898 completed (loss: 3.2298054695129395, acc: 0.6000000238418579)
[2025-02-17 16:42:23,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:23,359][root][INFO] - Training Epoch: 1/2, step 2585/107898 completed (loss: 1.250152349472046, acc: 0.800000011920929)
[2025-02-17 16:42:23,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:23,658][root][INFO] - Training Epoch: 1/2, step 2586/107898 completed (loss: 0.6651776432991028, acc: 0.7894737124443054)
[2025-02-17 16:42:23,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:23,964][root][INFO] - Training Epoch: 1/2, step 2587/107898 completed (loss: 0.8368980884552002, acc: 0.8095238208770752)
[2025-02-17 16:42:24,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:24,278][root][INFO] - Training Epoch: 1/2, step 2588/107898 completed (loss: 1.5036545991897583, acc: 0.5384615659713745)
[2025-02-17 16:42:24,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:24,619][root][INFO] - Training Epoch: 1/2, step 2589/107898 completed (loss: 3.8802709579467773, acc: 0.40909090638160706)
[2025-02-17 16:42:24,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:24,950][root][INFO] - Training Epoch: 1/2, step 2590/107898 completed (loss: 1.2257689237594604, acc: 0.7692307829856873)
[2025-02-17 16:42:25,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:25,307][root][INFO] - Training Epoch: 1/2, step 2591/107898 completed (loss: 0.8982245326042175, acc: 0.90625)
[2025-02-17 16:42:25,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:25,621][root][INFO] - Training Epoch: 1/2, step 2592/107898 completed (loss: 0.05244836583733559, acc: 1.0)
[2025-02-17 16:42:25,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:25,938][root][INFO] - Training Epoch: 1/2, step 2593/107898 completed (loss: 2.1694929599761963, acc: 0.5714285969734192)
[2025-02-17 16:42:26,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:26,257][root][INFO] - Training Epoch: 1/2, step 2594/107898 completed (loss: 0.2146104872226715, acc: 0.9375)
[2025-02-17 16:42:26,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:26,544][root][INFO] - Training Epoch: 1/2, step 2595/107898 completed (loss: 2.7910940647125244, acc: 0.5)
[2025-02-17 16:42:26,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:26,833][root][INFO] - Training Epoch: 1/2, step 2596/107898 completed (loss: 0.24588455259799957, acc: 0.9166666865348816)
[2025-02-17 16:42:26,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:27,121][root][INFO] - Training Epoch: 1/2, step 2597/107898 completed (loss: 2.8223013877868652, acc: 0.4615384638309479)
[2025-02-17 16:42:27,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:27,468][root][INFO] - Training Epoch: 1/2, step 2598/107898 completed (loss: 1.1782251596450806, acc: 0.7142857313156128)
[2025-02-17 16:42:27,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:27,797][root][INFO] - Training Epoch: 1/2, step 2599/107898 completed (loss: 0.15315747261047363, acc: 0.9523809552192688)
[2025-02-17 16:42:27,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:28,158][root][INFO] - Training Epoch: 1/2, step 2600/107898 completed (loss: 1.1630958318710327, acc: 0.8571428656578064)
[2025-02-17 16:42:28,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:28,450][root][INFO] - Training Epoch: 1/2, step 2601/107898 completed (loss: 0.023944612592458725, acc: 1.0)
[2025-02-17 16:42:28,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:28,743][root][INFO] - Training Epoch: 1/2, step 2602/107898 completed (loss: 0.3454646170139313, acc: 1.0)
[2025-02-17 16:42:28,849][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:29,094][root][INFO] - Training Epoch: 1/2, step 2603/107898 completed (loss: 1.2250003814697266, acc: 0.7142857313156128)
[2025-02-17 16:42:29,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:29,441][root][INFO] - Training Epoch: 1/2, step 2604/107898 completed (loss: 0.3771662712097168, acc: 1.0)
[2025-02-17 16:42:29,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:29,781][root][INFO] - Training Epoch: 1/2, step 2605/107898 completed (loss: 2.220799207687378, acc: 0.4000000059604645)
[2025-02-17 16:42:29,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:30,105][root][INFO] - Training Epoch: 1/2, step 2606/107898 completed (loss: 3.509986639022827, acc: 0.27272728085517883)
[2025-02-17 16:42:30,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:30,461][root][INFO] - Training Epoch: 1/2, step 2607/107898 completed (loss: 0.005248530302196741, acc: 1.0)
[2025-02-17 16:42:30,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:30,776][root][INFO] - Training Epoch: 1/2, step 2608/107898 completed (loss: 0.871567964553833, acc: 0.7916666865348816)
[2025-02-17 16:42:30,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:31,082][root][INFO] - Training Epoch: 1/2, step 2609/107898 completed (loss: 1.096956729888916, acc: 0.8095238208770752)
[2025-02-17 16:42:31,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:31,437][root][INFO] - Training Epoch: 1/2, step 2610/107898 completed (loss: 0.3825724422931671, acc: 0.9090909361839294)
[2025-02-17 16:42:31,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:31,736][root][INFO] - Training Epoch: 1/2, step 2611/107898 completed (loss: 1.647894024848938, acc: 0.8181818127632141)
[2025-02-17 16:42:31,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:32,027][root][INFO] - Training Epoch: 1/2, step 2612/107898 completed (loss: 2.767186403274536, acc: 0.5)
[2025-02-17 16:42:32,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:32,361][root][INFO] - Training Epoch: 1/2, step 2613/107898 completed (loss: 0.11936613917350769, acc: 1.0)
[2025-02-17 16:42:32,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:32,713][root][INFO] - Training Epoch: 1/2, step 2614/107898 completed (loss: 1.868675947189331, acc: 0.699999988079071)
[2025-02-17 16:42:32,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:32,994][root][INFO] - Training Epoch: 1/2, step 2615/107898 completed (loss: 0.025051888078451157, acc: 1.0)
[2025-02-17 16:42:33,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:33,292][root][INFO] - Training Epoch: 1/2, step 2616/107898 completed (loss: 3.3680531978607178, acc: 0.2142857164144516)
[2025-02-17 16:42:33,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:33,655][root][INFO] - Training Epoch: 1/2, step 2617/107898 completed (loss: 0.10413485765457153, acc: 1.0)
[2025-02-17 16:42:33,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:33,978][root][INFO] - Training Epoch: 1/2, step 2618/107898 completed (loss: 0.9050161242485046, acc: 0.6666666865348816)
[2025-02-17 16:42:34,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:34,294][root][INFO] - Training Epoch: 1/2, step 2619/107898 completed (loss: 1.0870766639709473, acc: 0.875)
[2025-02-17 16:42:34,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:34,602][root][INFO] - Training Epoch: 1/2, step 2620/107898 completed (loss: 0.010289361700415611, acc: 1.0)
[2025-02-17 16:42:34,685][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:34,916][root][INFO] - Training Epoch: 1/2, step 2621/107898 completed (loss: 0.09094542264938354, acc: 1.0)
[2025-02-17 16:42:35,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:35,227][root][INFO] - Training Epoch: 1/2, step 2622/107898 completed (loss: 0.4246487021446228, acc: 0.8571428656578064)
[2025-02-17 16:42:35,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:35,550][root][INFO] - Training Epoch: 1/2, step 2623/107898 completed (loss: 1.7623480558395386, acc: 0.6666666865348816)
[2025-02-17 16:42:35,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:35,859][root][INFO] - Training Epoch: 1/2, step 2624/107898 completed (loss: 0.03264991566538811, acc: 1.0)
[2025-02-17 16:42:35,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:36,216][root][INFO] - Training Epoch: 1/2, step 2625/107898 completed (loss: 4.005685329437256, acc: 0.20000000298023224)
[2025-02-17 16:42:36,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:36,561][root][INFO] - Training Epoch: 1/2, step 2626/107898 completed (loss: 3.4088122844696045, acc: 0.20000000298023224)
[2025-02-17 16:42:36,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:36,893][root][INFO] - Training Epoch: 1/2, step 2627/107898 completed (loss: 1.0071734189987183, acc: 0.800000011920929)
[2025-02-17 16:42:36,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:37,210][root][INFO] - Training Epoch: 1/2, step 2628/107898 completed (loss: 0.07018313556909561, acc: 1.0)
[2025-02-17 16:42:37,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:37,574][root][INFO] - Training Epoch: 1/2, step 2629/107898 completed (loss: 4.907366752624512, acc: 0.25)
[2025-02-17 16:42:37,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:37,906][root][INFO] - Training Epoch: 1/2, step 2630/107898 completed (loss: 0.5317566990852356, acc: 0.699999988079071)
[2025-02-17 16:42:38,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:38,254][root][INFO] - Training Epoch: 1/2, step 2631/107898 completed (loss: 0.4535028636455536, acc: 0.6666666865348816)
[2025-02-17 16:42:38,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:38,587][root][INFO] - Training Epoch: 1/2, step 2632/107898 completed (loss: 0.08676302433013916, acc: 1.0)
[2025-02-17 16:42:38,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:38,923][root][INFO] - Training Epoch: 1/2, step 2633/107898 completed (loss: 0.47129321098327637, acc: 0.9375)
[2025-02-17 16:42:39,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:39,250][root][INFO] - Training Epoch: 1/2, step 2634/107898 completed (loss: 0.040853552520275116, acc: 1.0)
[2025-02-17 16:42:39,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:39,561][root][INFO] - Training Epoch: 1/2, step 2635/107898 completed (loss: 0.5671482682228088, acc: 1.0)
[2025-02-17 16:42:39,635][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:39,840][root][INFO] - Training Epoch: 1/2, step 2636/107898 completed (loss: 0.5876532196998596, acc: 0.6666666865348816)
[2025-02-17 16:42:39,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:40,197][root][INFO] - Training Epoch: 1/2, step 2637/107898 completed (loss: 0.11454727500677109, acc: 1.0)
[2025-02-17 16:42:40,321][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:40,559][root][INFO] - Training Epoch: 1/2, step 2638/107898 completed (loss: 0.7341579794883728, acc: 0.807692289352417)
[2025-02-17 16:42:40,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:40,888][root][INFO] - Training Epoch: 1/2, step 2639/107898 completed (loss: 2.850679874420166, acc: 0.4285714328289032)
[2025-02-17 16:42:40,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:41,214][root][INFO] - Training Epoch: 1/2, step 2640/107898 completed (loss: 0.5134720206260681, acc: 0.9166666865348816)
[2025-02-17 16:42:41,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:41,556][root][INFO] - Training Epoch: 1/2, step 2641/107898 completed (loss: 0.31986406445503235, acc: 1.0)
[2025-02-17 16:42:41,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:41,887][root][INFO] - Training Epoch: 1/2, step 2642/107898 completed (loss: 0.8196890950202942, acc: 0.8333333134651184)
[2025-02-17 16:42:41,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:42,201][root][INFO] - Training Epoch: 1/2, step 2643/107898 completed (loss: 0.7017399668693542, acc: 0.8888888955116272)
[2025-02-17 16:42:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:42,556][root][INFO] - Training Epoch: 1/2, step 2644/107898 completed (loss: 0.07138698548078537, acc: 1.0)
[2025-02-17 16:42:42,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:42,840][root][INFO] - Training Epoch: 1/2, step 2645/107898 completed (loss: 0.4283398389816284, acc: 0.6666666865348816)
[2025-02-17 16:42:42,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:43,170][root][INFO] - Training Epoch: 1/2, step 2646/107898 completed (loss: 0.8022148013114929, acc: 0.8399999737739563)
[2025-02-17 16:42:43,257][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:43,473][root][INFO] - Training Epoch: 1/2, step 2647/107898 completed (loss: 0.6383770108222961, acc: 0.8333333134651184)
[2025-02-17 16:42:43,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:43,772][root][INFO] - Training Epoch: 1/2, step 2648/107898 completed (loss: 2.1752331256866455, acc: 0.4000000059604645)
[2025-02-17 16:42:43,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:44,072][root][INFO] - Training Epoch: 1/2, step 2649/107898 completed (loss: 0.008671719580888748, acc: 1.0)
[2025-02-17 16:42:44,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:44,372][root][INFO] - Training Epoch: 1/2, step 2650/107898 completed (loss: 0.3004671633243561, acc: 1.0)
[2025-02-17 16:42:44,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:44,670][root][INFO] - Training Epoch: 1/2, step 2651/107898 completed (loss: 2.1216495037078857, acc: 0.6666666865348816)
[2025-02-17 16:42:44,751][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:44,971][root][INFO] - Training Epoch: 1/2, step 2652/107898 completed (loss: 2.8678975105285645, acc: 0.5384615659713745)
[2025-02-17 16:42:45,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:45,294][root][INFO] - Training Epoch: 1/2, step 2653/107898 completed (loss: 5.120782375335693, acc: 0.5)
[2025-02-17 16:42:45,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:45,627][root][INFO] - Training Epoch: 1/2, step 2654/107898 completed (loss: 3.2014291286468506, acc: 0.3333333432674408)
[2025-02-17 16:42:45,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:45,919][root][INFO] - Training Epoch: 1/2, step 2655/107898 completed (loss: 0.2491324245929718, acc: 0.8571428656578064)
[2025-02-17 16:42:46,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:46,219][root][INFO] - Training Epoch: 1/2, step 2656/107898 completed (loss: 1.6663023233413696, acc: 0.8095238208770752)
[2025-02-17 16:42:46,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:46,538][root][INFO] - Training Epoch: 1/2, step 2657/107898 completed (loss: 2.175090789794922, acc: 0.5)
[2025-02-17 16:42:46,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:46,864][root][INFO] - Training Epoch: 1/2, step 2658/107898 completed (loss: 1.2631765604019165, acc: 0.5714285969734192)
[2025-02-17 16:42:46,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:47,186][root][INFO] - Training Epoch: 1/2, step 2659/107898 completed (loss: 0.9832927584648132, acc: 0.8620689511299133)
[2025-02-17 16:42:47,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:47,494][root][INFO] - Training Epoch: 1/2, step 2660/107898 completed (loss: 1.6960493326187134, acc: 0.6666666865348816)
[2025-02-17 16:42:47,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:47,796][root][INFO] - Training Epoch: 1/2, step 2661/107898 completed (loss: 1.375733494758606, acc: 0.5)
[2025-02-17 16:42:47,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:48,143][root][INFO] - Training Epoch: 1/2, step 2662/107898 completed (loss: 0.050917427986860275, acc: 1.0)
[2025-02-17 16:42:48,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:48,470][root][INFO] - Training Epoch: 1/2, step 2663/107898 completed (loss: 0.9245584011077881, acc: 0.5)
[2025-02-17 16:42:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:48,781][root][INFO] - Training Epoch: 1/2, step 2664/107898 completed (loss: 0.5024141073226929, acc: 1.0)
[2025-02-17 16:42:48,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:49,088][root][INFO] - Training Epoch: 1/2, step 2665/107898 completed (loss: 1.2251222133636475, acc: 0.0)
[2025-02-17 16:42:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:49,390][root][INFO] - Training Epoch: 1/2, step 2666/107898 completed (loss: 2.6085057258605957, acc: 0.5333333611488342)
[2025-02-17 16:42:49,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:49,695][root][INFO] - Training Epoch: 1/2, step 2667/107898 completed (loss: 0.382154643535614, acc: 0.8999999761581421)
[2025-02-17 16:42:49,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:50,029][root][INFO] - Training Epoch: 1/2, step 2668/107898 completed (loss: 1.9841711521148682, acc: 0.625)
[2025-02-17 16:42:50,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:50,350][root][INFO] - Training Epoch: 1/2, step 2669/107898 completed (loss: 0.6993206143379211, acc: 0.8484848737716675)
[2025-02-17 16:42:50,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:50,653][root][INFO] - Training Epoch: 1/2, step 2670/107898 completed (loss: 2.4152042865753174, acc: 0.6000000238418579)
[2025-02-17 16:42:50,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:50,950][root][INFO] - Training Epoch: 1/2, step 2671/107898 completed (loss: 0.7326577305793762, acc: 0.5)
[2025-02-17 16:42:51,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:51,276][root][INFO] - Training Epoch: 1/2, step 2672/107898 completed (loss: 0.5398615002632141, acc: 0.8947368264198303)
[2025-02-17 16:42:51,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:51,612][root][INFO] - Training Epoch: 1/2, step 2673/107898 completed (loss: 0.5349708795547485, acc: 0.9130434989929199)
[2025-02-17 16:42:51,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:51,927][root][INFO] - Training Epoch: 1/2, step 2674/107898 completed (loss: 2.5527560710906982, acc: 0.5)
[2025-02-17 16:42:52,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:52,242][root][INFO] - Training Epoch: 1/2, step 2675/107898 completed (loss: 0.28929272294044495, acc: 1.0)
[2025-02-17 16:42:52,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:52,559][root][INFO] - Training Epoch: 1/2, step 2676/107898 completed (loss: 0.9614791870117188, acc: 0.6666666865348816)
[2025-02-17 16:42:52,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:52,888][root][INFO] - Training Epoch: 1/2, step 2677/107898 completed (loss: 1.4796056747436523, acc: 0.6666666865348816)
[2025-02-17 16:42:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:53,214][root][INFO] - Training Epoch: 1/2, step 2678/107898 completed (loss: 2.524897813796997, acc: 0.5600000023841858)
[2025-02-17 16:42:53,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:53,525][root][INFO] - Training Epoch: 1/2, step 2679/107898 completed (loss: 0.3953200876712799, acc: 0.949999988079071)
[2025-02-17 16:42:53,635][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:53,875][root][INFO] - Training Epoch: 1/2, step 2680/107898 completed (loss: 0.17914418876171112, acc: 1.0)
[2025-02-17 16:42:53,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:54,192][root][INFO] - Training Epoch: 1/2, step 2681/107898 completed (loss: 3.8298861980438232, acc: 0.3333333432674408)
[2025-02-17 16:42:54,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:54,480][root][INFO] - Training Epoch: 1/2, step 2682/107898 completed (loss: 0.6466180086135864, acc: 1.0)
[2025-02-17 16:42:54,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:54,822][root][INFO] - Training Epoch: 1/2, step 2683/107898 completed (loss: 0.008412458933889866, acc: 1.0)
[2025-02-17 16:42:54,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:55,162][root][INFO] - Training Epoch: 1/2, step 2684/107898 completed (loss: 0.17163778841495514, acc: 1.0)
[2025-02-17 16:42:55,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:55,486][root][INFO] - Training Epoch: 1/2, step 2685/107898 completed (loss: 1.7390422821044922, acc: 0.5)
[2025-02-17 16:42:55,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:55,799][root][INFO] - Training Epoch: 1/2, step 2686/107898 completed (loss: 0.3455533981323242, acc: 1.0)
[2025-02-17 16:42:55,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:56,124][root][INFO] - Training Epoch: 1/2, step 2687/107898 completed (loss: 2.0668575763702393, acc: 0.6071428656578064)
[2025-02-17 16:42:56,227][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:56,449][root][INFO] - Training Epoch: 1/2, step 2688/107898 completed (loss: 3.1003777980804443, acc: 0.625)
[2025-02-17 16:42:56,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:56,753][root][INFO] - Training Epoch: 1/2, step 2689/107898 completed (loss: 0.0665198415517807, acc: 1.0)
[2025-02-17 16:42:56,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:57,057][root][INFO] - Training Epoch: 1/2, step 2690/107898 completed (loss: 0.6966527104377747, acc: 0.7142857313156128)
[2025-02-17 16:42:57,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:57,345][root][INFO] - Training Epoch: 1/2, step 2691/107898 completed (loss: 0.013152411207556725, acc: 1.0)
[2025-02-17 16:42:57,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:57,643][root][INFO] - Training Epoch: 1/2, step 2692/107898 completed (loss: 1.5259335041046143, acc: 0.800000011920929)
[2025-02-17 16:42:57,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:57,944][root][INFO] - Training Epoch: 1/2, step 2693/107898 completed (loss: 5.5876946449279785, acc: 0.3333333432674408)
[2025-02-17 16:42:58,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:58,244][root][INFO] - Training Epoch: 1/2, step 2694/107898 completed (loss: 2.3413538932800293, acc: 0.5)
[2025-02-17 16:42:58,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:58,537][root][INFO] - Training Epoch: 1/2, step 2695/107898 completed (loss: 4.367314338684082, acc: 0.4000000059604645)
[2025-02-17 16:42:58,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:58,835][root][INFO] - Training Epoch: 1/2, step 2696/107898 completed (loss: 1.280965805053711, acc: 0.7692307829856873)
[2025-02-17 16:42:58,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:59,136][root][INFO] - Training Epoch: 1/2, step 2697/107898 completed (loss: 0.09862674027681351, acc: 1.0)
[2025-02-17 16:42:59,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:59,455][root][INFO] - Training Epoch: 1/2, step 2698/107898 completed (loss: 2.4670612812042236, acc: 0.30000001192092896)
[2025-02-17 16:42:59,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:42:59,770][root][INFO] - Training Epoch: 1/2, step 2699/107898 completed (loss: 1.4541813135147095, acc: 0.6666666865348816)
[2025-02-17 16:42:59,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:00,115][root][INFO] - Training Epoch: 1/2, step 2700/107898 completed (loss: 0.6909356713294983, acc: 0.6666666865348816)
[2025-02-17 16:43:00,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:00,436][root][INFO] - Training Epoch: 1/2, step 2701/107898 completed (loss: 0.014684421941637993, acc: 1.0)
[2025-02-17 16:43:00,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:00,776][root][INFO] - Training Epoch: 1/2, step 2702/107898 completed (loss: 0.20731660723686218, acc: 1.0)
[2025-02-17 16:43:00,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:01,100][root][INFO] - Training Epoch: 1/2, step 2703/107898 completed (loss: 0.03248145431280136, acc: 1.0)
[2025-02-17 16:43:01,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:01,410][root][INFO] - Training Epoch: 1/2, step 2704/107898 completed (loss: 0.03517890349030495, acc: 1.0)
[2025-02-17 16:43:01,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:01,732][root][INFO] - Training Epoch: 1/2, step 2705/107898 completed (loss: 1.2494416236877441, acc: 0.800000011920929)
[2025-02-17 16:43:01,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:02,024][root][INFO] - Training Epoch: 1/2, step 2706/107898 completed (loss: 0.4677373766899109, acc: 1.0)
[2025-02-17 16:43:02,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:02,324][root][INFO] - Training Epoch: 1/2, step 2707/107898 completed (loss: 1.4754223823547363, acc: 0.7916666865348816)
[2025-02-17 16:43:02,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:02,619][root][INFO] - Training Epoch: 1/2, step 2708/107898 completed (loss: 1.0903252363204956, acc: 0.7142857313156128)
[2025-02-17 16:43:02,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:02,922][root][INFO] - Training Epoch: 1/2, step 2709/107898 completed (loss: 1.234671950340271, acc: 0.6666666865348816)
[2025-02-17 16:43:03,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:03,215][root][INFO] - Training Epoch: 1/2, step 2710/107898 completed (loss: 2.103506088256836, acc: 0.5714285969734192)
[2025-02-17 16:43:03,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:03,525][root][INFO] - Training Epoch: 1/2, step 2711/107898 completed (loss: 1.5030317306518555, acc: 0.75)
[2025-02-17 16:43:03,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:03,817][root][INFO] - Training Epoch: 1/2, step 2712/107898 completed (loss: 1.1864107847213745, acc: 0.782608687877655)
[2025-02-17 16:43:03,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:04,078][root][INFO] - Training Epoch: 1/2, step 2713/107898 completed (loss: 0.3581777513027191, acc: 0.8333333134651184)
[2025-02-17 16:43:04,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:04,369][root][INFO] - Training Epoch: 1/2, step 2714/107898 completed (loss: 0.8310155868530273, acc: 0.8333333134651184)
[2025-02-17 16:43:04,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:04,665][root][INFO] - Training Epoch: 1/2, step 2715/107898 completed (loss: 1.2945754528045654, acc: 0.7272727489471436)
[2025-02-17 16:43:04,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:04,972][root][INFO] - Training Epoch: 1/2, step 2716/107898 completed (loss: 1.1399542093276978, acc: 0.8125)
[2025-02-17 16:43:05,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:05,289][root][INFO] - Training Epoch: 1/2, step 2717/107898 completed (loss: 0.8038436770439148, acc: 0.8260869383811951)
[2025-02-17 16:43:05,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:05,581][root][INFO] - Training Epoch: 1/2, step 2718/107898 completed (loss: 0.566749632358551, acc: 0.875)
[2025-02-17 16:43:05,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:05,913][root][INFO] - Training Epoch: 1/2, step 2719/107898 completed (loss: 0.7155355215072632, acc: 1.0)
[2025-02-17 16:43:06,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:06,260][root][INFO] - Training Epoch: 1/2, step 2720/107898 completed (loss: 2.506338596343994, acc: 0.5)
[2025-02-17 16:43:06,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:06,607][root][INFO] - Training Epoch: 1/2, step 2721/107898 completed (loss: 0.3739478290081024, acc: 0.8461538553237915)
[2025-02-17 16:43:06,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:06,924][root][INFO] - Training Epoch: 1/2, step 2722/107898 completed (loss: 1.0466487407684326, acc: 0.6666666865348816)
[2025-02-17 16:43:07,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:07,220][root][INFO] - Training Epoch: 1/2, step 2723/107898 completed (loss: 0.23454849421977997, acc: 0.8888888955116272)
[2025-02-17 16:43:07,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:07,524][root][INFO] - Training Epoch: 1/2, step 2724/107898 completed (loss: 0.14647451043128967, acc: 1.0)
[2025-02-17 16:43:07,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:07,875][root][INFO] - Training Epoch: 1/2, step 2725/107898 completed (loss: 0.4888576567173004, acc: 0.8181818127632141)
[2025-02-17 16:43:07,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:08,272][root][INFO] - Training Epoch: 1/2, step 2726/107898 completed (loss: 0.1822819858789444, acc: 0.9375)
[2025-02-17 16:43:08,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:08,630][root][INFO] - Training Epoch: 1/2, step 2727/107898 completed (loss: 0.7009527087211609, acc: 0.8999999761581421)
[2025-02-17 16:43:08,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:08,979][root][INFO] - Training Epoch: 1/2, step 2728/107898 completed (loss: 2.530588150024414, acc: 0.5882353186607361)
[2025-02-17 16:43:09,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:09,293][root][INFO] - Training Epoch: 1/2, step 2729/107898 completed (loss: 4.145201683044434, acc: 0.1818181872367859)
[2025-02-17 16:43:09,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:09,595][root][INFO] - Training Epoch: 1/2, step 2730/107898 completed (loss: 0.307521253824234, acc: 1.0)
[2025-02-17 16:43:09,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:09,912][root][INFO] - Training Epoch: 1/2, step 2731/107898 completed (loss: 0.04761470481753349, acc: 1.0)
[2025-02-17 16:43:10,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:10,217][root][INFO] - Training Epoch: 1/2, step 2732/107898 completed (loss: 2.0156233310699463, acc: 0.7692307829856873)
[2025-02-17 16:43:10,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:10,519][root][INFO] - Training Epoch: 1/2, step 2733/107898 completed (loss: 0.0569816455245018, acc: 1.0)
[2025-02-17 16:43:10,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:10,846][root][INFO] - Training Epoch: 1/2, step 2734/107898 completed (loss: 0.4669573903083801, acc: 0.9375)
[2025-02-17 16:43:10,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:11,162][root][INFO] - Training Epoch: 1/2, step 2735/107898 completed (loss: 0.30188339948654175, acc: 1.0)
[2025-02-17 16:43:11,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:11,509][root][INFO] - Training Epoch: 1/2, step 2736/107898 completed (loss: 3.237072706222534, acc: 0.3333333432674408)
[2025-02-17 16:43:11,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:11,843][root][INFO] - Training Epoch: 1/2, step 2737/107898 completed (loss: 0.8824847936630249, acc: 0.8461538553237915)
[2025-02-17 16:43:11,971][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:12,221][root][INFO] - Training Epoch: 1/2, step 2738/107898 completed (loss: 1.388214349746704, acc: 0.5384615659713745)
[2025-02-17 16:43:12,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:12,581][root][INFO] - Training Epoch: 1/2, step 2739/107898 completed (loss: 3.174074411392212, acc: 0.3333333432674408)
[2025-02-17 16:43:12,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:12,907][root][INFO] - Training Epoch: 1/2, step 2740/107898 completed (loss: 1.576992392539978, acc: 0.7142857313156128)
[2025-02-17 16:43:13,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:13,243][root][INFO] - Training Epoch: 1/2, step 2741/107898 completed (loss: 0.787081241607666, acc: 0.8399999737739563)
[2025-02-17 16:43:13,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:13,566][root][INFO] - Training Epoch: 1/2, step 2742/107898 completed (loss: 1.6052383184432983, acc: 0.6666666865348816)
[2025-02-17 16:43:13,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:13,855][root][INFO] - Training Epoch: 1/2, step 2743/107898 completed (loss: 0.07183973491191864, acc: 1.0)
[2025-02-17 16:43:13,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:14,146][root][INFO] - Training Epoch: 1/2, step 2744/107898 completed (loss: 2.1363942623138428, acc: 0.7272727489471436)
[2025-02-17 16:43:14,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:14,460][root][INFO] - Training Epoch: 1/2, step 2745/107898 completed (loss: 1.6922117471694946, acc: 0.75)
[2025-02-17 16:43:14,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:14,796][root][INFO] - Training Epoch: 1/2, step 2746/107898 completed (loss: 1.6407697200775146, acc: 0.6428571343421936)
[2025-02-17 16:43:14,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:15,123][root][INFO] - Training Epoch: 1/2, step 2747/107898 completed (loss: 0.3953007161617279, acc: 1.0)
[2025-02-17 16:43:15,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:15,453][root][INFO] - Training Epoch: 1/2, step 2748/107898 completed (loss: 3.6624674797058105, acc: 0.13793103396892548)
[2025-02-17 16:43:15,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:15,756][root][INFO] - Training Epoch: 1/2, step 2749/107898 completed (loss: 1.5764844417572021, acc: 0.5)
[2025-02-17 16:43:15,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:16,082][root][INFO] - Training Epoch: 1/2, step 2750/107898 completed (loss: 1.1572364568710327, acc: 0.7647058963775635)
[2025-02-17 16:43:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:16,407][root][INFO] - Training Epoch: 1/2, step 2751/107898 completed (loss: 3.432117462158203, acc: 0.3333333432674408)
[2025-02-17 16:43:16,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:16,704][root][INFO] - Training Epoch: 1/2, step 2752/107898 completed (loss: 1.5713924169540405, acc: 0.7142857313156128)
[2025-02-17 16:43:16,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:17,022][root][INFO] - Training Epoch: 1/2, step 2753/107898 completed (loss: 0.1446460634469986, acc: 1.0)
[2025-02-17 16:43:17,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:17,354][root][INFO] - Training Epoch: 1/2, step 2754/107898 completed (loss: 2.148983955383301, acc: 0.550000011920929)
[2025-02-17 16:43:17,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:17,637][root][INFO] - Training Epoch: 1/2, step 2755/107898 completed (loss: 0.22341883182525635, acc: 1.0)
[2025-02-17 16:43:17,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:17,937][root][INFO] - Training Epoch: 1/2, step 2756/107898 completed (loss: 0.6153051257133484, acc: 0.7777777910232544)
[2025-02-17 16:43:18,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:18,226][root][INFO] - Training Epoch: 1/2, step 2757/107898 completed (loss: 0.3730192482471466, acc: 0.6666666865348816)
[2025-02-17 16:43:18,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:18,530][root][INFO] - Training Epoch: 1/2, step 2758/107898 completed (loss: 1.4791384935379028, acc: 0.75)
[2025-02-17 16:43:18,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:18,816][root][INFO] - Training Epoch: 1/2, step 2759/107898 completed (loss: 0.04507369548082352, acc: 1.0)
[2025-02-17 16:43:18,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:19,097][root][INFO] - Training Epoch: 1/2, step 2760/107898 completed (loss: 1.533869981765747, acc: 0.6000000238418579)
[2025-02-17 16:43:19,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:19,454][root][INFO] - Training Epoch: 1/2, step 2761/107898 completed (loss: 0.7361593842506409, acc: 0.8571428656578064)
[2025-02-17 16:43:19,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:19,751][root][INFO] - Training Epoch: 1/2, step 2762/107898 completed (loss: 1.0344823598861694, acc: 0.7894737124443054)
[2025-02-17 16:43:19,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:20,112][root][INFO] - Training Epoch: 1/2, step 2763/107898 completed (loss: 1.541316032409668, acc: 0.5)
[2025-02-17 16:43:20,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:20,444][root][INFO] - Training Epoch: 1/2, step 2764/107898 completed (loss: 2.4785499572753906, acc: 0.0)
[2025-02-17 16:43:20,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:20,768][root][INFO] - Training Epoch: 1/2, step 2765/107898 completed (loss: 0.9758093953132629, acc: 0.75)
[2025-02-17 16:43:20,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:21,081][root][INFO] - Training Epoch: 1/2, step 2766/107898 completed (loss: 3.172420024871826, acc: 0.5)
[2025-02-17 16:43:21,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:21,389][root][INFO] - Training Epoch: 1/2, step 2767/107898 completed (loss: 0.16432079672813416, acc: 1.0)
[2025-02-17 16:43:21,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:21,705][root][INFO] - Training Epoch: 1/2, step 2768/107898 completed (loss: 0.810693085193634, acc: 0.8333333134651184)
[2025-02-17 16:43:21,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:22,046][root][INFO] - Training Epoch: 1/2, step 2769/107898 completed (loss: 2.1533257961273193, acc: 0.692307710647583)
[2025-02-17 16:43:22,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:22,356][root][INFO] - Training Epoch: 1/2, step 2770/107898 completed (loss: 0.020310096442699432, acc: 1.0)
[2025-02-17 16:43:22,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:22,660][root][INFO] - Training Epoch: 1/2, step 2771/107898 completed (loss: 1.73408842086792, acc: 0.8181818127632141)
[2025-02-17 16:43:22,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:22,955][root][INFO] - Training Epoch: 1/2, step 2772/107898 completed (loss: 1.0459835529327393, acc: 0.6000000238418579)
[2025-02-17 16:43:23,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:23,316][root][INFO] - Training Epoch: 1/2, step 2773/107898 completed (loss: 1.0685524940490723, acc: 0.8235294222831726)
[2025-02-17 16:43:23,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:23,658][root][INFO] - Training Epoch: 1/2, step 2774/107898 completed (loss: 0.4193803071975708, acc: 1.0)
[2025-02-17 16:43:23,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:23,999][root][INFO] - Training Epoch: 1/2, step 2775/107898 completed (loss: 0.16303101181983948, acc: 1.0)
[2025-02-17 16:43:24,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:24,328][root][INFO] - Training Epoch: 1/2, step 2776/107898 completed (loss: 0.016339590772986412, acc: 1.0)
[2025-02-17 16:43:24,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:24,642][root][INFO] - Training Epoch: 1/2, step 2777/107898 completed (loss: 1.2800959348678589, acc: 0.5)
[2025-02-17 16:43:24,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:24,983][root][INFO] - Training Epoch: 1/2, step 2778/107898 completed (loss: 0.6824541687965393, acc: 0.8421052694320679)
[2025-02-17 16:43:25,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:25,336][root][INFO] - Training Epoch: 1/2, step 2779/107898 completed (loss: 0.007295285351574421, acc: 1.0)
[2025-02-17 16:43:25,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:25,663][root][INFO] - Training Epoch: 1/2, step 2780/107898 completed (loss: 1.111197829246521, acc: 0.4000000059604645)
[2025-02-17 16:43:25,774][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:25,996][root][INFO] - Training Epoch: 1/2, step 2781/107898 completed (loss: 3.4924895763397217, acc: 0.20000000298023224)
[2025-02-17 16:43:26,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:26,307][root][INFO] - Training Epoch: 1/2, step 2782/107898 completed (loss: 0.6927818059921265, acc: 0.8888888955116272)
[2025-02-17 16:43:26,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:26,674][root][INFO] - Training Epoch: 1/2, step 2783/107898 completed (loss: 0.5744293332099915, acc: 0.8095238208770752)
[2025-02-17 16:43:26,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:27,018][root][INFO] - Training Epoch: 1/2, step 2784/107898 completed (loss: 0.3763810694217682, acc: 0.9333333373069763)
[2025-02-17 16:43:27,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:27,369][root][INFO] - Training Epoch: 1/2, step 2785/107898 completed (loss: 1.032728672027588, acc: 0.5)
[2025-02-17 16:43:27,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:27,700][root][INFO] - Training Epoch: 1/2, step 2786/107898 completed (loss: 0.47311070561408997, acc: 0.9473684430122375)
[2025-02-17 16:43:27,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:28,043][root][INFO] - Training Epoch: 1/2, step 2787/107898 completed (loss: 1.6700235605239868, acc: 0.3333333432674408)
[2025-02-17 16:43:28,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:28,339][root][INFO] - Training Epoch: 1/2, step 2788/107898 completed (loss: 0.1576613187789917, acc: 1.0)
[2025-02-17 16:43:28,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:28,629][root][INFO] - Training Epoch: 1/2, step 2789/107898 completed (loss: 4.405023097991943, acc: 0.23529411852359772)
[2025-02-17 16:43:28,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:28,976][root][INFO] - Training Epoch: 1/2, step 2790/107898 completed (loss: 0.05756649374961853, acc: 1.0)
[2025-02-17 16:43:29,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:29,327][root][INFO] - Training Epoch: 1/2, step 2791/107898 completed (loss: 5.125526428222656, acc: 0.0)
[2025-02-17 16:43:29,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:29,655][root][INFO] - Training Epoch: 1/2, step 2792/107898 completed (loss: 0.01941542699933052, acc: 1.0)
[2025-02-17 16:43:29,737][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:29,957][root][INFO] - Training Epoch: 1/2, step 2793/107898 completed (loss: 0.5920562148094177, acc: 0.9090909361839294)
[2025-02-17 16:43:30,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:30,287][root][INFO] - Training Epoch: 1/2, step 2794/107898 completed (loss: 0.7811777591705322, acc: 0.800000011920929)
[2025-02-17 16:43:30,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:30,623][root][INFO] - Training Epoch: 1/2, step 2795/107898 completed (loss: 0.7175852656364441, acc: 0.8529411554336548)
[2025-02-17 16:43:30,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:30,942][root][INFO] - Training Epoch: 1/2, step 2796/107898 completed (loss: 0.1581447869539261, acc: 0.9411764740943909)
[2025-02-17 16:43:31,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:31,294][root][INFO] - Training Epoch: 1/2, step 2797/107898 completed (loss: 0.3734543025493622, acc: 0.8333333134651184)
[2025-02-17 16:43:31,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:31,606][root][INFO] - Training Epoch: 1/2, step 2798/107898 completed (loss: 3.159956455230713, acc: 0.25)
[2025-02-17 16:43:31,723][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:31,938][root][INFO] - Training Epoch: 1/2, step 2799/107898 completed (loss: 0.646087646484375, acc: 0.9166666865348816)
[2025-02-17 16:43:32,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:32,284][root][INFO] - Training Epoch: 1/2, step 2800/107898 completed (loss: 0.42460599541664124, acc: 0.8999999761581421)
[2025-02-17 16:43:32,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:32,617][root][INFO] - Training Epoch: 1/2, step 2801/107898 completed (loss: 2.982684373855591, acc: 0.5)
[2025-02-17 16:43:32,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:32,916][root][INFO] - Training Epoch: 1/2, step 2802/107898 completed (loss: 0.1039142832159996, acc: 0.9583333134651184)
[2025-02-17 16:43:32,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:33,221][root][INFO] - Training Epoch: 1/2, step 2803/107898 completed (loss: 0.08343485742807388, acc: 1.0)
[2025-02-17 16:43:33,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:33,594][root][INFO] - Training Epoch: 1/2, step 2804/107898 completed (loss: 3.910743236541748, acc: 0.05882352963089943)
[2025-02-17 16:43:33,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:33,921][root][INFO] - Training Epoch: 1/2, step 2805/107898 completed (loss: 0.04242154583334923, acc: 1.0)
[2025-02-17 16:43:34,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:34,219][root][INFO] - Training Epoch: 1/2, step 2806/107898 completed (loss: 1.315359354019165, acc: 0.5)
[2025-02-17 16:43:34,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:34,513][root][INFO] - Training Epoch: 1/2, step 2807/107898 completed (loss: 1.215437412261963, acc: 0.7058823704719543)
[2025-02-17 16:43:34,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:34,821][root][INFO] - Training Epoch: 1/2, step 2808/107898 completed (loss: 0.05908507481217384, acc: 1.0)
[2025-02-17 16:43:34,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:35,192][root][INFO] - Training Epoch: 1/2, step 2809/107898 completed (loss: 0.8321887254714966, acc: 0.5)
[2025-02-17 16:43:35,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:35,483][root][INFO] - Training Epoch: 1/2, step 2810/107898 completed (loss: 0.03266889601945877, acc: 1.0)
[2025-02-17 16:43:35,569][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:35,791][root][INFO] - Training Epoch: 1/2, step 2811/107898 completed (loss: 1.6177343130111694, acc: 0.6190476417541504)
[2025-02-17 16:43:35,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:36,100][root][INFO] - Training Epoch: 1/2, step 2812/107898 completed (loss: 0.1511976420879364, acc: 1.0)
[2025-02-17 16:43:36,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:36,414][root][INFO] - Training Epoch: 1/2, step 2813/107898 completed (loss: 2.428635597229004, acc: 0.5833333134651184)
[2025-02-17 16:43:36,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:36,723][root][INFO] - Training Epoch: 1/2, step 2814/107898 completed (loss: 0.39571094512939453, acc: 0.9166666865348816)
[2025-02-17 16:43:36,813][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:37,035][root][INFO] - Training Epoch: 1/2, step 2815/107898 completed (loss: 1.365849494934082, acc: 0.8235294222831726)
[2025-02-17 16:43:37,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:37,365][root][INFO] - Training Epoch: 1/2, step 2816/107898 completed (loss: 0.7772042155265808, acc: 0.800000011920929)
[2025-02-17 16:43:37,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:37,732][root][INFO] - Training Epoch: 1/2, step 2817/107898 completed (loss: 3.870645761489868, acc: 0.3103448152542114)
[2025-02-17 16:43:37,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:38,047][root][INFO] - Training Epoch: 1/2, step 2818/107898 completed (loss: 0.6867563128471375, acc: 0.8999999761581421)
[2025-02-17 16:43:38,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:38,357][root][INFO] - Training Epoch: 1/2, step 2819/107898 completed (loss: 1.94650399684906, acc: 0.6190476417541504)
[2025-02-17 16:43:38,478][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:38,708][root][INFO] - Training Epoch: 1/2, step 2820/107898 completed (loss: 1.5403493642807007, acc: 0.7272727489471436)
[2025-02-17 16:43:38,809][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:39,036][root][INFO] - Training Epoch: 1/2, step 2821/107898 completed (loss: 1.1424386501312256, acc: 0.7777777910232544)
[2025-02-17 16:43:39,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:39,355][root][INFO] - Training Epoch: 1/2, step 2822/107898 completed (loss: 0.48174113035202026, acc: 0.8999999761581421)
[2025-02-17 16:43:39,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:39,645][root][INFO] - Training Epoch: 1/2, step 2823/107898 completed (loss: 0.09771962463855743, acc: 1.0)
[2025-02-17 16:43:39,725][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:39,939][root][INFO] - Training Epoch: 1/2, step 2824/107898 completed (loss: 0.03199681639671326, acc: 1.0)
[2025-02-17 16:43:40,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:40,232][root][INFO] - Training Epoch: 1/2, step 2825/107898 completed (loss: 0.4003596901893616, acc: 0.800000011920929)
[2025-02-17 16:43:40,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:40,535][root][INFO] - Training Epoch: 1/2, step 2826/107898 completed (loss: 1.698911190032959, acc: 0.6666666865348816)
[2025-02-17 16:43:40,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:40,834][root][INFO] - Training Epoch: 1/2, step 2827/107898 completed (loss: 1.7471253871917725, acc: 0.800000011920929)
[2025-02-17 16:43:40,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:41,128][root][INFO] - Training Epoch: 1/2, step 2828/107898 completed (loss: 1.286199688911438, acc: 0.75)
[2025-02-17 16:43:41,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:41,424][root][INFO] - Training Epoch: 1/2, step 2829/107898 completed (loss: 0.7812375426292419, acc: 0.8333333134651184)
[2025-02-17 16:43:41,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:41,775][root][INFO] - Training Epoch: 1/2, step 2830/107898 completed (loss: 1.0785515308380127, acc: 0.8421052694320679)
[2025-02-17 16:43:41,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:42,062][root][INFO] - Training Epoch: 1/2, step 2831/107898 completed (loss: 2.851414442062378, acc: 0.3333333432674408)
[2025-02-17 16:43:42,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:42,356][root][INFO] - Training Epoch: 1/2, step 2832/107898 completed (loss: 1.553930640220642, acc: 0.5)
[2025-02-17 16:43:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:42,670][root][INFO] - Training Epoch: 1/2, step 2833/107898 completed (loss: 2.34964919090271, acc: 0.6111111044883728)
[2025-02-17 16:43:42,774][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:42,976][root][INFO] - Training Epoch: 1/2, step 2834/107898 completed (loss: 1.1191617250442505, acc: 0.7692307829856873)
[2025-02-17 16:43:43,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:43,281][root][INFO] - Training Epoch: 1/2, step 2835/107898 completed (loss: 2.517101764678955, acc: 0.375)
[2025-02-17 16:43:43,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:43,583][root][INFO] - Training Epoch: 1/2, step 2836/107898 completed (loss: 0.2697027325630188, acc: 1.0)
[2025-02-17 16:43:43,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:43,887][root][INFO] - Training Epoch: 1/2, step 2837/107898 completed (loss: 1.1290370225906372, acc: 0.75)
[2025-02-17 16:43:43,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:44,192][root][INFO] - Training Epoch: 1/2, step 2838/107898 completed (loss: 4.403329372406006, acc: 0.5)
[2025-02-17 16:43:44,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:44,487][root][INFO] - Training Epoch: 1/2, step 2839/107898 completed (loss: 0.6329774856567383, acc: 0.7142857313156128)
[2025-02-17 16:43:44,584][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:44,800][root][INFO] - Training Epoch: 1/2, step 2840/107898 completed (loss: 0.5162492990493774, acc: 0.8260869383811951)
[2025-02-17 16:43:44,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:45,094][root][INFO] - Training Epoch: 1/2, step 2841/107898 completed (loss: 0.028424303978681564, acc: 1.0)
[2025-02-17 16:43:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:45,420][root][INFO] - Training Epoch: 1/2, step 2842/107898 completed (loss: 0.5484975576400757, acc: 0.8500000238418579)
[2025-02-17 16:43:45,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:45,752][root][INFO] - Training Epoch: 1/2, step 2843/107898 completed (loss: 0.3628673255443573, acc: 0.9333333373069763)
[2025-02-17 16:43:45,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:46,084][root][INFO] - Training Epoch: 1/2, step 2844/107898 completed (loss: 0.15864546597003937, acc: 1.0)
[2025-02-17 16:43:46,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:46,402][root][INFO] - Training Epoch: 1/2, step 2845/107898 completed (loss: 0.06293948739767075, acc: 1.0)
[2025-02-17 16:43:46,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:46,703][root][INFO] - Training Epoch: 1/2, step 2846/107898 completed (loss: 0.8010350465774536, acc: 1.0)
[2025-02-17 16:43:46,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:47,026][root][INFO] - Training Epoch: 1/2, step 2847/107898 completed (loss: 0.5355023145675659, acc: 0.800000011920929)
[2025-02-17 16:43:47,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:47,342][root][INFO] - Training Epoch: 1/2, step 2848/107898 completed (loss: 0.5318307876586914, acc: 0.8695651888847351)
[2025-02-17 16:43:47,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:47,701][root][INFO] - Training Epoch: 1/2, step 2849/107898 completed (loss: 4.570323944091797, acc: 0.375)
[2025-02-17 16:43:47,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:48,040][root][INFO] - Training Epoch: 1/2, step 2850/107898 completed (loss: 2.2793638706207275, acc: 0.5)
[2025-02-17 16:43:48,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:48,351][root][INFO] - Training Epoch: 1/2, step 2851/107898 completed (loss: 0.46523261070251465, acc: 0.800000011920929)
[2025-02-17 16:43:48,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:48,655][root][INFO] - Training Epoch: 1/2, step 2852/107898 completed (loss: 2.9873266220092773, acc: 0.3636363744735718)
[2025-02-17 16:43:48,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:48,955][root][INFO] - Training Epoch: 1/2, step 2853/107898 completed (loss: 3.1886191368103027, acc: 0.3125)
[2025-02-17 16:43:49,043][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:49,261][root][INFO] - Training Epoch: 1/2, step 2854/107898 completed (loss: 2.5818867683410645, acc: 0.6000000238418579)
[2025-02-17 16:43:49,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:49,558][root][INFO] - Training Epoch: 1/2, step 2855/107898 completed (loss: 2.0660688877105713, acc: 0.6363636255264282)
[2025-02-17 16:43:49,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:49,851][root][INFO] - Training Epoch: 1/2, step 2856/107898 completed (loss: 0.021069830283522606, acc: 1.0)
[2025-02-17 16:43:49,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:50,149][root][INFO] - Training Epoch: 1/2, step 2857/107898 completed (loss: 0.0029559973627328873, acc: 1.0)
[2025-02-17 16:43:50,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:50,453][root][INFO] - Training Epoch: 1/2, step 2858/107898 completed (loss: 1.5599266290664673, acc: 0.7368420958518982)
[2025-02-17 16:43:50,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:50,765][root][INFO] - Training Epoch: 1/2, step 2859/107898 completed (loss: 1.3905994892120361, acc: 0.8181818127632141)
[2025-02-17 16:43:50,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:51,070][root][INFO] - Training Epoch: 1/2, step 2860/107898 completed (loss: 0.7779891490936279, acc: 0.75)
[2025-02-17 16:43:51,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:51,405][root][INFO] - Training Epoch: 1/2, step 2861/107898 completed (loss: 0.47223976254463196, acc: 0.8636363744735718)
[2025-02-17 16:43:51,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:51,710][root][INFO] - Training Epoch: 1/2, step 2862/107898 completed (loss: 0.6372114419937134, acc: 0.8999999761581421)
[2025-02-17 16:43:51,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:52,010][root][INFO] - Training Epoch: 1/2, step 2863/107898 completed (loss: 1.232770562171936, acc: 0.6176470518112183)
[2025-02-17 16:43:52,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:52,308][root][INFO] - Training Epoch: 1/2, step 2864/107898 completed (loss: 0.025900207459926605, acc: 1.0)
[2025-02-17 16:43:52,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:52,604][root][INFO] - Training Epoch: 1/2, step 2865/107898 completed (loss: 0.2441011220216751, acc: 0.800000011920929)
[2025-02-17 16:43:52,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:52,890][root][INFO] - Training Epoch: 1/2, step 2866/107898 completed (loss: 0.00255201430991292, acc: 1.0)
[2025-02-17 16:43:52,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:53,183][root][INFO] - Training Epoch: 1/2, step 2867/107898 completed (loss: 0.07575806975364685, acc: 1.0)
[2025-02-17 16:43:53,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:53,482][root][INFO] - Training Epoch: 1/2, step 2868/107898 completed (loss: 2.714569330215454, acc: 0.3333333432674408)
[2025-02-17 16:43:53,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:53,773][root][INFO] - Training Epoch: 1/2, step 2869/107898 completed (loss: 3.1216650009155273, acc: 0.5)
[2025-02-17 16:43:53,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:54,074][root][INFO] - Training Epoch: 1/2, step 2870/107898 completed (loss: 0.6412796974182129, acc: 0.6666666865348816)
[2025-02-17 16:43:54,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:54,374][root][INFO] - Training Epoch: 1/2, step 2871/107898 completed (loss: 0.09093110263347626, acc: 1.0)
[2025-02-17 16:43:54,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:54,673][root][INFO] - Training Epoch: 1/2, step 2872/107898 completed (loss: 0.11191468685865402, acc: 1.0)
[2025-02-17 16:43:54,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:55,001][root][INFO] - Training Epoch: 1/2, step 2873/107898 completed (loss: 2.723907947540283, acc: 0.5652173757553101)
[2025-02-17 16:43:55,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:55,309][root][INFO] - Training Epoch: 1/2, step 2874/107898 completed (loss: 0.031962115317583084, acc: 1.0)
[2025-02-17 16:43:55,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:55,669][root][INFO] - Training Epoch: 1/2, step 2875/107898 completed (loss: 0.4437733590602875, acc: 0.8999999761581421)
[2025-02-17 16:43:55,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:55,980][root][INFO] - Training Epoch: 1/2, step 2876/107898 completed (loss: 0.1969049721956253, acc: 1.0)
[2025-02-17 16:43:56,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:56,279][root][INFO] - Training Epoch: 1/2, step 2877/107898 completed (loss: 0.0013895730953663588, acc: 1.0)
[2025-02-17 16:43:56,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:56,609][root][INFO] - Training Epoch: 1/2, step 2878/107898 completed (loss: 1.4532716274261475, acc: 0.6666666865348816)
[2025-02-17 16:43:56,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:56,898][root][INFO] - Training Epoch: 1/2, step 2879/107898 completed (loss: 0.022606870159506798, acc: 1.0)
[2025-02-17 16:43:56,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:57,189][root][INFO] - Training Epoch: 1/2, step 2880/107898 completed (loss: 0.10005548596382141, acc: 1.0)
[2025-02-17 16:43:57,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:57,479][root][INFO] - Training Epoch: 1/2, step 2881/107898 completed (loss: 0.16997581720352173, acc: 1.0)
[2025-02-17 16:43:57,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:57,790][root][INFO] - Training Epoch: 1/2, step 2882/107898 completed (loss: 1.9622405767440796, acc: 0.6000000238418579)
[2025-02-17 16:43:57,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:58,105][root][INFO] - Training Epoch: 1/2, step 2883/107898 completed (loss: 2.6866683959960938, acc: 0.5)
[2025-02-17 16:43:58,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:58,437][root][INFO] - Training Epoch: 1/2, step 2884/107898 completed (loss: 0.00043757277308031917, acc: 1.0)
[2025-02-17 16:43:58,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:58,766][root][INFO] - Training Epoch: 1/2, step 2885/107898 completed (loss: 0.1816338449716568, acc: 0.9285714030265808)
[2025-02-17 16:43:58,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:59,081][root][INFO] - Training Epoch: 1/2, step 2886/107898 completed (loss: 1.7901573181152344, acc: 0.6000000238418579)
[2025-02-17 16:43:59,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:59,411][root][INFO] - Training Epoch: 1/2, step 2887/107898 completed (loss: 0.5824594497680664, acc: 0.8399999737739563)
[2025-02-17 16:43:59,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:59,662][root][INFO] - Training Epoch: 1/2, step 2888/107898 completed (loss: 0.6594680547714233, acc: 0.7142857313156128)
[2025-02-17 16:43:59,774][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:43:59,994][root][INFO] - Training Epoch: 1/2, step 2889/107898 completed (loss: 1.2989479303359985, acc: 0.6666666865348816)
[2025-02-17 16:44:00,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:00,302][root][INFO] - Training Epoch: 1/2, step 2890/107898 completed (loss: 1.5801095962524414, acc: 0.625)
[2025-02-17 16:44:00,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:00,597][root][INFO] - Training Epoch: 1/2, step 2891/107898 completed (loss: 4.511773586273193, acc: 0.5)
[2025-02-17 16:44:00,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:00,932][root][INFO] - Training Epoch: 1/2, step 2892/107898 completed (loss: 1.7097712755203247, acc: 0.5)
[2025-02-17 16:44:01,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:01,245][root][INFO] - Training Epoch: 1/2, step 2893/107898 completed (loss: 0.3232906758785248, acc: 0.9090909361839294)
[2025-02-17 16:44:01,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:01,548][root][INFO] - Training Epoch: 1/2, step 2894/107898 completed (loss: 0.14725980162620544, acc: 1.0)
[2025-02-17 16:44:01,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:01,863][root][INFO] - Training Epoch: 1/2, step 2895/107898 completed (loss: 0.3017845153808594, acc: 1.0)
[2025-02-17 16:44:01,950][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:02,169][root][INFO] - Training Epoch: 1/2, step 2896/107898 completed (loss: 2.558445453643799, acc: 0.5)
[2025-02-17 16:44:02,242][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:02,455][root][INFO] - Training Epoch: 1/2, step 2897/107898 completed (loss: 0.4046971797943115, acc: 0.800000011920929)
[2025-02-17 16:44:02,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:02,740][root][INFO] - Training Epoch: 1/2, step 2898/107898 completed (loss: 0.13073652982711792, acc: 1.0)
[2025-02-17 16:44:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:03,037][root][INFO] - Training Epoch: 1/2, step 2899/107898 completed (loss: 1.5099283456802368, acc: 0.6000000238418579)
[2025-02-17 16:44:03,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:03,324][root][INFO] - Training Epoch: 1/2, step 2900/107898 completed (loss: 0.00043810607166960835, acc: 1.0)
[2025-02-17 16:44:03,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:03,682][root][INFO] - Training Epoch: 1/2, step 2901/107898 completed (loss: 0.0011479227105155587, acc: 1.0)
[2025-02-17 16:44:03,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:04,013][root][INFO] - Training Epoch: 1/2, step 2902/107898 completed (loss: 0.9962494969367981, acc: 0.7647058963775635)
[2025-02-17 16:44:04,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:04,330][root][INFO] - Training Epoch: 1/2, step 2903/107898 completed (loss: 0.0007196145597845316, acc: 1.0)
[2025-02-17 16:44:04,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:04,625][root][INFO] - Training Epoch: 1/2, step 2904/107898 completed (loss: 0.037300046533346176, acc: 1.0)
[2025-02-17 16:44:04,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:04,939][root][INFO] - Training Epoch: 1/2, step 2905/107898 completed (loss: 4.250797271728516, acc: 0.2380952388048172)
[2025-02-17 16:44:05,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:05,230][root][INFO] - Training Epoch: 1/2, step 2906/107898 completed (loss: 2.537511110305786, acc: 0.6666666865348816)
[2025-02-17 16:44:05,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:05,515][root][INFO] - Training Epoch: 1/2, step 2907/107898 completed (loss: 0.005812828429043293, acc: 1.0)
[2025-02-17 16:44:05,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:05,854][root][INFO] - Training Epoch: 1/2, step 2908/107898 completed (loss: 0.003564384300261736, acc: 1.0)
[2025-02-17 16:44:05,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:06,172][root][INFO] - Training Epoch: 1/2, step 2909/107898 completed (loss: 0.03504861146211624, acc: 1.0)
[2025-02-17 16:44:06,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:06,480][root][INFO] - Training Epoch: 1/2, step 2910/107898 completed (loss: 0.46593788266181946, acc: 0.5)
[2025-02-17 16:44:06,570][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:06,797][root][INFO] - Training Epoch: 1/2, step 2911/107898 completed (loss: 0.5008227229118347, acc: 0.5)
[2025-02-17 16:44:06,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:07,085][root][INFO] - Training Epoch: 1/2, step 2912/107898 completed (loss: 1.7267487049102783, acc: 0.5)
[2025-02-17 16:44:07,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:07,388][root][INFO] - Training Epoch: 1/2, step 2913/107898 completed (loss: 0.2899470329284668, acc: 1.0)
[2025-02-17 16:44:07,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:07,704][root][INFO] - Training Epoch: 1/2, step 2914/107898 completed (loss: 0.6248111128807068, acc: 0.9090909361839294)
[2025-02-17 16:44:07,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:08,024][root][INFO] - Training Epoch: 1/2, step 2915/107898 completed (loss: 0.06543337553739548, acc: 1.0)
[2025-02-17 16:44:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:08,331][root][INFO] - Training Epoch: 1/2, step 2916/107898 completed (loss: 1.152756690979004, acc: 0.75)
[2025-02-17 16:44:08,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:08,642][root][INFO] - Training Epoch: 1/2, step 2917/107898 completed (loss: 0.8165839910507202, acc: 0.7857142686843872)
[2025-02-17 16:44:08,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:08,941][root][INFO] - Training Epoch: 1/2, step 2918/107898 completed (loss: 2.5281715393066406, acc: 0.5)
[2025-02-17 16:44:09,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:09,293][root][INFO] - Training Epoch: 1/2, step 2919/107898 completed (loss: 2.1834123134613037, acc: 0.4285714328289032)
[2025-02-17 16:44:09,385][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:09,618][root][INFO] - Training Epoch: 1/2, step 2920/107898 completed (loss: 0.03948786109685898, acc: 1.0)
[2025-02-17 16:44:09,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:09,932][root][INFO] - Training Epoch: 1/2, step 2921/107898 completed (loss: 2.8924479484558105, acc: 0.27272728085517883)
[2025-02-17 16:44:10,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:10,244][root][INFO] - Training Epoch: 1/2, step 2922/107898 completed (loss: 0.3547740876674652, acc: 0.949999988079071)
[2025-02-17 16:44:10,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:10,561][root][INFO] - Training Epoch: 1/2, step 2923/107898 completed (loss: 3.627084493637085, acc: 0.3333333432674408)
[2025-02-17 16:44:10,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:10,923][root][INFO] - Training Epoch: 1/2, step 2924/107898 completed (loss: 1.1124831438064575, acc: 0.6363636255264282)
[2025-02-17 16:44:11,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:11,259][root][INFO] - Training Epoch: 1/2, step 2925/107898 completed (loss: 2.5506207942962646, acc: 0.6000000238418579)
[2025-02-17 16:44:11,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:11,624][root][INFO] - Training Epoch: 1/2, step 2926/107898 completed (loss: 4.229880332946777, acc: 0.3333333432674408)
[2025-02-17 16:44:11,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:11,954][root][INFO] - Training Epoch: 1/2, step 2927/107898 completed (loss: 1.7435754537582397, acc: 0.5)
[2025-02-17 16:44:12,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:12,279][root][INFO] - Training Epoch: 1/2, step 2928/107898 completed (loss: 0.014741122722625732, acc: 1.0)
[2025-02-17 16:44:12,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:12,593][root][INFO] - Training Epoch: 1/2, step 2929/107898 completed (loss: 0.32059210538864136, acc: 0.875)
[2025-02-17 16:44:12,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:12,908][root][INFO] - Training Epoch: 1/2, step 2930/107898 completed (loss: 0.05974862724542618, acc: 1.0)
[2025-02-17 16:44:12,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:13,203][root][INFO] - Training Epoch: 1/2, step 2931/107898 completed (loss: 2.132556676864624, acc: 0.5454545617103577)
[2025-02-17 16:44:13,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:13,505][root][INFO] - Training Epoch: 1/2, step 2932/107898 completed (loss: 2.1036128997802734, acc: 0.7058823704719543)
[2025-02-17 16:44:13,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:13,817][root][INFO] - Training Epoch: 1/2, step 2933/107898 completed (loss: 1.3930020332336426, acc: 0.625)
[2025-02-17 16:44:13,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:14,139][root][INFO] - Training Epoch: 1/2, step 2934/107898 completed (loss: 0.8980173468589783, acc: 0.800000011920929)
[2025-02-17 16:44:14,229][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:14,451][root][INFO] - Training Epoch: 1/2, step 2935/107898 completed (loss: 0.5726474523544312, acc: 1.0)
[2025-02-17 16:44:14,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:14,757][root][INFO] - Training Epoch: 1/2, step 2936/107898 completed (loss: 0.028405405580997467, acc: 1.0)
[2025-02-17 16:44:14,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:15,066][root][INFO] - Training Epoch: 1/2, step 2937/107898 completed (loss: 0.8694555163383484, acc: 0.7727272510528564)
[2025-02-17 16:44:15,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:15,398][root][INFO] - Training Epoch: 1/2, step 2938/107898 completed (loss: 0.9618608951568604, acc: 0.7954545617103577)
[2025-02-17 16:44:15,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:15,689][root][INFO] - Training Epoch: 1/2, step 2939/107898 completed (loss: 1.2405750751495361, acc: 0.7272727489471436)
[2025-02-17 16:44:15,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:16,041][root][INFO] - Training Epoch: 1/2, step 2940/107898 completed (loss: 0.515326201915741, acc: 0.9333333373069763)
[2025-02-17 16:44:16,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:16,366][root][INFO] - Training Epoch: 1/2, step 2941/107898 completed (loss: 1.812549352645874, acc: 0.5862069129943848)
[2025-02-17 16:44:16,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:16,661][root][INFO] - Training Epoch: 1/2, step 2942/107898 completed (loss: 1.053420066833496, acc: 0.8999999761581421)
[2025-02-17 16:44:16,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:16,955][root][INFO] - Training Epoch: 1/2, step 2943/107898 completed (loss: 0.08773157745599747, acc: 1.0)
[2025-02-17 16:44:17,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:17,254][root][INFO] - Training Epoch: 1/2, step 2944/107898 completed (loss: 3.8526134490966797, acc: 0.1428571492433548)
[2025-02-17 16:44:17,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:17,566][root][INFO] - Training Epoch: 1/2, step 2945/107898 completed (loss: 1.370162010192871, acc: 0.6666666865348816)
[2025-02-17 16:44:17,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:17,866][root][INFO] - Training Epoch: 1/2, step 2946/107898 completed (loss: 0.08419043570756912, acc: 1.0)
[2025-02-17 16:44:17,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:18,192][root][INFO] - Training Epoch: 1/2, step 2947/107898 completed (loss: 0.38847848773002625, acc: 0.8823529481887817)
[2025-02-17 16:44:18,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:18,520][root][INFO] - Training Epoch: 1/2, step 2948/107898 completed (loss: 1.6439368724822998, acc: 0.6153846383094788)
[2025-02-17 16:44:18,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:18,848][root][INFO] - Training Epoch: 1/2, step 2949/107898 completed (loss: 3.112612724304199, acc: 0.4615384638309479)
[2025-02-17 16:44:18,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:19,154][root][INFO] - Training Epoch: 1/2, step 2950/107898 completed (loss: 3.4499809741973877, acc: 0.5)
[2025-02-17 16:44:19,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:19,449][root][INFO] - Training Epoch: 1/2, step 2951/107898 completed (loss: 1.497463345527649, acc: 0.7272727489471436)
[2025-02-17 16:44:19,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:19,743][root][INFO] - Training Epoch: 1/2, step 2952/107898 completed (loss: 0.33171546459198, acc: 0.8333333134651184)
[2025-02-17 16:44:19,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:20,036][root][INFO] - Training Epoch: 1/2, step 2953/107898 completed (loss: 1.3187674283981323, acc: 0.5833333134651184)
[2025-02-17 16:44:20,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:20,332][root][INFO] - Training Epoch: 1/2, step 2954/107898 completed (loss: 3.8556838035583496, acc: 0.25)
[2025-02-17 16:44:20,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:20,631][root][INFO] - Training Epoch: 1/2, step 2955/107898 completed (loss: 1.6239653825759888, acc: 0.5)
[2025-02-17 16:44:20,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:20,932][root][INFO] - Training Epoch: 1/2, step 2956/107898 completed (loss: 0.03561129793524742, acc: 1.0)
[2025-02-17 16:44:21,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:21,236][root][INFO] - Training Epoch: 1/2, step 2957/107898 completed (loss: 0.5103188753128052, acc: 0.8666666746139526)
[2025-02-17 16:44:21,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:21,534][root][INFO] - Training Epoch: 1/2, step 2958/107898 completed (loss: 0.18906953930854797, acc: 0.9375)
[2025-02-17 16:44:21,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:21,830][root][INFO] - Training Epoch: 1/2, step 2959/107898 completed (loss: 1.0944019556045532, acc: 0.9090909361839294)
[2025-02-17 16:44:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:22,142][root][INFO] - Training Epoch: 1/2, step 2960/107898 completed (loss: 1.0489150285720825, acc: 0.6666666865348816)
[2025-02-17 16:44:22,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:22,457][root][INFO] - Training Epoch: 1/2, step 2961/107898 completed (loss: 0.19974201917648315, acc: 1.0)
[2025-02-17 16:44:22,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:22,762][root][INFO] - Training Epoch: 1/2, step 2962/107898 completed (loss: 0.0208006352186203, acc: 1.0)
[2025-02-17 16:44:22,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:23,104][root][INFO] - Training Epoch: 1/2, step 2963/107898 completed (loss: 2.7684454917907715, acc: 0.42307692766189575)
[2025-02-17 16:44:23,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:23,432][root][INFO] - Training Epoch: 1/2, step 2964/107898 completed (loss: 0.5920761227607727, acc: 1.0)
[2025-02-17 16:44:23,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:23,784][root][INFO] - Training Epoch: 1/2, step 2965/107898 completed (loss: 0.893765389919281, acc: 0.6666666865348816)
[2025-02-17 16:44:23,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:24,097][root][INFO] - Training Epoch: 1/2, step 2966/107898 completed (loss: 0.009062843397259712, acc: 1.0)
[2025-02-17 16:44:24,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:24,411][root][INFO] - Training Epoch: 1/2, step 2967/107898 completed (loss: 0.17333321273326874, acc: 0.95652174949646)
[2025-02-17 16:44:24,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:24,740][root][INFO] - Training Epoch: 1/2, step 2968/107898 completed (loss: 0.030177515000104904, acc: 1.0)
[2025-02-17 16:44:24,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:25,054][root][INFO] - Training Epoch: 1/2, step 2969/107898 completed (loss: 0.28853175044059753, acc: 1.0)
[2025-02-17 16:44:25,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:25,394][root][INFO] - Training Epoch: 1/2, step 2970/107898 completed (loss: 0.3861931264400482, acc: 0.8571428656578064)
[2025-02-17 16:44:25,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:25,716][root][INFO] - Training Epoch: 1/2, step 2971/107898 completed (loss: 0.31963589787483215, acc: 0.9545454382896423)
[2025-02-17 16:44:25,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:25,997][root][INFO] - Training Epoch: 1/2, step 2972/107898 completed (loss: 2.649099826812744, acc: 0.4444444477558136)
[2025-02-17 16:44:26,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:26,285][root][INFO] - Training Epoch: 1/2, step 2973/107898 completed (loss: 0.33669501543045044, acc: 1.0)
[2025-02-17 16:44:26,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:26,589][root][INFO] - Training Epoch: 1/2, step 2974/107898 completed (loss: 1.384921669960022, acc: 0.7727272510528564)
[2025-02-17 16:44:26,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:26,921][root][INFO] - Training Epoch: 1/2, step 2975/107898 completed (loss: 0.026112835854291916, acc: 1.0)
[2025-02-17 16:44:27,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:27,219][root][INFO] - Training Epoch: 1/2, step 2976/107898 completed (loss: 3.7405142784118652, acc: 0.25)
[2025-02-17 16:44:27,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:27,548][root][INFO] - Training Epoch: 1/2, step 2977/107898 completed (loss: 3.2280831336975098, acc: 0.4615384638309479)
[2025-02-17 16:44:27,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:27,877][root][INFO] - Training Epoch: 1/2, step 2978/107898 completed (loss: 1.5568398237228394, acc: 0.8235294222831726)
[2025-02-17 16:44:27,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:28,175][root][INFO] - Training Epoch: 1/2, step 2979/107898 completed (loss: 2.293090343475342, acc: 0.0)
[2025-02-17 16:44:28,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:28,469][root][INFO] - Training Epoch: 1/2, step 2980/107898 completed (loss: 2.021940231323242, acc: 0.6666666865348816)
[2025-02-17 16:44:28,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:28,783][root][INFO] - Training Epoch: 1/2, step 2981/107898 completed (loss: 2.903796911239624, acc: 0.4545454680919647)
[2025-02-17 16:44:28,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:29,078][root][INFO] - Training Epoch: 1/2, step 2982/107898 completed (loss: 3.5542542934417725, acc: 0.1666666716337204)
[2025-02-17 16:44:29,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:29,378][root][INFO] - Training Epoch: 1/2, step 2983/107898 completed (loss: 4.394983291625977, acc: 0.3333333432674408)
[2025-02-17 16:44:29,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:29,683][root][INFO] - Training Epoch: 1/2, step 2984/107898 completed (loss: 3.517469882965088, acc: 0.3076923191547394)
[2025-02-17 16:44:29,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:29,982][root][INFO] - Training Epoch: 1/2, step 2985/107898 completed (loss: 0.10310391336679459, acc: 1.0)
[2025-02-17 16:44:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:30,274][root][INFO] - Training Epoch: 1/2, step 2986/107898 completed (loss: 2.262336254119873, acc: 0.5)
[2025-02-17 16:44:30,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:30,565][root][INFO] - Training Epoch: 1/2, step 2987/107898 completed (loss: 0.6167849898338318, acc: 1.0)
[2025-02-17 16:44:30,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:30,882][root][INFO] - Training Epoch: 1/2, step 2988/107898 completed (loss: 0.40634679794311523, acc: 0.800000011920929)
[2025-02-17 16:44:30,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:31,211][root][INFO] - Training Epoch: 1/2, step 2989/107898 completed (loss: 1.0874838829040527, acc: 0.5)
[2025-02-17 16:44:31,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:31,518][root][INFO] - Training Epoch: 1/2, step 2990/107898 completed (loss: 0.5660000443458557, acc: 0.875)
[2025-02-17 16:44:31,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:31,815][root][INFO] - Training Epoch: 1/2, step 2991/107898 completed (loss: 3.466367721557617, acc: 0.3333333432674408)
[2025-02-17 16:44:31,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:32,123][root][INFO] - Training Epoch: 1/2, step 2992/107898 completed (loss: 0.46330004930496216, acc: 1.0)
[2025-02-17 16:44:32,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:32,496][root][INFO] - Training Epoch: 1/2, step 2993/107898 completed (loss: 0.5354685187339783, acc: 0.9130434989929199)
[2025-02-17 16:44:32,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:32,790][root][INFO] - Training Epoch: 1/2, step 2994/107898 completed (loss: 1.2598893642425537, acc: 0.800000011920929)
[2025-02-17 16:44:32,872][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:33,088][root][INFO] - Training Epoch: 1/2, step 2995/107898 completed (loss: 1.001455307006836, acc: 0.7272727489471436)
[2025-02-17 16:44:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:33,411][root][INFO] - Training Epoch: 1/2, step 2996/107898 completed (loss: 0.5943796038627625, acc: 0.875)
[2025-02-17 16:44:33,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:33,760][root][INFO] - Training Epoch: 1/2, step 2997/107898 completed (loss: 2.9811227321624756, acc: 0.25)
[2025-02-17 16:44:33,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:34,082][root][INFO] - Training Epoch: 1/2, step 2998/107898 completed (loss: 0.9418455958366394, acc: 0.8148148059844971)
[2025-02-17 16:44:34,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:34,410][root][INFO] - Training Epoch: 1/2, step 2999/107898 completed (loss: 2.4691803455352783, acc: 0.6000000238418579)
[2025-02-17 16:44:34,509][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:34,731][root][INFO] - Training Epoch: 1/2, step 3000/107898 completed (loss: 0.059384386986494064, acc: 1.0)
[2025-02-17 16:44:34,813][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:35,036][root][INFO] - Training Epoch: 1/2, step 3001/107898 completed (loss: 0.0237870030105114, acc: 1.0)
[2025-02-17 16:44:35,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:35,360][root][INFO] - Training Epoch: 1/2, step 3002/107898 completed (loss: 0.0901162251830101, acc: 1.0)
[2025-02-17 16:44:35,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:35,688][root][INFO] - Training Epoch: 1/2, step 3003/107898 completed (loss: 0.023484470322728157, acc: 1.0)
[2025-02-17 16:44:35,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:36,013][root][INFO] - Training Epoch: 1/2, step 3004/107898 completed (loss: 3.5054471492767334, acc: 0.25)
[2025-02-17 16:44:36,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:36,336][root][INFO] - Training Epoch: 1/2, step 3005/107898 completed (loss: 0.9289889931678772, acc: 0.8695651888847351)
[2025-02-17 16:44:36,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:36,673][root][INFO] - Training Epoch: 1/2, step 3006/107898 completed (loss: 0.3710384666919708, acc: 0.9230769276618958)
[2025-02-17 16:44:36,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:36,985][root][INFO] - Training Epoch: 1/2, step 3007/107898 completed (loss: 1.1728078126907349, acc: 0.75)
[2025-02-17 16:44:37,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:37,341][root][INFO] - Training Epoch: 1/2, step 3008/107898 completed (loss: 0.17895545065402985, acc: 0.9375)
[2025-02-17 16:44:37,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:37,680][root][INFO] - Training Epoch: 1/2, step 3009/107898 completed (loss: 1.4200831651687622, acc: 0.7692307829856873)
[2025-02-17 16:44:37,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:38,063][root][INFO] - Training Epoch: 1/2, step 3010/107898 completed (loss: 1.388696551322937, acc: 0.7407407164573669)
[2025-02-17 16:44:38,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:38,368][root][INFO] - Training Epoch: 1/2, step 3011/107898 completed (loss: 2.717766046524048, acc: 0.46666666865348816)
[2025-02-17 16:44:38,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:38,719][root][INFO] - Training Epoch: 1/2, step 3012/107898 completed (loss: 0.7826693654060364, acc: 0.8666666746139526)
[2025-02-17 16:44:38,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:39,017][root][INFO] - Training Epoch: 1/2, step 3013/107898 completed (loss: 1.7777724266052246, acc: 0.5)
[2025-02-17 16:44:39,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:39,377][root][INFO] - Training Epoch: 1/2, step 3014/107898 completed (loss: 0.49628007411956787, acc: 1.0)
[2025-02-17 16:44:39,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:39,710][root][INFO] - Training Epoch: 1/2, step 3015/107898 completed (loss: 1.6197680234909058, acc: 0.6666666865348816)
[2025-02-17 16:44:39,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:40,037][root][INFO] - Training Epoch: 1/2, step 3016/107898 completed (loss: 1.8639111518859863, acc: 0.6153846383094788)
[2025-02-17 16:44:40,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:40,332][root][INFO] - Training Epoch: 1/2, step 3017/107898 completed (loss: 0.7881797552108765, acc: 0.8666666746139526)
[2025-02-17 16:44:40,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:40,680][root][INFO] - Training Epoch: 1/2, step 3018/107898 completed (loss: 1.3069865703582764, acc: 0.7272727489471436)
[2025-02-17 16:44:40,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:41,005][root][INFO] - Training Epoch: 1/2, step 3019/107898 completed (loss: 0.14045502245426178, acc: 1.0)
[2025-02-17 16:44:41,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:41,340][root][INFO] - Training Epoch: 1/2, step 3020/107898 completed (loss: 0.41442763805389404, acc: 0.9411764740943909)
[2025-02-17 16:44:41,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:41,626][root][INFO] - Training Epoch: 1/2, step 3021/107898 completed (loss: 0.009922336786985397, acc: 1.0)
[2025-02-17 16:44:41,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:41,965][root][INFO] - Training Epoch: 1/2, step 3022/107898 completed (loss: 0.13844448328018188, acc: 1.0)
[2025-02-17 16:44:42,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:42,313][root][INFO] - Training Epoch: 1/2, step 3023/107898 completed (loss: 1.1936708688735962, acc: 0.75)
[2025-02-17 16:44:42,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:42,625][root][INFO] - Training Epoch: 1/2, step 3024/107898 completed (loss: 0.29017210006713867, acc: 1.0)
[2025-02-17 16:44:42,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:42,944][root][INFO] - Training Epoch: 1/2, step 3025/107898 completed (loss: 0.4822694957256317, acc: 1.0)
[2025-02-17 16:44:43,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:43,281][root][INFO] - Training Epoch: 1/2, step 3026/107898 completed (loss: 1.0041558742523193, acc: 0.800000011920929)
[2025-02-17 16:44:43,383][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:43,600][root][INFO] - Training Epoch: 1/2, step 3027/107898 completed (loss: 1.2984213829040527, acc: 0.7727272510528564)
[2025-02-17 16:44:43,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:43,905][root][INFO] - Training Epoch: 1/2, step 3028/107898 completed (loss: 2.4003818035125732, acc: 0.6666666865348816)
[2025-02-17 16:44:43,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:44,209][root][INFO] - Training Epoch: 1/2, step 3029/107898 completed (loss: 1.4236745834350586, acc: 0.699999988079071)
[2025-02-17 16:44:44,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:44,543][root][INFO] - Training Epoch: 1/2, step 3030/107898 completed (loss: 1.5197595357894897, acc: 0.7428571581840515)
[2025-02-17 16:44:44,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:44,832][root][INFO] - Training Epoch: 1/2, step 3031/107898 completed (loss: 0.8151382207870483, acc: 0.7647058963775635)
[2025-02-17 16:44:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:45,187][root][INFO] - Training Epoch: 1/2, step 3032/107898 completed (loss: 0.9877669215202332, acc: 0.800000011920929)
[2025-02-17 16:44:45,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:45,508][root][INFO] - Training Epoch: 1/2, step 3033/107898 completed (loss: 0.0020576335955411196, acc: 1.0)
[2025-02-17 16:44:45,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:45,807][root][INFO] - Training Epoch: 1/2, step 3034/107898 completed (loss: 0.838073194026947, acc: 0.7599999904632568)
[2025-02-17 16:44:45,888][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:46,117][root][INFO] - Training Epoch: 1/2, step 3035/107898 completed (loss: 0.012229673564434052, acc: 1.0)
[2025-02-17 16:44:46,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:46,455][root][INFO] - Training Epoch: 1/2, step 3036/107898 completed (loss: 0.06072342395782471, acc: 1.0)
[2025-02-17 16:44:46,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:46,786][root][INFO] - Training Epoch: 1/2, step 3037/107898 completed (loss: 1.9361249208450317, acc: 0.5)
[2025-02-17 16:44:46,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:47,127][root][INFO] - Training Epoch: 1/2, step 3038/107898 completed (loss: 1.2180393934249878, acc: 0.6666666865348816)
[2025-02-17 16:44:47,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:47,432][root][INFO] - Training Epoch: 1/2, step 3039/107898 completed (loss: 0.015307198278605938, acc: 1.0)
[2025-02-17 16:44:47,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:47,751][root][INFO] - Training Epoch: 1/2, step 3040/107898 completed (loss: 3.693955898284912, acc: 0.18518517911434174)
[2025-02-17 16:44:47,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:48,073][root][INFO] - Training Epoch: 1/2, step 3041/107898 completed (loss: 1.9498649835586548, acc: 0.6666666865348816)
[2025-02-17 16:44:48,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:48,377][root][INFO] - Training Epoch: 1/2, step 3042/107898 completed (loss: 3.3468780517578125, acc: 0.1111111119389534)
[2025-02-17 16:44:48,450][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:48,663][root][INFO] - Training Epoch: 1/2, step 3043/107898 completed (loss: 1.2168852090835571, acc: 0.6000000238418579)
[2025-02-17 16:44:48,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:48,969][root][INFO] - Training Epoch: 1/2, step 3044/107898 completed (loss: 0.8012523055076599, acc: 0.5)
[2025-02-17 16:44:49,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:49,362][root][INFO] - Training Epoch: 1/2, step 3045/107898 completed (loss: 1.8144060373306274, acc: 0.7333333492279053)
[2025-02-17 16:44:49,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:49,702][root][INFO] - Training Epoch: 1/2, step 3046/107898 completed (loss: 0.19426558911800385, acc: 1.0)
[2025-02-17 16:44:49,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:50,000][root][INFO] - Training Epoch: 1/2, step 3047/107898 completed (loss: 3.4879534244537354, acc: 0.25)
[2025-02-17 16:44:50,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:50,335][root][INFO] - Training Epoch: 1/2, step 3048/107898 completed (loss: 0.45608800649642944, acc: 0.8571428656578064)
[2025-02-17 16:44:50,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:50,658][root][INFO] - Training Epoch: 1/2, step 3049/107898 completed (loss: 0.0747656524181366, acc: 1.0)
[2025-02-17 16:44:50,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:50,945][root][INFO] - Training Epoch: 1/2, step 3050/107898 completed (loss: 0.537950336933136, acc: 0.9285714030265808)
[2025-02-17 16:44:51,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:51,238][root][INFO] - Training Epoch: 1/2, step 3051/107898 completed (loss: 0.06738068908452988, acc: 1.0)
[2025-02-17 16:44:51,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:51,515][root][INFO] - Training Epoch: 1/2, step 3052/107898 completed (loss: 2.1224141120910645, acc: 0.6153846383094788)
[2025-02-17 16:44:51,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:51,814][root][INFO] - Training Epoch: 1/2, step 3053/107898 completed (loss: 0.37512895464897156, acc: 0.8571428656578064)
[2025-02-17 16:44:51,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:52,138][root][INFO] - Training Epoch: 1/2, step 3054/107898 completed (loss: 2.5481820106506348, acc: 0.3333333432674408)
[2025-02-17 16:44:52,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:52,498][root][INFO] - Training Epoch: 1/2, step 3055/107898 completed (loss: 4.974454402923584, acc: 0.2777777910232544)
[2025-02-17 16:44:52,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:52,793][root][INFO] - Training Epoch: 1/2, step 3056/107898 completed (loss: 0.7504664063453674, acc: 0.75)
[2025-02-17 16:44:52,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:53,152][root][INFO] - Training Epoch: 1/2, step 3057/107898 completed (loss: 0.04812110960483551, acc: 1.0)
[2025-02-17 16:44:53,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:53,482][root][INFO] - Training Epoch: 1/2, step 3058/107898 completed (loss: 0.7939649224281311, acc: 0.800000011920929)
[2025-02-17 16:44:53,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:53,796][root][INFO] - Training Epoch: 1/2, step 3059/107898 completed (loss: 0.13265246152877808, acc: 1.0)
[2025-02-17 16:44:53,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:54,122][root][INFO] - Training Epoch: 1/2, step 3060/107898 completed (loss: 0.9414081573486328, acc: 0.6666666865348816)
[2025-02-17 16:44:54,227][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:54,475][root][INFO] - Training Epoch: 1/2, step 3061/107898 completed (loss: 0.3375599980354309, acc: 1.0)
[2025-02-17 16:44:54,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:54,827][root][INFO] - Training Epoch: 1/2, step 3062/107898 completed (loss: 1.932456374168396, acc: 0.692307710647583)
[2025-02-17 16:44:54,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:55,187][root][INFO] - Training Epoch: 1/2, step 3063/107898 completed (loss: 0.06875894218683243, acc: 1.0)
[2025-02-17 16:44:55,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:55,506][root][INFO] - Training Epoch: 1/2, step 3064/107898 completed (loss: 4.926079273223877, acc: 0.3333333432674408)
[2025-02-17 16:44:55,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:55,816][root][INFO] - Training Epoch: 1/2, step 3065/107898 completed (loss: 0.006273603066802025, acc: 1.0)
[2025-02-17 16:44:55,901][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:56,134][root][INFO] - Training Epoch: 1/2, step 3066/107898 completed (loss: 0.6453824043273926, acc: 0.8571428656578064)
[2025-02-17 16:44:56,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:56,437][root][INFO] - Training Epoch: 1/2, step 3067/107898 completed (loss: 0.47211572527885437, acc: 1.0)
[2025-02-17 16:44:56,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:56,736][root][INFO] - Training Epoch: 1/2, step 3068/107898 completed (loss: 1.3028368949890137, acc: 0.692307710647583)
[2025-02-17 16:44:56,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:57,079][root][INFO] - Training Epoch: 1/2, step 3069/107898 completed (loss: 0.5021008253097534, acc: 0.8958333134651184)
[2025-02-17 16:44:57,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:57,392][root][INFO] - Training Epoch: 1/2, step 3070/107898 completed (loss: 1.5406423807144165, acc: 0.5)
[2025-02-17 16:44:57,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:57,687][root][INFO] - Training Epoch: 1/2, step 3071/107898 completed (loss: 1.1730602979660034, acc: 0.800000011920929)
[2025-02-17 16:44:57,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:58,012][root][INFO] - Training Epoch: 1/2, step 3072/107898 completed (loss: 0.17077133059501648, acc: 1.0)
[2025-02-17 16:44:58,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:58,332][root][INFO] - Training Epoch: 1/2, step 3073/107898 completed (loss: 0.19930724799633026, acc: 1.0)
[2025-02-17 16:44:58,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:58,651][root][INFO] - Training Epoch: 1/2, step 3074/107898 completed (loss: 1.290844440460205, acc: 0.7142857313156128)
[2025-02-17 16:44:58,736][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:58,959][root][INFO] - Training Epoch: 1/2, step 3075/107898 completed (loss: 0.9478784203529358, acc: 0.8181818127632141)
[2025-02-17 16:44:59,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:59,294][root][INFO] - Training Epoch: 1/2, step 3076/107898 completed (loss: 2.0939600467681885, acc: 0.5)
[2025-02-17 16:44:59,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:59,637][root][INFO] - Training Epoch: 1/2, step 3077/107898 completed (loss: 0.9379784464836121, acc: 0.800000011920929)
[2025-02-17 16:44:59,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:44:59,967][root][INFO] - Training Epoch: 1/2, step 3078/107898 completed (loss: 0.49094393849372864, acc: 0.8571428656578064)
[2025-02-17 16:45:00,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:00,277][root][INFO] - Training Epoch: 1/2, step 3079/107898 completed (loss: 0.8303378820419312, acc: 0.75)
[2025-02-17 16:45:00,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:00,580][root][INFO] - Training Epoch: 1/2, step 3080/107898 completed (loss: 0.8870628476142883, acc: 0.6666666865348816)
[2025-02-17 16:45:00,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:00,868][root][INFO] - Training Epoch: 1/2, step 3081/107898 completed (loss: 0.020969536155462265, acc: 1.0)
[2025-02-17 16:45:00,953][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:01,177][root][INFO] - Training Epoch: 1/2, step 3082/107898 completed (loss: 0.798329770565033, acc: 0.8571428656578064)
[2025-02-17 16:45:01,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:01,506][root][INFO] - Training Epoch: 1/2, step 3083/107898 completed (loss: 0.013437742367386818, acc: 1.0)
[2025-02-17 16:45:01,577][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:01,800][root][INFO] - Training Epoch: 1/2, step 3084/107898 completed (loss: 1.9925003051757812, acc: 0.5555555820465088)
[2025-02-17 16:45:01,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:02,114][root][INFO] - Training Epoch: 1/2, step 3085/107898 completed (loss: 0.19412145018577576, acc: 1.0)
[2025-02-17 16:45:02,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:02,441][root][INFO] - Training Epoch: 1/2, step 3086/107898 completed (loss: 1.1810925006866455, acc: 0.800000011920929)
[2025-02-17 16:45:02,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:02,764][root][INFO] - Training Epoch: 1/2, step 3087/107898 completed (loss: 2.625309944152832, acc: 0.5600000023841858)
[2025-02-17 16:45:02,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:03,057][root][INFO] - Training Epoch: 1/2, step 3088/107898 completed (loss: 0.7291205525398254, acc: 1.0)
[2025-02-17 16:45:03,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:03,358][root][INFO] - Training Epoch: 1/2, step 3089/107898 completed (loss: 0.40166714787483215, acc: 0.75)
[2025-02-17 16:45:03,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:03,714][root][INFO] - Training Epoch: 1/2, step 3090/107898 completed (loss: 2.2424166202545166, acc: 0.6363636255264282)
[2025-02-17 16:45:03,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:04,037][root][INFO] - Training Epoch: 1/2, step 3091/107898 completed (loss: 0.004280382767319679, acc: 1.0)
[2025-02-17 16:45:04,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:04,341][root][INFO] - Training Epoch: 1/2, step 3092/107898 completed (loss: 0.9817250370979309, acc: 0.8666666746139526)
[2025-02-17 16:45:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:04,695][root][INFO] - Training Epoch: 1/2, step 3093/107898 completed (loss: 0.6360198259353638, acc: 0.9285714030265808)
[2025-02-17 16:45:04,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:05,026][root][INFO] - Training Epoch: 1/2, step 3094/107898 completed (loss: 0.3782528340816498, acc: 0.8888888955116272)
[2025-02-17 16:45:05,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:05,314][root][INFO] - Training Epoch: 1/2, step 3095/107898 completed (loss: 0.5937079787254333, acc: 0.9090909361839294)
[2025-02-17 16:45:05,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:05,612][root][INFO] - Training Epoch: 1/2, step 3096/107898 completed (loss: 0.9492107033729553, acc: 0.8333333134651184)
[2025-02-17 16:45:05,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:05,907][root][INFO] - Training Epoch: 1/2, step 3097/107898 completed (loss: 1.0184340476989746, acc: 0.8888888955116272)
[2025-02-17 16:45:05,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:06,212][root][INFO] - Training Epoch: 1/2, step 3098/107898 completed (loss: 0.4496268033981323, acc: 1.0)
[2025-02-17 16:45:06,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:06,536][root][INFO] - Training Epoch: 1/2, step 3099/107898 completed (loss: 1.041100025177002, acc: 0.5)
[2025-02-17 16:45:06,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:06,846][root][INFO] - Training Epoch: 1/2, step 3100/107898 completed (loss: 0.11602594703435898, acc: 1.0)
[2025-02-17 16:45:06,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:07,162][root][INFO] - Training Epoch: 1/2, step 3101/107898 completed (loss: 0.6872395873069763, acc: 0.8636363744735718)
[2025-02-17 16:45:07,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:07,483][root][INFO] - Training Epoch: 1/2, step 3102/107898 completed (loss: 0.007757892832159996, acc: 1.0)
[2025-02-17 16:45:07,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:07,791][root][INFO] - Training Epoch: 1/2, step 3103/107898 completed (loss: 1.1078593730926514, acc: 0.625)
[2025-02-17 16:45:07,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:08,099][root][INFO] - Training Epoch: 1/2, step 3104/107898 completed (loss: 0.004789785947650671, acc: 1.0)
[2025-02-17 16:45:08,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:08,443][root][INFO] - Training Epoch: 1/2, step 3105/107898 completed (loss: 1.4824494123458862, acc: 0.699999988079071)
[2025-02-17 16:45:08,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:08,769][root][INFO] - Training Epoch: 1/2, step 3106/107898 completed (loss: 0.9838629961013794, acc: 0.8260869383811951)
[2025-02-17 16:45:08,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:09,058][root][INFO] - Training Epoch: 1/2, step 3107/107898 completed (loss: 1.6940993070602417, acc: 0.5555555820465088)
[2025-02-17 16:45:09,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:09,346][root][INFO] - Training Epoch: 1/2, step 3108/107898 completed (loss: 0.702248215675354, acc: 0.807692289352417)
[2025-02-17 16:45:09,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:09,643][root][INFO] - Training Epoch: 1/2, step 3109/107898 completed (loss: 1.1387369632720947, acc: 0.75)
[2025-02-17 16:45:09,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:09,936][root][INFO] - Training Epoch: 1/2, step 3110/107898 completed (loss: 0.12049025297164917, acc: 1.0)
[2025-02-17 16:45:10,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:10,232][root][INFO] - Training Epoch: 1/2, step 3111/107898 completed (loss: 0.517241358757019, acc: 0.9130434989929199)
[2025-02-17 16:45:10,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:10,519][root][INFO] - Training Epoch: 1/2, step 3112/107898 completed (loss: 1.3803887367248535, acc: 0.75)
[2025-02-17 16:45:10,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:10,811][root][INFO] - Training Epoch: 1/2, step 3113/107898 completed (loss: 0.11733036488294601, acc: 1.0)
[2025-02-17 16:45:10,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:11,117][root][INFO] - Training Epoch: 1/2, step 3114/107898 completed (loss: 0.0014964863657951355, acc: 1.0)
[2025-02-17 16:45:11,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:11,445][root][INFO] - Training Epoch: 1/2, step 3115/107898 completed (loss: 2.7099099159240723, acc: 0.20000000298023224)
[2025-02-17 16:45:11,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:11,795][root][INFO] - Training Epoch: 1/2, step 3116/107898 completed (loss: 0.7136627435684204, acc: 0.8421052694320679)
[2025-02-17 16:45:11,888][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:12,112][root][INFO] - Training Epoch: 1/2, step 3117/107898 completed (loss: 3.1034278869628906, acc: 0.2857142984867096)
[2025-02-17 16:45:12,215][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:12,439][root][INFO] - Training Epoch: 1/2, step 3118/107898 completed (loss: 0.6987113952636719, acc: 0.75)
[2025-02-17 16:45:12,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:12,753][root][INFO] - Training Epoch: 1/2, step 3119/107898 completed (loss: 0.899480938911438, acc: 0.7586206793785095)
[2025-02-17 16:45:12,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:13,064][root][INFO] - Training Epoch: 1/2, step 3120/107898 completed (loss: 1.8067916631698608, acc: 0.5454545617103577)
[2025-02-17 16:45:13,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:13,375][root][INFO] - Training Epoch: 1/2, step 3121/107898 completed (loss: 0.013458065688610077, acc: 1.0)
[2025-02-17 16:45:13,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:13,668][root][INFO] - Training Epoch: 1/2, step 3122/107898 completed (loss: 4.995044231414795, acc: 0.3333333432674408)
[2025-02-17 16:45:13,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:13,967][root][INFO] - Training Epoch: 1/2, step 3123/107898 completed (loss: 1.4960904121398926, acc: 0.75)
[2025-02-17 16:45:14,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:14,273][root][INFO] - Training Epoch: 1/2, step 3124/107898 completed (loss: 3.7033300399780273, acc: 0.27272728085517883)
[2025-02-17 16:45:14,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:14,586][root][INFO] - Training Epoch: 1/2, step 3125/107898 completed (loss: 4.358784198760986, acc: 0.1818181872367859)
[2025-02-17 16:45:14,671][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:14,857][root][INFO] - Training Epoch: 1/2, step 3126/107898 completed (loss: 0.7032524347305298, acc: 0.800000011920929)
[2025-02-17 16:45:14,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:15,152][root][INFO] - Training Epoch: 1/2, step 3127/107898 completed (loss: 1.4059971570968628, acc: 0.7200000286102295)
[2025-02-17 16:45:15,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:15,464][root][INFO] - Training Epoch: 1/2, step 3128/107898 completed (loss: 3.4557080268859863, acc: 0.4117647111415863)
[2025-02-17 16:45:15,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:15,812][root][INFO] - Training Epoch: 1/2, step 3129/107898 completed (loss: 1.0934818983078003, acc: 0.6666666865348816)
[2025-02-17 16:45:15,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:16,137][root][INFO] - Training Epoch: 1/2, step 3130/107898 completed (loss: 1.5028812885284424, acc: 0.800000011920929)
[2025-02-17 16:45:16,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:16,456][root][INFO] - Training Epoch: 1/2, step 3131/107898 completed (loss: 0.9271673560142517, acc: 0.7272727489471436)
[2025-02-17 16:45:16,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:16,759][root][INFO] - Training Epoch: 1/2, step 3132/107898 completed (loss: 0.04914272949099541, acc: 1.0)
[2025-02-17 16:45:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:17,128][root][INFO] - Training Epoch: 1/2, step 3133/107898 completed (loss: 1.2480286359786987, acc: 0.6666666865348816)
[2025-02-17 16:45:17,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:17,447][root][INFO] - Training Epoch: 1/2, step 3134/107898 completed (loss: 1.8727035522460938, acc: 0.6666666865348816)
[2025-02-17 16:45:17,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:17,766][root][INFO] - Training Epoch: 1/2, step 3135/107898 completed (loss: 0.10427047312259674, acc: 1.0)
[2025-02-17 16:45:17,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:18,070][root][INFO] - Training Epoch: 1/2, step 3136/107898 completed (loss: 1.4428863525390625, acc: 0.5)
[2025-02-17 16:45:18,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:18,371][root][INFO] - Training Epoch: 1/2, step 3137/107898 completed (loss: 0.9342571496963501, acc: 0.6666666865348816)
[2025-02-17 16:45:18,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:18,730][root][INFO] - Training Epoch: 1/2, step 3138/107898 completed (loss: 0.5525093674659729, acc: 0.9166666865348816)
[2025-02-17 16:45:18,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:19,059][root][INFO] - Training Epoch: 1/2, step 3139/107898 completed (loss: 0.5584868788719177, acc: 1.0)
[2025-02-17 16:45:19,171][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:19,383][root][INFO] - Training Epoch: 1/2, step 3140/107898 completed (loss: 1.9304015636444092, acc: 0.6153846383094788)
[2025-02-17 16:45:19,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:19,676][root][INFO] - Training Epoch: 1/2, step 3141/107898 completed (loss: 4.004322528839111, acc: 0.3333333432674408)
[2025-02-17 16:45:19,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:20,016][root][INFO] - Training Epoch: 1/2, step 3142/107898 completed (loss: 2.209765672683716, acc: 0.6190476417541504)
[2025-02-17 16:45:20,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:20,353][root][INFO] - Training Epoch: 1/2, step 3143/107898 completed (loss: 1.8442553281784058, acc: 0.5882353186607361)
[2025-02-17 16:45:20,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:20,650][root][INFO] - Training Epoch: 1/2, step 3144/107898 completed (loss: 0.101363904774189, acc: 1.0)
[2025-02-17 16:45:20,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:20,943][root][INFO] - Training Epoch: 1/2, step 3145/107898 completed (loss: 0.36578696966171265, acc: 1.0)
[2025-02-17 16:45:21,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:21,246][root][INFO] - Training Epoch: 1/2, step 3146/107898 completed (loss: 0.6955605745315552, acc: 0.75)
[2025-02-17 16:45:21,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:21,541][root][INFO] - Training Epoch: 1/2, step 3147/107898 completed (loss: 0.025738293305039406, acc: 1.0)
[2025-02-17 16:45:21,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:21,907][root][INFO] - Training Epoch: 1/2, step 3148/107898 completed (loss: 1.131540060043335, acc: 0.6000000238418579)
[2025-02-17 16:45:22,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:22,235][root][INFO] - Training Epoch: 1/2, step 3149/107898 completed (loss: 0.3941071331501007, acc: 0.9090909361839294)
[2025-02-17 16:45:22,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:22,529][root][INFO] - Training Epoch: 1/2, step 3150/107898 completed (loss: 2.481783866882324, acc: 0.6315789222717285)
[2025-02-17 16:45:22,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:22,827][root][INFO] - Training Epoch: 1/2, step 3151/107898 completed (loss: 2.405904531478882, acc: 0.75)
[2025-02-17 16:45:22,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:23,132][root][INFO] - Training Epoch: 1/2, step 3152/107898 completed (loss: 0.06587329506874084, acc: 1.0)
[2025-02-17 16:45:23,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:23,462][root][INFO] - Training Epoch: 1/2, step 3153/107898 completed (loss: 1.486087679862976, acc: 0.739130437374115)
[2025-02-17 16:45:23,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:23,767][root][INFO] - Training Epoch: 1/2, step 3154/107898 completed (loss: 0.25651898980140686, acc: 1.0)
[2025-02-17 16:45:23,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:24,088][root][INFO] - Training Epoch: 1/2, step 3155/107898 completed (loss: 0.15687237679958344, acc: 1.0)
[2025-02-17 16:45:24,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:24,418][root][INFO] - Training Epoch: 1/2, step 3156/107898 completed (loss: 0.4714110493659973, acc: 0.9354838728904724)
[2025-02-17 16:45:24,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:24,736][root][INFO] - Training Epoch: 1/2, step 3157/107898 completed (loss: 0.6460956931114197, acc: 0.9545454382896423)
[2025-02-17 16:45:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:25,036][root][INFO] - Training Epoch: 1/2, step 3158/107898 completed (loss: 0.6360233426094055, acc: 0.8571428656578064)
[2025-02-17 16:45:25,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:25,337][root][INFO] - Training Epoch: 1/2, step 3159/107898 completed (loss: 0.08267097175121307, acc: 1.0)
[2025-02-17 16:45:25,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:25,635][root][INFO] - Training Epoch: 1/2, step 3160/107898 completed (loss: 1.5150978565216064, acc: 0.75)
[2025-02-17 16:45:25,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:25,930][root][INFO] - Training Epoch: 1/2, step 3161/107898 completed (loss: 3.102259397506714, acc: 0.31578946113586426)
[2025-02-17 16:45:26,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:26,238][root][INFO] - Training Epoch: 1/2, step 3162/107898 completed (loss: 0.5160467028617859, acc: 0.9354838728904724)
[2025-02-17 16:45:26,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:26,528][root][INFO] - Training Epoch: 1/2, step 3163/107898 completed (loss: 1.1719714403152466, acc: 0.75)
[2025-02-17 16:45:26,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:26,827][root][INFO] - Training Epoch: 1/2, step 3164/107898 completed (loss: 1.4616516828536987, acc: 0.739130437374115)
[2025-02-17 16:45:26,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:27,125][root][INFO] - Training Epoch: 1/2, step 3165/107898 completed (loss: 1.201595425605774, acc: 0.6666666865348816)
[2025-02-17 16:45:27,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:27,462][root][INFO] - Training Epoch: 1/2, step 3166/107898 completed (loss: 1.910489559173584, acc: 0.6666666865348816)
[2025-02-17 16:45:27,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:27,829][root][INFO] - Training Epoch: 1/2, step 3167/107898 completed (loss: 1.4495831727981567, acc: 0.692307710647583)
[2025-02-17 16:45:27,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:28,149][root][INFO] - Training Epoch: 1/2, step 3168/107898 completed (loss: 0.2663792073726654, acc: 1.0)
[2025-02-17 16:45:28,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:28,479][root][INFO] - Training Epoch: 1/2, step 3169/107898 completed (loss: 0.9675636291503906, acc: 0.7777777910232544)
[2025-02-17 16:45:28,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:28,802][root][INFO] - Training Epoch: 1/2, step 3170/107898 completed (loss: 3.1227333545684814, acc: 0.5)
[2025-02-17 16:45:28,912][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:29,153][root][INFO] - Training Epoch: 1/2, step 3171/107898 completed (loss: 1.1688940525054932, acc: 0.800000011920929)
[2025-02-17 16:45:29,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:29,493][root][INFO] - Training Epoch: 1/2, step 3172/107898 completed (loss: 1.336104393005371, acc: 0.625)
[2025-02-17 16:45:29,634][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:29,853][root][INFO] - Training Epoch: 1/2, step 3173/107898 completed (loss: 1.8203468322753906, acc: 0.6666666865348816)
[2025-02-17 16:45:29,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:30,143][root][INFO] - Training Epoch: 1/2, step 3174/107898 completed (loss: 1.2297600507736206, acc: 0.7142857313156128)
[2025-02-17 16:45:30,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:30,459][root][INFO] - Training Epoch: 1/2, step 3175/107898 completed (loss: 0.37141501903533936, acc: 0.9032257795333862)
[2025-02-17 16:45:30,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:30,788][root][INFO] - Training Epoch: 1/2, step 3176/107898 completed (loss: 1.1865755319595337, acc: 0.8148148059844971)
[2025-02-17 16:45:30,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:31,125][root][INFO] - Training Epoch: 1/2, step 3177/107898 completed (loss: 1.7584666013717651, acc: 0.75)
[2025-02-17 16:45:31,228][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:31,459][root][INFO] - Training Epoch: 1/2, step 3178/107898 completed (loss: 0.6285706162452698, acc: 0.8999999761581421)
[2025-02-17 16:45:31,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:31,827][root][INFO] - Training Epoch: 1/2, step 3179/107898 completed (loss: 1.7018706798553467, acc: 0.5)
[2025-02-17 16:45:31,942][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:32,170][root][INFO] - Training Epoch: 1/2, step 3180/107898 completed (loss: 2.8674046993255615, acc: 0.25)
[2025-02-17 16:45:32,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:32,481][root][INFO] - Training Epoch: 1/2, step 3181/107898 completed (loss: 0.056997187435626984, acc: 1.0)
[2025-02-17 16:45:32,575][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:32,794][root][INFO] - Training Epoch: 1/2, step 3182/107898 completed (loss: 4.134249210357666, acc: 0.5)
[2025-02-17 16:45:32,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:33,102][root][INFO] - Training Epoch: 1/2, step 3183/107898 completed (loss: 0.7390668392181396, acc: 0.7272727489471436)
[2025-02-17 16:45:33,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:33,426][root][INFO] - Training Epoch: 1/2, step 3184/107898 completed (loss: 2.671586751937866, acc: 0.3333333432674408)
[2025-02-17 16:45:33,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:33,772][root][INFO] - Training Epoch: 1/2, step 3185/107898 completed (loss: 1.3901646137237549, acc: 0.800000011920929)
[2025-02-17 16:45:33,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:34,057][root][INFO] - Training Epoch: 1/2, step 3186/107898 completed (loss: 0.04909437522292137, acc: 1.0)
[2025-02-17 16:45:34,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:34,357][root][INFO] - Training Epoch: 1/2, step 3187/107898 completed (loss: 1.7182869911193848, acc: 0.6666666865348816)
[2025-02-17 16:45:34,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:34,679][root][INFO] - Training Epoch: 1/2, step 3188/107898 completed (loss: 3.1713967323303223, acc: 0.375)
[2025-02-17 16:45:34,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:35,014][root][INFO] - Training Epoch: 1/2, step 3189/107898 completed (loss: 1.384061336517334, acc: 0.8095238208770752)
[2025-02-17 16:45:35,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:35,368][root][INFO] - Training Epoch: 1/2, step 3190/107898 completed (loss: 0.4077011048793793, acc: 1.0)
[2025-02-17 16:45:35,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:35,686][root][INFO] - Training Epoch: 1/2, step 3191/107898 completed (loss: 0.5618536472320557, acc: 1.0)
[2025-02-17 16:45:35,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:36,014][root][INFO] - Training Epoch: 1/2, step 3192/107898 completed (loss: 0.5154753923416138, acc: 0.8333333134651184)
[2025-02-17 16:45:36,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:36,392][root][INFO] - Training Epoch: 1/2, step 3193/107898 completed (loss: 0.5079644918441772, acc: 0.875)
[2025-02-17 16:45:36,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:36,716][root][INFO] - Training Epoch: 1/2, step 3194/107898 completed (loss: 0.44125619530677795, acc: 0.9166666865348816)
[2025-02-17 16:45:36,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:36,998][root][INFO] - Training Epoch: 1/2, step 3195/107898 completed (loss: 0.947503924369812, acc: 0.8571428656578064)
[2025-02-17 16:45:37,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:37,305][root][INFO] - Training Epoch: 1/2, step 3196/107898 completed (loss: 0.014895251952111721, acc: 1.0)
[2025-02-17 16:45:37,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:37,578][root][INFO] - Training Epoch: 1/2, step 3197/107898 completed (loss: 0.3260158598423004, acc: 1.0)
[2025-02-17 16:45:37,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:37,952][root][INFO] - Training Epoch: 1/2, step 3198/107898 completed (loss: 2.591794013977051, acc: 0.4545454680919647)
[2025-02-17 16:45:38,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:38,322][root][INFO] - Training Epoch: 1/2, step 3199/107898 completed (loss: 0.006387132219970226, acc: 1.0)
[2025-02-17 16:45:38,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:38,634][root][INFO] - Training Epoch: 1/2, step 3200/107898 completed (loss: 1.259442687034607, acc: 0.8333333134651184)
[2025-02-17 16:45:38,737][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:38,952][root][INFO] - Training Epoch: 1/2, step 3201/107898 completed (loss: 1.175548791885376, acc: 0.7142857313156128)
[2025-02-17 16:45:39,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:39,302][root][INFO] - Training Epoch: 1/2, step 3202/107898 completed (loss: 1.7085349559783936, acc: 0.6739130616188049)
[2025-02-17 16:45:39,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:39,588][root][INFO] - Training Epoch: 1/2, step 3203/107898 completed (loss: 0.02516748756170273, acc: 1.0)
[2025-02-17 16:45:39,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:39,920][root][INFO] - Training Epoch: 1/2, step 3204/107898 completed (loss: 0.05409751087427139, acc: 1.0)
[2025-02-17 16:45:40,036][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:40,273][root][INFO] - Training Epoch: 1/2, step 3205/107898 completed (loss: 0.3624168336391449, acc: 1.0)
[2025-02-17 16:45:40,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:40,585][root][INFO] - Training Epoch: 1/2, step 3206/107898 completed (loss: 2.0448429584503174, acc: 0.5)
[2025-02-17 16:45:40,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:40,914][root][INFO] - Training Epoch: 1/2, step 3207/107898 completed (loss: 0.013715053908526897, acc: 1.0)
[2025-02-17 16:45:40,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:41,197][root][INFO] - Training Epoch: 1/2, step 3208/107898 completed (loss: 1.5584274530410767, acc: 0.6666666865348816)
[2025-02-17 16:45:41,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:41,479][root][INFO] - Training Epoch: 1/2, step 3209/107898 completed (loss: 4.206191539764404, acc: 0.3333333432674408)
[2025-02-17 16:45:41,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:41,732][root][INFO] - Training Epoch: 1/2, step 3210/107898 completed (loss: 0.007102128118276596, acc: 1.0)
[2025-02-17 16:45:41,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:42,031][root][INFO] - Training Epoch: 1/2, step 3211/107898 completed (loss: 0.44268935918807983, acc: 0.8571428656578064)
[2025-02-17 16:45:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:42,390][root][INFO] - Training Epoch: 1/2, step 3212/107898 completed (loss: 1.1265283823013306, acc: 0.5)
[2025-02-17 16:45:42,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:42,704][root][INFO] - Training Epoch: 1/2, step 3213/107898 completed (loss: 3.0263161659240723, acc: 0.5)
[2025-02-17 16:45:42,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:43,003][root][INFO] - Training Epoch: 1/2, step 3214/107898 completed (loss: 2.013582944869995, acc: 0.800000011920929)
[2025-02-17 16:45:43,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:43,302][root][INFO] - Training Epoch: 1/2, step 3215/107898 completed (loss: 0.9818684458732605, acc: 0.800000011920929)
[2025-02-17 16:45:43,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:43,618][root][INFO] - Training Epoch: 1/2, step 3216/107898 completed (loss: 1.4203259944915771, acc: 0.800000011920929)
[2025-02-17 16:45:43,736][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:43,974][root][INFO] - Training Epoch: 1/2, step 3217/107898 completed (loss: 1.7387139797210693, acc: 0.5555555820465088)
[2025-02-17 16:45:44,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:44,323][root][INFO] - Training Epoch: 1/2, step 3218/107898 completed (loss: 0.47648724913597107, acc: 0.9090909361839294)
[2025-02-17 16:45:44,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:44,621][root][INFO] - Training Epoch: 1/2, step 3219/107898 completed (loss: 0.2948811948299408, acc: 1.0)
[2025-02-17 16:45:44,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:44,914][root][INFO] - Training Epoch: 1/2, step 3220/107898 completed (loss: 0.17118708789348602, acc: 1.0)
[2025-02-17 16:45:45,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:45,225][root][INFO] - Training Epoch: 1/2, step 3221/107898 completed (loss: 2.9581854343414307, acc: 0.2800000011920929)
[2025-02-17 16:45:45,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:45,512][root][INFO] - Training Epoch: 1/2, step 3222/107898 completed (loss: 0.024340331554412842, acc: 1.0)
[2025-02-17 16:45:45,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:45,800][root][INFO] - Training Epoch: 1/2, step 3223/107898 completed (loss: 3.2110512256622314, acc: 0.6000000238418579)
[2025-02-17 16:45:45,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:46,112][root][INFO] - Training Epoch: 1/2, step 3224/107898 completed (loss: 3.6714906692504883, acc: 0.5)
[2025-02-17 16:45:46,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:46,391][root][INFO] - Training Epoch: 1/2, step 3225/107898 completed (loss: 1.7750110626220703, acc: 0.7692307829856873)
[2025-02-17 16:45:46,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:46,682][root][INFO] - Training Epoch: 1/2, step 3226/107898 completed (loss: 1.520167350769043, acc: 0.7777777910232544)
[2025-02-17 16:45:46,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:47,007][root][INFO] - Training Epoch: 1/2, step 3227/107898 completed (loss: 0.9943614602088928, acc: 0.7272727489471436)
[2025-02-17 16:45:47,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:47,350][root][INFO] - Training Epoch: 1/2, step 3228/107898 completed (loss: 0.7874139547348022, acc: 0.7931034564971924)
[2025-02-17 16:45:47,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:47,653][root][INFO] - Training Epoch: 1/2, step 3229/107898 completed (loss: 0.3990837633609772, acc: 0.6666666865348816)
[2025-02-17 16:45:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:47,997][root][INFO] - Training Epoch: 1/2, step 3230/107898 completed (loss: 1.0919660329818726, acc: 0.692307710647583)
[2025-02-17 16:45:48,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:48,306][root][INFO] - Training Epoch: 1/2, step 3231/107898 completed (loss: 2.4518136978149414, acc: 0.5)
[2025-02-17 16:45:48,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:48,608][root][INFO] - Training Epoch: 1/2, step 3232/107898 completed (loss: 0.0891486182808876, acc: 1.0)
[2025-02-17 16:45:48,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:48,935][root][INFO] - Training Epoch: 1/2, step 3233/107898 completed (loss: 6.040769577026367, acc: 0.25)
[2025-02-17 16:45:49,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:49,243][root][INFO] - Training Epoch: 1/2, step 3234/107898 completed (loss: 1.8945703506469727, acc: 0.52173912525177)
[2025-02-17 16:45:49,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:49,552][root][INFO] - Training Epoch: 1/2, step 3235/107898 completed (loss: 4.681324481964111, acc: 0.0)
[2025-02-17 16:45:49,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:49,874][root][INFO] - Training Epoch: 1/2, step 3236/107898 completed (loss: 0.6425420641899109, acc: 0.6666666865348816)
[2025-02-17 16:45:49,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:50,182][root][INFO] - Training Epoch: 1/2, step 3237/107898 completed (loss: 1.270836591720581, acc: 0.75)
[2025-02-17 16:45:50,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:50,486][root][INFO] - Training Epoch: 1/2, step 3238/107898 completed (loss: 1.534212589263916, acc: 0.6666666865348816)
[2025-02-17 16:45:50,584][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:50,811][root][INFO] - Training Epoch: 1/2, step 3239/107898 completed (loss: 1.1258869171142578, acc: 0.807692289352417)
[2025-02-17 16:45:50,888][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:51,100][root][INFO] - Training Epoch: 1/2, step 3240/107898 completed (loss: 0.007991698570549488, acc: 1.0)
[2025-02-17 16:45:51,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:51,388][root][INFO] - Training Epoch: 1/2, step 3241/107898 completed (loss: 0.7698416113853455, acc: 0.6666666865348816)
[2025-02-17 16:45:51,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:51,728][root][INFO] - Training Epoch: 1/2, step 3242/107898 completed (loss: 1.1709321737289429, acc: 0.5)
[2025-02-17 16:45:51,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:52,061][root][INFO] - Training Epoch: 1/2, step 3243/107898 completed (loss: 0.3915998041629791, acc: 0.9523809552192688)
[2025-02-17 16:45:52,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:52,396][root][INFO] - Training Epoch: 1/2, step 3244/107898 completed (loss: 1.36072838306427, acc: 0.7647058963775635)
[2025-02-17 16:45:52,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:52,717][root][INFO] - Training Epoch: 1/2, step 3245/107898 completed (loss: 4.013466835021973, acc: 0.1428571492433548)
[2025-02-17 16:45:52,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:53,012][root][INFO] - Training Epoch: 1/2, step 3246/107898 completed (loss: 0.3806836009025574, acc: 0.800000011920929)
[2025-02-17 16:45:53,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:53,321][root][INFO] - Training Epoch: 1/2, step 3247/107898 completed (loss: 1.3702592849731445, acc: 0.7727272510528564)
[2025-02-17 16:45:53,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:53,626][root][INFO] - Training Epoch: 1/2, step 3248/107898 completed (loss: 0.5141069293022156, acc: 0.8823529481887817)
[2025-02-17 16:45:53,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:53,926][root][INFO] - Training Epoch: 1/2, step 3249/107898 completed (loss: 1.0396875143051147, acc: 0.8333333134651184)
[2025-02-17 16:45:54,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:54,212][root][INFO] - Training Epoch: 1/2, step 3250/107898 completed (loss: 0.04362472519278526, acc: 1.0)
[2025-02-17 16:45:54,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:54,509][root][INFO] - Training Epoch: 1/2, step 3251/107898 completed (loss: 0.5852152109146118, acc: 0.75)
[2025-02-17 16:45:54,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:54,809][root][INFO] - Training Epoch: 1/2, step 3252/107898 completed (loss: 2.103078842163086, acc: 0.625)
[2025-02-17 16:45:54,887][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:55,101][root][INFO] - Training Epoch: 1/2, step 3253/107898 completed (loss: 1.8616749048233032, acc: 0.3333333432674408)
[2025-02-17 16:45:55,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:55,390][root][INFO] - Training Epoch: 1/2, step 3254/107898 completed (loss: 0.00986243411898613, acc: 1.0)
[2025-02-17 16:45:55,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:55,699][root][INFO] - Training Epoch: 1/2, step 3255/107898 completed (loss: 1.8982875347137451, acc: 0.5714285969734192)
[2025-02-17 16:45:55,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:55,982][root][INFO] - Training Epoch: 1/2, step 3256/107898 completed (loss: 1.2933958768844604, acc: 0.8181818127632141)
[2025-02-17 16:45:56,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:56,275][root][INFO] - Training Epoch: 1/2, step 3257/107898 completed (loss: 3.8159019947052, acc: 0.10000000149011612)
[2025-02-17 16:45:56,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:56,594][root][INFO] - Training Epoch: 1/2, step 3258/107898 completed (loss: 0.716008186340332, acc: 0.8571428656578064)
[2025-02-17 16:45:56,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:56,879][root][INFO] - Training Epoch: 1/2, step 3259/107898 completed (loss: 1.304577112197876, acc: 0.75)
[2025-02-17 16:45:57,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:57,242][root][INFO] - Training Epoch: 1/2, step 3260/107898 completed (loss: 2.373812675476074, acc: 0.6153846383094788)
[2025-02-17 16:45:57,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:57,574][root][INFO] - Training Epoch: 1/2, step 3261/107898 completed (loss: 1.1126028299331665, acc: 0.5714285969734192)
[2025-02-17 16:45:57,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:57,907][root][INFO] - Training Epoch: 1/2, step 3262/107898 completed (loss: 1.0337365865707397, acc: 0.7692307829856873)
[2025-02-17 16:45:58,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:58,224][root][INFO] - Training Epoch: 1/2, step 3263/107898 completed (loss: 1.0711311101913452, acc: 0.8333333134651184)
[2025-02-17 16:45:58,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:58,550][root][INFO] - Training Epoch: 1/2, step 3264/107898 completed (loss: 3.4545786380767822, acc: 0.1666666716337204)
[2025-02-17 16:45:58,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:58,858][root][INFO] - Training Epoch: 1/2, step 3265/107898 completed (loss: 5.030649662017822, acc: 0.1666666716337204)
[2025-02-17 16:45:58,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:59,163][root][INFO] - Training Epoch: 1/2, step 3266/107898 completed (loss: 2.8361120223999023, acc: 0.25)
[2025-02-17 16:45:59,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:59,484][root][INFO] - Training Epoch: 1/2, step 3267/107898 completed (loss: 1.1249926090240479, acc: 0.5)
[2025-02-17 16:45:59,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:45:59,820][root][INFO] - Training Epoch: 1/2, step 3268/107898 completed (loss: 0.6953331232070923, acc: 0.8888888955116272)
[2025-02-17 16:45:59,925][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:00,152][root][INFO] - Training Epoch: 1/2, step 3269/107898 completed (loss: 0.14430254697799683, acc: 1.0)
[2025-02-17 16:46:00,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:00,478][root][INFO] - Training Epoch: 1/2, step 3270/107898 completed (loss: 0.010118772275745869, acc: 1.0)
[2025-02-17 16:46:00,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:00,799][root][INFO] - Training Epoch: 1/2, step 3271/107898 completed (loss: 1.1219074726104736, acc: 0.0)
[2025-02-17 16:46:00,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:01,116][root][INFO] - Training Epoch: 1/2, step 3272/107898 completed (loss: 0.6485966444015503, acc: 0.9032257795333862)
[2025-02-17 16:46:01,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:01,427][root][INFO] - Training Epoch: 1/2, step 3273/107898 completed (loss: 0.6978508234024048, acc: 0.8571428656578064)
[2025-02-17 16:46:01,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:01,718][root][INFO] - Training Epoch: 1/2, step 3274/107898 completed (loss: 0.003042749362066388, acc: 1.0)
[2025-02-17 16:46:01,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:02,024][root][INFO] - Training Epoch: 1/2, step 3275/107898 completed (loss: 2.651550054550171, acc: 0.47058823704719543)
[2025-02-17 16:46:02,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:02,324][root][INFO] - Training Epoch: 1/2, step 3276/107898 completed (loss: 0.36166349053382874, acc: 0.9375)
[2025-02-17 16:46:02,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:02,634][root][INFO] - Training Epoch: 1/2, step 3277/107898 completed (loss: 0.6508170366287231, acc: 0.9047619104385376)
[2025-02-17 16:46:02,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:02,929][root][INFO] - Training Epoch: 1/2, step 3278/107898 completed (loss: 2.558095932006836, acc: 0.375)
[2025-02-17 16:46:03,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:03,225][root][INFO] - Training Epoch: 1/2, step 3279/107898 completed (loss: 0.030287951231002808, acc: 1.0)
[2025-02-17 16:46:03,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:03,521][root][INFO] - Training Epoch: 1/2, step 3280/107898 completed (loss: 0.09965794533491135, acc: 1.0)
[2025-02-17 16:46:03,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:03,830][root][INFO] - Training Epoch: 1/2, step 3281/107898 completed (loss: 0.43114519119262695, acc: 1.0)
[2025-02-17 16:46:03,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:04,143][root][INFO] - Training Epoch: 1/2, step 3282/107898 completed (loss: 0.8713996410369873, acc: 0.8636363744735718)
[2025-02-17 16:46:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:04,473][root][INFO] - Training Epoch: 1/2, step 3283/107898 completed (loss: 1.1154019832611084, acc: 0.7857142686843872)
[2025-02-17 16:46:04,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:04,782][root][INFO] - Training Epoch: 1/2, step 3284/107898 completed (loss: 1.1466037034988403, acc: 0.7058823704719543)
[2025-02-17 16:46:04,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:05,113][root][INFO] - Training Epoch: 1/2, step 3285/107898 completed (loss: 1.4257410764694214, acc: 0.8333333134651184)
[2025-02-17 16:46:05,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:05,426][root][INFO] - Training Epoch: 1/2, step 3286/107898 completed (loss: 0.178778737783432, acc: 1.0)
[2025-02-17 16:46:05,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:05,731][root][INFO] - Training Epoch: 1/2, step 3287/107898 completed (loss: 0.37937870621681213, acc: 0.8571428656578064)
[2025-02-17 16:46:05,814][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:06,029][root][INFO] - Training Epoch: 1/2, step 3288/107898 completed (loss: 0.008052864111959934, acc: 1.0)
[2025-02-17 16:46:06,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:06,332][root][INFO] - Training Epoch: 1/2, step 3289/107898 completed (loss: 1.4776643514633179, acc: 0.625)
[2025-02-17 16:46:06,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:06,629][root][INFO] - Training Epoch: 1/2, step 3290/107898 completed (loss: 0.034918412566185, acc: 1.0)
[2025-02-17 16:46:06,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:06,992][root][INFO] - Training Epoch: 1/2, step 3291/107898 completed (loss: 1.1051408052444458, acc: 0.804347813129425)
[2025-02-17 16:46:07,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:07,346][root][INFO] - Training Epoch: 1/2, step 3292/107898 completed (loss: 1.847753643989563, acc: 0.529411792755127)
[2025-02-17 16:46:07,483][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:07,699][root][INFO] - Training Epoch: 1/2, step 3293/107898 completed (loss: 1.6250156164169312, acc: 0.7241379022598267)
[2025-02-17 16:46:07,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:07,996][root][INFO] - Training Epoch: 1/2, step 3294/107898 completed (loss: 0.39130693674087524, acc: 0.8571428656578064)
[2025-02-17 16:46:08,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:08,297][root][INFO] - Training Epoch: 1/2, step 3295/107898 completed (loss: 0.3453185558319092, acc: 0.8571428656578064)
[2025-02-17 16:46:08,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:08,598][root][INFO] - Training Epoch: 1/2, step 3296/107898 completed (loss: 4.208902359008789, acc: 0.3636363744735718)
[2025-02-17 16:46:08,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:08,923][root][INFO] - Training Epoch: 1/2, step 3297/107898 completed (loss: 2.506619453430176, acc: 0.5555555820465088)
[2025-02-17 16:46:09,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:09,232][root][INFO] - Training Epoch: 1/2, step 3298/107898 completed (loss: 1.9201726913452148, acc: 0.800000011920929)
[2025-02-17 16:46:09,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:09,552][root][INFO] - Training Epoch: 1/2, step 3299/107898 completed (loss: 1.1357325315475464, acc: 0.761904776096344)
[2025-02-17 16:46:09,634][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:09,856][root][INFO] - Training Epoch: 1/2, step 3300/107898 completed (loss: 0.0022996519692242146, acc: 1.0)
[2025-02-17 16:46:09,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:10,152][root][INFO] - Training Epoch: 1/2, step 3301/107898 completed (loss: 0.17343971133232117, acc: 1.0)
[2025-02-17 16:46:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:10,446][root][INFO] - Training Epoch: 1/2, step 3302/107898 completed (loss: 3.646979331970215, acc: 0.375)
[2025-02-17 16:46:10,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:10,743][root][INFO] - Training Epoch: 1/2, step 3303/107898 completed (loss: 1.8127471208572388, acc: 0.5789473652839661)
[2025-02-17 16:46:10,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:11,037][root][INFO] - Training Epoch: 1/2, step 3304/107898 completed (loss: 6.025610446929932, acc: 0.20000000298023224)
[2025-02-17 16:46:11,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:11,342][root][INFO] - Training Epoch: 1/2, step 3305/107898 completed (loss: 0.02270382270216942, acc: 1.0)
[2025-02-17 16:46:11,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:11,646][root][INFO] - Training Epoch: 1/2, step 3306/107898 completed (loss: 2.5788443088531494, acc: 0.5)
[2025-02-17 16:46:11,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:11,983][root][INFO] - Training Epoch: 1/2, step 3307/107898 completed (loss: 3.4481444358825684, acc: 0.3333333432674408)
[2025-02-17 16:46:12,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:12,335][root][INFO] - Training Epoch: 1/2, step 3308/107898 completed (loss: 1.8941906690597534, acc: 0.5555555820465088)
[2025-02-17 16:46:12,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:12,666][root][INFO] - Training Epoch: 1/2, step 3309/107898 completed (loss: 1.8824154138565063, acc: 0.4736842215061188)
[2025-02-17 16:46:12,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:12,992][root][INFO] - Training Epoch: 1/2, step 3310/107898 completed (loss: 2.2212729454040527, acc: 0.5)
[2025-02-17 16:46:13,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:13,301][root][INFO] - Training Epoch: 1/2, step 3311/107898 completed (loss: 0.5650834441184998, acc: 0.9130434989929199)
[2025-02-17 16:46:13,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:13,606][root][INFO] - Training Epoch: 1/2, step 3312/107898 completed (loss: 3.819441318511963, acc: 0.5)
[2025-02-17 16:46:13,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:13,909][root][INFO] - Training Epoch: 1/2, step 3313/107898 completed (loss: 0.6686785221099854, acc: 0.8275862336158752)
[2025-02-17 16:46:13,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:14,211][root][INFO] - Training Epoch: 1/2, step 3314/107898 completed (loss: 0.05266575515270233, acc: 1.0)
[2025-02-17 16:46:14,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:14,548][root][INFO] - Training Epoch: 1/2, step 3315/107898 completed (loss: 0.23457981646060944, acc: 1.0)
[2025-02-17 16:46:14,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:14,867][root][INFO] - Training Epoch: 1/2, step 3316/107898 completed (loss: 3.9667153358459473, acc: 0.1538461595773697)
[2025-02-17 16:46:14,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:15,159][root][INFO] - Training Epoch: 1/2, step 3317/107898 completed (loss: 0.3930334448814392, acc: 0.95652174949646)
[2025-02-17 16:46:15,242][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:15,458][root][INFO] - Training Epoch: 1/2, step 3318/107898 completed (loss: 0.7415607571601868, acc: 0.5)
[2025-02-17 16:46:15,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:15,763][root][INFO] - Training Epoch: 1/2, step 3319/107898 completed (loss: 1.2153135538101196, acc: 0.6666666865348816)
[2025-02-17 16:46:15,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:16,074][root][INFO] - Training Epoch: 1/2, step 3320/107898 completed (loss: 0.8070974946022034, acc: 0.8181818127632141)
[2025-02-17 16:46:16,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:16,378][root][INFO] - Training Epoch: 1/2, step 3321/107898 completed (loss: 1.191584587097168, acc: 0.5)
[2025-02-17 16:46:16,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:16,673][root][INFO] - Training Epoch: 1/2, step 3322/107898 completed (loss: 3.537039279937744, acc: 0.29411765933036804)
[2025-02-17 16:46:16,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:16,979][root][INFO] - Training Epoch: 1/2, step 3323/107898 completed (loss: 3.6012542247772217, acc: 0.5)
[2025-02-17 16:46:17,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:17,274][root][INFO] - Training Epoch: 1/2, step 3324/107898 completed (loss: 0.6050286293029785, acc: 0.7857142686843872)
[2025-02-17 16:46:17,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:17,566][root][INFO] - Training Epoch: 1/2, step 3325/107898 completed (loss: 1.2412936687469482, acc: 0.5)
[2025-02-17 16:46:17,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:17,890][root][INFO] - Training Epoch: 1/2, step 3326/107898 completed (loss: 1.1333059072494507, acc: 0.7777777910232544)
[2025-02-17 16:46:17,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:18,181][root][INFO] - Training Epoch: 1/2, step 3327/107898 completed (loss: 1.3363418579101562, acc: 0.7647058963775635)
[2025-02-17 16:46:18,280][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:18,501][root][INFO] - Training Epoch: 1/2, step 3328/107898 completed (loss: 3.423456907272339, acc: 0.36666667461395264)
[2025-02-17 16:46:18,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:18,794][root][INFO] - Training Epoch: 1/2, step 3329/107898 completed (loss: 0.3223508596420288, acc: 1.0)
[2025-02-17 16:46:18,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:19,089][root][INFO] - Training Epoch: 1/2, step 3330/107898 completed (loss: 0.0010947062401100993, acc: 1.0)
[2025-02-17 16:46:19,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:19,375][root][INFO] - Training Epoch: 1/2, step 3331/107898 completed (loss: 0.08000581711530685, acc: 1.0)
[2025-02-17 16:46:19,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:19,685][root][INFO] - Training Epoch: 1/2, step 3332/107898 completed (loss: 0.14056053757667542, acc: 0.9666666388511658)
[2025-02-17 16:46:19,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:19,978][root][INFO] - Training Epoch: 1/2, step 3333/107898 completed (loss: 0.421068012714386, acc: 0.9130434989929199)
[2025-02-17 16:46:20,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:20,274][root][INFO] - Training Epoch: 1/2, step 3334/107898 completed (loss: 0.8943530321121216, acc: 0.692307710647583)
[2025-02-17 16:46:20,358][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:20,572][root][INFO] - Training Epoch: 1/2, step 3335/107898 completed (loss: 0.0023490542080253363, acc: 1.0)
[2025-02-17 16:46:20,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:20,919][root][INFO] - Training Epoch: 1/2, step 3336/107898 completed (loss: 1.3197633028030396, acc: 0.7692307829856873)
[2025-02-17 16:46:21,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:21,228][root][INFO] - Training Epoch: 1/2, step 3337/107898 completed (loss: 1.6567511558532715, acc: 0.6666666865348816)
[2025-02-17 16:46:21,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:21,533][root][INFO] - Training Epoch: 1/2, step 3338/107898 completed (loss: 0.03519419580698013, acc: 1.0)
[2025-02-17 16:46:21,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:21,836][root][INFO] - Training Epoch: 1/2, step 3339/107898 completed (loss: 0.03396592661738396, acc: 1.0)
[2025-02-17 16:46:21,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:22,142][root][INFO] - Training Epoch: 1/2, step 3340/107898 completed (loss: 0.29598647356033325, acc: 1.0)
[2025-02-17 16:46:22,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:22,437][root][INFO] - Training Epoch: 1/2, step 3341/107898 completed (loss: 0.11471151560544968, acc: 1.0)
[2025-02-17 16:46:22,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:22,731][root][INFO] - Training Epoch: 1/2, step 3342/107898 completed (loss: 0.21314583718776703, acc: 1.0)
[2025-02-17 16:46:22,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:23,029][root][INFO] - Training Epoch: 1/2, step 3343/107898 completed (loss: 2.3415756225585938, acc: 0.5714285969734192)
[2025-02-17 16:46:23,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:23,343][root][INFO] - Training Epoch: 1/2, step 3344/107898 completed (loss: 1.3999186754226685, acc: 0.6153846383094788)
[2025-02-17 16:46:23,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:23,638][root][INFO] - Training Epoch: 1/2, step 3345/107898 completed (loss: 4.564209938049316, acc: 0.13333334028720856)
[2025-02-17 16:46:23,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:23,927][root][INFO] - Training Epoch: 1/2, step 3346/107898 completed (loss: 0.6448172926902771, acc: 0.8333333134651184)
[2025-02-17 16:46:24,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:24,244][root][INFO] - Training Epoch: 1/2, step 3347/107898 completed (loss: 1.044070839881897, acc: 0.800000011920929)
[2025-02-17 16:46:24,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:24,612][root][INFO] - Training Epoch: 1/2, step 3348/107898 completed (loss: 0.98624187707901, acc: 0.8421052694320679)
[2025-02-17 16:46:24,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:24,957][root][INFO] - Training Epoch: 1/2, step 3349/107898 completed (loss: 0.0037318801041692495, acc: 1.0)
[2025-02-17 16:46:25,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:25,267][root][INFO] - Training Epoch: 1/2, step 3350/107898 completed (loss: 0.004412777256220579, acc: 1.0)
[2025-02-17 16:46:25,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:25,599][root][INFO] - Training Epoch: 1/2, step 3351/107898 completed (loss: 2.8501040935516357, acc: 0.6363636255264282)
[2025-02-17 16:46:25,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:25,905][root][INFO] - Training Epoch: 1/2, step 3352/107898 completed (loss: 3.738947629928589, acc: 0.3125)
[2025-02-17 16:46:25,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:26,183][root][INFO] - Training Epoch: 1/2, step 3353/107898 completed (loss: 0.6570683717727661, acc: 0.8125)
[2025-02-17 16:46:26,254][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:26,470][root][INFO] - Training Epoch: 1/2, step 3354/107898 completed (loss: 0.011840270832180977, acc: 1.0)
[2025-02-17 16:46:26,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:26,760][root][INFO] - Training Epoch: 1/2, step 3355/107898 completed (loss: 2.1324830055236816, acc: 0.6000000238418579)
[2025-02-17 16:46:26,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:27,054][root][INFO] - Training Epoch: 1/2, step 3356/107898 completed (loss: 0.5282754898071289, acc: 1.0)
[2025-02-17 16:46:27,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:27,356][root][INFO] - Training Epoch: 1/2, step 3357/107898 completed (loss: 4.002762317657471, acc: 0.3333333432674408)
[2025-02-17 16:46:27,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:27,652][root][INFO] - Training Epoch: 1/2, step 3358/107898 completed (loss: 0.39392194151878357, acc: 0.8181818127632141)
[2025-02-17 16:46:27,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:27,965][root][INFO] - Training Epoch: 1/2, step 3359/107898 completed (loss: 3.378239154815674, acc: 0.38461539149284363)
[2025-02-17 16:46:28,069][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:28,294][root][INFO] - Training Epoch: 1/2, step 3360/107898 completed (loss: 2.086792230606079, acc: 0.5625)
[2025-02-17 16:46:28,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:28,624][root][INFO] - Training Epoch: 1/2, step 3361/107898 completed (loss: 4.245678424835205, acc: 0.22727273404598236)
[2025-02-17 16:46:28,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:28,966][root][INFO] - Training Epoch: 1/2, step 3362/107898 completed (loss: 1.0433510541915894, acc: 0.75)
[2025-02-17 16:46:29,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:29,291][root][INFO] - Training Epoch: 1/2, step 3363/107898 completed (loss: 0.8908727169036865, acc: 0.7777777910232544)
[2025-02-17 16:46:29,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:29,606][root][INFO] - Training Epoch: 1/2, step 3364/107898 completed (loss: 0.8672851920127869, acc: 0.8947368264198303)
[2025-02-17 16:46:29,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:29,935][root][INFO] - Training Epoch: 1/2, step 3365/107898 completed (loss: 0.8304324150085449, acc: 0.7142857313156128)
[2025-02-17 16:46:30,034][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:30,259][root][INFO] - Training Epoch: 1/2, step 3366/107898 completed (loss: 0.4586428999900818, acc: 0.8888888955116272)
[2025-02-17 16:46:30,373][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:30,617][root][INFO] - Training Epoch: 1/2, step 3367/107898 completed (loss: 0.015830283984541893, acc: 1.0)
[2025-02-17 16:46:30,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:30,954][root][INFO] - Training Epoch: 1/2, step 3368/107898 completed (loss: 1.3997493982315063, acc: 0.8999999761581421)
[2025-02-17 16:46:31,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:31,256][root][INFO] - Training Epoch: 1/2, step 3369/107898 completed (loss: 0.24386915564537048, acc: 1.0)
[2025-02-17 16:46:31,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:31,553][root][INFO] - Training Epoch: 1/2, step 3370/107898 completed (loss: 0.4285697340965271, acc: 0.9375)
[2025-02-17 16:46:31,634][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:31,854][root][INFO] - Training Epoch: 1/2, step 3371/107898 completed (loss: 2.4963362216949463, acc: 0.5454545617103577)
[2025-02-17 16:46:31,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:32,154][root][INFO] - Training Epoch: 1/2, step 3372/107898 completed (loss: 2.4075958728790283, acc: 0.3333333432674408)
[2025-02-17 16:46:32,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:32,490][root][INFO] - Training Epoch: 1/2, step 3373/107898 completed (loss: 3.498014450073242, acc: 0.29411765933036804)
[2025-02-17 16:46:32,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:32,817][root][INFO] - Training Epoch: 1/2, step 3374/107898 completed (loss: 1.319518804550171, acc: 0.807692289352417)
[2025-02-17 16:46:32,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:33,104][root][INFO] - Training Epoch: 1/2, step 3375/107898 completed (loss: 1.7223869562149048, acc: 0.800000011920929)
[2025-02-17 16:46:33,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:33,401][root][INFO] - Training Epoch: 1/2, step 3376/107898 completed (loss: 0.009790705516934395, acc: 1.0)
[2025-02-17 16:46:33,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:33,698][root][INFO] - Training Epoch: 1/2, step 3377/107898 completed (loss: 3.0322487354278564, acc: 0.3333333432674408)
[2025-02-17 16:46:33,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:34,034][root][INFO] - Training Epoch: 1/2, step 3378/107898 completed (loss: 0.6762765049934387, acc: 1.0)
[2025-02-17 16:46:34,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:34,312][root][INFO] - Training Epoch: 1/2, step 3379/107898 completed (loss: 0.20390506088733673, acc: 1.0)
[2025-02-17 16:46:34,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:34,663][root][INFO] - Training Epoch: 1/2, step 3380/107898 completed (loss: 0.3680579960346222, acc: 0.875)
[2025-02-17 16:46:34,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:34,993][root][INFO] - Training Epoch: 1/2, step 3381/107898 completed (loss: 0.703496515750885, acc: 0.8928571343421936)
[2025-02-17 16:46:35,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:35,359][root][INFO] - Training Epoch: 1/2, step 3382/107898 completed (loss: 0.7406135201454163, acc: 0.8461538553237915)
[2025-02-17 16:46:35,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:35,683][root][INFO] - Training Epoch: 1/2, step 3383/107898 completed (loss: 2.0835394859313965, acc: 0.5)
[2025-02-17 16:46:35,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:36,023][root][INFO] - Training Epoch: 1/2, step 3384/107898 completed (loss: 1.586656928062439, acc: 0.6666666865348816)
[2025-02-17 16:46:36,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:36,334][root][INFO] - Training Epoch: 1/2, step 3385/107898 completed (loss: 2.6154627799987793, acc: 0.3333333432674408)
[2025-02-17 16:46:36,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:36,632][root][INFO] - Training Epoch: 1/2, step 3386/107898 completed (loss: 0.004448125138878822, acc: 1.0)
[2025-02-17 16:46:36,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:36,964][root][INFO] - Training Epoch: 1/2, step 3387/107898 completed (loss: 3.5700736045837402, acc: 0.42424243688583374)
[2025-02-17 16:46:37,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:37,307][root][INFO] - Training Epoch: 1/2, step 3388/107898 completed (loss: 1.8315167427062988, acc: 0.6666666865348816)
[2025-02-17 16:46:37,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:37,637][root][INFO] - Training Epoch: 1/2, step 3389/107898 completed (loss: 4.686470031738281, acc: 0.20000000298023224)
[2025-02-17 16:46:37,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:37,992][root][INFO] - Training Epoch: 1/2, step 3390/107898 completed (loss: 4.965834140777588, acc: 0.3333333432674408)
[2025-02-17 16:46:38,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:38,343][root][INFO] - Training Epoch: 1/2, step 3391/107898 completed (loss: 1.1178860664367676, acc: 0.7666666507720947)
[2025-02-17 16:46:38,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:38,680][root][INFO] - Training Epoch: 1/2, step 3392/107898 completed (loss: 1.2387621402740479, acc: 0.75)
[2025-02-17 16:46:38,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:39,022][root][INFO] - Training Epoch: 1/2, step 3393/107898 completed (loss: 2.4305193424224854, acc: 0.6666666865348816)
[2025-02-17 16:46:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:39,337][root][INFO] - Training Epoch: 1/2, step 3394/107898 completed (loss: 0.006758636329323053, acc: 1.0)
[2025-02-17 16:46:39,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:39,632][root][INFO] - Training Epoch: 1/2, step 3395/107898 completed (loss: 0.02364683896303177, acc: 1.0)
[2025-02-17 16:46:39,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:39,963][root][INFO] - Training Epoch: 1/2, step 3396/107898 completed (loss: 3.54822039604187, acc: 0.3333333432674408)
[2025-02-17 16:46:40,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:40,262][root][INFO] - Training Epoch: 1/2, step 3397/107898 completed (loss: 1.5227231979370117, acc: 0.6666666865348816)
[2025-02-17 16:46:40,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:40,569][root][INFO] - Training Epoch: 1/2, step 3398/107898 completed (loss: 0.39619752764701843, acc: 0.8666666746139526)
[2025-02-17 16:46:40,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:40,874][root][INFO] - Training Epoch: 1/2, step 3399/107898 completed (loss: 3.591393232345581, acc: 0.20000000298023224)
[2025-02-17 16:46:40,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:41,171][root][INFO] - Training Epoch: 1/2, step 3400/107898 completed (loss: 1.8100647926330566, acc: 0.5714285969734192)
[2025-02-17 16:46:41,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:41,465][root][INFO] - Training Epoch: 1/2, step 3401/107898 completed (loss: 0.9315966367721558, acc: 0.7857142686843872)
[2025-02-17 16:46:41,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:41,762][root][INFO] - Training Epoch: 1/2, step 3402/107898 completed (loss: 0.596898078918457, acc: 1.0)
[2025-02-17 16:46:41,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:42,070][root][INFO] - Training Epoch: 1/2, step 3403/107898 completed (loss: 3.7402596473693848, acc: 0.20000000298023224)
[2025-02-17 16:46:42,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:42,367][root][INFO] - Training Epoch: 1/2, step 3404/107898 completed (loss: 0.7005897164344788, acc: 0.8500000238418579)
[2025-02-17 16:46:42,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:42,698][root][INFO] - Training Epoch: 1/2, step 3405/107898 completed (loss: 1.7628471851348877, acc: 0.5454545617103577)
[2025-02-17 16:46:42,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:43,035][root][INFO] - Training Epoch: 1/2, step 3406/107898 completed (loss: 0.9435986280441284, acc: 0.699999988079071)
[2025-02-17 16:46:43,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:43,374][root][INFO] - Training Epoch: 1/2, step 3407/107898 completed (loss: 0.16991709172725677, acc: 1.0)
[2025-02-17 16:46:43,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:43,676][root][INFO] - Training Epoch: 1/2, step 3408/107898 completed (loss: 5.5777740478515625, acc: 0.0)
[2025-02-17 16:46:43,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:44,007][root][INFO] - Training Epoch: 1/2, step 3409/107898 completed (loss: 0.5606315732002258, acc: 0.8888888955116272)
[2025-02-17 16:46:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:44,327][root][INFO] - Training Epoch: 1/2, step 3410/107898 completed (loss: 2.378800630569458, acc: 0.4285714328289032)
[2025-02-17 16:46:44,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:44,634][root][INFO] - Training Epoch: 1/2, step 3411/107898 completed (loss: 0.7982687950134277, acc: 0.8999999761581421)
[2025-02-17 16:46:44,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:44,938][root][INFO] - Training Epoch: 1/2, step 3412/107898 completed (loss: 2.2764623165130615, acc: 0.5)
[2025-02-17 16:46:45,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:45,242][root][INFO] - Training Epoch: 1/2, step 3413/107898 completed (loss: 3.0434670448303223, acc: 0.30000001192092896)
[2025-02-17 16:46:45,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:45,542][root][INFO] - Training Epoch: 1/2, step 3414/107898 completed (loss: 0.921237587928772, acc: 0.7272727489471436)
[2025-02-17 16:46:45,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:45,840][root][INFO] - Training Epoch: 1/2, step 3415/107898 completed (loss: 3.664072275161743, acc: 0.0416666679084301)
[2025-02-17 16:46:45,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:46,120][root][INFO] - Training Epoch: 1/2, step 3416/107898 completed (loss: 2.0938796997070312, acc: 0.5)
[2025-02-17 16:46:46,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:46,430][root][INFO] - Training Epoch: 1/2, step 3417/107898 completed (loss: 0.29152417182922363, acc: 0.9047619104385376)
[2025-02-17 16:46:46,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:46,735][root][INFO] - Training Epoch: 1/2, step 3418/107898 completed (loss: 0.19761650264263153, acc: 1.0)
[2025-02-17 16:46:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:47,021][root][INFO] - Training Epoch: 1/2, step 3419/107898 completed (loss: 3.9507923126220703, acc: 0.3333333432674408)
[2025-02-17 16:46:47,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:47,312][root][INFO] - Training Epoch: 1/2, step 3420/107898 completed (loss: 0.5442299246788025, acc: 0.875)
[2025-02-17 16:46:47,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:47,674][root][INFO] - Training Epoch: 1/2, step 3421/107898 completed (loss: 1.2892054319381714, acc: 0.692307710647583)
[2025-02-17 16:46:47,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:47,991][root][INFO] - Training Epoch: 1/2, step 3422/107898 completed (loss: 0.4599149525165558, acc: 0.875)
[2025-02-17 16:46:48,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:48,313][root][INFO] - Training Epoch: 1/2, step 3423/107898 completed (loss: 1.2347716093063354, acc: 0.5)
[2025-02-17 16:46:48,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:48,624][root][INFO] - Training Epoch: 1/2, step 3424/107898 completed (loss: 2.170581340789795, acc: 0.5)
[2025-02-17 16:46:48,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:48,918][root][INFO] - Training Epoch: 1/2, step 3425/107898 completed (loss: 0.0068081580102443695, acc: 1.0)
[2025-02-17 16:46:49,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:49,171][root][INFO] - Training Epoch: 1/2, step 3426/107898 completed (loss: 1.5444155931472778, acc: 0.8125)
[2025-02-17 16:46:49,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:49,472][root][INFO] - Training Epoch: 1/2, step 3427/107898 completed (loss: 0.7323902249336243, acc: 0.7272727489471436)
[2025-02-17 16:46:49,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:49,773][root][INFO] - Training Epoch: 1/2, step 3428/107898 completed (loss: 0.8946257829666138, acc: 0.6000000238418579)
[2025-02-17 16:46:49,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:50,114][root][INFO] - Training Epoch: 1/2, step 3429/107898 completed (loss: 2.1898653507232666, acc: 0.5)
[2025-02-17 16:46:50,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:50,445][root][INFO] - Training Epoch: 1/2, step 3430/107898 completed (loss: 0.33394113183021545, acc: 0.9166666865348816)
[2025-02-17 16:46:50,559][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:50,799][root][INFO] - Training Epoch: 1/2, step 3431/107898 completed (loss: 1.6882336139678955, acc: 0.75)
[2025-02-17 16:46:50,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:51,155][root][INFO] - Training Epoch: 1/2, step 3432/107898 completed (loss: 2.389099597930908, acc: 0.5)
[2025-02-17 16:46:51,257][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:51,479][root][INFO] - Training Epoch: 1/2, step 3433/107898 completed (loss: 0.2083009034395218, acc: 1.0)
[2025-02-17 16:46:51,577][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:51,801][root][INFO] - Training Epoch: 1/2, step 3434/107898 completed (loss: 1.5865362882614136, acc: 0.7777777910232544)
[2025-02-17 16:46:51,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:52,138][root][INFO] - Training Epoch: 1/2, step 3435/107898 completed (loss: 4.6476922035217285, acc: 0.25)
[2025-02-17 16:46:52,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:52,511][root][INFO] - Training Epoch: 1/2, step 3436/107898 completed (loss: 0.4602545499801636, acc: 0.9130434989929199)
[2025-02-17 16:46:52,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:52,822][root][INFO] - Training Epoch: 1/2, step 3437/107898 completed (loss: 4.749232292175293, acc: 0.20000000298023224)
[2025-02-17 16:46:52,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:53,125][root][INFO] - Training Epoch: 1/2, step 3438/107898 completed (loss: 1.473623275756836, acc: 0.5)
[2025-02-17 16:46:53,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:53,479][root][INFO] - Training Epoch: 1/2, step 3439/107898 completed (loss: 2.63960599899292, acc: 0.2222222238779068)
[2025-02-17 16:46:53,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:53,831][root][INFO] - Training Epoch: 1/2, step 3440/107898 completed (loss: 0.01210186816751957, acc: 1.0)
[2025-02-17 16:46:53,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:54,144][root][INFO] - Training Epoch: 1/2, step 3441/107898 completed (loss: 1.975209355354309, acc: 0.6666666865348816)
[2025-02-17 16:46:54,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:54,493][root][INFO] - Training Epoch: 1/2, step 3442/107898 completed (loss: 1.795723795890808, acc: 0.5882353186607361)
[2025-02-17 16:46:54,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:54,834][root][INFO] - Training Epoch: 1/2, step 3443/107898 completed (loss: 0.6206599473953247, acc: 0.8571428656578064)
[2025-02-17 16:46:54,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:55,160][root][INFO] - Training Epoch: 1/2, step 3444/107898 completed (loss: 1.4405646324157715, acc: 0.692307710647583)
[2025-02-17 16:46:55,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:55,486][root][INFO] - Training Epoch: 1/2, step 3445/107898 completed (loss: 0.6807029843330383, acc: 0.8857142925262451)
[2025-02-17 16:46:55,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:55,828][root][INFO] - Training Epoch: 1/2, step 3446/107898 completed (loss: 0.20607975125312805, acc: 1.0)
[2025-02-17 16:46:55,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:56,161][root][INFO] - Training Epoch: 1/2, step 3447/107898 completed (loss: 0.1365070939064026, acc: 1.0)
[2025-02-17 16:46:56,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:56,460][root][INFO] - Training Epoch: 1/2, step 3448/107898 completed (loss: 0.9054163694381714, acc: 1.0)
[2025-02-17 16:46:56,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:56,731][root][INFO] - Training Epoch: 1/2, step 3449/107898 completed (loss: 0.5160871148109436, acc: 0.9333333373069763)
[2025-02-17 16:46:56,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:57,026][root][INFO] - Training Epoch: 1/2, step 3450/107898 completed (loss: 0.3155960440635681, acc: 0.875)
[2025-02-17 16:46:57,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:57,357][root][INFO] - Training Epoch: 1/2, step 3451/107898 completed (loss: 2.9474267959594727, acc: 0.5555555820465088)
[2025-02-17 16:46:57,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:57,713][root][INFO] - Training Epoch: 1/2, step 3452/107898 completed (loss: 0.4382833242416382, acc: 0.9200000166893005)
[2025-02-17 16:46:57,822][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:58,036][root][INFO] - Training Epoch: 1/2, step 3453/107898 completed (loss: 0.8000686168670654, acc: 0.7777777910232544)
[2025-02-17 16:46:58,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:58,354][root][INFO] - Training Epoch: 1/2, step 3454/107898 completed (loss: 0.07532280683517456, acc: 1.0)
[2025-02-17 16:46:58,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:58,711][root][INFO] - Training Epoch: 1/2, step 3455/107898 completed (loss: 0.6892545223236084, acc: 0.8333333134651184)
[2025-02-17 16:46:58,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:59,007][root][INFO] - Training Epoch: 1/2, step 3456/107898 completed (loss: 0.08210989832878113, acc: 1.0)
[2025-02-17 16:46:59,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:59,316][root][INFO] - Training Epoch: 1/2, step 3457/107898 completed (loss: 0.010099746286869049, acc: 1.0)
[2025-02-17 16:46:59,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:59,644][root][INFO] - Training Epoch: 1/2, step 3458/107898 completed (loss: 0.8571100831031799, acc: 0.8461538553237915)
[2025-02-17 16:46:59,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:46:59,962][root][INFO] - Training Epoch: 1/2, step 3459/107898 completed (loss: 1.5951342582702637, acc: 0.6818181872367859)
[2025-02-17 16:47:00,069][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:00,288][root][INFO] - Training Epoch: 1/2, step 3460/107898 completed (loss: 1.4340647459030151, acc: 0.8333333134651184)
[2025-02-17 16:47:00,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:00,636][root][INFO] - Training Epoch: 1/2, step 3461/107898 completed (loss: 0.01532658189535141, acc: 1.0)
[2025-02-17 16:47:00,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:00,989][root][INFO] - Training Epoch: 1/2, step 3462/107898 completed (loss: 3.5402626991271973, acc: 0.3571428656578064)
[2025-02-17 16:47:01,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:01,302][root][INFO] - Training Epoch: 1/2, step 3463/107898 completed (loss: 0.010480502620339394, acc: 1.0)
[2025-02-17 16:47:01,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:01,630][root][INFO] - Training Epoch: 1/2, step 3464/107898 completed (loss: 0.10285767167806625, acc: 1.0)
[2025-02-17 16:47:01,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:01,922][root][INFO] - Training Epoch: 1/2, step 3465/107898 completed (loss: 3.708799362182617, acc: 0.31578946113586426)
[2025-02-17 16:47:02,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:02,218][root][INFO] - Training Epoch: 1/2, step 3466/107898 completed (loss: 0.0403711199760437, acc: 1.0)
[2025-02-17 16:47:02,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:02,576][root][INFO] - Training Epoch: 1/2, step 3467/107898 completed (loss: 0.06779519468545914, acc: 1.0)
[2025-02-17 16:47:02,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:02,904][root][INFO] - Training Epoch: 1/2, step 3468/107898 completed (loss: 0.38407355546951294, acc: 0.8999999761581421)
[2025-02-17 16:47:03,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:03,224][root][INFO] - Training Epoch: 1/2, step 3469/107898 completed (loss: 0.38367393612861633, acc: 0.8461538553237915)
[2025-02-17 16:47:03,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:03,528][root][INFO] - Training Epoch: 1/2, step 3470/107898 completed (loss: 1.5610729455947876, acc: 0.6666666865348816)
[2025-02-17 16:47:03,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:03,818][root][INFO] - Training Epoch: 1/2, step 3471/107898 completed (loss: 0.30978134274482727, acc: 0.8888888955116272)
[2025-02-17 16:47:03,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:04,166][root][INFO] - Training Epoch: 1/2, step 3472/107898 completed (loss: 1.5473212003707886, acc: 0.6666666865348816)
[2025-02-17 16:47:04,280][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:04,508][root][INFO] - Training Epoch: 1/2, step 3473/107898 completed (loss: 0.04361681267619133, acc: 1.0)
[2025-02-17 16:47:04,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:04,823][root][INFO] - Training Epoch: 1/2, step 3474/107898 completed (loss: 1.118202805519104, acc: 0.7272727489471436)
[2025-02-17 16:47:04,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:05,124][root][INFO] - Training Epoch: 1/2, step 3475/107898 completed (loss: 0.08203353732824326, acc: 1.0)
[2025-02-17 16:47:05,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:05,423][root][INFO] - Training Epoch: 1/2, step 3476/107898 completed (loss: 3.4041852951049805, acc: 0.1818181872367859)
[2025-02-17 16:47:05,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:05,725][root][INFO] - Training Epoch: 1/2, step 3477/107898 completed (loss: 0.031889550387859344, acc: 1.0)
[2025-02-17 16:47:05,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:06,075][root][INFO] - Training Epoch: 1/2, step 3478/107898 completed (loss: 0.17969240248203278, acc: 0.9230769276618958)
[2025-02-17 16:47:06,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:06,417][root][INFO] - Training Epoch: 1/2, step 3479/107898 completed (loss: 0.030723128467798233, acc: 1.0)
[2025-02-17 16:47:06,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:06,744][root][INFO] - Training Epoch: 1/2, step 3480/107898 completed (loss: 0.12412600219249725, acc: 0.9333333373069763)
[2025-02-17 16:47:06,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:07,060][root][INFO] - Training Epoch: 1/2, step 3481/107898 completed (loss: 1.6732958555221558, acc: 0.7037037014961243)
[2025-02-17 16:47:07,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:07,440][root][INFO] - Training Epoch: 1/2, step 3482/107898 completed (loss: 2.1247451305389404, acc: 0.625)
[2025-02-17 16:47:07,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:07,776][root][INFO] - Training Epoch: 1/2, step 3483/107898 completed (loss: 0.0013266168534755707, acc: 1.0)
[2025-02-17 16:47:07,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:08,097][root][INFO] - Training Epoch: 1/2, step 3484/107898 completed (loss: 0.011530534364283085, acc: 1.0)
[2025-02-17 16:47:08,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:08,457][root][INFO] - Training Epoch: 1/2, step 3485/107898 completed (loss: 2.719158887863159, acc: 0.6086956262588501)
[2025-02-17 16:47:08,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:08,806][root][INFO] - Training Epoch: 1/2, step 3486/107898 completed (loss: 0.5427584648132324, acc: 0.9090909361839294)
[2025-02-17 16:47:08,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:09,163][root][INFO] - Training Epoch: 1/2, step 3487/107898 completed (loss: 0.5203213691711426, acc: 0.8518518805503845)
[2025-02-17 16:47:09,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:09,469][root][INFO] - Training Epoch: 1/2, step 3488/107898 completed (loss: 0.663140594959259, acc: 0.6666666865348816)
[2025-02-17 16:47:09,599][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:09,852][root][INFO] - Training Epoch: 1/2, step 3489/107898 completed (loss: 0.8787949085235596, acc: 0.8333333134651184)
[2025-02-17 16:47:09,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:10,187][root][INFO] - Training Epoch: 1/2, step 3490/107898 completed (loss: 3.007051944732666, acc: 0.4000000059604645)
[2025-02-17 16:47:10,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:10,520][root][INFO] - Training Epoch: 1/2, step 3491/107898 completed (loss: 0.49079054594039917, acc: 0.9285714030265808)
[2025-02-17 16:47:10,599][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:10,810][root][INFO] - Training Epoch: 1/2, step 3492/107898 completed (loss: 2.1969704627990723, acc: 0.7142857313156128)
[2025-02-17 16:47:10,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:11,105][root][INFO] - Training Epoch: 1/2, step 3493/107898 completed (loss: 1.4769700765609741, acc: 0.5)
[2025-02-17 16:47:11,189][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:11,454][root][INFO] - Training Epoch: 1/2, step 3494/107898 completed (loss: 1.5370612144470215, acc: 0.6800000071525574)
[2025-02-17 16:47:11,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:11,793][root][INFO] - Training Epoch: 1/2, step 3495/107898 completed (loss: 3.520979404449463, acc: 0.2857142984867096)
[2025-02-17 16:47:11,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:12,128][root][INFO] - Training Epoch: 1/2, step 3496/107898 completed (loss: 0.8225238919258118, acc: 0.800000011920929)
[2025-02-17 16:47:12,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:12,449][root][INFO] - Training Epoch: 1/2, step 3497/107898 completed (loss: 0.359090656042099, acc: 1.0)
[2025-02-17 16:47:12,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:12,777][root][INFO] - Training Epoch: 1/2, step 3498/107898 completed (loss: 0.7096139192581177, acc: 0.8666666746139526)
[2025-02-17 16:47:12,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:13,142][root][INFO] - Training Epoch: 1/2, step 3499/107898 completed (loss: 0.5496072173118591, acc: 0.8636363744735718)
[2025-02-17 16:47:13,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:13,475][root][INFO] - Training Epoch: 1/2, step 3500/107898 completed (loss: 0.07466471940279007, acc: 1.0)
[2025-02-17 16:47:13,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:13,800][root][INFO] - Training Epoch: 1/2, step 3501/107898 completed (loss: 1.9979251623153687, acc: 0.3333333432674408)
[2025-02-17 16:47:13,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:14,439][root][INFO] - Training Epoch: 1/2, step 3502/107898 completed (loss: 4.204187870025635, acc: 0.30000001192092896)
[2025-02-17 16:47:14,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:14,750][root][INFO] - Training Epoch: 1/2, step 3503/107898 completed (loss: 1.5038131475448608, acc: 0.6000000238418579)
[2025-02-17 16:47:14,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:15,052][root][INFO] - Training Epoch: 1/2, step 3504/107898 completed (loss: 1.1809293031692505, acc: 0.7692307829856873)
[2025-02-17 16:47:15,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:15,359][root][INFO] - Training Epoch: 1/2, step 3505/107898 completed (loss: 5.458058834075928, acc: 0.5)
[2025-02-17 16:47:15,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:15,649][root][INFO] - Training Epoch: 1/2, step 3506/107898 completed (loss: 0.4728530943393707, acc: 1.0)
[2025-02-17 16:47:15,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:15,956][root][INFO] - Training Epoch: 1/2, step 3507/107898 completed (loss: 0.887506902217865, acc: 0.8125)
[2025-02-17 16:47:16,069][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:16,275][root][INFO] - Training Epoch: 1/2, step 3508/107898 completed (loss: 0.3622993528842926, acc: 0.9411764740943909)
[2025-02-17 16:47:16,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:16,563][root][INFO] - Training Epoch: 1/2, step 3509/107898 completed (loss: 1.9890186786651611, acc: 0.75)
[2025-02-17 16:47:16,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:16,879][root][INFO] - Training Epoch: 1/2, step 3510/107898 completed (loss: 0.4742338955402374, acc: 0.75)
[2025-02-17 16:47:16,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:17,203][root][INFO] - Training Epoch: 1/2, step 3511/107898 completed (loss: 2.5540308952331543, acc: 0.5263158082962036)
[2025-02-17 16:47:17,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:17,506][root][INFO] - Training Epoch: 1/2, step 3512/107898 completed (loss: 1.5041193962097168, acc: 0.6666666865348816)
[2025-02-17 16:47:17,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:17,805][root][INFO] - Training Epoch: 1/2, step 3513/107898 completed (loss: 3.032721757888794, acc: 0.517241358757019)
[2025-02-17 16:47:17,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:18,136][root][INFO] - Training Epoch: 1/2, step 3514/107898 completed (loss: 1.3823249340057373, acc: 0.78125)
[2025-02-17 16:47:18,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:18,464][root][INFO] - Training Epoch: 1/2, step 3515/107898 completed (loss: 3.3222198486328125, acc: 0.6000000238418579)
[2025-02-17 16:47:18,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:18,769][root][INFO] - Training Epoch: 1/2, step 3516/107898 completed (loss: 2.010664701461792, acc: 0.5)
[2025-02-17 16:47:18,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:19,063][root][INFO] - Training Epoch: 1/2, step 3517/107898 completed (loss: 0.0033519254066050053, acc: 1.0)
[2025-02-17 16:47:19,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:19,355][root][INFO] - Training Epoch: 1/2, step 3518/107898 completed (loss: 0.6891545057296753, acc: 0.75)
[2025-02-17 16:47:19,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:19,652][root][INFO] - Training Epoch: 1/2, step 3519/107898 completed (loss: 0.0038258498534560204, acc: 1.0)
[2025-02-17 16:47:19,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:19,979][root][INFO] - Training Epoch: 1/2, step 3520/107898 completed (loss: 0.17909151315689087, acc: 1.0)
[2025-02-17 16:47:20,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:20,292][root][INFO] - Training Epoch: 1/2, step 3521/107898 completed (loss: 1.5246729850769043, acc: 0.6666666865348816)
[2025-02-17 16:47:20,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:20,575][root][INFO] - Training Epoch: 1/2, step 3522/107898 completed (loss: 0.04041155055165291, acc: 1.0)
[2025-02-17 16:47:20,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:20,865][root][INFO] - Training Epoch: 1/2, step 3523/107898 completed (loss: 1.5250927209854126, acc: 0.7142857313156128)
[2025-02-17 16:47:20,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:21,173][root][INFO] - Training Epoch: 1/2, step 3524/107898 completed (loss: 3.9216549396514893, acc: 0.25)
[2025-02-17 16:47:21,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:21,466][root][INFO] - Training Epoch: 1/2, step 3525/107898 completed (loss: 1.264304280281067, acc: 0.800000011920929)
[2025-02-17 16:47:21,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:21,767][root][INFO] - Training Epoch: 1/2, step 3526/107898 completed (loss: 0.8920472264289856, acc: 0.8571428656578064)
[2025-02-17 16:47:21,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:22,065][root][INFO] - Training Epoch: 1/2, step 3527/107898 completed (loss: 1.7515077590942383, acc: 0.6666666865348816)
[2025-02-17 16:47:22,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:22,366][root][INFO] - Training Epoch: 1/2, step 3528/107898 completed (loss: 0.023440157994627953, acc: 1.0)
[2025-02-17 16:47:22,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:22,681][root][INFO] - Training Epoch: 1/2, step 3529/107898 completed (loss: 0.6123223304748535, acc: 0.5)
[2025-02-17 16:47:22,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:23,018][root][INFO] - Training Epoch: 1/2, step 3530/107898 completed (loss: 0.2880861759185791, acc: 0.9166666865348816)
[2025-02-17 16:47:23,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:23,385][root][INFO] - Training Epoch: 1/2, step 3531/107898 completed (loss: 3.1071572303771973, acc: 0.43478259444236755)
[2025-02-17 16:47:23,478][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:23,702][root][INFO] - Training Epoch: 1/2, step 3532/107898 completed (loss: 2.1500391960144043, acc: 0.7142857313156128)
[2025-02-17 16:47:23,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:24,031][root][INFO] - Training Epoch: 1/2, step 3533/107898 completed (loss: 0.04169853404164314, acc: 1.0)
[2025-02-17 16:47:24,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:24,343][root][INFO] - Training Epoch: 1/2, step 3534/107898 completed (loss: 0.05076664686203003, acc: 1.0)
[2025-02-17 16:47:24,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:24,652][root][INFO] - Training Epoch: 1/2, step 3535/107898 completed (loss: 0.12470437586307526, acc: 1.0)
[2025-02-17 16:47:24,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:24,960][root][INFO] - Training Epoch: 1/2, step 3536/107898 completed (loss: 1.1994855403900146, acc: 0.8666666746139526)
[2025-02-17 16:47:25,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:25,262][root][INFO] - Training Epoch: 1/2, step 3537/107898 completed (loss: 1.0663214921951294, acc: 0.7692307829856873)
[2025-02-17 16:47:25,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:25,561][root][INFO] - Training Epoch: 1/2, step 3538/107898 completed (loss: 0.3635738492012024, acc: 0.9230769276618958)
[2025-02-17 16:47:25,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:25,860][root][INFO] - Training Epoch: 1/2, step 3539/107898 completed (loss: 1.4690377712249756, acc: 0.6666666865348816)
[2025-02-17 16:47:25,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:26,160][root][INFO] - Training Epoch: 1/2, step 3540/107898 completed (loss: 0.5046402215957642, acc: 0.800000011920929)
[2025-02-17 16:47:26,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:26,459][root][INFO] - Training Epoch: 1/2, step 3541/107898 completed (loss: 1.0997254848480225, acc: 0.761904776096344)
[2025-02-17 16:47:26,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:26,762][root][INFO] - Training Epoch: 1/2, step 3542/107898 completed (loss: 1.8367302417755127, acc: 0.5333333611488342)
[2025-02-17 16:47:26,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:27,104][root][INFO] - Training Epoch: 1/2, step 3543/107898 completed (loss: 5.326972961425781, acc: 0.20000000298023224)
[2025-02-17 16:47:27,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:27,422][root][INFO] - Training Epoch: 1/2, step 3544/107898 completed (loss: 4.271423816680908, acc: 0.3333333432674408)
[2025-02-17 16:47:27,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:27,730][root][INFO] - Training Epoch: 1/2, step 3545/107898 completed (loss: 0.9432053565979004, acc: 0.6666666865348816)
[2025-02-17 16:47:27,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:28,017][root][INFO] - Training Epoch: 1/2, step 3546/107898 completed (loss: 2.2995240688323975, acc: 0.5454545617103577)
[2025-02-17 16:47:28,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:28,319][root][INFO] - Training Epoch: 1/2, step 3547/107898 completed (loss: 1.0742981433868408, acc: 0.7647058963775635)
[2025-02-17 16:47:28,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:28,617][root][INFO] - Training Epoch: 1/2, step 3548/107898 completed (loss: 1.355211853981018, acc: 0.6666666865348816)
[2025-02-17 16:47:28,696][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:28,914][root][INFO] - Training Epoch: 1/2, step 3549/107898 completed (loss: 0.7117738127708435, acc: 0.8461538553237915)
[2025-02-17 16:47:28,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:29,212][root][INFO] - Training Epoch: 1/2, step 3550/107898 completed (loss: 1.7076419591903687, acc: 0.625)
[2025-02-17 16:47:29,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:29,510][root][INFO] - Training Epoch: 1/2, step 3551/107898 completed (loss: 0.00278549175709486, acc: 1.0)
[2025-02-17 16:47:29,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:29,820][root][INFO] - Training Epoch: 1/2, step 3552/107898 completed (loss: 0.6659072041511536, acc: 0.8571428656578064)
[2025-02-17 16:47:29,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:30,170][root][INFO] - Training Epoch: 1/2, step 3553/107898 completed (loss: 0.508816659450531, acc: 0.9285714030265808)
[2025-02-17 16:47:30,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:30,503][root][INFO] - Training Epoch: 1/2, step 3554/107898 completed (loss: 1.81100594997406, acc: 0.6666666865348816)
[2025-02-17 16:47:30,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:30,820][root][INFO] - Training Epoch: 1/2, step 3555/107898 completed (loss: 1.385819911956787, acc: 0.75)
[2025-02-17 16:47:30,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:31,119][root][INFO] - Training Epoch: 1/2, step 3556/107898 completed (loss: 0.8079491853713989, acc: 0.7692307829856873)
[2025-02-17 16:47:31,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:31,433][root][INFO] - Training Epoch: 1/2, step 3557/107898 completed (loss: 0.8966690897941589, acc: 0.807692289352417)
[2025-02-17 16:47:31,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:31,716][root][INFO] - Training Epoch: 1/2, step 3558/107898 completed (loss: 0.7564513683319092, acc: 1.0)
[2025-02-17 16:47:31,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:32,002][root][INFO] - Training Epoch: 1/2, step 3559/107898 completed (loss: 0.01657857745885849, acc: 1.0)
[2025-02-17 16:47:32,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:32,305][root][INFO] - Training Epoch: 1/2, step 3560/107898 completed (loss: 0.5395194888114929, acc: 0.9375)
[2025-02-17 16:47:32,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:32,605][root][INFO] - Training Epoch: 1/2, step 3561/107898 completed (loss: 0.12531809508800507, acc: 1.0)
[2025-02-17 16:47:32,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:32,932][root][INFO] - Training Epoch: 1/2, step 3562/107898 completed (loss: 1.3824316263198853, acc: 0.5)
[2025-02-17 16:47:33,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:33,233][root][INFO] - Training Epoch: 1/2, step 3563/107898 completed (loss: 0.5617168545722961, acc: 0.9375)
[2025-02-17 16:47:33,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:33,538][root][INFO] - Training Epoch: 1/2, step 3564/107898 completed (loss: 0.40634262561798096, acc: 0.8888888955116272)
[2025-02-17 16:47:33,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:33,869][root][INFO] - Training Epoch: 1/2, step 3565/107898 completed (loss: 1.4066914319992065, acc: 0.5)
[2025-02-17 16:47:33,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:34,170][root][INFO] - Training Epoch: 1/2, step 3566/107898 completed (loss: 0.19508729875087738, acc: 1.0)
[2025-02-17 16:47:34,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:34,452][root][INFO] - Training Epoch: 1/2, step 3567/107898 completed (loss: 1.860627293586731, acc: 0.7692307829856873)
[2025-02-17 16:47:34,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:34,753][root][INFO] - Training Epoch: 1/2, step 3568/107898 completed (loss: 4.5088605880737305, acc: 0.3333333432674408)
[2025-02-17 16:47:34,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:35,115][root][INFO] - Training Epoch: 1/2, step 3569/107898 completed (loss: 0.799075186252594, acc: 0.9090909361839294)
[2025-02-17 16:47:35,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:35,435][root][INFO] - Training Epoch: 1/2, step 3570/107898 completed (loss: 0.09999062865972519, acc: 1.0)
[2025-02-17 16:47:35,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:35,792][root][INFO] - Training Epoch: 1/2, step 3571/107898 completed (loss: 0.223835289478302, acc: 1.0)
[2025-02-17 16:47:35,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:36,139][root][INFO] - Training Epoch: 1/2, step 3572/107898 completed (loss: 0.41580817103385925, acc: 1.0)
[2025-02-17 16:47:36,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:36,437][root][INFO] - Training Epoch: 1/2, step 3573/107898 completed (loss: 0.26138564944267273, acc: 0.8333333134651184)
[2025-02-17 16:47:36,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:36,783][root][INFO] - Training Epoch: 1/2, step 3574/107898 completed (loss: 0.014489843510091305, acc: 1.0)
[2025-02-17 16:47:36,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:37,138][root][INFO] - Training Epoch: 1/2, step 3575/107898 completed (loss: 0.016271891072392464, acc: 1.0)
[2025-02-17 16:47:37,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:37,503][root][INFO] - Training Epoch: 1/2, step 3576/107898 completed (loss: 0.015188328921794891, acc: 1.0)
[2025-02-17 16:47:37,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:37,840][root][INFO] - Training Epoch: 1/2, step 3577/107898 completed (loss: 1.0639735460281372, acc: 0.6666666865348816)
[2025-02-17 16:47:37,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:38,195][root][INFO] - Training Epoch: 1/2, step 3578/107898 completed (loss: 1.4627195596694946, acc: 0.75)
[2025-02-17 16:47:38,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:38,527][root][INFO] - Training Epoch: 1/2, step 3579/107898 completed (loss: 0.6064649820327759, acc: 0.8999999761581421)
[2025-02-17 16:47:38,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:38,819][root][INFO] - Training Epoch: 1/2, step 3580/107898 completed (loss: 0.4643442630767822, acc: 0.75)
[2025-02-17 16:47:38,905][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:39,135][root][INFO] - Training Epoch: 1/2, step 3581/107898 completed (loss: 0.7779649496078491, acc: 0.8888888955116272)
[2025-02-17 16:47:39,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:39,467][root][INFO] - Training Epoch: 1/2, step 3582/107898 completed (loss: 1.4677637815475464, acc: 0.75)
[2025-02-17 16:47:39,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:39,832][root][INFO] - Training Epoch: 1/2, step 3583/107898 completed (loss: 3.681741237640381, acc: 0.5)
[2025-02-17 16:47:39,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:40,146][root][INFO] - Training Epoch: 1/2, step 3584/107898 completed (loss: 1.0588762760162354, acc: 0.7777777910232544)
[2025-02-17 16:47:40,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:40,508][root][INFO] - Training Epoch: 1/2, step 3585/107898 completed (loss: 4.425509929656982, acc: 0.25806450843811035)
[2025-02-17 16:47:40,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:40,808][root][INFO] - Training Epoch: 1/2, step 3586/107898 completed (loss: 0.0011054505594074726, acc: 1.0)
[2025-02-17 16:47:40,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:41,108][root][INFO] - Training Epoch: 1/2, step 3587/107898 completed (loss: 0.9335857033729553, acc: 0.8888888955116272)
[2025-02-17 16:47:41,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:41,420][root][INFO] - Training Epoch: 1/2, step 3588/107898 completed (loss: 0.23062223196029663, acc: 1.0)
[2025-02-17 16:47:41,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:41,711][root][INFO] - Training Epoch: 1/2, step 3589/107898 completed (loss: 2.38570499420166, acc: 0.5)
[2025-02-17 16:47:41,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:42,007][root][INFO] - Training Epoch: 1/2, step 3590/107898 completed (loss: 3.1744449138641357, acc: 0.2222222238779068)
[2025-02-17 16:47:42,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:42,302][root][INFO] - Training Epoch: 1/2, step 3591/107898 completed (loss: 0.1556122601032257, acc: 0.9333333373069763)
[2025-02-17 16:47:42,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:42,602][root][INFO] - Training Epoch: 1/2, step 3592/107898 completed (loss: 1.8796765804290771, acc: 0.6666666865348816)
[2025-02-17 16:47:42,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:42,901][root][INFO] - Training Epoch: 1/2, step 3593/107898 completed (loss: 0.00538713950663805, acc: 1.0)
[2025-02-17 16:47:43,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:43,222][root][INFO] - Training Epoch: 1/2, step 3594/107898 completed (loss: 0.0014796379255130887, acc: 1.0)
[2025-02-17 16:47:43,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:43,539][root][INFO] - Training Epoch: 1/2, step 3595/107898 completed (loss: 0.9270840883255005, acc: 0.75)
[2025-02-17 16:47:43,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:43,830][root][INFO] - Training Epoch: 1/2, step 3596/107898 completed (loss: 0.04766876623034477, acc: 1.0)
[2025-02-17 16:47:43,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:44,174][root][INFO] - Training Epoch: 1/2, step 3597/107898 completed (loss: 1.0176258087158203, acc: 0.800000011920929)
[2025-02-17 16:47:44,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:44,507][root][INFO] - Training Epoch: 1/2, step 3598/107898 completed (loss: 0.09193650633096695, acc: 1.0)
[2025-02-17 16:47:44,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:44,827][root][INFO] - Training Epoch: 1/2, step 3599/107898 completed (loss: 1.1532200574874878, acc: 0.7333333492279053)
[2025-02-17 16:47:44,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:45,122][root][INFO] - Training Epoch: 1/2, step 3600/107898 completed (loss: 0.50433349609375, acc: 0.8333333134651184)
[2025-02-17 16:47:45,212][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:45,440][root][INFO] - Training Epoch: 1/2, step 3601/107898 completed (loss: 0.2021501213312149, acc: 1.0)
[2025-02-17 16:47:45,509][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:45,724][root][INFO] - Training Epoch: 1/2, step 3602/107898 completed (loss: 2.773174524307251, acc: 0.523809552192688)
[2025-02-17 16:47:45,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:46,024][root][INFO] - Training Epoch: 1/2, step 3603/107898 completed (loss: 2.7999556064605713, acc: 0.6000000238418579)
[2025-02-17 16:47:46,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:46,331][root][INFO] - Training Epoch: 1/2, step 3604/107898 completed (loss: 1.5153931379318237, acc: 0.6470588445663452)
[2025-02-17 16:47:46,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:46,635][root][INFO] - Training Epoch: 1/2, step 3605/107898 completed (loss: 2.498626947402954, acc: 0.5)
[2025-02-17 16:47:46,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:46,960][root][INFO] - Training Epoch: 1/2, step 3606/107898 completed (loss: 0.6393827795982361, acc: 0.8571428656578064)
[2025-02-17 16:47:47,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:47,263][root][INFO] - Training Epoch: 1/2, step 3607/107898 completed (loss: 1.2975019216537476, acc: 0.6363636255264282)
[2025-02-17 16:47:47,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:47,572][root][INFO] - Training Epoch: 1/2, step 3608/107898 completed (loss: 1.8295390605926514, acc: 0.800000011920929)
[2025-02-17 16:47:47,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:47,928][root][INFO] - Training Epoch: 1/2, step 3609/107898 completed (loss: 1.0664722919464111, acc: 0.5)
[2025-02-17 16:47:48,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:48,250][root][INFO] - Training Epoch: 1/2, step 3610/107898 completed (loss: 0.0841418206691742, acc: 1.0)
[2025-02-17 16:47:48,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:48,569][root][INFO] - Training Epoch: 1/2, step 3611/107898 completed (loss: 0.1628781259059906, acc: 1.0)
[2025-02-17 16:47:48,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:48,921][root][INFO] - Training Epoch: 1/2, step 3612/107898 completed (loss: 0.19583652913570404, acc: 1.0)
[2025-02-17 16:47:49,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:49,250][root][INFO] - Training Epoch: 1/2, step 3613/107898 completed (loss: 0.0008318878244608641, acc: 1.0)
[2025-02-17 16:47:49,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:49,568][root][INFO] - Training Epoch: 1/2, step 3614/107898 completed (loss: 3.7731964588165283, acc: 0.4545454680919647)
[2025-02-17 16:47:49,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:49,898][root][INFO] - Training Epoch: 1/2, step 3615/107898 completed (loss: 0.7362020015716553, acc: 0.5)
[2025-02-17 16:47:49,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:50,230][root][INFO] - Training Epoch: 1/2, step 3616/107898 completed (loss: 3.4563093185424805, acc: 0.3333333432674408)
[2025-02-17 16:47:50,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:50,586][root][INFO] - Training Epoch: 1/2, step 3617/107898 completed (loss: 0.3318800926208496, acc: 0.9230769276618958)
[2025-02-17 16:47:50,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:50,892][root][INFO] - Training Epoch: 1/2, step 3618/107898 completed (loss: 0.019848331809043884, acc: 1.0)
[2025-02-17 16:47:50,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:51,197][root][INFO] - Training Epoch: 1/2, step 3619/107898 completed (loss: 2.297581911087036, acc: 0.6896551847457886)
[2025-02-17 16:47:51,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:51,511][root][INFO] - Training Epoch: 1/2, step 3620/107898 completed (loss: 0.0016372252721339464, acc: 1.0)
[2025-02-17 16:47:51,611][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:51,860][root][INFO] - Training Epoch: 1/2, step 3621/107898 completed (loss: 0.38712960481643677, acc: 1.0)
[2025-02-17 16:47:51,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:52,177][root][INFO] - Training Epoch: 1/2, step 3622/107898 completed (loss: 0.001740823034197092, acc: 1.0)
[2025-02-17 16:47:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:52,523][root][INFO] - Training Epoch: 1/2, step 3623/107898 completed (loss: 1.7445528507232666, acc: 0.5)
[2025-02-17 16:47:52,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:52,883][root][INFO] - Training Epoch: 1/2, step 3624/107898 completed (loss: 0.2029486447572708, acc: 1.0)
[2025-02-17 16:47:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:53,215][root][INFO] - Training Epoch: 1/2, step 3625/107898 completed (loss: 0.20411355793476105, acc: 1.0)
[2025-02-17 16:47:53,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:53,580][root][INFO] - Training Epoch: 1/2, step 3626/107898 completed (loss: 1.2030413150787354, acc: 0.800000011920929)
[2025-02-17 16:47:53,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:53,922][root][INFO] - Training Epoch: 1/2, step 3627/107898 completed (loss: 0.004941955674439669, acc: 1.0)
[2025-02-17 16:47:54,032][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:54,266][root][INFO] - Training Epoch: 1/2, step 3628/107898 completed (loss: 0.8075076937675476, acc: 0.8888888955116272)
[2025-02-17 16:47:54,373][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:54,598][root][INFO] - Training Epoch: 1/2, step 3629/107898 completed (loss: 1.7082403898239136, acc: 0.6428571343421936)
[2025-02-17 16:47:54,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:54,918][root][INFO] - Training Epoch: 1/2, step 3630/107898 completed (loss: 1.1872000694274902, acc: 0.7599999904632568)
[2025-02-17 16:47:55,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:55,249][root][INFO] - Training Epoch: 1/2, step 3631/107898 completed (loss: 0.7398024201393127, acc: 0.8571428656578064)
[2025-02-17 16:47:55,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:55,556][root][INFO] - Training Epoch: 1/2, step 3632/107898 completed (loss: 1.0841236114501953, acc: 0.8421052694320679)
[2025-02-17 16:47:55,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:55,886][root][INFO] - Training Epoch: 1/2, step 3633/107898 completed (loss: 0.34961459040641785, acc: 1.0)
[2025-02-17 16:47:56,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:56,308][root][INFO] - Training Epoch: 1/2, step 3634/107898 completed (loss: 1.246023416519165, acc: 0.5)
[2025-02-17 16:47:56,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:56,653][root][INFO] - Training Epoch: 1/2, step 3635/107898 completed (loss: 0.535532534122467, acc: 0.8461538553237915)
[2025-02-17 16:47:56,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:56,999][root][INFO] - Training Epoch: 1/2, step 3636/107898 completed (loss: 5.523735523223877, acc: 0.0)
[2025-02-17 16:47:57,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:57,334][root][INFO] - Training Epoch: 1/2, step 3637/107898 completed (loss: 1.2099322080612183, acc: 0.75)
[2025-02-17 16:47:57,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:57,673][root][INFO] - Training Epoch: 1/2, step 3638/107898 completed (loss: 0.026280857622623444, acc: 1.0)
[2025-02-17 16:47:57,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:57,996][root][INFO] - Training Epoch: 1/2, step 3639/107898 completed (loss: 3.413682222366333, acc: 0.4000000059604645)
[2025-02-17 16:47:58,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:58,299][root][INFO] - Training Epoch: 1/2, step 3640/107898 completed (loss: 0.36269107460975647, acc: 0.9090909361839294)
[2025-02-17 16:47:58,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:58,659][root][INFO] - Training Epoch: 1/2, step 3641/107898 completed (loss: 1.585300087928772, acc: 0.695652186870575)
[2025-02-17 16:47:58,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:59,040][root][INFO] - Training Epoch: 1/2, step 3642/107898 completed (loss: 0.0025331703945994377, acc: 1.0)
[2025-02-17 16:47:59,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:59,369][root][INFO] - Training Epoch: 1/2, step 3643/107898 completed (loss: 3.7475802898406982, acc: 0.3333333432674408)
[2025-02-17 16:47:59,456][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:47:59,687][root][INFO] - Training Epoch: 1/2, step 3644/107898 completed (loss: 0.6365748643875122, acc: 0.875)
[2025-02-17 16:47:59,772][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:00,010][root][INFO] - Training Epoch: 1/2, step 3645/107898 completed (loss: 0.20940285921096802, acc: 1.0)
[2025-02-17 16:48:00,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:00,372][root][INFO] - Training Epoch: 1/2, step 3646/107898 completed (loss: 1.0425102710723877, acc: 0.8461538553237915)
[2025-02-17 16:48:00,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:00,695][root][INFO] - Training Epoch: 1/2, step 3647/107898 completed (loss: 0.7892256379127502, acc: 0.8823529481887817)
[2025-02-17 16:48:00,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:01,032][root][INFO] - Training Epoch: 1/2, step 3648/107898 completed (loss: 2.5877668857574463, acc: 0.6363636255264282)
[2025-02-17 16:48:01,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:01,362][root][INFO] - Training Epoch: 1/2, step 3649/107898 completed (loss: 1.337577223777771, acc: 0.8333333134651184)
[2025-02-17 16:48:01,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:01,689][root][INFO] - Training Epoch: 1/2, step 3650/107898 completed (loss: 0.45676231384277344, acc: 1.0)
[2025-02-17 16:48:01,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:02,031][root][INFO] - Training Epoch: 1/2, step 3651/107898 completed (loss: 0.00345572829246521, acc: 1.0)
[2025-02-17 16:48:02,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:02,387][root][INFO] - Training Epoch: 1/2, step 3652/107898 completed (loss: 0.03443941846489906, acc: 1.0)
[2025-02-17 16:48:02,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:02,711][root][INFO] - Training Epoch: 1/2, step 3653/107898 completed (loss: 1.5084919929504395, acc: 0.6666666865348816)
[2025-02-17 16:48:02,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:03,074][root][INFO] - Training Epoch: 1/2, step 3654/107898 completed (loss: 1.4795045852661133, acc: 0.7058823704719543)
[2025-02-17 16:48:03,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:03,384][root][INFO] - Training Epoch: 1/2, step 3655/107898 completed (loss: 0.37721672654151917, acc: 0.9047619104385376)
[2025-02-17 16:48:03,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:03,711][root][INFO] - Training Epoch: 1/2, step 3656/107898 completed (loss: 1.1999377012252808, acc: 0.8571428656578064)
[2025-02-17 16:48:03,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:04,058][root][INFO] - Training Epoch: 1/2, step 3657/107898 completed (loss: 3.2671053409576416, acc: 0.3571428656578064)
[2025-02-17 16:48:04,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:04,415][root][INFO] - Training Epoch: 1/2, step 3658/107898 completed (loss: 2.291191577911377, acc: 0.5714285969734192)
[2025-02-17 16:48:04,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:04,761][root][INFO] - Training Epoch: 1/2, step 3659/107898 completed (loss: 0.40871700644493103, acc: 0.8823529481887817)
[2025-02-17 16:48:04,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:05,057][root][INFO] - Training Epoch: 1/2, step 3660/107898 completed (loss: 0.08957462757825851, acc: 1.0)
[2025-02-17 16:48:05,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:05,362][root][INFO] - Training Epoch: 1/2, step 3661/107898 completed (loss: 0.8654913306236267, acc: 0.7272727489471436)
[2025-02-17 16:48:05,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:05,686][root][INFO] - Training Epoch: 1/2, step 3662/107898 completed (loss: 2.072601556777954, acc: 0.5)
[2025-02-17 16:48:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:06,020][root][INFO] - Training Epoch: 1/2, step 3663/107898 completed (loss: 1.2654592990875244, acc: 0.75)
[2025-02-17 16:48:06,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:06,341][root][INFO] - Training Epoch: 1/2, step 3664/107898 completed (loss: 1.8721833229064941, acc: 0.692307710647583)
[2025-02-17 16:48:06,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:06,666][root][INFO] - Training Epoch: 1/2, step 3665/107898 completed (loss: 0.7499450445175171, acc: 0.8571428656578064)
[2025-02-17 16:48:06,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:07,079][root][INFO] - Training Epoch: 1/2, step 3666/107898 completed (loss: 3.0668532848358154, acc: 0.3214285671710968)
[2025-02-17 16:48:07,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:07,360][root][INFO] - Training Epoch: 1/2, step 3667/107898 completed (loss: 0.34498870372772217, acc: 1.0)
[2025-02-17 16:48:07,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:07,696][root][INFO] - Training Epoch: 1/2, step 3668/107898 completed (loss: 1.0626561641693115, acc: 0.807692289352417)
[2025-02-17 16:48:07,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:08,037][root][INFO] - Training Epoch: 1/2, step 3669/107898 completed (loss: 0.16490937769412994, acc: 1.0)
[2025-02-17 16:48:08,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:08,399][root][INFO] - Training Epoch: 1/2, step 3670/107898 completed (loss: 3.6140172481536865, acc: 0.37037035822868347)
[2025-02-17 16:48:08,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:08,706][root][INFO] - Training Epoch: 1/2, step 3671/107898 completed (loss: 0.06860575824975967, acc: 1.0)
[2025-02-17 16:48:08,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:09,051][root][INFO] - Training Epoch: 1/2, step 3672/107898 completed (loss: 1.9862182140350342, acc: 0.4285714328289032)
[2025-02-17 16:48:09,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:09,377][root][INFO] - Training Epoch: 1/2, step 3673/107898 completed (loss: 3.9635868072509766, acc: 0.2857142984867096)
[2025-02-17 16:48:09,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:09,710][root][INFO] - Training Epoch: 1/2, step 3674/107898 completed (loss: 1.5406438112258911, acc: 0.699999988079071)
[2025-02-17 16:48:09,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:10,016][root][INFO] - Training Epoch: 1/2, step 3675/107898 completed (loss: 2.7966835498809814, acc: 0.3333333432674408)
[2025-02-17 16:48:10,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:10,355][root][INFO] - Training Epoch: 1/2, step 3676/107898 completed (loss: 2.096571445465088, acc: 0.7307692170143127)
[2025-02-17 16:48:10,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:10,656][root][INFO] - Training Epoch: 1/2, step 3677/107898 completed (loss: 0.010083718225359917, acc: 1.0)
[2025-02-17 16:48:10,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:11,021][root][INFO] - Training Epoch: 1/2, step 3678/107898 completed (loss: 0.8662756085395813, acc: 0.75)
[2025-02-17 16:48:11,104][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:11,326][root][INFO] - Training Epoch: 1/2, step 3679/107898 completed (loss: 1.368323802947998, acc: 0.9166666865348816)
[2025-02-17 16:48:11,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:11,640][root][INFO] - Training Epoch: 1/2, step 3680/107898 completed (loss: 0.42726942896842957, acc: 0.75)
[2025-02-17 16:48:11,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:11,982][root][INFO] - Training Epoch: 1/2, step 3681/107898 completed (loss: 1.2649239301681519, acc: 0.6666666865348816)
[2025-02-17 16:48:12,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:12,326][root][INFO] - Training Epoch: 1/2, step 3682/107898 completed (loss: 2.314342975616455, acc: 0.5)
[2025-02-17 16:48:12,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:12,632][root][INFO] - Training Epoch: 1/2, step 3683/107898 completed (loss: 0.8373262286186218, acc: 0.6666666865348816)
[2025-02-17 16:48:12,757][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:12,989][root][INFO] - Training Epoch: 1/2, step 3684/107898 completed (loss: 1.3252520561218262, acc: 0.8333333134651184)
[2025-02-17 16:48:13,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:13,320][root][INFO] - Training Epoch: 1/2, step 3685/107898 completed (loss: 4.02333927154541, acc: 0.4444444477558136)
[2025-02-17 16:48:13,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:13,618][root][INFO] - Training Epoch: 1/2, step 3686/107898 completed (loss: 0.11943985521793365, acc: 1.0)
[2025-02-17 16:48:13,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:13,918][root][INFO] - Training Epoch: 1/2, step 3687/107898 completed (loss: 1.0084832906723022, acc: 0.6666666865348816)
[2025-02-17 16:48:13,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:14,225][root][INFO] - Training Epoch: 1/2, step 3688/107898 completed (loss: 0.012348553165793419, acc: 1.0)
[2025-02-17 16:48:14,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:14,526][root][INFO] - Training Epoch: 1/2, step 3689/107898 completed (loss: 1.4988257884979248, acc: 0.75)
[2025-02-17 16:48:14,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:14,832][root][INFO] - Training Epoch: 1/2, step 3690/107898 completed (loss: 0.6573081612586975, acc: 0.8421052694320679)
[2025-02-17 16:48:14,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:15,127][root][INFO] - Training Epoch: 1/2, step 3691/107898 completed (loss: 0.0025757593102753162, acc: 1.0)
[2025-02-17 16:48:15,206][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:15,431][root][INFO] - Training Epoch: 1/2, step 3692/107898 completed (loss: 0.6673089265823364, acc: 0.800000011920929)
[2025-02-17 16:48:15,511][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:15,740][root][INFO] - Training Epoch: 1/2, step 3693/107898 completed (loss: 1.6366122961044312, acc: 0.6000000238418579)
[2025-02-17 16:48:15,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:16,062][root][INFO] - Training Epoch: 1/2, step 3694/107898 completed (loss: 0.984139084815979, acc: 0.699999988079071)
[2025-02-17 16:48:16,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:16,419][root][INFO] - Training Epoch: 1/2, step 3695/107898 completed (loss: 0.01341999601572752, acc: 1.0)
[2025-02-17 16:48:16,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:16,726][root][INFO] - Training Epoch: 1/2, step 3696/107898 completed (loss: 3.097839117050171, acc: 0.25)
[2025-02-17 16:48:16,816][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:17,036][root][INFO] - Training Epoch: 1/2, step 3697/107898 completed (loss: 0.20221376419067383, acc: 1.0)
[2025-02-17 16:48:17,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:17,340][root][INFO] - Training Epoch: 1/2, step 3698/107898 completed (loss: 0.19458362460136414, acc: 1.0)
[2025-02-17 16:48:17,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:17,652][root][INFO] - Training Epoch: 1/2, step 3699/107898 completed (loss: 0.3563048243522644, acc: 0.949999988079071)
[2025-02-17 16:48:17,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:18,017][root][INFO] - Training Epoch: 1/2, step 3700/107898 completed (loss: 1.279823660850525, acc: 0.7142857313156128)
[2025-02-17 16:48:18,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:18,361][root][INFO] - Training Epoch: 1/2, step 3701/107898 completed (loss: 0.005907592363655567, acc: 1.0)
[2025-02-17 16:48:18,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:18,698][root][INFO] - Training Epoch: 1/2, step 3702/107898 completed (loss: 3.8549270629882812, acc: 0.4285714328289032)
[2025-02-17 16:48:18,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:19,041][root][INFO] - Training Epoch: 1/2, step 3703/107898 completed (loss: 0.35367557406425476, acc: 0.8333333134651184)
[2025-02-17 16:48:19,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:19,354][root][INFO] - Training Epoch: 1/2, step 3704/107898 completed (loss: 0.8127036690711975, acc: 0.6666666865348816)
[2025-02-17 16:48:19,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:19,688][root][INFO] - Training Epoch: 1/2, step 3705/107898 completed (loss: 0.6266179084777832, acc: 0.5)
[2025-02-17 16:48:19,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:20,060][root][INFO] - Training Epoch: 1/2, step 3706/107898 completed (loss: 0.05662056431174278, acc: 1.0)
[2025-02-17 16:48:20,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:20,417][root][INFO] - Training Epoch: 1/2, step 3707/107898 completed (loss: 0.3153964877128601, acc: 0.9599999785423279)
[2025-02-17 16:48:20,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:20,733][root][INFO] - Training Epoch: 1/2, step 3708/107898 completed (loss: 0.9487511515617371, acc: 0.6666666865348816)
[2025-02-17 16:48:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:21,044][root][INFO] - Training Epoch: 1/2, step 3709/107898 completed (loss: 0.0021741169039160013, acc: 1.0)
[2025-02-17 16:48:21,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:21,360][root][INFO] - Training Epoch: 1/2, step 3710/107898 completed (loss: 1.19758141040802, acc: 0.7692307829856873)
[2025-02-17 16:48:21,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:21,680][root][INFO] - Training Epoch: 1/2, step 3711/107898 completed (loss: 0.10324486345052719, acc: 1.0)
[2025-02-17 16:48:21,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:22,038][root][INFO] - Training Epoch: 1/2, step 3712/107898 completed (loss: 0.003767177928239107, acc: 1.0)
[2025-02-17 16:48:22,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:22,414][root][INFO] - Training Epoch: 1/2, step 3713/107898 completed (loss: 1.081900715827942, acc: 0.5)
[2025-02-17 16:48:22,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:22,782][root][INFO] - Training Epoch: 1/2, step 3714/107898 completed (loss: 0.6176285743713379, acc: 0.8888888955116272)
[2025-02-17 16:48:22,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:23,108][root][INFO] - Training Epoch: 1/2, step 3715/107898 completed (loss: 0.8358045220375061, acc: 0.8461538553237915)
[2025-02-17 16:48:23,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:23,462][root][INFO] - Training Epoch: 1/2, step 3716/107898 completed (loss: 0.7139148712158203, acc: 0.5)
[2025-02-17 16:48:23,569][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:23,804][root][INFO] - Training Epoch: 1/2, step 3717/107898 completed (loss: 1.338741660118103, acc: 0.7272727489471436)
[2025-02-17 16:48:23,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:24,121][root][INFO] - Training Epoch: 1/2, step 3718/107898 completed (loss: 0.027790864929556847, acc: 1.0)
[2025-02-17 16:48:24,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:24,464][root][INFO] - Training Epoch: 1/2, step 3719/107898 completed (loss: 4.437557697296143, acc: 0.20000000298023224)
[2025-02-17 16:48:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:24,781][root][INFO] - Training Epoch: 1/2, step 3720/107898 completed (loss: 0.3866289258003235, acc: 1.0)
[2025-02-17 16:48:24,863][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:25,091][root][INFO] - Training Epoch: 1/2, step 3721/107898 completed (loss: 0.6351178884506226, acc: 0.8461538553237915)
[2025-02-17 16:48:25,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:25,426][root][INFO] - Training Epoch: 1/2, step 3722/107898 completed (loss: 0.04569148272275925, acc: 1.0)
[2025-02-17 16:48:25,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:25,738][root][INFO] - Training Epoch: 1/2, step 3723/107898 completed (loss: 0.004375540651381016, acc: 1.0)
[2025-02-17 16:48:25,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:26,038][root][INFO] - Training Epoch: 1/2, step 3724/107898 completed (loss: 0.23753778636455536, acc: 1.0)
[2025-02-17 16:48:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:26,358][root][INFO] - Training Epoch: 1/2, step 3725/107898 completed (loss: 0.9951023459434509, acc: 0.75)
[2025-02-17 16:48:26,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:26,673][root][INFO] - Training Epoch: 1/2, step 3726/107898 completed (loss: 0.6372394561767578, acc: 0.8275862336158752)
[2025-02-17 16:48:26,751][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:26,973][root][INFO] - Training Epoch: 1/2, step 3727/107898 completed (loss: 2.2365894317626953, acc: 0.5714285969734192)
[2025-02-17 16:48:27,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:27,277][root][INFO] - Training Epoch: 1/2, step 3728/107898 completed (loss: 2.166224241256714, acc: 0.5)
[2025-02-17 16:48:27,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:27,567][root][INFO] - Training Epoch: 1/2, step 3729/107898 completed (loss: 0.00811844039708376, acc: 1.0)
[2025-02-17 16:48:27,660][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:27,889][root][INFO] - Training Epoch: 1/2, step 3730/107898 completed (loss: 2.5474727153778076, acc: 0.625)
[2025-02-17 16:48:27,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:28,215][root][INFO] - Training Epoch: 1/2, step 3731/107898 completed (loss: 1.0238473415374756, acc: 0.8181818127632141)
[2025-02-17 16:48:28,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:28,548][root][INFO] - Training Epoch: 1/2, step 3732/107898 completed (loss: 4.192978382110596, acc: 0.3333333432674408)
[2025-02-17 16:48:28,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:28,872][root][INFO] - Training Epoch: 1/2, step 3733/107898 completed (loss: 1.054416537284851, acc: 0.7272727489471436)
[2025-02-17 16:48:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:29,166][root][INFO] - Training Epoch: 1/2, step 3734/107898 completed (loss: 0.10777673125267029, acc: 1.0)
[2025-02-17 16:48:29,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:29,468][root][INFO] - Training Epoch: 1/2, step 3735/107898 completed (loss: 3.65279221534729, acc: 0.20000000298023224)
[2025-02-17 16:48:29,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:29,770][root][INFO] - Training Epoch: 1/2, step 3736/107898 completed (loss: 0.6061103343963623, acc: 0.800000011920929)
[2025-02-17 16:48:29,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:30,041][root][INFO] - Training Epoch: 1/2, step 3737/107898 completed (loss: 0.3004492521286011, acc: 0.8888888955116272)
[2025-02-17 16:48:30,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:30,369][root][INFO] - Training Epoch: 1/2, step 3738/107898 completed (loss: 1.6434249877929688, acc: 0.5555555820465088)
[2025-02-17 16:48:30,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:30,665][root][INFO] - Training Epoch: 1/2, step 3739/107898 completed (loss: 0.9339038133621216, acc: 0.75)
[2025-02-17 16:48:30,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:30,978][root][INFO] - Training Epoch: 1/2, step 3740/107898 completed (loss: 0.015270091593265533, acc: 1.0)
[2025-02-17 16:48:31,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:31,317][root][INFO] - Training Epoch: 1/2, step 3741/107898 completed (loss: 0.03698035702109337, acc: 1.0)
[2025-02-17 16:48:31,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:31,627][root][INFO] - Training Epoch: 1/2, step 3742/107898 completed (loss: 1.3404382467269897, acc: 0.692307710647583)
[2025-02-17 16:48:31,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:31,936][root][INFO] - Training Epoch: 1/2, step 3743/107898 completed (loss: 0.09074118733406067, acc: 1.0)
[2025-02-17 16:48:32,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:32,233][root][INFO] - Training Epoch: 1/2, step 3744/107898 completed (loss: 1.1418194770812988, acc: 0.8999999761581421)
[2025-02-17 16:48:32,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:32,534][root][INFO] - Training Epoch: 1/2, step 3745/107898 completed (loss: 0.7517722249031067, acc: 0.8571428656578064)
[2025-02-17 16:48:32,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:32,823][root][INFO] - Training Epoch: 1/2, step 3746/107898 completed (loss: 0.465319961309433, acc: 1.0)
[2025-02-17 16:48:32,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:33,134][root][INFO] - Training Epoch: 1/2, step 3747/107898 completed (loss: 0.2932579815387726, acc: 0.9166666865348816)
[2025-02-17 16:48:33,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:33,414][root][INFO] - Training Epoch: 1/2, step 3748/107898 completed (loss: 0.8229984045028687, acc: 0.75)
[2025-02-17 16:48:33,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:33,719][root][INFO] - Training Epoch: 1/2, step 3749/107898 completed (loss: 2.7843527793884277, acc: 0.5454545617103577)
[2025-02-17 16:48:33,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:34,055][root][INFO] - Training Epoch: 1/2, step 3750/107898 completed (loss: 0.8414192795753479, acc: 0.8148148059844971)
[2025-02-17 16:48:34,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:34,406][root][INFO] - Training Epoch: 1/2, step 3751/107898 completed (loss: 1.9046939611434937, acc: 0.5)
[2025-02-17 16:48:34,499][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:34,730][root][INFO] - Training Epoch: 1/2, step 3752/107898 completed (loss: 1.2412468194961548, acc: 0.8333333134651184)
[2025-02-17 16:48:34,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:35,052][root][INFO] - Training Epoch: 1/2, step 3753/107898 completed (loss: 0.2456173449754715, acc: 1.0)
[2025-02-17 16:48:35,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:35,381][root][INFO] - Training Epoch: 1/2, step 3754/107898 completed (loss: 0.6448649168014526, acc: 0.8461538553237915)
[2025-02-17 16:48:35,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:35,690][root][INFO] - Training Epoch: 1/2, step 3755/107898 completed (loss: 0.006985036190599203, acc: 1.0)
[2025-02-17 16:48:35,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:36,073][root][INFO] - Training Epoch: 1/2, step 3756/107898 completed (loss: 1.6057155132293701, acc: 0.7272727489471436)
[2025-02-17 16:48:36,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:36,406][root][INFO] - Training Epoch: 1/2, step 3757/107898 completed (loss: 1.1368573904037476, acc: 0.7058823704719543)
[2025-02-17 16:48:36,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:36,776][root][INFO] - Training Epoch: 1/2, step 3758/107898 completed (loss: 1.251236081123352, acc: 0.7058823704719543)
[2025-02-17 16:48:36,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:37,177][root][INFO] - Training Epoch: 1/2, step 3759/107898 completed (loss: 2.2031893730163574, acc: 0.4444444477558136)
[2025-02-17 16:48:37,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:37,522][root][INFO] - Training Epoch: 1/2, step 3760/107898 completed (loss: 0.4088401198387146, acc: 1.0)
[2025-02-17 16:48:37,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:37,830][root][INFO] - Training Epoch: 1/2, step 3761/107898 completed (loss: 1.5439289808273315, acc: 0.7272727489471436)
[2025-02-17 16:48:37,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:38,147][root][INFO] - Training Epoch: 1/2, step 3762/107898 completed (loss: 1.5068892240524292, acc: 0.800000011920929)
[2025-02-17 16:48:38,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:38,439][root][INFO] - Training Epoch: 1/2, step 3763/107898 completed (loss: 0.8351659774780273, acc: 0.5)
[2025-02-17 16:48:38,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:38,791][root][INFO] - Training Epoch: 1/2, step 3764/107898 completed (loss: 1.35086190700531, acc: 0.75)
[2025-02-17 16:48:38,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:39,102][root][INFO] - Training Epoch: 1/2, step 3765/107898 completed (loss: 0.6852558255195618, acc: 0.8787878751754761)
[2025-02-17 16:48:39,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:39,402][root][INFO] - Training Epoch: 1/2, step 3766/107898 completed (loss: 4.103950500488281, acc: 0.21052631735801697)
[2025-02-17 16:48:39,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:39,707][root][INFO] - Training Epoch: 1/2, step 3767/107898 completed (loss: 0.00031214632326737046, acc: 1.0)
[2025-02-17 16:48:39,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:40,070][root][INFO] - Training Epoch: 1/2, step 3768/107898 completed (loss: 0.08561291545629501, acc: 1.0)
[2025-02-17 16:48:40,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:40,347][root][INFO] - Training Epoch: 1/2, step 3769/107898 completed (loss: 0.0006917676073499024, acc: 1.0)
[2025-02-17 16:48:40,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:40,666][root][INFO] - Training Epoch: 1/2, step 3770/107898 completed (loss: 3.751185178756714, acc: 0.4000000059604645)
[2025-02-17 16:48:40,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:41,006][root][INFO] - Training Epoch: 1/2, step 3771/107898 completed (loss: 1.1807712316513062, acc: 0.739130437374115)
[2025-02-17 16:48:41,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:41,330][root][INFO] - Training Epoch: 1/2, step 3772/107898 completed (loss: 0.7822458148002625, acc: 0.7727272510528564)
[2025-02-17 16:48:41,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:41,679][root][INFO] - Training Epoch: 1/2, step 3773/107898 completed (loss: 0.8980893492698669, acc: 0.8181818127632141)
[2025-02-17 16:48:41,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:42,008][root][INFO] - Training Epoch: 1/2, step 3774/107898 completed (loss: 0.5581417679786682, acc: 0.9545454382896423)
[2025-02-17 16:48:42,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:42,330][root][INFO] - Training Epoch: 1/2, step 3775/107898 completed (loss: 1.0463950634002686, acc: 0.7692307829856873)
[2025-02-17 16:48:42,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:42,635][root][INFO] - Training Epoch: 1/2, step 3776/107898 completed (loss: 3.754978895187378, acc: 0.3636363744735718)
[2025-02-17 16:48:42,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:42,933][root][INFO] - Training Epoch: 1/2, step 3777/107898 completed (loss: 0.0014936442021280527, acc: 1.0)
[2025-02-17 16:48:43,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:43,222][root][INFO] - Training Epoch: 1/2, step 3778/107898 completed (loss: 4.494561195373535, acc: 0.5)
[2025-02-17 16:48:43,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:43,560][root][INFO] - Training Epoch: 1/2, step 3779/107898 completed (loss: 0.16984514892101288, acc: 1.0)
[2025-02-17 16:48:43,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:43,888][root][INFO] - Training Epoch: 1/2, step 3780/107898 completed (loss: 0.0004818465677089989, acc: 1.0)
[2025-02-17 16:48:43,977][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:44,211][root][INFO] - Training Epoch: 1/2, step 3781/107898 completed (loss: 0.7646306753158569, acc: 0.7857142686843872)
[2025-02-17 16:48:44,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:44,547][root][INFO] - Training Epoch: 1/2, step 3782/107898 completed (loss: 0.35011300444602966, acc: 1.0)
[2025-02-17 16:48:44,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:44,900][root][INFO] - Training Epoch: 1/2, step 3783/107898 completed (loss: 0.0008592489175498486, acc: 1.0)
[2025-02-17 16:48:45,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:45,233][root][INFO] - Training Epoch: 1/2, step 3784/107898 completed (loss: 0.6750710010528564, acc: 0.84375)
[2025-02-17 16:48:45,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:45,539][root][INFO] - Training Epoch: 1/2, step 3785/107898 completed (loss: 0.0026248455978929996, acc: 1.0)
[2025-02-17 16:48:45,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:45,846][root][INFO] - Training Epoch: 1/2, step 3786/107898 completed (loss: 0.005748288705945015, acc: 1.0)
[2025-02-17 16:48:45,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:46,162][root][INFO] - Training Epoch: 1/2, step 3787/107898 completed (loss: 1.3947008848190308, acc: 0.875)
[2025-02-17 16:48:46,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:46,480][root][INFO] - Training Epoch: 1/2, step 3788/107898 completed (loss: 1.9610334634780884, acc: 0.6428571343421936)
[2025-02-17 16:48:46,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:46,779][root][INFO] - Training Epoch: 1/2, step 3789/107898 completed (loss: 0.4721917510032654, acc: 1.0)
[2025-02-17 16:48:46,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:47,105][root][INFO] - Training Epoch: 1/2, step 3790/107898 completed (loss: 1.409411072731018, acc: 0.6666666865348816)
[2025-02-17 16:48:47,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:47,455][root][INFO] - Training Epoch: 1/2, step 3791/107898 completed (loss: 0.09001725167036057, acc: 1.0)
[2025-02-17 16:48:47,570][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:47,811][root][INFO] - Training Epoch: 1/2, step 3792/107898 completed (loss: 3.6206142902374268, acc: 0.3333333432674408)
[2025-02-17 16:48:47,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:48,164][root][INFO] - Training Epoch: 1/2, step 3793/107898 completed (loss: 0.9616473913192749, acc: 0.75)
[2025-02-17 16:48:48,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:48,523][root][INFO] - Training Epoch: 1/2, step 3794/107898 completed (loss: 0.3176097571849823, acc: 0.8333333134651184)
[2025-02-17 16:48:48,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:48,866][root][INFO] - Training Epoch: 1/2, step 3795/107898 completed (loss: 0.2908855378627777, acc: 0.9411764740943909)
[2025-02-17 16:48:48,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:49,213][root][INFO] - Training Epoch: 1/2, step 3796/107898 completed (loss: 2.791027307510376, acc: 0.4615384638309479)
[2025-02-17 16:48:49,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:49,538][root][INFO] - Training Epoch: 1/2, step 3797/107898 completed (loss: 1.3863240480422974, acc: 0.6666666865348816)
[2025-02-17 16:48:49,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:49,899][root][INFO] - Training Epoch: 1/2, step 3798/107898 completed (loss: 1.8907777070999146, acc: 0.6666666865348816)
[2025-02-17 16:48:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:50,257][root][INFO] - Training Epoch: 1/2, step 3799/107898 completed (loss: 0.2394857555627823, acc: 0.6666666865348816)
[2025-02-17 16:48:50,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:50,618][root][INFO] - Training Epoch: 1/2, step 3800/107898 completed (loss: 1.4535003900527954, acc: 0.6764705777168274)
[2025-02-17 16:48:50,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:50,931][root][INFO] - Training Epoch: 1/2, step 3801/107898 completed (loss: 5.010425567626953, acc: 0.20000000298023224)
[2025-02-17 16:48:51,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:51,234][root][INFO] - Training Epoch: 1/2, step 3802/107898 completed (loss: 0.0021883866284042597, acc: 1.0)
[2025-02-17 16:48:51,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:51,549][root][INFO] - Training Epoch: 1/2, step 3803/107898 completed (loss: 1.5707945823669434, acc: 0.6666666865348816)
[2025-02-17 16:48:51,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:51,881][root][INFO] - Training Epoch: 1/2, step 3804/107898 completed (loss: 2.8612687587738037, acc: 0.4583333432674408)
[2025-02-17 16:48:51,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:52,188][root][INFO] - Training Epoch: 1/2, step 3805/107898 completed (loss: 0.7060473561286926, acc: 0.8095238208770752)
[2025-02-17 16:48:52,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:52,487][root][INFO] - Training Epoch: 1/2, step 3806/107898 completed (loss: 1.640769600868225, acc: 0.71875)
[2025-02-17 16:48:52,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:52,783][root][INFO] - Training Epoch: 1/2, step 3807/107898 completed (loss: 3.2064626216888428, acc: 0.6666666865348816)
[2025-02-17 16:48:52,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:53,093][root][INFO] - Training Epoch: 1/2, step 3808/107898 completed (loss: 0.9410923719406128, acc: 0.7777777910232544)
[2025-02-17 16:48:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:53,385][root][INFO] - Training Epoch: 1/2, step 3809/107898 completed (loss: 2.83455491065979, acc: 0.3333333432674408)
[2025-02-17 16:48:53,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:53,706][root][INFO] - Training Epoch: 1/2, step 3810/107898 completed (loss: 4.325449466705322, acc: 0.2666666805744171)
[2025-02-17 16:48:53,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:54,088][root][INFO] - Training Epoch: 1/2, step 3811/107898 completed (loss: 0.7529774904251099, acc: 0.8536585569381714)
[2025-02-17 16:48:54,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:54,448][root][INFO] - Training Epoch: 1/2, step 3812/107898 completed (loss: 0.5115424394607544, acc: 0.9444444179534912)
[2025-02-17 16:48:54,545][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:54,831][root][INFO] - Training Epoch: 1/2, step 3813/107898 completed (loss: 0.3009193539619446, acc: 0.9375)
[2025-02-17 16:48:54,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:55,194][root][INFO] - Training Epoch: 1/2, step 3814/107898 completed (loss: 1.2059736251831055, acc: 0.782608687877655)
[2025-02-17 16:48:55,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:55,511][root][INFO] - Training Epoch: 1/2, step 3815/107898 completed (loss: 1.9707087278366089, acc: 0.3333333432674408)
[2025-02-17 16:48:55,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:55,855][root][INFO] - Training Epoch: 1/2, step 3816/107898 completed (loss: 1.4305534362792969, acc: 0.692307710647583)
[2025-02-17 16:48:55,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:56,171][root][INFO] - Training Epoch: 1/2, step 3817/107898 completed (loss: 0.24453529715538025, acc: 1.0)
[2025-02-17 16:48:56,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:56,491][root][INFO] - Training Epoch: 1/2, step 3818/107898 completed (loss: 0.1168210357427597, acc: 0.9473684430122375)
[2025-02-17 16:48:56,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:56,796][root][INFO] - Training Epoch: 1/2, step 3819/107898 completed (loss: 4.603302001953125, acc: 0.0)
[2025-02-17 16:48:56,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:57,100][root][INFO] - Training Epoch: 1/2, step 3820/107898 completed (loss: 1.67685866355896, acc: 0.6153846383094788)
[2025-02-17 16:48:57,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:57,431][root][INFO] - Training Epoch: 1/2, step 3821/107898 completed (loss: 3.8894903659820557, acc: 0.3125)
[2025-02-17 16:48:57,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:57,756][root][INFO] - Training Epoch: 1/2, step 3822/107898 completed (loss: 0.016161184757947922, acc: 1.0)
[2025-02-17 16:48:57,839][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:58,056][root][INFO] - Training Epoch: 1/2, step 3823/107898 completed (loss: 0.32793718576431274, acc: 1.0)
[2025-02-17 16:48:58,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:58,357][root][INFO] - Training Epoch: 1/2, step 3824/107898 completed (loss: 0.011697929352521896, acc: 1.0)
[2025-02-17 16:48:58,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:58,701][root][INFO] - Training Epoch: 1/2, step 3825/107898 completed (loss: 0.2711186110973358, acc: 0.9354838728904724)
[2025-02-17 16:48:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:59,000][root][INFO] - Training Epoch: 1/2, step 3826/107898 completed (loss: 1.0546677112579346, acc: 0.0)
[2025-02-17 16:48:59,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:59,350][root][INFO] - Training Epoch: 1/2, step 3827/107898 completed (loss: 0.7575264573097229, acc: 0.0)
[2025-02-17 16:48:59,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:59,661][root][INFO] - Training Epoch: 1/2, step 3828/107898 completed (loss: 1.0732094049453735, acc: 0.7647058963775635)
[2025-02-17 16:48:59,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:48:59,976][root][INFO] - Training Epoch: 1/2, step 3829/107898 completed (loss: 0.6215869188308716, acc: 0.8999999761581421)
[2025-02-17 16:49:00,086][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:00,324][root][INFO] - Training Epoch: 1/2, step 3830/107898 completed (loss: 0.15288029611110687, acc: 1.0)
[2025-02-17 16:49:00,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:00,691][root][INFO] - Training Epoch: 1/2, step 3831/107898 completed (loss: 1.3242698907852173, acc: 0.7777777910232544)
[2025-02-17 16:49:00,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:01,049][root][INFO] - Training Epoch: 1/2, step 3832/107898 completed (loss: 2.536409854888916, acc: 0.2857142984867096)
[2025-02-17 16:49:01,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:01,399][root][INFO] - Training Epoch: 1/2, step 3833/107898 completed (loss: 1.8238531351089478, acc: 0.6785714030265808)
[2025-02-17 16:49:01,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:01,741][root][INFO] - Training Epoch: 1/2, step 3834/107898 completed (loss: 4.062968730926514, acc: 0.3333333432674408)
[2025-02-17 16:49:01,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:02,034][root][INFO] - Training Epoch: 1/2, step 3835/107898 completed (loss: 0.0018549608066678047, acc: 1.0)
[2025-02-17 16:49:02,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:02,327][root][INFO] - Training Epoch: 1/2, step 3836/107898 completed (loss: 1.2697161436080933, acc: 0.6499999761581421)
[2025-02-17 16:49:02,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:02,623][root][INFO] - Training Epoch: 1/2, step 3837/107898 completed (loss: 0.024267634376883507, acc: 1.0)
[2025-02-17 16:49:02,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:02,975][root][INFO] - Training Epoch: 1/2, step 3838/107898 completed (loss: 0.030041325837373734, acc: 1.0)
[2025-02-17 16:49:03,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:03,300][root][INFO] - Training Epoch: 1/2, step 3839/107898 completed (loss: 1.2691174745559692, acc: 0.5)
[2025-02-17 16:49:03,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:03,623][root][INFO] - Training Epoch: 1/2, step 3840/107898 completed (loss: 1.1996711492538452, acc: 0.6666666865348816)
[2025-02-17 16:49:03,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:03,924][root][INFO] - Training Epoch: 1/2, step 3841/107898 completed (loss: 0.055018991231918335, acc: 1.0)
[2025-02-17 16:49:04,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:04,237][root][INFO] - Training Epoch: 1/2, step 3842/107898 completed (loss: 0.6120563745498657, acc: 0.5)
[2025-02-17 16:49:04,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:04,548][root][INFO] - Training Epoch: 1/2, step 3843/107898 completed (loss: 2.5817320346832275, acc: 0.6666666865348816)
[2025-02-17 16:49:04,635][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:04,854][root][INFO] - Training Epoch: 1/2, step 3844/107898 completed (loss: 0.021476801484823227, acc: 1.0)
[2025-02-17 16:49:04,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:05,167][root][INFO] - Training Epoch: 1/2, step 3845/107898 completed (loss: 1.0295964479446411, acc: 0.739130437374115)
[2025-02-17 16:49:05,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:05,513][root][INFO] - Training Epoch: 1/2, step 3846/107898 completed (loss: 3.466094970703125, acc: 0.2142857164144516)
[2025-02-17 16:49:05,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:05,842][root][INFO] - Training Epoch: 1/2, step 3847/107898 completed (loss: 0.5871415138244629, acc: 0.9047619104385376)
[2025-02-17 16:49:05,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:06,139][root][INFO] - Training Epoch: 1/2, step 3848/107898 completed (loss: 1.7389994859695435, acc: 0.8333333134651184)
[2025-02-17 16:49:06,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:06,428][root][INFO] - Training Epoch: 1/2, step 3849/107898 completed (loss: 1.1580702066421509, acc: 0.7647058963775635)
[2025-02-17 16:49:06,509][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:06,724][root][INFO] - Training Epoch: 1/2, step 3850/107898 completed (loss: 2.5390591621398926, acc: 0.75)
[2025-02-17 16:49:06,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:07,025][root][INFO] - Training Epoch: 1/2, step 3851/107898 completed (loss: 1.4863895177841187, acc: 0.75)
[2025-02-17 16:49:07,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:07,334][root][INFO] - Training Epoch: 1/2, step 3852/107898 completed (loss: 0.01923113316297531, acc: 1.0)
[2025-02-17 16:49:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:07,652][root][INFO] - Training Epoch: 1/2, step 3853/107898 completed (loss: 1.001871109008789, acc: 1.0)
[2025-02-17 16:49:07,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:07,974][root][INFO] - Training Epoch: 1/2, step 3854/107898 completed (loss: 0.051194339990615845, acc: 1.0)
[2025-02-17 16:49:08,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:08,291][root][INFO] - Training Epoch: 1/2, step 3855/107898 completed (loss: 2.1653337478637695, acc: 0.5714285969734192)
[2025-02-17 16:49:08,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:08,631][root][INFO] - Training Epoch: 1/2, step 3856/107898 completed (loss: 1.095586895942688, acc: 0.8333333134651184)
[2025-02-17 16:49:08,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:08,939][root][INFO] - Training Epoch: 1/2, step 3857/107898 completed (loss: 0.48867571353912354, acc: 1.0)
[2025-02-17 16:49:09,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:09,229][root][INFO] - Training Epoch: 1/2, step 3858/107898 completed (loss: 3.150834798812866, acc: 0.4444444477558136)
[2025-02-17 16:49:09,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:09,528][root][INFO] - Training Epoch: 1/2, step 3859/107898 completed (loss: 0.05414412543177605, acc: 1.0)
[2025-02-17 16:49:09,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:09,854][root][INFO] - Training Epoch: 1/2, step 3860/107898 completed (loss: 1.1718400716781616, acc: 0.761904776096344)
[2025-02-17 16:49:09,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:10,169][root][INFO] - Training Epoch: 1/2, step 3861/107898 completed (loss: 1.6598708629608154, acc: 0.6875)
[2025-02-17 16:49:10,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:10,526][root][INFO] - Training Epoch: 1/2, step 3862/107898 completed (loss: 0.2506651282310486, acc: 0.9375)
[2025-02-17 16:49:10,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:10,867][root][INFO] - Training Epoch: 1/2, step 3863/107898 completed (loss: 0.010181715711951256, acc: 1.0)
[2025-02-17 16:49:10,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:11,165][root][INFO] - Training Epoch: 1/2, step 3864/107898 completed (loss: 0.5384541153907776, acc: 0.6666666865348816)
[2025-02-17 16:49:11,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:11,517][root][INFO] - Training Epoch: 1/2, step 3865/107898 completed (loss: 0.6287781000137329, acc: 0.9090909361839294)
[2025-02-17 16:49:11,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:11,852][root][INFO] - Training Epoch: 1/2, step 3866/107898 completed (loss: 0.5510651469230652, acc: 0.8947368264198303)
[2025-02-17 16:49:11,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:12,150][root][INFO] - Training Epoch: 1/2, step 3867/107898 completed (loss: 0.7625812888145447, acc: 0.7916666865348816)
[2025-02-17 16:49:12,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:12,474][root][INFO] - Training Epoch: 1/2, step 3868/107898 completed (loss: 1.7160000801086426, acc: 0.7333333492279053)
[2025-02-17 16:49:12,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:12,838][root][INFO] - Training Epoch: 1/2, step 3869/107898 completed (loss: 1.346611738204956, acc: 0.699999988079071)
[2025-02-17 16:49:12,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:13,153][root][INFO] - Training Epoch: 1/2, step 3870/107898 completed (loss: 3.3668630123138428, acc: 0.4000000059604645)
[2025-02-17 16:49:13,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:13,451][root][INFO] - Training Epoch: 1/2, step 3871/107898 completed (loss: 0.6165717244148254, acc: 0.9047619104385376)
[2025-02-17 16:49:13,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:13,806][root][INFO] - Training Epoch: 1/2, step 3872/107898 completed (loss: 0.4722293019294739, acc: 0.8999999761581421)
[2025-02-17 16:49:13,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:14,159][root][INFO] - Training Epoch: 1/2, step 3873/107898 completed (loss: 0.5448879599571228, acc: 0.6666666865348816)
[2025-02-17 16:49:14,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:14,514][root][INFO] - Training Epoch: 1/2, step 3874/107898 completed (loss: 0.09346161782741547, acc: 1.0)
[2025-02-17 16:49:14,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:14,856][root][INFO] - Training Epoch: 1/2, step 3875/107898 completed (loss: 0.6633063554763794, acc: 0.800000011920929)
[2025-02-17 16:49:14,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:15,191][root][INFO] - Training Epoch: 1/2, step 3876/107898 completed (loss: 0.7630572319030762, acc: 0.7931034564971924)
[2025-02-17 16:49:15,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:15,445][root][INFO] - Training Epoch: 1/2, step 3877/107898 completed (loss: 2.4408040046691895, acc: 0.5)
[2025-02-17 16:49:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:15,726][root][INFO] - Training Epoch: 1/2, step 3878/107898 completed (loss: 1.6991609334945679, acc: 0.7857142686843872)
[2025-02-17 16:49:15,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:16,016][root][INFO] - Training Epoch: 1/2, step 3879/107898 completed (loss: 0.9874977469444275, acc: 0.7307692170143127)
[2025-02-17 16:49:16,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:16,311][root][INFO] - Training Epoch: 1/2, step 3880/107898 completed (loss: 0.27065667510032654, acc: 1.0)
[2025-02-17 16:49:16,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:16,596][root][INFO] - Training Epoch: 1/2, step 3881/107898 completed (loss: 0.006710824556648731, acc: 1.0)
[2025-02-17 16:49:16,678][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:16,896][root][INFO] - Training Epoch: 1/2, step 3882/107898 completed (loss: 2.5894978046417236, acc: 0.5)
[2025-02-17 16:49:16,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:17,195][root][INFO] - Training Epoch: 1/2, step 3883/107898 completed (loss: 0.6452829837799072, acc: 0.8695651888847351)
[2025-02-17 16:49:17,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:17,471][root][INFO] - Training Epoch: 1/2, step 3884/107898 completed (loss: 2.6842734813690186, acc: 0.3333333432674408)
[2025-02-17 16:49:17,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:17,749][root][INFO] - Training Epoch: 1/2, step 3885/107898 completed (loss: 0.05384625867009163, acc: 1.0)
[2025-02-17 16:49:17,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:18,096][root][INFO] - Training Epoch: 1/2, step 3886/107898 completed (loss: 3.160586357116699, acc: 0.3333333432674408)
[2025-02-17 16:49:18,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:18,423][root][INFO] - Training Epoch: 1/2, step 3887/107898 completed (loss: 0.4369116723537445, acc: 0.5)
[2025-02-17 16:49:18,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:18,798][root][INFO] - Training Epoch: 1/2, step 3888/107898 completed (loss: 3.0401535034179688, acc: 0.3636363744735718)
[2025-02-17 16:49:18,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:19,144][root][INFO] - Training Epoch: 1/2, step 3889/107898 completed (loss: 1.222152590751648, acc: 0.7894737124443054)
[2025-02-17 16:49:19,228][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:19,461][root][INFO] - Training Epoch: 1/2, step 3890/107898 completed (loss: 1.0629030466079712, acc: 0.6153846383094788)
[2025-02-17 16:49:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:19,777][root][INFO] - Training Epoch: 1/2, step 3891/107898 completed (loss: 0.8300639390945435, acc: 0.9259259104728699)
[2025-02-17 16:49:19,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:20,132][root][INFO] - Training Epoch: 1/2, step 3892/107898 completed (loss: 2.0057921409606934, acc: 0.625)
[2025-02-17 16:49:20,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:20,468][root][INFO] - Training Epoch: 1/2, step 3893/107898 completed (loss: 0.05572152137756348, acc: 1.0)
[2025-02-17 16:49:20,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:20,788][root][INFO] - Training Epoch: 1/2, step 3894/107898 completed (loss: 3.1732418537139893, acc: 0.0)
[2025-02-17 16:49:20,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:21,094][root][INFO] - Training Epoch: 1/2, step 3895/107898 completed (loss: 0.01411812100559473, acc: 1.0)
[2025-02-17 16:49:21,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:21,455][root][INFO] - Training Epoch: 1/2, step 3896/107898 completed (loss: 0.399146169424057, acc: 0.6666666865348816)
[2025-02-17 16:49:21,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:21,783][root][INFO] - Training Epoch: 1/2, step 3897/107898 completed (loss: 0.002541233552619815, acc: 1.0)
[2025-02-17 16:49:21,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:22,123][root][INFO] - Training Epoch: 1/2, step 3898/107898 completed (loss: 0.22190847992897034, acc: 1.0)
[2025-02-17 16:49:22,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:22,452][root][INFO] - Training Epoch: 1/2, step 3899/107898 completed (loss: 0.3169105052947998, acc: 0.9166666865348816)
[2025-02-17 16:49:22,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:22,761][root][INFO] - Training Epoch: 1/2, step 3900/107898 completed (loss: 1.1328704357147217, acc: 0.75)
[2025-02-17 16:49:22,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:23,108][root][INFO] - Training Epoch: 1/2, step 3901/107898 completed (loss: 0.7354924082756042, acc: 0.7647058963775635)
[2025-02-17 16:49:23,186][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:23,397][root][INFO] - Training Epoch: 1/2, step 3902/107898 completed (loss: 0.37517449259757996, acc: 1.0)
[2025-02-17 16:49:23,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:23,691][root][INFO] - Training Epoch: 1/2, step 3903/107898 completed (loss: 0.14800919592380524, acc: 1.0)
[2025-02-17 16:49:23,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:24,017][root][INFO] - Training Epoch: 1/2, step 3904/107898 completed (loss: 0.012622136622667313, acc: 1.0)
[2025-02-17 16:49:24,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:24,337][root][INFO] - Training Epoch: 1/2, step 3905/107898 completed (loss: 4.324533939361572, acc: 0.3333333432674408)
[2025-02-17 16:49:24,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:24,641][root][INFO] - Training Epoch: 1/2, step 3906/107898 completed (loss: 1.021635890007019, acc: 0.8181818127632141)
[2025-02-17 16:49:24,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:24,988][root][INFO] - Training Epoch: 1/2, step 3907/107898 completed (loss: 3.124401807785034, acc: 0.25)
[2025-02-17 16:49:25,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:25,322][root][INFO] - Training Epoch: 1/2, step 3908/107898 completed (loss: 2.2248966693878174, acc: 0.3333333432674408)
[2025-02-17 16:49:25,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:25,649][root][INFO] - Training Epoch: 1/2, step 3909/107898 completed (loss: 0.9694584608078003, acc: 0.8333333134651184)
[2025-02-17 16:49:25,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:25,980][root][INFO] - Training Epoch: 1/2, step 3910/107898 completed (loss: 0.5625669956207275, acc: 0.9090909361839294)
[2025-02-17 16:49:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:26,355][root][INFO] - Training Epoch: 1/2, step 3911/107898 completed (loss: 0.7805962562561035, acc: 0.5)
[2025-02-17 16:49:26,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:26,667][root][INFO] - Training Epoch: 1/2, step 3912/107898 completed (loss: 1.492460012435913, acc: 1.0)
[2025-02-17 16:49:26,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:27,012][root][INFO] - Training Epoch: 1/2, step 3913/107898 completed (loss: 1.9251461029052734, acc: 0.6666666865348816)
[2025-02-17 16:49:27,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:27,377][root][INFO] - Training Epoch: 1/2, step 3914/107898 completed (loss: 0.5249447822570801, acc: 1.0)
[2025-02-17 16:49:27,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:27,727][root][INFO] - Training Epoch: 1/2, step 3915/107898 completed (loss: 2.650116443634033, acc: 0.5714285969734192)
[2025-02-17 16:49:27,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:28,054][root][INFO] - Training Epoch: 1/2, step 3916/107898 completed (loss: 0.055524248629808426, acc: 1.0)
[2025-02-17 16:49:28,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:28,372][root][INFO] - Training Epoch: 1/2, step 3917/107898 completed (loss: 1.3969511985778809, acc: 0.6875)
[2025-02-17 16:49:28,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:28,735][root][INFO] - Training Epoch: 1/2, step 3918/107898 completed (loss: 0.06188206002116203, acc: 1.0)
[2025-02-17 16:49:28,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:29,040][root][INFO] - Training Epoch: 1/2, step 3919/107898 completed (loss: 0.07226503640413284, acc: 1.0)
[2025-02-17 16:49:29,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:29,390][root][INFO] - Training Epoch: 1/2, step 3920/107898 completed (loss: 1.0679364204406738, acc: 0.7222222089767456)
[2025-02-17 16:49:29,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:29,700][root][INFO] - Training Epoch: 1/2, step 3921/107898 completed (loss: 0.04530223831534386, acc: 1.0)
[2025-02-17 16:49:29,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:30,034][root][INFO] - Training Epoch: 1/2, step 3922/107898 completed (loss: 0.688244640827179, acc: 0.800000011920929)
[2025-02-17 16:49:30,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:30,329][root][INFO] - Training Epoch: 1/2, step 3923/107898 completed (loss: 2.7633755207061768, acc: 0.4285714328289032)
[2025-02-17 16:49:30,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:30,653][root][INFO] - Training Epoch: 1/2, step 3924/107898 completed (loss: 0.5016607642173767, acc: 0.9200000166893005)
[2025-02-17 16:49:30,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:30,974][root][INFO] - Training Epoch: 1/2, step 3925/107898 completed (loss: 3.49067759513855, acc: 0.32258063554763794)
[2025-02-17 16:49:31,056][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:31,248][root][INFO] - Training Epoch: 1/2, step 3926/107898 completed (loss: 0.35038310289382935, acc: 0.9523809552192688)
[2025-02-17 16:49:31,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:31,597][root][INFO] - Training Epoch: 1/2, step 3927/107898 completed (loss: 0.0035831150598824024, acc: 1.0)
[2025-02-17 16:49:31,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:31,913][root][INFO] - Training Epoch: 1/2, step 3928/107898 completed (loss: 4.244243144989014, acc: 0.3333333432674408)
[2025-02-17 16:49:31,998][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:32,220][root][INFO] - Training Epoch: 1/2, step 3929/107898 completed (loss: 0.015268403105437756, acc: 1.0)
[2025-02-17 16:49:32,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:32,580][root][INFO] - Training Epoch: 1/2, step 3930/107898 completed (loss: 1.5951176881790161, acc: 0.738095223903656)
[2025-02-17 16:49:32,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:32,884][root][INFO] - Training Epoch: 1/2, step 3931/107898 completed (loss: 2.772339344024658, acc: 0.0)
[2025-02-17 16:49:33,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:33,238][root][INFO] - Training Epoch: 1/2, step 3932/107898 completed (loss: 0.6916280388832092, acc: 0.9285714030265808)
[2025-02-17 16:49:33,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:33,540][root][INFO] - Training Epoch: 1/2, step 3933/107898 completed (loss: 3.0172488689422607, acc: 0.3333333432674408)
[2025-02-17 16:49:33,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:33,839][root][INFO] - Training Epoch: 1/2, step 3934/107898 completed (loss: 0.12566246092319489, acc: 1.0)
[2025-02-17 16:49:33,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:34,122][root][INFO] - Training Epoch: 1/2, step 3935/107898 completed (loss: 1.9799808263778687, acc: 0.5)
[2025-02-17 16:49:34,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:34,419][root][INFO] - Training Epoch: 1/2, step 3936/107898 completed (loss: 0.30546221137046814, acc: 0.949999988079071)
[2025-02-17 16:49:34,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:34,766][root][INFO] - Training Epoch: 1/2, step 3937/107898 completed (loss: 1.4271605014801025, acc: 0.7142857313156128)
[2025-02-17 16:49:34,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:35,093][root][INFO] - Training Epoch: 1/2, step 3938/107898 completed (loss: 0.36433109641075134, acc: 0.875)
[2025-02-17 16:49:35,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:35,405][root][INFO] - Training Epoch: 1/2, step 3939/107898 completed (loss: 0.48000234365463257, acc: 0.8571428656578064)
[2025-02-17 16:49:35,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:35,708][root][INFO] - Training Epoch: 1/2, step 3940/107898 completed (loss: 2.5123472213745117, acc: 0.5555555820465088)
[2025-02-17 16:49:35,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:36,004][root][INFO] - Training Epoch: 1/2, step 3941/107898 completed (loss: 0.1778305023908615, acc: 1.0)
[2025-02-17 16:49:36,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:36,309][root][INFO] - Training Epoch: 1/2, step 3942/107898 completed (loss: 0.676704466342926, acc: 0.8461538553237915)
[2025-02-17 16:49:36,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:36,565][root][INFO] - Training Epoch: 1/2, step 3943/107898 completed (loss: 0.025134939700365067, acc: 1.0)
[2025-02-17 16:49:36,635][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:36,843][root][INFO] - Training Epoch: 1/2, step 3944/107898 completed (loss: 0.2534094750881195, acc: 0.9090909361839294)
[2025-02-17 16:49:36,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:37,153][root][INFO] - Training Epoch: 1/2, step 3945/107898 completed (loss: 0.0035178749822080135, acc: 1.0)
[2025-02-17 16:49:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:37,512][root][INFO] - Training Epoch: 1/2, step 3946/107898 completed (loss: 0.7939633727073669, acc: 0.8461538553237915)
[2025-02-17 16:49:37,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:37,846][root][INFO] - Training Epoch: 1/2, step 3947/107898 completed (loss: 0.9718982577323914, acc: 0.75)
[2025-02-17 16:49:37,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:38,146][root][INFO] - Training Epoch: 1/2, step 3948/107898 completed (loss: 1.373568058013916, acc: 0.7931034564971924)
[2025-02-17 16:49:38,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:38,485][root][INFO] - Training Epoch: 1/2, step 3949/107898 completed (loss: 0.6011086106300354, acc: 0.8846153616905212)
[2025-02-17 16:49:38,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:38,790][root][INFO] - Training Epoch: 1/2, step 3950/107898 completed (loss: 0.6831170916557312, acc: 0.8888888955116272)
[2025-02-17 16:49:38,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:39,140][root][INFO] - Training Epoch: 1/2, step 3951/107898 completed (loss: 0.2712058126926422, acc: 1.0)
[2025-02-17 16:49:39,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:39,461][root][INFO] - Training Epoch: 1/2, step 3952/107898 completed (loss: 3.6333298683166504, acc: 0.27272728085517883)
[2025-02-17 16:49:39,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:39,801][root][INFO] - Training Epoch: 1/2, step 3953/107898 completed (loss: 0.34367674589157104, acc: 0.8611111044883728)
[2025-02-17 16:49:39,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:40,055][root][INFO] - Training Epoch: 1/2, step 3954/107898 completed (loss: 1.3909053802490234, acc: 0.625)
[2025-02-17 16:49:40,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:40,338][root][INFO] - Training Epoch: 1/2, step 3955/107898 completed (loss: 2.3052561283111572, acc: 0.4285714328289032)
[2025-02-17 16:49:40,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:40,653][root][INFO] - Training Epoch: 1/2, step 3956/107898 completed (loss: 0.7580601572990417, acc: 0.8333333134651184)
[2025-02-17 16:49:40,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:40,943][root][INFO] - Training Epoch: 1/2, step 3957/107898 completed (loss: 2.254812002182007, acc: 0.6000000238418579)
[2025-02-17 16:49:41,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:41,232][root][INFO] - Training Epoch: 1/2, step 3958/107898 completed (loss: 2.26613187789917, acc: 0.6000000238418579)
[2025-02-17 16:49:41,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:41,570][root][INFO] - Training Epoch: 1/2, step 3959/107898 completed (loss: 0.16088657081127167, acc: 1.0)
[2025-02-17 16:49:41,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:41,917][root][INFO] - Training Epoch: 1/2, step 3960/107898 completed (loss: 0.44903185963630676, acc: 1.0)
[2025-02-17 16:49:42,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:42,240][root][INFO] - Training Epoch: 1/2, step 3961/107898 completed (loss: 0.8796085119247437, acc: 0.8181818127632141)
[2025-02-17 16:49:42,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:42,574][root][INFO] - Training Epoch: 1/2, step 3962/107898 completed (loss: 1.1019389629364014, acc: 0.699999988079071)
[2025-02-17 16:49:42,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:42,893][root][INFO] - Training Epoch: 1/2, step 3963/107898 completed (loss: 0.089192233979702, acc: 1.0)
[2025-02-17 16:49:42,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:43,225][root][INFO] - Training Epoch: 1/2, step 3964/107898 completed (loss: 0.5559226870536804, acc: 1.0)
[2025-02-17 16:49:43,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:43,547][root][INFO] - Training Epoch: 1/2, step 3965/107898 completed (loss: 1.5645215511322021, acc: 0.5714285969734192)
[2025-02-17 16:49:43,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:43,850][root][INFO] - Training Epoch: 1/2, step 3966/107898 completed (loss: 0.08193875104188919, acc: 1.0)
[2025-02-17 16:49:43,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:44,149][root][INFO] - Training Epoch: 1/2, step 3967/107898 completed (loss: 1.6080169677734375, acc: 0.5)
[2025-02-17 16:49:44,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:44,464][root][INFO] - Training Epoch: 1/2, step 3968/107898 completed (loss: 0.03466159850358963, acc: 1.0)
[2025-02-17 16:49:44,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:44,822][root][INFO] - Training Epoch: 1/2, step 3969/107898 completed (loss: 0.771850049495697, acc: 0.800000011920929)
[2025-02-17 16:49:44,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:45,133][root][INFO] - Training Epoch: 1/2, step 3970/107898 completed (loss: 1.7186387777328491, acc: 0.5384615659713745)
[2025-02-17 16:49:45,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:45,426][root][INFO] - Training Epoch: 1/2, step 3971/107898 completed (loss: 1.7403374910354614, acc: 0.75)
[2025-02-17 16:49:45,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:45,715][root][INFO] - Training Epoch: 1/2, step 3972/107898 completed (loss: 0.39601585268974304, acc: 0.6666666865348816)
[2025-02-17 16:49:45,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:46,031][root][INFO] - Training Epoch: 1/2, step 3973/107898 completed (loss: 2.125363349914551, acc: 0.5)
[2025-02-17 16:49:46,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:46,322][root][INFO] - Training Epoch: 1/2, step 3974/107898 completed (loss: 0.6531200408935547, acc: 0.8333333134651184)
[2025-02-17 16:49:46,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:46,614][root][INFO] - Training Epoch: 1/2, step 3975/107898 completed (loss: 0.12587378919124603, acc: 1.0)
[2025-02-17 16:49:46,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:46,908][root][INFO] - Training Epoch: 1/2, step 3976/107898 completed (loss: 2.890016555786133, acc: 0.5454545617103577)
[2025-02-17 16:49:46,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:47,211][root][INFO] - Training Epoch: 1/2, step 3977/107898 completed (loss: 0.4963461756706238, acc: 0.8571428656578064)
[2025-02-17 16:49:47,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:47,520][root][INFO] - Training Epoch: 1/2, step 3978/107898 completed (loss: 0.03096207231283188, acc: 1.0)
[2025-02-17 16:49:47,611][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:47,866][root][INFO] - Training Epoch: 1/2, step 3979/107898 completed (loss: 0.5051418542861938, acc: 0.875)
[2025-02-17 16:49:47,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:48,225][root][INFO] - Training Epoch: 1/2, step 3980/107898 completed (loss: 0.26575636863708496, acc: 1.0)
[2025-02-17 16:49:48,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:48,519][root][INFO] - Training Epoch: 1/2, step 3981/107898 completed (loss: 0.07198384404182434, acc: 1.0)
[2025-02-17 16:49:48,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:48,828][root][INFO] - Training Epoch: 1/2, step 3982/107898 completed (loss: 2.5882580280303955, acc: 0.3684210479259491)
[2025-02-17 16:49:48,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:49,104][root][INFO] - Training Epoch: 1/2, step 3983/107898 completed (loss: 0.009882152080535889, acc: 1.0)
[2025-02-17 16:49:49,215][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:49,453][root][INFO] - Training Epoch: 1/2, step 3984/107898 completed (loss: 4.450826168060303, acc: 0.5)
[2025-02-17 16:49:49,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:49,773][root][INFO] - Training Epoch: 1/2, step 3985/107898 completed (loss: 1.110352635383606, acc: 0.75)
[2025-02-17 16:49:49,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:50,132][root][INFO] - Training Epoch: 1/2, step 3986/107898 completed (loss: 0.28246578574180603, acc: 0.9523809552192688)
[2025-02-17 16:49:50,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:50,489][root][INFO] - Training Epoch: 1/2, step 3987/107898 completed (loss: 4.282487869262695, acc: 0.4000000059604645)
[2025-02-17 16:49:50,586][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:50,805][root][INFO] - Training Epoch: 1/2, step 3988/107898 completed (loss: 1.2250046730041504, acc: 0.75)
[2025-02-17 16:49:50,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:51,108][root][INFO] - Training Epoch: 1/2, step 3989/107898 completed (loss: 3.524298667907715, acc: 0.3888888955116272)
[2025-02-17 16:49:51,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:51,401][root][INFO] - Training Epoch: 1/2, step 3990/107898 completed (loss: 2.0414834022521973, acc: 0.6428571343421936)
[2025-02-17 16:49:51,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:51,703][root][INFO] - Training Epoch: 1/2, step 3991/107898 completed (loss: 0.5521109104156494, acc: 1.0)
[2025-02-17 16:49:51,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:52,036][root][INFO] - Training Epoch: 1/2, step 3992/107898 completed (loss: 1.8948308229446411, acc: 0.6428571343421936)
[2025-02-17 16:49:52,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:52,349][root][INFO] - Training Epoch: 1/2, step 3993/107898 completed (loss: 0.6740342974662781, acc: 0.75)
[2025-02-17 16:49:52,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:52,644][root][INFO] - Training Epoch: 1/2, step 3994/107898 completed (loss: 0.0005398012581281364, acc: 1.0)
[2025-02-17 16:49:52,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:52,956][root][INFO] - Training Epoch: 1/2, step 3995/107898 completed (loss: 0.004800265654921532, acc: 1.0)
[2025-02-17 16:49:53,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:53,261][root][INFO] - Training Epoch: 1/2, step 3996/107898 completed (loss: 0.178892582654953, acc: 0.9444444179534912)
[2025-02-17 16:49:53,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:53,585][root][INFO] - Training Epoch: 1/2, step 3997/107898 completed (loss: 0.2756853997707367, acc: 0.9512194991111755)
[2025-02-17 16:49:53,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:53,896][root][INFO] - Training Epoch: 1/2, step 3998/107898 completed (loss: 0.9026454091072083, acc: 0.75)
[2025-02-17 16:49:53,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:54,197][root][INFO] - Training Epoch: 1/2, step 3999/107898 completed (loss: 0.25642454624176025, acc: 0.8636363744735718)
[2025-02-17 16:49:54,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:54,462][root][INFO] - Training Epoch: 1/2, step 4000/107898 completed (loss: 0.9222875237464905, acc: 0.6666666865348816)
[2025-02-17 16:49:54,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:54,765][root][INFO] - Training Epoch: 1/2, step 4001/107898 completed (loss: 1.0756301879882812, acc: 0.8666666746139526)
[2025-02-17 16:49:54,846][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:55,066][root][INFO] - Training Epoch: 1/2, step 4002/107898 completed (loss: 0.1159999743103981, acc: 1.0)
[2025-02-17 16:49:55,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:55,390][root][INFO] - Training Epoch: 1/2, step 4003/107898 completed (loss: 1.656014323234558, acc: 0.8461538553237915)
[2025-02-17 16:49:55,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:55,710][root][INFO] - Training Epoch: 1/2, step 4004/107898 completed (loss: 0.7884585857391357, acc: 0.7272727489471436)
[2025-02-17 16:49:55,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:56,049][root][INFO] - Training Epoch: 1/2, step 4005/107898 completed (loss: 4.281878471374512, acc: 0.3888888955116272)
[2025-02-17 16:49:56,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:56,339][root][INFO] - Training Epoch: 1/2, step 4006/107898 completed (loss: 0.3771927058696747, acc: 0.6666666865348816)
[2025-02-17 16:49:56,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:56,683][root][INFO] - Training Epoch: 1/2, step 4007/107898 completed (loss: 1.0619173049926758, acc: 0.5)
[2025-02-17 16:49:56,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:57,019][root][INFO] - Training Epoch: 1/2, step 4008/107898 completed (loss: 1.498292088508606, acc: 0.7857142686843872)
[2025-02-17 16:49:57,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:57,342][root][INFO] - Training Epoch: 1/2, step 4009/107898 completed (loss: 0.042736612260341644, acc: 1.0)
[2025-02-17 16:49:57,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:57,679][root][INFO] - Training Epoch: 1/2, step 4010/107898 completed (loss: 0.5744854211807251, acc: 0.8695651888847351)
[2025-02-17 16:49:57,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:58,033][root][INFO] - Training Epoch: 1/2, step 4011/107898 completed (loss: 0.08037500828504562, acc: 1.0)
[2025-02-17 16:49:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:58,408][root][INFO] - Training Epoch: 1/2, step 4012/107898 completed (loss: 1.1708440780639648, acc: 0.7948718070983887)
[2025-02-17 16:49:58,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:58,735][root][INFO] - Training Epoch: 1/2, step 4013/107898 completed (loss: 1.5175490379333496, acc: 0.6153846383094788)
[2025-02-17 16:49:58,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:59,041][root][INFO] - Training Epoch: 1/2, step 4014/107898 completed (loss: 0.5856884717941284, acc: 0.5)
[2025-02-17 16:49:59,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:59,380][root][INFO] - Training Epoch: 1/2, step 4015/107898 completed (loss: 0.09808962047100067, acc: 1.0)
[2025-02-17 16:49:59,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:49:59,711][root][INFO] - Training Epoch: 1/2, step 4016/107898 completed (loss: 1.7147727012634277, acc: 0.6666666865348816)
[2025-02-17 16:49:59,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:00,029][root][INFO] - Training Epoch: 1/2, step 4017/107898 completed (loss: 1.1304806470870972, acc: 0.8333333134651184)
[2025-02-17 16:50:00,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:00,344][root][INFO] - Training Epoch: 1/2, step 4018/107898 completed (loss: 0.029236119240522385, acc: 1.0)
[2025-02-17 16:50:00,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:00,674][root][INFO] - Training Epoch: 1/2, step 4019/107898 completed (loss: 1.1775517463684082, acc: 0.7272727489471436)
[2025-02-17 16:50:00,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:00,990][root][INFO] - Training Epoch: 1/2, step 4020/107898 completed (loss: 1.2286964654922485, acc: 0.7142857313156128)
[2025-02-17 16:50:01,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:01,308][root][INFO] - Training Epoch: 1/2, step 4021/107898 completed (loss: 0.05749067664146423, acc: 1.0)
[2025-02-17 16:50:01,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:01,645][root][INFO] - Training Epoch: 1/2, step 4022/107898 completed (loss: 0.8731967210769653, acc: 0.0)
[2025-02-17 16:50:01,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:01,971][root][INFO] - Training Epoch: 1/2, step 4023/107898 completed (loss: 0.9983839988708496, acc: 0.7142857313156128)
[2025-02-17 16:50:02,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:02,302][root][INFO] - Training Epoch: 1/2, step 4024/107898 completed (loss: 2.6050727367401123, acc: 0.529411792755127)
[2025-02-17 16:50:02,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:02,618][root][INFO] - Training Epoch: 1/2, step 4025/107898 completed (loss: 0.22709988057613373, acc: 0.9166666865348816)
[2025-02-17 16:50:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:02,918][root][INFO] - Training Epoch: 1/2, step 4026/107898 completed (loss: 3.0552823543548584, acc: 0.5)
[2025-02-17 16:50:02,996][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:03,213][root][INFO] - Training Epoch: 1/2, step 4027/107898 completed (loss: 0.41371169686317444, acc: 1.0)
[2025-02-17 16:50:03,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:03,535][root][INFO] - Training Epoch: 1/2, step 4028/107898 completed (loss: 0.49449628591537476, acc: 0.8846153616905212)
[2025-02-17 16:50:03,611][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:03,825][root][INFO] - Training Epoch: 1/2, step 4029/107898 completed (loss: 0.4313359260559082, acc: 1.0)
[2025-02-17 16:50:03,912][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:04,143][root][INFO] - Training Epoch: 1/2, step 4030/107898 completed (loss: 0.0001711560762487352, acc: 1.0)
[2025-02-17 16:50:04,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:04,469][root][INFO] - Training Epoch: 1/2, step 4031/107898 completed (loss: 1.4836972951889038, acc: 0.6666666865348816)
[2025-02-17 16:50:04,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:04,781][root][INFO] - Training Epoch: 1/2, step 4032/107898 completed (loss: 1.843529224395752, acc: 0.6666666865348816)
[2025-02-17 16:50:04,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:05,085][root][INFO] - Training Epoch: 1/2, step 4033/107898 completed (loss: 0.02659808285534382, acc: 1.0)
[2025-02-17 16:50:05,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:05,398][root][INFO] - Training Epoch: 1/2, step 4034/107898 completed (loss: 0.6325966119766235, acc: 0.8620689511299133)
[2025-02-17 16:50:05,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:05,634][root][INFO] - Training Epoch: 1/2, step 4035/107898 completed (loss: 0.3142148554325104, acc: 0.9090909361839294)
[2025-02-17 16:50:05,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:05,937][root][INFO] - Training Epoch: 1/2, step 4036/107898 completed (loss: 0.016410619020462036, acc: 1.0)
[2025-02-17 16:50:06,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:06,252][root][INFO] - Training Epoch: 1/2, step 4037/107898 completed (loss: 0.7001804709434509, acc: 0.8125)
[2025-02-17 16:50:06,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:06,571][root][INFO] - Training Epoch: 1/2, step 4038/107898 completed (loss: 0.03840354457497597, acc: 1.0)
[2025-02-17 16:50:06,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:06,901][root][INFO] - Training Epoch: 1/2, step 4039/107898 completed (loss: 0.9220183491706848, acc: 0.6666666865348816)
[2025-02-17 16:50:06,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:07,212][root][INFO] - Training Epoch: 1/2, step 4040/107898 completed (loss: 1.408974289894104, acc: 0.7647058963775635)
[2025-02-17 16:50:07,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:07,488][root][INFO] - Training Epoch: 1/2, step 4041/107898 completed (loss: 3.1230857372283936, acc: 0.5)
[2025-02-17 16:50:07,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:07,788][root][INFO] - Training Epoch: 1/2, step 4042/107898 completed (loss: 3.5363776683807373, acc: 0.30000001192092896)
[2025-02-17 16:50:07,901][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:08,103][root][INFO] - Training Epoch: 1/2, step 4043/107898 completed (loss: 1.6637163162231445, acc: 0.5)
[2025-02-17 16:50:08,215][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:08,429][root][INFO] - Training Epoch: 1/2, step 4044/107898 completed (loss: 0.665418267250061, acc: 0.8965517282485962)
[2025-02-17 16:50:08,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:08,774][root][INFO] - Training Epoch: 1/2, step 4045/107898 completed (loss: 0.2973286211490631, acc: 0.9411764740943909)
[2025-02-17 16:50:08,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:09,107][root][INFO] - Training Epoch: 1/2, step 4046/107898 completed (loss: 1.5207188129425049, acc: 0.75)
[2025-02-17 16:50:09,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:09,407][root][INFO] - Training Epoch: 1/2, step 4047/107898 completed (loss: 3.3885834217071533, acc: 0.25)
[2025-02-17 16:50:09,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:09,726][root][INFO] - Training Epoch: 1/2, step 4048/107898 completed (loss: 0.6969768404960632, acc: 0.761904776096344)
[2025-02-17 16:50:09,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:10,025][root][INFO] - Training Epoch: 1/2, step 4049/107898 completed (loss: 1.389731526374817, acc: 0.8571428656578064)
[2025-02-17 16:50:10,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:10,385][root][INFO] - Training Epoch: 1/2, step 4050/107898 completed (loss: 3.0967066287994385, acc: 0.3333333432674408)
[2025-02-17 16:50:10,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:10,725][root][INFO] - Training Epoch: 1/2, step 4051/107898 completed (loss: 4.200997352600098, acc: 0.25)
[2025-02-17 16:50:10,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:11,029][root][INFO] - Training Epoch: 1/2, step 4052/107898 completed (loss: 1.1339600086212158, acc: 0.875)
[2025-02-17 16:50:11,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:11,368][root][INFO] - Training Epoch: 1/2, step 4053/107898 completed (loss: 0.8775341510772705, acc: 0.8387096524238586)
[2025-02-17 16:50:11,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:11,693][root][INFO] - Training Epoch: 1/2, step 4054/107898 completed (loss: 0.00015221153444144875, acc: 1.0)
[2025-02-17 16:50:11,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:12,023][root][INFO] - Training Epoch: 1/2, step 4055/107898 completed (loss: 0.5520914793014526, acc: 0.761904776096344)
[2025-02-17 16:50:12,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:12,345][root][INFO] - Training Epoch: 1/2, step 4056/107898 completed (loss: 0.4757353365421295, acc: 0.9629629850387573)
[2025-02-17 16:50:12,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:12,705][root][INFO] - Training Epoch: 1/2, step 4057/107898 completed (loss: 0.25956472754478455, acc: 0.9375)
[2025-02-17 16:50:12,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:13,057][root][INFO] - Training Epoch: 1/2, step 4058/107898 completed (loss: 0.39670878648757935, acc: 0.9285714030265808)
[2025-02-17 16:50:13,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:13,389][root][INFO] - Training Epoch: 1/2, step 4059/107898 completed (loss: 0.002183559350669384, acc: 1.0)
[2025-02-17 16:50:13,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:13,699][root][INFO] - Training Epoch: 1/2, step 4060/107898 completed (loss: 1.5303905010223389, acc: 0.8214285969734192)
[2025-02-17 16:50:13,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:13,993][root][INFO] - Training Epoch: 1/2, step 4061/107898 completed (loss: 0.14450739324092865, acc: 1.0)
[2025-02-17 16:50:14,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:14,285][root][INFO] - Training Epoch: 1/2, step 4062/107898 completed (loss: 0.8393012285232544, acc: 0.8571428656578064)
[2025-02-17 16:50:14,358][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:14,578][root][INFO] - Training Epoch: 1/2, step 4063/107898 completed (loss: 1.148545503616333, acc: 0.5)
[2025-02-17 16:50:14,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:14,930][root][INFO] - Training Epoch: 1/2, step 4064/107898 completed (loss: 4.291790008544922, acc: 0.3076923191547394)
[2025-02-17 16:50:15,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:15,273][root][INFO] - Training Epoch: 1/2, step 4065/107898 completed (loss: 0.6810240745544434, acc: 0.875)
[2025-02-17 16:50:15,358][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:15,575][root][INFO] - Training Epoch: 1/2, step 4066/107898 completed (loss: 3.4203720092773438, acc: 0.5)
[2025-02-17 16:50:15,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:15,874][root][INFO] - Training Epoch: 1/2, step 4067/107898 completed (loss: 0.6044611930847168, acc: 0.8333333134651184)
[2025-02-17 16:50:15,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:16,185][root][INFO] - Training Epoch: 1/2, step 4068/107898 completed (loss: 1.8404641151428223, acc: 0.5833333134651184)
[2025-02-17 16:50:16,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:16,480][root][INFO] - Training Epoch: 1/2, step 4069/107898 completed (loss: 0.37978577613830566, acc: 0.8333333134651184)
[2025-02-17 16:50:16,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:16,830][root][INFO] - Training Epoch: 1/2, step 4070/107898 completed (loss: 2.3420698642730713, acc: 0.517241358757019)
[2025-02-17 16:50:16,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:17,172][root][INFO] - Training Epoch: 1/2, step 4071/107898 completed (loss: 0.5375422239303589, acc: 0.8235294222831726)
[2025-02-17 16:50:17,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:17,527][root][INFO] - Training Epoch: 1/2, step 4072/107898 completed (loss: 1.6534732580184937, acc: 0.5454545617103577)
[2025-02-17 16:50:17,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:17,873][root][INFO] - Training Epoch: 1/2, step 4073/107898 completed (loss: 0.6324788928031921, acc: 0.8571428656578064)
[2025-02-17 16:50:17,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:18,175][root][INFO] - Training Epoch: 1/2, step 4074/107898 completed (loss: 0.16497290134429932, acc: 1.0)
[2025-02-17 16:50:18,257][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:18,489][root][INFO] - Training Epoch: 1/2, step 4075/107898 completed (loss: 0.5708696246147156, acc: 0.8571428656578064)
[2025-02-17 16:50:18,584][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:18,810][root][INFO] - Training Epoch: 1/2, step 4076/107898 completed (loss: 0.27388259768486023, acc: 1.0)
[2025-02-17 16:50:18,901][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:19,085][root][INFO] - Training Epoch: 1/2, step 4077/107898 completed (loss: 0.21662242710590363, acc: 0.8571428656578064)
[2025-02-17 16:50:19,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:19,380][root][INFO] - Training Epoch: 1/2, step 4078/107898 completed (loss: 0.0046742926351726055, acc: 1.0)
[2025-02-17 16:50:19,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:19,666][root][INFO] - Training Epoch: 1/2, step 4079/107898 completed (loss: 0.33978694677352905, acc: 0.875)
[2025-02-17 16:50:19,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:20,015][root][INFO] - Training Epoch: 1/2, step 4080/107898 completed (loss: 0.38235554099082947, acc: 0.8333333134651184)
[2025-02-17 16:50:20,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:20,354][root][INFO] - Training Epoch: 1/2, step 4081/107898 completed (loss: 0.7775524258613586, acc: 0.7142857313156128)
[2025-02-17 16:50:20,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:20,675][root][INFO] - Training Epoch: 1/2, step 4082/107898 completed (loss: 0.7108789682388306, acc: 0.5)
[2025-02-17 16:50:20,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:20,997][root][INFO] - Training Epoch: 1/2, step 4083/107898 completed (loss: 1.7763302326202393, acc: 0.7272727489471436)
[2025-02-17 16:50:21,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:21,318][root][INFO] - Training Epoch: 1/2, step 4084/107898 completed (loss: 0.36541470885276794, acc: 1.0)
[2025-02-17 16:50:21,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:21,639][root][INFO] - Training Epoch: 1/2, step 4085/107898 completed (loss: 0.38177284598350525, acc: 0.800000011920929)
[2025-02-17 16:50:21,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:21,931][root][INFO] - Training Epoch: 1/2, step 4086/107898 completed (loss: 1.8531438112258911, acc: 0.75)
[2025-02-17 16:50:22,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:22,238][root][INFO] - Training Epoch: 1/2, step 4087/107898 completed (loss: 2.4878385066986084, acc: 0.5)
[2025-02-17 16:50:22,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:22,560][root][INFO] - Training Epoch: 1/2, step 4088/107898 completed (loss: 2.736931324005127, acc: 0.4545454680919647)
[2025-02-17 16:50:22,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:22,894][root][INFO] - Training Epoch: 1/2, step 4089/107898 completed (loss: 0.1568070501089096, acc: 0.9259259104728699)
[2025-02-17 16:50:22,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:23,195][root][INFO] - Training Epoch: 1/2, step 4090/107898 completed (loss: 2.0673904418945312, acc: 0.5454545617103577)
[2025-02-17 16:50:23,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:23,485][root][INFO] - Training Epoch: 1/2, step 4091/107898 completed (loss: 0.05230008438229561, acc: 1.0)
[2025-02-17 16:50:23,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:23,847][root][INFO] - Training Epoch: 1/2, step 4092/107898 completed (loss: 1.2880192995071411, acc: 0.692307710647583)
[2025-02-17 16:50:23,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:24,188][root][INFO] - Training Epoch: 1/2, step 4093/107898 completed (loss: 2.6301004886627197, acc: 0.4615384638309479)
[2025-02-17 16:50:24,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:24,441][root][INFO] - Training Epoch: 1/2, step 4094/107898 completed (loss: 0.01577376201748848, acc: 1.0)
[2025-02-17 16:50:24,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:24,731][root][INFO] - Training Epoch: 1/2, step 4095/107898 completed (loss: 0.032552123069763184, acc: 1.0)
[2025-02-17 16:50:24,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:25,091][root][INFO] - Training Epoch: 1/2, step 4096/107898 completed (loss: 0.003124890848994255, acc: 1.0)
[2025-02-17 16:50:25,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:25,425][root][INFO] - Training Epoch: 1/2, step 4097/107898 completed (loss: 1.2855108976364136, acc: 0.7142857313156128)
[2025-02-17 16:50:25,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:25,730][root][INFO] - Training Epoch: 1/2, step 4098/107898 completed (loss: 1.9490975141525269, acc: 0.7692307829856873)
[2025-02-17 16:50:25,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:26,057][root][INFO] - Training Epoch: 1/2, step 4099/107898 completed (loss: 0.21380765736103058, acc: 0.9166666865348816)
[2025-02-17 16:50:26,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:26,378][root][INFO] - Training Epoch: 1/2, step 4100/107898 completed (loss: 0.08833207190036774, acc: 1.0)
[2025-02-17 16:50:26,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:26,688][root][INFO] - Training Epoch: 1/2, step 4101/107898 completed (loss: 0.8776993155479431, acc: 0.8947368264198303)
[2025-02-17 16:50:26,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:27,052][root][INFO] - Training Epoch: 1/2, step 4102/107898 completed (loss: 0.6314926147460938, acc: 0.8666666746139526)
[2025-02-17 16:50:27,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:27,363][root][INFO] - Training Epoch: 1/2, step 4103/107898 completed (loss: 1.3892724514007568, acc: 0.8181818127632141)
[2025-02-17 16:50:27,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:27,666][root][INFO] - Training Epoch: 1/2, step 4104/107898 completed (loss: 1.0272493362426758, acc: 0.8275862336158752)
[2025-02-17 16:50:27,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:28,005][root][INFO] - Training Epoch: 1/2, step 4105/107898 completed (loss: 1.186906337738037, acc: 0.8095238208770752)
[2025-02-17 16:50:28,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:28,276][root][INFO] - Training Epoch: 1/2, step 4106/107898 completed (loss: 0.014523442834615707, acc: 1.0)
[2025-02-17 16:50:28,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:28,627][root][INFO] - Training Epoch: 1/2, step 4107/107898 completed (loss: 4.037492275238037, acc: 0.11538461595773697)
[2025-02-17 16:50:28,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:28,943][root][INFO] - Training Epoch: 1/2, step 4108/107898 completed (loss: 1.8726141452789307, acc: 0.7058823704719543)
[2025-02-17 16:50:29,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:29,228][root][INFO] - Training Epoch: 1/2, step 4109/107898 completed (loss: 0.24054944515228271, acc: 1.0)
[2025-02-17 16:50:29,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:29,547][root][INFO] - Training Epoch: 1/2, step 4110/107898 completed (loss: 0.3632919192314148, acc: 0.9230769276618958)
[2025-02-17 16:50:29,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:29,889][root][INFO] - Training Epoch: 1/2, step 4111/107898 completed (loss: 0.002783019794151187, acc: 1.0)
[2025-02-17 16:50:29,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:30,198][root][INFO] - Training Epoch: 1/2, step 4112/107898 completed (loss: 1.7273460626602173, acc: 0.6000000238418579)
[2025-02-17 16:50:30,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:30,498][root][INFO] - Training Epoch: 1/2, step 4113/107898 completed (loss: 1.256500482559204, acc: 0.7307692170143127)
[2025-02-17 16:50:30,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:30,785][root][INFO] - Training Epoch: 1/2, step 4114/107898 completed (loss: 0.010263686068356037, acc: 1.0)
[2025-02-17 16:50:30,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:31,094][root][INFO] - Training Epoch: 1/2, step 4115/107898 completed (loss: 0.3690451383590698, acc: 0.9473684430122375)
[2025-02-17 16:50:31,206][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:31,427][root][INFO] - Training Epoch: 1/2, step 4116/107898 completed (loss: 1.7109757661819458, acc: 0.6666666865348816)
[2025-02-17 16:50:31,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:31,805][root][INFO] - Training Epoch: 1/2, step 4117/107898 completed (loss: 0.4216885268688202, acc: 0.8823529481887817)
[2025-02-17 16:50:31,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:32,155][root][INFO] - Training Epoch: 1/2, step 4118/107898 completed (loss: 4.224737644195557, acc: 0.1666666716337204)
[2025-02-17 16:50:32,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:32,493][root][INFO] - Training Epoch: 1/2, step 4119/107898 completed (loss: 0.17239230871200562, acc: 1.0)
[2025-02-17 16:50:32,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:32,798][root][INFO] - Training Epoch: 1/2, step 4120/107898 completed (loss: 0.9240112900733948, acc: 0.8461538553237915)
[2025-02-17 16:50:32,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:33,090][root][INFO] - Training Epoch: 1/2, step 4121/107898 completed (loss: 0.35032445192337036, acc: 0.8999999761581421)
[2025-02-17 16:50:33,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:33,388][root][INFO] - Training Epoch: 1/2, step 4122/107898 completed (loss: 2.4677557945251465, acc: 0.4285714328289032)
[2025-02-17 16:50:33,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:33,672][root][INFO] - Training Epoch: 1/2, step 4123/107898 completed (loss: 0.6583637595176697, acc: 0.8999999761581421)
[2025-02-17 16:50:33,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:33,992][root][INFO] - Training Epoch: 1/2, step 4124/107898 completed (loss: 1.3177701234817505, acc: 0.7777777910232544)
[2025-02-17 16:50:34,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:34,340][root][INFO] - Training Epoch: 1/2, step 4125/107898 completed (loss: 0.00039010102045722306, acc: 1.0)
[2025-02-17 16:50:34,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:34,676][root][INFO] - Training Epoch: 1/2, step 4126/107898 completed (loss: 1.6277631521224976, acc: 0.6521739363670349)
[2025-02-17 16:50:34,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:35,059][root][INFO] - Training Epoch: 1/2, step 4127/107898 completed (loss: 2.648151159286499, acc: 0.4545454680919647)
[2025-02-17 16:50:35,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:35,394][root][INFO] - Training Epoch: 1/2, step 4128/107898 completed (loss: 1.20390784740448, acc: 1.0)
[2025-02-17 16:50:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:35,721][root][INFO] - Training Epoch: 1/2, step 4129/107898 completed (loss: 1.3594882488250732, acc: 0.6666666865348816)
[2025-02-17 16:50:35,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:36,042][root][INFO] - Training Epoch: 1/2, step 4130/107898 completed (loss: 2.3793184757232666, acc: 0.6666666865348816)
[2025-02-17 16:50:36,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:36,366][root][INFO] - Training Epoch: 1/2, step 4131/107898 completed (loss: 1.1833722591400146, acc: 0.6666666865348816)
[2025-02-17 16:50:36,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:36,707][root][INFO] - Training Epoch: 1/2, step 4132/107898 completed (loss: 0.7717788815498352, acc: 0.8205128312110901)
[2025-02-17 16:50:36,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:36,996][root][INFO] - Training Epoch: 1/2, step 4133/107898 completed (loss: 0.7871461510658264, acc: 0.75)
[2025-02-17 16:50:37,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:37,334][root][INFO] - Training Epoch: 1/2, step 4134/107898 completed (loss: 0.0024556738790124655, acc: 1.0)
[2025-02-17 16:50:37,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:37,677][root][INFO] - Training Epoch: 1/2, step 4135/107898 completed (loss: 6.301955223083496, acc: 0.5)
[2025-02-17 16:50:37,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:38,032][root][INFO] - Training Epoch: 1/2, step 4136/107898 completed (loss: 0.001376689993776381, acc: 1.0)
[2025-02-17 16:50:38,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:38,354][root][INFO] - Training Epoch: 1/2, step 4137/107898 completed (loss: 0.0006384543958120048, acc: 1.0)
[2025-02-17 16:50:38,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:38,671][root][INFO] - Training Epoch: 1/2, step 4138/107898 completed (loss: 0.7962088584899902, acc: 0.75)
[2025-02-17 16:50:38,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:38,972][root][INFO] - Training Epoch: 1/2, step 4139/107898 completed (loss: 0.0559309720993042, acc: 1.0)
[2025-02-17 16:50:39,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:39,281][root][INFO] - Training Epoch: 1/2, step 4140/107898 completed (loss: 0.47188594937324524, acc: 0.8235294222831726)
[2025-02-17 16:50:39,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:39,584][root][INFO] - Training Epoch: 1/2, step 4141/107898 completed (loss: 0.40866222977638245, acc: 0.9090909361839294)
[2025-02-17 16:50:39,671][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:39,894][root][INFO] - Training Epoch: 1/2, step 4142/107898 completed (loss: 0.3543330729007721, acc: 0.8999999761581421)
[2025-02-17 16:50:39,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:40,217][root][INFO] - Training Epoch: 1/2, step 4143/107898 completed (loss: 1.0097990036010742, acc: 0.5)
[2025-02-17 16:50:40,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:40,580][root][INFO] - Training Epoch: 1/2, step 4144/107898 completed (loss: 1.6562728881835938, acc: 0.5)
[2025-02-17 16:50:40,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:40,912][root][INFO] - Training Epoch: 1/2, step 4145/107898 completed (loss: 0.346517950296402, acc: 0.9285714030265808)
[2025-02-17 16:50:41,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:41,223][root][INFO] - Training Epoch: 1/2, step 4146/107898 completed (loss: 0.4949384927749634, acc: 0.8888888955116272)
[2025-02-17 16:50:41,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:41,575][root][INFO] - Training Epoch: 1/2, step 4147/107898 completed (loss: 1.3255608081817627, acc: 0.6499999761581421)
[2025-02-17 16:50:41,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:41,940][root][INFO] - Training Epoch: 1/2, step 4148/107898 completed (loss: 4.608362674713135, acc: 0.25)
[2025-02-17 16:50:42,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:42,278][root][INFO] - Training Epoch: 1/2, step 4149/107898 completed (loss: 0.32924115657806396, acc: 0.8947368264198303)
[2025-02-17 16:50:42,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:42,575][root][INFO] - Training Epoch: 1/2, step 4150/107898 completed (loss: 1.0617917776107788, acc: 0.5)
[2025-02-17 16:50:42,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:42,886][root][INFO] - Training Epoch: 1/2, step 4151/107898 completed (loss: 0.6035521030426025, acc: 0.9090909361839294)
[2025-02-17 16:50:42,974][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:43,218][root][INFO] - Training Epoch: 1/2, step 4152/107898 completed (loss: 0.45605388283729553, acc: 0.7777777910232544)
[2025-02-17 16:50:43,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:43,596][root][INFO] - Training Epoch: 1/2, step 4153/107898 completed (loss: 0.33148249983787537, acc: 0.9210526347160339)
[2025-02-17 16:50:43,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:43,972][root][INFO] - Training Epoch: 1/2, step 4154/107898 completed (loss: 3.3067684173583984, acc: 0.2777777910232544)
[2025-02-17 16:50:44,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:44,311][root][INFO] - Training Epoch: 1/2, step 4155/107898 completed (loss: 1.3594067096710205, acc: 0.6666666865348816)
[2025-02-17 16:50:44,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:44,650][root][INFO] - Training Epoch: 1/2, step 4156/107898 completed (loss: 1.1455062627792358, acc: 0.8260869383811951)
[2025-02-17 16:50:44,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:45,018][root][INFO] - Training Epoch: 1/2, step 4157/107898 completed (loss: 1.1249498128890991, acc: 0.7142857313156128)
[2025-02-17 16:50:45,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:45,333][root][INFO] - Training Epoch: 1/2, step 4158/107898 completed (loss: 0.08365335315465927, acc: 1.0)
[2025-02-17 16:50:45,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:45,699][root][INFO] - Training Epoch: 1/2, step 4159/107898 completed (loss: 0.18849584460258484, acc: 1.0)
[2025-02-17 16:50:45,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:46,077][root][INFO] - Training Epoch: 1/2, step 4160/107898 completed (loss: 0.6815826296806335, acc: 0.8823529481887817)
[2025-02-17 16:50:46,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:46,422][root][INFO] - Training Epoch: 1/2, step 4161/107898 completed (loss: 0.8097025752067566, acc: 0.75)
[2025-02-17 16:50:46,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:46,760][root][INFO] - Training Epoch: 1/2, step 4162/107898 completed (loss: 1.1026949882507324, acc: 0.9166666865348816)
[2025-02-17 16:50:46,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:47,069][root][INFO] - Training Epoch: 1/2, step 4163/107898 completed (loss: 0.060772430151700974, acc: 1.0)
[2025-02-17 16:50:47,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:47,383][root][INFO] - Training Epoch: 1/2, step 4164/107898 completed (loss: 0.3712567090988159, acc: 0.8846153616905212)
[2025-02-17 16:50:47,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:47,704][root][INFO] - Training Epoch: 1/2, step 4165/107898 completed (loss: 1.3478747606277466, acc: 0.6470588445663452)
[2025-02-17 16:50:47,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:48,039][root][INFO] - Training Epoch: 1/2, step 4166/107898 completed (loss: 2.714287757873535, acc: 0.5)
[2025-02-17 16:50:48,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:48,394][root][INFO] - Training Epoch: 1/2, step 4167/107898 completed (loss: 0.9563175439834595, acc: 0.800000011920929)
[2025-02-17 16:50:48,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:48,805][root][INFO] - Training Epoch: 1/2, step 4168/107898 completed (loss: 0.9535477757453918, acc: 0.8064516186714172)
[2025-02-17 16:50:48,901][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:49,144][root][INFO] - Training Epoch: 1/2, step 4169/107898 completed (loss: 0.002357468707486987, acc: 1.0)
[2025-02-17 16:50:49,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:49,485][root][INFO] - Training Epoch: 1/2, step 4170/107898 completed (loss: 1.9434806108474731, acc: 0.6428571343421936)
[2025-02-17 16:50:49,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:49,803][root][INFO] - Training Epoch: 1/2, step 4171/107898 completed (loss: 0.9528117775917053, acc: 0.875)
[2025-02-17 16:50:49,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:50,133][root][INFO] - Training Epoch: 1/2, step 4172/107898 completed (loss: 1.7452237606048584, acc: 0.5)
[2025-02-17 16:50:50,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:50,461][root][INFO] - Training Epoch: 1/2, step 4173/107898 completed (loss: 4.031122207641602, acc: 0.23076923191547394)
[2025-02-17 16:50:50,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:50,781][root][INFO] - Training Epoch: 1/2, step 4174/107898 completed (loss: 1.715699315071106, acc: 0.75)
[2025-02-17 16:50:50,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:51,112][root][INFO] - Training Epoch: 1/2, step 4175/107898 completed (loss: 3.9697206020355225, acc: 0.3333333432674408)
[2025-02-17 16:50:51,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:51,456][root][INFO] - Training Epoch: 1/2, step 4176/107898 completed (loss: 0.00969003327190876, acc: 1.0)
[2025-02-17 16:50:51,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:51,783][root][INFO] - Training Epoch: 1/2, step 4177/107898 completed (loss: 0.47037509083747864, acc: 0.8666666746139526)
[2025-02-17 16:50:51,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:52,099][root][INFO] - Training Epoch: 1/2, step 4178/107898 completed (loss: 0.20056986808776855, acc: 1.0)
[2025-02-17 16:50:52,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:52,392][root][INFO] - Training Epoch: 1/2, step 4179/107898 completed (loss: 0.32885029911994934, acc: 0.8888888955116272)
[2025-02-17 16:50:52,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:52,702][root][INFO] - Training Epoch: 1/2, step 4180/107898 completed (loss: 0.003957442939281464, acc: 1.0)
[2025-02-17 16:50:52,809][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:53,037][root][INFO] - Training Epoch: 1/2, step 4181/107898 completed (loss: 1.5429658889770508, acc: 0.6296296119689941)
[2025-02-17 16:50:53,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:53,359][root][INFO] - Training Epoch: 1/2, step 4182/107898 completed (loss: 1.1652591228485107, acc: 0.800000011920929)
[2025-02-17 16:50:53,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:53,732][root][INFO] - Training Epoch: 1/2, step 4183/107898 completed (loss: 3.9776804447174072, acc: 0.3103448152542114)
[2025-02-17 16:50:53,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:54,052][root][INFO] - Training Epoch: 1/2, step 4184/107898 completed (loss: 0.24223357439041138, acc: 0.9090909361839294)
[2025-02-17 16:50:54,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:54,370][root][INFO] - Training Epoch: 1/2, step 4185/107898 completed (loss: 0.7971587777137756, acc: 0.8214285969734192)
[2025-02-17 16:50:54,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:54,671][root][INFO] - Training Epoch: 1/2, step 4186/107898 completed (loss: 1.9609569311141968, acc: 0.550000011920929)
[2025-02-17 16:50:54,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:55,009][root][INFO] - Training Epoch: 1/2, step 4187/107898 completed (loss: 0.022350510582327843, acc: 1.0)
[2025-02-17 16:50:55,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:55,359][root][INFO] - Training Epoch: 1/2, step 4188/107898 completed (loss: 0.6740390062332153, acc: 0.8636363744735718)
[2025-02-17 16:50:55,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:55,665][root][INFO] - Training Epoch: 1/2, step 4189/107898 completed (loss: 0.17324471473693848, acc: 0.9090909361839294)
[2025-02-17 16:50:55,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:56,006][root][INFO] - Training Epoch: 1/2, step 4190/107898 completed (loss: 0.30448976159095764, acc: 1.0)
[2025-02-17 16:50:56,104][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:56,338][root][INFO] - Training Epoch: 1/2, step 4191/107898 completed (loss: 0.7207769155502319, acc: 0.90625)
[2025-02-17 16:50:56,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:56,643][root][INFO] - Training Epoch: 1/2, step 4192/107898 completed (loss: 3.2696597576141357, acc: 0.1428571492433548)
[2025-02-17 16:50:56,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:56,947][root][INFO] - Training Epoch: 1/2, step 4193/107898 completed (loss: 1.6172511577606201, acc: 0.7857142686843872)
[2025-02-17 16:50:57,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:57,256][root][INFO] - Training Epoch: 1/2, step 4194/107898 completed (loss: 2.0289151668548584, acc: 0.4615384638309479)
[2025-02-17 16:50:57,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:57,569][root][INFO] - Training Epoch: 1/2, step 4195/107898 completed (loss: 1.8001669645309448, acc: 0.6363636255264282)
[2025-02-17 16:50:57,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:57,876][root][INFO] - Training Epoch: 1/2, step 4196/107898 completed (loss: 0.12313160300254822, acc: 1.0)
[2025-02-17 16:50:57,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:58,170][root][INFO] - Training Epoch: 1/2, step 4197/107898 completed (loss: 1.113388180732727, acc: 0.5)
[2025-02-17 16:50:58,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:58,473][root][INFO] - Training Epoch: 1/2, step 4198/107898 completed (loss: 1.1654335260391235, acc: 0.75)
[2025-02-17 16:50:58,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:58,797][root][INFO] - Training Epoch: 1/2, step 4199/107898 completed (loss: 0.29735249280929565, acc: 0.9655172228813171)
[2025-02-17 16:50:58,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:59,130][root][INFO] - Training Epoch: 1/2, step 4200/107898 completed (loss: 1.485713243484497, acc: 0.5)
[2025-02-17 16:50:59,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:59,479][root][INFO] - Training Epoch: 1/2, step 4201/107898 completed (loss: 0.5208764672279358, acc: 0.75)
[2025-02-17 16:50:59,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:50:59,808][root][INFO] - Training Epoch: 1/2, step 4202/107898 completed (loss: 0.5304503440856934, acc: 0.9375)
[2025-02-17 16:50:59,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:00,112][root][INFO] - Training Epoch: 1/2, step 4203/107898 completed (loss: 0.6615766286849976, acc: 0.7777777910232544)
[2025-02-17 16:51:00,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:00,427][root][INFO] - Training Epoch: 1/2, step 4204/107898 completed (loss: 0.8482913374900818, acc: 0.807692289352417)
[2025-02-17 16:51:00,503][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:00,734][root][INFO] - Training Epoch: 1/2, step 4205/107898 completed (loss: 2.3647148609161377, acc: 0.5384615659713745)
[2025-02-17 16:51:00,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:01,055][root][INFO] - Training Epoch: 1/2, step 4206/107898 completed (loss: 2.8046624660491943, acc: 0.6666666865348816)
[2025-02-17 16:51:01,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:01,361][root][INFO] - Training Epoch: 1/2, step 4207/107898 completed (loss: 0.23956826329231262, acc: 1.0)
[2025-02-17 16:51:01,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:01,668][root][INFO] - Training Epoch: 1/2, step 4208/107898 completed (loss: 0.7317394018173218, acc: 0.800000011920929)
[2025-02-17 16:51:01,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:01,997][root][INFO] - Training Epoch: 1/2, step 4209/107898 completed (loss: 3.587512969970703, acc: 0.3333333432674408)
[2025-02-17 16:51:02,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:02,312][root][INFO] - Training Epoch: 1/2, step 4210/107898 completed (loss: 0.2984314560890198, acc: 0.8999999761581421)
[2025-02-17 16:51:02,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:02,628][root][INFO] - Training Epoch: 1/2, step 4211/107898 completed (loss: 0.242370143532753, acc: 1.0)
[2025-02-17 16:51:02,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:02,948][root][INFO] - Training Epoch: 1/2, step 4212/107898 completed (loss: 4.381871700286865, acc: 0.3333333432674408)
[2025-02-17 16:51:03,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:03,257][root][INFO] - Training Epoch: 1/2, step 4213/107898 completed (loss: 0.004985283128917217, acc: 1.0)
[2025-02-17 16:51:03,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:03,555][root][INFO] - Training Epoch: 1/2, step 4214/107898 completed (loss: 0.9684847593307495, acc: 0.8888888955116272)
[2025-02-17 16:51:03,631][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:03,846][root][INFO] - Training Epoch: 1/2, step 4215/107898 completed (loss: 0.001992609119042754, acc: 1.0)
[2025-02-17 16:51:03,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:04,150][root][INFO] - Training Epoch: 1/2, step 4216/107898 completed (loss: 0.6687930226325989, acc: 0.875)
[2025-02-17 16:51:04,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:04,477][root][INFO] - Training Epoch: 1/2, step 4217/107898 completed (loss: 1.9083424806594849, acc: 0.5)
[2025-02-17 16:51:04,564][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:04,781][root][INFO] - Training Epoch: 1/2, step 4218/107898 completed (loss: 0.2277432233095169, acc: 1.0)
[2025-02-17 16:51:04,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:05,077][root][INFO] - Training Epoch: 1/2, step 4219/107898 completed (loss: 0.8144019842147827, acc: 0.7692307829856873)
[2025-02-17 16:51:05,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:05,376][root][INFO] - Training Epoch: 1/2, step 4220/107898 completed (loss: 0.7036113739013672, acc: 0.8500000238418579)
[2025-02-17 16:51:05,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:05,674][root][INFO] - Training Epoch: 1/2, step 4221/107898 completed (loss: 0.02130741998553276, acc: 1.0)
[2025-02-17 16:51:05,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:05,972][root][INFO] - Training Epoch: 1/2, step 4222/107898 completed (loss: 0.5615302920341492, acc: 1.0)
[2025-02-17 16:51:06,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:06,262][root][INFO] - Training Epoch: 1/2, step 4223/107898 completed (loss: 1.8855081796646118, acc: 0.6000000238418579)
[2025-02-17 16:51:06,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:06,562][root][INFO] - Training Epoch: 1/2, step 4224/107898 completed (loss: 2.0582871437072754, acc: 0.5384615659713745)
[2025-02-17 16:51:06,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:06,861][root][INFO] - Training Epoch: 1/2, step 4225/107898 completed (loss: 0.19790302217006683, acc: 1.0)
[2025-02-17 16:51:06,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:07,191][root][INFO] - Training Epoch: 1/2, step 4226/107898 completed (loss: 0.14690008759498596, acc: 1.0)
[2025-02-17 16:51:07,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:07,500][root][INFO] - Training Epoch: 1/2, step 4227/107898 completed (loss: 0.7566947937011719, acc: 0.8461538553237915)
[2025-02-17 16:51:07,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:07,800][root][INFO] - Training Epoch: 1/2, step 4228/107898 completed (loss: 0.9676666855812073, acc: 0.6666666865348816)
[2025-02-17 16:51:07,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:08,142][root][INFO] - Training Epoch: 1/2, step 4229/107898 completed (loss: 0.4930977523326874, acc: 0.9200000166893005)
[2025-02-17 16:51:08,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:08,481][root][INFO] - Training Epoch: 1/2, step 4230/107898 completed (loss: 0.46185755729675293, acc: 0.8125)
[2025-02-17 16:51:08,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:08,803][root][INFO] - Training Epoch: 1/2, step 4231/107898 completed (loss: 0.39029884338378906, acc: 0.9166666865348816)
[2025-02-17 16:51:08,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:09,132][root][INFO] - Training Epoch: 1/2, step 4232/107898 completed (loss: 0.0059485770761966705, acc: 1.0)
[2025-02-17 16:51:09,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:09,452][root][INFO] - Training Epoch: 1/2, step 4233/107898 completed (loss: 4.537468910217285, acc: 0.1599999964237213)
[2025-02-17 16:51:09,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:09,766][root][INFO] - Training Epoch: 1/2, step 4234/107898 completed (loss: 4.945007801055908, acc: 0.3333333432674408)
[2025-02-17 16:51:09,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:10,050][root][INFO] - Training Epoch: 1/2, step 4235/107898 completed (loss: 0.40895459055900574, acc: 0.6666666865348816)
[2025-02-17 16:51:10,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:10,353][root][INFO] - Training Epoch: 1/2, step 4236/107898 completed (loss: 1.472414493560791, acc: 0.5789473652839661)
[2025-02-17 16:51:10,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:10,667][root][INFO] - Training Epoch: 1/2, step 4237/107898 completed (loss: 0.622566819190979, acc: 0.8421052694320679)
[2025-02-17 16:51:10,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:10,993][root][INFO] - Training Epoch: 1/2, step 4238/107898 completed (loss: 1.0206841230392456, acc: 0.7894737124443054)
[2025-02-17 16:51:11,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:11,313][root][INFO] - Training Epoch: 1/2, step 4239/107898 completed (loss: 1.6705695390701294, acc: 0.6666666865348816)
[2025-02-17 16:51:11,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:11,612][root][INFO] - Training Epoch: 1/2, step 4240/107898 completed (loss: 2.7331395149230957, acc: 0.625)
[2025-02-17 16:51:11,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:11,904][root][INFO] - Training Epoch: 1/2, step 4241/107898 completed (loss: 0.6422762274742126, acc: 0.5)
[2025-02-17 16:51:11,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:12,235][root][INFO] - Training Epoch: 1/2, step 4242/107898 completed (loss: 0.033293016254901886, acc: 1.0)
[2025-02-17 16:51:12,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:12,533][root][INFO] - Training Epoch: 1/2, step 4243/107898 completed (loss: 0.004948681220412254, acc: 1.0)
[2025-02-17 16:51:12,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:12,882][root][INFO] - Training Epoch: 1/2, step 4244/107898 completed (loss: 0.0046411799266934395, acc: 1.0)
[2025-02-17 16:51:12,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:13,210][root][INFO] - Training Epoch: 1/2, step 4245/107898 completed (loss: 1.804227352142334, acc: 0.6129032373428345)
[2025-02-17 16:51:13,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:13,516][root][INFO] - Training Epoch: 1/2, step 4246/107898 completed (loss: 0.29194265604019165, acc: 1.0)
[2025-02-17 16:51:13,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:13,840][root][INFO] - Training Epoch: 1/2, step 4247/107898 completed (loss: 1.752577781677246, acc: 0.8125)
[2025-02-17 16:51:13,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:14,148][root][INFO] - Training Epoch: 1/2, step 4248/107898 completed (loss: 4.823896884918213, acc: 0.4000000059604645)
[2025-02-17 16:51:14,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:14,450][root][INFO] - Training Epoch: 1/2, step 4249/107898 completed (loss: 3.615159034729004, acc: 0.3333333432674408)
[2025-02-17 16:51:14,528][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:14,743][root][INFO] - Training Epoch: 1/2, step 4250/107898 completed (loss: 0.27450084686279297, acc: 1.0)
[2025-02-17 16:51:14,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:15,044][root][INFO] - Training Epoch: 1/2, step 4251/107898 completed (loss: 1.376939296722412, acc: 0.7083333134651184)
[2025-02-17 16:51:15,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:15,348][root][INFO] - Training Epoch: 1/2, step 4252/107898 completed (loss: 3.3082611560821533, acc: 0.1111111119389534)
[2025-02-17 16:51:15,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:15,658][root][INFO] - Training Epoch: 1/2, step 4253/107898 completed (loss: 4.049892902374268, acc: 0.25)
[2025-02-17 16:51:15,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:15,958][root][INFO] - Training Epoch: 1/2, step 4254/107898 completed (loss: 1.3738867044448853, acc: 0.6000000238418579)
[2025-02-17 16:51:16,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:16,261][root][INFO] - Training Epoch: 1/2, step 4255/107898 completed (loss: 2.048173189163208, acc: 0.695652186870575)
[2025-02-17 16:51:16,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:16,567][root][INFO] - Training Epoch: 1/2, step 4256/107898 completed (loss: 0.5231920480728149, acc: 0.8333333134651184)
[2025-02-17 16:51:16,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:16,864][root][INFO] - Training Epoch: 1/2, step 4257/107898 completed (loss: 0.9388589262962341, acc: 0.7777777910232544)
[2025-02-17 16:51:16,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:17,164][root][INFO] - Training Epoch: 1/2, step 4258/107898 completed (loss: 0.18441089987754822, acc: 1.0)
[2025-02-17 16:51:17,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:17,462][root][INFO] - Training Epoch: 1/2, step 4259/107898 completed (loss: 3.219325065612793, acc: 0.3333333432674408)
[2025-02-17 16:51:17,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:17,763][root][INFO] - Training Epoch: 1/2, step 4260/107898 completed (loss: 0.5465976595878601, acc: 0.9375)
[2025-02-17 16:51:17,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:18,064][root][INFO] - Training Epoch: 1/2, step 4261/107898 completed (loss: 0.18898998200893402, acc: 1.0)
[2025-02-17 16:51:18,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:18,365][root][INFO] - Training Epoch: 1/2, step 4262/107898 completed (loss: 1.7031792402267456, acc: 0.5)
[2025-02-17 16:51:18,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:18,671][root][INFO] - Training Epoch: 1/2, step 4263/107898 completed (loss: 4.579163074493408, acc: 0.25)
[2025-02-17 16:51:18,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:18,978][root][INFO] - Training Epoch: 1/2, step 4264/107898 completed (loss: 0.6990579962730408, acc: 0.949999988079071)
[2025-02-17 16:51:19,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:19,292][root][INFO] - Training Epoch: 1/2, step 4265/107898 completed (loss: 0.08802293241024017, acc: 1.0)
[2025-02-17 16:51:19,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:19,587][root][INFO] - Training Epoch: 1/2, step 4266/107898 completed (loss: 1.5833877325057983, acc: 0.8333333134651184)
[2025-02-17 16:51:19,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:19,896][root][INFO] - Training Epoch: 1/2, step 4267/107898 completed (loss: 0.03594236448407173, acc: 1.0)
[2025-02-17 16:51:19,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:20,205][root][INFO] - Training Epoch: 1/2, step 4268/107898 completed (loss: 0.8045011162757874, acc: 0.8666666746139526)
[2025-02-17 16:51:20,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:20,466][root][INFO] - Training Epoch: 1/2, step 4269/107898 completed (loss: 0.10794039815664291, acc: 1.0)
[2025-02-17 16:51:20,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:20,732][root][INFO] - Training Epoch: 1/2, step 4270/107898 completed (loss: 0.021838029846549034, acc: 1.0)
[2025-02-17 16:51:20,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:21,025][root][INFO] - Training Epoch: 1/2, step 4271/107898 completed (loss: 0.6602797508239746, acc: 1.0)
[2025-02-17 16:51:21,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:21,320][root][INFO] - Training Epoch: 1/2, step 4272/107898 completed (loss: 2.574605941772461, acc: 0.5)
[2025-02-17 16:51:21,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:21,625][root][INFO] - Training Epoch: 1/2, step 4273/107898 completed (loss: 0.4643031358718872, acc: 0.875)
[2025-02-17 16:51:21,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:21,955][root][INFO] - Training Epoch: 1/2, step 4274/107898 completed (loss: 1.3187296390533447, acc: 0.7586206793785095)
[2025-02-17 16:51:22,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:22,248][root][INFO] - Training Epoch: 1/2, step 4275/107898 completed (loss: 0.09179254621267319, acc: 1.0)
[2025-02-17 16:51:22,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:22,584][root][INFO] - Training Epoch: 1/2, step 4276/107898 completed (loss: 4.896224021911621, acc: 0.2068965584039688)
[2025-02-17 16:51:22,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:22,878][root][INFO] - Training Epoch: 1/2, step 4277/107898 completed (loss: 1.2132362127304077, acc: 0.5)
[2025-02-17 16:51:22,959][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:23,176][root][INFO] - Training Epoch: 1/2, step 4278/107898 completed (loss: 0.9134241938591003, acc: 0.800000011920929)
[2025-02-17 16:51:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:23,475][root][INFO] - Training Epoch: 1/2, step 4279/107898 completed (loss: 1.4114739894866943, acc: 0.75)
[2025-02-17 16:51:23,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:23,773][root][INFO] - Training Epoch: 1/2, step 4280/107898 completed (loss: 3.022458553314209, acc: 0.5)
[2025-02-17 16:51:23,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:24,095][root][INFO] - Training Epoch: 1/2, step 4281/107898 completed (loss: 0.4371802806854248, acc: 0.9166666865348816)
[2025-02-17 16:51:24,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:24,393][root][INFO] - Training Epoch: 1/2, step 4282/107898 completed (loss: 1.5418152809143066, acc: 0.800000011920929)
[2025-02-17 16:51:24,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:24,704][root][INFO] - Training Epoch: 1/2, step 4283/107898 completed (loss: 0.0015382185811176896, acc: 1.0)
[2025-02-17 16:51:24,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:25,083][root][INFO] - Training Epoch: 1/2, step 4284/107898 completed (loss: 1.127313494682312, acc: 0.8333333134651184)
[2025-02-17 16:51:25,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:25,405][root][INFO] - Training Epoch: 1/2, step 4285/107898 completed (loss: 0.07938862591981888, acc: 1.0)
[2025-02-17 16:51:25,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:25,726][root][INFO] - Training Epoch: 1/2, step 4286/107898 completed (loss: 0.09246735274791718, acc: 1.0)
[2025-02-17 16:51:25,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:26,024][root][INFO] - Training Epoch: 1/2, step 4287/107898 completed (loss: 0.2743236720561981, acc: 0.9130434989929199)
[2025-02-17 16:51:26,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:26,337][root][INFO] - Training Epoch: 1/2, step 4288/107898 completed (loss: 0.8804593086242676, acc: 0.5)
[2025-02-17 16:51:26,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:26,658][root][INFO] - Training Epoch: 1/2, step 4289/107898 completed (loss: 3.9975829124450684, acc: 0.11999999731779099)
[2025-02-17 16:51:26,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:26,964][root][INFO] - Training Epoch: 1/2, step 4290/107898 completed (loss: 0.493390828371048, acc: 0.7142857313156128)
[2025-02-17 16:51:27,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:27,258][root][INFO] - Training Epoch: 1/2, step 4291/107898 completed (loss: 0.004521505907177925, acc: 1.0)
[2025-02-17 16:51:27,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:27,552][root][INFO] - Training Epoch: 1/2, step 4292/107898 completed (loss: 1.1948219537734985, acc: 0.6666666865348816)
[2025-02-17 16:51:27,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:27,859][root][INFO] - Training Epoch: 1/2, step 4293/107898 completed (loss: 1.504678726196289, acc: 0.5882353186607361)
[2025-02-17 16:51:27,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:28,164][root][INFO] - Training Epoch: 1/2, step 4294/107898 completed (loss: 0.40919753909111023, acc: 0.9285714030265808)
[2025-02-17 16:51:28,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:28,493][root][INFO] - Training Epoch: 1/2, step 4295/107898 completed (loss: 0.0035860897041857243, acc: 1.0)
[2025-02-17 16:51:28,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:28,804][root][INFO] - Training Epoch: 1/2, step 4296/107898 completed (loss: 3.0928966999053955, acc: 0.5)
[2025-02-17 16:51:28,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:29,119][root][INFO] - Training Epoch: 1/2, step 4297/107898 completed (loss: 0.9175679087638855, acc: 0.761904776096344)
[2025-02-17 16:51:29,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:29,416][root][INFO] - Training Epoch: 1/2, step 4298/107898 completed (loss: 1.3628637790679932, acc: 0.7333333492279053)
[2025-02-17 16:51:29,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:29,774][root][INFO] - Training Epoch: 1/2, step 4299/107898 completed (loss: 1.5369915962219238, acc: 0.7272727489471436)
[2025-02-17 16:51:29,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:30,138][root][INFO] - Training Epoch: 1/2, step 4300/107898 completed (loss: 1.351088523864746, acc: 0.75)
[2025-02-17 16:51:30,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:30,482][root][INFO] - Training Epoch: 1/2, step 4301/107898 completed (loss: 0.0443640872836113, acc: 1.0)
[2025-02-17 16:51:30,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:30,779][root][INFO] - Training Epoch: 1/2, step 4302/107898 completed (loss: 3.1967244148254395, acc: 0.3333333432674408)
[2025-02-17 16:51:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:31,082][root][INFO] - Training Epoch: 1/2, step 4303/107898 completed (loss: 0.9283490180969238, acc: 0.8333333134651184)
[2025-02-17 16:51:31,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:31,396][root][INFO] - Training Epoch: 1/2, step 4304/107898 completed (loss: 0.9238778948783875, acc: 0.8571428656578064)
[2025-02-17 16:51:31,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:31,737][root][INFO] - Training Epoch: 1/2, step 4305/107898 completed (loss: 1.6375329494476318, acc: 0.6785714030265808)
[2025-02-17 16:51:31,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:32,044][root][INFO] - Training Epoch: 1/2, step 4306/107898 completed (loss: 2.4090542793273926, acc: 0.4000000059604645)
[2025-02-17 16:51:32,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:32,350][root][INFO] - Training Epoch: 1/2, step 4307/107898 completed (loss: 0.8037837743759155, acc: 0.8095238208770752)
[2025-02-17 16:51:32,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:32,725][root][INFO] - Training Epoch: 1/2, step 4308/107898 completed (loss: 0.3590695858001709, acc: 0.8421052694320679)
[2025-02-17 16:51:32,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:33,086][root][INFO] - Training Epoch: 1/2, step 4309/107898 completed (loss: 3.172872304916382, acc: 0.3333333432674408)
[2025-02-17 16:51:33,185][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:33,411][root][INFO] - Training Epoch: 1/2, step 4310/107898 completed (loss: 2.514638900756836, acc: 0.5)
[2025-02-17 16:51:33,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:33,722][root][INFO] - Training Epoch: 1/2, step 4311/107898 completed (loss: 0.12046631425619125, acc: 1.0)
[2025-02-17 16:51:33,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:34,073][root][INFO] - Training Epoch: 1/2, step 4312/107898 completed (loss: 0.8653839230537415, acc: 0.75)
[2025-02-17 16:51:34,195][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:34,440][root][INFO] - Training Epoch: 1/2, step 4313/107898 completed (loss: 1.2614686489105225, acc: 0.75)
[2025-02-17 16:51:34,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:34,838][root][INFO] - Training Epoch: 1/2, step 4314/107898 completed (loss: 0.242884561419487, acc: 0.9666666388511658)
[2025-02-17 16:51:34,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:35,242][root][INFO] - Training Epoch: 1/2, step 4315/107898 completed (loss: 0.15666534006595612, acc: 0.9677419066429138)
[2025-02-17 16:51:35,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:35,596][root][INFO] - Training Epoch: 1/2, step 4316/107898 completed (loss: 0.26281797885894775, acc: 0.8888888955116272)
[2025-02-17 16:51:35,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:35,952][root][INFO] - Training Epoch: 1/2, step 4317/107898 completed (loss: 2.5085668563842773, acc: 0.529411792755127)
[2025-02-17 16:51:36,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:36,311][root][INFO] - Training Epoch: 1/2, step 4318/107898 completed (loss: 0.2888447344303131, acc: 1.0)
[2025-02-17 16:51:36,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:36,660][root][INFO] - Training Epoch: 1/2, step 4319/107898 completed (loss: 0.055214352905750275, acc: 1.0)
[2025-02-17 16:51:36,757][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:36,997][root][INFO] - Training Epoch: 1/2, step 4320/107898 completed (loss: 0.5448895692825317, acc: 0.8823529481887817)
[2025-02-17 16:51:37,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:37,360][root][INFO] - Training Epoch: 1/2, step 4321/107898 completed (loss: 2.2102599143981934, acc: 0.5)
[2025-02-17 16:51:37,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:37,710][root][INFO] - Training Epoch: 1/2, step 4322/107898 completed (loss: 1.315687656402588, acc: 0.6666666865348816)
[2025-02-17 16:51:37,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:38,047][root][INFO] - Training Epoch: 1/2, step 4323/107898 completed (loss: 2.606008291244507, acc: 0.5)
[2025-02-17 16:51:38,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:38,380][root][INFO] - Training Epoch: 1/2, step 4324/107898 completed (loss: 1.7430628538131714, acc: 0.6666666865348816)
[2025-02-17 16:51:38,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:38,738][root][INFO] - Training Epoch: 1/2, step 4325/107898 completed (loss: 0.6887021660804749, acc: 0.6666666865348816)
[2025-02-17 16:51:38,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:39,063][root][INFO] - Training Epoch: 1/2, step 4326/107898 completed (loss: 5.677955627441406, acc: 0.5)
[2025-02-17 16:51:39,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:39,392][root][INFO] - Training Epoch: 1/2, step 4327/107898 completed (loss: 0.690976083278656, acc: 0.800000011920929)
[2025-02-17 16:51:39,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:39,720][root][INFO] - Training Epoch: 1/2, step 4328/107898 completed (loss: 0.18787555396556854, acc: 1.0)
[2025-02-17 16:51:39,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:40,100][root][INFO] - Training Epoch: 1/2, step 4329/107898 completed (loss: 1.124179482460022, acc: 0.7058823704719543)
[2025-02-17 16:51:40,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:40,414][root][INFO] - Training Epoch: 1/2, step 4330/107898 completed (loss: 2.7684147357940674, acc: 0.4000000059604645)
[2025-02-17 16:51:40,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:40,758][root][INFO] - Training Epoch: 1/2, step 4331/107898 completed (loss: 0.7660692930221558, acc: 0.8571428656578064)
[2025-02-17 16:51:40,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:41,056][root][INFO] - Training Epoch: 1/2, step 4332/107898 completed (loss: 3.9234864711761475, acc: 0.0)
[2025-02-17 16:51:41,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:41,378][root][INFO] - Training Epoch: 1/2, step 4333/107898 completed (loss: 3.2203288078308105, acc: 0.30000001192092896)
[2025-02-17 16:51:41,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:41,675][root][INFO] - Training Epoch: 1/2, step 4334/107898 completed (loss: 0.027633916586637497, acc: 1.0)
[2025-02-17 16:51:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:41,980][root][INFO] - Training Epoch: 1/2, step 4335/107898 completed (loss: 0.7656418085098267, acc: 0.8421052694320679)
[2025-02-17 16:51:42,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:42,291][root][INFO] - Training Epoch: 1/2, step 4336/107898 completed (loss: 0.13414664566516876, acc: 1.0)
[2025-02-17 16:51:42,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:42,605][root][INFO] - Training Epoch: 1/2, step 4337/107898 completed (loss: 3.722817897796631, acc: 0.4000000059604645)
[2025-02-17 16:51:42,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:42,903][root][INFO] - Training Epoch: 1/2, step 4338/107898 completed (loss: 0.00617506168782711, acc: 1.0)
[2025-02-17 16:51:42,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:43,212][root][INFO] - Training Epoch: 1/2, step 4339/107898 completed (loss: 0.898709774017334, acc: 0.8695651888847351)
[2025-02-17 16:51:43,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:43,551][root][INFO] - Training Epoch: 1/2, step 4340/107898 completed (loss: 1.3302725553512573, acc: 0.6666666865348816)
[2025-02-17 16:51:43,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:43,920][root][INFO] - Training Epoch: 1/2, step 4341/107898 completed (loss: 1.1554292440414429, acc: 0.75)
[2025-02-17 16:51:44,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:44,234][root][INFO] - Training Epoch: 1/2, step 4342/107898 completed (loss: 0.38119953870773315, acc: 1.0)
[2025-02-17 16:51:44,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:44,510][root][INFO] - Training Epoch: 1/2, step 4343/107898 completed (loss: 0.3308775722980499, acc: 0.9375)
[2025-02-17 16:51:44,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:44,787][root][INFO] - Training Epoch: 1/2, step 4344/107898 completed (loss: 0.07985233515501022, acc: 1.0)
[2025-02-17 16:51:44,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:45,078][root][INFO] - Training Epoch: 1/2, step 4345/107898 completed (loss: 1.023176670074463, acc: 0.5)
[2025-02-17 16:51:45,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:45,371][root][INFO] - Training Epoch: 1/2, step 4346/107898 completed (loss: 3.4108643531799316, acc: 0.4000000059604645)
[2025-02-17 16:51:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:45,691][root][INFO] - Training Epoch: 1/2, step 4347/107898 completed (loss: 1.9018839597702026, acc: 0.7058823704719543)
[2025-02-17 16:51:45,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:46,005][root][INFO] - Training Epoch: 1/2, step 4348/107898 completed (loss: 0.2021855264902115, acc: 1.0)
[2025-02-17 16:51:46,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:46,348][root][INFO] - Training Epoch: 1/2, step 4349/107898 completed (loss: 2.765446424484253, acc: 0.4000000059604645)
[2025-02-17 16:51:46,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:46,677][root][INFO] - Training Epoch: 1/2, step 4350/107898 completed (loss: 0.13501067459583282, acc: 1.0)
[2025-02-17 16:51:46,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:47,026][root][INFO] - Training Epoch: 1/2, step 4351/107898 completed (loss: 0.1239563599228859, acc: 1.0)
[2025-02-17 16:51:47,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:47,350][root][INFO] - Training Epoch: 1/2, step 4352/107898 completed (loss: 0.0023904331028461456, acc: 1.0)
[2025-02-17 16:51:47,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:47,657][root][INFO] - Training Epoch: 1/2, step 4353/107898 completed (loss: 1.9470893144607544, acc: 0.8333333134651184)
[2025-02-17 16:51:47,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:47,955][root][INFO] - Training Epoch: 1/2, step 4354/107898 completed (loss: 0.6575211882591248, acc: 0.5)
[2025-02-17 16:51:48,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:48,256][root][INFO] - Training Epoch: 1/2, step 4355/107898 completed (loss: 1.2960237264633179, acc: 0.6666666865348816)
[2025-02-17 16:51:48,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:48,567][root][INFO] - Training Epoch: 1/2, step 4356/107898 completed (loss: 0.7204620838165283, acc: 0.6666666865348816)
[2025-02-17 16:51:48,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:48,905][root][INFO] - Training Epoch: 1/2, step 4357/107898 completed (loss: 2.7618792057037354, acc: 0.5454545617103577)
[2025-02-17 16:51:49,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:49,240][root][INFO] - Training Epoch: 1/2, step 4358/107898 completed (loss: 0.6573558449745178, acc: 1.0)
[2025-02-17 16:51:49,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:49,532][root][INFO] - Training Epoch: 1/2, step 4359/107898 completed (loss: 0.04599321633577347, acc: 1.0)
[2025-02-17 16:51:49,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:49,829][root][INFO] - Training Epoch: 1/2, step 4360/107898 completed (loss: 1.032759666442871, acc: 0.75)
[2025-02-17 16:51:49,896][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:50,106][root][INFO] - Training Epoch: 1/2, step 4361/107898 completed (loss: 1.7417436838150024, acc: 0.75)
[2025-02-17 16:51:50,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:50,411][root][INFO] - Training Epoch: 1/2, step 4362/107898 completed (loss: 0.9778798818588257, acc: 0.8999999761581421)
[2025-02-17 16:51:50,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:50,747][root][INFO] - Training Epoch: 1/2, step 4363/107898 completed (loss: 0.7092302441596985, acc: 0.8333333134651184)
[2025-02-17 16:51:50,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:51,054][root][INFO] - Training Epoch: 1/2, step 4364/107898 completed (loss: 0.4380066394805908, acc: 0.9166666865348816)
[2025-02-17 16:51:51,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:51,355][root][INFO] - Training Epoch: 1/2, step 4365/107898 completed (loss: 0.3669135868549347, acc: 0.9090909361839294)
[2025-02-17 16:51:51,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:51,653][root][INFO] - Training Epoch: 1/2, step 4366/107898 completed (loss: 0.6336879730224609, acc: 0.8965517282485962)
[2025-02-17 16:51:51,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:51,958][root][INFO] - Training Epoch: 1/2, step 4367/107898 completed (loss: 0.12196314334869385, acc: 1.0)
[2025-02-17 16:51:52,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:52,261][root][INFO] - Training Epoch: 1/2, step 4368/107898 completed (loss: 1.9090927839279175, acc: 0.6666666865348816)
[2025-02-17 16:51:52,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:52,569][root][INFO] - Training Epoch: 1/2, step 4369/107898 completed (loss: 0.00504713412374258, acc: 1.0)
[2025-02-17 16:51:52,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:52,860][root][INFO] - Training Epoch: 1/2, step 4370/107898 completed (loss: 3.869866371154785, acc: 0.375)
[2025-02-17 16:51:52,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:53,151][root][INFO] - Training Epoch: 1/2, step 4371/107898 completed (loss: 0.6753490567207336, acc: 0.75)
[2025-02-17 16:51:53,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:53,465][root][INFO] - Training Epoch: 1/2, step 4372/107898 completed (loss: 3.6166703701019287, acc: 0.22727273404598236)
[2025-02-17 16:51:53,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:53,774][root][INFO] - Training Epoch: 1/2, step 4373/107898 completed (loss: 0.9009670615196228, acc: 0.5)
[2025-02-17 16:51:53,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:54,060][root][INFO] - Training Epoch: 1/2, step 4374/107898 completed (loss: 0.7056475281715393, acc: 0.8571428656578064)
[2025-02-17 16:51:54,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:54,431][root][INFO] - Training Epoch: 1/2, step 4375/107898 completed (loss: 0.4898397624492645, acc: 0.9166666865348816)
[2025-02-17 16:51:54,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:54,751][root][INFO] - Training Epoch: 1/2, step 4376/107898 completed (loss: 2.689573049545288, acc: 0.5)
[2025-02-17 16:51:54,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:55,094][root][INFO] - Training Epoch: 1/2, step 4377/107898 completed (loss: 2.1702027320861816, acc: 0.5)
[2025-02-17 16:51:55,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:55,399][root][INFO] - Training Epoch: 1/2, step 4378/107898 completed (loss: 0.017338691279292107, acc: 1.0)
[2025-02-17 16:51:55,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:55,722][root][INFO] - Training Epoch: 1/2, step 4379/107898 completed (loss: 4.272763729095459, acc: 0.25)
[2025-02-17 16:51:55,813][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:56,034][root][INFO] - Training Epoch: 1/2, step 4380/107898 completed (loss: 1.8413258790969849, acc: 0.5)
[2025-02-17 16:51:56,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:56,382][root][INFO] - Training Epoch: 1/2, step 4381/107898 completed (loss: 0.08396439254283905, acc: 1.0)
[2025-02-17 16:51:56,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:56,716][root][INFO] - Training Epoch: 1/2, step 4382/107898 completed (loss: 0.749579668045044, acc: 0.5)
[2025-02-17 16:51:56,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:57,013][root][INFO] - Training Epoch: 1/2, step 4383/107898 completed (loss: 2.503640651702881, acc: 0.6000000238418579)
[2025-02-17 16:51:57,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:57,308][root][INFO] - Training Epoch: 1/2, step 4384/107898 completed (loss: 1.0487438440322876, acc: 0.6666666865348816)
[2025-02-17 16:51:57,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:57,617][root][INFO] - Training Epoch: 1/2, step 4385/107898 completed (loss: 1.0506271123886108, acc: 0.8125)
[2025-02-17 16:51:57,725][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:57,967][root][INFO] - Training Epoch: 1/2, step 4386/107898 completed (loss: 3.2158408164978027, acc: 0.30000001192092896)
[2025-02-17 16:51:58,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:58,319][root][INFO] - Training Epoch: 1/2, step 4387/107898 completed (loss: 0.40544629096984863, acc: 0.8333333134651184)
[2025-02-17 16:51:58,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:58,651][root][INFO] - Training Epoch: 1/2, step 4388/107898 completed (loss: 0.2786722183227539, acc: 0.9166666865348816)
[2025-02-17 16:51:58,737][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:58,956][root][INFO] - Training Epoch: 1/2, step 4389/107898 completed (loss: 0.4841894209384918, acc: 0.8666666746139526)
[2025-02-17 16:51:59,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:59,301][root][INFO] - Training Epoch: 1/2, step 4390/107898 completed (loss: 0.04696883261203766, acc: 1.0)
[2025-02-17 16:51:59,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:59,624][root][INFO] - Training Epoch: 1/2, step 4391/107898 completed (loss: 0.5717750787734985, acc: 0.8888888955116272)
[2025-02-17 16:51:59,694][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:51:59,880][root][INFO] - Training Epoch: 1/2, step 4392/107898 completed (loss: 0.032406825572252274, acc: 1.0)
[2025-02-17 16:51:59,977][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:00,191][root][INFO] - Training Epoch: 1/2, step 4393/107898 completed (loss: 2.336473226547241, acc: 0.6785714030265808)
[2025-02-17 16:52:00,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:00,449][root][INFO] - Training Epoch: 1/2, step 4394/107898 completed (loss: 0.16224482655525208, acc: 1.0)
[2025-02-17 16:52:00,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:00,757][root][INFO] - Training Epoch: 1/2, step 4395/107898 completed (loss: 0.374210923910141, acc: 0.9200000166893005)
[2025-02-17 16:52:00,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:01,057][root][INFO] - Training Epoch: 1/2, step 4396/107898 completed (loss: 2.0606048107147217, acc: 0.4000000059604645)
[2025-02-17 16:52:01,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:01,401][root][INFO] - Training Epoch: 1/2, step 4397/107898 completed (loss: 1.697758674621582, acc: 0.6315789222717285)
[2025-02-17 16:52:01,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:01,731][root][INFO] - Training Epoch: 1/2, step 4398/107898 completed (loss: 2.9272704124450684, acc: 0.0)
[2025-02-17 16:52:01,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:02,051][root][INFO] - Training Epoch: 1/2, step 4399/107898 completed (loss: 3.485888957977295, acc: 0.25)
[2025-02-17 16:52:02,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:02,362][root][INFO] - Training Epoch: 1/2, step 4400/107898 completed (loss: 0.36258047819137573, acc: 0.9545454382896423)
[2025-02-17 16:52:02,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:02,688][root][INFO] - Training Epoch: 1/2, step 4401/107898 completed (loss: 0.14490073919296265, acc: 0.8888888955116272)
[2025-02-17 16:52:02,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:03,003][root][INFO] - Training Epoch: 1/2, step 4402/107898 completed (loss: 2.2891643047332764, acc: 0.5416666865348816)
[2025-02-17 16:52:03,086][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:03,304][root][INFO] - Training Epoch: 1/2, step 4403/107898 completed (loss: 2.7064738273620605, acc: 0.5)
[2025-02-17 16:52:03,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:03,603][root][INFO] - Training Epoch: 1/2, step 4404/107898 completed (loss: 3.2555453777313232, acc: 0.25)
[2025-02-17 16:52:03,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:03,905][root][INFO] - Training Epoch: 1/2, step 4405/107898 completed (loss: 4.502277374267578, acc: 0.25)
[2025-02-17 16:52:04,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:04,264][root][INFO] - Training Epoch: 1/2, step 4406/107898 completed (loss: 2.2455546855926514, acc: 0.6666666865348816)
[2025-02-17 16:52:04,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:04,598][root][INFO] - Training Epoch: 1/2, step 4407/107898 completed (loss: 1.5984015464782715, acc: 0.75)
[2025-02-17 16:52:04,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:04,937][root][INFO] - Training Epoch: 1/2, step 4408/107898 completed (loss: 3.276226282119751, acc: 0.5)
[2025-02-17 16:52:05,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:05,275][root][INFO] - Training Epoch: 1/2, step 4409/107898 completed (loss: 0.28553226590156555, acc: 1.0)
[2025-02-17 16:52:05,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:05,665][root][INFO] - Training Epoch: 1/2, step 4410/107898 completed (loss: 1.4732446670532227, acc: 0.5)
[2025-02-17 16:52:05,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:05,996][root][INFO] - Training Epoch: 1/2, step 4411/107898 completed (loss: 1.2069716453552246, acc: 0.7307692170143127)
[2025-02-17 16:52:06,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:06,309][root][INFO] - Training Epoch: 1/2, step 4412/107898 completed (loss: 0.6058416962623596, acc: 0.6666666865348816)
[2025-02-17 16:52:06,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:06,678][root][INFO] - Training Epoch: 1/2, step 4413/107898 completed (loss: 0.7285047769546509, acc: 0.800000011920929)
[2025-02-17 16:52:06,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:07,015][root][INFO] - Training Epoch: 1/2, step 4414/107898 completed (loss: 3.394108295440674, acc: 0.20000000298023224)
[2025-02-17 16:52:07,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:07,351][root][INFO] - Training Epoch: 1/2, step 4415/107898 completed (loss: 1.192784070968628, acc: 0.692307710647583)
[2025-02-17 16:52:07,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:07,701][root][INFO] - Training Epoch: 1/2, step 4416/107898 completed (loss: 0.6568269729614258, acc: 0.8888888955116272)
[2025-02-17 16:52:07,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:08,036][root][INFO] - Training Epoch: 1/2, step 4417/107898 completed (loss: 1.617409586906433, acc: 0.6315789222717285)
[2025-02-17 16:52:08,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:08,379][root][INFO] - Training Epoch: 1/2, step 4418/107898 completed (loss: 0.4469638764858246, acc: 1.0)
[2025-02-17 16:52:08,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:08,737][root][INFO] - Training Epoch: 1/2, step 4419/107898 completed (loss: 0.3340681791305542, acc: 0.9487179517745972)
[2025-02-17 16:52:08,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:09,077][root][INFO] - Training Epoch: 1/2, step 4420/107898 completed (loss: 3.573291063308716, acc: 0.2857142984867096)
[2025-02-17 16:52:09,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:09,414][root][INFO] - Training Epoch: 1/2, step 4421/107898 completed (loss: 0.5870218276977539, acc: 0.5)
[2025-02-17 16:52:09,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:09,764][root][INFO] - Training Epoch: 1/2, step 4422/107898 completed (loss: 0.7352653741836548, acc: 0.875)
[2025-02-17 16:52:09,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:10,081][root][INFO] - Training Epoch: 1/2, step 4423/107898 completed (loss: 1.7155994176864624, acc: 0.4285714328289032)
[2025-02-17 16:52:10,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:10,387][root][INFO] - Training Epoch: 1/2, step 4424/107898 completed (loss: 0.11434416472911835, acc: 1.0)
[2025-02-17 16:52:10,492][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:10,723][root][INFO] - Training Epoch: 1/2, step 4425/107898 completed (loss: 2.305997133255005, acc: 0.5)
[2025-02-17 16:52:10,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:11,078][root][INFO] - Training Epoch: 1/2, step 4426/107898 completed (loss: 1.027008295059204, acc: 0.7142857313156128)
[2025-02-17 16:52:11,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:11,439][root][INFO] - Training Epoch: 1/2, step 4427/107898 completed (loss: 3.2859346866607666, acc: 0.3333333432674408)
[2025-02-17 16:52:11,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:11,797][root][INFO] - Training Epoch: 1/2, step 4428/107898 completed (loss: 0.8475209474563599, acc: 0.7368420958518982)
[2025-02-17 16:52:11,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:12,114][root][INFO] - Training Epoch: 1/2, step 4429/107898 completed (loss: 0.1426183581352234, acc: 0.9545454382896423)
[2025-02-17 16:52:12,227][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:12,467][root][INFO] - Training Epoch: 1/2, step 4430/107898 completed (loss: 0.3581920266151428, acc: 0.8999999761581421)
[2025-02-17 16:52:12,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:12,767][root][INFO] - Training Epoch: 1/2, step 4431/107898 completed (loss: 0.0903610810637474, acc: 1.0)
[2025-02-17 16:52:12,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:13,075][root][INFO] - Training Epoch: 1/2, step 4432/107898 completed (loss: 0.11232584714889526, acc: 1.0)
[2025-02-17 16:52:13,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:13,381][root][INFO] - Training Epoch: 1/2, step 4433/107898 completed (loss: 1.005916714668274, acc: 0.5)
[2025-02-17 16:52:13,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:13,681][root][INFO] - Training Epoch: 1/2, step 4434/107898 completed (loss: 0.024941327050328255, acc: 1.0)
[2025-02-17 16:52:13,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:14,051][root][INFO] - Training Epoch: 1/2, step 4435/107898 completed (loss: 1.5783538818359375, acc: 0.6666666865348816)
[2025-02-17 16:52:14,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:14,374][root][INFO] - Training Epoch: 1/2, step 4436/107898 completed (loss: 2.052881956100464, acc: 0.5833333134651184)
[2025-02-17 16:52:14,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:14,706][root][INFO] - Training Epoch: 1/2, step 4437/107898 completed (loss: 0.6742567420005798, acc: 0.75)
[2025-02-17 16:52:14,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:14,979][root][INFO] - Training Epoch: 1/2, step 4438/107898 completed (loss: 2.105654001235962, acc: 0.6666666865348816)
[2025-02-17 16:52:15,056][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:15,277][root][INFO] - Training Epoch: 1/2, step 4439/107898 completed (loss: 0.013408246450126171, acc: 1.0)
[2025-02-17 16:52:15,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:15,598][root][INFO] - Training Epoch: 1/2, step 4440/107898 completed (loss: 0.1262224316596985, acc: 1.0)
[2025-02-17 16:52:15,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:15,894][root][INFO] - Training Epoch: 1/2, step 4441/107898 completed (loss: 1.9120898246765137, acc: 0.5)
[2025-02-17 16:52:15,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:16,206][root][INFO] - Training Epoch: 1/2, step 4442/107898 completed (loss: 1.8849819898605347, acc: 0.6428571343421936)
[2025-02-17 16:52:16,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:16,547][root][INFO] - Training Epoch: 1/2, step 4443/107898 completed (loss: 0.6481497287750244, acc: 0.782608687877655)
[2025-02-17 16:52:16,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:16,898][root][INFO] - Training Epoch: 1/2, step 4444/107898 completed (loss: 0.1345198005437851, acc: 1.0)
[2025-02-17 16:52:16,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:17,220][root][INFO] - Training Epoch: 1/2, step 4445/107898 completed (loss: 0.29679957032203674, acc: 0.9166666865348816)
[2025-02-17 16:52:17,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:17,619][root][INFO] - Training Epoch: 1/2, step 4446/107898 completed (loss: 1.7562369108200073, acc: 0.75)
[2025-02-17 16:52:17,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:17,961][root][INFO] - Training Epoch: 1/2, step 4447/107898 completed (loss: 0.31307294964790344, acc: 0.9285714030265808)
[2025-02-17 16:52:18,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:18,270][root][INFO] - Training Epoch: 1/2, step 4448/107898 completed (loss: 3.6965091228485107, acc: 0.3333333432674408)
[2025-02-17 16:52:18,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:18,625][root][INFO] - Training Epoch: 1/2, step 4449/107898 completed (loss: 0.04741419851779938, acc: 1.0)
[2025-02-17 16:52:18,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:18,902][root][INFO] - Training Epoch: 1/2, step 4450/107898 completed (loss: 1.1003894805908203, acc: 0.8461538553237915)
[2025-02-17 16:52:18,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:19,198][root][INFO] - Training Epoch: 1/2, step 4451/107898 completed (loss: 2.5949831008911133, acc: 0.5333333611488342)
[2025-02-17 16:52:19,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:19,517][root][INFO] - Training Epoch: 1/2, step 4452/107898 completed (loss: 0.14806881546974182, acc: 1.0)
[2025-02-17 16:52:19,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:19,822][root][INFO] - Training Epoch: 1/2, step 4453/107898 completed (loss: 0.5504618883132935, acc: 1.0)
[2025-02-17 16:52:19,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:20,143][root][INFO] - Training Epoch: 1/2, step 4454/107898 completed (loss: 3.466810703277588, acc: 0.20000000298023224)
[2025-02-17 16:52:20,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:20,442][root][INFO] - Training Epoch: 1/2, step 4455/107898 completed (loss: 0.10445688664913177, acc: 1.0)
[2025-02-17 16:52:20,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:20,769][root][INFO] - Training Epoch: 1/2, step 4456/107898 completed (loss: 1.3641523122787476, acc: 0.6666666865348816)
[2025-02-17 16:52:20,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:21,064][root][INFO] - Training Epoch: 1/2, step 4457/107898 completed (loss: 0.07228541374206543, acc: 1.0)
[2025-02-17 16:52:21,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:21,381][root][INFO] - Training Epoch: 1/2, step 4458/107898 completed (loss: 2.082042932510376, acc: 0.5714285969734192)
[2025-02-17 16:52:21,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:21,724][root][INFO] - Training Epoch: 1/2, step 4459/107898 completed (loss: 0.4901617765426636, acc: 0.8333333134651184)
[2025-02-17 16:52:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:22,050][root][INFO] - Training Epoch: 1/2, step 4460/107898 completed (loss: 2.7726433277130127, acc: 0.4000000059604645)
[2025-02-17 16:52:22,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:22,406][root][INFO] - Training Epoch: 1/2, step 4461/107898 completed (loss: 0.009889819659292698, acc: 1.0)
[2025-02-17 16:52:22,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:22,741][root][INFO] - Training Epoch: 1/2, step 4462/107898 completed (loss: 3.4150357246398926, acc: 0.29032257199287415)
[2025-02-17 16:52:22,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:23,050][root][INFO] - Training Epoch: 1/2, step 4463/107898 completed (loss: 1.250196099281311, acc: 0.5)
[2025-02-17 16:52:23,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:23,367][root][INFO] - Training Epoch: 1/2, step 4464/107898 completed (loss: 0.11312402039766312, acc: 1.0)
[2025-02-17 16:52:23,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:23,717][root][INFO] - Training Epoch: 1/2, step 4465/107898 completed (loss: 1.007566213607788, acc: 0.8461538553237915)
[2025-02-17 16:52:23,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:24,054][root][INFO] - Training Epoch: 1/2, step 4466/107898 completed (loss: 0.025133222341537476, acc: 1.0)
[2025-02-17 16:52:24,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:24,343][root][INFO] - Training Epoch: 1/2, step 4467/107898 completed (loss: 0.03780142217874527, acc: 1.0)
[2025-02-17 16:52:24,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:24,651][root][INFO] - Training Epoch: 1/2, step 4468/107898 completed (loss: 1.6395950317382812, acc: 0.6666666865348816)
[2025-02-17 16:52:24,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:24,945][root][INFO] - Training Epoch: 1/2, step 4469/107898 completed (loss: 0.010169437155127525, acc: 1.0)
[2025-02-17 16:52:25,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:25,283][root][INFO] - Training Epoch: 1/2, step 4470/107898 completed (loss: 1.2641050815582275, acc: 0.5)
[2025-02-17 16:52:25,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:25,611][root][INFO] - Training Epoch: 1/2, step 4471/107898 completed (loss: 1.3930414915084839, acc: 0.7894737124443054)
[2025-02-17 16:52:25,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:25,919][root][INFO] - Training Epoch: 1/2, step 4472/107898 completed (loss: 2.2041077613830566, acc: 0.5)
[2025-02-17 16:52:25,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:26,215][root][INFO] - Training Epoch: 1/2, step 4473/107898 completed (loss: 0.03699331730604172, acc: 1.0)
[2025-02-17 16:52:26,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:26,512][root][INFO] - Training Epoch: 1/2, step 4474/107898 completed (loss: 4.055054187774658, acc: 0.3333333432674408)
[2025-02-17 16:52:26,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:26,800][root][INFO] - Training Epoch: 1/2, step 4475/107898 completed (loss: 3.684659481048584, acc: 0.5714285969734192)
[2025-02-17 16:52:26,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:27,102][root][INFO] - Training Epoch: 1/2, step 4476/107898 completed (loss: 0.09630516171455383, acc: 1.0)
[2025-02-17 16:52:27,185][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:27,414][root][INFO] - Training Epoch: 1/2, step 4477/107898 completed (loss: 0.011807212606072426, acc: 1.0)
[2025-02-17 16:52:27,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:27,753][root][INFO] - Training Epoch: 1/2, step 4478/107898 completed (loss: 0.879538357257843, acc: 0.800000011920929)
[2025-02-17 16:52:27,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:28,087][root][INFO] - Training Epoch: 1/2, step 4479/107898 completed (loss: 2.396977424621582, acc: 0.6666666865348816)
[2025-02-17 16:52:28,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:28,419][root][INFO] - Training Epoch: 1/2, step 4480/107898 completed (loss: 0.03796623647212982, acc: 1.0)
[2025-02-17 16:52:28,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:28,731][root][INFO] - Training Epoch: 1/2, step 4481/107898 completed (loss: 0.5198953747749329, acc: 0.8095238208770752)
[2025-02-17 16:52:28,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:29,025][root][INFO] - Training Epoch: 1/2, step 4482/107898 completed (loss: 0.7524319291114807, acc: 0.8148148059844971)
[2025-02-17 16:52:29,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:29,332][root][INFO] - Training Epoch: 1/2, step 4483/107898 completed (loss: 0.9879819750785828, acc: 0.8999999761581421)
[2025-02-17 16:52:29,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:29,667][root][INFO] - Training Epoch: 1/2, step 4484/107898 completed (loss: 0.036309126764535904, acc: 1.0)
[2025-02-17 16:52:29,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:30,012][root][INFO] - Training Epoch: 1/2, step 4485/107898 completed (loss: 0.3917325735092163, acc: 0.9375)
[2025-02-17 16:52:30,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:30,373][root][INFO] - Training Epoch: 1/2, step 4486/107898 completed (loss: 0.5497459769248962, acc: 0.9166666865348816)
[2025-02-17 16:52:30,475][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:30,700][root][INFO] - Training Epoch: 1/2, step 4487/107898 completed (loss: 0.7687286734580994, acc: 0.8275862336158752)
[2025-02-17 16:52:30,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:31,010][root][INFO] - Training Epoch: 1/2, step 4488/107898 completed (loss: 0.9627860188484192, acc: 0.7857142686843872)
[2025-02-17 16:52:31,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:31,396][root][INFO] - Training Epoch: 1/2, step 4489/107898 completed (loss: 1.2004693746566772, acc: 0.75)
[2025-02-17 16:52:31,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:31,752][root][INFO] - Training Epoch: 1/2, step 4490/107898 completed (loss: 0.8138390779495239, acc: 0.9047619104385376)
[2025-02-17 16:52:31,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:32,055][root][INFO] - Training Epoch: 1/2, step 4491/107898 completed (loss: 0.00716070830821991, acc: 1.0)
[2025-02-17 16:52:32,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:32,402][root][INFO] - Training Epoch: 1/2, step 4492/107898 completed (loss: 4.3911309242248535, acc: 0.4000000059604645)
[2025-02-17 16:52:32,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:32,696][root][INFO] - Training Epoch: 1/2, step 4493/107898 completed (loss: 0.22468255460262299, acc: 0.9629629850387573)
[2025-02-17 16:52:32,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:32,990][root][INFO] - Training Epoch: 1/2, step 4494/107898 completed (loss: 0.053662411868572235, acc: 1.0)
[2025-02-17 16:52:33,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:33,296][root][INFO] - Training Epoch: 1/2, step 4495/107898 completed (loss: 0.006101722829043865, acc: 1.0)
[2025-02-17 16:52:33,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:33,660][root][INFO] - Training Epoch: 1/2, step 4496/107898 completed (loss: 0.3714321255683899, acc: 0.9615384340286255)
[2025-02-17 16:52:33,762][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:33,978][root][INFO] - Training Epoch: 1/2, step 4497/107898 completed (loss: 5.009821891784668, acc: 0.0714285746216774)
[2025-02-17 16:52:34,064][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:34,290][root][INFO] - Training Epoch: 1/2, step 4498/107898 completed (loss: 0.661560595035553, acc: 0.5)
[2025-02-17 16:52:34,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:34,624][root][INFO] - Training Epoch: 1/2, step 4499/107898 completed (loss: 1.3920061588287354, acc: 0.7142857313156128)
[2025-02-17 16:52:34,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:34,876][root][INFO] - Training Epoch: 1/2, step 4500/107898 completed (loss: 0.08053316175937653, acc: 1.0)
[2025-02-17 16:52:34,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:35,180][root][INFO] - Training Epoch: 1/2, step 4501/107898 completed (loss: 1.663921594619751, acc: 0.5)
[2025-02-17 16:52:35,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:35,479][root][INFO] - Training Epoch: 1/2, step 4502/107898 completed (loss: 0.844037652015686, acc: 0.699999988079071)
[2025-02-17 16:52:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:35,791][root][INFO] - Training Epoch: 1/2, step 4503/107898 completed (loss: 1.3970139026641846, acc: 0.8125)
[2025-02-17 16:52:35,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:36,146][root][INFO] - Training Epoch: 1/2, step 4504/107898 completed (loss: 1.3237597942352295, acc: 0.7857142686843872)
[2025-02-17 16:52:36,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:36,478][root][INFO] - Training Epoch: 1/2, step 4505/107898 completed (loss: 1.776379942893982, acc: 0.5)
[2025-02-17 16:52:36,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:36,795][root][INFO] - Training Epoch: 1/2, step 4506/107898 completed (loss: 0.8359392881393433, acc: 0.9047619104385376)
[2025-02-17 16:52:36,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:37,114][root][INFO] - Training Epoch: 1/2, step 4507/107898 completed (loss: 2.280094861984253, acc: 0.4545454680919647)
[2025-02-17 16:52:37,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:37,433][root][INFO] - Training Epoch: 1/2, step 4508/107898 completed (loss: 1.047078251838684, acc: 0.7058823704719543)
[2025-02-17 16:52:37,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:37,743][root][INFO] - Training Epoch: 1/2, step 4509/107898 completed (loss: 1.841878056526184, acc: 0.6060606241226196)
[2025-02-17 16:52:37,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:38,045][root][INFO] - Training Epoch: 1/2, step 4510/107898 completed (loss: 0.20188510417938232, acc: 1.0)
[2025-02-17 16:52:38,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:38,394][root][INFO] - Training Epoch: 1/2, step 4511/107898 completed (loss: 2.040630340576172, acc: 0.5)
[2025-02-17 16:52:38,466][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:38,681][root][INFO] - Training Epoch: 1/2, step 4512/107898 completed (loss: 0.20636498928070068, acc: 1.0)
[2025-02-17 16:52:38,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:38,988][root][INFO] - Training Epoch: 1/2, step 4513/107898 completed (loss: 1.3907530307769775, acc: 0.875)
[2025-02-17 16:52:39,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:39,300][root][INFO] - Training Epoch: 1/2, step 4514/107898 completed (loss: 0.20121735334396362, acc: 1.0)
[2025-02-17 16:52:39,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:39,608][root][INFO] - Training Epoch: 1/2, step 4515/107898 completed (loss: 0.1833893209695816, acc: 1.0)
[2025-02-17 16:52:39,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:39,967][root][INFO] - Training Epoch: 1/2, step 4516/107898 completed (loss: 0.22696584463119507, acc: 0.8888888955116272)
[2025-02-17 16:52:40,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:40,289][root][INFO] - Training Epoch: 1/2, step 4517/107898 completed (loss: 1.0280324220657349, acc: 0.8095238208770752)
[2025-02-17 16:52:40,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:40,592][root][INFO] - Training Epoch: 1/2, step 4518/107898 completed (loss: 4.386582851409912, acc: 0.1666666716337204)
[2025-02-17 16:52:40,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:40,901][root][INFO] - Training Epoch: 1/2, step 4519/107898 completed (loss: 0.5860050916671753, acc: 0.8571428656578064)
[2025-02-17 16:52:40,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:41,204][root][INFO] - Training Epoch: 1/2, step 4520/107898 completed (loss: 0.430154025554657, acc: 0.8571428656578064)
[2025-02-17 16:52:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:41,493][root][INFO] - Training Epoch: 1/2, step 4521/107898 completed (loss: 2.180196523666382, acc: 0.6666666865348816)
[2025-02-17 16:52:41,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:41,834][root][INFO] - Training Epoch: 1/2, step 4522/107898 completed (loss: 2.1535019874572754, acc: 0.5555555820465088)
[2025-02-17 16:52:41,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:42,173][root][INFO] - Training Epoch: 1/2, step 4523/107898 completed (loss: 3.7170464992523193, acc: 0.25)
[2025-02-17 16:52:42,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:42,480][root][INFO] - Training Epoch: 1/2, step 4524/107898 completed (loss: 2.594860315322876, acc: 0.4399999976158142)
[2025-02-17 16:52:42,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:42,819][root][INFO] - Training Epoch: 1/2, step 4525/107898 completed (loss: 0.3157457113265991, acc: 0.8888888955116272)
[2025-02-17 16:52:42,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:43,151][root][INFO] - Training Epoch: 1/2, step 4526/107898 completed (loss: 2.22739315032959, acc: 0.5333333611488342)
[2025-02-17 16:52:43,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:43,453][root][INFO] - Training Epoch: 1/2, step 4527/107898 completed (loss: 1.4478741884231567, acc: 0.6666666865348816)
[2025-02-17 16:52:43,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:43,730][root][INFO] - Training Epoch: 1/2, step 4528/107898 completed (loss: 0.8902252316474915, acc: 0.8571428656578064)
[2025-02-17 16:52:43,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:44,073][root][INFO] - Training Epoch: 1/2, step 4529/107898 completed (loss: 0.49281397461891174, acc: 0.8695651888847351)
[2025-02-17 16:52:44,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:44,449][root][INFO] - Training Epoch: 1/2, step 4530/107898 completed (loss: 1.3034878969192505, acc: 0.807692289352417)
[2025-02-17 16:52:44,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:44,784][root][INFO] - Training Epoch: 1/2, step 4531/107898 completed (loss: 4.711541652679443, acc: 0.1818181872367859)
[2025-02-17 16:52:44,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:45,133][root][INFO] - Training Epoch: 1/2, step 4532/107898 completed (loss: 0.002967478008940816, acc: 1.0)
[2025-02-17 16:52:45,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:45,483][root][INFO] - Training Epoch: 1/2, step 4533/107898 completed (loss: 1.034738302230835, acc: 0.800000011920929)
[2025-02-17 16:52:45,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:45,826][root][INFO] - Training Epoch: 1/2, step 4534/107898 completed (loss: 4.0200629234313965, acc: 0.3181818127632141)
[2025-02-17 16:52:45,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:46,147][root][INFO] - Training Epoch: 1/2, step 4535/107898 completed (loss: 0.3612368404865265, acc: 1.0)
[2025-02-17 16:52:46,242][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:46,478][root][INFO] - Training Epoch: 1/2, step 4536/107898 completed (loss: 3.687995195388794, acc: 0.21739129722118378)
[2025-02-17 16:52:46,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:46,817][root][INFO] - Training Epoch: 1/2, step 4537/107898 completed (loss: 2.243769407272339, acc: 0.6666666865348816)
[2025-02-17 16:52:46,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:47,140][root][INFO] - Training Epoch: 1/2, step 4538/107898 completed (loss: 0.684393584728241, acc: 0.6666666865348816)
[2025-02-17 16:52:47,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:47,469][root][INFO] - Training Epoch: 1/2, step 4539/107898 completed (loss: 0.010870394296944141, acc: 1.0)
[2025-02-17 16:52:47,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:47,775][root][INFO] - Training Epoch: 1/2, step 4540/107898 completed (loss: 0.007402580231428146, acc: 1.0)
[2025-02-17 16:52:47,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:48,112][root][INFO] - Training Epoch: 1/2, step 4541/107898 completed (loss: 0.5884110927581787, acc: 0.8235294222831726)
[2025-02-17 16:52:48,212][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:48,435][root][INFO] - Training Epoch: 1/2, step 4542/107898 completed (loss: 0.006199529394507408, acc: 1.0)
[2025-02-17 16:52:48,525][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:48,744][root][INFO] - Training Epoch: 1/2, step 4543/107898 completed (loss: 0.7980713248252869, acc: 0.7857142686843872)
[2025-02-17 16:52:48,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:49,048][root][INFO] - Training Epoch: 1/2, step 4544/107898 completed (loss: 0.468736469745636, acc: 0.875)
[2025-02-17 16:52:49,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:49,351][root][INFO] - Training Epoch: 1/2, step 4545/107898 completed (loss: 1.2952765226364136, acc: 0.7692307829856873)
[2025-02-17 16:52:49,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:49,680][root][INFO] - Training Epoch: 1/2, step 4546/107898 completed (loss: 3.0959908962249756, acc: 0.6666666865348816)
[2025-02-17 16:52:49,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:50,010][root][INFO] - Training Epoch: 1/2, step 4547/107898 completed (loss: 0.005199512001127005, acc: 1.0)
[2025-02-17 16:52:50,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:50,348][root][INFO] - Training Epoch: 1/2, step 4548/107898 completed (loss: 2.3548526763916016, acc: 0.4000000059604645)
[2025-02-17 16:52:50,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:50,690][root][INFO] - Training Epoch: 1/2, step 4549/107898 completed (loss: 1.320379614830017, acc: 0.75)
[2025-02-17 16:52:50,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:51,051][root][INFO] - Training Epoch: 1/2, step 4550/107898 completed (loss: 3.501802682876587, acc: 0.375)
[2025-02-17 16:52:51,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:51,392][root][INFO] - Training Epoch: 1/2, step 4551/107898 completed (loss: 0.4313874840736389, acc: 0.75)
[2025-02-17 16:52:51,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:51,798][root][INFO] - Training Epoch: 1/2, step 4552/107898 completed (loss: 0.7822117209434509, acc: 0.8888888955116272)
[2025-02-17 16:52:51,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:52,161][root][INFO] - Training Epoch: 1/2, step 4553/107898 completed (loss: 0.5064642429351807, acc: 1.0)
[2025-02-17 16:52:52,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:52,482][root][INFO] - Training Epoch: 1/2, step 4554/107898 completed (loss: 0.5631884336471558, acc: 0.6666666865348816)
[2025-02-17 16:52:52,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:52,807][root][INFO] - Training Epoch: 1/2, step 4555/107898 completed (loss: 0.005598471965640783, acc: 1.0)
[2025-02-17 16:52:52,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:53,119][root][INFO] - Training Epoch: 1/2, step 4556/107898 completed (loss: 0.19132743775844574, acc: 1.0)
[2025-02-17 16:52:53,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:53,424][root][INFO] - Training Epoch: 1/2, step 4557/107898 completed (loss: 0.4374830424785614, acc: 0.8965517282485962)
[2025-02-17 16:52:53,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:53,753][root][INFO] - Training Epoch: 1/2, step 4558/107898 completed (loss: 1.553109049797058, acc: 0.7222222089767456)
[2025-02-17 16:52:53,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:54,082][root][INFO] - Training Epoch: 1/2, step 4559/107898 completed (loss: 1.129846453666687, acc: 0.692307710647583)
[2025-02-17 16:52:54,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:54,372][root][INFO] - Training Epoch: 1/2, step 4560/107898 completed (loss: 0.07743944227695465, acc: 1.0)
[2025-02-17 16:52:54,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:54,713][root][INFO] - Training Epoch: 1/2, step 4561/107898 completed (loss: 2.475226402282715, acc: 0.375)
[2025-02-17 16:52:54,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:55,079][root][INFO] - Training Epoch: 1/2, step 4562/107898 completed (loss: 1.912535309791565, acc: 0.5)
[2025-02-17 16:52:55,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:55,408][root][INFO] - Training Epoch: 1/2, step 4563/107898 completed (loss: 0.08263999223709106, acc: 1.0)
[2025-02-17 16:52:55,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:55,734][root][INFO] - Training Epoch: 1/2, step 4564/107898 completed (loss: 0.5184242725372314, acc: 0.9333333373069763)
[2025-02-17 16:52:55,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:56,037][root][INFO] - Training Epoch: 1/2, step 4565/107898 completed (loss: 0.44173744320869446, acc: 1.0)
[2025-02-17 16:52:56,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:56,334][root][INFO] - Training Epoch: 1/2, step 4566/107898 completed (loss: 0.22000941634178162, acc: 0.8999999761581421)
[2025-02-17 16:52:56,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:56,617][root][INFO] - Training Epoch: 1/2, step 4567/107898 completed (loss: 0.00808226689696312, acc: 1.0)
[2025-02-17 16:52:56,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:56,948][root][INFO] - Training Epoch: 1/2, step 4568/107898 completed (loss: 0.5604439973831177, acc: 0.8571428656578064)
[2025-02-17 16:52:57,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:57,294][root][INFO] - Training Epoch: 1/2, step 4569/107898 completed (loss: 2.5968639850616455, acc: 0.3499999940395355)
[2025-02-17 16:52:57,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:57,632][root][INFO] - Training Epoch: 1/2, step 4570/107898 completed (loss: 0.37467890977859497, acc: 0.8999999761581421)
[2025-02-17 16:52:57,731][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:57,966][root][INFO] - Training Epoch: 1/2, step 4571/107898 completed (loss: 0.4046357572078705, acc: 0.9285714030265808)
[2025-02-17 16:52:58,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:58,311][root][INFO] - Training Epoch: 1/2, step 4572/107898 completed (loss: 0.9115220308303833, acc: 0.75)
[2025-02-17 16:52:58,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:58,660][root][INFO] - Training Epoch: 1/2, step 4573/107898 completed (loss: 0.576811671257019, acc: 0.8928571343421936)
[2025-02-17 16:52:58,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:58,983][root][INFO] - Training Epoch: 1/2, step 4574/107898 completed (loss: 0.1959257572889328, acc: 0.8333333134651184)
[2025-02-17 16:52:59,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:59,292][root][INFO] - Training Epoch: 1/2, step 4575/107898 completed (loss: 0.0036068304907530546, acc: 1.0)
[2025-02-17 16:52:59,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:59,603][root][INFO] - Training Epoch: 1/2, step 4576/107898 completed (loss: 0.8225301504135132, acc: 0.800000011920929)
[2025-02-17 16:52:59,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:52:59,905][root][INFO] - Training Epoch: 1/2, step 4577/107898 completed (loss: 4.914090633392334, acc: 0.3333333432674408)
[2025-02-17 16:53:00,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:00,272][root][INFO] - Training Epoch: 1/2, step 4578/107898 completed (loss: 0.6190455555915833, acc: 0.8823529481887817)
[2025-02-17 16:53:00,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:00,637][root][INFO] - Training Epoch: 1/2, step 4579/107898 completed (loss: 0.39131972193717957, acc: 0.9032257795333862)
[2025-02-17 16:53:00,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:00,975][root][INFO] - Training Epoch: 1/2, step 4580/107898 completed (loss: 0.0023153768852353096, acc: 1.0)
[2025-02-17 16:53:01,069][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:01,300][root][INFO] - Training Epoch: 1/2, step 4581/107898 completed (loss: 3.617866039276123, acc: 0.5)
[2025-02-17 16:53:01,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:01,618][root][INFO] - Training Epoch: 1/2, step 4582/107898 completed (loss: 0.10637470334768295, acc: 1.0)
[2025-02-17 16:53:01,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:01,926][root][INFO] - Training Epoch: 1/2, step 4583/107898 completed (loss: 0.010189681313931942, acc: 1.0)
[2025-02-17 16:53:02,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:02,234][root][INFO] - Training Epoch: 1/2, step 4584/107898 completed (loss: 3.396650552749634, acc: 0.25)
[2025-02-17 16:53:02,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:02,544][root][INFO] - Training Epoch: 1/2, step 4585/107898 completed (loss: 0.6842948794364929, acc: 0.8684210777282715)
[2025-02-17 16:53:02,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:02,894][root][INFO] - Training Epoch: 1/2, step 4586/107898 completed (loss: 0.019282160326838493, acc: 1.0)
[2025-02-17 16:53:02,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:03,178][root][INFO] - Training Epoch: 1/2, step 4587/107898 completed (loss: 4.8937273025512695, acc: 0.2222222238779068)
[2025-02-17 16:53:03,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:03,510][root][INFO] - Training Epoch: 1/2, step 4588/107898 completed (loss: 1.458927035331726, acc: 0.7857142686843872)
[2025-02-17 16:53:03,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:03,831][root][INFO] - Training Epoch: 1/2, step 4589/107898 completed (loss: 2.8219704627990723, acc: 0.5454545617103577)
[2025-02-17 16:53:03,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:04,158][root][INFO] - Training Epoch: 1/2, step 4590/107898 completed (loss: 0.01799755170941353, acc: 1.0)
[2025-02-17 16:53:04,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:04,459][root][INFO] - Training Epoch: 1/2, step 4591/107898 completed (loss: 3.5054140090942383, acc: 0.375)
[2025-02-17 16:53:04,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:04,778][root][INFO] - Training Epoch: 1/2, step 4592/107898 completed (loss: 0.42790281772613525, acc: 0.8095238208770752)
[2025-02-17 16:53:04,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:05,090][root][INFO] - Training Epoch: 1/2, step 4593/107898 completed (loss: 2.265967607498169, acc: 0.3333333432674408)
[2025-02-17 16:53:05,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:05,403][root][INFO] - Training Epoch: 1/2, step 4594/107898 completed (loss: 0.508363664150238, acc: 0.9411764740943909)
[2025-02-17 16:53:05,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:05,706][root][INFO] - Training Epoch: 1/2, step 4595/107898 completed (loss: 3.887044906616211, acc: 0.5)
[2025-02-17 16:53:05,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:06,050][root][INFO] - Training Epoch: 1/2, step 4596/107898 completed (loss: 4.390956401824951, acc: 0.3333333432674408)
[2025-02-17 16:53:06,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:06,390][root][INFO] - Training Epoch: 1/2, step 4597/107898 completed (loss: 1.6753820180892944, acc: 0.7096773982048035)
[2025-02-17 16:53:06,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:06,636][root][INFO] - Training Epoch: 1/2, step 4598/107898 completed (loss: 1.290806531906128, acc: 0.800000011920929)
[2025-02-17 16:53:06,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:06,931][root][INFO] - Training Epoch: 1/2, step 4599/107898 completed (loss: 4.562370300292969, acc: 0.5)
[2025-02-17 16:53:07,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:07,230][root][INFO] - Training Epoch: 1/2, step 4600/107898 completed (loss: 0.7317297458648682, acc: 0.8333333134651184)
[2025-02-17 16:53:07,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:07,588][root][INFO] - Training Epoch: 1/2, step 4601/107898 completed (loss: 1.2473270893096924, acc: 0.875)
[2025-02-17 16:53:07,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:07,917][root][INFO] - Training Epoch: 1/2, step 4602/107898 completed (loss: 1.4844064712524414, acc: 0.6000000238418579)
[2025-02-17 16:53:07,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:08,194][root][INFO] - Training Epoch: 1/2, step 4603/107898 completed (loss: 0.1626957505941391, acc: 1.0)
[2025-02-17 16:53:08,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:08,484][root][INFO] - Training Epoch: 1/2, step 4604/107898 completed (loss: 2.552637815475464, acc: 0.4000000059604645)
[2025-02-17 16:53:08,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:08,788][root][INFO] - Training Epoch: 1/2, step 4605/107898 completed (loss: 0.7566003799438477, acc: 0.875)
[2025-02-17 16:53:08,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:09,127][root][INFO] - Training Epoch: 1/2, step 4606/107898 completed (loss: 4.420092582702637, acc: 0.3333333432674408)
[2025-02-17 16:53:09,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:09,425][root][INFO] - Training Epoch: 1/2, step 4607/107898 completed (loss: 0.01165771484375, acc: 1.0)
[2025-02-17 16:53:09,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:09,701][root][INFO] - Training Epoch: 1/2, step 4608/107898 completed (loss: 0.25273117423057556, acc: 1.0)
[2025-02-17 16:53:09,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:10,030][root][INFO] - Training Epoch: 1/2, step 4609/107898 completed (loss: 0.7598710656166077, acc: 0.5)
[2025-02-17 16:53:10,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:10,371][root][INFO] - Training Epoch: 1/2, step 4610/107898 completed (loss: 3.5566246509552, acc: 0.29411765933036804)
[2025-02-17 16:53:10,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:10,689][root][INFO] - Training Epoch: 1/2, step 4611/107898 completed (loss: 0.48048582673072815, acc: 1.0)
[2025-02-17 16:53:10,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:11,027][root][INFO] - Training Epoch: 1/2, step 4612/107898 completed (loss: 0.4871869683265686, acc: 0.949999988079071)
[2025-02-17 16:53:11,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:11,337][root][INFO] - Training Epoch: 1/2, step 4613/107898 completed (loss: 2.3511927127838135, acc: 0.5)
[2025-02-17 16:53:11,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:11,682][root][INFO] - Training Epoch: 1/2, step 4614/107898 completed (loss: 0.210691437125206, acc: 1.0)
[2025-02-17 16:53:11,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:12,007][root][INFO] - Training Epoch: 1/2, step 4615/107898 completed (loss: 0.9596927165985107, acc: 0.692307710647583)
[2025-02-17 16:53:12,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:12,311][root][INFO] - Training Epoch: 1/2, step 4616/107898 completed (loss: 0.38043954968452454, acc: 1.0)
[2025-02-17 16:53:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:12,673][root][INFO] - Training Epoch: 1/2, step 4617/107898 completed (loss: 1.7480201721191406, acc: 0.699999988079071)
[2025-02-17 16:53:12,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:12,988][root][INFO] - Training Epoch: 1/2, step 4618/107898 completed (loss: 0.9574093818664551, acc: 0.761904776096344)
[2025-02-17 16:53:13,061][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:13,277][root][INFO] - Training Epoch: 1/2, step 4619/107898 completed (loss: 1.0277409553527832, acc: 0.739130437374115)
[2025-02-17 16:53:13,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:13,594][root][INFO] - Training Epoch: 1/2, step 4620/107898 completed (loss: 5.574507713317871, acc: 0.0)
[2025-02-17 16:53:13,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:13,920][root][INFO] - Training Epoch: 1/2, step 4621/107898 completed (loss: 1.3058074712753296, acc: 0.7777777910232544)
[2025-02-17 16:53:14,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:14,230][root][INFO] - Training Epoch: 1/2, step 4622/107898 completed (loss: 0.36206114292144775, acc: 0.949999988079071)
[2025-02-17 16:53:14,326][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:14,543][root][INFO] - Training Epoch: 1/2, step 4623/107898 completed (loss: 0.07606570422649384, acc: 1.0)
[2025-02-17 16:53:14,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:14,836][root][INFO] - Training Epoch: 1/2, step 4624/107898 completed (loss: 0.9222545027732849, acc: 0.8235294222831726)
[2025-02-17 16:53:14,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:15,134][root][INFO] - Training Epoch: 1/2, step 4625/107898 completed (loss: 0.030393529683351517, acc: 1.0)
[2025-02-17 16:53:15,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:15,443][root][INFO] - Training Epoch: 1/2, step 4626/107898 completed (loss: 2.1813058853149414, acc: 0.5)
[2025-02-17 16:53:15,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:15,750][root][INFO] - Training Epoch: 1/2, step 4627/107898 completed (loss: 2.2407338619232178, acc: 0.5714285969734192)
[2025-02-17 16:53:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:16,059][root][INFO] - Training Epoch: 1/2, step 4628/107898 completed (loss: 0.11988092958927155, acc: 1.0)
[2025-02-17 16:53:16,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:16,323][root][INFO] - Training Epoch: 1/2, step 4629/107898 completed (loss: 1.248087763786316, acc: 0.5)
[2025-02-17 16:53:16,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:16,608][root][INFO] - Training Epoch: 1/2, step 4630/107898 completed (loss: 0.004839390981942415, acc: 1.0)
[2025-02-17 16:53:16,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:16,904][root][INFO] - Training Epoch: 1/2, step 4631/107898 completed (loss: 0.8361372351646423, acc: 0.8571428656578064)
[2025-02-17 16:53:17,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:17,264][root][INFO] - Training Epoch: 1/2, step 4632/107898 completed (loss: 1.3497238159179688, acc: 0.7058823704719543)
[2025-02-17 16:53:17,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:17,591][root][INFO] - Training Epoch: 1/2, step 4633/107898 completed (loss: 1.3487974405288696, acc: 0.6000000238418579)
[2025-02-17 16:53:17,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:17,947][root][INFO] - Training Epoch: 1/2, step 4634/107898 completed (loss: 2.1804356575012207, acc: 0.5)
[2025-02-17 16:53:18,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:18,306][root][INFO] - Training Epoch: 1/2, step 4635/107898 completed (loss: 0.36137858033180237, acc: 0.8181818127632141)
[2025-02-17 16:53:18,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:18,642][root][INFO] - Training Epoch: 1/2, step 4636/107898 completed (loss: 0.01042107306420803, acc: 1.0)
[2025-02-17 16:53:18,774][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:18,999][root][INFO] - Training Epoch: 1/2, step 4637/107898 completed (loss: 1.7413532733917236, acc: 0.6666666865348816)
[2025-02-17 16:53:19,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:19,345][root][INFO] - Training Epoch: 1/2, step 4638/107898 completed (loss: 1.390723705291748, acc: 0.7142857313156128)
[2025-02-17 16:53:19,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:19,702][root][INFO] - Training Epoch: 1/2, step 4639/107898 completed (loss: 0.06433182209730148, acc: 1.0)
[2025-02-17 16:53:19,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:20,030][root][INFO] - Training Epoch: 1/2, step 4640/107898 completed (loss: 0.42405396699905396, acc: 0.9285714030265808)
[2025-02-17 16:53:20,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:20,342][root][INFO] - Training Epoch: 1/2, step 4641/107898 completed (loss: 3.7720916271209717, acc: 0.18518517911434174)
[2025-02-17 16:53:20,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:20,656][root][INFO] - Training Epoch: 1/2, step 4642/107898 completed (loss: 2.140293598175049, acc: 0.75)
[2025-02-17 16:53:20,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:20,989][root][INFO] - Training Epoch: 1/2, step 4643/107898 completed (loss: 2.3987791538238525, acc: 0.5)
[2025-02-17 16:53:21,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:21,331][root][INFO] - Training Epoch: 1/2, step 4644/107898 completed (loss: 0.7516704201698303, acc: 0.7777777910232544)
[2025-02-17 16:53:21,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:21,650][root][INFO] - Training Epoch: 1/2, step 4645/107898 completed (loss: 0.5322901606559753, acc: 0.8666666746139526)
[2025-02-17 16:53:21,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:21,945][root][INFO] - Training Epoch: 1/2, step 4646/107898 completed (loss: 2.345736265182495, acc: 0.6000000238418579)
[2025-02-17 16:53:22,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:22,236][root][INFO] - Training Epoch: 1/2, step 4647/107898 completed (loss: 1.856580138206482, acc: 0.75)
[2025-02-17 16:53:22,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:22,606][root][INFO] - Training Epoch: 1/2, step 4648/107898 completed (loss: 0.7328751087188721, acc: 0.8235294222831726)
[2025-02-17 16:53:22,685][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:22,895][root][INFO] - Training Epoch: 1/2, step 4649/107898 completed (loss: 0.201755553483963, acc: 1.0)
[2025-02-17 16:53:22,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:23,185][root][INFO] - Training Epoch: 1/2, step 4650/107898 completed (loss: 0.558861494064331, acc: 0.8636363744735718)
[2025-02-17 16:53:23,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:23,513][root][INFO] - Training Epoch: 1/2, step 4651/107898 completed (loss: 0.47897645831108093, acc: 1.0)
[2025-02-17 16:53:23,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:23,879][root][INFO] - Training Epoch: 1/2, step 4652/107898 completed (loss: 2.994249105453491, acc: 0.3571428656578064)
[2025-02-17 16:53:23,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:24,221][root][INFO] - Training Epoch: 1/2, step 4653/107898 completed (loss: 0.9292872548103333, acc: 0.7333333492279053)
[2025-02-17 16:53:24,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:24,557][root][INFO] - Training Epoch: 1/2, step 4654/107898 completed (loss: 0.16060473024845123, acc: 1.0)
[2025-02-17 16:53:24,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:24,868][root][INFO] - Training Epoch: 1/2, step 4655/107898 completed (loss: 0.9431673884391785, acc: 0.7647058963775635)
[2025-02-17 16:53:24,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:25,165][root][INFO] - Training Epoch: 1/2, step 4656/107898 completed (loss: 0.0440773069858551, acc: 1.0)
[2025-02-17 16:53:25,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:25,493][root][INFO] - Training Epoch: 1/2, step 4657/107898 completed (loss: 0.234832301735878, acc: 1.0)
[2025-02-17 16:53:25,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:25,781][root][INFO] - Training Epoch: 1/2, step 4658/107898 completed (loss: 0.6477219462394714, acc: 0.5)
[2025-02-17 16:53:25,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:26,067][root][INFO] - Training Epoch: 1/2, step 4659/107898 completed (loss: 1.9501266479492188, acc: 0.625)
[2025-02-17 16:53:26,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:26,353][root][INFO] - Training Epoch: 1/2, step 4660/107898 completed (loss: 0.6637942790985107, acc: 0.8666666746139526)
[2025-02-17 16:53:26,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:26,658][root][INFO] - Training Epoch: 1/2, step 4661/107898 completed (loss: 1.4004541635513306, acc: 0.6842105388641357)
[2025-02-17 16:53:26,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:26,960][root][INFO] - Training Epoch: 1/2, step 4662/107898 completed (loss: 0.521323561668396, acc: 1.0)
[2025-02-17 16:53:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:27,254][root][INFO] - Training Epoch: 1/2, step 4663/107898 completed (loss: 2.290527820587158, acc: 0.6666666865348816)
[2025-02-17 16:53:27,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:27,554][root][INFO] - Training Epoch: 1/2, step 4664/107898 completed (loss: 1.3159598112106323, acc: 0.7142857313156128)
[2025-02-17 16:53:27,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:27,853][root][INFO] - Training Epoch: 1/2, step 4665/107898 completed (loss: 2.6245005130767822, acc: 0.6000000238418579)
[2025-02-17 16:53:27,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:28,157][root][INFO] - Training Epoch: 1/2, step 4666/107898 completed (loss: 0.502332866191864, acc: 0.6666666865348816)
[2025-02-17 16:53:28,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:28,486][root][INFO] - Training Epoch: 1/2, step 4667/107898 completed (loss: 0.003246330190449953, acc: 1.0)
[2025-02-17 16:53:28,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:28,806][root][INFO] - Training Epoch: 1/2, step 4668/107898 completed (loss: 0.025075584650039673, acc: 1.0)
[2025-02-17 16:53:28,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:29,144][root][INFO] - Training Epoch: 1/2, step 4669/107898 completed (loss: 0.2507413327693939, acc: 1.0)
[2025-02-17 16:53:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:29,465][root][INFO] - Training Epoch: 1/2, step 4670/107898 completed (loss: 0.5327409505844116, acc: 0.9090909361839294)
[2025-02-17 16:53:29,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:29,787][root][INFO] - Training Epoch: 1/2, step 4671/107898 completed (loss: 1.2043102979660034, acc: 0.6666666865348816)
[2025-02-17 16:53:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:30,103][root][INFO] - Training Epoch: 1/2, step 4672/107898 completed (loss: 0.02444634772837162, acc: 1.0)
[2025-02-17 16:53:30,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:30,415][root][INFO] - Training Epoch: 1/2, step 4673/107898 completed (loss: 0.010334041900932789, acc: 1.0)
[2025-02-17 16:53:30,511][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:30,748][root][INFO] - Training Epoch: 1/2, step 4674/107898 completed (loss: 0.05469927191734314, acc: 1.0)
[2025-02-17 16:53:30,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:31,076][root][INFO] - Training Epoch: 1/2, step 4675/107898 completed (loss: 0.7534359097480774, acc: 0.8823529481887817)
[2025-02-17 16:53:31,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:31,380][root][INFO] - Training Epoch: 1/2, step 4676/107898 completed (loss: 1.6899765729904175, acc: 0.6363636255264282)
[2025-02-17 16:53:31,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:31,680][root][INFO] - Training Epoch: 1/2, step 4677/107898 completed (loss: 1.3429944515228271, acc: 0.6000000238418579)
[2025-02-17 16:53:31,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:31,965][root][INFO] - Training Epoch: 1/2, step 4678/107898 completed (loss: 1.8921598196029663, acc: 0.625)
[2025-02-17 16:53:32,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:32,256][root][INFO] - Training Epoch: 1/2, step 4679/107898 completed (loss: 1.8478833436965942, acc: 0.6666666865348816)
[2025-02-17 16:53:32,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:32,584][root][INFO] - Training Epoch: 1/2, step 4680/107898 completed (loss: 0.8192827701568604, acc: 0.800000011920929)
[2025-02-17 16:53:32,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:32,918][root][INFO] - Training Epoch: 1/2, step 4681/107898 completed (loss: 2.597120761871338, acc: 0.5)
[2025-02-17 16:53:33,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:33,254][root][INFO] - Training Epoch: 1/2, step 4682/107898 completed (loss: 1.0577389001846313, acc: 0.8958333134651184)
[2025-02-17 16:53:33,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:33,554][root][INFO] - Training Epoch: 1/2, step 4683/107898 completed (loss: 1.081521987915039, acc: 0.8333333134651184)
[2025-02-17 16:53:33,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:33,933][root][INFO] - Training Epoch: 1/2, step 4684/107898 completed (loss: 0.7566561102867126, acc: 0.7727272510528564)
[2025-02-17 16:53:34,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:34,270][root][INFO] - Training Epoch: 1/2, step 4685/107898 completed (loss: 0.6655484437942505, acc: 0.8666666746139526)
[2025-02-17 16:53:34,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:34,597][root][INFO] - Training Epoch: 1/2, step 4686/107898 completed (loss: 0.552966296672821, acc: 0.9411764740943909)
[2025-02-17 16:53:34,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:34,917][root][INFO] - Training Epoch: 1/2, step 4687/107898 completed (loss: 0.7644240856170654, acc: 0.8846153616905212)
[2025-02-17 16:53:35,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:35,264][root][INFO] - Training Epoch: 1/2, step 4688/107898 completed (loss: 0.03686006739735603, acc: 1.0)
[2025-02-17 16:53:35,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:35,577][root][INFO] - Training Epoch: 1/2, step 4689/107898 completed (loss: 1.8804428577423096, acc: 0.6000000238418579)
[2025-02-17 16:53:35,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:35,909][root][INFO] - Training Epoch: 1/2, step 4690/107898 completed (loss: 0.3224429488182068, acc: 0.8999999761581421)
[2025-02-17 16:53:36,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:36,279][root][INFO] - Training Epoch: 1/2, step 4691/107898 completed (loss: 2.6025664806365967, acc: 0.4444444477558136)
[2025-02-17 16:53:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:36,620][root][INFO] - Training Epoch: 1/2, step 4692/107898 completed (loss: 0.6796491146087646, acc: 0.8500000238418579)
[2025-02-17 16:53:36,693][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:36,903][root][INFO] - Training Epoch: 1/2, step 4693/107898 completed (loss: 0.9842021465301514, acc: 0.75)
[2025-02-17 16:53:36,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:37,211][root][INFO] - Training Epoch: 1/2, step 4694/107898 completed (loss: 0.7522593140602112, acc: 0.9285714030265808)
[2025-02-17 16:53:37,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:37,545][root][INFO] - Training Epoch: 1/2, step 4695/107898 completed (loss: 1.680036187171936, acc: 0.6969696879386902)
[2025-02-17 16:53:37,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:37,847][root][INFO] - Training Epoch: 1/2, step 4696/107898 completed (loss: 0.09421641379594803, acc: 1.0)
[2025-02-17 16:53:37,957][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:38,198][root][INFO] - Training Epoch: 1/2, step 4697/107898 completed (loss: 0.7887200117111206, acc: 0.875)
[2025-02-17 16:53:38,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:38,556][root][INFO] - Training Epoch: 1/2, step 4698/107898 completed (loss: 0.9485750794410706, acc: 0.7692307829856873)
[2025-02-17 16:53:38,676][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:38,919][root][INFO] - Training Epoch: 1/2, step 4699/107898 completed (loss: 3.7076828479766846, acc: 0.1666666716337204)
[2025-02-17 16:53:39,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:39,251][root][INFO] - Training Epoch: 1/2, step 4700/107898 completed (loss: 4.158591270446777, acc: 0.3333333432674408)
[2025-02-17 16:53:39,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:39,566][root][INFO] - Training Epoch: 1/2, step 4701/107898 completed (loss: 1.1258468627929688, acc: 0.800000011920929)
[2025-02-17 16:53:39,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:39,859][root][INFO] - Training Epoch: 1/2, step 4702/107898 completed (loss: 0.5693651437759399, acc: 0.5)
[2025-02-17 16:53:39,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:40,167][root][INFO] - Training Epoch: 1/2, step 4703/107898 completed (loss: 0.6663126945495605, acc: 0.8888888955116272)
[2025-02-17 16:53:40,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:40,481][root][INFO] - Training Epoch: 1/2, step 4704/107898 completed (loss: 0.4282870292663574, acc: 1.0)
[2025-02-17 16:53:40,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:40,802][root][INFO] - Training Epoch: 1/2, step 4705/107898 completed (loss: 0.7474015951156616, acc: 0.8823529481887817)
[2025-02-17 16:53:40,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:41,092][root][INFO] - Training Epoch: 1/2, step 4706/107898 completed (loss: 2.1660327911376953, acc: 0.4285714328289032)
[2025-02-17 16:53:41,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:41,376][root][INFO] - Training Epoch: 1/2, step 4707/107898 completed (loss: 0.06087889522314072, acc: 1.0)
[2025-02-17 16:53:41,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:41,676][root][INFO] - Training Epoch: 1/2, step 4708/107898 completed (loss: 1.2718430757522583, acc: 0.8181818127632141)
[2025-02-17 16:53:41,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:42,016][root][INFO] - Training Epoch: 1/2, step 4709/107898 completed (loss: 0.10931088775396347, acc: 1.0)
[2025-02-17 16:53:42,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:42,317][root][INFO] - Training Epoch: 1/2, step 4710/107898 completed (loss: 1.7002241611480713, acc: 0.5)
[2025-02-17 16:53:42,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:42,628][root][INFO] - Training Epoch: 1/2, step 4711/107898 completed (loss: 0.44188392162323, acc: 0.9166666865348816)
[2025-02-17 16:53:42,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:42,932][root][INFO] - Training Epoch: 1/2, step 4712/107898 completed (loss: 1.8861690759658813, acc: 0.5789473652839661)
[2025-02-17 16:53:43,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:43,255][root][INFO] - Training Epoch: 1/2, step 4713/107898 completed (loss: 0.5163209438323975, acc: 0.875)
[2025-02-17 16:53:43,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:43,547][root][INFO] - Training Epoch: 1/2, step 4714/107898 completed (loss: 0.19263099133968353, acc: 1.0)
[2025-02-17 16:53:43,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:43,921][root][INFO] - Training Epoch: 1/2, step 4715/107898 completed (loss: 0.18895959854125977, acc: 0.9375)
[2025-02-17 16:53:44,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:44,240][root][INFO] - Training Epoch: 1/2, step 4716/107898 completed (loss: 1.5194236040115356, acc: 0.774193525314331)
[2025-02-17 16:53:44,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:44,609][root][INFO] - Training Epoch: 1/2, step 4717/107898 completed (loss: 3.256845235824585, acc: 0.42307692766189575)
[2025-02-17 16:53:44,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:44,905][root][INFO] - Training Epoch: 1/2, step 4718/107898 completed (loss: 0.7017547488212585, acc: 0.8333333134651184)
[2025-02-17 16:53:44,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:45,212][root][INFO] - Training Epoch: 1/2, step 4719/107898 completed (loss: 1.2337464094161987, acc: 0.6764705777168274)
[2025-02-17 16:53:45,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:45,500][root][INFO] - Training Epoch: 1/2, step 4720/107898 completed (loss: 2.978646755218506, acc: 0.3333333432674408)
[2025-02-17 16:53:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:45,798][root][INFO] - Training Epoch: 1/2, step 4721/107898 completed (loss: 0.004136997740715742, acc: 1.0)
[2025-02-17 16:53:45,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:46,092][root][INFO] - Training Epoch: 1/2, step 4722/107898 completed (loss: 0.17519545555114746, acc: 1.0)
[2025-02-17 16:53:46,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:46,408][root][INFO] - Training Epoch: 1/2, step 4723/107898 completed (loss: 0.7588998675346375, acc: 0.8125)
[2025-02-17 16:53:46,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:46,710][root][INFO] - Training Epoch: 1/2, step 4724/107898 completed (loss: 0.7164671421051025, acc: 0.75)
[2025-02-17 16:53:46,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:47,006][root][INFO] - Training Epoch: 1/2, step 4725/107898 completed (loss: 0.9644753336906433, acc: 0.800000011920929)
[2025-02-17 16:53:47,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:47,297][root][INFO] - Training Epoch: 1/2, step 4726/107898 completed (loss: 1.6318126916885376, acc: 0.4000000059604645)
[2025-02-17 16:53:47,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:47,640][root][INFO] - Training Epoch: 1/2, step 4727/107898 completed (loss: 2.026951789855957, acc: 0.5555555820465088)
[2025-02-17 16:53:47,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:47,930][root][INFO] - Training Epoch: 1/2, step 4728/107898 completed (loss: 0.13961365818977356, acc: 1.0)
[2025-02-17 16:53:48,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:48,229][root][INFO] - Training Epoch: 1/2, step 4729/107898 completed (loss: 0.045309264212846756, acc: 1.0)
[2025-02-17 16:53:48,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:48,576][root][INFO] - Training Epoch: 1/2, step 4730/107898 completed (loss: 0.225790873169899, acc: 0.9444444179534912)
[2025-02-17 16:53:48,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:48,900][root][INFO] - Training Epoch: 1/2, step 4731/107898 completed (loss: 1.650874376296997, acc: 0.7142857313156128)
[2025-02-17 16:53:49,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:49,237][root][INFO] - Training Epoch: 1/2, step 4732/107898 completed (loss: 0.862276017665863, acc: 0.807692289352417)
[2025-02-17 16:53:49,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:49,551][root][INFO] - Training Epoch: 1/2, step 4733/107898 completed (loss: 1.4741944074630737, acc: 0.6785714030265808)
[2025-02-17 16:53:49,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:49,873][root][INFO] - Training Epoch: 1/2, step 4734/107898 completed (loss: 4.367864608764648, acc: 0.5714285969734192)
[2025-02-17 16:53:49,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:50,186][root][INFO] - Training Epoch: 1/2, step 4735/107898 completed (loss: 1.3117389678955078, acc: 0.7777777910232544)
[2025-02-17 16:53:50,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:50,495][root][INFO] - Training Epoch: 1/2, step 4736/107898 completed (loss: 2.4803030490875244, acc: 0.6153846383094788)
[2025-02-17 16:53:50,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:50,777][root][INFO] - Training Epoch: 1/2, step 4737/107898 completed (loss: 1.744530200958252, acc: 0.8181818127632141)
[2025-02-17 16:53:50,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:51,086][root][INFO] - Training Epoch: 1/2, step 4738/107898 completed (loss: 0.8620907664299011, acc: 0.75)
[2025-02-17 16:53:51,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:51,455][root][INFO] - Training Epoch: 1/2, step 4739/107898 completed (loss: 4.316353797912598, acc: 0.23529411852359772)
[2025-02-17 16:53:51,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:51,797][root][INFO] - Training Epoch: 1/2, step 4740/107898 completed (loss: 0.701815128326416, acc: 0.800000011920929)
[2025-02-17 16:53:51,887][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:52,121][root][INFO] - Training Epoch: 1/2, step 4741/107898 completed (loss: 0.1101374700665474, acc: 1.0)
[2025-02-17 16:53:52,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:52,455][root][INFO] - Training Epoch: 1/2, step 4742/107898 completed (loss: 0.002923702821135521, acc: 1.0)
[2025-02-17 16:53:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:52,781][root][INFO] - Training Epoch: 1/2, step 4743/107898 completed (loss: 0.27691563963890076, acc: 1.0)
[2025-02-17 16:53:52,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:53,097][root][INFO] - Training Epoch: 1/2, step 4744/107898 completed (loss: 0.7463093996047974, acc: 0.75)
[2025-02-17 16:53:53,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:53,389][root][INFO] - Training Epoch: 1/2, step 4745/107898 completed (loss: 1.498972773551941, acc: 0.7692307829856873)
[2025-02-17 16:53:53,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:53,696][root][INFO] - Training Epoch: 1/2, step 4746/107898 completed (loss: 1.1121641397476196, acc: 0.7142857313156128)
[2025-02-17 16:53:53,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:54,027][root][INFO] - Training Epoch: 1/2, step 4747/107898 completed (loss: 1.3983049392700195, acc: 0.625)
[2025-02-17 16:53:54,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:54,324][root][INFO] - Training Epoch: 1/2, step 4748/107898 completed (loss: 0.40254244208335876, acc: 0.75)
[2025-02-17 16:53:54,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:54,649][root][INFO] - Training Epoch: 1/2, step 4749/107898 completed (loss: 3.5401968955993652, acc: 0.3181818127632141)
[2025-02-17 16:53:54,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:54,961][root][INFO] - Training Epoch: 1/2, step 4750/107898 completed (loss: 1.2450668811798096, acc: 0.875)
[2025-02-17 16:53:55,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:55,262][root][INFO] - Training Epoch: 1/2, step 4751/107898 completed (loss: 2.389230489730835, acc: 0.7142857313156128)
[2025-02-17 16:53:55,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:55,580][root][INFO] - Training Epoch: 1/2, step 4752/107898 completed (loss: 1.3749144077301025, acc: 0.761904776096344)
[2025-02-17 16:53:55,685][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:55,912][root][INFO] - Training Epoch: 1/2, step 4753/107898 completed (loss: 1.975046992301941, acc: 0.6666666865348816)
[2025-02-17 16:53:56,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:56,229][root][INFO] - Training Epoch: 1/2, step 4754/107898 completed (loss: 0.001933708437718451, acc: 1.0)
[2025-02-17 16:53:56,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:56,512][root][INFO] - Training Epoch: 1/2, step 4755/107898 completed (loss: 1.2340997457504272, acc: 0.6363636255264282)
[2025-02-17 16:53:56,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:56,869][root][INFO] - Training Epoch: 1/2, step 4756/107898 completed (loss: 0.4152948260307312, acc: 0.8571428656578064)
[2025-02-17 16:53:56,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:57,190][root][INFO] - Training Epoch: 1/2, step 4757/107898 completed (loss: 1.3770514726638794, acc: 0.3333333432674408)
[2025-02-17 16:53:57,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:57,484][root][INFO] - Training Epoch: 1/2, step 4758/107898 completed (loss: 0.007064383942633867, acc: 1.0)
[2025-02-17 16:53:57,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:57,816][root][INFO] - Training Epoch: 1/2, step 4759/107898 completed (loss: 0.8149810433387756, acc: 0.8999999761581421)
[2025-02-17 16:53:57,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:58,119][root][INFO] - Training Epoch: 1/2, step 4760/107898 completed (loss: 0.3089924156665802, acc: 1.0)
[2025-02-17 16:53:58,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:58,434][root][INFO] - Training Epoch: 1/2, step 4761/107898 completed (loss: 0.47445395588874817, acc: 0.5)
[2025-02-17 16:53:58,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:58,749][root][INFO] - Training Epoch: 1/2, step 4762/107898 completed (loss: 0.10749214887619019, acc: 0.9655172228813171)
[2025-02-17 16:53:58,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:59,061][root][INFO] - Training Epoch: 1/2, step 4763/107898 completed (loss: 0.4988408386707306, acc: 0.8421052694320679)
[2025-02-17 16:53:59,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:59,363][root][INFO] - Training Epoch: 1/2, step 4764/107898 completed (loss: 1.780424952507019, acc: 0.7142857313156128)
[2025-02-17 16:53:59,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:53:59,694][root][INFO] - Training Epoch: 1/2, step 4765/107898 completed (loss: 0.2095814198255539, acc: 1.0)
[2025-02-17 16:53:59,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:00,018][root][INFO] - Training Epoch: 1/2, step 4766/107898 completed (loss: 2.615989923477173, acc: 0.6666666865348816)
[2025-02-17 16:54:00,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:00,322][root][INFO] - Training Epoch: 1/2, step 4767/107898 completed (loss: 3.472193717956543, acc: 0.4444444477558136)
[2025-02-17 16:54:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:00,646][root][INFO] - Training Epoch: 1/2, step 4768/107898 completed (loss: 0.0644821897149086, acc: 1.0)
[2025-02-17 16:54:00,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:00,952][root][INFO] - Training Epoch: 1/2, step 4769/107898 completed (loss: 1.562729835510254, acc: 0.8235294222831726)
[2025-02-17 16:54:01,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:01,250][root][INFO] - Training Epoch: 1/2, step 4770/107898 completed (loss: 0.005384017247706652, acc: 1.0)
[2025-02-17 16:54:01,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:01,607][root][INFO] - Training Epoch: 1/2, step 4771/107898 completed (loss: 0.8653872013092041, acc: 0.8636363744735718)
[2025-02-17 16:54:01,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:01,938][root][INFO] - Training Epoch: 1/2, step 4772/107898 completed (loss: 1.7452174425125122, acc: 0.7272727489471436)
[2025-02-17 16:54:02,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:02,241][root][INFO] - Training Epoch: 1/2, step 4773/107898 completed (loss: 0.4358978867530823, acc: 0.8947368264198303)
[2025-02-17 16:54:02,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:02,526][root][INFO] - Training Epoch: 1/2, step 4774/107898 completed (loss: 0.003548627719283104, acc: 1.0)
[2025-02-17 16:54:02,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:02,857][root][INFO] - Training Epoch: 1/2, step 4775/107898 completed (loss: 1.0526305437088013, acc: 0.5714285969734192)
[2025-02-17 16:54:02,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:03,158][root][INFO] - Training Epoch: 1/2, step 4776/107898 completed (loss: 0.22440047562122345, acc: 1.0)
[2025-02-17 16:54:03,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:03,477][root][INFO] - Training Epoch: 1/2, step 4777/107898 completed (loss: 0.18586190044879913, acc: 0.9375)
[2025-02-17 16:54:03,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:03,810][root][INFO] - Training Epoch: 1/2, step 4778/107898 completed (loss: 4.046138286590576, acc: 0.27272728085517883)
[2025-02-17 16:54:03,882][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:04,092][root][INFO] - Training Epoch: 1/2, step 4779/107898 completed (loss: 0.39432433247566223, acc: 0.875)
[2025-02-17 16:54:04,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:04,382][root][INFO] - Training Epoch: 1/2, step 4780/107898 completed (loss: 0.08864207565784454, acc: 1.0)
[2025-02-17 16:54:04,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:04,711][root][INFO] - Training Epoch: 1/2, step 4781/107898 completed (loss: 0.0010944003006443381, acc: 1.0)
[2025-02-17 16:54:04,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:05,052][root][INFO] - Training Epoch: 1/2, step 4782/107898 completed (loss: 0.9839478731155396, acc: 0.75)
[2025-02-17 16:54:05,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:05,399][root][INFO] - Training Epoch: 1/2, step 4783/107898 completed (loss: 1.3649386167526245, acc: 0.7368420958518982)
[2025-02-17 16:54:05,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:05,739][root][INFO] - Training Epoch: 1/2, step 4784/107898 completed (loss: 0.8700503706932068, acc: 0.875)
[2025-02-17 16:54:05,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:06,020][root][INFO] - Training Epoch: 1/2, step 4785/107898 completed (loss: 1.2030178308486938, acc: 0.6428571343421936)
[2025-02-17 16:54:06,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:06,360][root][INFO] - Training Epoch: 1/2, step 4786/107898 completed (loss: 0.0041765207424759865, acc: 1.0)
[2025-02-17 16:54:06,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:06,675][root][INFO] - Training Epoch: 1/2, step 4787/107898 completed (loss: 0.1284502148628235, acc: 1.0)
[2025-02-17 16:54:06,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:07,014][root][INFO] - Training Epoch: 1/2, step 4788/107898 completed (loss: 1.350736379623413, acc: 0.8421052694320679)
[2025-02-17 16:54:07,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:07,386][root][INFO] - Training Epoch: 1/2, step 4789/107898 completed (loss: 0.96706622838974, acc: 0.8225806355476379)
[2025-02-17 16:54:07,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:07,701][root][INFO] - Training Epoch: 1/2, step 4790/107898 completed (loss: 0.4047221839427948, acc: 0.8888888955116272)
[2025-02-17 16:54:07,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:08,045][root][INFO] - Training Epoch: 1/2, step 4791/107898 completed (loss: 1.1297632455825806, acc: 0.75)
[2025-02-17 16:54:08,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:08,366][root][INFO] - Training Epoch: 1/2, step 4792/107898 completed (loss: 0.004864862654358149, acc: 1.0)
[2025-02-17 16:54:08,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:08,647][root][INFO] - Training Epoch: 1/2, step 4793/107898 completed (loss: 1.0365275144577026, acc: 0.8333333134651184)
[2025-02-17 16:54:08,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:08,993][root][INFO] - Training Epoch: 1/2, step 4794/107898 completed (loss: 0.08232977986335754, acc: 1.0)
[2025-02-17 16:54:09,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:09,334][root][INFO] - Training Epoch: 1/2, step 4795/107898 completed (loss: 1.028149962425232, acc: 0.7142857313156128)
[2025-02-17 16:54:09,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:09,661][root][INFO] - Training Epoch: 1/2, step 4796/107898 completed (loss: 4.155367851257324, acc: 0.20000000298023224)
[2025-02-17 16:54:09,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:10,009][root][INFO] - Training Epoch: 1/2, step 4797/107898 completed (loss: 0.8272597193717957, acc: 0.8571428656578064)
[2025-02-17 16:54:10,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:10,331][root][INFO] - Training Epoch: 1/2, step 4798/107898 completed (loss: 3.2470555305480957, acc: 0.5)
[2025-02-17 16:54:10,414][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:10,638][root][INFO] - Training Epoch: 1/2, step 4799/107898 completed (loss: 1.5740138292312622, acc: 0.5)
[2025-02-17 16:54:10,731][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:10,960][root][INFO] - Training Epoch: 1/2, step 4800/107898 completed (loss: 1.1933636665344238, acc: 0.8999999761581421)
[2025-02-17 16:54:11,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:11,275][root][INFO] - Training Epoch: 1/2, step 4801/107898 completed (loss: 0.05273493006825447, acc: 1.0)
[2025-02-17 16:54:11,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:11,605][root][INFO] - Training Epoch: 1/2, step 4802/107898 completed (loss: 2.028714179992676, acc: 0.5)
[2025-02-17 16:54:11,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:11,960][root][INFO] - Training Epoch: 1/2, step 4803/107898 completed (loss: 0.6531068682670593, acc: 0.8421052694320679)
[2025-02-17 16:54:12,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:12,295][root][INFO] - Training Epoch: 1/2, step 4804/107898 completed (loss: 1.9509931802749634, acc: 0.7142857313156128)
[2025-02-17 16:54:12,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:12,586][root][INFO] - Training Epoch: 1/2, step 4805/107898 completed (loss: 0.31557920575141907, acc: 0.8823529481887817)
[2025-02-17 16:54:12,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:12,889][root][INFO] - Training Epoch: 1/2, step 4806/107898 completed (loss: 0.14786045253276825, acc: 0.9523809552192688)
[2025-02-17 16:54:12,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:13,220][root][INFO] - Training Epoch: 1/2, step 4807/107898 completed (loss: 0.3604956269264221, acc: 0.9090909361839294)
[2025-02-17 16:54:13,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:13,524][root][INFO] - Training Epoch: 1/2, step 4808/107898 completed (loss: 0.2088485211133957, acc: 0.9473684430122375)
[2025-02-17 16:54:13,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:13,820][root][INFO] - Training Epoch: 1/2, step 4809/107898 completed (loss: 0.916641891002655, acc: 0.8620689511299133)
[2025-02-17 16:54:13,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:14,125][root][INFO] - Training Epoch: 1/2, step 4810/107898 completed (loss: 0.3546704053878784, acc: 0.9473684430122375)
[2025-02-17 16:54:14,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:14,413][root][INFO] - Training Epoch: 1/2, step 4811/107898 completed (loss: 2.817586660385132, acc: 0.3333333432674408)
[2025-02-17 16:54:14,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:14,676][root][INFO] - Training Epoch: 1/2, step 4812/107898 completed (loss: 0.004542423877865076, acc: 1.0)
[2025-02-17 16:54:14,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:14,956][root][INFO] - Training Epoch: 1/2, step 4813/107898 completed (loss: 0.6648960113525391, acc: 0.7777777910232544)
[2025-02-17 16:54:15,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:15,252][root][INFO] - Training Epoch: 1/2, step 4814/107898 completed (loss: 0.8063084483146667, acc: 0.8095238208770752)
[2025-02-17 16:54:15,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:15,537][root][INFO] - Training Epoch: 1/2, step 4815/107898 completed (loss: 0.039415519684553146, acc: 1.0)
[2025-02-17 16:54:15,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:15,820][root][INFO] - Training Epoch: 1/2, step 4816/107898 completed (loss: 3.6402440071105957, acc: 0.0)
[2025-02-17 16:54:15,896][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:16,134][root][INFO] - Training Epoch: 1/2, step 4817/107898 completed (loss: 2.073545455932617, acc: 0.625)
[2025-02-17 16:54:16,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:16,475][root][INFO] - Training Epoch: 1/2, step 4818/107898 completed (loss: 2.120936393737793, acc: 0.5384615659713745)
[2025-02-17 16:54:16,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:16,788][root][INFO] - Training Epoch: 1/2, step 4819/107898 completed (loss: 1.0190072059631348, acc: 0.8333333134651184)
[2025-02-17 16:54:16,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:17,095][root][INFO] - Training Epoch: 1/2, step 4820/107898 completed (loss: 1.535691261291504, acc: 0.5)
[2025-02-17 16:54:17,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:17,411][root][INFO] - Training Epoch: 1/2, step 4821/107898 completed (loss: 1.520879864692688, acc: 0.6538461446762085)
[2025-02-17 16:54:17,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:17,707][root][INFO] - Training Epoch: 1/2, step 4822/107898 completed (loss: 0.2930677831172943, acc: 0.9047619104385376)
[2025-02-17 16:54:17,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:17,995][root][INFO] - Training Epoch: 1/2, step 4823/107898 completed (loss: 0.47708365321159363, acc: 0.6666666865348816)
[2025-02-17 16:54:18,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:18,278][root][INFO] - Training Epoch: 1/2, step 4824/107898 completed (loss: 0.014335459098219872, acc: 1.0)
[2025-02-17 16:54:18,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:18,565][root][INFO] - Training Epoch: 1/2, step 4825/107898 completed (loss: 1.7858129739761353, acc: 0.75)
[2025-02-17 16:54:18,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:18,897][root][INFO] - Training Epoch: 1/2, step 4826/107898 completed (loss: 1.1477313041687012, acc: 0.8235294222831726)
[2025-02-17 16:54:18,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:19,219][root][INFO] - Training Epoch: 1/2, step 4827/107898 completed (loss: 0.10459943115711212, acc: 1.0)
[2025-02-17 16:54:19,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:19,532][root][INFO] - Training Epoch: 1/2, step 4828/107898 completed (loss: 0.003719259286299348, acc: 1.0)
[2025-02-17 16:54:19,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:19,851][root][INFO] - Training Epoch: 1/2, step 4829/107898 completed (loss: 3.1513209342956543, acc: 0.4444444477558136)
[2025-02-17 16:54:19,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:20,199][root][INFO] - Training Epoch: 1/2, step 4830/107898 completed (loss: 0.0016361339949071407, acc: 1.0)
[2025-02-17 16:54:20,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:20,508][root][INFO] - Training Epoch: 1/2, step 4831/107898 completed (loss: 0.015537346713244915, acc: 1.0)
[2025-02-17 16:54:20,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:20,828][root][INFO] - Training Epoch: 1/2, step 4832/107898 completed (loss: 1.212207317352295, acc: 0.5882353186607361)
[2025-02-17 16:54:20,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:21,138][root][INFO] - Training Epoch: 1/2, step 4833/107898 completed (loss: 0.16527244448661804, acc: 0.9230769276618958)
[2025-02-17 16:54:21,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:21,443][root][INFO] - Training Epoch: 1/2, step 4834/107898 completed (loss: 2.316143035888672, acc: 0.625)
[2025-02-17 16:54:21,517][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:21,733][root][INFO] - Training Epoch: 1/2, step 4835/107898 completed (loss: 0.6549437046051025, acc: 0.7777777910232544)
[2025-02-17 16:54:21,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:22,061][root][INFO] - Training Epoch: 1/2, step 4836/107898 completed (loss: 0.24981029331684113, acc: 1.0)
[2025-02-17 16:54:22,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:22,379][root][INFO] - Training Epoch: 1/2, step 4837/107898 completed (loss: 0.22737689316272736, acc: 1.0)
[2025-02-17 16:54:22,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:22,693][root][INFO] - Training Epoch: 1/2, step 4838/107898 completed (loss: 0.010466022416949272, acc: 1.0)
[2025-02-17 16:54:22,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:22,997][root][INFO] - Training Epoch: 1/2, step 4839/107898 completed (loss: 0.0035865544341504574, acc: 1.0)
[2025-02-17 16:54:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:23,314][root][INFO] - Training Epoch: 1/2, step 4840/107898 completed (loss: 0.4109177589416504, acc: 0.9285714030265808)
[2025-02-17 16:54:23,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:23,627][root][INFO] - Training Epoch: 1/2, step 4841/107898 completed (loss: 3.2130861282348633, acc: 0.25)
[2025-02-17 16:54:23,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:23,923][root][INFO] - Training Epoch: 1/2, step 4842/107898 completed (loss: 0.9641177654266357, acc: 0.7272727489471436)
[2025-02-17 16:54:24,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:24,267][root][INFO] - Training Epoch: 1/2, step 4843/107898 completed (loss: 1.302721619606018, acc: 0.7142857313156128)
[2025-02-17 16:54:24,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:24,551][root][INFO] - Training Epoch: 1/2, step 4844/107898 completed (loss: 0.7980595231056213, acc: 0.75)
[2025-02-17 16:54:24,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:24,886][root][INFO] - Training Epoch: 1/2, step 4845/107898 completed (loss: 0.3951510787010193, acc: 0.9722222089767456)
[2025-02-17 16:54:24,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:25,233][root][INFO] - Training Epoch: 1/2, step 4846/107898 completed (loss: 0.05986542999744415, acc: 1.0)
[2025-02-17 16:54:25,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:25,551][root][INFO] - Training Epoch: 1/2, step 4847/107898 completed (loss: 0.7024387717247009, acc: 0.7777777910232544)
[2025-02-17 16:54:25,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:25,864][root][INFO] - Training Epoch: 1/2, step 4848/107898 completed (loss: 1.7831217050552368, acc: 0.5)
[2025-02-17 16:54:25,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:26,208][root][INFO] - Training Epoch: 1/2, step 4849/107898 completed (loss: 0.3195139169692993, acc: 0.8823529481887817)
[2025-02-17 16:54:26,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:26,558][root][INFO] - Training Epoch: 1/2, step 4850/107898 completed (loss: 1.6677329540252686, acc: 0.7777777910232544)
[2025-02-17 16:54:26,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:26,879][root][INFO] - Training Epoch: 1/2, step 4851/107898 completed (loss: 0.1251901090145111, acc: 1.0)
[2025-02-17 16:54:26,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:27,194][root][INFO] - Training Epoch: 1/2, step 4852/107898 completed (loss: 0.13758058845996857, acc: 1.0)
[2025-02-17 16:54:27,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:27,512][root][INFO] - Training Epoch: 1/2, step 4853/107898 completed (loss: 0.40645724534988403, acc: 0.8846153616905212)
[2025-02-17 16:54:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:27,844][root][INFO] - Training Epoch: 1/2, step 4854/107898 completed (loss: 0.39262673258781433, acc: 0.8571428656578064)
[2025-02-17 16:54:27,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:28,194][root][INFO] - Training Epoch: 1/2, step 4855/107898 completed (loss: 0.985526442527771, acc: 1.0)
[2025-02-17 16:54:28,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:28,478][root][INFO] - Training Epoch: 1/2, step 4856/107898 completed (loss: 0.4617330729961395, acc: 0.8888888955116272)
[2025-02-17 16:54:28,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:28,773][root][INFO] - Training Epoch: 1/2, step 4857/107898 completed (loss: 0.32263875007629395, acc: 1.0)
[2025-02-17 16:54:28,849][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:29,076][root][INFO] - Training Epoch: 1/2, step 4858/107898 completed (loss: 2.233098030090332, acc: 0.5454545617103577)
[2025-02-17 16:54:29,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:29,413][root][INFO] - Training Epoch: 1/2, step 4859/107898 completed (loss: 0.40145355463027954, acc: 0.5)
[2025-02-17 16:54:29,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:29,748][root][INFO] - Training Epoch: 1/2, step 4860/107898 completed (loss: 2.188711404800415, acc: 0.5384615659713745)
[2025-02-17 16:54:29,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:30,126][root][INFO] - Training Epoch: 1/2, step 4861/107898 completed (loss: 2.0642213821411133, acc: 0.7272727489471436)
[2025-02-17 16:54:30,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:30,458][root][INFO] - Training Epoch: 1/2, step 4862/107898 completed (loss: 0.10538919270038605, acc: 1.0)
[2025-02-17 16:54:30,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:30,744][root][INFO] - Training Epoch: 1/2, step 4863/107898 completed (loss: 0.4092373549938202, acc: 0.8666666746139526)
[2025-02-17 16:54:30,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:31,081][root][INFO] - Training Epoch: 1/2, step 4864/107898 completed (loss: 0.22714577615261078, acc: 0.9230769276618958)
[2025-02-17 16:54:31,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:31,445][root][INFO] - Training Epoch: 1/2, step 4865/107898 completed (loss: 1.3250089883804321, acc: 0.800000011920929)
[2025-02-17 16:54:31,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:31,814][root][INFO] - Training Epoch: 1/2, step 4866/107898 completed (loss: 0.3329693078994751, acc: 0.914893627166748)
[2025-02-17 16:54:31,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:32,108][root][INFO] - Training Epoch: 1/2, step 4867/107898 completed (loss: 0.07036176323890686, acc: 1.0)
[2025-02-17 16:54:32,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:32,457][root][INFO] - Training Epoch: 1/2, step 4868/107898 completed (loss: 1.623244285583496, acc: 0.761904776096344)
[2025-02-17 16:54:32,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:32,791][root][INFO] - Training Epoch: 1/2, step 4869/107898 completed (loss: 1.2834230661392212, acc: 0.5555555820465088)
[2025-02-17 16:54:32,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:33,090][root][INFO] - Training Epoch: 1/2, step 4870/107898 completed (loss: 0.17688986659049988, acc: 1.0)
[2025-02-17 16:54:33,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:33,418][root][INFO] - Training Epoch: 1/2, step 4871/107898 completed (loss: 4.021079063415527, acc: 0.0)
[2025-02-17 16:54:33,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:33,732][root][INFO] - Training Epoch: 1/2, step 4872/107898 completed (loss: 2.5063490867614746, acc: 0.7058823704719543)
[2025-02-17 16:54:33,816][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:34,035][root][INFO] - Training Epoch: 1/2, step 4873/107898 completed (loss: 2.822544813156128, acc: 0.25)
[2025-02-17 16:54:34,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:34,373][root][INFO] - Training Epoch: 1/2, step 4874/107898 completed (loss: 0.018823713064193726, acc: 1.0)
[2025-02-17 16:54:34,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:34,665][root][INFO] - Training Epoch: 1/2, step 4875/107898 completed (loss: 0.315971702337265, acc: 0.9285714030265808)
[2025-02-17 16:54:34,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:34,963][root][INFO] - Training Epoch: 1/2, step 4876/107898 completed (loss: 4.603278160095215, acc: 0.27272728085517883)
[2025-02-17 16:54:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:35,254][root][INFO] - Training Epoch: 1/2, step 4877/107898 completed (loss: 0.014956828206777573, acc: 1.0)
[2025-02-17 16:54:35,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:35,591][root][INFO] - Training Epoch: 1/2, step 4878/107898 completed (loss: 1.4946397542953491, acc: 0.875)
[2025-02-17 16:54:35,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:35,914][root][INFO] - Training Epoch: 1/2, step 4879/107898 completed (loss: 1.1039084196090698, acc: 0.800000011920929)
[2025-02-17 16:54:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:36,197][root][INFO] - Training Epoch: 1/2, step 4880/107898 completed (loss: 0.0046048592776060104, acc: 1.0)
[2025-02-17 16:54:36,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:36,553][root][INFO] - Training Epoch: 1/2, step 4881/107898 completed (loss: 0.7690035104751587, acc: 0.782608687877655)
[2025-02-17 16:54:36,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:36,888][root][INFO] - Training Epoch: 1/2, step 4882/107898 completed (loss: 0.34527143836021423, acc: 1.0)
[2025-02-17 16:54:37,005][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:37,242][root][INFO] - Training Epoch: 1/2, step 4883/107898 completed (loss: 0.001779057434760034, acc: 1.0)
[2025-02-17 16:54:37,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:37,595][root][INFO] - Training Epoch: 1/2, step 4884/107898 completed (loss: 0.6228770017623901, acc: 0.8636363744735718)
[2025-02-17 16:54:37,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:37,908][root][INFO] - Training Epoch: 1/2, step 4885/107898 completed (loss: 1.6580380201339722, acc: 0.7200000286102295)
[2025-02-17 16:54:37,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:38,206][root][INFO] - Training Epoch: 1/2, step 4886/107898 completed (loss: 1.3479562997817993, acc: 0.6666666865348816)
[2025-02-17 16:54:38,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:38,547][root][INFO] - Training Epoch: 1/2, step 4887/107898 completed (loss: 0.0024669698905199766, acc: 1.0)
[2025-02-17 16:54:38,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:38,874][root][INFO] - Training Epoch: 1/2, step 4888/107898 completed (loss: 1.1193656921386719, acc: 0.8181818127632141)
[2025-02-17 16:54:38,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:39,181][root][INFO] - Training Epoch: 1/2, step 4889/107898 completed (loss: 0.2213713377714157, acc: 0.949999988079071)
[2025-02-17 16:54:39,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:39,491][root][INFO] - Training Epoch: 1/2, step 4890/107898 completed (loss: 1.3045071363449097, acc: 0.6666666865348816)
[2025-02-17 16:54:39,599][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:39,835][root][INFO] - Training Epoch: 1/2, step 4891/107898 completed (loss: 0.8714985847473145, acc: 0.75)
[2025-02-17 16:54:39,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:40,133][root][INFO] - Training Epoch: 1/2, step 4892/107898 completed (loss: 0.24175004661083221, acc: 0.9333333373069763)
[2025-02-17 16:54:40,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:40,490][root][INFO] - Training Epoch: 1/2, step 4893/107898 completed (loss: 0.1910315304994583, acc: 1.0)
[2025-02-17 16:54:40,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:40,849][root][INFO] - Training Epoch: 1/2, step 4894/107898 completed (loss: 0.8982387185096741, acc: 1.0)
[2025-02-17 16:54:40,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:41,179][root][INFO] - Training Epoch: 1/2, step 4895/107898 completed (loss: 1.7296314239501953, acc: 0.7272727489471436)
[2025-02-17 16:54:41,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:41,522][root][INFO] - Training Epoch: 1/2, step 4896/107898 completed (loss: 0.5768715143203735, acc: 0.8999999761581421)
[2025-02-17 16:54:41,631][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:41,865][root][INFO] - Training Epoch: 1/2, step 4897/107898 completed (loss: 1.06934654712677, acc: 0.8333333134651184)
[2025-02-17 16:54:41,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:42,153][root][INFO] - Training Epoch: 1/2, step 4898/107898 completed (loss: 0.47047218680381775, acc: 0.7857142686843872)
[2025-02-17 16:54:42,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:42,496][root][INFO] - Training Epoch: 1/2, step 4899/107898 completed (loss: 4.7373199462890625, acc: 0.3333333432674408)
[2025-02-17 16:54:42,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:42,852][root][INFO] - Training Epoch: 1/2, step 4900/107898 completed (loss: 0.0923025980591774, acc: 1.0)
[2025-02-17 16:54:42,949][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:43,156][root][INFO] - Training Epoch: 1/2, step 4901/107898 completed (loss: 0.7708855867385864, acc: 0.8999999761581421)
[2025-02-17 16:54:43,259][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:43,493][root][INFO] - Training Epoch: 1/2, step 4902/107898 completed (loss: 1.321670413017273, acc: 0.6666666865348816)
[2025-02-17 16:54:43,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:43,848][root][INFO] - Training Epoch: 1/2, step 4903/107898 completed (loss: 0.014196231961250305, acc: 1.0)
[2025-02-17 16:54:43,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:44,170][root][INFO] - Training Epoch: 1/2, step 4904/107898 completed (loss: 2.066804885864258, acc: 0.5555555820465088)
[2025-02-17 16:54:44,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:44,476][root][INFO] - Training Epoch: 1/2, step 4905/107898 completed (loss: 0.20645268261432648, acc: 1.0)
[2025-02-17 16:54:44,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:44,821][root][INFO] - Training Epoch: 1/2, step 4906/107898 completed (loss: 0.08627699315547943, acc: 1.0)
[2025-02-17 16:54:44,925][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:45,155][root][INFO] - Training Epoch: 1/2, step 4907/107898 completed (loss: 0.6038277745246887, acc: 0.90625)
[2025-02-17 16:54:45,259][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:45,497][root][INFO] - Training Epoch: 1/2, step 4908/107898 completed (loss: 0.8698933720588684, acc: 0.6666666865348816)
[2025-02-17 16:54:45,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:45,842][root][INFO] - Training Epoch: 1/2, step 4909/107898 completed (loss: 2.0479836463928223, acc: 0.6000000238418579)
[2025-02-17 16:54:45,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:46,153][root][INFO] - Training Epoch: 1/2, step 4910/107898 completed (loss: 0.04262789711356163, acc: 1.0)
[2025-02-17 16:54:46,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:46,473][root][INFO] - Training Epoch: 1/2, step 4911/107898 completed (loss: 0.44239160418510437, acc: 1.0)
[2025-02-17 16:54:46,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:46,803][root][INFO] - Training Epoch: 1/2, step 4912/107898 completed (loss: 4.378920078277588, acc: 0.5)
[2025-02-17 16:54:46,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:47,124][root][INFO] - Training Epoch: 1/2, step 4913/107898 completed (loss: 0.28998425602912903, acc: 0.9375)
[2025-02-17 16:54:47,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:47,508][root][INFO] - Training Epoch: 1/2, step 4914/107898 completed (loss: 0.9527758359909058, acc: 0.800000011920929)
[2025-02-17 16:54:47,611][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:47,839][root][INFO] - Training Epoch: 1/2, step 4915/107898 completed (loss: 0.3184933364391327, acc: 0.8999999761581421)
[2025-02-17 16:54:47,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:48,160][root][INFO] - Training Epoch: 1/2, step 4916/107898 completed (loss: 0.2113310992717743, acc: 1.0)
[2025-02-17 16:54:48,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:48,469][root][INFO] - Training Epoch: 1/2, step 4917/107898 completed (loss: 2.6101956367492676, acc: 0.3333333432674408)
[2025-02-17 16:54:48,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:48,757][root][INFO] - Training Epoch: 1/2, step 4918/107898 completed (loss: 3.375486135482788, acc: 0.3333333432674408)
[2025-02-17 16:54:48,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:49,066][root][INFO] - Training Epoch: 1/2, step 4919/107898 completed (loss: 0.37282511591911316, acc: 0.8999999761581421)
[2025-02-17 16:54:49,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:49,437][root][INFO] - Training Epoch: 1/2, step 4920/107898 completed (loss: 0.024562697857618332, acc: 1.0)
[2025-02-17 16:54:49,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:49,783][root][INFO] - Training Epoch: 1/2, step 4921/107898 completed (loss: 0.06411252170801163, acc: 1.0)
[2025-02-17 16:54:49,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:50,122][root][INFO] - Training Epoch: 1/2, step 4922/107898 completed (loss: 0.05293813347816467, acc: 1.0)
[2025-02-17 16:54:50,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:50,453][root][INFO] - Training Epoch: 1/2, step 4923/107898 completed (loss: 0.5079201459884644, acc: 0.8571428656578064)
[2025-02-17 16:54:50,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:50,814][root][INFO] - Training Epoch: 1/2, step 4924/107898 completed (loss: 0.994966983795166, acc: 0.7857142686843872)
[2025-02-17 16:54:50,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:51,119][root][INFO] - Training Epoch: 1/2, step 4925/107898 completed (loss: 1.8271290063858032, acc: 0.5)
[2025-02-17 16:54:51,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:51,428][root][INFO] - Training Epoch: 1/2, step 4926/107898 completed (loss: 0.636044979095459, acc: 1.0)
[2025-02-17 16:54:51,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:51,747][root][INFO] - Training Epoch: 1/2, step 4927/107898 completed (loss: 0.14383746683597565, acc: 1.0)
[2025-02-17 16:54:51,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:52,101][root][INFO] - Training Epoch: 1/2, step 4928/107898 completed (loss: 0.41084060072898865, acc: 0.7777777910232544)
[2025-02-17 16:54:52,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:52,429][root][INFO] - Training Epoch: 1/2, step 4929/107898 completed (loss: 0.6475619673728943, acc: 0.8888888955116272)
[2025-02-17 16:54:52,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:52,747][root][INFO] - Training Epoch: 1/2, step 4930/107898 completed (loss: 1.0427852869033813, acc: 0.8333333134651184)
[2025-02-17 16:54:52,832][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:53,045][root][INFO] - Training Epoch: 1/2, step 4931/107898 completed (loss: 0.9001685976982117, acc: 0.5)
[2025-02-17 16:54:53,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:53,328][root][INFO] - Training Epoch: 1/2, step 4932/107898 completed (loss: 0.2952401340007782, acc: 0.8888888955116272)
[2025-02-17 16:54:53,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:53,634][root][INFO] - Training Epoch: 1/2, step 4933/107898 completed (loss: 0.7961370348930359, acc: 0.8571428656578064)
[2025-02-17 16:54:53,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:53,994][root][INFO] - Training Epoch: 1/2, step 4934/107898 completed (loss: 0.16553734242916107, acc: 0.9655172228813171)
[2025-02-17 16:54:54,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:54,310][root][INFO] - Training Epoch: 1/2, step 4935/107898 completed (loss: 1.2850868701934814, acc: 0.8125)
[2025-02-17 16:54:54,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:54,651][root][INFO] - Training Epoch: 1/2, step 4936/107898 completed (loss: 3.529428482055664, acc: 0.3684210479259491)
[2025-02-17 16:54:54,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:54,962][root][INFO] - Training Epoch: 1/2, step 4937/107898 completed (loss: 0.2116440087556839, acc: 0.9375)
[2025-02-17 16:54:55,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:55,262][root][INFO] - Training Epoch: 1/2, step 4938/107898 completed (loss: 0.6667402386665344, acc: 0.8999999761581421)
[2025-02-17 16:54:55,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:55,549][root][INFO] - Training Epoch: 1/2, step 4939/107898 completed (loss: 0.3545095920562744, acc: 1.0)
[2025-02-17 16:54:55,660][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:55,894][root][INFO] - Training Epoch: 1/2, step 4940/107898 completed (loss: 0.3898892104625702, acc: 0.800000011920929)
[2025-02-17 16:54:55,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:56,198][root][INFO] - Training Epoch: 1/2, step 4941/107898 completed (loss: 2.317617893218994, acc: 0.6000000238418579)
[2025-02-17 16:54:56,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:56,499][root][INFO] - Training Epoch: 1/2, step 4942/107898 completed (loss: 0.0446418821811676, acc: 1.0)
[2025-02-17 16:54:56,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:56,798][root][INFO] - Training Epoch: 1/2, step 4943/107898 completed (loss: 1.0461173057556152, acc: 0.800000011920929)
[2025-02-17 16:54:56,912][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:57,134][root][INFO] - Training Epoch: 1/2, step 4944/107898 completed (loss: 0.6077131628990173, acc: 0.90625)
[2025-02-17 16:54:57,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:57,452][root][INFO] - Training Epoch: 1/2, step 4945/107898 completed (loss: 0.25097382068634033, acc: 0.8666666746139526)
[2025-02-17 16:54:57,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:57,770][root][INFO] - Training Epoch: 1/2, step 4946/107898 completed (loss: 0.3007177710533142, acc: 0.9117646813392639)
[2025-02-17 16:54:57,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:58,067][root][INFO] - Training Epoch: 1/2, step 4947/107898 completed (loss: 0.08594782650470734, acc: 1.0)
[2025-02-17 16:54:58,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:58,377][root][INFO] - Training Epoch: 1/2, step 4948/107898 completed (loss: 3.103353977203369, acc: 0.20000000298023224)
[2025-02-17 16:54:58,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:58,720][root][INFO] - Training Epoch: 1/2, step 4949/107898 completed (loss: 0.9967731237411499, acc: 0.75)
[2025-02-17 16:54:58,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:59,037][root][INFO] - Training Epoch: 1/2, step 4950/107898 completed (loss: 2.2934138774871826, acc: 0.48148149251937866)
[2025-02-17 16:54:59,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:59,333][root][INFO] - Training Epoch: 1/2, step 4951/107898 completed (loss: 0.9880568385124207, acc: 0.6666666865348816)
[2025-02-17 16:54:59,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:59,664][root][INFO] - Training Epoch: 1/2, step 4952/107898 completed (loss: 2.414670467376709, acc: 0.1666666716337204)
[2025-02-17 16:54:59,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:54:59,964][root][INFO] - Training Epoch: 1/2, step 4953/107898 completed (loss: 0.6524996757507324, acc: 1.0)
[2025-02-17 16:55:00,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:00,264][root][INFO] - Training Epoch: 1/2, step 4954/107898 completed (loss: 0.23867975175380707, acc: 1.0)
[2025-02-17 16:55:00,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:00,563][root][INFO] - Training Epoch: 1/2, step 4955/107898 completed (loss: 2.4778687953948975, acc: 0.6153846383094788)
[2025-02-17 16:55:00,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:00,894][root][INFO] - Training Epoch: 1/2, step 4956/107898 completed (loss: 0.8607311248779297, acc: 0.8333333134651184)
[2025-02-17 16:55:01,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:01,224][root][INFO] - Training Epoch: 1/2, step 4957/107898 completed (loss: 0.6819295287132263, acc: 0.8571428656578064)
[2025-02-17 16:55:01,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:01,526][root][INFO] - Training Epoch: 1/2, step 4958/107898 completed (loss: 1.3519601821899414, acc: 0.7941176295280457)
[2025-02-17 16:55:01,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:01,808][root][INFO] - Training Epoch: 1/2, step 4959/107898 completed (loss: 0.004850881174206734, acc: 1.0)
[2025-02-17 16:55:01,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:02,102][root][INFO] - Training Epoch: 1/2, step 4960/107898 completed (loss: 2.165766477584839, acc: 0.4000000059604645)
[2025-02-17 16:55:02,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:02,417][root][INFO] - Training Epoch: 1/2, step 4961/107898 completed (loss: 2.321606397628784, acc: 0.6666666865348816)
[2025-02-17 16:55:02,534][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:02,748][root][INFO] - Training Epoch: 1/2, step 4962/107898 completed (loss: 0.7534573674201965, acc: 0.7777777910232544)
[2025-02-17 16:55:02,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:03,040][root][INFO] - Training Epoch: 1/2, step 4963/107898 completed (loss: 0.28941309452056885, acc: 0.9090909361839294)
[2025-02-17 16:55:03,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:03,337][root][INFO] - Training Epoch: 1/2, step 4964/107898 completed (loss: 1.1364736557006836, acc: 0.6666666865348816)
[2025-02-17 16:55:03,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:03,675][root][INFO] - Training Epoch: 1/2, step 4965/107898 completed (loss: 3.232966899871826, acc: 0.3461538553237915)
[2025-02-17 16:55:03,751][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:03,968][root][INFO] - Training Epoch: 1/2, step 4966/107898 completed (loss: 2.68007755279541, acc: 0.3333333432674408)
[2025-02-17 16:55:04,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:04,273][root][INFO] - Training Epoch: 1/2, step 4967/107898 completed (loss: 0.3801485598087311, acc: 1.0)
[2025-02-17 16:55:04,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:04,563][root][INFO] - Training Epoch: 1/2, step 4968/107898 completed (loss: 0.16240300238132477, acc: 1.0)
[2025-02-17 16:55:04,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:04,917][root][INFO] - Training Epoch: 1/2, step 4969/107898 completed (loss: 0.827606737613678, acc: 0.8235294222831726)
[2025-02-17 16:55:05,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:05,303][root][INFO] - Training Epoch: 1/2, step 4970/107898 completed (loss: 1.3222538232803345, acc: 0.7837837934494019)
[2025-02-17 16:55:05,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:05,613][root][INFO] - Training Epoch: 1/2, step 4971/107898 completed (loss: 0.07070695608854294, acc: 1.0)
[2025-02-17 16:55:05,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:05,917][root][INFO] - Training Epoch: 1/2, step 4972/107898 completed (loss: 0.9579452276229858, acc: 0.5)
[2025-02-17 16:55:06,036][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:06,257][root][INFO] - Training Epoch: 1/2, step 4973/107898 completed (loss: 0.02523079514503479, acc: 1.0)
[2025-02-17 16:55:06,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:06,604][root][INFO] - Training Epoch: 1/2, step 4974/107898 completed (loss: 1.9004566669464111, acc: 0.75)
[2025-02-17 16:55:06,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:06,920][root][INFO] - Training Epoch: 1/2, step 4975/107898 completed (loss: 0.03593197092413902, acc: 1.0)
[2025-02-17 16:55:07,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:07,225][root][INFO] - Training Epoch: 1/2, step 4976/107898 completed (loss: 0.823687732219696, acc: 0.8181818127632141)
[2025-02-17 16:55:07,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:07,530][root][INFO] - Training Epoch: 1/2, step 4977/107898 completed (loss: 0.44585922360420227, acc: 1.0)
[2025-02-17 16:55:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:07,861][root][INFO] - Training Epoch: 1/2, step 4978/107898 completed (loss: 0.6799571514129639, acc: 0.875)
[2025-02-17 16:55:07,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:08,185][root][INFO] - Training Epoch: 1/2, step 4979/107898 completed (loss: 0.16511280834674835, acc: 1.0)
[2025-02-17 16:55:08,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:08,517][root][INFO] - Training Epoch: 1/2, step 4980/107898 completed (loss: 4.462288856506348, acc: 0.13333334028720856)
[2025-02-17 16:55:08,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:08,828][root][INFO] - Training Epoch: 1/2, step 4981/107898 completed (loss: 2.2252140045166016, acc: 0.5714285969734192)
[2025-02-17 16:55:08,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:09,155][root][INFO] - Training Epoch: 1/2, step 4982/107898 completed (loss: 1.216770052909851, acc: 0.8333333134651184)
[2025-02-17 16:55:09,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:09,509][root][INFO] - Training Epoch: 1/2, step 4983/107898 completed (loss: 1.9287177324295044, acc: 0.4285714328289032)
[2025-02-17 16:55:09,599][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:09,822][root][INFO] - Training Epoch: 1/2, step 4984/107898 completed (loss: 0.45210790634155273, acc: 0.875)
[2025-02-17 16:55:09,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:10,138][root][INFO] - Training Epoch: 1/2, step 4985/107898 completed (loss: 0.027586914598941803, acc: 1.0)
[2025-02-17 16:55:10,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:10,460][root][INFO] - Training Epoch: 1/2, step 4986/107898 completed (loss: 1.8362510204315186, acc: 0.7142857313156128)
[2025-02-17 16:55:10,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:10,785][root][INFO] - Training Epoch: 1/2, step 4987/107898 completed (loss: 0.02197634056210518, acc: 1.0)
[2025-02-17 16:55:10,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:11,112][root][INFO] - Training Epoch: 1/2, step 4988/107898 completed (loss: 0.4161562919616699, acc: 0.9111111164093018)
[2025-02-17 16:55:11,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:11,425][root][INFO] - Training Epoch: 1/2, step 4989/107898 completed (loss: 0.9224722385406494, acc: 0.9166666865348816)
[2025-02-17 16:55:11,503][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:11,716][root][INFO] - Training Epoch: 1/2, step 4990/107898 completed (loss: 1.7205265760421753, acc: 0.7857142686843872)
[2025-02-17 16:55:11,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:12,022][root][INFO] - Training Epoch: 1/2, step 4991/107898 completed (loss: 0.5174234509468079, acc: 1.0)
[2025-02-17 16:55:12,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:12,326][root][INFO] - Training Epoch: 1/2, step 4992/107898 completed (loss: 2.1316967010498047, acc: 0.4285714328289032)
[2025-02-17 16:55:12,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:12,629][root][INFO] - Training Epoch: 1/2, step 4993/107898 completed (loss: 1.3353716135025024, acc: 0.75)
[2025-02-17 16:55:12,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:12,910][root][INFO] - Training Epoch: 1/2, step 4994/107898 completed (loss: 1.4805508852005005, acc: 0.6666666865348816)
[2025-02-17 16:55:12,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:13,214][root][INFO] - Training Epoch: 1/2, step 4995/107898 completed (loss: 4.555632591247559, acc: 0.2631579041481018)
[2025-02-17 16:55:13,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:13,513][root][INFO] - Training Epoch: 1/2, step 4996/107898 completed (loss: 0.039308588951826096, acc: 1.0)
[2025-02-17 16:55:13,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:13,831][root][INFO] - Training Epoch: 1/2, step 4997/107898 completed (loss: 0.17033785581588745, acc: 0.9166666865348816)
[2025-02-17 16:55:13,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:14,150][root][INFO] - Training Epoch: 1/2, step 4998/107898 completed (loss: 0.823719322681427, acc: 0.774193525314331)
[2025-02-17 16:55:14,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:14,430][root][INFO] - Training Epoch: 1/2, step 4999/107898 completed (loss: 0.015129794366657734, acc: 1.0)
[2025-02-17 16:55:14,511][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:14,730][root][INFO] - Training Epoch: 1/2, step 5000/107898 completed (loss: 1.7484859228134155, acc: 0.7142857313156128)
[2025-02-17 16:55:14,813][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:15,030][root][INFO] - Training Epoch: 1/2, step 5001/107898 completed (loss: 0.2428000271320343, acc: 1.0)
[2025-02-17 16:55:15,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:15,316][root][INFO] - Training Epoch: 1/2, step 5002/107898 completed (loss: 0.9156007766723633, acc: 0.6666666865348816)
[2025-02-17 16:55:15,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:15,592][root][INFO] - Training Epoch: 1/2, step 5003/107898 completed (loss: 4.325761318206787, acc: 0.1818181872367859)
[2025-02-17 16:55:15,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:15,888][root][INFO] - Training Epoch: 1/2, step 5004/107898 completed (loss: 0.009091604501008987, acc: 1.0)
[2025-02-17 16:55:15,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:16,179][root][INFO] - Training Epoch: 1/2, step 5005/107898 completed (loss: 0.14901761710643768, acc: 1.0)
[2025-02-17 16:55:16,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:16,466][root][INFO] - Training Epoch: 1/2, step 5006/107898 completed (loss: 1.5753424167633057, acc: 0.6666666865348816)
[2025-02-17 16:55:16,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:16,786][root][INFO] - Training Epoch: 1/2, step 5007/107898 completed (loss: 1.3063199520111084, acc: 0.761904776096344)
[2025-02-17 16:55:16,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:17,078][root][INFO] - Training Epoch: 1/2, step 5008/107898 completed (loss: 1.1375919580459595, acc: 0.7407407164573669)
[2025-02-17 16:55:17,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:17,392][root][INFO] - Training Epoch: 1/2, step 5009/107898 completed (loss: 0.8164393901824951, acc: 0.875)
[2025-02-17 16:55:17,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:17,693][root][INFO] - Training Epoch: 1/2, step 5010/107898 completed (loss: 0.9832213521003723, acc: 0.6000000238418579)
[2025-02-17 16:55:17,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:18,020][root][INFO] - Training Epoch: 1/2, step 5011/107898 completed (loss: 0.5035268068313599, acc: 0.8888888955116272)
[2025-02-17 16:55:18,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:18,332][root][INFO] - Training Epoch: 1/2, step 5012/107898 completed (loss: 0.06489965319633484, acc: 1.0)
[2025-02-17 16:55:18,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:18,640][root][INFO] - Training Epoch: 1/2, step 5013/107898 completed (loss: 0.4645909070968628, acc: 1.0)
[2025-02-17 16:55:18,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:18,953][root][INFO] - Training Epoch: 1/2, step 5014/107898 completed (loss: 1.5922991037368774, acc: 0.8333333134651184)
[2025-02-17 16:55:19,050][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:19,276][root][INFO] - Training Epoch: 1/2, step 5015/107898 completed (loss: 1.2228312492370605, acc: 0.7777777910232544)
[2025-02-17 16:55:19,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:19,563][root][INFO] - Training Epoch: 1/2, step 5016/107898 completed (loss: 0.14276304841041565, acc: 1.0)
[2025-02-17 16:55:19,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:19,866][root][INFO] - Training Epoch: 1/2, step 5017/107898 completed (loss: 1.8844283819198608, acc: 0.0)
[2025-02-17 16:55:19,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:20,165][root][INFO] - Training Epoch: 1/2, step 5018/107898 completed (loss: 0.012206588871777058, acc: 1.0)
[2025-02-17 16:55:20,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:20,490][root][INFO] - Training Epoch: 1/2, step 5019/107898 completed (loss: 0.03750208020210266, acc: 1.0)
[2025-02-17 16:55:20,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:20,783][root][INFO] - Training Epoch: 1/2, step 5020/107898 completed (loss: 0.004289040341973305, acc: 1.0)
[2025-02-17 16:55:20,896][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:21,125][root][INFO] - Training Epoch: 1/2, step 5021/107898 completed (loss: 0.971118688583374, acc: 0.6666666865348816)
[2025-02-17 16:55:21,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:21,476][root][INFO] - Training Epoch: 1/2, step 5022/107898 completed (loss: 0.7232696413993835, acc: 0.7272727489471436)
[2025-02-17 16:55:21,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:21,796][root][INFO] - Training Epoch: 1/2, step 5023/107898 completed (loss: 3.678253650665283, acc: 0.3499999940395355)
[2025-02-17 16:55:21,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:22,114][root][INFO] - Training Epoch: 1/2, step 5024/107898 completed (loss: 2.1803743839263916, acc: 0.5652173757553101)
[2025-02-17 16:55:22,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:22,423][root][INFO] - Training Epoch: 1/2, step 5025/107898 completed (loss: 1.7999112606048584, acc: 0.625)
[2025-02-17 16:55:22,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:22,752][root][INFO] - Training Epoch: 1/2, step 5026/107898 completed (loss: 0.005255009047687054, acc: 1.0)
[2025-02-17 16:55:22,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:23,085][root][INFO] - Training Epoch: 1/2, step 5027/107898 completed (loss: 1.1692347526550293, acc: 0.692307710647583)
[2025-02-17 16:55:23,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:23,363][root][INFO] - Training Epoch: 1/2, step 5028/107898 completed (loss: 0.6782477498054504, acc: 0.8421052694320679)
[2025-02-17 16:55:23,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:23,642][root][INFO] - Training Epoch: 1/2, step 5029/107898 completed (loss: 0.3212842643260956, acc: 1.0)
[2025-02-17 16:55:23,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:23,911][root][INFO] - Training Epoch: 1/2, step 5030/107898 completed (loss: 1.7720953226089478, acc: 0.7857142686843872)
[2025-02-17 16:55:23,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:24,209][root][INFO] - Training Epoch: 1/2, step 5031/107898 completed (loss: 0.0014143531443551183, acc: 1.0)
[2025-02-17 16:55:24,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:24,544][root][INFO] - Training Epoch: 1/2, step 5032/107898 completed (loss: 1.5403774976730347, acc: 0.7272727489471436)
[2025-02-17 16:55:24,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:24,877][root][INFO] - Training Epoch: 1/2, step 5033/107898 completed (loss: 0.910338819026947, acc: 0.8181818127632141)
[2025-02-17 16:55:24,959][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:25,178][root][INFO] - Training Epoch: 1/2, step 5034/107898 completed (loss: 1.1435763835906982, acc: 0.692307710647583)
[2025-02-17 16:55:25,259][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:25,481][root][INFO] - Training Epoch: 1/2, step 5035/107898 completed (loss: 1.7227956056594849, acc: 0.6666666865348816)
[2025-02-17 16:55:25,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:25,769][root][INFO] - Training Epoch: 1/2, step 5036/107898 completed (loss: 0.21752291917800903, acc: 1.0)
[2025-02-17 16:55:25,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:26,132][root][INFO] - Training Epoch: 1/2, step 5037/107898 completed (loss: 0.41569575667381287, acc: 0.9024389982223511)
[2025-02-17 16:55:26,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:26,476][root][INFO] - Training Epoch: 1/2, step 5038/107898 completed (loss: 0.9957378506660461, acc: 0.800000011920929)
[2025-02-17 16:55:26,586][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:26,829][root][INFO] - Training Epoch: 1/2, step 5039/107898 completed (loss: 1.0197718143463135, acc: 0.6666666865348816)
[2025-02-17 16:55:26,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:27,142][root][INFO] - Training Epoch: 1/2, step 5040/107898 completed (loss: 0.0020515569485723972, acc: 1.0)
[2025-02-17 16:55:27,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:27,495][root][INFO] - Training Epoch: 1/2, step 5041/107898 completed (loss: 2.785665512084961, acc: 0.3571428656578064)
[2025-02-17 16:55:27,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:27,821][root][INFO] - Training Epoch: 1/2, step 5042/107898 completed (loss: 0.045937057584524155, acc: 1.0)
[2025-02-17 16:55:27,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:28,129][root][INFO] - Training Epoch: 1/2, step 5043/107898 completed (loss: 1.060007929801941, acc: 0.7777777910232544)
[2025-02-17 16:55:28,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:28,464][root][INFO] - Training Epoch: 1/2, step 5044/107898 completed (loss: 0.8256962299346924, acc: 0.7777777910232544)
[2025-02-17 16:55:28,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:28,794][root][INFO] - Training Epoch: 1/2, step 5045/107898 completed (loss: 0.06978240609169006, acc: 0.9629629850387573)
[2025-02-17 16:55:28,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:29,053][root][INFO] - Training Epoch: 1/2, step 5046/107898 completed (loss: 3.006392002105713, acc: 0.4285714328289032)
[2025-02-17 16:55:29,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:29,396][root][INFO] - Training Epoch: 1/2, step 5047/107898 completed (loss: 0.0032061953097581863, acc: 1.0)
[2025-02-17 16:55:29,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:29,737][root][INFO] - Training Epoch: 1/2, step 5048/107898 completed (loss: 1.9464704990386963, acc: 0.7037037014961243)
[2025-02-17 16:55:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:30,074][root][INFO] - Training Epoch: 1/2, step 5049/107898 completed (loss: 0.9485443830490112, acc: 0.75)
[2025-02-17 16:55:30,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:30,363][root][INFO] - Training Epoch: 1/2, step 5050/107898 completed (loss: 0.022861385717988014, acc: 1.0)
[2025-02-17 16:55:30,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:30,667][root][INFO] - Training Epoch: 1/2, step 5051/107898 completed (loss: 0.6663098931312561, acc: 0.8636363744735718)
[2025-02-17 16:55:30,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:31,003][root][INFO] - Training Epoch: 1/2, step 5052/107898 completed (loss: 3.821662187576294, acc: 0.2380952388048172)
[2025-02-17 16:55:31,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:31,332][root][INFO] - Training Epoch: 1/2, step 5053/107898 completed (loss: 0.1390472650527954, acc: 1.0)
[2025-02-17 16:55:31,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:31,667][root][INFO] - Training Epoch: 1/2, step 5054/107898 completed (loss: 1.6544711589813232, acc: 0.6000000238418579)
[2025-02-17 16:55:31,759][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:31,981][root][INFO] - Training Epoch: 1/2, step 5055/107898 completed (loss: 0.002257650950923562, acc: 1.0)
[2025-02-17 16:55:32,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:32,332][root][INFO] - Training Epoch: 1/2, step 5056/107898 completed (loss: 3.0939459800720215, acc: 0.5)
[2025-02-17 16:55:32,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:32,663][root][INFO] - Training Epoch: 1/2, step 5057/107898 completed (loss: 0.4625222682952881, acc: 0.8333333134651184)
[2025-02-17 16:55:32,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:32,997][root][INFO] - Training Epoch: 1/2, step 5058/107898 completed (loss: 1.0617228746414185, acc: 0.8125)
[2025-02-17 16:55:33,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:33,311][root][INFO] - Training Epoch: 1/2, step 5059/107898 completed (loss: 0.8179324865341187, acc: 0.8571428656578064)
[2025-02-17 16:55:33,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:33,621][root][INFO] - Training Epoch: 1/2, step 5060/107898 completed (loss: 0.27615228295326233, acc: 1.0)
[2025-02-17 16:55:33,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:33,908][root][INFO] - Training Epoch: 1/2, step 5061/107898 completed (loss: 0.8491116762161255, acc: 0.7142857313156128)
[2025-02-17 16:55:33,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:34,208][root][INFO] - Training Epoch: 1/2, step 5062/107898 completed (loss: 0.62957364320755, acc: 0.9166666865348816)
[2025-02-17 16:55:34,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:34,514][root][INFO] - Training Epoch: 1/2, step 5063/107898 completed (loss: 0.35077965259552, acc: 0.6666666865348816)
[2025-02-17 16:55:34,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:34,842][root][INFO] - Training Epoch: 1/2, step 5064/107898 completed (loss: 0.2620542347431183, acc: 0.6666666865348816)
[2025-02-17 16:55:34,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:35,193][root][INFO] - Training Epoch: 1/2, step 5065/107898 completed (loss: 1.212607979774475, acc: 0.699999988079071)
[2025-02-17 16:55:35,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:35,559][root][INFO] - Training Epoch: 1/2, step 5066/107898 completed (loss: 0.7380460500717163, acc: 0.8571428656578064)
[2025-02-17 16:55:35,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:35,883][root][INFO] - Training Epoch: 1/2, step 5067/107898 completed (loss: 0.08850262314081192, acc: 1.0)
[2025-02-17 16:55:35,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:36,200][root][INFO] - Training Epoch: 1/2, step 5068/107898 completed (loss: 0.09749924391508102, acc: 0.9642857313156128)
[2025-02-17 16:55:36,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:36,501][root][INFO] - Training Epoch: 1/2, step 5069/107898 completed (loss: 1.2622451782226562, acc: 0.0)
[2025-02-17 16:55:36,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:36,802][root][INFO] - Training Epoch: 1/2, step 5070/107898 completed (loss: 0.004159420728683472, acc: 1.0)
[2025-02-17 16:55:36,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:37,099][root][INFO] - Training Epoch: 1/2, step 5071/107898 completed (loss: 0.518680989742279, acc: 0.8571428656578064)
[2025-02-17 16:55:37,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:37,405][root][INFO] - Training Epoch: 1/2, step 5072/107898 completed (loss: 0.2359353005886078, acc: 0.9411764740943909)
[2025-02-17 16:55:37,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:37,710][root][INFO] - Training Epoch: 1/2, step 5073/107898 completed (loss: 0.448577880859375, acc: 1.0)
[2025-02-17 16:55:37,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:38,025][root][INFO] - Training Epoch: 1/2, step 5074/107898 completed (loss: 0.10864531248807907, acc: 1.0)
[2025-02-17 16:55:38,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:38,328][root][INFO] - Training Epoch: 1/2, step 5075/107898 completed (loss: 1.8949511051177979, acc: 0.4444444477558136)
[2025-02-17 16:55:38,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:38,637][root][INFO] - Training Epoch: 1/2, step 5076/107898 completed (loss: 0.5453636050224304, acc: 0.6666666865348816)
[2025-02-17 16:55:38,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:38,996][root][INFO] - Training Epoch: 1/2, step 5077/107898 completed (loss: 0.6830644607543945, acc: 0.875)
[2025-02-17 16:55:39,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:39,327][root][INFO] - Training Epoch: 1/2, step 5078/107898 completed (loss: 0.5011549592018127, acc: 0.5)
[2025-02-17 16:55:39,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:39,652][root][INFO] - Training Epoch: 1/2, step 5079/107898 completed (loss: 1.4806718826293945, acc: 0.8571428656578064)
[2025-02-17 16:55:39,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:39,968][root][INFO] - Training Epoch: 1/2, step 5080/107898 completed (loss: 0.19048644602298737, acc: 1.0)
[2025-02-17 16:55:40,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:40,297][root][INFO] - Training Epoch: 1/2, step 5081/107898 completed (loss: 3.3593814373016357, acc: 0.23999999463558197)
[2025-02-17 16:55:40,385][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:40,593][root][INFO] - Training Epoch: 1/2, step 5082/107898 completed (loss: 0.011126795783638954, acc: 1.0)
[2025-02-17 16:55:40,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:40,920][root][INFO] - Training Epoch: 1/2, step 5083/107898 completed (loss: 0.057031359523534775, acc: 1.0)
[2025-02-17 16:55:41,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:41,269][root][INFO] - Training Epoch: 1/2, step 5084/107898 completed (loss: 1.231339693069458, acc: 0.625)
[2025-02-17 16:55:41,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:41,587][root][INFO] - Training Epoch: 1/2, step 5085/107898 completed (loss: 0.04975706711411476, acc: 1.0)
[2025-02-17 16:55:41,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:41,922][root][INFO] - Training Epoch: 1/2, step 5086/107898 completed (loss: 0.4693965017795563, acc: 0.8999999761581421)
[2025-02-17 16:55:42,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:42,240][root][INFO] - Training Epoch: 1/2, step 5087/107898 completed (loss: 0.5203670859336853, acc: 0.9411764740943909)
[2025-02-17 16:55:42,358][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:42,596][root][INFO] - Training Epoch: 1/2, step 5088/107898 completed (loss: 0.0046259257942438126, acc: 1.0)
[2025-02-17 16:55:42,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:42,896][root][INFO] - Training Epoch: 1/2, step 5089/107898 completed (loss: 0.9424833655357361, acc: 0.6666666865348816)
[2025-02-17 16:55:42,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:43,201][root][INFO] - Training Epoch: 1/2, step 5090/107898 completed (loss: 0.028745736926794052, acc: 1.0)
[2025-02-17 16:55:43,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:43,549][root][INFO] - Training Epoch: 1/2, step 5091/107898 completed (loss: 0.5447171926498413, acc: 0.8399999737739563)
[2025-02-17 16:55:43,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:43,878][root][INFO] - Training Epoch: 1/2, step 5092/107898 completed (loss: 0.08843981474637985, acc: 1.0)
[2025-02-17 16:55:43,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:44,240][root][INFO] - Training Epoch: 1/2, step 5093/107898 completed (loss: 1.1072428226470947, acc: 0.8235294222831726)
[2025-02-17 16:55:44,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:44,572][root][INFO] - Training Epoch: 1/2, step 5094/107898 completed (loss: 0.1434561014175415, acc: 0.949999988079071)
[2025-02-17 16:55:44,651][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:44,871][root][INFO] - Training Epoch: 1/2, step 5095/107898 completed (loss: 0.1364472657442093, acc: 1.0)
[2025-02-17 16:55:44,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:45,202][root][INFO] - Training Epoch: 1/2, step 5096/107898 completed (loss: 4.185384750366211, acc: 0.25)
[2025-02-17 16:55:45,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:45,542][root][INFO] - Training Epoch: 1/2, step 5097/107898 completed (loss: 3.6184887886047363, acc: 0.6000000238418579)
[2025-02-17 16:55:45,627][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:45,848][root][INFO] - Training Epoch: 1/2, step 5098/107898 completed (loss: 0.7203801274299622, acc: 0.6666666865348816)
[2025-02-17 16:55:45,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:46,153][root][INFO] - Training Epoch: 1/2, step 5099/107898 completed (loss: 1.6359866857528687, acc: 0.7777777910232544)
[2025-02-17 16:55:46,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:46,499][root][INFO] - Training Epoch: 1/2, step 5100/107898 completed (loss: 0.7831823229789734, acc: 0.9090909361839294)
[2025-02-17 16:55:46,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:46,809][root][INFO] - Training Epoch: 1/2, step 5101/107898 completed (loss: 0.3045315444469452, acc: 0.9090909361839294)
[2025-02-17 16:55:46,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:47,118][root][INFO] - Training Epoch: 1/2, step 5102/107898 completed (loss: 0.2240293323993683, acc: 0.96875)
[2025-02-17 16:55:47,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:47,406][root][INFO] - Training Epoch: 1/2, step 5103/107898 completed (loss: 0.01765977405011654, acc: 1.0)
[2025-02-17 16:55:47,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:47,703][root][INFO] - Training Epoch: 1/2, step 5104/107898 completed (loss: 0.016853390261530876, acc: 1.0)
[2025-02-17 16:55:47,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:48,042][root][INFO] - Training Epoch: 1/2, step 5105/107898 completed (loss: 1.4396538734436035, acc: 0.7272727489471436)
[2025-02-17 16:55:48,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:48,357][root][INFO] - Training Epoch: 1/2, step 5106/107898 completed (loss: 0.23542626202106476, acc: 1.0)
[2025-02-17 16:55:48,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:48,736][root][INFO] - Training Epoch: 1/2, step 5107/107898 completed (loss: 0.3226528465747833, acc: 0.9523809552192688)
[2025-02-17 16:55:48,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:49,073][root][INFO] - Training Epoch: 1/2, step 5108/107898 completed (loss: 0.34719738364219666, acc: 0.9411764740943909)
[2025-02-17 16:55:49,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:49,379][root][INFO] - Training Epoch: 1/2, step 5109/107898 completed (loss: 4.745982646942139, acc: 0.2222222238779068)
[2025-02-17 16:55:49,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:49,683][root][INFO] - Training Epoch: 1/2, step 5110/107898 completed (loss: 3.787838935852051, acc: 0.23076923191547394)
[2025-02-17 16:55:49,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:49,965][root][INFO] - Training Epoch: 1/2, step 5111/107898 completed (loss: 0.001385195180773735, acc: 1.0)
[2025-02-17 16:55:50,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:50,256][root][INFO] - Training Epoch: 1/2, step 5112/107898 completed (loss: 1.2593406438827515, acc: 0.6666666865348816)
[2025-02-17 16:55:50,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:50,538][root][INFO] - Training Epoch: 1/2, step 5113/107898 completed (loss: 0.6818318367004395, acc: 0.8214285969734192)
[2025-02-17 16:55:50,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:50,888][root][INFO] - Training Epoch: 1/2, step 5114/107898 completed (loss: 0.4368392825126648, acc: 0.8999999761581421)
[2025-02-17 16:55:50,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:51,227][root][INFO] - Training Epoch: 1/2, step 5115/107898 completed (loss: 1.1287882328033447, acc: 0.75)
[2025-02-17 16:55:51,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:51,513][root][INFO] - Training Epoch: 1/2, step 5116/107898 completed (loss: 0.7972097396850586, acc: 0.0)
[2025-02-17 16:55:51,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:51,878][root][INFO] - Training Epoch: 1/2, step 5117/107898 completed (loss: 3.125321388244629, acc: 0.5)
[2025-02-17 16:55:51,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:52,216][root][INFO] - Training Epoch: 1/2, step 5118/107898 completed (loss: 0.6673867106437683, acc: 1.0)
[2025-02-17 16:55:52,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:52,547][root][INFO] - Training Epoch: 1/2, step 5119/107898 completed (loss: 0.3977506756782532, acc: 0.8571428656578064)
[2025-02-17 16:55:52,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:52,862][root][INFO] - Training Epoch: 1/2, step 5120/107898 completed (loss: 3.242637872695923, acc: 0.4642857015132904)
[2025-02-17 16:55:52,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:53,217][root][INFO] - Training Epoch: 1/2, step 5121/107898 completed (loss: 4.414674758911133, acc: 0.1111111119389534)
[2025-02-17 16:55:53,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:53,560][root][INFO] - Training Epoch: 1/2, step 5122/107898 completed (loss: 0.8727037310600281, acc: 0.6666666865348816)
[2025-02-17 16:55:53,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:53,872][root][INFO] - Training Epoch: 1/2, step 5123/107898 completed (loss: 2.6323773860931396, acc: 0.6666666865348816)
[2025-02-17 16:55:53,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:54,220][root][INFO] - Training Epoch: 1/2, step 5124/107898 completed (loss: 0.0037961711641401052, acc: 1.0)
[2025-02-17 16:55:54,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:54,587][root][INFO] - Training Epoch: 1/2, step 5125/107898 completed (loss: 3.9676804542541504, acc: 0.27272728085517883)
[2025-02-17 16:55:54,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:54,994][root][INFO] - Training Epoch: 1/2, step 5126/107898 completed (loss: 1.0487710237503052, acc: 0.6666666865348816)
[2025-02-17 16:55:55,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:55,365][root][INFO] - Training Epoch: 1/2, step 5127/107898 completed (loss: 1.7132855653762817, acc: 0.5)
[2025-02-17 16:55:55,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:55,675][root][INFO] - Training Epoch: 1/2, step 5128/107898 completed (loss: 0.4713773727416992, acc: 0.875)
[2025-02-17 16:55:55,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:56,017][root][INFO] - Training Epoch: 1/2, step 5129/107898 completed (loss: 2.0251669883728027, acc: 0.7142857313156128)
[2025-02-17 16:55:56,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:56,363][root][INFO] - Training Epoch: 1/2, step 5130/107898 completed (loss: 0.9544097781181335, acc: 0.6666666865348816)
[2025-02-17 16:55:56,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:56,665][root][INFO] - Training Epoch: 1/2, step 5131/107898 completed (loss: 0.29520249366760254, acc: 0.9285714030265808)
[2025-02-17 16:55:56,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:56,981][root][INFO] - Training Epoch: 1/2, step 5132/107898 completed (loss: 0.22033219039440155, acc: 1.0)
[2025-02-17 16:55:57,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:57,290][root][INFO] - Training Epoch: 1/2, step 5133/107898 completed (loss: 2.6010324954986572, acc: 0.4285714328289032)
[2025-02-17 16:55:57,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:57,607][root][INFO] - Training Epoch: 1/2, step 5134/107898 completed (loss: 2.481602668762207, acc: 0.20000000298023224)
[2025-02-17 16:55:57,762][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:57,992][root][INFO] - Training Epoch: 1/2, step 5135/107898 completed (loss: 1.3447304964065552, acc: 0.7200000286102295)
[2025-02-17 16:55:58,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:58,293][root][INFO] - Training Epoch: 1/2, step 5136/107898 completed (loss: 3.26263165473938, acc: 0.4285714328289032)
[2025-02-17 16:55:58,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:58,605][root][INFO] - Training Epoch: 1/2, step 5137/107898 completed (loss: 0.8803493976593018, acc: 0.6666666865348816)
[2025-02-17 16:55:58,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:58,947][root][INFO] - Training Epoch: 1/2, step 5138/107898 completed (loss: 0.36012324690818787, acc: 0.9166666865348816)
[2025-02-17 16:55:59,034][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:59,221][root][INFO] - Training Epoch: 1/2, step 5139/107898 completed (loss: 1.529361605644226, acc: 0.75)
[2025-02-17 16:55:59,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:59,548][root][INFO] - Training Epoch: 1/2, step 5140/107898 completed (loss: 0.009981827810406685, acc: 1.0)
[2025-02-17 16:55:59,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:55:59,895][root][INFO] - Training Epoch: 1/2, step 5141/107898 completed (loss: 0.05347262695431709, acc: 1.0)
[2025-02-17 16:56:00,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:00,261][root][INFO] - Training Epoch: 1/2, step 5142/107898 completed (loss: 0.7756027579307556, acc: 0.8461538553237915)
[2025-02-17 16:56:00,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:00,623][root][INFO] - Training Epoch: 1/2, step 5143/107898 completed (loss: 0.2745220959186554, acc: 1.0)
[2025-02-17 16:56:00,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:00,960][root][INFO] - Training Epoch: 1/2, step 5144/107898 completed (loss: 3.2375588417053223, acc: 0.5)
[2025-02-17 16:56:01,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:01,344][root][INFO] - Training Epoch: 1/2, step 5145/107898 completed (loss: 3.6874098777770996, acc: 0.2857142984867096)
[2025-02-17 16:56:01,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:01,697][root][INFO] - Training Epoch: 1/2, step 5146/107898 completed (loss: 0.3765869140625, acc: 0.6666666865348816)
[2025-02-17 16:56:01,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:02,074][root][INFO] - Training Epoch: 1/2, step 5147/107898 completed (loss: 0.9357956647872925, acc: 0.5)
[2025-02-17 16:56:02,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:02,442][root][INFO] - Training Epoch: 1/2, step 5148/107898 completed (loss: 0.7612611055374146, acc: 0.5)
[2025-02-17 16:56:02,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:02,758][root][INFO] - Training Epoch: 1/2, step 5149/107898 completed (loss: 0.30094051361083984, acc: 1.0)
[2025-02-17 16:56:02,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:03,104][root][INFO] - Training Epoch: 1/2, step 5150/107898 completed (loss: 0.4684467315673828, acc: 0.9473684430122375)
[2025-02-17 16:56:03,227][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:03,457][root][INFO] - Training Epoch: 1/2, step 5151/107898 completed (loss: 0.6882293820381165, acc: 0.800000011920929)
[2025-02-17 16:56:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:03,774][root][INFO] - Training Epoch: 1/2, step 5152/107898 completed (loss: 1.4517836570739746, acc: 0.699999988079071)
[2025-02-17 16:56:03,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:04,097][root][INFO] - Training Epoch: 1/2, step 5153/107898 completed (loss: 1.8357558250427246, acc: 0.6875)
[2025-02-17 16:56:04,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:04,479][root][INFO] - Training Epoch: 1/2, step 5154/107898 completed (loss: 0.07887310534715652, acc: 1.0)
[2025-02-17 16:56:04,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:04,836][root][INFO] - Training Epoch: 1/2, step 5155/107898 completed (loss: 0.5354109406471252, acc: 0.8999999761581421)
[2025-02-17 16:56:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:05,182][root][INFO] - Training Epoch: 1/2, step 5156/107898 completed (loss: 1.3612899780273438, acc: 0.7272727489471436)
[2025-02-17 16:56:05,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:05,500][root][INFO] - Training Epoch: 1/2, step 5157/107898 completed (loss: 1.3107330799102783, acc: 0.800000011920929)
[2025-02-17 16:56:05,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:05,851][root][INFO] - Training Epoch: 1/2, step 5158/107898 completed (loss: 0.17547142505645752, acc: 1.0)
[2025-02-17 16:56:05,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:06,214][root][INFO] - Training Epoch: 1/2, step 5159/107898 completed (loss: 0.2680990695953369, acc: 0.96875)
[2025-02-17 16:56:06,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:06,520][root][INFO] - Training Epoch: 1/2, step 5160/107898 completed (loss: 0.9938763380050659, acc: 0.6666666865348816)
[2025-02-17 16:56:06,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:06,841][root][INFO] - Training Epoch: 1/2, step 5161/107898 completed (loss: 0.15508896112442017, acc: 1.0)
[2025-02-17 16:56:06,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:07,166][root][INFO] - Training Epoch: 1/2, step 5162/107898 completed (loss: 0.3907645344734192, acc: 0.8888888955116272)
[2025-02-17 16:56:07,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:07,488][root][INFO] - Training Epoch: 1/2, step 5163/107898 completed (loss: 0.12774372100830078, acc: 1.0)
[2025-02-17 16:56:07,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:07,837][root][INFO] - Training Epoch: 1/2, step 5164/107898 completed (loss: 1.658746361732483, acc: 0.7200000286102295)
[2025-02-17 16:56:07,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:08,172][root][INFO] - Training Epoch: 1/2, step 5165/107898 completed (loss: 0.0042043449357151985, acc: 1.0)
[2025-02-17 16:56:08,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:08,514][root][INFO] - Training Epoch: 1/2, step 5166/107898 completed (loss: 0.42338424921035767, acc: 1.0)
[2025-02-17 16:56:08,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:08,854][root][INFO] - Training Epoch: 1/2, step 5167/107898 completed (loss: 0.5986667275428772, acc: 0.875)
[2025-02-17 16:56:08,947][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:09,168][root][INFO] - Training Epoch: 1/2, step 5168/107898 completed (loss: 0.020823080092668533, acc: 1.0)
[2025-02-17 16:56:09,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:09,462][root][INFO] - Training Epoch: 1/2, step 5169/107898 completed (loss: 0.013331830501556396, acc: 1.0)
[2025-02-17 16:56:09,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:09,798][root][INFO] - Training Epoch: 1/2, step 5170/107898 completed (loss: 0.13618406653404236, acc: 1.0)
[2025-02-17 16:56:09,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:10,133][root][INFO] - Training Epoch: 1/2, step 5171/107898 completed (loss: 0.12238213419914246, acc: 1.0)
[2025-02-17 16:56:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:10,456][root][INFO] - Training Epoch: 1/2, step 5172/107898 completed (loss: 0.16769511997699738, acc: 1.0)
[2025-02-17 16:56:10,545][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:10,813][root][INFO] - Training Epoch: 1/2, step 5173/107898 completed (loss: 0.06830698996782303, acc: 1.0)
[2025-02-17 16:56:10,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:11,132][root][INFO] - Training Epoch: 1/2, step 5174/107898 completed (loss: 0.016860444098711014, acc: 1.0)
[2025-02-17 16:56:11,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:11,446][root][INFO] - Training Epoch: 1/2, step 5175/107898 completed (loss: 3.450319290161133, acc: 0.25)
[2025-02-17 16:56:11,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:11,735][root][INFO] - Training Epoch: 1/2, step 5176/107898 completed (loss: 0.024771548807621002, acc: 1.0)
[2025-02-17 16:56:11,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:12,039][root][INFO] - Training Epoch: 1/2, step 5177/107898 completed (loss: 0.19397211074829102, acc: 0.9285714030265808)
[2025-02-17 16:56:12,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:12,345][root][INFO] - Training Epoch: 1/2, step 5178/107898 completed (loss: 0.9769386053085327, acc: 0.75)
[2025-02-17 16:56:12,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:12,666][root][INFO] - Training Epoch: 1/2, step 5179/107898 completed (loss: 4.198513031005859, acc: 0.375)
[2025-02-17 16:56:12,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:12,957][root][INFO] - Training Epoch: 1/2, step 5180/107898 completed (loss: 2.15161395072937, acc: 0.6000000238418579)
[2025-02-17 16:56:13,034][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:13,249][root][INFO] - Training Epoch: 1/2, step 5181/107898 completed (loss: 0.0751870796084404, acc: 1.0)
[2025-02-17 16:56:13,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:13,555][root][INFO] - Training Epoch: 1/2, step 5182/107898 completed (loss: 0.12919779121875763, acc: 1.0)
[2025-02-17 16:56:13,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:13,891][root][INFO] - Training Epoch: 1/2, step 5183/107898 completed (loss: 1.8468176126480103, acc: 0.0)
[2025-02-17 16:56:13,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:14,215][root][INFO] - Training Epoch: 1/2, step 5184/107898 completed (loss: 0.019419392570853233, acc: 1.0)
[2025-02-17 16:56:14,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:14,530][root][INFO] - Training Epoch: 1/2, step 5185/107898 completed (loss: 0.06981328874826431, acc: 1.0)
[2025-02-17 16:56:14,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:14,827][root][INFO] - Training Epoch: 1/2, step 5186/107898 completed (loss: 0.32180073857307434, acc: 0.6666666865348816)
[2025-02-17 16:56:14,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:15,145][root][INFO] - Training Epoch: 1/2, step 5187/107898 completed (loss: 0.6970050930976868, acc: 0.75)
[2025-02-17 16:56:15,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:15,524][root][INFO] - Training Epoch: 1/2, step 5188/107898 completed (loss: 3.142277240753174, acc: 0.3076923191547394)
[2025-02-17 16:56:15,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:15,810][root][INFO] - Training Epoch: 1/2, step 5189/107898 completed (loss: 0.4445423185825348, acc: 0.5)
[2025-02-17 16:56:15,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:16,113][root][INFO] - Training Epoch: 1/2, step 5190/107898 completed (loss: 1.2380344867706299, acc: 0.7142857313156128)
[2025-02-17 16:56:16,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:16,448][root][INFO] - Training Epoch: 1/2, step 5191/107898 completed (loss: 0.28666093945503235, acc: 0.875)
[2025-02-17 16:56:16,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:16,775][root][INFO] - Training Epoch: 1/2, step 5192/107898 completed (loss: 0.6172351837158203, acc: 0.9090909361839294)
[2025-02-17 16:56:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:17,103][root][INFO] - Training Epoch: 1/2, step 5193/107898 completed (loss: 0.04136122763156891, acc: 1.0)
[2025-02-17 16:56:17,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:17,455][root][INFO] - Training Epoch: 1/2, step 5194/107898 completed (loss: 1.9649763107299805, acc: 0.5)
[2025-02-17 16:56:17,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:17,778][root][INFO] - Training Epoch: 1/2, step 5195/107898 completed (loss: 0.36429563164711, acc: 0.6666666865348816)
[2025-02-17 16:56:17,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:18,120][root][INFO] - Training Epoch: 1/2, step 5196/107898 completed (loss: 1.1199499368667603, acc: 0.6666666865348816)
[2025-02-17 16:56:18,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:18,469][root][INFO] - Training Epoch: 1/2, step 5197/107898 completed (loss: 0.515053391456604, acc: 0.95652174949646)
[2025-02-17 16:56:18,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:18,816][root][INFO] - Training Epoch: 1/2, step 5198/107898 completed (loss: 2.991543769836426, acc: 0.25)
[2025-02-17 16:56:18,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:19,112][root][INFO] - Training Epoch: 1/2, step 5199/107898 completed (loss: 0.8106932044029236, acc: 0.8125)
[2025-02-17 16:56:19,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:19,412][root][INFO] - Training Epoch: 1/2, step 5200/107898 completed (loss: 0.30424290895462036, acc: 0.9285714030265808)
[2025-02-17 16:56:19,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:19,712][root][INFO] - Training Epoch: 1/2, step 5201/107898 completed (loss: 0.723179817199707, acc: 0.8666666746139526)
[2025-02-17 16:56:19,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:20,004][root][INFO] - Training Epoch: 1/2, step 5202/107898 completed (loss: 2.1447885036468506, acc: 0.2857142984867096)
[2025-02-17 16:56:20,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:20,336][root][INFO] - Training Epoch: 1/2, step 5203/107898 completed (loss: 0.6269429326057434, acc: 0.6666666865348816)
[2025-02-17 16:56:20,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:20,685][root][INFO] - Training Epoch: 1/2, step 5204/107898 completed (loss: 0.6369686722755432, acc: 0.6666666865348816)
[2025-02-17 16:56:20,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:21,006][root][INFO] - Training Epoch: 1/2, step 5205/107898 completed (loss: 1.2066209316253662, acc: 0.6000000238418579)
[2025-02-17 16:56:21,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:21,347][root][INFO] - Training Epoch: 1/2, step 5206/107898 completed (loss: 0.5180694460868835, acc: 0.6666666865348816)
[2025-02-17 16:56:21,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:21,676][root][INFO] - Training Epoch: 1/2, step 5207/107898 completed (loss: 0.04947073757648468, acc: 1.0)
[2025-02-17 16:56:21,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:22,019][root][INFO] - Training Epoch: 1/2, step 5208/107898 completed (loss: 0.8981068730354309, acc: 0.9130434989929199)
[2025-02-17 16:56:22,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:22,354][root][INFO] - Training Epoch: 1/2, step 5209/107898 completed (loss: 0.05420629307627678, acc: 1.0)
[2025-02-17 16:56:22,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:22,673][root][INFO] - Training Epoch: 1/2, step 5210/107898 completed (loss: 3.210263967514038, acc: 0.5)
[2025-02-17 16:56:22,772][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:23,001][root][INFO] - Training Epoch: 1/2, step 5211/107898 completed (loss: 0.3434866666793823, acc: 1.0)
[2025-02-17 16:56:23,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:23,278][root][INFO] - Training Epoch: 1/2, step 5212/107898 completed (loss: 0.13676510751247406, acc: 1.0)
[2025-02-17 16:56:23,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:23,563][root][INFO] - Training Epoch: 1/2, step 5213/107898 completed (loss: 0.30339112877845764, acc: 1.0)
[2025-02-17 16:56:23,631][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:23,853][root][INFO] - Training Epoch: 1/2, step 5214/107898 completed (loss: 0.9769724607467651, acc: 0.8823529481887817)
[2025-02-17 16:56:23,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:24,199][root][INFO] - Training Epoch: 1/2, step 5215/107898 completed (loss: 0.8360119462013245, acc: 0.800000011920929)
[2025-02-17 16:56:24,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:24,508][root][INFO] - Training Epoch: 1/2, step 5216/107898 completed (loss: 0.20680595934391022, acc: 1.0)
[2025-02-17 16:56:24,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:24,817][root][INFO] - Training Epoch: 1/2, step 5217/107898 completed (loss: 0.017478348687291145, acc: 1.0)
[2025-02-17 16:56:24,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:25,147][root][INFO] - Training Epoch: 1/2, step 5218/107898 completed (loss: 1.9445832967758179, acc: 0.6666666865348816)
[2025-02-17 16:56:25,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:25,476][root][INFO] - Training Epoch: 1/2, step 5219/107898 completed (loss: 0.3802070915699005, acc: 0.7857142686843872)
[2025-02-17 16:56:25,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:25,823][root][INFO] - Training Epoch: 1/2, step 5220/107898 completed (loss: 1.864495038986206, acc: 0.529411792755127)
[2025-02-17 16:56:25,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:26,148][root][INFO] - Training Epoch: 1/2, step 5221/107898 completed (loss: 2.4621355533599854, acc: 0.3333333432674408)
[2025-02-17 16:56:26,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:26,451][root][INFO] - Training Epoch: 1/2, step 5222/107898 completed (loss: 2.3526289463043213, acc: 0.0)
[2025-02-17 16:56:26,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:26,729][root][INFO] - Training Epoch: 1/2, step 5223/107898 completed (loss: 0.04235063120722771, acc: 1.0)
[2025-02-17 16:56:26,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:27,037][root][INFO] - Training Epoch: 1/2, step 5224/107898 completed (loss: 0.6643972992897034, acc: 0.8947368264198303)
[2025-02-17 16:56:27,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:27,334][root][INFO] - Training Epoch: 1/2, step 5225/107898 completed (loss: 1.1543103456497192, acc: 0.7599999904632568)
[2025-02-17 16:56:27,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:27,660][root][INFO] - Training Epoch: 1/2, step 5226/107898 completed (loss: 0.006163079757243395, acc: 1.0)
[2025-02-17 16:56:27,751][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:27,969][root][INFO] - Training Epoch: 1/2, step 5227/107898 completed (loss: 0.7323832511901855, acc: 0.800000011920929)
[2025-02-17 16:56:28,050][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:28,267][root][INFO] - Training Epoch: 1/2, step 5228/107898 completed (loss: 0.48251375555992126, acc: 0.6666666865348816)
[2025-02-17 16:56:28,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:28,599][root][INFO] - Training Epoch: 1/2, step 5229/107898 completed (loss: 0.001438115374185145, acc: 1.0)
[2025-02-17 16:56:28,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:28,926][root][INFO] - Training Epoch: 1/2, step 5230/107898 completed (loss: 0.3653767704963684, acc: 0.949999988079071)
[2025-02-17 16:56:29,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:29,233][root][INFO] - Training Epoch: 1/2, step 5231/107898 completed (loss: 2.0172181129455566, acc: 0.2857142984867096)
[2025-02-17 16:56:29,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:29,536][root][INFO] - Training Epoch: 1/2, step 5232/107898 completed (loss: 0.03361637517809868, acc: 1.0)
[2025-02-17 16:56:29,651][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:29,889][root][INFO] - Training Epoch: 1/2, step 5233/107898 completed (loss: 0.7105319499969482, acc: 0.8399999737739563)
[2025-02-17 16:56:29,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:30,226][root][INFO] - Training Epoch: 1/2, step 5234/107898 completed (loss: 0.035626985132694244, acc: 1.0)
[2025-02-17 16:56:30,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:30,563][root][INFO] - Training Epoch: 1/2, step 5235/107898 completed (loss: 0.08176618814468384, acc: 0.9677419066429138)
[2025-02-17 16:56:30,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:30,903][root][INFO] - Training Epoch: 1/2, step 5236/107898 completed (loss: 0.9319582581520081, acc: 0.875)
[2025-02-17 16:56:31,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:31,238][root][INFO] - Training Epoch: 1/2, step 5237/107898 completed (loss: 0.38893163204193115, acc: 1.0)
[2025-02-17 16:56:31,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:31,565][root][INFO] - Training Epoch: 1/2, step 5238/107898 completed (loss: 3.2510104179382324, acc: 0.6000000238418579)
[2025-02-17 16:56:31,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:31,891][root][INFO] - Training Epoch: 1/2, step 5239/107898 completed (loss: 1.8501704931259155, acc: 0.7857142686843872)
[2025-02-17 16:56:31,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:32,221][root][INFO] - Training Epoch: 1/2, step 5240/107898 completed (loss: 0.5887895822525024, acc: 0.9047619104385376)
[2025-02-17 16:56:32,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:32,538][root][INFO] - Training Epoch: 1/2, step 5241/107898 completed (loss: 2.223510265350342, acc: 0.6000000238418579)
[2025-02-17 16:56:32,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:32,839][root][INFO] - Training Epoch: 1/2, step 5242/107898 completed (loss: 0.535155713558197, acc: 0.6666666865348816)
[2025-02-17 16:56:32,949][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:33,173][root][INFO] - Training Epoch: 1/2, step 5243/107898 completed (loss: 0.6418904662132263, acc: 0.5)
[2025-02-17 16:56:33,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:33,505][root][INFO] - Training Epoch: 1/2, step 5244/107898 completed (loss: 1.751695990562439, acc: 0.6000000238418579)
[2025-02-17 16:56:33,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:33,816][root][INFO] - Training Epoch: 1/2, step 5245/107898 completed (loss: 0.8913494348526001, acc: 0.8571428656578064)
[2025-02-17 16:56:33,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:34,124][root][INFO] - Training Epoch: 1/2, step 5246/107898 completed (loss: 1.1582932472229004, acc: 0.7272727489471436)
[2025-02-17 16:56:34,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:34,423][root][INFO] - Training Epoch: 1/2, step 5247/107898 completed (loss: 0.0046140821650624275, acc: 1.0)
[2025-02-17 16:56:34,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:34,724][root][INFO] - Training Epoch: 1/2, step 5248/107898 completed (loss: 1.7901519536972046, acc: 0.4000000059604645)
[2025-02-17 16:56:34,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:35,019][root][INFO] - Training Epoch: 1/2, step 5249/107898 completed (loss: 0.16369743645191193, acc: 1.0)
[2025-02-17 16:56:35,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:35,322][root][INFO] - Training Epoch: 1/2, step 5250/107898 completed (loss: 0.9902471303939819, acc: 0.800000011920929)
[2025-02-17 16:56:35,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:35,628][root][INFO] - Training Epoch: 1/2, step 5251/107898 completed (loss: 0.6493869423866272, acc: 0.800000011920929)
[2025-02-17 16:56:35,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:35,946][root][INFO] - Training Epoch: 1/2, step 5252/107898 completed (loss: 3.451646566390991, acc: 0.0)
[2025-02-17 16:56:36,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:36,261][root][INFO] - Training Epoch: 1/2, step 5253/107898 completed (loss: 0.16949661076068878, acc: 1.0)
[2025-02-17 16:56:36,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:36,589][root][INFO] - Training Epoch: 1/2, step 5254/107898 completed (loss: 2.7331702709198, acc: 0.31578946113586426)
[2025-02-17 16:56:36,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:36,938][root][INFO] - Training Epoch: 1/2, step 5255/107898 completed (loss: 1.0764079093933105, acc: 0.800000011920929)
[2025-02-17 16:56:37,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:37,241][root][INFO] - Training Epoch: 1/2, step 5256/107898 completed (loss: 5.556690692901611, acc: 0.5)
[2025-02-17 16:56:37,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:37,565][root][INFO] - Training Epoch: 1/2, step 5257/107898 completed (loss: 0.3690473735332489, acc: 0.8888888955116272)
[2025-02-17 16:56:37,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:37,894][root][INFO] - Training Epoch: 1/2, step 5258/107898 completed (loss: 0.006587529554963112, acc: 1.0)
[2025-02-17 16:56:37,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:38,243][root][INFO] - Training Epoch: 1/2, step 5259/107898 completed (loss: 0.592628538608551, acc: 0.6666666865348816)
[2025-02-17 16:56:38,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:38,598][root][INFO] - Training Epoch: 1/2, step 5260/107898 completed (loss: 0.5396780371665955, acc: 0.8823529481887817)
[2025-02-17 16:56:38,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:38,943][root][INFO] - Training Epoch: 1/2, step 5261/107898 completed (loss: 3.9110305309295654, acc: 0.1428571492433548)
[2025-02-17 16:56:39,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:39,194][root][INFO] - Training Epoch: 1/2, step 5262/107898 completed (loss: 0.3813929855823517, acc: 0.875)
[2025-02-17 16:56:39,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:39,529][root][INFO] - Training Epoch: 1/2, step 5263/107898 completed (loss: 0.2566141188144684, acc: 1.0)
[2025-02-17 16:56:39,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:39,844][root][INFO] - Training Epoch: 1/2, step 5264/107898 completed (loss: 0.14019522070884705, acc: 1.0)
[2025-02-17 16:56:39,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:40,166][root][INFO] - Training Epoch: 1/2, step 5265/107898 completed (loss: 0.46993646025657654, acc: 0.949999988079071)
[2025-02-17 16:56:40,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:40,503][root][INFO] - Training Epoch: 1/2, step 5266/107898 completed (loss: 1.9120877981185913, acc: 0.6666666865348816)
[2025-02-17 16:56:40,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:40,813][root][INFO] - Training Epoch: 1/2, step 5267/107898 completed (loss: 0.9591888189315796, acc: 0.800000011920929)
[2025-02-17 16:56:40,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:41,126][root][INFO] - Training Epoch: 1/2, step 5268/107898 completed (loss: 0.609235405921936, acc: 0.8888888955116272)
[2025-02-17 16:56:41,209][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:41,419][root][INFO] - Training Epoch: 1/2, step 5269/107898 completed (loss: 0.20304548740386963, acc: 0.9375)
[2025-02-17 16:56:41,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:41,727][root][INFO] - Training Epoch: 1/2, step 5270/107898 completed (loss: 0.05264612287282944, acc: 1.0)
[2025-02-17 16:56:41,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:42,032][root][INFO] - Training Epoch: 1/2, step 5271/107898 completed (loss: 0.21054627001285553, acc: 0.875)
[2025-02-17 16:56:42,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:42,354][root][INFO] - Training Epoch: 1/2, step 5272/107898 completed (loss: 0.49908414483070374, acc: 0.8333333134651184)
[2025-02-17 16:56:42,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:42,661][root][INFO] - Training Epoch: 1/2, step 5273/107898 completed (loss: 0.044899873435497284, acc: 1.0)
[2025-02-17 16:56:42,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:43,013][root][INFO] - Training Epoch: 1/2, step 5274/107898 completed (loss: 0.239687979221344, acc: 1.0)
[2025-02-17 16:56:43,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:43,363][root][INFO] - Training Epoch: 1/2, step 5275/107898 completed (loss: 1.1918822526931763, acc: 0.7727272510528564)
[2025-02-17 16:56:43,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:43,727][root][INFO] - Training Epoch: 1/2, step 5276/107898 completed (loss: 2.6996281147003174, acc: 0.4117647111415863)
[2025-02-17 16:56:43,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:44,065][root][INFO] - Training Epoch: 1/2, step 5277/107898 completed (loss: 0.009951768442988396, acc: 1.0)
[2025-02-17 16:56:44,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:44,385][root][INFO] - Training Epoch: 1/2, step 5278/107898 completed (loss: 5.855271816253662, acc: 0.06666667014360428)
[2025-02-17 16:56:44,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:44,713][root][INFO] - Training Epoch: 1/2, step 5279/107898 completed (loss: 5.653954029083252, acc: 0.5)
[2025-02-17 16:56:44,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:45,021][root][INFO] - Training Epoch: 1/2, step 5280/107898 completed (loss: 0.004004070535302162, acc: 1.0)
[2025-02-17 16:56:45,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:45,311][root][INFO] - Training Epoch: 1/2, step 5281/107898 completed (loss: 3.272003412246704, acc: 0.25)
[2025-02-17 16:56:45,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:45,646][root][INFO] - Training Epoch: 1/2, step 5282/107898 completed (loss: 0.0599505752325058, acc: 1.0)
[2025-02-17 16:56:45,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:45,994][root][INFO] - Training Epoch: 1/2, step 5283/107898 completed (loss: 1.291656255722046, acc: 0.7368420958518982)
[2025-02-17 16:56:46,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:46,324][root][INFO] - Training Epoch: 1/2, step 5284/107898 completed (loss: 0.32540249824523926, acc: 0.9285714030265808)
[2025-02-17 16:56:46,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:46,683][root][INFO] - Training Epoch: 1/2, step 5285/107898 completed (loss: 3.2179079055786133, acc: 0.3076923191547394)
[2025-02-17 16:56:46,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:47,044][root][INFO] - Training Epoch: 1/2, step 5286/107898 completed (loss: 3.5707976818084717, acc: 0.3571428656578064)
[2025-02-17 16:56:47,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:47,356][root][INFO] - Training Epoch: 1/2, step 5287/107898 completed (loss: 2.6232097148895264, acc: 0.20000000298023224)
[2025-02-17 16:56:47,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:47,688][root][INFO] - Training Epoch: 1/2, step 5288/107898 completed (loss: 2.223825216293335, acc: 0.692307710647583)
[2025-02-17 16:56:47,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:48,009][root][INFO] - Training Epoch: 1/2, step 5289/107898 completed (loss: 0.35237374901771545, acc: 0.8999999761581421)
[2025-02-17 16:56:48,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:48,398][root][INFO] - Training Epoch: 1/2, step 5290/107898 completed (loss: 3.38285756111145, acc: 0.3333333432674408)
[2025-02-17 16:56:48,525][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:48,722][root][INFO] - Training Epoch: 1/2, step 5291/107898 completed (loss: 1.294940710067749, acc: 0.7272727489471436)
[2025-02-17 16:56:48,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:49,025][root][INFO] - Training Epoch: 1/2, step 5292/107898 completed (loss: 0.4712757170200348, acc: 1.0)
[2025-02-17 16:56:49,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:49,327][root][INFO] - Training Epoch: 1/2, step 5293/107898 completed (loss: 2.7978224754333496, acc: 0.2222222238779068)
[2025-02-17 16:56:49,414][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:49,641][root][INFO] - Training Epoch: 1/2, step 5294/107898 completed (loss: 1.3463388681411743, acc: 0.699999988079071)
[2025-02-17 16:56:49,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:49,948][root][INFO] - Training Epoch: 1/2, step 5295/107898 completed (loss: 0.1022331565618515, acc: 1.0)
[2025-02-17 16:56:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:50,242][root][INFO] - Training Epoch: 1/2, step 5296/107898 completed (loss: 0.5051980018615723, acc: 0.8888888955116272)
[2025-02-17 16:56:50,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:50,549][root][INFO] - Training Epoch: 1/2, step 5297/107898 completed (loss: 3.671001434326172, acc: 0.5)
[2025-02-17 16:56:50,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:50,850][root][INFO] - Training Epoch: 1/2, step 5298/107898 completed (loss: 1.6885285377502441, acc: 0.6666666865348816)
[2025-02-17 16:56:50,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:51,154][root][INFO] - Training Epoch: 1/2, step 5299/107898 completed (loss: 0.043064240366220474, acc: 1.0)
[2025-02-17 16:56:51,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:51,448][root][INFO] - Training Epoch: 1/2, step 5300/107898 completed (loss: 0.5042195320129395, acc: 1.0)
[2025-02-17 16:56:51,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:51,749][root][INFO] - Training Epoch: 1/2, step 5301/107898 completed (loss: 0.02203015796840191, acc: 1.0)
[2025-02-17 16:56:51,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:52,060][root][INFO] - Training Epoch: 1/2, step 5302/107898 completed (loss: 0.9841744303703308, acc: 0.6666666865348816)
[2025-02-17 16:56:52,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:52,398][root][INFO] - Training Epoch: 1/2, step 5303/107898 completed (loss: 2.4572513103485107, acc: 0.3333333432674408)
[2025-02-17 16:56:52,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:52,704][root][INFO] - Training Epoch: 1/2, step 5304/107898 completed (loss: 0.17834311723709106, acc: 1.0)
[2025-02-17 16:56:52,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:53,046][root][INFO] - Training Epoch: 1/2, step 5305/107898 completed (loss: 0.1497306525707245, acc: 0.9473684430122375)
[2025-02-17 16:56:53,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:53,392][root][INFO] - Training Epoch: 1/2, step 5306/107898 completed (loss: 0.49110695719718933, acc: 0.9333333373069763)
[2025-02-17 16:56:53,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:53,736][root][INFO] - Training Epoch: 1/2, step 5307/107898 completed (loss: 0.6787523627281189, acc: 0.807692289352417)
[2025-02-17 16:56:53,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:54,063][root][INFO] - Training Epoch: 1/2, step 5308/107898 completed (loss: 3.984099864959717, acc: 0.3125)
[2025-02-17 16:56:54,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:54,389][root][INFO] - Training Epoch: 1/2, step 5309/107898 completed (loss: 0.3194635808467865, acc: 0.9599999785423279)
[2025-02-17 16:56:54,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:54,706][root][INFO] - Training Epoch: 1/2, step 5310/107898 completed (loss: 1.8044761419296265, acc: 0.3333333432674408)
[2025-02-17 16:56:54,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:55,016][root][INFO] - Training Epoch: 1/2, step 5311/107898 completed (loss: 2.1704113483428955, acc: 0.5)
[2025-02-17 16:56:55,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:55,328][root][INFO] - Training Epoch: 1/2, step 5312/107898 completed (loss: 0.38002556562423706, acc: 1.0)
[2025-02-17 16:56:55,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:55,635][root][INFO] - Training Epoch: 1/2, step 5313/107898 completed (loss: 0.06895487755537033, acc: 1.0)
[2025-02-17 16:56:55,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:55,984][root][INFO] - Training Epoch: 1/2, step 5314/107898 completed (loss: 0.016608772799372673, acc: 1.0)
[2025-02-17 16:56:56,077][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:56,312][root][INFO] - Training Epoch: 1/2, step 5315/107898 completed (loss: 4.685035705566406, acc: 0.0)
[2025-02-17 16:56:56,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:56,970][root][INFO] - Training Epoch: 1/2, step 5316/107898 completed (loss: 5.547187805175781, acc: 0.05882352963089943)
[2025-02-17 16:56:57,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:57,271][root][INFO] - Training Epoch: 1/2, step 5317/107898 completed (loss: 0.033341314643621445, acc: 1.0)
[2025-02-17 16:56:57,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:57,587][root][INFO] - Training Epoch: 1/2, step 5318/107898 completed (loss: 3.7945096492767334, acc: 0.2857142984867096)
[2025-02-17 16:56:57,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:57,894][root][INFO] - Training Epoch: 1/2, step 5319/107898 completed (loss: 3.01312518119812, acc: 0.4444444477558136)
[2025-02-17 16:56:57,971][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:58,199][root][INFO] - Training Epoch: 1/2, step 5320/107898 completed (loss: 0.04115094617009163, acc: 1.0)
[2025-02-17 16:56:58,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:58,555][root][INFO] - Training Epoch: 1/2, step 5321/107898 completed (loss: 2.090914249420166, acc: 0.8571428656578064)
[2025-02-17 16:56:58,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:58,915][root][INFO] - Training Epoch: 1/2, step 5322/107898 completed (loss: 2.1234540939331055, acc: 0.25)
[2025-02-17 16:56:59,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:59,261][root][INFO] - Training Epoch: 1/2, step 5323/107898 completed (loss: 2.3587698936462402, acc: 0.5)
[2025-02-17 16:56:59,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:59,583][root][INFO] - Training Epoch: 1/2, step 5324/107898 completed (loss: 0.2960337996482849, acc: 1.0)
[2025-02-17 16:56:59,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:56:59,904][root][INFO] - Training Epoch: 1/2, step 5325/107898 completed (loss: 3.249063730239868, acc: 0.3333333432674408)
[2025-02-17 16:56:59,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:00,228][root][INFO] - Training Epoch: 1/2, step 5326/107898 completed (loss: 3.6166369915008545, acc: 0.4285714328289032)
[2025-02-17 16:57:00,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:00,594][root][INFO] - Training Epoch: 1/2, step 5327/107898 completed (loss: 0.2809540033340454, acc: 1.0)
[2025-02-17 16:57:00,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:00,974][root][INFO] - Training Epoch: 1/2, step 5328/107898 completed (loss: 1.4666616916656494, acc: 0.5)
[2025-02-17 16:57:01,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:01,332][root][INFO] - Training Epoch: 1/2, step 5329/107898 completed (loss: 0.2866017520427704, acc: 0.6666666865348816)
[2025-02-17 16:57:01,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:01,633][root][INFO] - Training Epoch: 1/2, step 5330/107898 completed (loss: 2.840024948120117, acc: 0.3333333432674408)
[2025-02-17 16:57:01,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:01,928][root][INFO] - Training Epoch: 1/2, step 5331/107898 completed (loss: 0.4578458070755005, acc: 0.6666666865348816)
[2025-02-17 16:57:02,036][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:02,279][root][INFO] - Training Epoch: 1/2, step 5332/107898 completed (loss: 1.391603946685791, acc: 0.7777777910232544)
[2025-02-17 16:57:02,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:02,611][root][INFO] - Training Epoch: 1/2, step 5333/107898 completed (loss: 0.8300453424453735, acc: 0.8999999761581421)
[2025-02-17 16:57:02,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:02,905][root][INFO] - Training Epoch: 1/2, step 5334/107898 completed (loss: 3.8623604774475098, acc: 0.1599999964237213)
[2025-02-17 16:57:02,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:03,207][root][INFO] - Training Epoch: 1/2, step 5335/107898 completed (loss: 2.097399950027466, acc: 0.6666666865348816)
[2025-02-17 16:57:03,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:03,515][root][INFO] - Training Epoch: 1/2, step 5336/107898 completed (loss: 0.035141438245773315, acc: 1.0)
[2025-02-17 16:57:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:03,897][root][INFO] - Training Epoch: 1/2, step 5337/107898 completed (loss: 0.6264610290527344, acc: 0.9285714030265808)
[2025-02-17 16:57:03,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:04,195][root][INFO] - Training Epoch: 1/2, step 5338/107898 completed (loss: 0.3429386019706726, acc: 0.9473684430122375)
[2025-02-17 16:57:04,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:04,489][root][INFO] - Training Epoch: 1/2, step 5339/107898 completed (loss: 0.009438208304345608, acc: 1.0)
[2025-02-17 16:57:04,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:04,789][root][INFO] - Training Epoch: 1/2, step 5340/107898 completed (loss: 1.1597486734390259, acc: 0.800000011920929)
[2025-02-17 16:57:04,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:05,130][root][INFO] - Training Epoch: 1/2, step 5341/107898 completed (loss: 0.011042792350053787, acc: 1.0)
[2025-02-17 16:57:05,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:05,434][root][INFO] - Training Epoch: 1/2, step 5342/107898 completed (loss: 0.08184031397104263, acc: 1.0)
[2025-02-17 16:57:05,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:05,767][root][INFO] - Training Epoch: 1/2, step 5343/107898 completed (loss: 1.1009873151779175, acc: 0.6666666865348816)
[2025-02-17 16:57:05,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:06,085][root][INFO] - Training Epoch: 1/2, step 5344/107898 completed (loss: 3.6808793544769287, acc: 0.2142857164144516)
[2025-02-17 16:57:06,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:06,393][root][INFO] - Training Epoch: 1/2, step 5345/107898 completed (loss: 0.037773583084344864, acc: 1.0)
[2025-02-17 16:57:06,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:06,695][root][INFO] - Training Epoch: 1/2, step 5346/107898 completed (loss: 0.1903301179409027, acc: 0.9599999785423279)
[2025-02-17 16:57:06,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:07,009][root][INFO] - Training Epoch: 1/2, step 5347/107898 completed (loss: 0.48777931928634644, acc: 0.8918918967247009)
[2025-02-17 16:57:07,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:07,313][root][INFO] - Training Epoch: 1/2, step 5348/107898 completed (loss: 0.006828364450484514, acc: 1.0)
[2025-02-17 16:57:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:07,649][root][INFO] - Training Epoch: 1/2, step 5349/107898 completed (loss: 0.4382803738117218, acc: 0.5)
[2025-02-17 16:57:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:07,984][root][INFO] - Training Epoch: 1/2, step 5350/107898 completed (loss: 0.48186877369880676, acc: 0.8333333134651184)
[2025-02-17 16:57:08,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:08,313][root][INFO] - Training Epoch: 1/2, step 5351/107898 completed (loss: 1.5044513940811157, acc: 0.6666666865348816)
[2025-02-17 16:57:08,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:08,620][root][INFO] - Training Epoch: 1/2, step 5352/107898 completed (loss: 1.15843665599823, acc: 0.8181818127632141)
[2025-02-17 16:57:08,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:08,953][root][INFO] - Training Epoch: 1/2, step 5353/107898 completed (loss: 0.09569903463125229, acc: 1.0)
[2025-02-17 16:57:09,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:09,325][root][INFO] - Training Epoch: 1/2, step 5354/107898 completed (loss: 3.900122880935669, acc: 0.2857142984867096)
[2025-02-17 16:57:09,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:09,641][root][INFO] - Training Epoch: 1/2, step 5355/107898 completed (loss: 0.052421797066926956, acc: 1.0)
[2025-02-17 16:57:09,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:09,981][root][INFO] - Training Epoch: 1/2, step 5356/107898 completed (loss: 0.5869157910346985, acc: 0.800000011920929)
[2025-02-17 16:57:10,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:10,327][root][INFO] - Training Epoch: 1/2, step 5357/107898 completed (loss: 2.2345547676086426, acc: 0.6000000238418579)
[2025-02-17 16:57:10,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:10,632][root][INFO] - Training Epoch: 1/2, step 5358/107898 completed (loss: 0.15007314085960388, acc: 1.0)
[2025-02-17 16:57:10,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:10,985][root][INFO] - Training Epoch: 1/2, step 5359/107898 completed (loss: 3.624464750289917, acc: 0.5)
[2025-02-17 16:57:11,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:11,326][root][INFO] - Training Epoch: 1/2, step 5360/107898 completed (loss: 0.47724249958992004, acc: 0.8636363744735718)
[2025-02-17 16:57:11,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:11,668][root][INFO] - Training Epoch: 1/2, step 5361/107898 completed (loss: 0.012943520210683346, acc: 1.0)
[2025-02-17 16:57:11,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:12,023][root][INFO] - Training Epoch: 1/2, step 5362/107898 completed (loss: 0.08436904847621918, acc: 1.0)
[2025-02-17 16:57:12,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:12,302][root][INFO] - Training Epoch: 1/2, step 5363/107898 completed (loss: 0.027087515220046043, acc: 1.0)
[2025-02-17 16:57:12,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:12,665][root][INFO] - Training Epoch: 1/2, step 5364/107898 completed (loss: 1.193743109703064, acc: 0.75)
[2025-02-17 16:57:12,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:12,996][root][INFO] - Training Epoch: 1/2, step 5365/107898 completed (loss: 0.08249147236347198, acc: 1.0)
[2025-02-17 16:57:13,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:13,310][root][INFO] - Training Epoch: 1/2, step 5366/107898 completed (loss: 2.0993754863739014, acc: 0.523809552192688)
[2025-02-17 16:57:13,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:13,678][root][INFO] - Training Epoch: 1/2, step 5367/107898 completed (loss: 1.0881239175796509, acc: 0.8333333134651184)
[2025-02-17 16:57:13,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:14,000][root][INFO] - Training Epoch: 1/2, step 5368/107898 completed (loss: 1.9231806993484497, acc: 0.5)
[2025-02-17 16:57:14,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:14,304][root][INFO] - Training Epoch: 1/2, step 5369/107898 completed (loss: 0.03879736363887787, acc: 1.0)
[2025-02-17 16:57:14,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:14,609][root][INFO] - Training Epoch: 1/2, step 5370/107898 completed (loss: 1.5975600481033325, acc: 0.7272727489471436)
[2025-02-17 16:57:14,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:14,835][root][INFO] - Training Epoch: 1/2, step 5371/107898 completed (loss: 0.8868538737297058, acc: 0.7692307829856873)
[2025-02-17 16:57:14,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:15,188][root][INFO] - Training Epoch: 1/2, step 5372/107898 completed (loss: 3.9573097229003906, acc: 0.20000000298023224)
[2025-02-17 16:57:15,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:15,509][root][INFO] - Training Epoch: 1/2, step 5373/107898 completed (loss: 0.06871116906404495, acc: 1.0)
[2025-02-17 16:57:15,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:15,807][root][INFO] - Training Epoch: 1/2, step 5374/107898 completed (loss: 0.44004103541374207, acc: 0.6666666865348816)
[2025-02-17 16:57:15,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:16,126][root][INFO] - Training Epoch: 1/2, step 5375/107898 completed (loss: 1.9837526082992554, acc: 0.5)
[2025-02-17 16:57:16,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:16,482][root][INFO] - Training Epoch: 1/2, step 5376/107898 completed (loss: 0.04907882586121559, acc: 1.0)
[2025-02-17 16:57:16,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:16,804][root][INFO] - Training Epoch: 1/2, step 5377/107898 completed (loss: 0.2980590760707855, acc: 1.0)
[2025-02-17 16:57:16,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:17,106][root][INFO] - Training Epoch: 1/2, step 5378/107898 completed (loss: 0.6039605736732483, acc: 0.8888888955116272)
[2025-02-17 16:57:17,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:17,399][root][INFO] - Training Epoch: 1/2, step 5379/107898 completed (loss: 0.1723124086856842, acc: 1.0)
[2025-02-17 16:57:17,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:17,727][root][INFO] - Training Epoch: 1/2, step 5380/107898 completed (loss: 0.2103765606880188, acc: 1.0)
[2025-02-17 16:57:17,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:18,031][root][INFO] - Training Epoch: 1/2, step 5381/107898 completed (loss: 0.007429766468703747, acc: 1.0)
[2025-02-17 16:57:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:18,335][root][INFO] - Training Epoch: 1/2, step 5382/107898 completed (loss: 0.7878280878067017, acc: 0.8947368264198303)
[2025-02-17 16:57:18,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:18,628][root][INFO] - Training Epoch: 1/2, step 5383/107898 completed (loss: 2.1689341068267822, acc: 0.5)
[2025-02-17 16:57:18,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:18,926][root][INFO] - Training Epoch: 1/2, step 5384/107898 completed (loss: 2.4214651584625244, acc: 0.5)
[2025-02-17 16:57:19,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:19,268][root][INFO] - Training Epoch: 1/2, step 5385/107898 completed (loss: 0.0036535211838781834, acc: 1.0)
[2025-02-17 16:57:19,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:19,572][root][INFO] - Training Epoch: 1/2, step 5386/107898 completed (loss: 2.9039628505706787, acc: 0.4000000059604645)
[2025-02-17 16:57:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:19,878][root][INFO] - Training Epoch: 1/2, step 5387/107898 completed (loss: 0.03695337474346161, acc: 1.0)
[2025-02-17 16:57:19,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:20,201][root][INFO] - Training Epoch: 1/2, step 5388/107898 completed (loss: 0.1648438721895218, acc: 1.0)
[2025-02-17 16:57:20,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:20,515][root][INFO] - Training Epoch: 1/2, step 5389/107898 completed (loss: 1.0411217212677002, acc: 0.8260869383811951)
[2025-02-17 16:57:20,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:20,832][root][INFO] - Training Epoch: 1/2, step 5390/107898 completed (loss: 1.4644324779510498, acc: 0.6000000238418579)
[2025-02-17 16:57:20,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:21,136][root][INFO] - Training Epoch: 1/2, step 5391/107898 completed (loss: 0.13702714443206787, acc: 1.0)
[2025-02-17 16:57:21,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:21,493][root][INFO] - Training Epoch: 1/2, step 5392/107898 completed (loss: 3.632380485534668, acc: 0.2916666567325592)
[2025-02-17 16:57:21,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:21,827][root][INFO] - Training Epoch: 1/2, step 5393/107898 completed (loss: 0.035535432398319244, acc: 1.0)
[2025-02-17 16:57:21,959][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:22,187][root][INFO] - Training Epoch: 1/2, step 5394/107898 completed (loss: 1.543350100517273, acc: 0.6785714030265808)
[2025-02-17 16:57:22,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:22,501][root][INFO] - Training Epoch: 1/2, step 5395/107898 completed (loss: 0.26023930311203003, acc: 0.9411764740943909)
[2025-02-17 16:57:22,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:22,771][root][INFO] - Training Epoch: 1/2, step 5396/107898 completed (loss: 0.014623873867094517, acc: 1.0)
[2025-02-17 16:57:22,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:23,072][root][INFO] - Training Epoch: 1/2, step 5397/107898 completed (loss: 0.0051694088615477085, acc: 1.0)
[2025-02-17 16:57:23,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:23,383][root][INFO] - Training Epoch: 1/2, step 5398/107898 completed (loss: 0.000945275358390063, acc: 1.0)
[2025-02-17 16:57:23,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:23,733][root][INFO] - Training Epoch: 1/2, step 5399/107898 completed (loss: 1.2589843273162842, acc: 0.7777777910232544)
[2025-02-17 16:57:23,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:24,055][root][INFO] - Training Epoch: 1/2, step 5400/107898 completed (loss: 0.00079303327947855, acc: 1.0)
[2025-02-17 16:57:24,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:24,398][root][INFO] - Training Epoch: 1/2, step 5401/107898 completed (loss: 1.9633619785308838, acc: 0.7777777910232544)
[2025-02-17 16:57:24,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:24,746][root][INFO] - Training Epoch: 1/2, step 5402/107898 completed (loss: 0.03290398046374321, acc: 1.0)
[2025-02-17 16:57:24,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:25,044][root][INFO] - Training Epoch: 1/2, step 5403/107898 completed (loss: 0.006729795131832361, acc: 1.0)
[2025-02-17 16:57:25,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:25,348][root][INFO] - Training Epoch: 1/2, step 5404/107898 completed (loss: 0.14236383140087128, acc: 1.0)
[2025-02-17 16:57:25,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:25,629][root][INFO] - Training Epoch: 1/2, step 5405/107898 completed (loss: 0.04065866768360138, acc: 1.0)
[2025-02-17 16:57:25,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:25,938][root][INFO] - Training Epoch: 1/2, step 5406/107898 completed (loss: 1.0398128032684326, acc: 0.7575757503509521)
[2025-02-17 16:57:26,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:26,283][root][INFO] - Training Epoch: 1/2, step 5407/107898 completed (loss: 1.861891269683838, acc: 0.7222222089767456)
[2025-02-17 16:57:26,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:26,601][root][INFO] - Training Epoch: 1/2, step 5408/107898 completed (loss: 0.06815411895513535, acc: 1.0)
[2025-02-17 16:57:26,696][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:26,944][root][INFO] - Training Epoch: 1/2, step 5409/107898 completed (loss: 0.0015292952302843332, acc: 1.0)
[2025-02-17 16:57:27,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:27,274][root][INFO] - Training Epoch: 1/2, step 5410/107898 completed (loss: 0.7208003401756287, acc: 0.800000011920929)
[2025-02-17 16:57:27,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:27,599][root][INFO] - Training Epoch: 1/2, step 5411/107898 completed (loss: 0.0331592820584774, acc: 1.0)
[2025-02-17 16:57:27,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:27,906][root][INFO] - Training Epoch: 1/2, step 5412/107898 completed (loss: 4.529264450073242, acc: 0.31578946113586426)
[2025-02-17 16:57:28,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:28,251][root][INFO] - Training Epoch: 1/2, step 5413/107898 completed (loss: 2.7168571949005127, acc: 0.3333333432674408)
[2025-02-17 16:57:28,349][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:28,564][root][INFO] - Training Epoch: 1/2, step 5414/107898 completed (loss: 0.02772274799644947, acc: 1.0)
[2025-02-17 16:57:28,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:28,868][root][INFO] - Training Epoch: 1/2, step 5415/107898 completed (loss: 1.418179988861084, acc: 0.6800000071525574)
[2025-02-17 16:57:28,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:29,152][root][INFO] - Training Epoch: 1/2, step 5416/107898 completed (loss: 0.5804309248924255, acc: 0.8571428656578064)
[2025-02-17 16:57:29,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:29,471][root][INFO] - Training Epoch: 1/2, step 5417/107898 completed (loss: 3.795330762863159, acc: 0.3478260934352875)
[2025-02-17 16:57:29,570][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:29,803][root][INFO] - Training Epoch: 1/2, step 5418/107898 completed (loss: 2.490565776824951, acc: 0.800000011920929)
[2025-02-17 16:57:29,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:30,128][root][INFO] - Training Epoch: 1/2, step 5419/107898 completed (loss: 0.017460396513342857, acc: 1.0)
[2025-02-17 16:57:30,227][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:30,458][root][INFO] - Training Epoch: 1/2, step 5420/107898 completed (loss: 1.375727653503418, acc: 0.7857142686843872)
[2025-02-17 16:57:30,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:30,773][root][INFO] - Training Epoch: 1/2, step 5421/107898 completed (loss: 0.07173742353916168, acc: 1.0)
[2025-02-17 16:57:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:31,069][root][INFO] - Training Epoch: 1/2, step 5422/107898 completed (loss: 0.12695761024951935, acc: 1.0)
[2025-02-17 16:57:31,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:31,365][root][INFO] - Training Epoch: 1/2, step 5423/107898 completed (loss: 1.2855744361877441, acc: 0.8181818127632141)
[2025-02-17 16:57:31,466][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:31,638][root][INFO] - Training Epoch: 1/2, step 5424/107898 completed (loss: 0.17611908912658691, acc: 1.0)
[2025-02-17 16:57:31,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:31,909][root][INFO] - Training Epoch: 1/2, step 5425/107898 completed (loss: 0.7751160264015198, acc: 0.8333333134651184)
[2025-02-17 16:57:31,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:32,199][root][INFO] - Training Epoch: 1/2, step 5426/107898 completed (loss: 0.7251870036125183, acc: 0.8421052694320679)
[2025-02-17 16:57:32,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:32,486][root][INFO] - Training Epoch: 1/2, step 5427/107898 completed (loss: 0.11816010624170303, acc: 1.0)
[2025-02-17 16:57:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:32,797][root][INFO] - Training Epoch: 1/2, step 5428/107898 completed (loss: 6.405201435089111, acc: 0.5)
[2025-02-17 16:57:32,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:33,129][root][INFO] - Training Epoch: 1/2, step 5429/107898 completed (loss: 0.17034867405891418, acc: 1.0)
[2025-02-17 16:57:33,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:33,432][root][INFO] - Training Epoch: 1/2, step 5430/107898 completed (loss: 0.013501904904842377, acc: 1.0)
[2025-02-17 16:57:33,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:33,812][root][INFO] - Training Epoch: 1/2, step 5431/107898 completed (loss: 2.2272329330444336, acc: 0.0)
[2025-02-17 16:57:33,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:34,159][root][INFO] - Training Epoch: 1/2, step 5432/107898 completed (loss: 1.1248518228530884, acc: 0.739130437374115)
[2025-02-17 16:57:34,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:34,405][root][INFO] - Training Epoch: 1/2, step 5433/107898 completed (loss: 0.10099112242460251, acc: 1.0)
[2025-02-17 16:57:34,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:34,697][root][INFO] - Training Epoch: 1/2, step 5434/107898 completed (loss: 3.868941307067871, acc: 0.3333333432674408)
[2025-02-17 16:57:34,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:35,049][root][INFO] - Training Epoch: 1/2, step 5435/107898 completed (loss: 0.33206912875175476, acc: 0.6666666865348816)
[2025-02-17 16:57:35,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:35,362][root][INFO] - Training Epoch: 1/2, step 5436/107898 completed (loss: 0.0038098772056400776, acc: 1.0)
[2025-02-17 16:57:35,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:35,674][root][INFO] - Training Epoch: 1/2, step 5437/107898 completed (loss: 0.6834658980369568, acc: 0.800000011920929)
[2025-02-17 16:57:35,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:36,013][root][INFO] - Training Epoch: 1/2, step 5438/107898 completed (loss: 0.08933750540018082, acc: 1.0)
[2025-02-17 16:57:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:36,312][root][INFO] - Training Epoch: 1/2, step 5439/107898 completed (loss: 0.04674466699361801, acc: 1.0)
[2025-02-17 16:57:36,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:36,622][root][INFO] - Training Epoch: 1/2, step 5440/107898 completed (loss: 0.6078683137893677, acc: 0.8571428656578064)
[2025-02-17 16:57:36,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:36,921][root][INFO] - Training Epoch: 1/2, step 5441/107898 completed (loss: 0.008161314763128757, acc: 1.0)
[2025-02-17 16:57:37,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:37,275][root][INFO] - Training Epoch: 1/2, step 5442/107898 completed (loss: 0.07820595800876617, acc: 1.0)
[2025-02-17 16:57:37,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:37,606][root][INFO] - Training Epoch: 1/2, step 5443/107898 completed (loss: 0.7984409332275391, acc: 0.6666666865348816)
[2025-02-17 16:57:37,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:37,941][root][INFO] - Training Epoch: 1/2, step 5444/107898 completed (loss: 0.3798176944255829, acc: 0.9210526347160339)
[2025-02-17 16:57:38,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:38,243][root][INFO] - Training Epoch: 1/2, step 5445/107898 completed (loss: 0.0627916008234024, acc: 1.0)
[2025-02-17 16:57:38,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:38,535][root][INFO] - Training Epoch: 1/2, step 5446/107898 completed (loss: 0.8192837834358215, acc: 0.8999999761581421)
[2025-02-17 16:57:38,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:38,879][root][INFO] - Training Epoch: 1/2, step 5447/107898 completed (loss: 0.01546897366642952, acc: 1.0)
[2025-02-17 16:57:38,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:39,201][root][INFO] - Training Epoch: 1/2, step 5448/107898 completed (loss: 3.6120853424072266, acc: 0.25)
[2025-02-17 16:57:39,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:39,505][root][INFO] - Training Epoch: 1/2, step 5449/107898 completed (loss: 1.4719997644424438, acc: 0.800000011920929)
[2025-02-17 16:57:39,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:39,812][root][INFO] - Training Epoch: 1/2, step 5450/107898 completed (loss: 0.6040762066841125, acc: 0.9090909361839294)
[2025-02-17 16:57:39,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:40,085][root][INFO] - Training Epoch: 1/2, step 5451/107898 completed (loss: 0.6613943576812744, acc: 0.875)
[2025-02-17 16:57:40,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:40,391][root][INFO] - Training Epoch: 1/2, step 5452/107898 completed (loss: 0.3126245141029358, acc: 1.0)
[2025-02-17 16:57:40,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:40,688][root][INFO] - Training Epoch: 1/2, step 5453/107898 completed (loss: 0.06519079953432083, acc: 1.0)
[2025-02-17 16:57:40,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:40,982][root][INFO] - Training Epoch: 1/2, step 5454/107898 completed (loss: 0.04979551210999489, acc: 1.0)
[2025-02-17 16:57:41,064][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:41,288][root][INFO] - Training Epoch: 1/2, step 5455/107898 completed (loss: 0.47204652428627014, acc: 0.6666666865348816)
[2025-02-17 16:57:41,394][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:41,621][root][INFO] - Training Epoch: 1/2, step 5456/107898 completed (loss: 0.0943213626742363, acc: 1.0)
[2025-02-17 16:57:41,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:41,948][root][INFO] - Training Epoch: 1/2, step 5457/107898 completed (loss: 0.1411265730857849, acc: 1.0)
[2025-02-17 16:57:42,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:42,273][root][INFO] - Training Epoch: 1/2, step 5458/107898 completed (loss: 2.906630754470825, acc: 0.5)
[2025-02-17 16:57:42,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:42,625][root][INFO] - Training Epoch: 1/2, step 5459/107898 completed (loss: 0.8327386975288391, acc: 0.800000011920929)
[2025-02-17 16:57:42,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:42,951][root][INFO] - Training Epoch: 1/2, step 5460/107898 completed (loss: 0.4690715968608856, acc: 0.9130434989929199)
[2025-02-17 16:57:43,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:43,296][root][INFO] - Training Epoch: 1/2, step 5461/107898 completed (loss: 0.004660284612327814, acc: 1.0)
[2025-02-17 16:57:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:43,639][root][INFO] - Training Epoch: 1/2, step 5462/107898 completed (loss: 0.0011913827620446682, acc: 1.0)
[2025-02-17 16:57:43,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:43,945][root][INFO] - Training Epoch: 1/2, step 5463/107898 completed (loss: 0.060888487845659256, acc: 1.0)
[2025-02-17 16:57:44,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:44,291][root][INFO] - Training Epoch: 1/2, step 5464/107898 completed (loss: 0.15674449503421783, acc: 1.0)
[2025-02-17 16:57:44,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:44,614][root][INFO] - Training Epoch: 1/2, step 5465/107898 completed (loss: 0.14620836079120636, acc: 0.9473684430122375)
[2025-02-17 16:57:44,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:44,924][root][INFO] - Training Epoch: 1/2, step 5466/107898 completed (loss: 0.9295470118522644, acc: 0.8235294222831726)
[2025-02-17 16:57:44,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:45,212][root][INFO] - Training Epoch: 1/2, step 5467/107898 completed (loss: 0.4334436357021332, acc: 0.8333333134651184)
[2025-02-17 16:57:45,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:45,559][root][INFO] - Training Epoch: 1/2, step 5468/107898 completed (loss: 0.0013175965286791325, acc: 1.0)
[2025-02-17 16:57:45,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:45,890][root][INFO] - Training Epoch: 1/2, step 5469/107898 completed (loss: 0.6977996826171875, acc: 0.6666666865348816)
[2025-02-17 16:57:45,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:46,208][root][INFO] - Training Epoch: 1/2, step 5470/107898 completed (loss: 1.3053264617919922, acc: 0.8695651888847351)
[2025-02-17 16:57:46,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:46,556][root][INFO] - Training Epoch: 1/2, step 5471/107898 completed (loss: 0.03493818640708923, acc: 1.0)
[2025-02-17 16:57:46,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:46,892][root][INFO] - Training Epoch: 1/2, step 5472/107898 completed (loss: 0.4150230288505554, acc: 0.9333333373069763)
[2025-02-17 16:57:47,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:47,239][root][INFO] - Training Epoch: 1/2, step 5473/107898 completed (loss: 0.3309099078178406, acc: 0.875)
[2025-02-17 16:57:47,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:47,592][root][INFO] - Training Epoch: 1/2, step 5474/107898 completed (loss: 0.22475510835647583, acc: 0.9166666865348816)
[2025-02-17 16:57:47,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:47,935][root][INFO] - Training Epoch: 1/2, step 5475/107898 completed (loss: 1.8203399181365967, acc: 0.4000000059604645)
[2025-02-17 16:57:48,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:48,277][root][INFO] - Training Epoch: 1/2, step 5476/107898 completed (loss: 0.0717662125825882, acc: 1.0)
[2025-02-17 16:57:48,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:48,594][root][INFO] - Training Epoch: 1/2, step 5477/107898 completed (loss: 2.110424757003784, acc: 0.695652186870575)
[2025-02-17 16:57:48,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:48,868][root][INFO] - Training Epoch: 1/2, step 5478/107898 completed (loss: 0.14226487278938293, acc: 1.0)
[2025-02-17 16:57:48,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:49,210][root][INFO] - Training Epoch: 1/2, step 5479/107898 completed (loss: 1.9634270668029785, acc: 0.6666666865348816)
[2025-02-17 16:57:49,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:49,529][root][INFO] - Training Epoch: 1/2, step 5480/107898 completed (loss: 0.0660552829504013, acc: 1.0)
[2025-02-17 16:57:49,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:49,852][root][INFO] - Training Epoch: 1/2, step 5481/107898 completed (loss: 0.934873640537262, acc: 0.3333333432674408)
[2025-02-17 16:57:49,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:50,203][root][INFO] - Training Epoch: 1/2, step 5482/107898 completed (loss: 0.2716061770915985, acc: 0.949999988079071)
[2025-02-17 16:57:50,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:50,514][root][INFO] - Training Epoch: 1/2, step 5483/107898 completed (loss: 1.4337481260299683, acc: 0.75)
[2025-02-17 16:57:50,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:50,822][root][INFO] - Training Epoch: 1/2, step 5484/107898 completed (loss: 1.2241387367248535, acc: 0.699999988079071)
[2025-02-17 16:57:50,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:51,126][root][INFO] - Training Epoch: 1/2, step 5485/107898 completed (loss: 2.3513875007629395, acc: 0.6666666865348816)
[2025-02-17 16:57:51,212][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:51,426][root][INFO] - Training Epoch: 1/2, step 5486/107898 completed (loss: 0.35471221804618835, acc: 1.0)
[2025-02-17 16:57:51,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:51,817][root][INFO] - Training Epoch: 1/2, step 5487/107898 completed (loss: 0.2181176096200943, acc: 0.9411764740943909)
[2025-02-17 16:57:51,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:52,155][root][INFO] - Training Epoch: 1/2, step 5488/107898 completed (loss: 1.1601743698120117, acc: 0.7857142686843872)
[2025-02-17 16:57:52,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:52,478][root][INFO] - Training Epoch: 1/2, step 5489/107898 completed (loss: 9.992932319641113, acc: 0.3333333432674408)
[2025-02-17 16:57:52,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:52,782][root][INFO] - Training Epoch: 1/2, step 5490/107898 completed (loss: 0.0037478806916624308, acc: 1.0)
[2025-02-17 16:57:52,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:53,088][root][INFO] - Training Epoch: 1/2, step 5491/107898 completed (loss: 0.6678594350814819, acc: 0.8666666746139526)
[2025-02-17 16:57:53,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:53,370][root][INFO] - Training Epoch: 1/2, step 5492/107898 completed (loss: 0.16448448598384857, acc: 0.8999999761581421)
[2025-02-17 16:57:53,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:53,681][root][INFO] - Training Epoch: 1/2, step 5493/107898 completed (loss: 3.177943468093872, acc: 0.25)
[2025-02-17 16:57:53,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:54,044][root][INFO] - Training Epoch: 1/2, step 5494/107898 completed (loss: 1.0283576250076294, acc: 0.8571428656578064)
[2025-02-17 16:57:54,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:54,360][root][INFO] - Training Epoch: 1/2, step 5495/107898 completed (loss: 0.08220947533845901, acc: 1.0)
[2025-02-17 16:57:54,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:54,699][root][INFO] - Training Epoch: 1/2, step 5496/107898 completed (loss: 2.4991495609283447, acc: 0.6666666865348816)
[2025-02-17 16:57:54,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:55,024][root][INFO] - Training Epoch: 1/2, step 5497/107898 completed (loss: 4.002645492553711, acc: 0.13333334028720856)
[2025-02-17 16:57:55,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:55,328][root][INFO] - Training Epoch: 1/2, step 5498/107898 completed (loss: 1.0042802095413208, acc: 0.6666666865348816)
[2025-02-17 16:57:55,414][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:55,627][root][INFO] - Training Epoch: 1/2, step 5499/107898 completed (loss: 0.41072216629981995, acc: 0.800000011920929)
[2025-02-17 16:57:55,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:55,929][root][INFO] - Training Epoch: 1/2, step 5500/107898 completed (loss: 0.08284663408994675, acc: 1.0)
[2025-02-17 16:57:56,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:56,225][root][INFO] - Training Epoch: 1/2, step 5501/107898 completed (loss: 0.18739807605743408, acc: 1.0)
[2025-02-17 16:57:56,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:56,525][root][INFO] - Training Epoch: 1/2, step 5502/107898 completed (loss: 0.302285373210907, acc: 1.0)
[2025-02-17 16:57:56,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:56,877][root][INFO] - Training Epoch: 1/2, step 5503/107898 completed (loss: 0.19206081330776215, acc: 0.9230769276618958)
[2025-02-17 16:57:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:57,255][root][INFO] - Training Epoch: 1/2, step 5504/107898 completed (loss: 0.6540077924728394, acc: 0.8571428656578064)
[2025-02-17 16:57:57,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:57,603][root][INFO] - Training Epoch: 1/2, step 5505/107898 completed (loss: 0.024389170110225677, acc: 1.0)
[2025-02-17 16:57:57,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:57,921][root][INFO] - Training Epoch: 1/2, step 5506/107898 completed (loss: 7.9734954833984375, acc: 0.0)
[2025-02-17 16:57:58,032][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:58,273][root][INFO] - Training Epoch: 1/2, step 5507/107898 completed (loss: 0.02049027383327484, acc: 1.0)
[2025-02-17 16:57:58,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:58,638][root][INFO] - Training Epoch: 1/2, step 5508/107898 completed (loss: 0.6227597594261169, acc: 0.9090909361839294)
[2025-02-17 16:57:58,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:58,970][root][INFO] - Training Epoch: 1/2, step 5509/107898 completed (loss: 0.0698389858007431, acc: 1.0)
[2025-02-17 16:57:59,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:59,304][root][INFO] - Training Epoch: 1/2, step 5510/107898 completed (loss: 1.2938097715377808, acc: 0.75)
[2025-02-17 16:57:59,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:59,586][root][INFO] - Training Epoch: 1/2, step 5511/107898 completed (loss: 3.027460813522339, acc: 0.3333333432674408)
[2025-02-17 16:57:59,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:57:59,886][root][INFO] - Training Epoch: 1/2, step 5512/107898 completed (loss: 0.31041646003723145, acc: 0.8888888955116272)
[2025-02-17 16:57:59,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:00,228][root][INFO] - Training Epoch: 1/2, step 5513/107898 completed (loss: 2.1158835887908936, acc: 0.0)
[2025-02-17 16:58:00,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:00,544][root][INFO] - Training Epoch: 1/2, step 5514/107898 completed (loss: 2.1038832664489746, acc: 0.375)
[2025-02-17 16:58:00,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:00,863][root][INFO] - Training Epoch: 1/2, step 5515/107898 completed (loss: 0.6937623620033264, acc: 0.9333333373069763)
[2025-02-17 16:58:00,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:01,161][root][INFO] - Training Epoch: 1/2, step 5516/107898 completed (loss: 1.4900907278060913, acc: 0.75)
[2025-02-17 16:58:01,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:01,463][root][INFO] - Training Epoch: 1/2, step 5517/107898 completed (loss: 2.3129525184631348, acc: 0.6666666865348816)
[2025-02-17 16:58:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:01,786][root][INFO] - Training Epoch: 1/2, step 5518/107898 completed (loss: 0.9735187292098999, acc: 0.7058823704719543)
[2025-02-17 16:58:01,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:02,104][root][INFO] - Training Epoch: 1/2, step 5519/107898 completed (loss: 1.471368670463562, acc: 0.7692307829856873)
[2025-02-17 16:58:02,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:02,445][root][INFO] - Training Epoch: 1/2, step 5520/107898 completed (loss: 0.021992716938257217, acc: 1.0)
[2025-02-17 16:58:02,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:02,775][root][INFO] - Training Epoch: 1/2, step 5521/107898 completed (loss: 0.9998732805252075, acc: 0.8125)
[2025-02-17 16:58:02,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:03,079][root][INFO] - Training Epoch: 1/2, step 5522/107898 completed (loss: 0.9516752362251282, acc: 0.6818181872367859)
[2025-02-17 16:58:03,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:03,380][root][INFO] - Training Epoch: 1/2, step 5523/107898 completed (loss: 1.0369253158569336, acc: 0.3333333432674408)
[2025-02-17 16:58:03,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:03,727][root][INFO] - Training Epoch: 1/2, step 5524/107898 completed (loss: 2.105384111404419, acc: 0.6000000238418579)
[2025-02-17 16:58:03,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:04,063][root][INFO] - Training Epoch: 1/2, step 5525/107898 completed (loss: 1.2021807432174683, acc: 0.8181818127632141)
[2025-02-17 16:58:04,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:04,373][root][INFO] - Training Epoch: 1/2, step 5526/107898 completed (loss: 2.221233606338501, acc: 0.625)
[2025-02-17 16:58:04,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:04,623][root][INFO] - Training Epoch: 1/2, step 5527/107898 completed (loss: 0.9239022731781006, acc: 0.0)
[2025-02-17 16:58:04,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:04,905][root][INFO] - Training Epoch: 1/2, step 5528/107898 completed (loss: 0.5647123456001282, acc: 0.8823529481887817)
[2025-02-17 16:58:04,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:05,184][root][INFO] - Training Epoch: 1/2, step 5529/107898 completed (loss: 1.1933823823928833, acc: 0.5)
[2025-02-17 16:58:05,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:05,485][root][INFO] - Training Epoch: 1/2, step 5530/107898 completed (loss: 3.3184452056884766, acc: 0.0)
[2025-02-17 16:58:05,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:05,780][root][INFO] - Training Epoch: 1/2, step 5531/107898 completed (loss: 1.669678807258606, acc: 0.75)
[2025-02-17 16:58:05,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:06,110][root][INFO] - Training Epoch: 1/2, step 5532/107898 completed (loss: 1.419421911239624, acc: 0.7142857313156128)
[2025-02-17 16:58:06,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:06,439][root][INFO] - Training Epoch: 1/2, step 5533/107898 completed (loss: 1.2949851751327515, acc: 0.75)
[2025-02-17 16:58:06,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:06,779][root][INFO] - Training Epoch: 1/2, step 5534/107898 completed (loss: 0.8446646928787231, acc: 0.9047619104385376)
[2025-02-17 16:58:06,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:07,135][root][INFO] - Training Epoch: 1/2, step 5535/107898 completed (loss: 0.18422210216522217, acc: 0.8888888955116272)
[2025-02-17 16:58:07,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:07,471][root][INFO] - Training Epoch: 1/2, step 5536/107898 completed (loss: 0.39887094497680664, acc: 0.8571428656578064)
[2025-02-17 16:58:07,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:07,822][root][INFO] - Training Epoch: 1/2, step 5537/107898 completed (loss: 0.44482842087745667, acc: 1.0)
[2025-02-17 16:58:07,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:08,160][root][INFO] - Training Epoch: 1/2, step 5538/107898 completed (loss: 0.05178862065076828, acc: 1.0)
[2025-02-17 16:58:08,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:08,512][root][INFO] - Training Epoch: 1/2, step 5539/107898 completed (loss: 1.2098993062973022, acc: 0.7272727489471436)
[2025-02-17 16:58:08,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:08,831][root][INFO] - Training Epoch: 1/2, step 5540/107898 completed (loss: 0.16793744266033173, acc: 1.0)
[2025-02-17 16:58:08,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:09,144][root][INFO] - Training Epoch: 1/2, step 5541/107898 completed (loss: 0.9829132556915283, acc: 0.8518518805503845)
[2025-02-17 16:58:09,229][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:09,443][root][INFO] - Training Epoch: 1/2, step 5542/107898 completed (loss: 3.5671513080596924, acc: 0.2222222238779068)
[2025-02-17 16:58:09,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:09,744][root][INFO] - Training Epoch: 1/2, step 5543/107898 completed (loss: 1.0258415937423706, acc: 0.7333333492279053)
[2025-02-17 16:58:09,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:10,055][root][INFO] - Training Epoch: 1/2, step 5544/107898 completed (loss: 1.0764875411987305, acc: 0.6666666865348816)
[2025-02-17 16:58:10,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:10,361][root][INFO] - Training Epoch: 1/2, step 5545/107898 completed (loss: 0.9153435826301575, acc: 0.6666666865348816)
[2025-02-17 16:58:10,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:10,677][root][INFO] - Training Epoch: 1/2, step 5546/107898 completed (loss: 0.02089497819542885, acc: 1.0)
[2025-02-17 16:58:10,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:11,009][root][INFO] - Training Epoch: 1/2, step 5547/107898 completed (loss: 2.912931203842163, acc: 0.4545454680919647)
[2025-02-17 16:58:11,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:11,310][root][INFO] - Training Epoch: 1/2, step 5548/107898 completed (loss: 0.006812306120991707, acc: 1.0)
[2025-02-17 16:58:11,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:11,660][root][INFO] - Training Epoch: 1/2, step 5549/107898 completed (loss: 1.1910333633422852, acc: 0.6666666865348816)
[2025-02-17 16:58:11,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:11,974][root][INFO] - Training Epoch: 1/2, step 5550/107898 completed (loss: 2.586280584335327, acc: 0.25)
[2025-02-17 16:58:12,064][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:12,286][root][INFO] - Training Epoch: 1/2, step 5551/107898 completed (loss: 0.6814463138580322, acc: 0.6666666865348816)
[2025-02-17 16:58:12,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:12,625][root][INFO] - Training Epoch: 1/2, step 5552/107898 completed (loss: 0.0263921357691288, acc: 1.0)
[2025-02-17 16:58:12,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:12,971][root][INFO] - Training Epoch: 1/2, step 5553/107898 completed (loss: 0.20877832174301147, acc: 1.0)
[2025-02-17 16:58:13,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:13,228][root][INFO] - Training Epoch: 1/2, step 5554/107898 completed (loss: 0.27730971574783325, acc: 1.0)
[2025-02-17 16:58:13,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:13,524][root][INFO] - Training Epoch: 1/2, step 5555/107898 completed (loss: 1.5191149711608887, acc: 0.6000000238418579)
[2025-02-17 16:58:13,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:13,853][root][INFO] - Training Epoch: 1/2, step 5556/107898 completed (loss: 0.012007573619484901, acc: 1.0)
[2025-02-17 16:58:13,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:14,194][root][INFO] - Training Epoch: 1/2, step 5557/107898 completed (loss: 2.6117913722991943, acc: 0.3333333432674408)
[2025-02-17 16:58:14,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:14,510][root][INFO] - Training Epoch: 1/2, step 5558/107898 completed (loss: 0.6265078186988831, acc: 0.800000011920929)
[2025-02-17 16:58:14,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:14,870][root][INFO] - Training Epoch: 1/2, step 5559/107898 completed (loss: 0.13407307863235474, acc: 1.0)
[2025-02-17 16:58:14,959][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:15,184][root][INFO] - Training Epoch: 1/2, step 5560/107898 completed (loss: 2.453664779663086, acc: 0.6666666865348816)
[2025-02-17 16:58:15,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:15,504][root][INFO] - Training Epoch: 1/2, step 5561/107898 completed (loss: 3.345956802368164, acc: 0.20000000298023224)
[2025-02-17 16:58:15,585][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:15,798][root][INFO] - Training Epoch: 1/2, step 5562/107898 completed (loss: 0.36028197407722473, acc: 0.8421052694320679)
[2025-02-17 16:58:15,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:16,101][root][INFO] - Training Epoch: 1/2, step 5563/107898 completed (loss: 0.45506444573402405, acc: 0.8666666746139526)
[2025-02-17 16:58:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:16,392][root][INFO] - Training Epoch: 1/2, step 5564/107898 completed (loss: 0.08636781573295593, acc: 1.0)
[2025-02-17 16:58:16,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:16,696][root][INFO] - Training Epoch: 1/2, step 5565/107898 completed (loss: 1.2322872877120972, acc: 0.6538461446762085)
[2025-02-17 16:58:16,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:16,950][root][INFO] - Training Epoch: 1/2, step 5566/107898 completed (loss: 0.11495068669319153, acc: 1.0)
[2025-02-17 16:58:17,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:17,260][root][INFO] - Training Epoch: 1/2, step 5567/107898 completed (loss: 0.3015936613082886, acc: 1.0)
[2025-02-17 16:58:17,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:17,595][root][INFO] - Training Epoch: 1/2, step 5568/107898 completed (loss: 0.8528344035148621, acc: 0.8999999761581421)
[2025-02-17 16:58:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:17,913][root][INFO] - Training Epoch: 1/2, step 5569/107898 completed (loss: 1.0271499156951904, acc: 0.9333333373069763)
[2025-02-17 16:58:17,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:18,189][root][INFO] - Training Epoch: 1/2, step 5570/107898 completed (loss: 0.013534458354115486, acc: 1.0)
[2025-02-17 16:58:18,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:18,482][root][INFO] - Training Epoch: 1/2, step 5571/107898 completed (loss: 0.17841045558452606, acc: 0.8888888955116272)
[2025-02-17 16:58:18,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:18,830][root][INFO] - Training Epoch: 1/2, step 5572/107898 completed (loss: 2.663203001022339, acc: 0.4000000059604645)
[2025-02-17 16:58:18,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:19,177][root][INFO] - Training Epoch: 1/2, step 5573/107898 completed (loss: 0.7055493593215942, acc: 0.5)
[2025-02-17 16:58:19,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:19,490][root][INFO] - Training Epoch: 1/2, step 5574/107898 completed (loss: 0.15993070602416992, acc: 1.0)
[2025-02-17 16:58:19,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:19,835][root][INFO] - Training Epoch: 1/2, step 5575/107898 completed (loss: 0.32525762915611267, acc: 1.0)
[2025-02-17 16:58:19,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:20,159][root][INFO] - Training Epoch: 1/2, step 5576/107898 completed (loss: 0.08550513535737991, acc: 1.0)
[2025-02-17 16:58:20,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:20,505][root][INFO] - Training Epoch: 1/2, step 5577/107898 completed (loss: 0.0317830815911293, acc: 1.0)
[2025-02-17 16:58:20,599][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:20,830][root][INFO] - Training Epoch: 1/2, step 5578/107898 completed (loss: 0.18632540106773376, acc: 1.0)
[2025-02-17 16:58:20,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:21,121][root][INFO] - Training Epoch: 1/2, step 5579/107898 completed (loss: 0.9877079129219055, acc: 0.8999999761581421)
[2025-02-17 16:58:21,204][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:21,415][root][INFO] - Training Epoch: 1/2, step 5580/107898 completed (loss: 2.934424638748169, acc: 0.5789473652839661)
[2025-02-17 16:58:21,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:21,721][root][INFO] - Training Epoch: 1/2, step 5581/107898 completed (loss: 0.09512951970100403, acc: 1.0)
[2025-02-17 16:58:21,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:22,066][root][INFO] - Training Epoch: 1/2, step 5582/107898 completed (loss: 1.1083143949508667, acc: 0.6666666865348816)
[2025-02-17 16:58:22,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:22,387][root][INFO] - Training Epoch: 1/2, step 5583/107898 completed (loss: 3.607492208480835, acc: 0.5)
[2025-02-17 16:58:22,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:22,712][root][INFO] - Training Epoch: 1/2, step 5584/107898 completed (loss: 0.002903417684137821, acc: 1.0)
[2025-02-17 16:58:22,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:23,012][root][INFO] - Training Epoch: 1/2, step 5585/107898 completed (loss: 0.1424323171377182, acc: 1.0)
[2025-02-17 16:58:23,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:23,319][root][INFO] - Training Epoch: 1/2, step 5586/107898 completed (loss: 0.3136018216609955, acc: 0.8571428656578064)
[2025-02-17 16:58:23,394][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:23,615][root][INFO] - Training Epoch: 1/2, step 5587/107898 completed (loss: 0.24415040016174316, acc: 1.0)
[2025-02-17 16:58:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:23,910][root][INFO] - Training Epoch: 1/2, step 5588/107898 completed (loss: 1.6309056282043457, acc: 0.6666666865348816)
[2025-02-17 16:58:24,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:24,245][root][INFO] - Training Epoch: 1/2, step 5589/107898 completed (loss: 3.034558057785034, acc: 0.4545454680919647)
[2025-02-17 16:58:24,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:24,599][root][INFO] - Training Epoch: 1/2, step 5590/107898 completed (loss: 0.8857623338699341, acc: 0.5)
[2025-02-17 16:58:24,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:24,885][root][INFO] - Training Epoch: 1/2, step 5591/107898 completed (loss: 0.2739276885986328, acc: 1.0)
[2025-02-17 16:58:24,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:25,170][root][INFO] - Training Epoch: 1/2, step 5592/107898 completed (loss: 1.4182556867599487, acc: 0.6666666865348816)
[2025-02-17 16:58:25,250][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:25,475][root][INFO] - Training Epoch: 1/2, step 5593/107898 completed (loss: 0.44856390357017517, acc: 0.8888888955116272)
[2025-02-17 16:58:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:25,738][root][INFO] - Training Epoch: 1/2, step 5594/107898 completed (loss: 0.027154358103871346, acc: 1.0)
[2025-02-17 16:58:25,822][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:26,046][root][INFO] - Training Epoch: 1/2, step 5595/107898 completed (loss: 3.16117787361145, acc: 0.5)
[2025-02-17 16:58:26,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:26,319][root][INFO] - Training Epoch: 1/2, step 5596/107898 completed (loss: 0.2948218286037445, acc: 1.0)
[2025-02-17 16:58:26,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:26,629][root][INFO] - Training Epoch: 1/2, step 5597/107898 completed (loss: 0.8310949802398682, acc: 0.8888888955116272)
[2025-02-17 16:58:26,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:26,942][root][INFO] - Training Epoch: 1/2, step 5598/107898 completed (loss: 0.25093236565589905, acc: 1.0)
[2025-02-17 16:58:27,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:27,256][root][INFO] - Training Epoch: 1/2, step 5599/107898 completed (loss: 4.723504543304443, acc: 0.5)
[2025-02-17 16:58:27,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:27,558][root][INFO] - Training Epoch: 1/2, step 5600/107898 completed (loss: 0.1576090008020401, acc: 1.0)
[2025-02-17 16:58:27,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:27,865][root][INFO] - Training Epoch: 1/2, step 5601/107898 completed (loss: 0.37542083859443665, acc: 0.8888888955116272)
[2025-02-17 16:58:27,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:28,162][root][INFO] - Training Epoch: 1/2, step 5602/107898 completed (loss: 1.0292052030563354, acc: 0.6315789222717285)
[2025-02-17 16:58:28,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:28,497][root][INFO] - Training Epoch: 1/2, step 5603/107898 completed (loss: 1.3719356060028076, acc: 0.5)
[2025-02-17 16:58:28,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:28,853][root][INFO] - Training Epoch: 1/2, step 5604/107898 completed (loss: 1.1526585817337036, acc: 0.75)
[2025-02-17 16:58:28,957][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:29,195][root][INFO] - Training Epoch: 1/2, step 5605/107898 completed (loss: 0.05021290481090546, acc: 1.0)
[2025-02-17 16:58:29,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:29,511][root][INFO] - Training Epoch: 1/2, step 5606/107898 completed (loss: 0.42802301049232483, acc: 1.0)
[2025-02-17 16:58:29,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:29,871][root][INFO] - Training Epoch: 1/2, step 5607/107898 completed (loss: 0.4014500081539154, acc: 0.9615384340286255)
[2025-02-17 16:58:29,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:30,225][root][INFO] - Training Epoch: 1/2, step 5608/107898 completed (loss: 0.1320895105600357, acc: 1.0)
[2025-02-17 16:58:30,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:30,546][root][INFO] - Training Epoch: 1/2, step 5609/107898 completed (loss: 0.12695208191871643, acc: 0.9545454382896423)
[2025-02-17 16:58:30,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:30,845][root][INFO] - Training Epoch: 1/2, step 5610/107898 completed (loss: 0.320924311876297, acc: 1.0)
[2025-02-17 16:58:30,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:31,140][root][INFO] - Training Epoch: 1/2, step 5611/107898 completed (loss: 0.20887480676174164, acc: 0.875)
[2025-02-17 16:58:31,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:31,435][root][INFO] - Training Epoch: 1/2, step 5612/107898 completed (loss: 0.5776929259300232, acc: 0.8333333134651184)
[2025-02-17 16:58:31,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:31,741][root][INFO] - Training Epoch: 1/2, step 5613/107898 completed (loss: 2.1624767780303955, acc: 0.5714285969734192)
[2025-02-17 16:58:31,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:32,036][root][INFO] - Training Epoch: 1/2, step 5614/107898 completed (loss: 0.0595242865383625, acc: 1.0)
[2025-02-17 16:58:32,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:32,344][root][INFO] - Training Epoch: 1/2, step 5615/107898 completed (loss: 0.1954168975353241, acc: 0.949999988079071)
[2025-02-17 16:58:32,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:32,642][root][INFO] - Training Epoch: 1/2, step 5616/107898 completed (loss: 0.04717840626835823, acc: 1.0)
[2025-02-17 16:58:32,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:32,983][root][INFO] - Training Epoch: 1/2, step 5617/107898 completed (loss: 0.06876148283481598, acc: 1.0)
[2025-02-17 16:58:33,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:33,304][root][INFO] - Training Epoch: 1/2, step 5618/107898 completed (loss: 0.004883757326751947, acc: 1.0)
[2025-02-17 16:58:33,414][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:33,656][root][INFO] - Training Epoch: 1/2, step 5619/107898 completed (loss: 0.0710870549082756, acc: 1.0)
[2025-02-17 16:58:33,759][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:33,994][root][INFO] - Training Epoch: 1/2, step 5620/107898 completed (loss: 0.6650792360305786, acc: 0.800000011920929)
[2025-02-17 16:58:34,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:34,307][root][INFO] - Training Epoch: 1/2, step 5621/107898 completed (loss: 0.01167256198823452, acc: 1.0)
[2025-02-17 16:58:34,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:34,613][root][INFO] - Training Epoch: 1/2, step 5622/107898 completed (loss: 0.041730847209692, acc: 1.0)
[2025-02-17 16:58:34,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:34,913][root][INFO] - Training Epoch: 1/2, step 5623/107898 completed (loss: 0.5162250399589539, acc: 0.8333333134651184)
[2025-02-17 16:58:34,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:35,214][root][INFO] - Training Epoch: 1/2, step 5624/107898 completed (loss: 2.401614189147949, acc: 0.6000000238418579)
[2025-02-17 16:58:35,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:35,528][root][INFO] - Training Epoch: 1/2, step 5625/107898 completed (loss: 0.40273788571357727, acc: 0.75)
[2025-02-17 16:58:35,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:35,858][root][INFO] - Training Epoch: 1/2, step 5626/107898 completed (loss: 0.02530333586037159, acc: 1.0)
[2025-02-17 16:58:35,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:36,163][root][INFO] - Training Epoch: 1/2, step 5627/107898 completed (loss: 0.05557290464639664, acc: 1.0)
[2025-02-17 16:58:36,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:36,516][root][INFO] - Training Epoch: 1/2, step 5628/107898 completed (loss: 0.03491321578621864, acc: 1.0)
[2025-02-17 16:58:36,631][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:36,867][root][INFO] - Training Epoch: 1/2, step 5629/107898 completed (loss: 0.30412906408309937, acc: 0.875)
[2025-02-17 16:58:36,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:37,177][root][INFO] - Training Epoch: 1/2, step 5630/107898 completed (loss: 0.05414476618170738, acc: 1.0)
[2025-02-17 16:58:37,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:37,483][root][INFO] - Training Epoch: 1/2, step 5631/107898 completed (loss: 0.011284398846328259, acc: 1.0)
[2025-02-17 16:58:37,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:37,811][root][INFO] - Training Epoch: 1/2, step 5632/107898 completed (loss: 1.5794422626495361, acc: 0.800000011920929)
[2025-02-17 16:58:37,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:38,097][root][INFO] - Training Epoch: 1/2, step 5633/107898 completed (loss: 0.12669657170772552, acc: 1.0)
[2025-02-17 16:58:38,204][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:38,447][root][INFO] - Training Epoch: 1/2, step 5634/107898 completed (loss: 2.4321579933166504, acc: 0.6000000238418579)
[2025-02-17 16:58:38,564][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:38,794][root][INFO] - Training Epoch: 1/2, step 5635/107898 completed (loss: 4.0025200843811035, acc: 0.1111111119389534)
[2025-02-17 16:58:38,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:39,085][root][INFO] - Training Epoch: 1/2, step 5636/107898 completed (loss: 1.147879719734192, acc: 0.8333333134651184)
[2025-02-17 16:58:39,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:39,392][root][INFO] - Training Epoch: 1/2, step 5637/107898 completed (loss: 0.017143653705716133, acc: 1.0)
[2025-02-17 16:58:39,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:39,705][root][INFO] - Training Epoch: 1/2, step 5638/107898 completed (loss: 3.346059560775757, acc: 0.5)
[2025-02-17 16:58:39,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:40,024][root][INFO] - Training Epoch: 1/2, step 5639/107898 completed (loss: 0.7333366870880127, acc: 0.8333333134651184)
[2025-02-17 16:58:40,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:40,306][root][INFO] - Training Epoch: 1/2, step 5640/107898 completed (loss: 0.6098524928092957, acc: 0.5)
[2025-02-17 16:58:40,383][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:40,537][root][INFO] - Training Epoch: 1/2, step 5641/107898 completed (loss: 2.6896822452545166, acc: 0.3333333432674408)
[2025-02-17 16:58:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:40,829][root][INFO] - Training Epoch: 1/2, step 5642/107898 completed (loss: 2.1847872734069824, acc: 0.3333333432674408)
[2025-02-17 16:58:40,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:41,125][root][INFO] - Training Epoch: 1/2, step 5643/107898 completed (loss: 0.4799163043498993, acc: 0.9117646813392639)
[2025-02-17 16:58:41,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:41,445][root][INFO] - Training Epoch: 1/2, step 5644/107898 completed (loss: 1.5866239070892334, acc: 0.6190476417541504)
[2025-02-17 16:58:41,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:41,744][root][INFO] - Training Epoch: 1/2, step 5645/107898 completed (loss: 1.870519757270813, acc: 0.692307710647583)
[2025-02-17 16:58:41,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:42,080][root][INFO] - Training Epoch: 1/2, step 5646/107898 completed (loss: 0.8122493028640747, acc: 0.8518518805503845)
[2025-02-17 16:58:42,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:42,395][root][INFO] - Training Epoch: 1/2, step 5647/107898 completed (loss: 2.545100688934326, acc: 0.4000000059604645)
[2025-02-17 16:58:42,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:42,721][root][INFO] - Training Epoch: 1/2, step 5648/107898 completed (loss: 0.7525662183761597, acc: 0.800000011920929)
[2025-02-17 16:58:42,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:43,028][root][INFO] - Training Epoch: 1/2, step 5649/107898 completed (loss: 0.6449898481369019, acc: 0.84375)
[2025-02-17 16:58:43,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:43,339][root][INFO] - Training Epoch: 1/2, step 5650/107898 completed (loss: 0.011472209356725216, acc: 1.0)
[2025-02-17 16:58:43,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:43,668][root][INFO] - Training Epoch: 1/2, step 5651/107898 completed (loss: 1.2836612462997437, acc: 0.6499999761581421)
[2025-02-17 16:58:43,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:43,966][root][INFO] - Training Epoch: 1/2, step 5652/107898 completed (loss: 2.0995187759399414, acc: 0.6666666865348816)
[2025-02-17 16:58:44,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:44,253][root][INFO] - Training Epoch: 1/2, step 5653/107898 completed (loss: 0.15922290086746216, acc: 1.0)
[2025-02-17 16:58:44,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:44,586][root][INFO] - Training Epoch: 1/2, step 5654/107898 completed (loss: 1.1675771474838257, acc: 0.8571428656578064)
[2025-02-17 16:58:44,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:44,893][root][INFO] - Training Epoch: 1/2, step 5655/107898 completed (loss: 0.045019615441560745, acc: 1.0)
[2025-02-17 16:58:44,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:45,172][root][INFO] - Training Epoch: 1/2, step 5656/107898 completed (loss: 0.7951363325119019, acc: 0.800000011920929)
[2025-02-17 16:58:45,250][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:45,461][root][INFO] - Training Epoch: 1/2, step 5657/107898 completed (loss: 6.216693878173828, acc: 0.0)
[2025-02-17 16:58:45,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:45,756][root][INFO] - Training Epoch: 1/2, step 5658/107898 completed (loss: 0.019399361684918404, acc: 1.0)
[2025-02-17 16:58:45,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:46,055][root][INFO] - Training Epoch: 1/2, step 5659/107898 completed (loss: 0.046999868005514145, acc: 1.0)
[2025-02-17 16:58:46,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:46,411][root][INFO] - Training Epoch: 1/2, step 5660/107898 completed (loss: 0.3053370416164398, acc: 0.9354838728904724)
[2025-02-17 16:58:46,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:46,711][root][INFO] - Training Epoch: 1/2, step 5661/107898 completed (loss: 0.28699740767478943, acc: 0.6666666865348816)
[2025-02-17 16:58:46,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:47,034][root][INFO] - Training Epoch: 1/2, step 5662/107898 completed (loss: 0.13200509548187256, acc: 1.0)
[2025-02-17 16:58:47,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:47,341][root][INFO] - Training Epoch: 1/2, step 5663/107898 completed (loss: 0.003784777596592903, acc: 1.0)
[2025-02-17 16:58:47,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:47,685][root][INFO] - Training Epoch: 1/2, step 5664/107898 completed (loss: 0.8983467221260071, acc: 0.800000011920929)
[2025-02-17 16:58:47,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:48,012][root][INFO] - Training Epoch: 1/2, step 5665/107898 completed (loss: 0.24957618117332458, acc: 0.9545454382896423)
[2025-02-17 16:58:48,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:48,357][root][INFO] - Training Epoch: 1/2, step 5666/107898 completed (loss: 1.3188248872756958, acc: 0.8888888955116272)
[2025-02-17 16:58:48,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:48,672][root][INFO] - Training Epoch: 1/2, step 5667/107898 completed (loss: 3.788532257080078, acc: 0.25)
[2025-02-17 16:58:48,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:48,986][root][INFO] - Training Epoch: 1/2, step 5668/107898 completed (loss: 1.564219355583191, acc: 0.5)
[2025-02-17 16:58:49,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:49,299][root][INFO] - Training Epoch: 1/2, step 5669/107898 completed (loss: 0.21436934173107147, acc: 1.0)
[2025-02-17 16:58:49,383][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:49,605][root][INFO] - Training Epoch: 1/2, step 5670/107898 completed (loss: 2.3005847930908203, acc: 0.75)
[2025-02-17 16:58:49,687][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:49,908][root][INFO] - Training Epoch: 1/2, step 5671/107898 completed (loss: 1.8165098428726196, acc: 0.6000000238418579)
[2025-02-17 16:58:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:50,240][root][INFO] - Training Epoch: 1/2, step 5672/107898 completed (loss: 0.6708584427833557, acc: 0.6666666865348816)
[2025-02-17 16:58:50,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:50,566][root][INFO] - Training Epoch: 1/2, step 5673/107898 completed (loss: 0.23737455904483795, acc: 1.0)
[2025-02-17 16:58:50,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:50,874][root][INFO] - Training Epoch: 1/2, step 5674/107898 completed (loss: 0.6436091661453247, acc: 0.8888888955116272)
[2025-02-17 16:58:50,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:51,157][root][INFO] - Training Epoch: 1/2, step 5675/107898 completed (loss: 0.13996385037899017, acc: 1.0)
[2025-02-17 16:58:51,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:51,454][root][INFO] - Training Epoch: 1/2, step 5676/107898 completed (loss: 0.00830139685422182, acc: 1.0)
[2025-02-17 16:58:51,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:51,786][root][INFO] - Training Epoch: 1/2, step 5677/107898 completed (loss: 1.5771645307540894, acc: 0.5)
[2025-02-17 16:58:51,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:52,101][root][INFO] - Training Epoch: 1/2, step 5678/107898 completed (loss: 0.9409151673316956, acc: 0.5714285969734192)
[2025-02-17 16:58:52,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:52,386][root][INFO] - Training Epoch: 1/2, step 5679/107898 completed (loss: 0.004363635554909706, acc: 1.0)
[2025-02-17 16:58:52,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:52,681][root][INFO] - Training Epoch: 1/2, step 5680/107898 completed (loss: 1.8076057434082031, acc: 0.25)
[2025-02-17 16:58:52,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:52,999][root][INFO] - Training Epoch: 1/2, step 5681/107898 completed (loss: 0.0018589877290651202, acc: 1.0)
[2025-02-17 16:58:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:53,333][root][INFO] - Training Epoch: 1/2, step 5682/107898 completed (loss: 0.38912513852119446, acc: 0.8333333134651184)
[2025-02-17 16:58:53,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:53,657][root][INFO] - Training Epoch: 1/2, step 5683/107898 completed (loss: 0.026076359674334526, acc: 1.0)
[2025-02-17 16:58:53,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:53,952][root][INFO] - Training Epoch: 1/2, step 5684/107898 completed (loss: 0.0035780633334070444, acc: 1.0)
[2025-02-17 16:58:54,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:54,257][root][INFO] - Training Epoch: 1/2, step 5685/107898 completed (loss: 3.506591558456421, acc: 0.5)
[2025-02-17 16:58:54,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:54,568][root][INFO] - Training Epoch: 1/2, step 5686/107898 completed (loss: 0.18481619656085968, acc: 0.9166666865348816)
[2025-02-17 16:58:54,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:54,875][root][INFO] - Training Epoch: 1/2, step 5687/107898 completed (loss: 1.0906431674957275, acc: 0.7272727489471436)
[2025-02-17 16:58:54,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:55,221][root][INFO] - Training Epoch: 1/2, step 5688/107898 completed (loss: 0.6927967667579651, acc: 0.8461538553237915)
[2025-02-17 16:58:55,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:55,550][root][INFO] - Training Epoch: 1/2, step 5689/107898 completed (loss: 0.0928589254617691, acc: 1.0)
[2025-02-17 16:58:55,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:55,877][root][INFO] - Training Epoch: 1/2, step 5690/107898 completed (loss: 2.440958023071289, acc: 0.5)
[2025-02-17 16:58:55,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:56,201][root][INFO] - Training Epoch: 1/2, step 5691/107898 completed (loss: 0.6505300998687744, acc: 0.8947368264198303)
[2025-02-17 16:58:56,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:56,519][root][INFO] - Training Epoch: 1/2, step 5692/107898 completed (loss: 0.2833886444568634, acc: 0.95652174949646)
[2025-02-17 16:58:56,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:56,825][root][INFO] - Training Epoch: 1/2, step 5693/107898 completed (loss: 0.15676690638065338, acc: 1.0)
[2025-02-17 16:58:56,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:57,133][root][INFO] - Training Epoch: 1/2, step 5694/107898 completed (loss: 0.3032735288143158, acc: 0.9629629850387573)
[2025-02-17 16:58:57,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:57,455][root][INFO] - Training Epoch: 1/2, step 5695/107898 completed (loss: 0.7520713210105896, acc: 0.5)
[2025-02-17 16:58:57,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:57,745][root][INFO] - Training Epoch: 1/2, step 5696/107898 completed (loss: 0.3230409324169159, acc: 0.9473684430122375)
[2025-02-17 16:58:57,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:58,091][root][INFO] - Training Epoch: 1/2, step 5697/107898 completed (loss: 0.3456537127494812, acc: 0.9545454382896423)
[2025-02-17 16:58:58,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:58,435][root][INFO] - Training Epoch: 1/2, step 5698/107898 completed (loss: 1.7652480602264404, acc: 0.5555555820465088)
[2025-02-17 16:58:58,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:58,757][root][INFO] - Training Epoch: 1/2, step 5699/107898 completed (loss: 0.0457330085337162, acc: 1.0)
[2025-02-17 16:58:58,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:59,059][root][INFO] - Training Epoch: 1/2, step 5700/107898 completed (loss: 0.8501273989677429, acc: 0.8666666746139526)
[2025-02-17 16:58:59,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:59,371][root][INFO] - Training Epoch: 1/2, step 5701/107898 completed (loss: 1.2389795780181885, acc: 0.5)
[2025-02-17 16:58:59,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:58:59,690][root][INFO] - Training Epoch: 1/2, step 5702/107898 completed (loss: 1.8119572401046753, acc: 0.75)
[2025-02-17 16:58:59,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:00,019][root][INFO] - Training Epoch: 1/2, step 5703/107898 completed (loss: 1.3142324686050415, acc: 0.7647058963775635)
[2025-02-17 16:59:00,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:00,370][root][INFO] - Training Epoch: 1/2, step 5704/107898 completed (loss: 0.5782068371772766, acc: 1.0)
[2025-02-17 16:59:00,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:00,666][root][INFO] - Training Epoch: 1/2, step 5705/107898 completed (loss: 0.10595826059579849, acc: 1.0)
[2025-02-17 16:59:00,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:01,005][root][INFO] - Training Epoch: 1/2, step 5706/107898 completed (loss: 0.6469193696975708, acc: 0.8571428656578064)
[2025-02-17 16:59:01,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:01,328][root][INFO] - Training Epoch: 1/2, step 5707/107898 completed (loss: 0.14186586439609528, acc: 1.0)
[2025-02-17 16:59:01,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:01,619][root][INFO] - Training Epoch: 1/2, step 5708/107898 completed (loss: 1.8259788751602173, acc: 0.6666666865348816)
[2025-02-17 16:59:01,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:01,977][root][INFO] - Training Epoch: 1/2, step 5709/107898 completed (loss: 0.17014040052890778, acc: 1.0)
[2025-02-17 16:59:02,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:02,257][root][INFO] - Training Epoch: 1/2, step 5710/107898 completed (loss: 1.247633695602417, acc: 0.75)
[2025-02-17 16:59:02,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:02,556][root][INFO] - Training Epoch: 1/2, step 5711/107898 completed (loss: 0.054362211376428604, acc: 1.0)
[2025-02-17 16:59:02,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:02,799][root][INFO] - Training Epoch: 1/2, step 5712/107898 completed (loss: 0.007695906795561314, acc: 1.0)
[2025-02-17 16:59:02,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:03,060][root][INFO] - Training Epoch: 1/2, step 5713/107898 completed (loss: 0.6847233772277832, acc: 0.75)
[2025-02-17 16:59:03,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:03,394][root][INFO] - Training Epoch: 1/2, step 5714/107898 completed (loss: 3.280057668685913, acc: 0.3333333432674408)
[2025-02-17 16:59:03,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:03,677][root][INFO] - Training Epoch: 1/2, step 5715/107898 completed (loss: 0.8790371417999268, acc: 1.0)
[2025-02-17 16:59:03,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:03,981][root][INFO] - Training Epoch: 1/2, step 5716/107898 completed (loss: 0.07359105348587036, acc: 1.0)
[2025-02-17 16:59:04,061][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:04,280][root][INFO] - Training Epoch: 1/2, step 5717/107898 completed (loss: 1.7258912324905396, acc: 0.6666666865348816)
[2025-02-17 16:59:04,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:04,577][root][INFO] - Training Epoch: 1/2, step 5718/107898 completed (loss: 0.18310841917991638, acc: 1.0)
[2025-02-17 16:59:04,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:04,911][root][INFO] - Training Epoch: 1/2, step 5719/107898 completed (loss: 0.049296990036964417, acc: 1.0)
[2025-02-17 16:59:04,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:05,215][root][INFO] - Training Epoch: 1/2, step 5720/107898 completed (loss: 0.22995290160179138, acc: 0.9090909361839294)
[2025-02-17 16:59:05,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:05,523][root][INFO] - Training Epoch: 1/2, step 5721/107898 completed (loss: 3.7054543495178223, acc: 0.23076923191547394)
[2025-02-17 16:59:05,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:05,828][root][INFO] - Training Epoch: 1/2, step 5722/107898 completed (loss: 1.7650538682937622, acc: 0.5)
[2025-02-17 16:59:05,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:06,123][root][INFO] - Training Epoch: 1/2, step 5723/107898 completed (loss: 0.42035973072052, acc: 0.9230769276618958)
[2025-02-17 16:59:06,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:06,411][root][INFO] - Training Epoch: 1/2, step 5724/107898 completed (loss: 4.070635795593262, acc: 0.6000000238418579)
[2025-02-17 16:59:06,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:06,713][root][INFO] - Training Epoch: 1/2, step 5725/107898 completed (loss: 0.029990483075380325, acc: 1.0)
[2025-02-17 16:59:06,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:07,014][root][INFO] - Training Epoch: 1/2, step 5726/107898 completed (loss: 1.8038015365600586, acc: 0.6000000238418579)
[2025-02-17 16:59:07,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:07,286][root][INFO] - Training Epoch: 1/2, step 5727/107898 completed (loss: 2.3711345195770264, acc: 0.6470588445663452)
[2025-02-17 16:59:07,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:07,588][root][INFO] - Training Epoch: 1/2, step 5728/107898 completed (loss: 0.82337486743927, acc: 0.5)
[2025-02-17 16:59:07,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:07,897][root][INFO] - Training Epoch: 1/2, step 5729/107898 completed (loss: 0.5043025016784668, acc: 0.875)
[2025-02-17 16:59:08,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:08,231][root][INFO] - Training Epoch: 1/2, step 5730/107898 completed (loss: 0.13742510974407196, acc: 0.9230769276618958)
[2025-02-17 16:59:08,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:08,566][root][INFO] - Training Epoch: 1/2, step 5731/107898 completed (loss: 3.9478867053985596, acc: 0.4000000059604645)
[2025-02-17 16:59:08,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:08,890][root][INFO] - Training Epoch: 1/2, step 5732/107898 completed (loss: 0.20150922238826752, acc: 1.0)
[2025-02-17 16:59:09,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:09,252][root][INFO] - Training Epoch: 1/2, step 5733/107898 completed (loss: 0.49775201082229614, acc: 0.8181818127632141)
[2025-02-17 16:59:09,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:09,600][root][INFO] - Training Epoch: 1/2, step 5734/107898 completed (loss: 1.2988293170928955, acc: 0.5)
[2025-02-17 16:59:09,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:09,952][root][INFO] - Training Epoch: 1/2, step 5735/107898 completed (loss: 0.0286864023655653, acc: 1.0)
[2025-02-17 16:59:10,055][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:10,283][root][INFO] - Training Epoch: 1/2, step 5736/107898 completed (loss: 2.1909372806549072, acc: 0.0)
[2025-02-17 16:59:10,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:10,630][root][INFO] - Training Epoch: 1/2, step 5737/107898 completed (loss: 0.14523418247699738, acc: 0.9285714030265808)
[2025-02-17 16:59:10,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:10,927][root][INFO] - Training Epoch: 1/2, step 5738/107898 completed (loss: 0.027739541605114937, acc: 1.0)
[2025-02-17 16:59:11,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:11,258][root][INFO] - Training Epoch: 1/2, step 5739/107898 completed (loss: 1.554203987121582, acc: 0.75)
[2025-02-17 16:59:11,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:11,569][root][INFO] - Training Epoch: 1/2, step 5740/107898 completed (loss: 0.7923145890235901, acc: 0.0)
[2025-02-17 16:59:11,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:11,908][root][INFO] - Training Epoch: 1/2, step 5741/107898 completed (loss: 0.04308410733938217, acc: 1.0)
[2025-02-17 16:59:12,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:12,250][root][INFO] - Training Epoch: 1/2, step 5742/107898 completed (loss: 0.3680790960788727, acc: 0.8666666746139526)
[2025-02-17 16:59:12,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:12,561][root][INFO] - Training Epoch: 1/2, step 5743/107898 completed (loss: 1.2181951999664307, acc: 0.8181818127632141)
[2025-02-17 16:59:12,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:12,897][root][INFO] - Training Epoch: 1/2, step 5744/107898 completed (loss: 0.8794605135917664, acc: 0.6666666865348816)
[2025-02-17 16:59:13,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:13,240][root][INFO] - Training Epoch: 1/2, step 5745/107898 completed (loss: 0.14424221217632294, acc: 0.9285714030265808)
[2025-02-17 16:59:13,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:13,561][root][INFO] - Training Epoch: 1/2, step 5746/107898 completed (loss: 1.2532097101211548, acc: 0.7058823704719543)
[2025-02-17 16:59:13,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:13,858][root][INFO] - Training Epoch: 1/2, step 5747/107898 completed (loss: 0.1308714747428894, acc: 1.0)
[2025-02-17 16:59:13,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:14,188][root][INFO] - Training Epoch: 1/2, step 5748/107898 completed (loss: 1.4409334659576416, acc: 0.75)
[2025-02-17 16:59:14,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:14,457][root][INFO] - Training Epoch: 1/2, step 5749/107898 completed (loss: 0.003375429892912507, acc: 1.0)
[2025-02-17 16:59:14,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:14,754][root][INFO] - Training Epoch: 1/2, step 5750/107898 completed (loss: 0.6123253703117371, acc: 0.8333333134651184)
[2025-02-17 16:59:14,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:15,083][root][INFO] - Training Epoch: 1/2, step 5751/107898 completed (loss: 0.735284149646759, acc: 0.7857142686843872)
[2025-02-17 16:59:15,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:15,441][root][INFO] - Training Epoch: 1/2, step 5752/107898 completed (loss: 4.124969959259033, acc: 0.07692307978868484)
[2025-02-17 16:59:15,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:15,763][root][INFO] - Training Epoch: 1/2, step 5753/107898 completed (loss: 1.50751793384552, acc: 0.7857142686843872)
[2025-02-17 16:59:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:16,069][root][INFO] - Training Epoch: 1/2, step 5754/107898 completed (loss: 0.05658586323261261, acc: 1.0)
[2025-02-17 16:59:16,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:16,368][root][INFO] - Training Epoch: 1/2, step 5755/107898 completed (loss: 1.7945404052734375, acc: 0.6666666865348816)
[2025-02-17 16:59:16,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:16,632][root][INFO] - Training Epoch: 1/2, step 5756/107898 completed (loss: 0.4328741133213043, acc: 0.875)
[2025-02-17 16:59:16,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:16,928][root][INFO] - Training Epoch: 1/2, step 5757/107898 completed (loss: 1.1642930507659912, acc: 0.8125)
[2025-02-17 16:59:17,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:17,230][root][INFO] - Training Epoch: 1/2, step 5758/107898 completed (loss: 0.6018810272216797, acc: 0.5)
[2025-02-17 16:59:17,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:17,531][root][INFO] - Training Epoch: 1/2, step 5759/107898 completed (loss: 3.560210943222046, acc: 0.25806450843811035)
[2025-02-17 16:59:17,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:17,819][root][INFO] - Training Epoch: 1/2, step 5760/107898 completed (loss: 0.9246668815612793, acc: 0.6666666865348816)
[2025-02-17 16:59:17,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:18,129][root][INFO] - Training Epoch: 1/2, step 5761/107898 completed (loss: 0.0014774783048778772, acc: 1.0)
[2025-02-17 16:59:18,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:18,443][root][INFO] - Training Epoch: 1/2, step 5762/107898 completed (loss: 0.8570094108581543, acc: 0.6666666865348816)
[2025-02-17 16:59:18,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:18,763][root][INFO] - Training Epoch: 1/2, step 5763/107898 completed (loss: 1.2139941453933716, acc: 0.5)
[2025-02-17 16:59:18,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:19,066][root][INFO] - Training Epoch: 1/2, step 5764/107898 completed (loss: 0.016557345166802406, acc: 1.0)
[2025-02-17 16:59:19,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:19,388][root][INFO] - Training Epoch: 1/2, step 5765/107898 completed (loss: 0.010240153409540653, acc: 1.0)
[2025-02-17 16:59:19,478][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:19,702][root][INFO] - Training Epoch: 1/2, step 5766/107898 completed (loss: 0.0067286016419529915, acc: 1.0)
[2025-02-17 16:59:19,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:20,040][root][INFO] - Training Epoch: 1/2, step 5767/107898 completed (loss: 0.5118309855461121, acc: 0.6666666865348816)
[2025-02-17 16:59:20,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:20,378][root][INFO] - Training Epoch: 1/2, step 5768/107898 completed (loss: 0.19699102640151978, acc: 1.0)
[2025-02-17 16:59:20,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:20,732][root][INFO] - Training Epoch: 1/2, step 5769/107898 completed (loss: 1.8159123659133911, acc: 0.7272727489471436)
[2025-02-17 16:59:20,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:21,075][root][INFO] - Training Epoch: 1/2, step 5770/107898 completed (loss: 0.024675028398633003, acc: 1.0)
[2025-02-17 16:59:21,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:21,405][root][INFO] - Training Epoch: 1/2, step 5771/107898 completed (loss: 0.21943287551403046, acc: 0.9130434989929199)
[2025-02-17 16:59:21,517][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:21,750][root][INFO] - Training Epoch: 1/2, step 5772/107898 completed (loss: 0.02308192104101181, acc: 1.0)
[2025-02-17 16:59:21,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:22,079][root][INFO] - Training Epoch: 1/2, step 5773/107898 completed (loss: 5.379917621612549, acc: 0.2857142984867096)
[2025-02-17 16:59:22,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:22,382][root][INFO] - Training Epoch: 1/2, step 5774/107898 completed (loss: 0.9659162163734436, acc: 0.8888888955116272)
[2025-02-17 16:59:22,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:22,707][root][INFO] - Training Epoch: 1/2, step 5775/107898 completed (loss: 0.8394564390182495, acc: 0.7368420958518982)
[2025-02-17 16:59:22,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:23,010][root][INFO] - Training Epoch: 1/2, step 5776/107898 completed (loss: 0.0705685168504715, acc: 1.0)
[2025-02-17 16:59:23,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:23,355][root][INFO] - Training Epoch: 1/2, step 5777/107898 completed (loss: 5.9124884605407715, acc: 0.1666666716337204)
[2025-02-17 16:59:23,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:23,674][root][INFO] - Training Epoch: 1/2, step 5778/107898 completed (loss: 0.01108394656330347, acc: 1.0)
[2025-02-17 16:59:23,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:23,998][root][INFO] - Training Epoch: 1/2, step 5779/107898 completed (loss: 0.057448651641607285, acc: 1.0)
[2025-02-17 16:59:24,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:24,349][root][INFO] - Training Epoch: 1/2, step 5780/107898 completed (loss: 1.0201647281646729, acc: 0.7857142686843872)
[2025-02-17 16:59:24,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:24,631][root][INFO] - Training Epoch: 1/2, step 5781/107898 completed (loss: 0.0441286563873291, acc: 1.0)
[2025-02-17 16:59:24,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:24,939][root][INFO] - Training Epoch: 1/2, step 5782/107898 completed (loss: 0.6710360646247864, acc: 0.75)
[2025-02-17 16:59:25,046][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:25,272][root][INFO] - Training Epoch: 1/2, step 5783/107898 completed (loss: 0.3613458573818207, acc: 0.9090909361839294)
[2025-02-17 16:59:25,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:25,566][root][INFO] - Training Epoch: 1/2, step 5784/107898 completed (loss: 0.06684920191764832, acc: 1.0)
[2025-02-17 16:59:25,678][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:25,910][root][INFO] - Training Epoch: 1/2, step 5785/107898 completed (loss: 0.2861308455467224, acc: 0.9090909361839294)
[2025-02-17 16:59:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:26,248][root][INFO] - Training Epoch: 1/2, step 5786/107898 completed (loss: 0.0077909547835588455, acc: 1.0)
[2025-02-17 16:59:26,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:26,612][root][INFO] - Training Epoch: 1/2, step 5787/107898 completed (loss: 0.593396782875061, acc: 0.800000011920929)
[2025-02-17 16:59:26,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:26,940][root][INFO] - Training Epoch: 1/2, step 5788/107898 completed (loss: 2.7687501907348633, acc: 0.5)
[2025-02-17 16:59:27,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:27,275][root][INFO] - Training Epoch: 1/2, step 5789/107898 completed (loss: 0.09822796285152435, acc: 1.0)
[2025-02-17 16:59:27,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:27,617][root][INFO] - Training Epoch: 1/2, step 5790/107898 completed (loss: 0.32313069701194763, acc: 0.8571428656578064)
[2025-02-17 16:59:27,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:27,937][root][INFO] - Training Epoch: 1/2, step 5791/107898 completed (loss: 0.38176748156547546, acc: 0.8333333134651184)
[2025-02-17 16:59:28,043][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:28,279][root][INFO] - Training Epoch: 1/2, step 5792/107898 completed (loss: 2.0992705821990967, acc: 0.0)
[2025-02-17 16:59:28,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:28,601][root][INFO] - Training Epoch: 1/2, step 5793/107898 completed (loss: 2.0571014881134033, acc: 0.7142857313156128)
[2025-02-17 16:59:28,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:28,893][root][INFO] - Training Epoch: 1/2, step 5794/107898 completed (loss: 0.004491835366934538, acc: 1.0)
[2025-02-17 16:59:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:29,197][root][INFO] - Training Epoch: 1/2, step 5795/107898 completed (loss: 0.14283813536167145, acc: 1.0)
[2025-02-17 16:59:29,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:29,515][root][INFO] - Training Epoch: 1/2, step 5796/107898 completed (loss: 1.725702166557312, acc: 0.6896551847457886)
[2025-02-17 16:59:29,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:29,857][root][INFO] - Training Epoch: 1/2, step 5797/107898 completed (loss: 0.3255369961261749, acc: 0.9090909361839294)
[2025-02-17 16:59:29,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:30,206][root][INFO] - Training Epoch: 1/2, step 5798/107898 completed (loss: 1.6817256212234497, acc: 0.7083333134651184)
[2025-02-17 16:59:30,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:30,538][root][INFO] - Training Epoch: 1/2, step 5799/107898 completed (loss: 4.932401180267334, acc: 0.1538461595773697)
[2025-02-17 16:59:30,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:30,877][root][INFO] - Training Epoch: 1/2, step 5800/107898 completed (loss: 1.561497688293457, acc: 0.75)
[2025-02-17 16:59:30,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:31,181][root][INFO] - Training Epoch: 1/2, step 5801/107898 completed (loss: 4.667094707489014, acc: 0.2857142984867096)
[2025-02-17 16:59:31,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:31,486][root][INFO] - Training Epoch: 1/2, step 5802/107898 completed (loss: 0.01151278242468834, acc: 1.0)
[2025-02-17 16:59:31,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:31,861][root][INFO] - Training Epoch: 1/2, step 5803/107898 completed (loss: 0.8767417073249817, acc: 1.0)
[2025-02-17 16:59:31,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:32,193][root][INFO] - Training Epoch: 1/2, step 5804/107898 completed (loss: 0.26753950119018555, acc: 0.9090909361839294)
[2025-02-17 16:59:32,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:32,526][root][INFO] - Training Epoch: 1/2, step 5805/107898 completed (loss: 0.03335116058588028, acc: 1.0)
[2025-02-17 16:59:32,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:32,838][root][INFO] - Training Epoch: 1/2, step 5806/107898 completed (loss: 0.31570419669151306, acc: 0.6666666865348816)
[2025-02-17 16:59:32,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:33,138][root][INFO] - Training Epoch: 1/2, step 5807/107898 completed (loss: 0.2853613495826721, acc: 0.9090909361839294)
[2025-02-17 16:59:33,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:33,443][root][INFO] - Training Epoch: 1/2, step 5808/107898 completed (loss: 1.036206603050232, acc: 0.6666666865348816)
[2025-02-17 16:59:33,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:33,814][root][INFO] - Training Epoch: 1/2, step 5809/107898 completed (loss: 0.31285396218299866, acc: 0.9047619104385376)
[2025-02-17 16:59:33,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:34,147][root][INFO] - Training Epoch: 1/2, step 5810/107898 completed (loss: 0.22464439272880554, acc: 0.90625)
[2025-02-17 16:59:34,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:34,430][root][INFO] - Training Epoch: 1/2, step 5811/107898 completed (loss: 0.012279823422431946, acc: 1.0)
[2025-02-17 16:59:34,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:34,753][root][INFO] - Training Epoch: 1/2, step 5812/107898 completed (loss: 0.402495414018631, acc: 0.8823529481887817)
[2025-02-17 16:59:34,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:35,114][root][INFO] - Training Epoch: 1/2, step 5813/107898 completed (loss: 0.03502523899078369, acc: 1.0)
[2025-02-17 16:59:35,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:35,456][root][INFO] - Training Epoch: 1/2, step 5814/107898 completed (loss: 0.008295970037579536, acc: 1.0)
[2025-02-17 16:59:35,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:35,797][root][INFO] - Training Epoch: 1/2, step 5815/107898 completed (loss: 0.2041027694940567, acc: 1.0)
[2025-02-17 16:59:35,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:36,140][root][INFO] - Training Epoch: 1/2, step 5816/107898 completed (loss: 0.4681490361690521, acc: 0.9047619104385376)
[2025-02-17 16:59:36,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:36,455][root][INFO] - Training Epoch: 1/2, step 5817/107898 completed (loss: 0.28375476598739624, acc: 0.9333333373069763)
[2025-02-17 16:59:36,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:36,786][root][INFO] - Training Epoch: 1/2, step 5818/107898 completed (loss: 1.7613028287887573, acc: 0.5)
[2025-02-17 16:59:36,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:37,105][root][INFO] - Training Epoch: 1/2, step 5819/107898 completed (loss: 0.049689192324876785, acc: 1.0)
[2025-02-17 16:59:37,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:37,448][root][INFO] - Training Epoch: 1/2, step 5820/107898 completed (loss: 3.6794769763946533, acc: 0.25)
[2025-02-17 16:59:37,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:37,772][root][INFO] - Training Epoch: 1/2, step 5821/107898 completed (loss: 0.21048277616500854, acc: 1.0)
[2025-02-17 16:59:37,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:38,077][root][INFO] - Training Epoch: 1/2, step 5822/107898 completed (loss: 0.4108280539512634, acc: 0.8571428656578064)
[2025-02-17 16:59:38,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:38,376][root][INFO] - Training Epoch: 1/2, step 5823/107898 completed (loss: 0.13699419796466827, acc: 1.0)
[2025-02-17 16:59:38,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:38,648][root][INFO] - Training Epoch: 1/2, step 5824/107898 completed (loss: 0.1633066087961197, acc: 1.0)
[2025-02-17 16:59:38,723][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:38,939][root][INFO] - Training Epoch: 1/2, step 5825/107898 completed (loss: 0.1784663051366806, acc: 1.0)
[2025-02-17 16:59:39,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:39,243][root][INFO] - Training Epoch: 1/2, step 5826/107898 completed (loss: 0.10772005468606949, acc: 1.0)
[2025-02-17 16:59:39,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:39,544][root][INFO] - Training Epoch: 1/2, step 5827/107898 completed (loss: 0.44444596767425537, acc: 0.6666666865348816)
[2025-02-17 16:59:39,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:39,848][root][INFO] - Training Epoch: 1/2, step 5828/107898 completed (loss: 0.0015637713950127363, acc: 1.0)
[2025-02-17 16:59:39,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:40,173][root][INFO] - Training Epoch: 1/2, step 5829/107898 completed (loss: 5.40836763381958, acc: 0.5)
[2025-02-17 16:59:40,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:40,484][root][INFO] - Training Epoch: 1/2, step 5830/107898 completed (loss: 0.003055952489376068, acc: 1.0)
[2025-02-17 16:59:40,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:40,784][root][INFO] - Training Epoch: 1/2, step 5831/107898 completed (loss: 0.08053838461637497, acc: 1.0)
[2025-02-17 16:59:40,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:41,127][root][INFO] - Training Epoch: 1/2, step 5832/107898 completed (loss: 0.177316814661026, acc: 1.0)
[2025-02-17 16:59:41,229][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:41,465][root][INFO] - Training Epoch: 1/2, step 5833/107898 completed (loss: 0.0015769327292218804, acc: 1.0)
[2025-02-17 16:59:41,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:41,788][root][INFO] - Training Epoch: 1/2, step 5834/107898 completed (loss: 0.6530085206031799, acc: 0.6666666865348816)
[2025-02-17 16:59:41,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:42,103][root][INFO] - Training Epoch: 1/2, step 5835/107898 completed (loss: 0.17071017622947693, acc: 0.875)
[2025-02-17 16:59:42,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:42,419][root][INFO] - Training Epoch: 1/2, step 5836/107898 completed (loss: 0.21091558039188385, acc: 0.95652174949646)
[2025-02-17 16:59:42,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:42,732][root][INFO] - Training Epoch: 1/2, step 5837/107898 completed (loss: 0.06952398270368576, acc: 1.0)
[2025-02-17 16:59:42,832][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:43,068][root][INFO] - Training Epoch: 1/2, step 5838/107898 completed (loss: 1.1918662786483765, acc: 0.75)
[2025-02-17 16:59:43,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:43,347][root][INFO] - Training Epoch: 1/2, step 5839/107898 completed (loss: 0.10499611496925354, acc: 1.0)
[2025-02-17 16:59:43,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:43,699][root][INFO] - Training Epoch: 1/2, step 5840/107898 completed (loss: 0.006082754582166672, acc: 1.0)
[2025-02-17 16:59:43,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:44,056][root][INFO] - Training Epoch: 1/2, step 5841/107898 completed (loss: 1.667330265045166, acc: 0.625)
[2025-02-17 16:59:44,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:44,392][root][INFO] - Training Epoch: 1/2, step 5842/107898 completed (loss: 0.11131519079208374, acc: 1.0)
[2025-02-17 16:59:44,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:44,700][root][INFO] - Training Epoch: 1/2, step 5843/107898 completed (loss: 3.7825405597686768, acc: 0.5)
[2025-02-17 16:59:44,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:45,033][root][INFO] - Training Epoch: 1/2, step 5844/107898 completed (loss: 0.9806680679321289, acc: 0.8333333134651184)
[2025-02-17 16:59:45,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:45,336][root][INFO] - Training Epoch: 1/2, step 5845/107898 completed (loss: 1.1373119354248047, acc: 0.5)
[2025-02-17 16:59:45,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:45,722][root][INFO] - Training Epoch: 1/2, step 5846/107898 completed (loss: 1.580386757850647, acc: 0.6666666865348816)
[2025-02-17 16:59:45,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:46,053][root][INFO] - Training Epoch: 1/2, step 5847/107898 completed (loss: 2.4127020835876465, acc: 0.75)
[2025-02-17 16:59:46,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:46,389][root][INFO] - Training Epoch: 1/2, step 5848/107898 completed (loss: 0.1751498132944107, acc: 0.8888888955116272)
[2025-02-17 16:59:46,478][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:46,702][root][INFO] - Training Epoch: 1/2, step 5849/107898 completed (loss: 0.49526447057724, acc: 1.0)
[2025-02-17 16:59:46,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:47,023][root][INFO] - Training Epoch: 1/2, step 5850/107898 completed (loss: 1.5289795398712158, acc: 0.75)
[2025-02-17 16:59:47,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:47,331][root][INFO] - Training Epoch: 1/2, step 5851/107898 completed (loss: 0.02648780308663845, acc: 1.0)
[2025-02-17 16:59:47,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:47,672][root][INFO] - Training Epoch: 1/2, step 5852/107898 completed (loss: 0.14751431345939636, acc: 0.9090909361839294)
[2025-02-17 16:59:47,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:47,990][root][INFO] - Training Epoch: 1/2, step 5853/107898 completed (loss: 0.11265601962804794, acc: 1.0)
[2025-02-17 16:59:48,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:48,312][root][INFO] - Training Epoch: 1/2, step 5854/107898 completed (loss: 0.13606490194797516, acc: 1.0)
[2025-02-17 16:59:48,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:48,630][root][INFO] - Training Epoch: 1/2, step 5855/107898 completed (loss: 1.2298777103424072, acc: 0.6499999761581421)
[2025-02-17 16:59:48,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:48,908][root][INFO] - Training Epoch: 1/2, step 5856/107898 completed (loss: 1.0994828939437866, acc: 0.7083333134651184)
[2025-02-17 16:59:48,996][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:49,218][root][INFO] - Training Epoch: 1/2, step 5857/107898 completed (loss: 0.27849501371383667, acc: 0.9090909361839294)
[2025-02-17 16:59:49,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:49,486][root][INFO] - Training Epoch: 1/2, step 5858/107898 completed (loss: 0.12730321288108826, acc: 1.0)
[2025-02-17 16:59:49,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:49,839][root][INFO] - Training Epoch: 1/2, step 5859/107898 completed (loss: 0.4845944941043854, acc: 0.9333333373069763)
[2025-02-17 16:59:49,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:50,162][root][INFO] - Training Epoch: 1/2, step 5860/107898 completed (loss: 1.3724300861358643, acc: 0.5)
[2025-02-17 16:59:50,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:50,485][root][INFO] - Training Epoch: 1/2, step 5861/107898 completed (loss: 3.388989210128784, acc: 0.6666666865348816)
[2025-02-17 16:59:50,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:50,777][root][INFO] - Training Epoch: 1/2, step 5862/107898 completed (loss: 4.9057793617248535, acc: 0.5)
[2025-02-17 16:59:50,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:51,133][root][INFO] - Training Epoch: 1/2, step 5863/107898 completed (loss: 0.2781635820865631, acc: 0.800000011920929)
[2025-02-17 16:59:51,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:51,458][root][INFO] - Training Epoch: 1/2, step 5864/107898 completed (loss: 0.14321383833885193, acc: 1.0)
[2025-02-17 16:59:51,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:51,771][root][INFO] - Training Epoch: 1/2, step 5865/107898 completed (loss: 0.08336141705513, acc: 1.0)
[2025-02-17 16:59:51,846][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:52,081][root][INFO] - Training Epoch: 1/2, step 5866/107898 completed (loss: 0.14365412294864655, acc: 1.0)
[2025-02-17 16:59:52,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:52,415][root][INFO] - Training Epoch: 1/2, step 5867/107898 completed (loss: 5.832886695861816, acc: 0.1428571492433548)
[2025-02-17 16:59:52,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:52,770][root][INFO] - Training Epoch: 1/2, step 5868/107898 completed (loss: 0.814826250076294, acc: 0.8461538553237915)
[2025-02-17 16:59:52,872][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:53,108][root][INFO] - Training Epoch: 1/2, step 5869/107898 completed (loss: 4.432435512542725, acc: 0.2142857164144516)
[2025-02-17 16:59:53,195][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:53,420][root][INFO] - Training Epoch: 1/2, step 5870/107898 completed (loss: 1.264345645904541, acc: 0.6666666865348816)
[2025-02-17 16:59:53,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:53,743][root][INFO] - Training Epoch: 1/2, step 5871/107898 completed (loss: 0.3449063301086426, acc: 1.0)
[2025-02-17 16:59:53,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:54,073][root][INFO] - Training Epoch: 1/2, step 5872/107898 completed (loss: 0.7586327195167542, acc: 0.6666666865348816)
[2025-02-17 16:59:54,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:54,402][root][INFO] - Training Epoch: 1/2, step 5873/107898 completed (loss: 0.08663517236709595, acc: 1.0)
[2025-02-17 16:59:54,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:54,701][root][INFO] - Training Epoch: 1/2, step 5874/107898 completed (loss: 0.06739255785942078, acc: 1.0)
[2025-02-17 16:59:54,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:55,103][root][INFO] - Training Epoch: 1/2, step 5875/107898 completed (loss: 0.8707567453384399, acc: 0.8260869383811951)
[2025-02-17 16:59:55,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:55,429][root][INFO] - Training Epoch: 1/2, step 5876/107898 completed (loss: 1.2359087467193604, acc: 0.6666666865348816)
[2025-02-17 16:59:55,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:55,720][root][INFO] - Training Epoch: 1/2, step 5877/107898 completed (loss: 0.34679678082466125, acc: 0.9166666865348816)
[2025-02-17 16:59:55,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:56,010][root][INFO] - Training Epoch: 1/2, step 5878/107898 completed (loss: 0.08501579612493515, acc: 1.0)
[2025-02-17 16:59:56,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:56,302][root][INFO] - Training Epoch: 1/2, step 5879/107898 completed (loss: 0.07204392552375793, acc: 1.0)
[2025-02-17 16:59:56,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:56,608][root][INFO] - Training Epoch: 1/2, step 5880/107898 completed (loss: 3.2134315967559814, acc: 0.4545454680919647)
[2025-02-17 16:59:56,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:56,921][root][INFO] - Training Epoch: 1/2, step 5881/107898 completed (loss: 0.20382370054721832, acc: 0.9333333373069763)
[2025-02-17 16:59:57,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:57,236][root][INFO] - Training Epoch: 1/2, step 5882/107898 completed (loss: 1.7330173254013062, acc: 0.5)
[2025-02-17 16:59:57,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:57,538][root][INFO] - Training Epoch: 1/2, step 5883/107898 completed (loss: 0.9535512328147888, acc: 0.800000011920929)
[2025-02-17 16:59:57,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:57,882][root][INFO] - Training Epoch: 1/2, step 5884/107898 completed (loss: 0.9090518951416016, acc: 0.8148148059844971)
[2025-02-17 16:59:57,953][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:58,172][root][INFO] - Training Epoch: 1/2, step 5885/107898 completed (loss: 2.4873602390289307, acc: 0.375)
[2025-02-17 16:59:58,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:58,464][root][INFO] - Training Epoch: 1/2, step 5886/107898 completed (loss: 0.012333863414824009, acc: 1.0)
[2025-02-17 16:59:58,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:58,792][root][INFO] - Training Epoch: 1/2, step 5887/107898 completed (loss: 0.0248680729418993, acc: 1.0)
[2025-02-17 16:59:58,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:59,110][root][INFO] - Training Epoch: 1/2, step 5888/107898 completed (loss: 0.7244104146957397, acc: 0.5)
[2025-02-17 16:59:59,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:59,425][root][INFO] - Training Epoch: 1/2, step 5889/107898 completed (loss: 0.5044407844543457, acc: 0.8888888955116272)
[2025-02-17 16:59:59,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 16:59:59,783][root][INFO] - Training Epoch: 1/2, step 5890/107898 completed (loss: 1.0909734964370728, acc: 0.8333333134651184)
[2025-02-17 16:59:59,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:00,129][root][INFO] - Training Epoch: 1/2, step 5891/107898 completed (loss: 2.6297402381896973, acc: 0.6666666865348816)
[2025-02-17 17:00:00,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:00,477][root][INFO] - Training Epoch: 1/2, step 5892/107898 completed (loss: 1.153404951095581, acc: 0.7222222089767456)
[2025-02-17 17:00:00,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:00,754][root][INFO] - Training Epoch: 1/2, step 5893/107898 completed (loss: 1.3146001100540161, acc: 0.7777777910232544)
[2025-02-17 17:00:00,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:01,051][root][INFO] - Training Epoch: 1/2, step 5894/107898 completed (loss: 0.6871752142906189, acc: 0.8461538553237915)
[2025-02-17 17:00:01,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:01,350][root][INFO] - Training Epoch: 1/2, step 5895/107898 completed (loss: 0.33667412400245667, acc: 0.6666666865348816)
[2025-02-17 17:00:01,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:01,667][root][INFO] - Training Epoch: 1/2, step 5896/107898 completed (loss: 0.034863945096731186, acc: 1.0)
[2025-02-17 17:00:01,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:01,988][root][INFO] - Training Epoch: 1/2, step 5897/107898 completed (loss: 0.1024622917175293, acc: 1.0)
[2025-02-17 17:00:02,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:02,330][root][INFO] - Training Epoch: 1/2, step 5898/107898 completed (loss: 2.709418296813965, acc: 0.25)
[2025-02-17 17:00:02,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:02,664][root][INFO] - Training Epoch: 1/2, step 5899/107898 completed (loss: 0.9037944078445435, acc: 0.5)
[2025-02-17 17:00:02,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:03,015][root][INFO] - Training Epoch: 1/2, step 5900/107898 completed (loss: 4.697316646575928, acc: 0.3333333432674408)
[2025-02-17 17:00:03,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:03,337][root][INFO] - Training Epoch: 1/2, step 5901/107898 completed (loss: 0.426554411649704, acc: 1.0)
[2025-02-17 17:00:03,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:03,639][root][INFO] - Training Epoch: 1/2, step 5902/107898 completed (loss: 3.5724756717681885, acc: 0.375)
[2025-02-17 17:00:03,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:03,955][root][INFO] - Training Epoch: 1/2, step 5903/107898 completed (loss: 0.10393761098384857, acc: 0.949999988079071)
[2025-02-17 17:00:04,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:04,262][root][INFO] - Training Epoch: 1/2, step 5904/107898 completed (loss: 0.7310498356819153, acc: 1.0)
[2025-02-17 17:00:04,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:04,567][root][INFO] - Training Epoch: 1/2, step 5905/107898 completed (loss: 1.9654580354690552, acc: 0.6666666865348816)
[2025-02-17 17:00:04,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:04,894][root][INFO] - Training Epoch: 1/2, step 5906/107898 completed (loss: 1.0674837827682495, acc: 0.8333333134651184)
[2025-02-17 17:00:04,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:05,199][root][INFO] - Training Epoch: 1/2, step 5907/107898 completed (loss: 1.1848814487457275, acc: 0.75)
[2025-02-17 17:00:05,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:05,510][root][INFO] - Training Epoch: 1/2, step 5908/107898 completed (loss: 0.8247795104980469, acc: 0.8333333134651184)
[2025-02-17 17:00:05,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:05,806][root][INFO] - Training Epoch: 1/2, step 5909/107898 completed (loss: 0.19204466044902802, acc: 0.875)
[2025-02-17 17:00:05,887][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:06,097][root][INFO] - Training Epoch: 1/2, step 5910/107898 completed (loss: 2.029892683029175, acc: 0.5)
[2025-02-17 17:00:06,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:06,395][root][INFO] - Training Epoch: 1/2, step 5911/107898 completed (loss: 1.1385140419006348, acc: 0.7692307829856873)
[2025-02-17 17:00:06,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:06,739][root][INFO] - Training Epoch: 1/2, step 5912/107898 completed (loss: 5.587143898010254, acc: 0.15789473056793213)
[2025-02-17 17:00:06,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:07,062][root][INFO] - Training Epoch: 1/2, step 5913/107898 completed (loss: 2.0344009399414062, acc: 0.0)
[2025-02-17 17:00:07,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:07,349][root][INFO] - Training Epoch: 1/2, step 5914/107898 completed (loss: 0.9515537023544312, acc: 0.5)
[2025-02-17 17:00:07,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:07,649][root][INFO] - Training Epoch: 1/2, step 5915/107898 completed (loss: 2.5885660648345947, acc: 0.5555555820465088)
[2025-02-17 17:00:07,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:07,961][root][INFO] - Training Epoch: 1/2, step 5916/107898 completed (loss: 0.13784602284431458, acc: 1.0)
[2025-02-17 17:00:08,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:08,235][root][INFO] - Training Epoch: 1/2, step 5917/107898 completed (loss: 1.8718479871749878, acc: 0.6666666865348816)
[2025-02-17 17:00:08,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:08,583][root][INFO] - Training Epoch: 1/2, step 5918/107898 completed (loss: 1.259713888168335, acc: 0.5)
[2025-02-17 17:00:08,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:08,915][root][INFO] - Training Epoch: 1/2, step 5919/107898 completed (loss: 0.05765269696712494, acc: 1.0)
[2025-02-17 17:00:09,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:09,240][root][INFO] - Training Epoch: 1/2, step 5920/107898 completed (loss: 0.6298147439956665, acc: 1.0)
[2025-02-17 17:00:09,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:09,546][root][INFO] - Training Epoch: 1/2, step 5921/107898 completed (loss: 0.23655910789966583, acc: 1.0)
[2025-02-17 17:00:09,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:09,881][root][INFO] - Training Epoch: 1/2, step 5922/107898 completed (loss: 2.376239538192749, acc: 0.6875)
[2025-02-17 17:00:09,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:10,161][root][INFO] - Training Epoch: 1/2, step 5923/107898 completed (loss: 0.35263487696647644, acc: 1.0)
[2025-02-17 17:00:10,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:10,486][root][INFO] - Training Epoch: 1/2, step 5924/107898 completed (loss: 1.406078815460205, acc: 0.5)
[2025-02-17 17:00:10,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:10,828][root][INFO] - Training Epoch: 1/2, step 5925/107898 completed (loss: 0.002058962592855096, acc: 1.0)
[2025-02-17 17:00:10,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:11,107][root][INFO] - Training Epoch: 1/2, step 5926/107898 completed (loss: 0.2647136151790619, acc: 1.0)
[2025-02-17 17:00:11,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:11,413][root][INFO] - Training Epoch: 1/2, step 5927/107898 completed (loss: 1.2948659658432007, acc: 0.7916666865348816)
[2025-02-17 17:00:11,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:11,702][root][INFO] - Training Epoch: 1/2, step 5928/107898 completed (loss: 3.4045302867889404, acc: 0.6666666865348816)
[2025-02-17 17:00:11,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:12,048][root][INFO] - Training Epoch: 1/2, step 5929/107898 completed (loss: 2.5152533054351807, acc: 0.3333333432674408)
[2025-02-17 17:00:12,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:12,382][root][INFO] - Training Epoch: 1/2, step 5930/107898 completed (loss: 0.8053840398788452, acc: 0.8260869383811951)
[2025-02-17 17:00:12,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:12,686][root][INFO] - Training Epoch: 1/2, step 5931/107898 completed (loss: 1.594749927520752, acc: 0.7272727489471436)
[2025-02-17 17:00:12,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:13,040][root][INFO] - Training Epoch: 1/2, step 5932/107898 completed (loss: 0.43610474467277527, acc: 0.9090909361839294)
[2025-02-17 17:00:13,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:13,348][root][INFO] - Training Epoch: 1/2, step 5933/107898 completed (loss: 2.869419813156128, acc: 0.6666666865348816)
[2025-02-17 17:00:13,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:13,641][root][INFO] - Training Epoch: 1/2, step 5934/107898 completed (loss: 4.906924724578857, acc: 0.1818181872367859)
[2025-02-17 17:00:13,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:13,961][root][INFO] - Training Epoch: 1/2, step 5935/107898 completed (loss: 1.2662972211837769, acc: 0.800000011920929)
[2025-02-17 17:00:14,064][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:14,305][root][INFO] - Training Epoch: 1/2, step 5936/107898 completed (loss: 0.8950960040092468, acc: 0.6666666865348816)
[2025-02-17 17:00:14,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:14,656][root][INFO] - Training Epoch: 1/2, step 5937/107898 completed (loss: 1.028773307800293, acc: 0.8260869383811951)
[2025-02-17 17:00:14,751][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:14,986][root][INFO] - Training Epoch: 1/2, step 5938/107898 completed (loss: 2.117645263671875, acc: 0.5)
[2025-02-17 17:00:15,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:15,298][root][INFO] - Training Epoch: 1/2, step 5939/107898 completed (loss: 1.9561798572540283, acc: 0.5)
[2025-02-17 17:00:15,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:15,609][root][INFO] - Training Epoch: 1/2, step 5940/107898 completed (loss: 0.6473721861839294, acc: 0.9090909361839294)
[2025-02-17 17:00:15,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:15,946][root][INFO] - Training Epoch: 1/2, step 5941/107898 completed (loss: 0.8552826642990112, acc: 0.8518518805503845)
[2025-02-17 17:00:16,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:16,288][root][INFO] - Training Epoch: 1/2, step 5942/107898 completed (loss: 2.192697763442993, acc: 0.5)
[2025-02-17 17:00:16,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:16,603][root][INFO] - Training Epoch: 1/2, step 5943/107898 completed (loss: 2.181441068649292, acc: 0.75)
[2025-02-17 17:00:16,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:16,947][root][INFO] - Training Epoch: 1/2, step 5944/107898 completed (loss: 2.4385738372802734, acc: 0.4000000059604645)
[2025-02-17 17:00:17,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:17,269][root][INFO] - Training Epoch: 1/2, step 5945/107898 completed (loss: 0.20210584998130798, acc: 0.9090909361839294)
[2025-02-17 17:00:17,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:17,566][root][INFO] - Training Epoch: 1/2, step 5946/107898 completed (loss: 0.03409845754504204, acc: 1.0)
[2025-02-17 17:00:17,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:17,831][root][INFO] - Training Epoch: 1/2, step 5947/107898 completed (loss: 0.15115636587142944, acc: 1.0)
[2025-02-17 17:00:17,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:18,127][root][INFO] - Training Epoch: 1/2, step 5948/107898 completed (loss: 0.15854178369045258, acc: 0.9696969985961914)
[2025-02-17 17:00:18,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:18,421][root][INFO] - Training Epoch: 1/2, step 5949/107898 completed (loss: 0.8631969094276428, acc: 0.5)
[2025-02-17 17:00:18,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:18,776][root][INFO] - Training Epoch: 1/2, step 5950/107898 completed (loss: 0.5183685421943665, acc: 0.930232584476471)
[2025-02-17 17:00:18,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:19,101][root][INFO] - Training Epoch: 1/2, step 5951/107898 completed (loss: 1.780893325805664, acc: 0.6666666865348816)
[2025-02-17 17:00:19,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:19,412][root][INFO] - Training Epoch: 1/2, step 5952/107898 completed (loss: 3.331519365310669, acc: 0.3333333432674408)
[2025-02-17 17:00:19,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:19,775][root][INFO] - Training Epoch: 1/2, step 5953/107898 completed (loss: 0.4341733157634735, acc: 0.6666666865348816)
[2025-02-17 17:00:19,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:20,094][root][INFO] - Training Epoch: 1/2, step 5954/107898 completed (loss: 2.466823101043701, acc: 0.6666666865348816)
[2025-02-17 17:00:20,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:20,419][root][INFO] - Training Epoch: 1/2, step 5955/107898 completed (loss: 0.47814881801605225, acc: 0.8571428656578064)
[2025-02-17 17:00:20,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:20,703][root][INFO] - Training Epoch: 1/2, step 5956/107898 completed (loss: 3.6177735328674316, acc: 0.260869562625885)
[2025-02-17 17:00:20,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:21,025][root][INFO] - Training Epoch: 1/2, step 5957/107898 completed (loss: 0.9339211583137512, acc: 0.7692307829856873)
[2025-02-17 17:00:21,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:21,337][root][INFO] - Training Epoch: 1/2, step 5958/107898 completed (loss: 0.6744028925895691, acc: 0.6666666865348816)
[2025-02-17 17:00:21,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:21,692][root][INFO] - Training Epoch: 1/2, step 5959/107898 completed (loss: 0.46780815720558167, acc: 0.6666666865348816)
[2025-02-17 17:00:21,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:22,016][root][INFO] - Training Epoch: 1/2, step 5960/107898 completed (loss: 1.3500851392745972, acc: 0.6000000238418579)
[2025-02-17 17:00:22,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:22,300][root][INFO] - Training Epoch: 1/2, step 5961/107898 completed (loss: 0.042389482259750366, acc: 1.0)
[2025-02-17 17:00:22,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:22,643][root][INFO] - Training Epoch: 1/2, step 5962/107898 completed (loss: 0.4120521545410156, acc: 0.6666666865348816)
[2025-02-17 17:00:22,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:22,975][root][INFO] - Training Epoch: 1/2, step 5963/107898 completed (loss: 0.32684850692749023, acc: 0.9411764740943909)
[2025-02-17 17:00:23,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:23,284][root][INFO] - Training Epoch: 1/2, step 5964/107898 completed (loss: 0.18429048359394073, acc: 1.0)
[2025-02-17 17:00:23,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:23,595][root][INFO] - Training Epoch: 1/2, step 5965/107898 completed (loss: 3.438420057296753, acc: 0.25)
[2025-02-17 17:00:23,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:23,903][root][INFO] - Training Epoch: 1/2, step 5966/107898 completed (loss: 0.9336966872215271, acc: 0.8571428656578064)
[2025-02-17 17:00:23,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:24,183][root][INFO] - Training Epoch: 1/2, step 5967/107898 completed (loss: 0.06661020964384079, acc: 1.0)
[2025-02-17 17:00:24,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:24,519][root][INFO] - Training Epoch: 1/2, step 5968/107898 completed (loss: 3.953505277633667, acc: 0.27659574151039124)
[2025-02-17 17:00:24,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:24,877][root][INFO] - Training Epoch: 1/2, step 5969/107898 completed (loss: 1.262316107749939, acc: 0.6666666865348816)
[2025-02-17 17:00:24,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:25,214][root][INFO] - Training Epoch: 1/2, step 5970/107898 completed (loss: 4.573972225189209, acc: 0.1666666716337204)
[2025-02-17 17:00:25,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:25,535][root][INFO] - Training Epoch: 1/2, step 5971/107898 completed (loss: 0.9919995665550232, acc: 0.6666666865348816)
[2025-02-17 17:00:25,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:25,848][root][INFO] - Training Epoch: 1/2, step 5972/107898 completed (loss: 1.3808456659317017, acc: 0.699999988079071)
[2025-02-17 17:00:25,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:26,218][root][INFO] - Training Epoch: 1/2, step 5973/107898 completed (loss: 1.084643840789795, acc: 0.8108108043670654)
[2025-02-17 17:00:26,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:26,492][root][INFO] - Training Epoch: 1/2, step 5974/107898 completed (loss: 1.0979505777359009, acc: 0.8571428656578064)
[2025-02-17 17:00:26,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:26,761][root][INFO] - Training Epoch: 1/2, step 5975/107898 completed (loss: 0.04461328312754631, acc: 1.0)
[2025-02-17 17:00:26,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:27,066][root][INFO] - Training Epoch: 1/2, step 5976/107898 completed (loss: 0.6416704058647156, acc: 0.8648648858070374)
[2025-02-17 17:00:27,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:27,361][root][INFO] - Training Epoch: 1/2, step 5977/107898 completed (loss: 2.3678619861602783, acc: 0.47058823704719543)
[2025-02-17 17:00:27,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:27,697][root][INFO] - Training Epoch: 1/2, step 5978/107898 completed (loss: 0.7305263876914978, acc: 0.5)
[2025-02-17 17:00:27,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:28,031][root][INFO] - Training Epoch: 1/2, step 5979/107898 completed (loss: 1.7340121269226074, acc: 0.625)
[2025-02-17 17:00:28,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:28,334][root][INFO] - Training Epoch: 1/2, step 5980/107898 completed (loss: 1.7346713542938232, acc: 0.5)
[2025-02-17 17:00:28,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:28,632][root][INFO] - Training Epoch: 1/2, step 5981/107898 completed (loss: 3.225895404815674, acc: 0.25)
[2025-02-17 17:00:28,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:28,925][root][INFO] - Training Epoch: 1/2, step 5982/107898 completed (loss: 0.12463711947202682, acc: 1.0)
[2025-02-17 17:00:29,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:29,251][root][INFO] - Training Epoch: 1/2, step 5983/107898 completed (loss: 2.1595754623413086, acc: 0.0)
[2025-02-17 17:00:29,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:29,558][root][INFO] - Training Epoch: 1/2, step 5984/107898 completed (loss: 0.49395981431007385, acc: 1.0)
[2025-02-17 17:00:29,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:29,866][root][INFO] - Training Epoch: 1/2, step 5985/107898 completed (loss: 0.4250974655151367, acc: 1.0)
[2025-02-17 17:00:29,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:30,188][root][INFO] - Training Epoch: 1/2, step 5986/107898 completed (loss: 0.7639280557632446, acc: 0.5)
[2025-02-17 17:00:30,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:30,490][root][INFO] - Training Epoch: 1/2, step 5987/107898 completed (loss: 1.143864631652832, acc: 0.75)
[2025-02-17 17:00:30,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:30,830][root][INFO] - Training Epoch: 1/2, step 5988/107898 completed (loss: 0.30247393250465393, acc: 1.0)
[2025-02-17 17:00:30,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:31,182][root][INFO] - Training Epoch: 1/2, step 5989/107898 completed (loss: 0.135286346077919, acc: 1.0)
[2025-02-17 17:00:31,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:31,531][root][INFO] - Training Epoch: 1/2, step 5990/107898 completed (loss: 0.6928041577339172, acc: 0.8571428656578064)
[2025-02-17 17:00:31,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:31,833][root][INFO] - Training Epoch: 1/2, step 5991/107898 completed (loss: 0.3619036376476288, acc: 0.8888888955116272)
[2025-02-17 17:00:31,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:32,134][root][INFO] - Training Epoch: 1/2, step 5992/107898 completed (loss: 4.4842729568481445, acc: 0.5)
[2025-02-17 17:00:32,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:32,466][root][INFO] - Training Epoch: 1/2, step 5993/107898 completed (loss: 0.0423651859164238, acc: 1.0)
[2025-02-17 17:00:32,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:32,805][root][INFO] - Training Epoch: 1/2, step 5994/107898 completed (loss: 0.006012826692312956, acc: 1.0)
[2025-02-17 17:00:32,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:33,131][root][INFO] - Training Epoch: 1/2, step 5995/107898 completed (loss: 1.8601447343826294, acc: 0.5909090638160706)
[2025-02-17 17:00:33,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:33,438][root][INFO] - Training Epoch: 1/2, step 5996/107898 completed (loss: 1.4104442596435547, acc: 0.6666666865348816)
[2025-02-17 17:00:33,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:33,739][root][INFO] - Training Epoch: 1/2, step 5997/107898 completed (loss: 0.43998515605926514, acc: 0.75)
[2025-02-17 17:00:33,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:34,051][root][INFO] - Training Epoch: 1/2, step 5998/107898 completed (loss: 0.2966165244579315, acc: 0.8571428656578064)
[2025-02-17 17:00:34,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:34,339][root][INFO] - Training Epoch: 1/2, step 5999/107898 completed (loss: 0.31801465153694153, acc: 0.6666666865348816)
[2025-02-17 17:00:34,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:34,621][root][INFO] - Training Epoch: 1/2, step 6000/107898 completed (loss: 0.44406402111053467, acc: 1.0)
[2025-02-17 17:00:34,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:34,926][root][INFO] - Training Epoch: 1/2, step 6001/107898 completed (loss: 1.8638936281204224, acc: 0.7647058963775635)
[2025-02-17 17:00:35,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:35,232][root][INFO] - Training Epoch: 1/2, step 6002/107898 completed (loss: 3.4686989784240723, acc: 0.3333333432674408)
[2025-02-17 17:00:35,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:35,576][root][INFO] - Training Epoch: 1/2, step 6003/107898 completed (loss: 0.00201383582316339, acc: 1.0)
[2025-02-17 17:00:35,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:35,910][root][INFO] - Training Epoch: 1/2, step 6004/107898 completed (loss: 1.5469622611999512, acc: 0.5555555820465088)
[2025-02-17 17:00:36,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:36,221][root][INFO] - Training Epoch: 1/2, step 6005/107898 completed (loss: 0.009466399438679218, acc: 1.0)
[2025-02-17 17:00:36,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:36,528][root][INFO] - Training Epoch: 1/2, step 6006/107898 completed (loss: 3.9246058464050293, acc: 0.2666666805744171)
[2025-02-17 17:00:36,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:36,891][root][INFO] - Training Epoch: 1/2, step 6007/107898 completed (loss: 0.17468184232711792, acc: 0.9166666865348816)
[2025-02-17 17:00:36,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:37,209][root][INFO] - Training Epoch: 1/2, step 6008/107898 completed (loss: 0.13969817757606506, acc: 1.0)
[2025-02-17 17:00:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:37,525][root][INFO] - Training Epoch: 1/2, step 6009/107898 completed (loss: 0.004135158844292164, acc: 1.0)
[2025-02-17 17:00:37,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:37,832][root][INFO] - Training Epoch: 1/2, step 6010/107898 completed (loss: 0.08824370801448822, acc: 1.0)
[2025-02-17 17:00:37,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:38,149][root][INFO] - Training Epoch: 1/2, step 6011/107898 completed (loss: 0.40866363048553467, acc: 0.6666666865348816)
[2025-02-17 17:00:38,242][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:38,451][root][INFO] - Training Epoch: 1/2, step 6012/107898 completed (loss: 1.2261379957199097, acc: 0.6666666865348816)
[2025-02-17 17:00:38,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:38,743][root][INFO] - Training Epoch: 1/2, step 6013/107898 completed (loss: 0.5740985870361328, acc: 1.0)
[2025-02-17 17:00:38,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:39,045][root][INFO] - Training Epoch: 1/2, step 6014/107898 completed (loss: 0.8343234658241272, acc: 1.0)
[2025-02-17 17:00:39,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:39,385][root][INFO] - Training Epoch: 1/2, step 6015/107898 completed (loss: 1.7107644081115723, acc: 0.6666666865348816)
[2025-02-17 17:00:39,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:39,829][root][INFO] - Training Epoch: 1/2, step 6016/107898 completed (loss: 0.33183175325393677, acc: 0.9230769276618958)
[2025-02-17 17:00:39,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:40,161][root][INFO] - Training Epoch: 1/2, step 6017/107898 completed (loss: 0.027410797774791718, acc: 1.0)
[2025-02-17 17:00:40,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:40,489][root][INFO] - Training Epoch: 1/2, step 6018/107898 completed (loss: 0.045911964029073715, acc: 1.0)
[2025-02-17 17:00:40,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:40,813][root][INFO] - Training Epoch: 1/2, step 6019/107898 completed (loss: 2.27634334564209, acc: 0.5199999809265137)
[2025-02-17 17:00:40,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:41,103][root][INFO] - Training Epoch: 1/2, step 6020/107898 completed (loss: 0.18779420852661133, acc: 1.0)
[2025-02-17 17:00:41,195][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:41,407][root][INFO] - Training Epoch: 1/2, step 6021/107898 completed (loss: 0.9816879034042358, acc: 0.699999988079071)
[2025-02-17 17:00:41,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:41,700][root][INFO] - Training Epoch: 1/2, step 6022/107898 completed (loss: 0.6920760869979858, acc: 0.5)
[2025-02-17 17:00:41,772][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:41,986][root][INFO] - Training Epoch: 1/2, step 6023/107898 completed (loss: 0.09093920886516571, acc: 1.0)
[2025-02-17 17:00:42,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:42,287][root][INFO] - Training Epoch: 1/2, step 6024/107898 completed (loss: 1.9381015300750732, acc: 0.5)
[2025-02-17 17:00:42,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:42,631][root][INFO] - Training Epoch: 1/2, step 6025/107898 completed (loss: 1.2889366149902344, acc: 0.7142857313156128)
[2025-02-17 17:00:42,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:42,945][root][INFO] - Training Epoch: 1/2, step 6026/107898 completed (loss: 1.1141408681869507, acc: 0.7777777910232544)
[2025-02-17 17:00:43,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:43,265][root][INFO] - Training Epoch: 1/2, step 6027/107898 completed (loss: 1.443102240562439, acc: 0.8421052694320679)
[2025-02-17 17:00:43,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:43,585][root][INFO] - Training Epoch: 1/2, step 6028/107898 completed (loss: 1.608298897743225, acc: 0.6785714030265808)
[2025-02-17 17:00:43,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:43,890][root][INFO] - Training Epoch: 1/2, step 6029/107898 completed (loss: 0.03185821324586868, acc: 1.0)
[2025-02-17 17:00:43,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:44,190][root][INFO] - Training Epoch: 1/2, step 6030/107898 completed (loss: 1.791746735572815, acc: 0.75)
[2025-02-17 17:00:44,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:44,496][root][INFO] - Training Epoch: 1/2, step 6031/107898 completed (loss: 3.051424026489258, acc: 0.6000000238418579)
[2025-02-17 17:00:44,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:44,802][root][INFO] - Training Epoch: 1/2, step 6032/107898 completed (loss: 0.41150909662246704, acc: 0.800000011920929)
[2025-02-17 17:00:44,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:45,103][root][INFO] - Training Epoch: 1/2, step 6033/107898 completed (loss: 2.030918598175049, acc: 0.4000000059604645)
[2025-02-17 17:00:45,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:45,400][root][INFO] - Training Epoch: 1/2, step 6034/107898 completed (loss: 2.088514566421509, acc: 0.75)
[2025-02-17 17:00:45,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:45,708][root][INFO] - Training Epoch: 1/2, step 6035/107898 completed (loss: 6.5745697021484375, acc: 0.3333333432674408)
[2025-02-17 17:00:45,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:46,061][root][INFO] - Training Epoch: 1/2, step 6036/107898 completed (loss: 0.9168860912322998, acc: 0.8125)
[2025-02-17 17:00:46,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:46,382][root][INFO] - Training Epoch: 1/2, step 6037/107898 completed (loss: 3.4371886253356934, acc: 0.30000001192092896)
[2025-02-17 17:00:46,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:46,696][root][INFO] - Training Epoch: 1/2, step 6038/107898 completed (loss: 0.5725567936897278, acc: 1.0)
[2025-02-17 17:00:46,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:46,973][root][INFO] - Training Epoch: 1/2, step 6039/107898 completed (loss: 0.3917110860347748, acc: 1.0)
[2025-02-17 17:00:47,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:47,312][root][INFO] - Training Epoch: 1/2, step 6040/107898 completed (loss: 0.5561203360557556, acc: 1.0)
[2025-02-17 17:00:47,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:47,634][root][INFO] - Training Epoch: 1/2, step 6041/107898 completed (loss: 0.3065584599971771, acc: 1.0)
[2025-02-17 17:00:47,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:47,942][root][INFO] - Training Epoch: 1/2, step 6042/107898 completed (loss: 1.1164216995239258, acc: 0.7200000286102295)
[2025-02-17 17:00:48,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:48,249][root][INFO] - Training Epoch: 1/2, step 6043/107898 completed (loss: 0.5967780947685242, acc: 0.8571428656578064)
[2025-02-17 17:00:48,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:48,592][root][INFO] - Training Epoch: 1/2, step 6044/107898 completed (loss: 0.0191277414560318, acc: 1.0)
[2025-02-17 17:00:48,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:48,910][root][INFO] - Training Epoch: 1/2, step 6045/107898 completed (loss: 0.09687710553407669, acc: 1.0)
[2025-02-17 17:00:49,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:49,209][root][INFO] - Training Epoch: 1/2, step 6046/107898 completed (loss: 1.0345520973205566, acc: 0.75)
[2025-02-17 17:00:49,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:49,512][root][INFO] - Training Epoch: 1/2, step 6047/107898 completed (loss: 2.363250494003296, acc: 0.5)
[2025-02-17 17:00:49,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:49,835][root][INFO] - Training Epoch: 1/2, step 6048/107898 completed (loss: 0.9775993227958679, acc: 0.8571428656578064)
[2025-02-17 17:00:49,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:50,135][root][INFO] - Training Epoch: 1/2, step 6049/107898 completed (loss: 1.0665355920791626, acc: 0.75)
[2025-02-17 17:00:50,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:50,465][root][INFO] - Training Epoch: 1/2, step 6050/107898 completed (loss: 2.1263060569763184, acc: 0.875)
[2025-02-17 17:00:50,534][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:50,748][root][INFO] - Training Epoch: 1/2, step 6051/107898 completed (loss: 0.4384864866733551, acc: 0.6666666865348816)
[2025-02-17 17:00:50,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:51,072][root][INFO] - Training Epoch: 1/2, step 6052/107898 completed (loss: 1.4883228540420532, acc: 0.7419354915618896)
[2025-02-17 17:00:51,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:51,381][root][INFO] - Training Epoch: 1/2, step 6053/107898 completed (loss: 5.770758628845215, acc: 0.5)
[2025-02-17 17:00:51,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:51,691][root][INFO] - Training Epoch: 1/2, step 6054/107898 completed (loss: 0.12475357204675674, acc: 1.0)
[2025-02-17 17:00:51,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:52,039][root][INFO] - Training Epoch: 1/2, step 6055/107898 completed (loss: 0.351408451795578, acc: 0.8999999761581421)
[2025-02-17 17:00:52,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:52,333][root][INFO] - Training Epoch: 1/2, step 6056/107898 completed (loss: 0.4062279164791107, acc: 1.0)
[2025-02-17 17:00:52,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:52,678][root][INFO] - Training Epoch: 1/2, step 6057/107898 completed (loss: 3.024815797805786, acc: 0.6666666865348816)
[2025-02-17 17:00:52,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:53,013][root][INFO] - Training Epoch: 1/2, step 6058/107898 completed (loss: 4.259705543518066, acc: 0.19230769574642181)
[2025-02-17 17:00:53,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:53,321][root][INFO] - Training Epoch: 1/2, step 6059/107898 completed (loss: 0.004959347657859325, acc: 1.0)
[2025-02-17 17:00:53,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:53,627][root][INFO] - Training Epoch: 1/2, step 6060/107898 completed (loss: 1.2398475408554077, acc: 0.6875)
[2025-02-17 17:00:53,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:53,911][root][INFO] - Training Epoch: 1/2, step 6061/107898 completed (loss: 1.2222621440887451, acc: 0.692307710647583)
[2025-02-17 17:00:53,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:54,199][root][INFO] - Training Epoch: 1/2, step 6062/107898 completed (loss: 1.3758833408355713, acc: 0.5)
[2025-02-17 17:00:54,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:54,488][root][INFO] - Training Epoch: 1/2, step 6063/107898 completed (loss: 0.02129017747938633, acc: 1.0)
[2025-02-17 17:00:54,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:54,806][root][INFO] - Training Epoch: 1/2, step 6064/107898 completed (loss: 1.9726401567459106, acc: 0.46666666865348816)
[2025-02-17 17:00:54,901][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:55,125][root][INFO] - Training Epoch: 1/2, step 6065/107898 completed (loss: 0.793190598487854, acc: 0.8823529481887817)
[2025-02-17 17:00:55,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:55,411][root][INFO] - Training Epoch: 1/2, step 6066/107898 completed (loss: 0.8497569561004639, acc: 0.8636363744735718)
[2025-02-17 17:00:55,483][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:55,702][root][INFO] - Training Epoch: 1/2, step 6067/107898 completed (loss: 0.17333440482616425, acc: 1.0)
[2025-02-17 17:00:55,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:55,978][root][INFO] - Training Epoch: 1/2, step 6068/107898 completed (loss: 0.47336167097091675, acc: 0.8571428656578064)
[2025-02-17 17:00:56,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:56,290][root][INFO] - Training Epoch: 1/2, step 6069/107898 completed (loss: 4.497202396392822, acc: 0.22580644488334656)
[2025-02-17 17:00:56,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:56,595][root][INFO] - Training Epoch: 1/2, step 6070/107898 completed (loss: 0.4227285385131836, acc: 0.9166666865348816)
[2025-02-17 17:00:56,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:56,982][root][INFO] - Training Epoch: 1/2, step 6071/107898 completed (loss: 0.025670189410448074, acc: 1.0)
[2025-02-17 17:00:57,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:57,328][root][INFO] - Training Epoch: 1/2, step 6072/107898 completed (loss: 1.1412770748138428, acc: 0.6842105388641357)
[2025-02-17 17:00:57,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:57,614][root][INFO] - Training Epoch: 1/2, step 6073/107898 completed (loss: 2.782736301422119, acc: 0.3636363744735718)
[2025-02-17 17:00:57,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:57,955][root][INFO] - Training Epoch: 1/2, step 6074/107898 completed (loss: 0.07868708670139313, acc: 1.0)
[2025-02-17 17:00:58,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:58,267][root][INFO] - Training Epoch: 1/2, step 6075/107898 completed (loss: 1.3422291278839111, acc: 0.6363636255264282)
[2025-02-17 17:00:58,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:58,559][root][INFO] - Training Epoch: 1/2, step 6076/107898 completed (loss: 0.7375233173370361, acc: 0.6666666865348816)
[2025-02-17 17:00:58,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:58,893][root][INFO] - Training Epoch: 1/2, step 6077/107898 completed (loss: 0.01986231468617916, acc: 1.0)
[2025-02-17 17:00:59,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:59,223][root][INFO] - Training Epoch: 1/2, step 6078/107898 completed (loss: 0.5949754118919373, acc: 0.8571428656578064)
[2025-02-17 17:00:59,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:59,575][root][INFO] - Training Epoch: 1/2, step 6079/107898 completed (loss: 0.013077701441943645, acc: 1.0)
[2025-02-17 17:00:59,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:00:59,883][root][INFO] - Training Epoch: 1/2, step 6080/107898 completed (loss: 3.3632352352142334, acc: 0.3333333432674408)
[2025-02-17 17:00:59,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:00,151][root][INFO] - Training Epoch: 1/2, step 6081/107898 completed (loss: 3.474118947982788, acc: 0.5)
[2025-02-17 17:01:00,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:00,465][root][INFO] - Training Epoch: 1/2, step 6082/107898 completed (loss: 0.08163181692361832, acc: 1.0)
[2025-02-17 17:01:00,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:00,817][root][INFO] - Training Epoch: 1/2, step 6083/107898 completed (loss: 0.6985957026481628, acc: 0.9333333373069763)
[2025-02-17 17:01:00,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:01,157][root][INFO] - Training Epoch: 1/2, step 6084/107898 completed (loss: 6.141458034515381, acc: 0.25)
[2025-02-17 17:01:01,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:01,498][root][INFO] - Training Epoch: 1/2, step 6085/107898 completed (loss: 1.1260625123977661, acc: 0.8421052694320679)
[2025-02-17 17:01:01,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:01,826][root][INFO] - Training Epoch: 1/2, step 6086/107898 completed (loss: 0.026892611756920815, acc: 1.0)
[2025-02-17 17:01:01,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:02,177][root][INFO] - Training Epoch: 1/2, step 6087/107898 completed (loss: 1.2419533729553223, acc: 0.7906976938247681)
[2025-02-17 17:01:02,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:02,526][root][INFO] - Training Epoch: 1/2, step 6088/107898 completed (loss: 0.5351278185844421, acc: 0.800000011920929)
[2025-02-17 17:01:02,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:02,882][root][INFO] - Training Epoch: 1/2, step 6089/107898 completed (loss: 1.150069236755371, acc: 0.8214285969734192)
[2025-02-17 17:01:02,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:03,219][root][INFO] - Training Epoch: 1/2, step 6090/107898 completed (loss: 0.3974814713001251, acc: 0.8333333134651184)
[2025-02-17 17:01:03,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:03,527][root][INFO] - Training Epoch: 1/2, step 6091/107898 completed (loss: 0.15285617113113403, acc: 1.0)
[2025-02-17 17:01:03,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:03,842][root][INFO] - Training Epoch: 1/2, step 6092/107898 completed (loss: 0.40900716185569763, acc: 0.8823529481887817)
[2025-02-17 17:01:03,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:04,151][root][INFO] - Training Epoch: 1/2, step 6093/107898 completed (loss: 0.14050136506557465, acc: 1.0)
[2025-02-17 17:01:04,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:04,487][root][INFO] - Training Epoch: 1/2, step 6094/107898 completed (loss: 0.7389249801635742, acc: 0.7777777910232544)
[2025-02-17 17:01:04,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:04,850][root][INFO] - Training Epoch: 1/2, step 6095/107898 completed (loss: 0.9003962278366089, acc: 0.8888888955116272)
[2025-02-17 17:01:04,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:05,206][root][INFO] - Training Epoch: 1/2, step 6096/107898 completed (loss: 0.5617318153381348, acc: 0.6666666865348816)
[2025-02-17 17:01:05,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:05,530][root][INFO] - Training Epoch: 1/2, step 6097/107898 completed (loss: 0.05439772084355354, acc: 1.0)
[2025-02-17 17:01:05,634][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:05,861][root][INFO] - Training Epoch: 1/2, step 6098/107898 completed (loss: 0.12631455063819885, acc: 1.0)
[2025-02-17 17:01:05,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:06,176][root][INFO] - Training Epoch: 1/2, step 6099/107898 completed (loss: 1.1922402381896973, acc: 0.75)
[2025-02-17 17:01:06,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:06,484][root][INFO] - Training Epoch: 1/2, step 6100/107898 completed (loss: 1.2709182500839233, acc: 0.8999999761581421)
[2025-02-17 17:01:06,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:06,838][root][INFO] - Training Epoch: 1/2, step 6101/107898 completed (loss: 0.9603806138038635, acc: 0.6666666865348816)
[2025-02-17 17:01:06,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:07,168][root][INFO] - Training Epoch: 1/2, step 6102/107898 completed (loss: 1.2124195098876953, acc: 0.625)
[2025-02-17 17:01:07,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:07,484][root][INFO] - Training Epoch: 1/2, step 6103/107898 completed (loss: 0.8218883275985718, acc: 0.75)
[2025-02-17 17:01:07,585][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:07,784][root][INFO] - Training Epoch: 1/2, step 6104/107898 completed (loss: 0.6127362847328186, acc: 0.9230769276618958)
[2025-02-17 17:01:07,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:08,101][root][INFO] - Training Epoch: 1/2, step 6105/107898 completed (loss: 0.25807371735572815, acc: 0.9166666865348816)
[2025-02-17 17:01:08,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:08,423][root][INFO] - Training Epoch: 1/2, step 6106/107898 completed (loss: 1.31584632396698, acc: 0.7777777910232544)
[2025-02-17 17:01:08,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:08,679][root][INFO] - Training Epoch: 1/2, step 6107/107898 completed (loss: 0.7334148287773132, acc: 0.6666666865348816)
[2025-02-17 17:01:08,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:08,958][root][INFO] - Training Epoch: 1/2, step 6108/107898 completed (loss: 0.0800781100988388, acc: 1.0)
[2025-02-17 17:01:09,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:09,267][root][INFO] - Training Epoch: 1/2, step 6109/107898 completed (loss: 2.6206791400909424, acc: 0.375)
[2025-02-17 17:01:09,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:09,569][root][INFO] - Training Epoch: 1/2, step 6110/107898 completed (loss: 3.220707893371582, acc: 0.5)
[2025-02-17 17:01:09,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:09,897][root][INFO] - Training Epoch: 1/2, step 6111/107898 completed (loss: 0.6735702753067017, acc: 0.5)
[2025-02-17 17:01:10,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:10,243][root][INFO] - Training Epoch: 1/2, step 6112/107898 completed (loss: 0.10719073563814163, acc: 1.0)
[2025-02-17 17:01:10,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:10,578][root][INFO] - Training Epoch: 1/2, step 6113/107898 completed (loss: 1.4261456727981567, acc: 0.6190476417541504)
[2025-02-17 17:01:10,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:10,919][root][INFO] - Training Epoch: 1/2, step 6114/107898 completed (loss: 1.0777944326400757, acc: 0.800000011920929)
[2025-02-17 17:01:11,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:11,226][root][INFO] - Training Epoch: 1/2, step 6115/107898 completed (loss: 2.449143886566162, acc: 0.6000000238418579)
[2025-02-17 17:01:11,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:11,534][root][INFO] - Training Epoch: 1/2, step 6116/107898 completed (loss: 1.3151671886444092, acc: 0.9230769276618958)
[2025-02-17 17:01:11,619][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:11,845][root][INFO] - Training Epoch: 1/2, step 6117/107898 completed (loss: 3.620116710662842, acc: 0.20000000298023224)
[2025-02-17 17:01:11,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:12,146][root][INFO] - Training Epoch: 1/2, step 6118/107898 completed (loss: 0.5415001511573792, acc: 0.9375)
[2025-02-17 17:01:12,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:12,451][root][INFO] - Training Epoch: 1/2, step 6119/107898 completed (loss: 0.01662360318005085, acc: 1.0)
[2025-02-17 17:01:12,559][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:12,797][root][INFO] - Training Epoch: 1/2, step 6120/107898 completed (loss: 1.8873449563980103, acc: 0.5)
[2025-02-17 17:01:12,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:13,144][root][INFO] - Training Epoch: 1/2, step 6121/107898 completed (loss: 3.4731194972991943, acc: 0.125)
[2025-02-17 17:01:13,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:13,471][root][INFO] - Training Epoch: 1/2, step 6122/107898 completed (loss: 3.651505947113037, acc: 0.5)
[2025-02-17 17:01:13,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:13,789][root][INFO] - Training Epoch: 1/2, step 6123/107898 completed (loss: 0.022151673212647438, acc: 1.0)
[2025-02-17 17:01:13,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:14,120][root][INFO] - Training Epoch: 1/2, step 6124/107898 completed (loss: 2.207611560821533, acc: 0.6000000238418579)
[2025-02-17 17:01:14,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:14,493][root][INFO] - Training Epoch: 1/2, step 6125/107898 completed (loss: 1.6865718364715576, acc: 0.65625)
[2025-02-17 17:01:14,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:14,787][root][INFO] - Training Epoch: 1/2, step 6126/107898 completed (loss: 0.19821099936962128, acc: 1.0)
[2025-02-17 17:01:14,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:15,088][root][INFO] - Training Epoch: 1/2, step 6127/107898 completed (loss: 0.14885616302490234, acc: 1.0)
[2025-02-17 17:01:15,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:15,428][root][INFO] - Training Epoch: 1/2, step 6128/107898 completed (loss: 0.17923805117607117, acc: 1.0)
[2025-02-17 17:01:15,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:15,742][root][INFO] - Training Epoch: 1/2, step 6129/107898 completed (loss: 0.39694565534591675, acc: 1.0)
[2025-02-17 17:01:15,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:16,060][root][INFO] - Training Epoch: 1/2, step 6130/107898 completed (loss: 0.26404547691345215, acc: 1.0)
[2025-02-17 17:01:16,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:16,352][root][INFO] - Training Epoch: 1/2, step 6131/107898 completed (loss: 0.14687204360961914, acc: 1.0)
[2025-02-17 17:01:16,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:16,645][root][INFO] - Training Epoch: 1/2, step 6132/107898 completed (loss: 1.3317519426345825, acc: 0.8181818127632141)
[2025-02-17 17:01:16,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:16,935][root][INFO] - Training Epoch: 1/2, step 6133/107898 completed (loss: 1.4706469774246216, acc: 0.8125)
[2025-02-17 17:01:17,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:17,225][root][INFO] - Training Epoch: 1/2, step 6134/107898 completed (loss: 0.9856716394424438, acc: 0.8214285969734192)
[2025-02-17 17:01:17,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:17,530][root][INFO] - Training Epoch: 1/2, step 6135/107898 completed (loss: 2.5660805702209473, acc: 0.25)
[2025-02-17 17:01:17,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:17,823][root][INFO] - Training Epoch: 1/2, step 6136/107898 completed (loss: 0.6083860397338867, acc: 0.8181818127632141)
[2025-02-17 17:01:17,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:18,134][root][INFO] - Training Epoch: 1/2, step 6137/107898 completed (loss: 0.11889369785785675, acc: 0.9615384340286255)
[2025-02-17 17:01:18,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:18,427][root][INFO] - Training Epoch: 1/2, step 6138/107898 completed (loss: 1.2556946277618408, acc: 0.0)
[2025-02-17 17:01:18,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:18,801][root][INFO] - Training Epoch: 1/2, step 6139/107898 completed (loss: 3.011322259902954, acc: 0.6666666865348816)
[2025-02-17 17:01:18,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:19,123][root][INFO] - Training Epoch: 1/2, step 6140/107898 completed (loss: 1.2015753984451294, acc: 0.7307692170143127)
[2025-02-17 17:01:19,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:19,444][root][INFO] - Training Epoch: 1/2, step 6141/107898 completed (loss: 1.8754689693450928, acc: 0.75)
[2025-02-17 17:01:19,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:19,767][root][INFO] - Training Epoch: 1/2, step 6142/107898 completed (loss: 1.4915294647216797, acc: 0.7272727489471436)
[2025-02-17 17:01:19,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:20,107][root][INFO] - Training Epoch: 1/2, step 6143/107898 completed (loss: 0.039897289127111435, acc: 1.0)
[2025-02-17 17:01:20,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:20,435][root][INFO] - Training Epoch: 1/2, step 6144/107898 completed (loss: 1.2030349969863892, acc: 0.5)
[2025-02-17 17:01:20,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:20,764][root][INFO] - Training Epoch: 1/2, step 6145/107898 completed (loss: 0.0013384203193709254, acc: 1.0)
[2025-02-17 17:01:20,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:21,075][root][INFO] - Training Epoch: 1/2, step 6146/107898 completed (loss: 0.7321361303329468, acc: 0.8636363744735718)
[2025-02-17 17:01:21,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:21,384][root][INFO] - Training Epoch: 1/2, step 6147/107898 completed (loss: 0.6804343461990356, acc: 0.7894737124443054)
[2025-02-17 17:01:21,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:21,712][root][INFO] - Training Epoch: 1/2, step 6148/107898 completed (loss: 1.0745445489883423, acc: 0.7599999904632568)
[2025-02-17 17:01:21,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:21,997][root][INFO] - Training Epoch: 1/2, step 6149/107898 completed (loss: 0.000589260074775666, acc: 1.0)
[2025-02-17 17:01:22,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:22,296][root][INFO] - Training Epoch: 1/2, step 6150/107898 completed (loss: 2.6631577014923096, acc: 0.4166666567325592)
[2025-02-17 17:01:22,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:22,592][root][INFO] - Training Epoch: 1/2, step 6151/107898 completed (loss: 2.3660733699798584, acc: 0.4000000059604645)
[2025-02-17 17:01:22,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:22,902][root][INFO] - Training Epoch: 1/2, step 6152/107898 completed (loss: 1.06096613407135, acc: 0.6666666865348816)
[2025-02-17 17:01:23,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:23,234][root][INFO] - Training Epoch: 1/2, step 6153/107898 completed (loss: 4.9555864334106445, acc: 0.25)
[2025-02-17 17:01:23,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:23,531][root][INFO] - Training Epoch: 1/2, step 6154/107898 completed (loss: 1.258041262626648, acc: 0.6000000238418579)
[2025-02-17 17:01:23,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:23,878][root][INFO] - Training Epoch: 1/2, step 6155/107898 completed (loss: 1.9887123107910156, acc: 0.7777777910232544)
[2025-02-17 17:01:23,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:24,233][root][INFO] - Training Epoch: 1/2, step 6156/107898 completed (loss: 0.028797976672649384, acc: 1.0)
[2025-02-17 17:01:24,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:24,581][root][INFO] - Training Epoch: 1/2, step 6157/107898 completed (loss: 0.5762130618095398, acc: 0.75)
[2025-02-17 17:01:24,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:24,931][root][INFO] - Training Epoch: 1/2, step 6158/107898 completed (loss: 0.4733196496963501, acc: 0.875)
[2025-02-17 17:01:25,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:25,271][root][INFO] - Training Epoch: 1/2, step 6159/107898 completed (loss: 1.2467238903045654, acc: 0.75)
[2025-02-17 17:01:25,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:25,619][root][INFO] - Training Epoch: 1/2, step 6160/107898 completed (loss: 5.1238579750061035, acc: 0.3333333432674408)
[2025-02-17 17:01:25,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:25,901][root][INFO] - Training Epoch: 1/2, step 6161/107898 completed (loss: 2.5700225830078125, acc: 0.6666666865348816)
[2025-02-17 17:01:26,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:26,244][root][INFO] - Training Epoch: 1/2, step 6162/107898 completed (loss: 0.0005255724536255002, acc: 1.0)
[2025-02-17 17:01:26,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:26,599][root][INFO] - Training Epoch: 1/2, step 6163/107898 completed (loss: 0.5455682277679443, acc: 0.8666666746139526)
[2025-02-17 17:01:26,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:26,939][root][INFO] - Training Epoch: 1/2, step 6164/107898 completed (loss: 4.1465582847595215, acc: 0.20000000298023224)
[2025-02-17 17:01:27,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:27,256][root][INFO] - Training Epoch: 1/2, step 6165/107898 completed (loss: 1.0980160236358643, acc: 0.75)
[2025-02-17 17:01:27,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:27,567][root][INFO] - Training Epoch: 1/2, step 6166/107898 completed (loss: 0.4431350827217102, acc: 0.90625)
[2025-02-17 17:01:27,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:27,870][root][INFO] - Training Epoch: 1/2, step 6167/107898 completed (loss: 0.8975570201873779, acc: 0.8461538553237915)
[2025-02-17 17:01:27,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:28,163][root][INFO] - Training Epoch: 1/2, step 6168/107898 completed (loss: 0.6770868897438049, acc: 0.9333333373069763)
[2025-02-17 17:01:28,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:28,457][root][INFO] - Training Epoch: 1/2, step 6169/107898 completed (loss: 0.21455547213554382, acc: 1.0)
[2025-02-17 17:01:28,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:28,749][root][INFO] - Training Epoch: 1/2, step 6170/107898 completed (loss: 5.215817928314209, acc: 0.0)
[2025-02-17 17:01:28,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:29,050][root][INFO] - Training Epoch: 1/2, step 6171/107898 completed (loss: 4.541927814483643, acc: 0.4285714328289032)
[2025-02-17 17:01:29,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:29,367][root][INFO] - Training Epoch: 1/2, step 6172/107898 completed (loss: 1.1371617317199707, acc: 0.7368420958518982)
[2025-02-17 17:01:29,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:29,655][root][INFO] - Training Epoch: 1/2, step 6173/107898 completed (loss: 4.833009243011475, acc: 0.1666666716337204)
[2025-02-17 17:01:29,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:29,967][root][INFO] - Training Epoch: 1/2, step 6174/107898 completed (loss: 0.26535600423812866, acc: 0.8999999761581421)
[2025-02-17 17:01:30,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:30,237][root][INFO] - Training Epoch: 1/2, step 6175/107898 completed (loss: 0.2991637587547302, acc: 1.0)
[2025-02-17 17:01:30,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:30,532][root][INFO] - Training Epoch: 1/2, step 6176/107898 completed (loss: 0.5643039345741272, acc: 0.800000011920929)
[2025-02-17 17:01:30,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:30,822][root][INFO] - Training Epoch: 1/2, step 6177/107898 completed (loss: 0.2173290103673935, acc: 1.0)
[2025-02-17 17:01:30,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:31,113][root][INFO] - Training Epoch: 1/2, step 6178/107898 completed (loss: 1.536010503768921, acc: 0.75)
[2025-02-17 17:01:31,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:31,463][root][INFO] - Training Epoch: 1/2, step 6179/107898 completed (loss: 1.5521793365478516, acc: 0.6888889074325562)
[2025-02-17 17:01:31,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:31,757][root][INFO] - Training Epoch: 1/2, step 6180/107898 completed (loss: 1.1364295482635498, acc: 0.739130437374115)
[2025-02-17 17:01:31,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:32,047][root][INFO] - Training Epoch: 1/2, step 6181/107898 completed (loss: 2.1967897415161133, acc: 0.5)
[2025-02-17 17:01:32,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:32,344][root][INFO] - Training Epoch: 1/2, step 6182/107898 completed (loss: 0.9203522801399231, acc: 0.6666666865348816)
[2025-02-17 17:01:32,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:32,624][root][INFO] - Training Epoch: 1/2, step 6183/107898 completed (loss: 0.7194952964782715, acc: 0.6666666865348816)
[2025-02-17 17:01:32,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:32,967][root][INFO] - Training Epoch: 1/2, step 6184/107898 completed (loss: 0.5423903465270996, acc: 0.6666666865348816)
[2025-02-17 17:01:33,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:33,294][root][INFO] - Training Epoch: 1/2, step 6185/107898 completed (loss: 0.08707001805305481, acc: 1.0)
[2025-02-17 17:01:33,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:33,622][root][INFO] - Training Epoch: 1/2, step 6186/107898 completed (loss: 2.509873867034912, acc: 0.5)
[2025-02-17 17:01:33,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:33,953][root][INFO] - Training Epoch: 1/2, step 6187/107898 completed (loss: 1.3385443687438965, acc: 0.6296296119689941)
[2025-02-17 17:01:34,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:34,303][root][INFO] - Training Epoch: 1/2, step 6188/107898 completed (loss: 0.005026796832680702, acc: 1.0)
[2025-02-17 17:01:34,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:34,636][root][INFO] - Training Epoch: 1/2, step 6189/107898 completed (loss: 0.30005407333374023, acc: 0.9166666865348816)
[2025-02-17 17:01:34,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:34,971][root][INFO] - Training Epoch: 1/2, step 6190/107898 completed (loss: 0.004907181020826101, acc: 1.0)
[2025-02-17 17:01:35,069][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:35,295][root][INFO] - Training Epoch: 1/2, step 6191/107898 completed (loss: 0.032429687678813934, acc: 1.0)
[2025-02-17 17:01:35,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:35,599][root][INFO] - Training Epoch: 1/2, step 6192/107898 completed (loss: 0.020467011258006096, acc: 1.0)
[2025-02-17 17:01:35,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:35,896][root][INFO] - Training Epoch: 1/2, step 6193/107898 completed (loss: 0.04771770164370537, acc: 1.0)
[2025-02-17 17:01:36,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:36,222][root][INFO] - Training Epoch: 1/2, step 6194/107898 completed (loss: 0.4448705315589905, acc: 0.5)
[2025-02-17 17:01:36,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:36,538][root][INFO] - Training Epoch: 1/2, step 6195/107898 completed (loss: 2.048647165298462, acc: 0.6666666865348816)
[2025-02-17 17:01:36,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:36,848][root][INFO] - Training Epoch: 1/2, step 6196/107898 completed (loss: 3.2029712200164795, acc: 0.25)
[2025-02-17 17:01:36,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:37,147][root][INFO] - Training Epoch: 1/2, step 6197/107898 completed (loss: 0.005239564459770918, acc: 1.0)
[2025-02-17 17:01:37,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:37,444][root][INFO] - Training Epoch: 1/2, step 6198/107898 completed (loss: 0.4315076768398285, acc: 0.8823529481887817)
[2025-02-17 17:01:37,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:37,750][root][INFO] - Training Epoch: 1/2, step 6199/107898 completed (loss: 2.832646369934082, acc: 0.5)
[2025-02-17 17:01:37,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:38,047][root][INFO] - Training Epoch: 1/2, step 6200/107898 completed (loss: 0.4097886383533478, acc: 0.6666666865348816)
[2025-02-17 17:01:38,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:38,352][root][INFO] - Training Epoch: 1/2, step 6201/107898 completed (loss: 0.6231563687324524, acc: 0.6666666865348816)
[2025-02-17 17:01:38,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:38,708][root][INFO] - Training Epoch: 1/2, step 6202/107898 completed (loss: 2.034667730331421, acc: 0.6666666865348816)
[2025-02-17 17:01:38,814][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:39,037][root][INFO] - Training Epoch: 1/2, step 6203/107898 completed (loss: 0.6452372074127197, acc: 0.875)
[2025-02-17 17:01:39,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:39,394][root][INFO] - Training Epoch: 1/2, step 6204/107898 completed (loss: 0.006424583960324526, acc: 1.0)
[2025-02-17 17:01:39,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:39,681][root][INFO] - Training Epoch: 1/2, step 6205/107898 completed (loss: 1.8457767963409424, acc: 0.75)
[2025-02-17 17:01:39,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:39,971][root][INFO] - Training Epoch: 1/2, step 6206/107898 completed (loss: 0.007731716614216566, acc: 1.0)
[2025-02-17 17:01:40,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:40,289][root][INFO] - Training Epoch: 1/2, step 6207/107898 completed (loss: 1.459845781326294, acc: 0.692307710647583)
[2025-02-17 17:01:40,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:40,625][root][INFO] - Training Epoch: 1/2, step 6208/107898 completed (loss: 0.45524415373802185, acc: 0.8333333134651184)
[2025-02-17 17:01:40,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:40,956][root][INFO] - Training Epoch: 1/2, step 6209/107898 completed (loss: 0.2771698236465454, acc: 0.6666666865348816)
[2025-02-17 17:01:41,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:41,264][root][INFO] - Training Epoch: 1/2, step 6210/107898 completed (loss: 0.0996185839176178, acc: 1.0)
[2025-02-17 17:01:41,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:41,608][root][INFO] - Training Epoch: 1/2, step 6211/107898 completed (loss: 1.4482777118682861, acc: 0.6428571343421936)
[2025-02-17 17:01:41,723][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:41,969][root][INFO] - Training Epoch: 1/2, step 6212/107898 completed (loss: 0.7675703763961792, acc: 0.8461538553237915)
[2025-02-17 17:01:42,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:42,309][root][INFO] - Training Epoch: 1/2, step 6213/107898 completed (loss: 0.826257050037384, acc: 0.7777777910232544)
[2025-02-17 17:01:42,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:42,641][root][INFO] - Training Epoch: 1/2, step 6214/107898 completed (loss: 0.8782984614372253, acc: 0.800000011920929)
[2025-02-17 17:01:42,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:42,942][root][INFO] - Training Epoch: 1/2, step 6215/107898 completed (loss: 0.05429866537451744, acc: 1.0)
[2025-02-17 17:01:43,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:43,234][root][INFO] - Training Epoch: 1/2, step 6216/107898 completed (loss: 0.11379844695329666, acc: 1.0)
[2025-02-17 17:01:43,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:43,539][root][INFO] - Training Epoch: 1/2, step 6217/107898 completed (loss: 0.01663549430668354, acc: 1.0)
[2025-02-17 17:01:43,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:43,889][root][INFO] - Training Epoch: 1/2, step 6218/107898 completed (loss: 1.1756632328033447, acc: 0.6666666865348816)
[2025-02-17 17:01:43,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:44,196][root][INFO] - Training Epoch: 1/2, step 6219/107898 completed (loss: 0.23546218872070312, acc: 1.0)
[2025-02-17 17:01:44,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:44,505][root][INFO] - Training Epoch: 1/2, step 6220/107898 completed (loss: 0.28084394335746765, acc: 1.0)
[2025-02-17 17:01:44,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:44,825][root][INFO] - Training Epoch: 1/2, step 6221/107898 completed (loss: 1.9006984233856201, acc: 0.75)
[2025-02-17 17:01:44,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:45,159][root][INFO] - Training Epoch: 1/2, step 6222/107898 completed (loss: 0.24598850309848785, acc: 0.6666666865348816)
[2025-02-17 17:01:45,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:45,488][root][INFO] - Training Epoch: 1/2, step 6223/107898 completed (loss: 1.449843406677246, acc: 0.7142857313156128)
[2025-02-17 17:01:45,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:45,808][root][INFO] - Training Epoch: 1/2, step 6224/107898 completed (loss: 0.09081926941871643, acc: 1.0)
[2025-02-17 17:01:45,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:46,124][root][INFO] - Training Epoch: 1/2, step 6225/107898 completed (loss: 2.5121326446533203, acc: 0.5)
[2025-02-17 17:01:46,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:46,447][root][INFO] - Training Epoch: 1/2, step 6226/107898 completed (loss: 4.066431522369385, acc: 0.0)
[2025-02-17 17:01:46,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:46,802][root][INFO] - Training Epoch: 1/2, step 6227/107898 completed (loss: 0.9542783498764038, acc: 0.8260869383811951)
[2025-02-17 17:01:46,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:47,144][root][INFO] - Training Epoch: 1/2, step 6228/107898 completed (loss: 0.008854384534060955, acc: 1.0)
[2025-02-17 17:01:47,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:47,465][root][INFO] - Training Epoch: 1/2, step 6229/107898 completed (loss: 0.01813843660056591, acc: 1.0)
[2025-02-17 17:01:47,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:47,766][root][INFO] - Training Epoch: 1/2, step 6230/107898 completed (loss: 1.2414878606796265, acc: 0.7894737124443054)
[2025-02-17 17:01:47,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:48,067][root][INFO] - Training Epoch: 1/2, step 6231/107898 completed (loss: 3.2634475231170654, acc: 0.3333333432674408)
[2025-02-17 17:01:48,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:48,374][root][INFO] - Training Epoch: 1/2, step 6232/107898 completed (loss: 1.9371974468231201, acc: 0.6315789222717285)
[2025-02-17 17:01:48,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:48,678][root][INFO] - Training Epoch: 1/2, step 6233/107898 completed (loss: 0.3752264082431793, acc: 1.0)
[2025-02-17 17:01:48,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:48,981][root][INFO] - Training Epoch: 1/2, step 6234/107898 completed (loss: 0.021261947229504585, acc: 1.0)
[2025-02-17 17:01:49,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:49,288][root][INFO] - Training Epoch: 1/2, step 6235/107898 completed (loss: 1.3158975839614868, acc: 0.800000011920929)
[2025-02-17 17:01:49,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:49,575][root][INFO] - Training Epoch: 1/2, step 6236/107898 completed (loss: 0.12907573580741882, acc: 1.0)
[2025-02-17 17:01:49,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:49,866][root][INFO] - Training Epoch: 1/2, step 6237/107898 completed (loss: 1.5232163667678833, acc: 0.7142857313156128)
[2025-02-17 17:01:49,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:50,165][root][INFO] - Training Epoch: 1/2, step 6238/107898 completed (loss: 1.2230489253997803, acc: 0.7142857313156128)
[2025-02-17 17:01:50,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:50,488][root][INFO] - Training Epoch: 1/2, step 6239/107898 completed (loss: 1.51002037525177, acc: 0.699999988079071)
[2025-02-17 17:01:50,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:50,824][root][INFO] - Training Epoch: 1/2, step 6240/107898 completed (loss: 0.032245464622974396, acc: 1.0)
[2025-02-17 17:01:50,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:51,141][root][INFO] - Training Epoch: 1/2, step 6241/107898 completed (loss: 0.4635450541973114, acc: 0.8888888955116272)
[2025-02-17 17:01:51,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:51,450][root][INFO] - Training Epoch: 1/2, step 6242/107898 completed (loss: 1.2833163738250732, acc: 0.699999988079071)
[2025-02-17 17:01:51,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:51,750][root][INFO] - Training Epoch: 1/2, step 6243/107898 completed (loss: 2.215447425842285, acc: 0.5)
[2025-02-17 17:01:51,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:52,082][root][INFO] - Training Epoch: 1/2, step 6244/107898 completed (loss: 0.9903238415718079, acc: 0.5)
[2025-02-17 17:01:52,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:52,387][root][INFO] - Training Epoch: 1/2, step 6245/107898 completed (loss: 3.1870830059051514, acc: 0.625)
[2025-02-17 17:01:52,466][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:52,671][root][INFO] - Training Epoch: 1/2, step 6246/107898 completed (loss: 2.3576443195343018, acc: 0.3333333432674408)
[2025-02-17 17:01:52,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:52,970][root][INFO] - Training Epoch: 1/2, step 6247/107898 completed (loss: 1.9990860223770142, acc: 0.800000011920929)
[2025-02-17 17:01:53,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:53,272][root][INFO] - Training Epoch: 1/2, step 6248/107898 completed (loss: 0.8997824192047119, acc: 0.75)
[2025-02-17 17:01:53,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:53,581][root][INFO] - Training Epoch: 1/2, step 6249/107898 completed (loss: 3.3455307483673096, acc: 0.0)
[2025-02-17 17:01:53,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:53,874][root][INFO] - Training Epoch: 1/2, step 6250/107898 completed (loss: 0.3676382303237915, acc: 1.0)
[2025-02-17 17:01:53,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:54,170][root][INFO] - Training Epoch: 1/2, step 6251/107898 completed (loss: 4.745546340942383, acc: 0.4000000059604645)
[2025-02-17 17:01:54,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:54,461][root][INFO] - Training Epoch: 1/2, step 6252/107898 completed (loss: 0.675199568271637, acc: 0.875)
[2025-02-17 17:01:54,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:54,761][root][INFO] - Training Epoch: 1/2, step 6253/107898 completed (loss: 0.5107617378234863, acc: 1.0)
[2025-02-17 17:01:54,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:55,093][root][INFO] - Training Epoch: 1/2, step 6254/107898 completed (loss: 0.2564176917076111, acc: 0.6666666865348816)
[2025-02-17 17:01:55,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:55,444][root][INFO] - Training Epoch: 1/2, step 6255/107898 completed (loss: 1.0772392749786377, acc: 0.800000011920929)
[2025-02-17 17:01:55,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:55,801][root][INFO] - Training Epoch: 1/2, step 6256/107898 completed (loss: 2.167328357696533, acc: 0.6111111044883728)
[2025-02-17 17:01:55,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:56,105][root][INFO] - Training Epoch: 1/2, step 6257/107898 completed (loss: 0.028432229533791542, acc: 1.0)
[2025-02-17 17:01:56,209][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:56,447][root][INFO] - Training Epoch: 1/2, step 6258/107898 completed (loss: 0.10125883668661118, acc: 1.0)
[2025-02-17 17:01:56,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:56,772][root][INFO] - Training Epoch: 1/2, step 6259/107898 completed (loss: 5.633302211761475, acc: 0.3333333432674408)
[2025-02-17 17:01:56,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:57,059][root][INFO] - Training Epoch: 1/2, step 6260/107898 completed (loss: 2.0389344692230225, acc: 0.75)
[2025-02-17 17:01:57,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:57,395][root][INFO] - Training Epoch: 1/2, step 6261/107898 completed (loss: 0.15688034892082214, acc: 1.0)
[2025-02-17 17:01:57,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:57,751][root][INFO] - Training Epoch: 1/2, step 6262/107898 completed (loss: 1.278977632522583, acc: 0.5)
[2025-02-17 17:01:57,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:58,080][root][INFO] - Training Epoch: 1/2, step 6263/107898 completed (loss: 0.4494653642177582, acc: 0.8571428656578064)
[2025-02-17 17:01:58,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:58,408][root][INFO] - Training Epoch: 1/2, step 6264/107898 completed (loss: 1.6819608211517334, acc: 0.5)
[2025-02-17 17:01:58,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:58,763][root][INFO] - Training Epoch: 1/2, step 6265/107898 completed (loss: 0.006018493324518204, acc: 1.0)
[2025-02-17 17:01:58,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:59,102][root][INFO] - Training Epoch: 1/2, step 6266/107898 completed (loss: 0.024329744279384613, acc: 1.0)
[2025-02-17 17:01:59,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:59,387][root][INFO] - Training Epoch: 1/2, step 6267/107898 completed (loss: 3.253974199295044, acc: 0.4545454680919647)
[2025-02-17 17:01:59,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:01:59,671][root][INFO] - Training Epoch: 1/2, step 6268/107898 completed (loss: 0.25306111574172974, acc: 1.0)
[2025-02-17 17:01:59,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:00,003][root][INFO] - Training Epoch: 1/2, step 6269/107898 completed (loss: 0.5857499837875366, acc: 0.9047619104385376)
[2025-02-17 17:02:00,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:00,325][root][INFO] - Training Epoch: 1/2, step 6270/107898 completed (loss: 0.4778180420398712, acc: 0.6666666865348816)
[2025-02-17 17:02:00,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:00,636][root][INFO] - Training Epoch: 1/2, step 6271/107898 completed (loss: 2.806082010269165, acc: 0.5555555820465088)
[2025-02-17 17:02:00,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:00,964][root][INFO] - Training Epoch: 1/2, step 6272/107898 completed (loss: 0.45512548089027405, acc: 1.0)
[2025-02-17 17:02:01,062][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:01,289][root][INFO] - Training Epoch: 1/2, step 6273/107898 completed (loss: 0.01881607621908188, acc: 1.0)
[2025-02-17 17:02:01,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:01,596][root][INFO] - Training Epoch: 1/2, step 6274/107898 completed (loss: 0.746501624584198, acc: 0.6666666865348816)
[2025-02-17 17:02:01,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:01,909][root][INFO] - Training Epoch: 1/2, step 6275/107898 completed (loss: 0.03162557631731033, acc: 1.0)
[2025-02-17 17:02:01,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:02,201][root][INFO] - Training Epoch: 1/2, step 6276/107898 completed (loss: 0.03817726671695709, acc: 1.0)
[2025-02-17 17:02:02,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:02,501][root][INFO] - Training Epoch: 1/2, step 6277/107898 completed (loss: 0.4003196060657501, acc: 0.9375)
[2025-02-17 17:02:02,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:02,822][root][INFO] - Training Epoch: 1/2, step 6278/107898 completed (loss: 2.980264663696289, acc: 0.3333333432674408)
[2025-02-17 17:02:02,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:03,146][root][INFO] - Training Epoch: 1/2, step 6279/107898 completed (loss: 0.007106622215360403, acc: 1.0)
[2025-02-17 17:02:03,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:03,439][root][INFO] - Training Epoch: 1/2, step 6280/107898 completed (loss: 1.4850982427597046, acc: 0.5)
[2025-02-17 17:02:03,517][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:03,732][root][INFO] - Training Epoch: 1/2, step 6281/107898 completed (loss: 2.166400671005249, acc: 0.529411792755127)
[2025-02-17 17:02:03,814][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:04,026][root][INFO] - Training Epoch: 1/2, step 6282/107898 completed (loss: 0.7313191890716553, acc: 0.8461538553237915)
[2025-02-17 17:02:04,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:04,322][root][INFO] - Training Epoch: 1/2, step 6283/107898 completed (loss: 0.15325812995433807, acc: 1.0)
[2025-02-17 17:02:04,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:04,634][root][INFO] - Training Epoch: 1/2, step 6284/107898 completed (loss: 0.8348389267921448, acc: 0.5)
[2025-02-17 17:02:04,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:04,938][root][INFO] - Training Epoch: 1/2, step 6285/107898 completed (loss: 0.14707472920417786, acc: 1.0)
[2025-02-17 17:02:05,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:05,244][root][INFO] - Training Epoch: 1/2, step 6286/107898 completed (loss: 0.43344831466674805, acc: 1.0)
[2025-02-17 17:02:05,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:05,555][root][INFO] - Training Epoch: 1/2, step 6287/107898 completed (loss: 1.7663236856460571, acc: 0.75)
[2025-02-17 17:02:05,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:05,855][root][INFO] - Training Epoch: 1/2, step 6288/107898 completed (loss: 2.2660462856292725, acc: 0.5714285969734192)
[2025-02-17 17:02:05,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:06,172][root][INFO] - Training Epoch: 1/2, step 6289/107898 completed (loss: 2.194871664047241, acc: 0.3333333432674408)
[2025-02-17 17:02:06,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:06,505][root][INFO] - Training Epoch: 1/2, step 6290/107898 completed (loss: 2.1061203479766846, acc: 0.5)
[2025-02-17 17:02:06,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:06,815][root][INFO] - Training Epoch: 1/2, step 6291/107898 completed (loss: 2.292820930480957, acc: 0.25)
[2025-02-17 17:02:06,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:07,171][root][INFO] - Training Epoch: 1/2, step 6292/107898 completed (loss: 0.5398488640785217, acc: 0.9523809552192688)
[2025-02-17 17:02:07,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:07,517][root][INFO] - Training Epoch: 1/2, step 6293/107898 completed (loss: 1.13355553150177, acc: 0.7333333492279053)
[2025-02-17 17:02:07,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:07,815][root][INFO] - Training Epoch: 1/2, step 6294/107898 completed (loss: 0.366070032119751, acc: 0.6666666865348816)
[2025-02-17 17:02:07,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:08,155][root][INFO] - Training Epoch: 1/2, step 6295/107898 completed (loss: 0.05141422897577286, acc: 1.0)
[2025-02-17 17:02:08,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:08,447][root][INFO] - Training Epoch: 1/2, step 6296/107898 completed (loss: 0.5123843550682068, acc: 1.0)
[2025-02-17 17:02:08,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:08,824][root][INFO] - Training Epoch: 1/2, step 6297/107898 completed (loss: 0.8437052965164185, acc: 0.7777777910232544)
[2025-02-17 17:02:08,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:09,149][root][INFO] - Training Epoch: 1/2, step 6298/107898 completed (loss: 2.073859691619873, acc: 0.375)
[2025-02-17 17:02:09,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:09,461][root][INFO] - Training Epoch: 1/2, step 6299/107898 completed (loss: 0.19696812331676483, acc: 0.9166666865348816)
[2025-02-17 17:02:09,564][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:09,796][root][INFO] - Training Epoch: 1/2, step 6300/107898 completed (loss: 0.4828653931617737, acc: 0.8500000238418579)
[2025-02-17 17:02:09,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:10,091][root][INFO] - Training Epoch: 1/2, step 6301/107898 completed (loss: 4.489073276519775, acc: 0.1785714328289032)
[2025-02-17 17:02:10,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:10,379][root][INFO] - Training Epoch: 1/2, step 6302/107898 completed (loss: 0.5355886816978455, acc: 0.9230769276618958)
[2025-02-17 17:02:10,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:10,675][root][INFO] - Training Epoch: 1/2, step 6303/107898 completed (loss: 1.3838084936141968, acc: 0.5)
[2025-02-17 17:02:10,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:11,019][root][INFO] - Training Epoch: 1/2, step 6304/107898 completed (loss: 0.3027641177177429, acc: 0.9166666865348816)
[2025-02-17 17:02:11,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:11,380][root][INFO] - Training Epoch: 1/2, step 6305/107898 completed (loss: 1.1972215175628662, acc: 0.6666666865348816)
[2025-02-17 17:02:11,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:11,695][root][INFO] - Training Epoch: 1/2, step 6306/107898 completed (loss: 4.02632474899292, acc: 0.4545454680919647)
[2025-02-17 17:02:11,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:12,023][root][INFO] - Training Epoch: 1/2, step 6307/107898 completed (loss: 0.38307905197143555, acc: 0.9090909361839294)
[2025-02-17 17:02:12,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:12,335][root][INFO] - Training Epoch: 1/2, step 6308/107898 completed (loss: 0.04326207935810089, acc: 1.0)
[2025-02-17 17:02:12,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:12,623][root][INFO] - Training Epoch: 1/2, step 6309/107898 completed (loss: 0.01842382736504078, acc: 1.0)
[2025-02-17 17:02:12,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:12,969][root][INFO] - Training Epoch: 1/2, step 6310/107898 completed (loss: 0.0369761660695076, acc: 1.0)
[2025-02-17 17:02:13,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:13,311][root][INFO] - Training Epoch: 1/2, step 6311/107898 completed (loss: 1.2826764583587646, acc: 0.699999988079071)
[2025-02-17 17:02:13,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:13,661][root][INFO] - Training Epoch: 1/2, step 6312/107898 completed (loss: 4.906418800354004, acc: 0.1428571492433548)
[2025-02-17 17:02:13,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:13,990][root][INFO] - Training Epoch: 1/2, step 6313/107898 completed (loss: 0.017923343926668167, acc: 1.0)
[2025-02-17 17:02:14,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:14,312][root][INFO] - Training Epoch: 1/2, step 6314/107898 completed (loss: 1.5579618215560913, acc: 0.7692307829856873)
[2025-02-17 17:02:14,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:14,641][root][INFO] - Training Epoch: 1/2, step 6315/107898 completed (loss: 0.13732483983039856, acc: 1.0)
[2025-02-17 17:02:14,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:14,993][root][INFO] - Training Epoch: 1/2, step 6316/107898 completed (loss: 4.4225335121154785, acc: 0.5)
[2025-02-17 17:02:15,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:15,350][root][INFO] - Training Epoch: 1/2, step 6317/107898 completed (loss: 1.299655556678772, acc: 0.6666666865348816)
[2025-02-17 17:02:15,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:15,669][root][INFO] - Training Epoch: 1/2, step 6318/107898 completed (loss: 0.42436766624450684, acc: 0.6666666865348816)
[2025-02-17 17:02:15,778][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:15,973][root][INFO] - Training Epoch: 1/2, step 6319/107898 completed (loss: 0.8190174102783203, acc: 0.7692307829856873)
[2025-02-17 17:02:16,086][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:16,320][root][INFO] - Training Epoch: 1/2, step 6320/107898 completed (loss: 2.9560163021087646, acc: 0.4000000059604645)
[2025-02-17 17:02:16,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:16,629][root][INFO] - Training Epoch: 1/2, step 6321/107898 completed (loss: 2.8019580841064453, acc: 0.5)
[2025-02-17 17:02:16,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:16,914][root][INFO] - Training Epoch: 1/2, step 6322/107898 completed (loss: 0.005010548047721386, acc: 1.0)
[2025-02-17 17:02:17,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:17,258][root][INFO] - Training Epoch: 1/2, step 6323/107898 completed (loss: 0.33470267057418823, acc: 0.8999999761581421)
[2025-02-17 17:02:17,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:17,578][root][INFO] - Training Epoch: 1/2, step 6324/107898 completed (loss: 4.288816928863525, acc: 0.3333333432674408)
[2025-02-17 17:02:17,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:17,888][root][INFO] - Training Epoch: 1/2, step 6325/107898 completed (loss: 0.23702430725097656, acc: 1.0)
[2025-02-17 17:02:17,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:18,229][root][INFO] - Training Epoch: 1/2, step 6326/107898 completed (loss: 0.056196969002485275, acc: 1.0)
[2025-02-17 17:02:18,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:18,517][root][INFO] - Training Epoch: 1/2, step 6327/107898 completed (loss: 0.15135236084461212, acc: 1.0)
[2025-02-17 17:02:18,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:18,806][root][INFO] - Training Epoch: 1/2, step 6328/107898 completed (loss: 1.5596258640289307, acc: 0.800000011920929)
[2025-02-17 17:02:18,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:19,103][root][INFO] - Training Epoch: 1/2, step 6329/107898 completed (loss: 0.34755849838256836, acc: 1.0)
[2025-02-17 17:02:19,185][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:19,412][root][INFO] - Training Epoch: 1/2, step 6330/107898 completed (loss: 0.047154005616903305, acc: 1.0)
[2025-02-17 17:02:19,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:19,716][root][INFO] - Training Epoch: 1/2, step 6331/107898 completed (loss: 1.140892505645752, acc: 0.0)
[2025-02-17 17:02:19,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:20,006][root][INFO] - Training Epoch: 1/2, step 6332/107898 completed (loss: 0.02193588763475418, acc: 1.0)
[2025-02-17 17:02:20,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:20,310][root][INFO] - Training Epoch: 1/2, step 6333/107898 completed (loss: 0.6084801554679871, acc: 0.8999999761581421)
[2025-02-17 17:02:20,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:20,661][root][INFO] - Training Epoch: 1/2, step 6334/107898 completed (loss: 1.7205919027328491, acc: 0.75)
[2025-02-17 17:02:20,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:20,999][root][INFO] - Training Epoch: 1/2, step 6335/107898 completed (loss: 1.193823218345642, acc: 0.5)
[2025-02-17 17:02:21,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:21,348][root][INFO] - Training Epoch: 1/2, step 6336/107898 completed (loss: 1.0279384851455688, acc: 0.6363636255264282)
[2025-02-17 17:02:21,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:21,677][root][INFO] - Training Epoch: 1/2, step 6337/107898 completed (loss: 0.7778729200363159, acc: 0.7142857313156128)
[2025-02-17 17:02:21,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:21,970][root][INFO] - Training Epoch: 1/2, step 6338/107898 completed (loss: 0.14636090397834778, acc: 1.0)
[2025-02-17 17:02:22,064][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:22,292][root][INFO] - Training Epoch: 1/2, step 6339/107898 completed (loss: 0.8572172522544861, acc: 0.8181818127632141)
[2025-02-17 17:02:22,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:22,597][root][INFO] - Training Epoch: 1/2, step 6340/107898 completed (loss: 0.3507874011993408, acc: 0.8571428656578064)
[2025-02-17 17:02:22,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:22,881][root][INFO] - Training Epoch: 1/2, step 6341/107898 completed (loss: 0.11498934775590897, acc: 1.0)
[2025-02-17 17:02:22,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:23,184][root][INFO] - Training Epoch: 1/2, step 6342/107898 completed (loss: 0.03424352407455444, acc: 1.0)
[2025-02-17 17:02:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:23,473][root][INFO] - Training Epoch: 1/2, step 6343/107898 completed (loss: 0.002097907941788435, acc: 1.0)
[2025-02-17 17:02:23,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:23,766][root][INFO] - Training Epoch: 1/2, step 6344/107898 completed (loss: 1.0638006925582886, acc: 0.6666666865348816)
[2025-02-17 17:02:23,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:24,061][root][INFO] - Training Epoch: 1/2, step 6345/107898 completed (loss: 1.1200177669525146, acc: 0.7222222089767456)
[2025-02-17 17:02:24,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:24,327][root][INFO] - Training Epoch: 1/2, step 6346/107898 completed (loss: 1.358737587928772, acc: 0.5)
[2025-02-17 17:02:24,448][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:24,682][root][INFO] - Training Epoch: 1/2, step 6347/107898 completed (loss: 1.3392513990402222, acc: 0.7419354915618896)
[2025-02-17 17:02:24,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:24,995][root][INFO] - Training Epoch: 1/2, step 6348/107898 completed (loss: 3.471133232116699, acc: 0.25)
[2025-02-17 17:02:25,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:25,341][root][INFO] - Training Epoch: 1/2, step 6349/107898 completed (loss: 0.17438359558582306, acc: 1.0)
[2025-02-17 17:02:25,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:25,632][root][INFO] - Training Epoch: 1/2, step 6350/107898 completed (loss: 0.5716608166694641, acc: 1.0)
[2025-02-17 17:02:25,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:25,918][root][INFO] - Training Epoch: 1/2, step 6351/107898 completed (loss: 0.7313465476036072, acc: 0.9166666865348816)
[2025-02-17 17:02:26,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:26,221][root][INFO] - Training Epoch: 1/2, step 6352/107898 completed (loss: 0.7056686282157898, acc: 0.7777777910232544)
[2025-02-17 17:02:26,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:26,494][root][INFO] - Training Epoch: 1/2, step 6353/107898 completed (loss: 0.7995063066482544, acc: 0.875)
[2025-02-17 17:02:26,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:26,791][root][INFO] - Training Epoch: 1/2, step 6354/107898 completed (loss: 0.3464970588684082, acc: 0.800000011920929)
[2025-02-17 17:02:26,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:27,144][root][INFO] - Training Epoch: 1/2, step 6355/107898 completed (loss: 0.1800128072500229, acc: 1.0)
[2025-02-17 17:02:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:27,490][root][INFO] - Training Epoch: 1/2, step 6356/107898 completed (loss: 0.8590964674949646, acc: 0.7931034564971924)
[2025-02-17 17:02:27,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:27,819][root][INFO] - Training Epoch: 1/2, step 6357/107898 completed (loss: 0.024503441527485847, acc: 1.0)
[2025-02-17 17:02:27,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:28,136][root][INFO] - Training Epoch: 1/2, step 6358/107898 completed (loss: 5.497302532196045, acc: 0.0)
[2025-02-17 17:02:28,212][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:28,432][root][INFO] - Training Epoch: 1/2, step 6359/107898 completed (loss: 2.7312235832214355, acc: 0.5)
[2025-02-17 17:02:28,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:28,710][root][INFO] - Training Epoch: 1/2, step 6360/107898 completed (loss: 0.15054163336753845, acc: 1.0)
[2025-02-17 17:02:28,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:28,961][root][INFO] - Training Epoch: 1/2, step 6361/107898 completed (loss: 1.153011441230774, acc: 0.8260869383811951)
[2025-02-17 17:02:29,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:29,233][root][INFO] - Training Epoch: 1/2, step 6362/107898 completed (loss: 0.06831186264753342, acc: 1.0)
[2025-02-17 17:02:29,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:29,578][root][INFO] - Training Epoch: 1/2, step 6363/107898 completed (loss: 2.821584463119507, acc: 0.5)
[2025-02-17 17:02:29,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:29,936][root][INFO] - Training Epoch: 1/2, step 6364/107898 completed (loss: 0.7452910542488098, acc: 0.8214285969734192)
[2025-02-17 17:02:30,043][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:30,276][root][INFO] - Training Epoch: 1/2, step 6365/107898 completed (loss: 0.009664117358624935, acc: 1.0)
[2025-02-17 17:02:30,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:30,600][root][INFO] - Training Epoch: 1/2, step 6366/107898 completed (loss: 2.955845594406128, acc: 0.3333333432674408)
[2025-02-17 17:02:30,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:30,935][root][INFO] - Training Epoch: 1/2, step 6367/107898 completed (loss: 0.4337984621524811, acc: 0.8999999761581421)
[2025-02-17 17:02:31,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:31,238][root][INFO] - Training Epoch: 1/2, step 6368/107898 completed (loss: 5.580188274383545, acc: 0.2857142984867096)
[2025-02-17 17:02:31,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:31,538][root][INFO] - Training Epoch: 1/2, step 6369/107898 completed (loss: 0.011056630872189999, acc: 1.0)
[2025-02-17 17:02:31,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:31,832][root][INFO] - Training Epoch: 1/2, step 6370/107898 completed (loss: 0.06428262591362, acc: 1.0)
[2025-02-17 17:02:31,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:32,110][root][INFO] - Training Epoch: 1/2, step 6371/107898 completed (loss: 0.030712133273482323, acc: 1.0)
[2025-02-17 17:02:32,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:32,390][root][INFO] - Training Epoch: 1/2, step 6372/107898 completed (loss: 2.6598477363586426, acc: 0.375)
[2025-02-17 17:02:32,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:32,678][root][INFO] - Training Epoch: 1/2, step 6373/107898 completed (loss: 0.05374644696712494, acc: 1.0)
[2025-02-17 17:02:32,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:32,992][root][INFO] - Training Epoch: 1/2, step 6374/107898 completed (loss: 0.005286647006869316, acc: 1.0)
[2025-02-17 17:02:33,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:33,296][root][INFO] - Training Epoch: 1/2, step 6375/107898 completed (loss: 0.06928456574678421, acc: 1.0)
[2025-02-17 17:02:33,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:33,628][root][INFO] - Training Epoch: 1/2, step 6376/107898 completed (loss: 0.28321415185928345, acc: 1.0)
[2025-02-17 17:02:33,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:33,963][root][INFO] - Training Epoch: 1/2, step 6377/107898 completed (loss: 0.653265655040741, acc: 0.8333333134651184)
[2025-02-17 17:02:34,077][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:34,303][root][INFO] - Training Epoch: 1/2, step 6378/107898 completed (loss: 4.113717079162598, acc: 0.5)
[2025-02-17 17:02:34,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:34,621][root][INFO] - Training Epoch: 1/2, step 6379/107898 completed (loss: 0.2692304253578186, acc: 1.0)
[2025-02-17 17:02:34,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:34,931][root][INFO] - Training Epoch: 1/2, step 6380/107898 completed (loss: 0.06352837383747101, acc: 1.0)
[2025-02-17 17:02:35,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:35,287][root][INFO] - Training Epoch: 1/2, step 6381/107898 completed (loss: 1.1430433988571167, acc: 0.5)
[2025-02-17 17:02:35,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:35,589][root][INFO] - Training Epoch: 1/2, step 6382/107898 completed (loss: 1.0460060834884644, acc: 0.5)
[2025-02-17 17:02:35,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:35,907][root][INFO] - Training Epoch: 1/2, step 6383/107898 completed (loss: 4.329093933105469, acc: 0.25)
[2025-02-17 17:02:35,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:36,208][root][INFO] - Training Epoch: 1/2, step 6384/107898 completed (loss: 0.9827056527137756, acc: 0.7894737124443054)
[2025-02-17 17:02:36,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:36,515][root][INFO] - Training Epoch: 1/2, step 6385/107898 completed (loss: 2.9958255290985107, acc: 0.5)
[2025-02-17 17:02:36,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:36,833][root][INFO] - Training Epoch: 1/2, step 6386/107898 completed (loss: 2.1900670528411865, acc: 0.3333333432674408)
[2025-02-17 17:02:36,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:37,157][root][INFO] - Training Epoch: 1/2, step 6387/107898 completed (loss: 2.8836863040924072, acc: 0.5)
[2025-02-17 17:02:37,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:37,493][root][INFO] - Training Epoch: 1/2, step 6388/107898 completed (loss: 1.0068386793136597, acc: 0.7727272510528564)
[2025-02-17 17:02:37,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:37,858][root][INFO] - Training Epoch: 1/2, step 6389/107898 completed (loss: 1.2444498538970947, acc: 0.7666666507720947)
[2025-02-17 17:02:37,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:38,199][root][INFO] - Training Epoch: 1/2, step 6390/107898 completed (loss: 0.008814946748316288, acc: 1.0)
[2025-02-17 17:02:38,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:38,548][root][INFO] - Training Epoch: 1/2, step 6391/107898 completed (loss: 2.549107074737549, acc: 0.5)
[2025-02-17 17:02:38,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:38,881][root][INFO] - Training Epoch: 1/2, step 6392/107898 completed (loss: 2.12149977684021, acc: 0.5)
[2025-02-17 17:02:38,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:39,213][root][INFO] - Training Epoch: 1/2, step 6393/107898 completed (loss: 0.4413093030452728, acc: 0.8571428656578064)
[2025-02-17 17:02:39,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:39,520][root][INFO] - Training Epoch: 1/2, step 6394/107898 completed (loss: 0.5075648427009583, acc: 1.0)
[2025-02-17 17:02:39,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:39,832][root][INFO] - Training Epoch: 1/2, step 6395/107898 completed (loss: 0.20823311805725098, acc: 1.0)
[2025-02-17 17:02:39,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:40,139][root][INFO] - Training Epoch: 1/2, step 6396/107898 completed (loss: 1.097854495048523, acc: 0.6666666865348816)
[2025-02-17 17:02:40,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:40,452][root][INFO] - Training Epoch: 1/2, step 6397/107898 completed (loss: 0.30025210976600647, acc: 0.6666666865348816)
[2025-02-17 17:02:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:40,815][root][INFO] - Training Epoch: 1/2, step 6398/107898 completed (loss: 2.7008683681488037, acc: 0.3333333432674408)
[2025-02-17 17:02:40,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:41,150][root][INFO] - Training Epoch: 1/2, step 6399/107898 completed (loss: 0.3494528532028198, acc: 1.0)
[2025-02-17 17:02:41,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:41,478][root][INFO] - Training Epoch: 1/2, step 6400/107898 completed (loss: 0.17315761744976044, acc: 1.0)
[2025-02-17 17:02:41,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:41,810][root][INFO] - Training Epoch: 1/2, step 6401/107898 completed (loss: 0.39013347029685974, acc: 0.6666666865348816)
[2025-02-17 17:02:41,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:42,124][root][INFO] - Training Epoch: 1/2, step 6402/107898 completed (loss: 1.051510214805603, acc: 0.5)
[2025-02-17 17:02:42,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:42,441][root][INFO] - Training Epoch: 1/2, step 6403/107898 completed (loss: 0.0034890705719590187, acc: 1.0)
[2025-02-17 17:02:42,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:42,804][root][INFO] - Training Epoch: 1/2, step 6404/107898 completed (loss: 4.293290615081787, acc: 0.4000000059604645)
[2025-02-17 17:02:42,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:43,127][root][INFO] - Training Epoch: 1/2, step 6405/107898 completed (loss: 2.4483399391174316, acc: 0.6666666865348816)
[2025-02-17 17:02:43,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:43,460][root][INFO] - Training Epoch: 1/2, step 6406/107898 completed (loss: 3.247352361679077, acc: 0.6666666865348816)
[2025-02-17 17:02:43,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:43,831][root][INFO] - Training Epoch: 1/2, step 6407/107898 completed (loss: 0.16693051159381866, acc: 1.0)
[2025-02-17 17:02:43,942][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:44,164][root][INFO] - Training Epoch: 1/2, step 6408/107898 completed (loss: 0.5264395475387573, acc: 1.0)
[2025-02-17 17:02:44,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:44,498][root][INFO] - Training Epoch: 1/2, step 6409/107898 completed (loss: 4.644538402557373, acc: 0.125)
[2025-02-17 17:02:44,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:44,800][root][INFO] - Training Epoch: 1/2, step 6410/107898 completed (loss: 0.016926269978284836, acc: 1.0)
[2025-02-17 17:02:44,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:45,131][root][INFO] - Training Epoch: 1/2, step 6411/107898 completed (loss: 0.5999263525009155, acc: 0.6666666865348816)
[2025-02-17 17:02:45,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:45,450][root][INFO] - Training Epoch: 1/2, step 6412/107898 completed (loss: 0.6225863099098206, acc: 0.9166666865348816)
[2025-02-17 17:02:45,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:45,800][root][INFO] - Training Epoch: 1/2, step 6413/107898 completed (loss: 0.3755570352077484, acc: 0.6666666865348816)
[2025-02-17 17:02:45,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:46,117][root][INFO] - Training Epoch: 1/2, step 6414/107898 completed (loss: 4.696436405181885, acc: 0.25)
[2025-02-17 17:02:46,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:46,416][root][INFO] - Training Epoch: 1/2, step 6415/107898 completed (loss: 0.5210662484169006, acc: 0.5)
[2025-02-17 17:02:46,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:46,730][root][INFO] - Training Epoch: 1/2, step 6416/107898 completed (loss: 0.1860859990119934, acc: 0.9583333134651184)
[2025-02-17 17:02:46,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:47,049][root][INFO] - Training Epoch: 1/2, step 6417/107898 completed (loss: 2.788508415222168, acc: 0.3333333432674408)
[2025-02-17 17:02:47,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:47,386][root][INFO] - Training Epoch: 1/2, step 6418/107898 completed (loss: 0.0131998211145401, acc: 1.0)
[2025-02-17 17:02:47,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:47,716][root][INFO] - Training Epoch: 1/2, step 6419/107898 completed (loss: 0.817536473274231, acc: 1.0)
[2025-02-17 17:02:47,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:48,018][root][INFO] - Training Epoch: 1/2, step 6420/107898 completed (loss: 5.864898204803467, acc: 0.375)
[2025-02-17 17:02:48,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:48,368][root][INFO] - Training Epoch: 1/2, step 6421/107898 completed (loss: 0.7786884307861328, acc: 0.6666666865348816)
[2025-02-17 17:02:48,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:48,761][root][INFO] - Training Epoch: 1/2, step 6422/107898 completed (loss: 0.6917961835861206, acc: 0.8620689511299133)
[2025-02-17 17:02:48,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:49,085][root][INFO] - Training Epoch: 1/2, step 6423/107898 completed (loss: 0.007380208000540733, acc: 1.0)
[2025-02-17 17:02:49,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:49,395][root][INFO] - Training Epoch: 1/2, step 6424/107898 completed (loss: 1.198352336883545, acc: 0.6000000238418579)
[2025-02-17 17:02:49,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:49,698][root][INFO] - Training Epoch: 1/2, step 6425/107898 completed (loss: 2.4945390224456787, acc: 0.5454545617103577)
[2025-02-17 17:02:49,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:50,027][root][INFO] - Training Epoch: 1/2, step 6426/107898 completed (loss: 0.7190530300140381, acc: 1.0)
[2025-02-17 17:02:50,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:50,336][root][INFO] - Training Epoch: 1/2, step 6427/107898 completed (loss: 0.011380517855286598, acc: 1.0)
[2025-02-17 17:02:50,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:50,657][root][INFO] - Training Epoch: 1/2, step 6428/107898 completed (loss: 0.019821878522634506, acc: 1.0)
[2025-02-17 17:02:50,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:50,961][root][INFO] - Training Epoch: 1/2, step 6429/107898 completed (loss: 1.8127233982086182, acc: 0.6000000238418579)
[2025-02-17 17:02:51,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:51,277][root][INFO] - Training Epoch: 1/2, step 6430/107898 completed (loss: 0.6478831768035889, acc: 0.6666666865348816)
[2025-02-17 17:02:51,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:51,583][root][INFO] - Training Epoch: 1/2, step 6431/107898 completed (loss: 0.21032597124576569, acc: 1.0)
[2025-02-17 17:02:51,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:51,949][root][INFO] - Training Epoch: 1/2, step 6432/107898 completed (loss: 1.1399335861206055, acc: 0.761904776096344)
[2025-02-17 17:02:52,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:52,263][root][INFO] - Training Epoch: 1/2, step 6433/107898 completed (loss: 1.1687469482421875, acc: 0.7272727489471436)
[2025-02-17 17:02:52,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:52,598][root][INFO] - Training Epoch: 1/2, step 6434/107898 completed (loss: 1.3758984804153442, acc: 0.625)
[2025-02-17 17:02:52,694][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:52,915][root][INFO] - Training Epoch: 1/2, step 6435/107898 completed (loss: 1.0894657373428345, acc: 0.6666666865348816)
[2025-02-17 17:02:52,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:53,186][root][INFO] - Training Epoch: 1/2, step 6436/107898 completed (loss: 0.06084655597805977, acc: 1.0)
[2025-02-17 17:02:53,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:53,534][root][INFO] - Training Epoch: 1/2, step 6437/107898 completed (loss: 0.8417217135429382, acc: 0.800000011920929)
[2025-02-17 17:02:53,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:53,871][root][INFO] - Training Epoch: 1/2, step 6438/107898 completed (loss: 3.3634538650512695, acc: 0.5)
[2025-02-17 17:02:53,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:54,189][root][INFO] - Training Epoch: 1/2, step 6439/107898 completed (loss: 1.6456571817398071, acc: 0.75)
[2025-02-17 17:02:54,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:54,511][root][INFO] - Training Epoch: 1/2, step 6440/107898 completed (loss: 0.028369655832648277, acc: 1.0)
[2025-02-17 17:02:54,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:54,890][root][INFO] - Training Epoch: 1/2, step 6441/107898 completed (loss: 0.06392741948366165, acc: 1.0)
[2025-02-17 17:02:55,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:55,249][root][INFO] - Training Epoch: 1/2, step 6442/107898 completed (loss: 0.47339916229248047, acc: 1.0)
[2025-02-17 17:02:55,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:55,579][root][INFO] - Training Epoch: 1/2, step 6443/107898 completed (loss: 1.8207989931106567, acc: 0.6666666865348816)
[2025-02-17 17:02:55,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:55,897][root][INFO] - Training Epoch: 1/2, step 6444/107898 completed (loss: 0.15079061686992645, acc: 1.0)
[2025-02-17 17:02:56,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:56,255][root][INFO] - Training Epoch: 1/2, step 6445/107898 completed (loss: 1.088141918182373, acc: 0.800000011920929)
[2025-02-17 17:02:56,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:56,554][root][INFO] - Training Epoch: 1/2, step 6446/107898 completed (loss: 0.01507649663835764, acc: 1.0)
[2025-02-17 17:02:56,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:56,843][root][INFO] - Training Epoch: 1/2, step 6447/107898 completed (loss: 4.876904010772705, acc: 0.5)
[2025-02-17 17:02:56,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:57,148][root][INFO] - Training Epoch: 1/2, step 6448/107898 completed (loss: 2.190147876739502, acc: 0.800000011920929)
[2025-02-17 17:02:57,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:57,438][root][INFO] - Training Epoch: 1/2, step 6449/107898 completed (loss: 3.5560266971588135, acc: 0.375)
[2025-02-17 17:02:57,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:57,700][root][INFO] - Training Epoch: 1/2, step 6450/107898 completed (loss: 0.024440182372927666, acc: 1.0)
[2025-02-17 17:02:57,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:57,999][root][INFO] - Training Epoch: 1/2, step 6451/107898 completed (loss: 1.2845536470413208, acc: 0.7857142686843872)
[2025-02-17 17:02:58,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:58,321][root][INFO] - Training Epoch: 1/2, step 6452/107898 completed (loss: 1.774383306503296, acc: 0.800000011920929)
[2025-02-17 17:02:58,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:58,664][root][INFO] - Training Epoch: 1/2, step 6453/107898 completed (loss: 0.6667913794517517, acc: 0.8999999761581421)
[2025-02-17 17:02:58,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:58,993][root][INFO] - Training Epoch: 1/2, step 6454/107898 completed (loss: 0.17205069959163666, acc: 1.0)
[2025-02-17 17:02:59,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:59,327][root][INFO] - Training Epoch: 1/2, step 6455/107898 completed (loss: 3.3670520782470703, acc: 0.375)
[2025-02-17 17:02:59,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:59,652][root][INFO] - Training Epoch: 1/2, step 6456/107898 completed (loss: 0.005866975523531437, acc: 1.0)
[2025-02-17 17:02:59,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:02:59,962][root][INFO] - Training Epoch: 1/2, step 6457/107898 completed (loss: 0.40246209502220154, acc: 0.8571428656578064)
[2025-02-17 17:03:00,062][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:00,305][root][INFO] - Training Epoch: 1/2, step 6458/107898 completed (loss: 3.2481348514556885, acc: 0.25)
[2025-02-17 17:03:00,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:00,618][root][INFO] - Training Epoch: 1/2, step 6459/107898 completed (loss: 0.05600525438785553, acc: 1.0)
[2025-02-17 17:03:00,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:00,910][root][INFO] - Training Epoch: 1/2, step 6460/107898 completed (loss: 0.35600990056991577, acc: 1.0)
[2025-02-17 17:03:01,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:01,238][root][INFO] - Training Epoch: 1/2, step 6461/107898 completed (loss: 0.2044358253479004, acc: 1.0)
[2025-02-17 17:03:01,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:01,543][root][INFO] - Training Epoch: 1/2, step 6462/107898 completed (loss: 0.8747071027755737, acc: 0.7142857313156128)
[2025-02-17 17:03:01,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:01,828][root][INFO] - Training Epoch: 1/2, step 6463/107898 completed (loss: 1.2841501235961914, acc: 0.800000011920929)
[2025-02-17 17:03:01,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:02,129][root][INFO] - Training Epoch: 1/2, step 6464/107898 completed (loss: 0.2988123297691345, acc: 0.8333333134651184)
[2025-02-17 17:03:02,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:02,450][root][INFO] - Training Epoch: 1/2, step 6465/107898 completed (loss: 1.154698133468628, acc: 0.7368420958518982)
[2025-02-17 17:03:02,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:02,742][root][INFO] - Training Epoch: 1/2, step 6466/107898 completed (loss: 0.6755238771438599, acc: 0.8888888955116272)
[2025-02-17 17:03:02,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:03,050][root][INFO] - Training Epoch: 1/2, step 6467/107898 completed (loss: 1.1500662565231323, acc: 0.6363636255264282)
[2025-02-17 17:03:03,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:03,330][root][INFO] - Training Epoch: 1/2, step 6468/107898 completed (loss: 1.1786669492721558, acc: 0.8275862336158752)
[2025-02-17 17:03:03,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:03,637][root][INFO] - Training Epoch: 1/2, step 6469/107898 completed (loss: 4.340063095092773, acc: 0.3181818127632141)
[2025-02-17 17:03:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:03,966][root][INFO] - Training Epoch: 1/2, step 6470/107898 completed (loss: 4.017457485198975, acc: 0.0)
[2025-02-17 17:03:04,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:04,278][root][INFO] - Training Epoch: 1/2, step 6471/107898 completed (loss: 0.4389517307281494, acc: 1.0)
[2025-02-17 17:03:04,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:04,584][root][INFO] - Training Epoch: 1/2, step 6472/107898 completed (loss: 0.6945160627365112, acc: 1.0)
[2025-02-17 17:03:04,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:04,883][root][INFO] - Training Epoch: 1/2, step 6473/107898 completed (loss: 1.050539493560791, acc: 0.5)
[2025-02-17 17:03:04,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:05,204][root][INFO] - Training Epoch: 1/2, step 6474/107898 completed (loss: 0.5663938522338867, acc: 0.84375)
[2025-02-17 17:03:05,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:05,518][root][INFO] - Training Epoch: 1/2, step 6475/107898 completed (loss: 1.5525139570236206, acc: 0.7777777910232544)
[2025-02-17 17:03:05,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:05,829][root][INFO] - Training Epoch: 1/2, step 6476/107898 completed (loss: 0.013914125971496105, acc: 1.0)
[2025-02-17 17:03:05,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:06,146][root][INFO] - Training Epoch: 1/2, step 6477/107898 completed (loss: 1.0955685377120972, acc: 0.5)
[2025-02-17 17:03:06,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:06,408][root][INFO] - Training Epoch: 1/2, step 6478/107898 completed (loss: 0.47880569100379944, acc: 1.0)
[2025-02-17 17:03:06,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:06,705][root][INFO] - Training Epoch: 1/2, step 6479/107898 completed (loss: 0.006679798010736704, acc: 1.0)
[2025-02-17 17:03:06,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:06,990][root][INFO] - Training Epoch: 1/2, step 6480/107898 completed (loss: 0.02000749297440052, acc: 1.0)
[2025-02-17 17:03:07,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:07,286][root][INFO] - Training Epoch: 1/2, step 6481/107898 completed (loss: 0.07013324648141861, acc: 1.0)
[2025-02-17 17:03:07,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:07,584][root][INFO] - Training Epoch: 1/2, step 6482/107898 completed (loss: 0.10918380320072174, acc: 1.0)
[2025-02-17 17:03:07,685][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:07,909][root][INFO] - Training Epoch: 1/2, step 6483/107898 completed (loss: 0.40690895915031433, acc: 0.9090909361839294)
[2025-02-17 17:03:07,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:08,198][root][INFO] - Training Epoch: 1/2, step 6484/107898 completed (loss: 3.3054890632629395, acc: 0.25)
[2025-02-17 17:03:08,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:08,517][root][INFO] - Training Epoch: 1/2, step 6485/107898 completed (loss: 3.1934943199157715, acc: 0.4000000059604645)
[2025-02-17 17:03:08,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:08,838][root][INFO] - Training Epoch: 1/2, step 6486/107898 completed (loss: 0.007546267472207546, acc: 1.0)
[2025-02-17 17:03:08,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:09,110][root][INFO] - Training Epoch: 1/2, step 6487/107898 completed (loss: 2.165170907974243, acc: 0.3333333432674408)
[2025-02-17 17:03:09,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:09,392][root][INFO] - Training Epoch: 1/2, step 6488/107898 completed (loss: 3.7996087074279785, acc: 0.1428571492433548)
[2025-02-17 17:03:09,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:09,741][root][INFO] - Training Epoch: 1/2, step 6489/107898 completed (loss: 0.0027186835650354624, acc: 1.0)
[2025-02-17 17:03:09,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:10,073][root][INFO] - Training Epoch: 1/2, step 6490/107898 completed (loss: 1.5529842376708984, acc: 0.6666666865348816)
[2025-02-17 17:03:10,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:10,389][root][INFO] - Training Epoch: 1/2, step 6491/107898 completed (loss: 1.1763951778411865, acc: 0.5)
[2025-02-17 17:03:10,466][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:10,699][root][INFO] - Training Epoch: 1/2, step 6492/107898 completed (loss: 2.6525824069976807, acc: 0.2857142984867096)
[2025-02-17 17:03:10,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:11,052][root][INFO] - Training Epoch: 1/2, step 6493/107898 completed (loss: 1.4897992610931396, acc: 0.800000011920929)
[2025-02-17 17:03:11,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:11,393][root][INFO] - Training Epoch: 1/2, step 6494/107898 completed (loss: 1.300838589668274, acc: 0.7083333134651184)
[2025-02-17 17:03:11,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:11,728][root][INFO] - Training Epoch: 1/2, step 6495/107898 completed (loss: 3.4193568229675293, acc: 0.6000000238418579)
[2025-02-17 17:03:11,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:12,009][root][INFO] - Training Epoch: 1/2, step 6496/107898 completed (loss: 0.193740114569664, acc: 1.0)
[2025-02-17 17:03:12,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:12,279][root][INFO] - Training Epoch: 1/2, step 6497/107898 completed (loss: 0.21372124552726746, acc: 1.0)
[2025-02-17 17:03:12,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:12,580][root][INFO] - Training Epoch: 1/2, step 6498/107898 completed (loss: 3.3055739402770996, acc: 0.5)
[2025-02-17 17:03:12,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:12,874][root][INFO] - Training Epoch: 1/2, step 6499/107898 completed (loss: 0.8542431592941284, acc: 0.8888888955116272)
[2025-02-17 17:03:12,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:13,217][root][INFO] - Training Epoch: 1/2, step 6500/107898 completed (loss: 0.46318694949150085, acc: 0.9285714030265808)
[2025-02-17 17:03:13,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:13,529][root][INFO] - Training Epoch: 1/2, step 6501/107898 completed (loss: 0.9644140601158142, acc: 0.7692307829856873)
[2025-02-17 17:03:13,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:13,836][root][INFO] - Training Epoch: 1/2, step 6502/107898 completed (loss: 0.9150628447532654, acc: 0.6666666865348816)
[2025-02-17 17:03:13,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:14,148][root][INFO] - Training Epoch: 1/2, step 6503/107898 completed (loss: 1.8577626943588257, acc: 0.5714285969734192)
[2025-02-17 17:03:14,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:14,430][root][INFO] - Training Epoch: 1/2, step 6504/107898 completed (loss: 2.9955055713653564, acc: 0.0)
[2025-02-17 17:03:14,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:14,737][root][INFO] - Training Epoch: 1/2, step 6505/107898 completed (loss: 0.23686301708221436, acc: 1.0)
[2025-02-17 17:03:14,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:15,062][root][INFO] - Training Epoch: 1/2, step 6506/107898 completed (loss: 1.6415033340454102, acc: 0.7142857313156128)
[2025-02-17 17:03:15,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:15,351][root][INFO] - Training Epoch: 1/2, step 6507/107898 completed (loss: 0.006031148601323366, acc: 1.0)
[2025-02-17 17:03:15,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:15,659][root][INFO] - Training Epoch: 1/2, step 6508/107898 completed (loss: 0.7943072319030762, acc: 0.7142857313156128)
[2025-02-17 17:03:15,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:15,957][root][INFO] - Training Epoch: 1/2, step 6509/107898 completed (loss: 2.45182204246521, acc: 0.6666666865348816)
[2025-02-17 17:03:16,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:16,248][root][INFO] - Training Epoch: 1/2, step 6510/107898 completed (loss: 0.0856984406709671, acc: 1.0)
[2025-02-17 17:03:16,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:16,557][root][INFO] - Training Epoch: 1/2, step 6511/107898 completed (loss: 2.220778226852417, acc: 0.5)
[2025-02-17 17:03:16,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:16,860][root][INFO] - Training Epoch: 1/2, step 6512/107898 completed (loss: 0.4611303210258484, acc: 0.800000011920929)
[2025-02-17 17:03:16,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:17,165][root][INFO] - Training Epoch: 1/2, step 6513/107898 completed (loss: 0.27415475249290466, acc: 1.0)
[2025-02-17 17:03:17,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:17,469][root][INFO] - Training Epoch: 1/2, step 6514/107898 completed (loss: 0.6295719146728516, acc: 0.9333333373069763)
[2025-02-17 17:03:17,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:17,808][root][INFO] - Training Epoch: 1/2, step 6515/107898 completed (loss: 1.1141397953033447, acc: 0.75)
[2025-02-17 17:03:17,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:18,136][root][INFO] - Training Epoch: 1/2, step 6516/107898 completed (loss: 0.11707918345928192, acc: 1.0)
[2025-02-17 17:03:18,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:18,480][root][INFO] - Training Epoch: 1/2, step 6517/107898 completed (loss: 2.939282178878784, acc: 0.5)
[2025-02-17 17:03:18,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:18,801][root][INFO] - Training Epoch: 1/2, step 6518/107898 completed (loss: 0.045404717326164246, acc: 1.0)
[2025-02-17 17:03:18,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:19,114][root][INFO] - Training Epoch: 1/2, step 6519/107898 completed (loss: 0.03140803799033165, acc: 1.0)
[2025-02-17 17:03:19,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:19,420][root][INFO] - Training Epoch: 1/2, step 6520/107898 completed (loss: 0.016674213111400604, acc: 1.0)
[2025-02-17 17:03:19,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:19,703][root][INFO] - Training Epoch: 1/2, step 6521/107898 completed (loss: 0.9524804949760437, acc: 0.7419354915618896)
[2025-02-17 17:03:19,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:20,047][root][INFO] - Training Epoch: 1/2, step 6522/107898 completed (loss: 0.5992028713226318, acc: 0.800000011920929)
[2025-02-17 17:03:20,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:20,363][root][INFO] - Training Epoch: 1/2, step 6523/107898 completed (loss: 2.7810873985290527, acc: 0.4000000059604645)
[2025-02-17 17:03:20,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:20,705][root][INFO] - Training Epoch: 1/2, step 6524/107898 completed (loss: 0.4025234580039978, acc: 0.9230769276618958)
[2025-02-17 17:03:20,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:21,019][root][INFO] - Training Epoch: 1/2, step 6525/107898 completed (loss: 0.04412175342440605, acc: 1.0)
[2025-02-17 17:03:21,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:21,340][root][INFO] - Training Epoch: 1/2, step 6526/107898 completed (loss: 0.002010003197938204, acc: 1.0)
[2025-02-17 17:03:21,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:21,654][root][INFO] - Training Epoch: 1/2, step 6527/107898 completed (loss: 0.08642933517694473, acc: 1.0)
[2025-02-17 17:03:21,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:21,951][root][INFO] - Training Epoch: 1/2, step 6528/107898 completed (loss: 3.066099166870117, acc: 0.75)
[2025-02-17 17:03:22,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:22,314][root][INFO] - Training Epoch: 1/2, step 6529/107898 completed (loss: 0.7972345352172852, acc: 0.7777777910232544)
[2025-02-17 17:03:22,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:22,630][root][INFO] - Training Epoch: 1/2, step 6530/107898 completed (loss: 1.6573843955993652, acc: 0.625)
[2025-02-17 17:03:22,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:22,912][root][INFO] - Training Epoch: 1/2, step 6531/107898 completed (loss: 0.024608997628092766, acc: 1.0)
[2025-02-17 17:03:22,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:23,170][root][INFO] - Training Epoch: 1/2, step 6532/107898 completed (loss: 2.222261905670166, acc: 0.75)
[2025-02-17 17:03:23,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:23,524][root][INFO] - Training Epoch: 1/2, step 6533/107898 completed (loss: 0.8911446332931519, acc: 0.8888888955116272)
[2025-02-17 17:03:23,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:23,853][root][INFO] - Training Epoch: 1/2, step 6534/107898 completed (loss: 0.10296358913183212, acc: 1.0)
[2025-02-17 17:03:23,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:24,174][root][INFO] - Training Epoch: 1/2, step 6535/107898 completed (loss: 4.785850524902344, acc: 0.0)
[2025-02-17 17:03:24,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:24,506][root][INFO] - Training Epoch: 1/2, step 6536/107898 completed (loss: 2.5321764945983887, acc: 0.25)
[2025-02-17 17:03:24,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:24,820][root][INFO] - Training Epoch: 1/2, step 6537/107898 completed (loss: 0.1981719434261322, acc: 1.0)
[2025-02-17 17:03:24,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:25,097][root][INFO] - Training Epoch: 1/2, step 6538/107898 completed (loss: 0.04474928602576256, acc: 1.0)
[2025-02-17 17:03:25,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:25,401][root][INFO] - Training Epoch: 1/2, step 6539/107898 completed (loss: 0.4578797519207001, acc: 0.9375)
[2025-02-17 17:03:25,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:25,686][root][INFO] - Training Epoch: 1/2, step 6540/107898 completed (loss: 0.007375401444733143, acc: 1.0)
[2025-02-17 17:03:25,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:25,989][root][INFO] - Training Epoch: 1/2, step 6541/107898 completed (loss: 0.1466476321220398, acc: 1.0)
[2025-02-17 17:03:26,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:26,297][root][INFO] - Training Epoch: 1/2, step 6542/107898 completed (loss: 0.009780105203390121, acc: 1.0)
[2025-02-17 17:03:26,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:26,562][root][INFO] - Training Epoch: 1/2, step 6543/107898 completed (loss: 1.2282253503799438, acc: 0.6666666865348816)
[2025-02-17 17:03:26,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:26,852][root][INFO] - Training Epoch: 1/2, step 6544/107898 completed (loss: 0.25464117527008057, acc: 1.0)
[2025-02-17 17:03:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:27,158][root][INFO] - Training Epoch: 1/2, step 6545/107898 completed (loss: 1.071416974067688, acc: 0.5)
[2025-02-17 17:03:27,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:27,482][root][INFO] - Training Epoch: 1/2, step 6546/107898 completed (loss: 1.5231468677520752, acc: 0.6800000071525574)
[2025-02-17 17:03:27,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:27,824][root][INFO] - Training Epoch: 1/2, step 6547/107898 completed (loss: 0.6233652830123901, acc: 0.7777777910232544)
[2025-02-17 17:03:27,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:28,174][root][INFO] - Training Epoch: 1/2, step 6548/107898 completed (loss: 0.8573280572891235, acc: 0.8333333134651184)
[2025-02-17 17:03:28,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:28,517][root][INFO] - Training Epoch: 1/2, step 6549/107898 completed (loss: 1.1982892751693726, acc: 0.7777777910232544)
[2025-02-17 17:03:28,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:28,820][root][INFO] - Training Epoch: 1/2, step 6550/107898 completed (loss: 3.2401721477508545, acc: 0.5)
[2025-02-17 17:03:28,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:29,089][root][INFO] - Training Epoch: 1/2, step 6551/107898 completed (loss: 3.6100409030914307, acc: 0.3333333432674408)
[2025-02-17 17:03:29,189][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:29,410][root][INFO] - Training Epoch: 1/2, step 6552/107898 completed (loss: 3.76210355758667, acc: 0.5)
[2025-02-17 17:03:29,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:29,763][root][INFO] - Training Epoch: 1/2, step 6553/107898 completed (loss: 0.1583481729030609, acc: 1.0)
[2025-02-17 17:03:29,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:30,058][root][INFO] - Training Epoch: 1/2, step 6554/107898 completed (loss: 0.10231383144855499, acc: 1.0)
[2025-02-17 17:03:30,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:30,351][root][INFO] - Training Epoch: 1/2, step 6555/107898 completed (loss: 3.1478116512298584, acc: 0.6666666865348816)
[2025-02-17 17:03:30,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:30,654][root][INFO] - Training Epoch: 1/2, step 6556/107898 completed (loss: 1.3104935884475708, acc: 0.739130437374115)
[2025-02-17 17:03:30,737][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:30,962][root][INFO] - Training Epoch: 1/2, step 6557/107898 completed (loss: 0.5653904676437378, acc: 0.875)
[2025-02-17 17:03:31,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:31,256][root][INFO] - Training Epoch: 1/2, step 6558/107898 completed (loss: 3.336453676223755, acc: 0.3333333432674408)
[2025-02-17 17:03:31,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:31,567][root][INFO] - Training Epoch: 1/2, step 6559/107898 completed (loss: 0.6220263838768005, acc: 0.75)
[2025-02-17 17:03:31,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:31,874][root][INFO] - Training Epoch: 1/2, step 6560/107898 completed (loss: 1.0604289770126343, acc: 0.75)
[2025-02-17 17:03:31,953][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:32,173][root][INFO] - Training Epoch: 1/2, step 6561/107898 completed (loss: 0.21226181089878082, acc: 1.0)
[2025-02-17 17:03:32,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:32,461][root][INFO] - Training Epoch: 1/2, step 6562/107898 completed (loss: 1.9231897592544556, acc: 0.5)
[2025-02-17 17:03:32,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:32,762][root][INFO] - Training Epoch: 1/2, step 6563/107898 completed (loss: 2.9302592277526855, acc: 0.5)
[2025-02-17 17:03:32,839][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:33,050][root][INFO] - Training Epoch: 1/2, step 6564/107898 completed (loss: 0.2850534915924072, acc: 1.0)
[2025-02-17 17:03:33,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:33,329][root][INFO] - Training Epoch: 1/2, step 6565/107898 completed (loss: 0.0489920899271965, acc: 1.0)
[2025-02-17 17:03:33,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:33,659][root][INFO] - Training Epoch: 1/2, step 6566/107898 completed (loss: 2.012596368789673, acc: 0.6666666865348816)
[2025-02-17 17:03:33,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:34,018][root][INFO] - Training Epoch: 1/2, step 6567/107898 completed (loss: 2.5813467502593994, acc: 0.4000000059604645)
[2025-02-17 17:03:34,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:34,337][root][INFO] - Training Epoch: 1/2, step 6568/107898 completed (loss: 0.32041749358177185, acc: 0.8823529481887817)
[2025-02-17 17:03:34,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:34,658][root][INFO] - Training Epoch: 1/2, step 6569/107898 completed (loss: 2.219196081161499, acc: 0.4545454680919647)
[2025-02-17 17:03:34,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:34,975][root][INFO] - Training Epoch: 1/2, step 6570/107898 completed (loss: 2.6057074069976807, acc: 0.4285714328289032)
[2025-02-17 17:03:35,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:35,279][root][INFO] - Training Epoch: 1/2, step 6571/107898 completed (loss: 2.5628228187561035, acc: 0.0)
[2025-02-17 17:03:35,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:35,592][root][INFO] - Training Epoch: 1/2, step 6572/107898 completed (loss: 1.7168231010437012, acc: 0.6521739363670349)
[2025-02-17 17:03:35,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:35,887][root][INFO] - Training Epoch: 1/2, step 6573/107898 completed (loss: 4.180622577667236, acc: 0.5)
[2025-02-17 17:03:35,953][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:36,168][root][INFO] - Training Epoch: 1/2, step 6574/107898 completed (loss: 1.4024156332015991, acc: 0.0)
[2025-02-17 17:03:36,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:36,512][root][INFO] - Training Epoch: 1/2, step 6575/107898 completed (loss: 0.03648173436522484, acc: 1.0)
[2025-02-17 17:03:36,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:36,829][root][INFO] - Training Epoch: 1/2, step 6576/107898 completed (loss: 1.759790301322937, acc: 0.6666666865348816)
[2025-02-17 17:03:36,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:37,130][root][INFO] - Training Epoch: 1/2, step 6577/107898 completed (loss: 0.29477542638778687, acc: 1.0)
[2025-02-17 17:03:37,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:37,488][root][INFO] - Training Epoch: 1/2, step 6578/107898 completed (loss: 0.14664503931999207, acc: 1.0)
[2025-02-17 17:03:37,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:37,820][root][INFO] - Training Epoch: 1/2, step 6579/107898 completed (loss: 0.6536333560943604, acc: 0.9375)
[2025-02-17 17:03:37,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:38,177][root][INFO] - Training Epoch: 1/2, step 6580/107898 completed (loss: 1.69806706905365, acc: 0.75)
[2025-02-17 17:03:38,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:38,495][root][INFO] - Training Epoch: 1/2, step 6581/107898 completed (loss: 0.010310720652341843, acc: 1.0)
[2025-02-17 17:03:38,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:38,856][root][INFO] - Training Epoch: 1/2, step 6582/107898 completed (loss: 0.04254576563835144, acc: 1.0)
[2025-02-17 17:03:38,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:39,213][root][INFO] - Training Epoch: 1/2, step 6583/107898 completed (loss: 0.2809238135814667, acc: 0.9230769276618958)
[2025-02-17 17:03:39,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:39,550][root][INFO] - Training Epoch: 1/2, step 6584/107898 completed (loss: 1.5393582582473755, acc: 0.5454545617103577)
[2025-02-17 17:03:39,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:39,872][root][INFO] - Training Epoch: 1/2, step 6585/107898 completed (loss: 2.9142677783966064, acc: 0.625)
[2025-02-17 17:03:39,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:40,200][root][INFO] - Training Epoch: 1/2, step 6586/107898 completed (loss: 0.0580211840569973, acc: 1.0)
[2025-02-17 17:03:40,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:40,535][root][INFO] - Training Epoch: 1/2, step 6587/107898 completed (loss: 0.18838340044021606, acc: 1.0)
[2025-02-17 17:03:40,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:40,871][root][INFO] - Training Epoch: 1/2, step 6588/107898 completed (loss: 1.0036131143569946, acc: 0.3333333432674408)
[2025-02-17 17:03:40,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:41,205][root][INFO] - Training Epoch: 1/2, step 6589/107898 completed (loss: 0.04272262379527092, acc: 1.0)
[2025-02-17 17:03:41,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:41,523][root][INFO] - Training Epoch: 1/2, step 6590/107898 completed (loss: 1.7448114156723022, acc: 0.800000011920929)
[2025-02-17 17:03:41,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:41,837][root][INFO] - Training Epoch: 1/2, step 6591/107898 completed (loss: 1.196128249168396, acc: 0.625)
[2025-02-17 17:03:41,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:42,145][root][INFO] - Training Epoch: 1/2, step 6592/107898 completed (loss: 3.596353530883789, acc: 0.2857142984867096)
[2025-02-17 17:03:42,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:42,429][root][INFO] - Training Epoch: 1/2, step 6593/107898 completed (loss: 2.070143938064575, acc: 0.4444444477558136)
[2025-02-17 17:03:42,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:42,722][root][INFO] - Training Epoch: 1/2, step 6594/107898 completed (loss: 1.5136686563491821, acc: 0.6666666865348816)
[2025-02-17 17:03:42,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:43,059][root][INFO] - Training Epoch: 1/2, step 6595/107898 completed (loss: 0.13008640706539154, acc: 1.0)
[2025-02-17 17:03:43,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:43,395][root][INFO] - Training Epoch: 1/2, step 6596/107898 completed (loss: 0.5285242795944214, acc: 0.8461538553237915)
[2025-02-17 17:03:43,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:43,706][root][INFO] - Training Epoch: 1/2, step 6597/107898 completed (loss: 0.021824324503540993, acc: 1.0)
[2025-02-17 17:03:43,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:44,057][root][INFO] - Training Epoch: 1/2, step 6598/107898 completed (loss: 1.5447237491607666, acc: 0.6428571343421936)
[2025-02-17 17:03:44,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:44,376][root][INFO] - Training Epoch: 1/2, step 6599/107898 completed (loss: 0.40557000041007996, acc: 0.8571428656578064)
[2025-02-17 17:03:44,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:44,707][root][INFO] - Training Epoch: 1/2, step 6600/107898 completed (loss: 2.0051052570343018, acc: 0.5555555820465088)
[2025-02-17 17:03:44,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:45,007][root][INFO] - Training Epoch: 1/2, step 6601/107898 completed (loss: 1.768032431602478, acc: 0.6666666865348816)
[2025-02-17 17:03:45,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:45,349][root][INFO] - Training Epoch: 1/2, step 6602/107898 completed (loss: 0.8328909277915955, acc: 0.5)
[2025-02-17 17:03:45,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:45,672][root][INFO] - Training Epoch: 1/2, step 6603/107898 completed (loss: 0.31706878542900085, acc: 0.75)
[2025-02-17 17:03:45,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:46,008][root][INFO] - Training Epoch: 1/2, step 6604/107898 completed (loss: 1.4784889221191406, acc: 0.8571428656578064)
[2025-02-17 17:03:46,124][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:46,365][root][INFO] - Training Epoch: 1/2, step 6605/107898 completed (loss: 0.986182689666748, acc: 0.8799999952316284)
[2025-02-17 17:03:46,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:46,708][root][INFO] - Training Epoch: 1/2, step 6606/107898 completed (loss: 0.17359380424022675, acc: 1.0)
[2025-02-17 17:03:46,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:47,036][root][INFO] - Training Epoch: 1/2, step 6607/107898 completed (loss: 0.38791728019714355, acc: 1.0)
[2025-02-17 17:03:47,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:47,327][root][INFO] - Training Epoch: 1/2, step 6608/107898 completed (loss: 0.38614165782928467, acc: 0.800000011920929)
[2025-02-17 17:03:47,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:47,639][root][INFO] - Training Epoch: 1/2, step 6609/107898 completed (loss: 1.2619249820709229, acc: 0.5)
[2025-02-17 17:03:47,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:47,897][root][INFO] - Training Epoch: 1/2, step 6610/107898 completed (loss: 0.1742904931306839, acc: 1.0)
[2025-02-17 17:03:47,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:48,196][root][INFO] - Training Epoch: 1/2, step 6611/107898 completed (loss: 0.025251729413866997, acc: 1.0)
[2025-02-17 17:03:48,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:48,529][root][INFO] - Training Epoch: 1/2, step 6612/107898 completed (loss: 1.4495365619659424, acc: 0.800000011920929)
[2025-02-17 17:03:48,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:48,837][root][INFO] - Training Epoch: 1/2, step 6613/107898 completed (loss: 2.9976654052734375, acc: 0.6666666865348816)
[2025-02-17 17:03:48,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:49,147][root][INFO] - Training Epoch: 1/2, step 6614/107898 completed (loss: 1.046047568321228, acc: 0.7222222089767456)
[2025-02-17 17:03:49,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:49,447][root][INFO] - Training Epoch: 1/2, step 6615/107898 completed (loss: 0.010327717289328575, acc: 1.0)
[2025-02-17 17:03:49,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:49,800][root][INFO] - Training Epoch: 1/2, step 6616/107898 completed (loss: 0.0013197246007621288, acc: 1.0)
[2025-02-17 17:03:49,901][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:50,124][root][INFO] - Training Epoch: 1/2, step 6617/107898 completed (loss: 0.3887586295604706, acc: 1.0)
[2025-02-17 17:03:50,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:50,442][root][INFO] - Training Epoch: 1/2, step 6618/107898 completed (loss: 0.11165475845336914, acc: 1.0)
[2025-02-17 17:03:50,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:50,753][root][INFO] - Training Epoch: 1/2, step 6619/107898 completed (loss: 0.09267248958349228, acc: 1.0)
[2025-02-17 17:03:50,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:51,044][root][INFO] - Training Epoch: 1/2, step 6620/107898 completed (loss: 2.245802879333496, acc: 0.5)
[2025-02-17 17:03:51,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:51,303][root][INFO] - Training Epoch: 1/2, step 6621/107898 completed (loss: 2.6710119247436523, acc: 0.5)
[2025-02-17 17:03:51,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:51,661][root][INFO] - Training Epoch: 1/2, step 6622/107898 completed (loss: 0.033001430332660675, acc: 1.0)
[2025-02-17 17:03:51,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:51,974][root][INFO] - Training Epoch: 1/2, step 6623/107898 completed (loss: 2.743356704711914, acc: 0.6666666865348816)
[2025-02-17 17:03:52,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:52,289][root][INFO] - Training Epoch: 1/2, step 6624/107898 completed (loss: 0.10296399146318436, acc: 1.0)
[2025-02-17 17:03:52,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:52,597][root][INFO] - Training Epoch: 1/2, step 6625/107898 completed (loss: 0.0011962646385654807, acc: 1.0)
[2025-02-17 17:03:52,676][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:52,893][root][INFO] - Training Epoch: 1/2, step 6626/107898 completed (loss: 0.006183658726513386, acc: 1.0)
[2025-02-17 17:03:52,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:53,206][root][INFO] - Training Epoch: 1/2, step 6627/107898 completed (loss: 1.2093632221221924, acc: 0.75)
[2025-02-17 17:03:53,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:53,557][root][INFO] - Training Epoch: 1/2, step 6628/107898 completed (loss: 1.1425025463104248, acc: 0.8999999761581421)
[2025-02-17 17:03:53,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:53,892][root][INFO] - Training Epoch: 1/2, step 6629/107898 completed (loss: 1.0840908288955688, acc: 0.800000011920929)
[2025-02-17 17:03:53,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:54,192][root][INFO] - Training Epoch: 1/2, step 6630/107898 completed (loss: 0.5621098279953003, acc: 0.6666666865348816)
[2025-02-17 17:03:54,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:54,499][root][INFO] - Training Epoch: 1/2, step 6631/107898 completed (loss: 0.9612756371498108, acc: 0.6666666865348816)
[2025-02-17 17:03:54,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:54,825][root][INFO] - Training Epoch: 1/2, step 6632/107898 completed (loss: 0.17202229797840118, acc: 1.0)
[2025-02-17 17:03:54,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:55,156][root][INFO] - Training Epoch: 1/2, step 6633/107898 completed (loss: 1.0019891262054443, acc: 0.800000011920929)
[2025-02-17 17:03:55,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:55,417][root][INFO] - Training Epoch: 1/2, step 6634/107898 completed (loss: 0.4131920635700226, acc: 1.0)
[2025-02-17 17:03:55,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:55,712][root][INFO] - Training Epoch: 1/2, step 6635/107898 completed (loss: 0.7310253381729126, acc: 0.8181818127632141)
[2025-02-17 17:03:55,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:56,029][root][INFO] - Training Epoch: 1/2, step 6636/107898 completed (loss: 0.8145018219947815, acc: 0.6666666865348816)
[2025-02-17 17:03:56,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:56,353][root][INFO] - Training Epoch: 1/2, step 6637/107898 completed (loss: 2.79874587059021, acc: 0.6111111044883728)
[2025-02-17 17:03:56,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:56,659][root][INFO] - Training Epoch: 1/2, step 6638/107898 completed (loss: 0.0022730010095983744, acc: 1.0)
[2025-02-17 17:03:56,762][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:56,990][root][INFO] - Training Epoch: 1/2, step 6639/107898 completed (loss: 4.674530506134033, acc: 0.3333333432674408)
[2025-02-17 17:03:57,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:57,297][root][INFO] - Training Epoch: 1/2, step 6640/107898 completed (loss: 1.7960470914840698, acc: 0.6666666865348816)
[2025-02-17 17:03:57,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:57,545][root][INFO] - Training Epoch: 1/2, step 6641/107898 completed (loss: 0.11961078643798828, acc: 1.0)
[2025-02-17 17:03:57,651][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:57,897][root][INFO] - Training Epoch: 1/2, step 6642/107898 completed (loss: 1.194076657295227, acc: 0.699999988079071)
[2025-02-17 17:03:57,998][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:58,217][root][INFO] - Training Epoch: 1/2, step 6643/107898 completed (loss: 2.5574450492858887, acc: 0.5)
[2025-02-17 17:03:58,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:58,533][root][INFO] - Training Epoch: 1/2, step 6644/107898 completed (loss: 1.0724406242370605, acc: 0.800000011920929)
[2025-02-17 17:03:58,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:58,854][root][INFO] - Training Epoch: 1/2, step 6645/107898 completed (loss: 0.16160115599632263, acc: 0.8999999761581421)
[2025-02-17 17:03:58,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:59,161][root][INFO] - Training Epoch: 1/2, step 6646/107898 completed (loss: 0.0216999351978302, acc: 1.0)
[2025-02-17 17:03:59,280][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:59,500][root][INFO] - Training Epoch: 1/2, step 6647/107898 completed (loss: 1.3864980936050415, acc: 0.7200000286102295)
[2025-02-17 17:03:59,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:03:59,787][root][INFO] - Training Epoch: 1/2, step 6648/107898 completed (loss: 0.04034385457634926, acc: 1.0)
[2025-02-17 17:03:59,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:00,082][root][INFO] - Training Epoch: 1/2, step 6649/107898 completed (loss: 0.6614726781845093, acc: 0.8666666746139526)
[2025-02-17 17:04:00,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:00,398][root][INFO] - Training Epoch: 1/2, step 6650/107898 completed (loss: 0.334107905626297, acc: 1.0)
[2025-02-17 17:04:00,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:00,736][root][INFO] - Training Epoch: 1/2, step 6651/107898 completed (loss: 0.9041505455970764, acc: 0.7727272510528564)
[2025-02-17 17:04:00,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:01,016][root][INFO] - Training Epoch: 1/2, step 6652/107898 completed (loss: 0.28504669666290283, acc: 0.8636363744735718)
[2025-02-17 17:04:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:01,324][root][INFO] - Training Epoch: 1/2, step 6653/107898 completed (loss: 2.5891644954681396, acc: 0.75)
[2025-02-17 17:04:01,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:01,651][root][INFO] - Training Epoch: 1/2, step 6654/107898 completed (loss: 0.7561553120613098, acc: 0.5)
[2025-02-17 17:04:01,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:01,984][root][INFO] - Training Epoch: 1/2, step 6655/107898 completed (loss: 0.3751686215400696, acc: 1.0)
[2025-02-17 17:04:02,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:02,312][root][INFO] - Training Epoch: 1/2, step 6656/107898 completed (loss: 1.0602598190307617, acc: 0.800000011920929)
[2025-02-17 17:04:02,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:02,608][root][INFO] - Training Epoch: 1/2, step 6657/107898 completed (loss: 0.22904549539089203, acc: 1.0)
[2025-02-17 17:04:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:02,914][root][INFO] - Training Epoch: 1/2, step 6658/107898 completed (loss: 1.099717378616333, acc: 0.75)
[2025-02-17 17:04:02,996][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:03,222][root][INFO] - Training Epoch: 1/2, step 6659/107898 completed (loss: 0.390706330537796, acc: 0.8999999761581421)
[2025-02-17 17:04:03,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:03,564][root][INFO] - Training Epoch: 1/2, step 6660/107898 completed (loss: 1.0448381900787354, acc: 0.5)
[2025-02-17 17:04:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:03,889][root][INFO] - Training Epoch: 1/2, step 6661/107898 completed (loss: 2.1508853435516357, acc: 0.625)
[2025-02-17 17:04:03,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:04,228][root][INFO] - Training Epoch: 1/2, step 6662/107898 completed (loss: 1.4859338998794556, acc: 0.5)
[2025-02-17 17:04:04,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:04,566][root][INFO] - Training Epoch: 1/2, step 6663/107898 completed (loss: 1.647806167602539, acc: 0.0)
[2025-02-17 17:04:04,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:04,890][root][INFO] - Training Epoch: 1/2, step 6664/107898 completed (loss: 1.5785980224609375, acc: 0.6666666865348816)
[2025-02-17 17:04:04,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:05,199][root][INFO] - Training Epoch: 1/2, step 6665/107898 completed (loss: 0.6141021847724915, acc: 0.9166666865348816)
[2025-02-17 17:04:05,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:05,528][root][INFO] - Training Epoch: 1/2, step 6666/107898 completed (loss: 0.8145960569381714, acc: 0.8709677457809448)
[2025-02-17 17:04:05,627][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:05,854][root][INFO] - Training Epoch: 1/2, step 6667/107898 completed (loss: 1.4876571893692017, acc: 0.5)
[2025-02-17 17:04:05,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:06,173][root][INFO] - Training Epoch: 1/2, step 6668/107898 completed (loss: 4.882743835449219, acc: 0.20000000298023224)
[2025-02-17 17:04:06,280][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:06,511][root][INFO] - Training Epoch: 1/2, step 6669/107898 completed (loss: 0.6728301048278809, acc: 0.6666666865348816)
[2025-02-17 17:04:06,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:06,834][root][INFO] - Training Epoch: 1/2, step 6670/107898 completed (loss: 3.276273488998413, acc: 0.0)
[2025-02-17 17:04:06,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:07,143][root][INFO] - Training Epoch: 1/2, step 6671/107898 completed (loss: 0.09297255426645279, acc: 1.0)
[2025-02-17 17:04:07,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:07,468][root][INFO] - Training Epoch: 1/2, step 6672/107898 completed (loss: 1.2276824712753296, acc: 0.6666666865348816)
[2025-02-17 17:04:07,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:07,816][root][INFO] - Training Epoch: 1/2, step 6673/107898 completed (loss: 0.4954245090484619, acc: 1.0)
[2025-02-17 17:04:07,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:08,161][root][INFO] - Training Epoch: 1/2, step 6674/107898 completed (loss: 0.5902056097984314, acc: 0.6666666865348816)
[2025-02-17 17:04:08,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:08,474][root][INFO] - Training Epoch: 1/2, step 6675/107898 completed (loss: 0.017166782170534134, acc: 1.0)
[2025-02-17 17:04:08,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:08,808][root][INFO] - Training Epoch: 1/2, step 6676/107898 completed (loss: 1.1060224771499634, acc: 0.8571428656578064)
[2025-02-17 17:04:08,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:09,136][root][INFO] - Training Epoch: 1/2, step 6677/107898 completed (loss: 0.3722231388092041, acc: 0.8518518805503845)
[2025-02-17 17:04:09,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:09,469][root][INFO] - Training Epoch: 1/2, step 6678/107898 completed (loss: 0.23797063529491425, acc: 1.0)
[2025-02-17 17:04:09,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:09,787][root][INFO] - Training Epoch: 1/2, step 6679/107898 completed (loss: 0.19044235348701477, acc: 1.0)
[2025-02-17 17:04:09,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:10,113][root][INFO] - Training Epoch: 1/2, step 6680/107898 completed (loss: 3.256610870361328, acc: 0.3333333432674408)
[2025-02-17 17:04:10,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:10,421][root][INFO] - Training Epoch: 1/2, step 6681/107898 completed (loss: 0.520257294178009, acc: 0.6666666865348816)
[2025-02-17 17:04:10,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:10,761][root][INFO] - Training Epoch: 1/2, step 6682/107898 completed (loss: 0.14442302286624908, acc: 1.0)
[2025-02-17 17:04:10,832][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:11,050][root][INFO] - Training Epoch: 1/2, step 6683/107898 completed (loss: 0.013254840858280659, acc: 1.0)
[2025-02-17 17:04:11,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:11,330][root][INFO] - Training Epoch: 1/2, step 6684/107898 completed (loss: 0.7845343947410583, acc: 0.7647058963775635)
[2025-02-17 17:04:11,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:11,626][root][INFO] - Training Epoch: 1/2, step 6685/107898 completed (loss: 0.3674802780151367, acc: 0.6666666865348816)
[2025-02-17 17:04:11,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:11,975][root][INFO] - Training Epoch: 1/2, step 6686/107898 completed (loss: 0.23147092759609222, acc: 1.0)
[2025-02-17 17:04:12,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:12,336][root][INFO] - Training Epoch: 1/2, step 6687/107898 completed (loss: 0.6520983576774597, acc: 0.800000011920929)
[2025-02-17 17:04:12,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:12,681][root][INFO] - Training Epoch: 1/2, step 6688/107898 completed (loss: 0.9210667014122009, acc: 0.6666666865348816)
[2025-02-17 17:04:12,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:13,013][root][INFO] - Training Epoch: 1/2, step 6689/107898 completed (loss: 0.07009293884038925, acc: 1.0)
[2025-02-17 17:04:13,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:13,323][root][INFO] - Training Epoch: 1/2, step 6690/107898 completed (loss: 2.808751344680786, acc: 0.3333333432674408)
[2025-02-17 17:04:13,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:13,625][root][INFO] - Training Epoch: 1/2, step 6691/107898 completed (loss: 0.4004892408847809, acc: 1.0)
[2025-02-17 17:04:13,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:13,906][root][INFO] - Training Epoch: 1/2, step 6692/107898 completed (loss: 0.06772131472826004, acc: 1.0)
[2025-02-17 17:04:13,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:14,211][root][INFO] - Training Epoch: 1/2, step 6693/107898 completed (loss: 0.019530685618519783, acc: 1.0)
[2025-02-17 17:04:14,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:14,503][root][INFO] - Training Epoch: 1/2, step 6694/107898 completed (loss: 1.6918693780899048, acc: 0.695652186870575)
[2025-02-17 17:04:14,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:14,826][root][INFO] - Training Epoch: 1/2, step 6695/107898 completed (loss: 0.010262813419103622, acc: 1.0)
[2025-02-17 17:04:14,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:15,176][root][INFO] - Training Epoch: 1/2, step 6696/107898 completed (loss: 1.7829735279083252, acc: 0.7142857313156128)
[2025-02-17 17:04:15,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:15,500][root][INFO] - Training Epoch: 1/2, step 6697/107898 completed (loss: 0.7908501029014587, acc: 0.7777777910232544)
[2025-02-17 17:04:15,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:15,833][root][INFO] - Training Epoch: 1/2, step 6698/107898 completed (loss: 0.5869544744491577, acc: 0.9130434989929199)
[2025-02-17 17:04:15,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:16,184][root][INFO] - Training Epoch: 1/2, step 6699/107898 completed (loss: 3.6366794109344482, acc: 0.20000000298023224)
[2025-02-17 17:04:16,289][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:16,494][root][INFO] - Training Epoch: 1/2, step 6700/107898 completed (loss: 0.020814217627048492, acc: 1.0)
[2025-02-17 17:04:16,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:16,883][root][INFO] - Training Epoch: 1/2, step 6701/107898 completed (loss: 3.4419987201690674, acc: 0.0)
[2025-02-17 17:04:16,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:17,212][root][INFO] - Training Epoch: 1/2, step 6702/107898 completed (loss: 0.9644458889961243, acc: 0.8999999761581421)
[2025-02-17 17:04:17,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:17,538][root][INFO] - Training Epoch: 1/2, step 6703/107898 completed (loss: 1.5877346992492676, acc: 0.699999988079071)
[2025-02-17 17:04:17,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:17,827][root][INFO] - Training Epoch: 1/2, step 6704/107898 completed (loss: 0.6113383173942566, acc: 1.0)
[2025-02-17 17:04:17,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:18,120][root][INFO] - Training Epoch: 1/2, step 6705/107898 completed (loss: 2.409942865371704, acc: 0.7272727489471436)
[2025-02-17 17:04:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:18,462][root][INFO] - Training Epoch: 1/2, step 6706/107898 completed (loss: 0.4008506238460541, acc: 0.8666666746139526)
[2025-02-17 17:04:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:18,779][root][INFO] - Training Epoch: 1/2, step 6707/107898 completed (loss: 0.1442289799451828, acc: 1.0)
[2025-02-17 17:04:18,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:19,115][root][INFO] - Training Epoch: 1/2, step 6708/107898 completed (loss: 1.9089460372924805, acc: 0.7037037014961243)
[2025-02-17 17:04:19,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:19,414][root][INFO] - Training Epoch: 1/2, step 6709/107898 completed (loss: 0.022713351994752884, acc: 1.0)
[2025-02-17 17:04:19,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:19,781][root][INFO] - Training Epoch: 1/2, step 6710/107898 completed (loss: 0.2376532405614853, acc: 0.9090909361839294)
[2025-02-17 17:04:19,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:20,122][root][INFO] - Training Epoch: 1/2, step 6711/107898 completed (loss: 0.42770814895629883, acc: 1.0)
[2025-02-17 17:04:20,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:20,455][root][INFO] - Training Epoch: 1/2, step 6712/107898 completed (loss: 0.7740824818611145, acc: 0.8333333134651184)
[2025-02-17 17:04:20,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:20,767][root][INFO] - Training Epoch: 1/2, step 6713/107898 completed (loss: 0.028262706473469734, acc: 1.0)
[2025-02-17 17:04:20,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:21,071][root][INFO] - Training Epoch: 1/2, step 6714/107898 completed (loss: 0.996854841709137, acc: 0.7857142686843872)
[2025-02-17 17:04:21,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:21,374][root][INFO] - Training Epoch: 1/2, step 6715/107898 completed (loss: 0.033689189702272415, acc: 1.0)
[2025-02-17 17:04:21,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:21,681][root][INFO] - Training Epoch: 1/2, step 6716/107898 completed (loss: 0.11600751429796219, acc: 1.0)
[2025-02-17 17:04:21,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:22,024][root][INFO] - Training Epoch: 1/2, step 6717/107898 completed (loss: 1.3640162944793701, acc: 0.7647058963775635)
[2025-02-17 17:04:22,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:22,330][root][INFO] - Training Epoch: 1/2, step 6718/107898 completed (loss: 1.6862430572509766, acc: 0.6666666865348816)
[2025-02-17 17:04:22,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:22,622][root][INFO] - Training Epoch: 1/2, step 6719/107898 completed (loss: 0.021312972530722618, acc: 1.0)
[2025-02-17 17:04:22,737][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:22,974][root][INFO] - Training Epoch: 1/2, step 6720/107898 completed (loss: 0.30928656458854675, acc: 0.9333333373069763)
[2025-02-17 17:04:23,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:23,295][root][INFO] - Training Epoch: 1/2, step 6721/107898 completed (loss: 1.0213114023208618, acc: 0.8636363744735718)
[2025-02-17 17:04:23,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:23,570][root][INFO] - Training Epoch: 1/2, step 6722/107898 completed (loss: 0.019962307065725327, acc: 1.0)
[2025-02-17 17:04:23,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:23,864][root][INFO] - Training Epoch: 1/2, step 6723/107898 completed (loss: 2.0122971534729004, acc: 0.5454545617103577)
[2025-02-17 17:04:23,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:24,159][root][INFO] - Training Epoch: 1/2, step 6724/107898 completed (loss: 0.02099289931356907, acc: 1.0)
[2025-02-17 17:04:24,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:24,449][root][INFO] - Training Epoch: 1/2, step 6725/107898 completed (loss: 1.3789613246917725, acc: 0.6875)
[2025-02-17 17:04:24,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:24,755][root][INFO] - Training Epoch: 1/2, step 6726/107898 completed (loss: 2.0224814414978027, acc: 0.699999988079071)
[2025-02-17 17:04:24,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:25,047][root][INFO] - Training Epoch: 1/2, step 6727/107898 completed (loss: 0.21996958553791046, acc: 0.8999999761581421)
[2025-02-17 17:04:25,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:25,309][root][INFO] - Training Epoch: 1/2, step 6728/107898 completed (loss: 1.8836231231689453, acc: 0.5)
[2025-02-17 17:04:25,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:25,620][root][INFO] - Training Epoch: 1/2, step 6729/107898 completed (loss: 2.4708828926086426, acc: 0.6190476417541504)
[2025-02-17 17:04:25,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:25,909][root][INFO] - Training Epoch: 1/2, step 6730/107898 completed (loss: 1.5098315477371216, acc: 0.5714285969734192)
[2025-02-17 17:04:25,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:26,158][root][INFO] - Training Epoch: 1/2, step 6731/107898 completed (loss: 3.177614450454712, acc: 0.3333333432674408)
[2025-02-17 17:04:26,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:26,451][root][INFO] - Training Epoch: 1/2, step 6732/107898 completed (loss: 0.2556712031364441, acc: 1.0)
[2025-02-17 17:04:26,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:26,746][root][INFO] - Training Epoch: 1/2, step 6733/107898 completed (loss: 1.493404507637024, acc: 0.6666666865348816)
[2025-02-17 17:04:26,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:27,084][root][INFO] - Training Epoch: 1/2, step 6734/107898 completed (loss: 0.30207952857017517, acc: 1.0)
[2025-02-17 17:04:27,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:27,416][root][INFO] - Training Epoch: 1/2, step 6735/107898 completed (loss: 0.383590430021286, acc: 0.800000011920929)
[2025-02-17 17:04:27,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:27,754][root][INFO] - Training Epoch: 1/2, step 6736/107898 completed (loss: 0.5713897943496704, acc: 0.7333333492279053)
[2025-02-17 17:04:27,863][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:28,101][root][INFO] - Training Epoch: 1/2, step 6737/107898 completed (loss: 0.8288863897323608, acc: 0.5)
[2025-02-17 17:04:28,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:28,456][root][INFO] - Training Epoch: 1/2, step 6738/107898 completed (loss: 3.9028284549713135, acc: 0.5)
[2025-02-17 17:04:28,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:28,809][root][INFO] - Training Epoch: 1/2, step 6739/107898 completed (loss: 1.8892552852630615, acc: 0.6666666865348816)
[2025-02-17 17:04:28,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:29,131][root][INFO] - Training Epoch: 1/2, step 6740/107898 completed (loss: 1.7034622430801392, acc: 0.3333333432674408)
[2025-02-17 17:04:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:29,439][root][INFO] - Training Epoch: 1/2, step 6741/107898 completed (loss: 0.17341698706150055, acc: 1.0)
[2025-02-17 17:04:29,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:29,781][root][INFO] - Training Epoch: 1/2, step 6742/107898 completed (loss: 0.1673596352338791, acc: 1.0)
[2025-02-17 17:04:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:30,109][root][INFO] - Training Epoch: 1/2, step 6743/107898 completed (loss: 0.01186355110257864, acc: 1.0)
[2025-02-17 17:04:30,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:30,448][root][INFO] - Training Epoch: 1/2, step 6744/107898 completed (loss: 2.6904306411743164, acc: 0.27272728085517883)
[2025-02-17 17:04:30,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:30,762][root][INFO] - Training Epoch: 1/2, step 6745/107898 completed (loss: 0.12379581481218338, acc: 1.0)
[2025-02-17 17:04:30,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:31,072][root][INFO] - Training Epoch: 1/2, step 6746/107898 completed (loss: 0.8794576525688171, acc: 0.75)
[2025-02-17 17:04:31,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:31,363][root][INFO] - Training Epoch: 1/2, step 6747/107898 completed (loss: 0.14343106746673584, acc: 1.0)
[2025-02-17 17:04:31,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:31,673][root][INFO] - Training Epoch: 1/2, step 6748/107898 completed (loss: 2.602213144302368, acc: 0.5555555820465088)
[2025-02-17 17:04:31,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:32,002][root][INFO] - Training Epoch: 1/2, step 6749/107898 completed (loss: 2.6521003246307373, acc: 0.44999998807907104)
[2025-02-17 17:04:32,115][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:32,363][root][INFO] - Training Epoch: 1/2, step 6750/107898 completed (loss: 0.4994742274284363, acc: 1.0)
[2025-02-17 17:04:32,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:32,736][root][INFO] - Training Epoch: 1/2, step 6751/107898 completed (loss: 3.9228556156158447, acc: 0.20000000298023224)
[2025-02-17 17:04:32,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:33,075][root][INFO] - Training Epoch: 1/2, step 6752/107898 completed (loss: 1.1627508401870728, acc: 0.7777777910232544)
[2025-02-17 17:04:33,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:33,397][root][INFO] - Training Epoch: 1/2, step 6753/107898 completed (loss: 0.03410237655043602, acc: 1.0)
[2025-02-17 17:04:33,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:33,720][root][INFO] - Training Epoch: 1/2, step 6754/107898 completed (loss: 1.0986731052398682, acc: 0.8125)
[2025-02-17 17:04:33,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:34,039][root][INFO] - Training Epoch: 1/2, step 6755/107898 completed (loss: 3.651339530944824, acc: 0.4166666567325592)
[2025-02-17 17:04:34,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:34,335][root][INFO] - Training Epoch: 1/2, step 6756/107898 completed (loss: 0.016755392774939537, acc: 1.0)
[2025-02-17 17:04:34,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:34,595][root][INFO] - Training Epoch: 1/2, step 6757/107898 completed (loss: 3.4466376304626465, acc: 0.25)
[2025-02-17 17:04:34,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:34,887][root][INFO] - Training Epoch: 1/2, step 6758/107898 completed (loss: 0.5923535823822021, acc: 1.0)
[2025-02-17 17:04:34,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:35,214][root][INFO] - Training Epoch: 1/2, step 6759/107898 completed (loss: 0.025702709332108498, acc: 1.0)
[2025-02-17 17:04:35,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:35,529][root][INFO] - Training Epoch: 1/2, step 6760/107898 completed (loss: 3.508512258529663, acc: 0.5)
[2025-02-17 17:04:35,619][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:35,843][root][INFO] - Training Epoch: 1/2, step 6761/107898 completed (loss: 0.994850218296051, acc: 0.7142857313156128)
[2025-02-17 17:04:35,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:36,149][root][INFO] - Training Epoch: 1/2, step 6762/107898 completed (loss: 1.6235262155532837, acc: 0.5)
[2025-02-17 17:04:36,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:36,515][root][INFO] - Training Epoch: 1/2, step 6763/107898 completed (loss: 0.8191163539886475, acc: 0.6666666865348816)
[2025-02-17 17:04:36,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:36,838][root][INFO] - Training Epoch: 1/2, step 6764/107898 completed (loss: 0.40263333916664124, acc: 0.8333333134651184)
[2025-02-17 17:04:36,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:37,190][root][INFO] - Training Epoch: 1/2, step 6765/107898 completed (loss: 0.806201159954071, acc: 0.800000011920929)
[2025-02-17 17:04:37,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:37,522][root][INFO] - Training Epoch: 1/2, step 6766/107898 completed (loss: 0.30356642603874207, acc: 1.0)
[2025-02-17 17:04:37,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:37,841][root][INFO] - Training Epoch: 1/2, step 6767/107898 completed (loss: 0.29413363337516785, acc: 0.9230769276618958)
[2025-02-17 17:04:37,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:38,154][root][INFO] - Training Epoch: 1/2, step 6768/107898 completed (loss: 0.2833555340766907, acc: 1.0)
[2025-02-17 17:04:38,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:38,450][root][INFO] - Training Epoch: 1/2, step 6769/107898 completed (loss: 1.6139745712280273, acc: 0.6666666865348816)
[2025-02-17 17:04:38,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:38,780][root][INFO] - Training Epoch: 1/2, step 6770/107898 completed (loss: 1.372515320777893, acc: 0.75)
[2025-02-17 17:04:38,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:39,096][root][INFO] - Training Epoch: 1/2, step 6771/107898 completed (loss: 1.8360629081726074, acc: 0.6666666865348816)
[2025-02-17 17:04:39,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:39,399][root][INFO] - Training Epoch: 1/2, step 6772/107898 completed (loss: 0.030497334897518158, acc: 1.0)
[2025-02-17 17:04:39,483][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:39,711][root][INFO] - Training Epoch: 1/2, step 6773/107898 completed (loss: 0.5523660778999329, acc: 1.0)
[2025-02-17 17:04:39,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:40,043][root][INFO] - Training Epoch: 1/2, step 6774/107898 completed (loss: 1.2372907400131226, acc: 0.7777777910232544)
[2025-02-17 17:04:40,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:40,355][root][INFO] - Training Epoch: 1/2, step 6775/107898 completed (loss: 2.0073161125183105, acc: 0.6363636255264282)
[2025-02-17 17:04:40,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:40,653][root][INFO] - Training Epoch: 1/2, step 6776/107898 completed (loss: 1.4628299474716187, acc: 0.6428571343421936)
[2025-02-17 17:04:40,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:40,950][root][INFO] - Training Epoch: 1/2, step 6777/107898 completed (loss: 1.2456797361373901, acc: 0.8461538553237915)
[2025-02-17 17:04:41,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:41,255][root][INFO] - Training Epoch: 1/2, step 6778/107898 completed (loss: 0.2958073318004608, acc: 0.8571428656578064)
[2025-02-17 17:04:41,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:41,542][root][INFO] - Training Epoch: 1/2, step 6779/107898 completed (loss: 0.4540228843688965, acc: 1.0)
[2025-02-17 17:04:41,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:41,845][root][INFO] - Training Epoch: 1/2, step 6780/107898 completed (loss: 1.0602738857269287, acc: 0.5)
[2025-02-17 17:04:41,925][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:42,143][root][INFO] - Training Epoch: 1/2, step 6781/107898 completed (loss: 2.2024667263031006, acc: 0.7142857313156128)
[2025-02-17 17:04:42,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:42,427][root][INFO] - Training Epoch: 1/2, step 6782/107898 completed (loss: 1.5482271909713745, acc: 0.8461538553237915)
[2025-02-17 17:04:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:42,718][root][INFO] - Training Epoch: 1/2, step 6783/107898 completed (loss: 1.0264941453933716, acc: 0.800000011920929)
[2025-02-17 17:04:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:43,051][root][INFO] - Training Epoch: 1/2, step 6784/107898 completed (loss: 1.193719506263733, acc: 0.875)
[2025-02-17 17:04:43,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:43,341][root][INFO] - Training Epoch: 1/2, step 6785/107898 completed (loss: 1.7969177961349487, acc: 0.5714285969734192)
[2025-02-17 17:04:43,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:43,702][root][INFO] - Training Epoch: 1/2, step 6786/107898 completed (loss: 0.8419837951660156, acc: 0.9090909361839294)
[2025-02-17 17:04:43,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:44,025][root][INFO] - Training Epoch: 1/2, step 6787/107898 completed (loss: 1.4915189743041992, acc: 0.739130437374115)
[2025-02-17 17:04:44,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:44,313][root][INFO] - Training Epoch: 1/2, step 6788/107898 completed (loss: 0.1135810986161232, acc: 1.0)
[2025-02-17 17:04:44,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:44,620][root][INFO] - Training Epoch: 1/2, step 6789/107898 completed (loss: 0.8009847402572632, acc: 0.8181818127632141)
[2025-02-17 17:04:44,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:44,940][root][INFO] - Training Epoch: 1/2, step 6790/107898 completed (loss: 0.617660403251648, acc: 1.0)
[2025-02-17 17:04:45,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:45,273][root][INFO] - Training Epoch: 1/2, step 6791/107898 completed (loss: 1.8597419261932373, acc: 0.5)
[2025-02-17 17:04:45,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:45,565][root][INFO] - Training Epoch: 1/2, step 6792/107898 completed (loss: 0.3828088939189911, acc: 0.9230769276618958)
[2025-02-17 17:04:45,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:45,857][root][INFO] - Training Epoch: 1/2, step 6793/107898 completed (loss: 0.012588758952915668, acc: 1.0)
[2025-02-17 17:04:45,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:46,155][root][INFO] - Training Epoch: 1/2, step 6794/107898 completed (loss: 1.1579890251159668, acc: 0.8947368264198303)
[2025-02-17 17:04:46,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:46,468][root][INFO] - Training Epoch: 1/2, step 6795/107898 completed (loss: 1.1813163757324219, acc: 0.800000011920929)
[2025-02-17 17:04:46,575][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:46,804][root][INFO] - Training Epoch: 1/2, step 6796/107898 completed (loss: 0.8730614185333252, acc: 0.6666666865348816)
[2025-02-17 17:04:46,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:47,127][root][INFO] - Training Epoch: 1/2, step 6797/107898 completed (loss: 0.9043439030647278, acc: 0.0)
[2025-02-17 17:04:47,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:47,428][root][INFO] - Training Epoch: 1/2, step 6798/107898 completed (loss: 0.06165554001927376, acc: 1.0)
[2025-02-17 17:04:47,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:47,726][root][INFO] - Training Epoch: 1/2, step 6799/107898 completed (loss: 1.9639310836791992, acc: 0.0)
[2025-02-17 17:04:47,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:48,027][root][INFO] - Training Epoch: 1/2, step 6800/107898 completed (loss: 1.5855011940002441, acc: 0.6818181872367859)
[2025-02-17 17:04:48,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:48,328][root][INFO] - Training Epoch: 1/2, step 6801/107898 completed (loss: 0.7099802494049072, acc: 0.5)
[2025-02-17 17:04:48,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:48,624][root][INFO] - Training Epoch: 1/2, step 6802/107898 completed (loss: 0.24711738526821136, acc: 1.0)
[2025-02-17 17:04:48,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:48,908][root][INFO] - Training Epoch: 1/2, step 6803/107898 completed (loss: 0.006866104435175657, acc: 1.0)
[2025-02-17 17:04:48,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:49,214][root][INFO] - Training Epoch: 1/2, step 6804/107898 completed (loss: 0.8857054710388184, acc: 0.875)
[2025-02-17 17:04:49,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:49,518][root][INFO] - Training Epoch: 1/2, step 6805/107898 completed (loss: 0.47245410084724426, acc: 1.0)
[2025-02-17 17:04:49,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:49,822][root][INFO] - Training Epoch: 1/2, step 6806/107898 completed (loss: 3.7893593311309814, acc: 0.4166666567325592)
[2025-02-17 17:04:49,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:50,123][root][INFO] - Training Epoch: 1/2, step 6807/107898 completed (loss: 0.8843719959259033, acc: 0.6666666865348816)
[2025-02-17 17:04:50,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:50,418][root][INFO] - Training Epoch: 1/2, step 6808/107898 completed (loss: 0.018880046904087067, acc: 1.0)
[2025-02-17 17:04:50,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:50,757][root][INFO] - Training Epoch: 1/2, step 6809/107898 completed (loss: 1.163204550743103, acc: 0.7692307829856873)
[2025-02-17 17:04:50,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:51,110][root][INFO] - Training Epoch: 1/2, step 6810/107898 completed (loss: 3.0268642902374268, acc: 0.5)
[2025-02-17 17:04:51,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:51,431][root][INFO] - Training Epoch: 1/2, step 6811/107898 completed (loss: 3.2618589401245117, acc: 0.5)
[2025-02-17 17:04:51,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:51,781][root][INFO] - Training Epoch: 1/2, step 6812/107898 completed (loss: 2.695906162261963, acc: 0.550000011920929)
[2025-02-17 17:04:51,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:52,099][root][INFO] - Training Epoch: 1/2, step 6813/107898 completed (loss: 0.44181856513023376, acc: 0.8333333134651184)
[2025-02-17 17:04:52,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:52,439][root][INFO] - Training Epoch: 1/2, step 6814/107898 completed (loss: 1.882181167602539, acc: 0.6000000238418579)
[2025-02-17 17:04:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:52,786][root][INFO] - Training Epoch: 1/2, step 6815/107898 completed (loss: 0.426494836807251, acc: 0.8947368264198303)
[2025-02-17 17:04:52,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:53,106][root][INFO] - Training Epoch: 1/2, step 6816/107898 completed (loss: 0.9853947758674622, acc: 0.6000000238418579)
[2025-02-17 17:04:53,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:53,443][root][INFO] - Training Epoch: 1/2, step 6817/107898 completed (loss: 0.2592766582965851, acc: 0.9090909361839294)
[2025-02-17 17:04:53,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:53,763][root][INFO] - Training Epoch: 1/2, step 6818/107898 completed (loss: 0.6745724081993103, acc: 0.800000011920929)
[2025-02-17 17:04:53,839][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:54,058][root][INFO] - Training Epoch: 1/2, step 6819/107898 completed (loss: 0.12676827609539032, acc: 1.0)
[2025-02-17 17:04:54,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:54,359][root][INFO] - Training Epoch: 1/2, step 6820/107898 completed (loss: 1.6792738437652588, acc: 0.75)
[2025-02-17 17:04:54,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:54,712][root][INFO] - Training Epoch: 1/2, step 6821/107898 completed (loss: 0.38938668370246887, acc: 0.6666666865348816)
[2025-02-17 17:04:54,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:55,041][root][INFO] - Training Epoch: 1/2, step 6822/107898 completed (loss: 0.9385097622871399, acc: 0.6666666865348816)
[2025-02-17 17:04:55,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:55,356][root][INFO] - Training Epoch: 1/2, step 6823/107898 completed (loss: 0.5796089172363281, acc: 0.6666666865348816)
[2025-02-17 17:04:55,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:55,705][root][INFO] - Training Epoch: 1/2, step 6824/107898 completed (loss: 0.4537029266357422, acc: 0.8823529481887817)
[2025-02-17 17:04:55,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:56,007][root][INFO] - Training Epoch: 1/2, step 6825/107898 completed (loss: 0.011212944984436035, acc: 1.0)
[2025-02-17 17:04:56,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:56,279][root][INFO] - Training Epoch: 1/2, step 6826/107898 completed (loss: 0.10408137738704681, acc: 1.0)
[2025-02-17 17:04:56,358][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:56,565][root][INFO] - Training Epoch: 1/2, step 6827/107898 completed (loss: 0.13875938951969147, acc: 1.0)
[2025-02-17 17:04:56,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:56,865][root][INFO] - Training Epoch: 1/2, step 6828/107898 completed (loss: 0.7161582112312317, acc: 0.8888888955116272)
[2025-02-17 17:04:56,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:57,150][root][INFO] - Training Epoch: 1/2, step 6829/107898 completed (loss: 0.17977134883403778, acc: 1.0)
[2025-02-17 17:04:57,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:57,442][root][INFO] - Training Epoch: 1/2, step 6830/107898 completed (loss: 2.1086509227752686, acc: 0.6666666865348816)
[2025-02-17 17:04:57,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:57,746][root][INFO] - Training Epoch: 1/2, step 6831/107898 completed (loss: 3.8029191493988037, acc: 0.3333333432674408)
[2025-02-17 17:04:57,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:58,040][root][INFO] - Training Epoch: 1/2, step 6832/107898 completed (loss: 0.9447738528251648, acc: 0.7272727489471436)
[2025-02-17 17:04:58,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:58,332][root][INFO] - Training Epoch: 1/2, step 6833/107898 completed (loss: 1.3349851369857788, acc: 0.7727272510528564)
[2025-02-17 17:04:58,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:58,659][root][INFO] - Training Epoch: 1/2, step 6834/107898 completed (loss: 0.3425467312335968, acc: 0.9523809552192688)
[2025-02-17 17:04:58,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:58,961][root][INFO] - Training Epoch: 1/2, step 6835/107898 completed (loss: 0.06083839014172554, acc: 1.0)
[2025-02-17 17:04:59,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:59,301][root][INFO] - Training Epoch: 1/2, step 6836/107898 completed (loss: 2.5305166244506836, acc: 0.5)
[2025-02-17 17:04:59,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:04:59,653][root][INFO] - Training Epoch: 1/2, step 6837/107898 completed (loss: 1.2500925064086914, acc: 0.8500000238418579)
[2025-02-17 17:04:59,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:00,012][root][INFO] - Training Epoch: 1/2, step 6838/107898 completed (loss: 0.8055534362792969, acc: 0.8214285969734192)
[2025-02-17 17:05:00,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:00,314][root][INFO] - Training Epoch: 1/2, step 6839/107898 completed (loss: 0.5948961973190308, acc: 0.9230769276618958)
[2025-02-17 17:05:00,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:00,579][root][INFO] - Training Epoch: 1/2, step 6840/107898 completed (loss: 1.6130794286727905, acc: 0.5625)
[2025-02-17 17:05:00,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:00,882][root][INFO] - Training Epoch: 1/2, step 6841/107898 completed (loss: 0.03448852151632309, acc: 1.0)
[2025-02-17 17:05:00,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:01,210][root][INFO] - Training Epoch: 1/2, step 6842/107898 completed (loss: 0.010527555830776691, acc: 1.0)
[2025-02-17 17:05:01,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:01,537][root][INFO] - Training Epoch: 1/2, step 6843/107898 completed (loss: 1.3978804349899292, acc: 0.6153846383094788)
[2025-02-17 17:05:01,619][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:01,841][root][INFO] - Training Epoch: 1/2, step 6844/107898 completed (loss: 0.007699158042669296, acc: 1.0)
[2025-02-17 17:05:01,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:02,133][root][INFO] - Training Epoch: 1/2, step 6845/107898 completed (loss: 0.3177783787250519, acc: 0.800000011920929)
[2025-02-17 17:05:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:02,442][root][INFO] - Training Epoch: 1/2, step 6846/107898 completed (loss: 0.40429505705833435, acc: 0.8333333134651184)
[2025-02-17 17:05:02,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:02,739][root][INFO] - Training Epoch: 1/2, step 6847/107898 completed (loss: 2.8889360427856445, acc: 0.3125)
[2025-02-17 17:05:02,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:03,014][root][INFO] - Training Epoch: 1/2, step 6848/107898 completed (loss: 0.08200129121541977, acc: 1.0)
[2025-02-17 17:05:03,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:03,311][root][INFO] - Training Epoch: 1/2, step 6849/107898 completed (loss: 0.6087062954902649, acc: 0.6666666865348816)
[2025-02-17 17:05:03,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:03,596][root][INFO] - Training Epoch: 1/2, step 6850/107898 completed (loss: 0.09017978608608246, acc: 1.0)
[2025-02-17 17:05:03,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:03,876][root][INFO] - Training Epoch: 1/2, step 6851/107898 completed (loss: 0.013854188844561577, acc: 1.0)
[2025-02-17 17:05:03,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:04,172][root][INFO] - Training Epoch: 1/2, step 6852/107898 completed (loss: 0.01404481753706932, acc: 1.0)
[2025-02-17 17:05:04,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:04,458][root][INFO] - Training Epoch: 1/2, step 6853/107898 completed (loss: 0.01355226244777441, acc: 1.0)
[2025-02-17 17:05:04,534][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:04,748][root][INFO] - Training Epoch: 1/2, step 6854/107898 completed (loss: 1.3146003484725952, acc: 0.5)
[2025-02-17 17:05:04,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:05,042][root][INFO] - Training Epoch: 1/2, step 6855/107898 completed (loss: 0.3249587118625641, acc: 1.0)
[2025-02-17 17:05:05,124][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:05,338][root][INFO] - Training Epoch: 1/2, step 6856/107898 completed (loss: 0.7789715528488159, acc: 1.0)
[2025-02-17 17:05:05,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:05,681][root][INFO] - Training Epoch: 1/2, step 6857/107898 completed (loss: 1.4732887744903564, acc: 0.5)
[2025-02-17 17:05:05,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:05,995][root][INFO] - Training Epoch: 1/2, step 6858/107898 completed (loss: 0.504357635974884, acc: 0.6666666865348816)
[2025-02-17 17:05:06,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:06,316][root][INFO] - Training Epoch: 1/2, step 6859/107898 completed (loss: 0.008944104425609112, acc: 1.0)
[2025-02-17 17:05:06,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:06,604][root][INFO] - Training Epoch: 1/2, step 6860/107898 completed (loss: 0.020123232156038284, acc: 1.0)
[2025-02-17 17:05:06,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:06,908][root][INFO] - Training Epoch: 1/2, step 6861/107898 completed (loss: 0.1505289226770401, acc: 1.0)
[2025-02-17 17:05:06,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:07,211][root][INFO] - Training Epoch: 1/2, step 6862/107898 completed (loss: 0.12513960897922516, acc: 1.0)
[2025-02-17 17:05:07,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:07,499][root][INFO] - Training Epoch: 1/2, step 6863/107898 completed (loss: 0.790195643901825, acc: 0.6666666865348816)
[2025-02-17 17:05:07,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:07,792][root][INFO] - Training Epoch: 1/2, step 6864/107898 completed (loss: 2.552367925643921, acc: 0.3333333432674408)
[2025-02-17 17:05:07,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:08,080][root][INFO] - Training Epoch: 1/2, step 6865/107898 completed (loss: 0.008972244337201118, acc: 1.0)
[2025-02-17 17:05:08,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:08,368][root][INFO] - Training Epoch: 1/2, step 6866/107898 completed (loss: 0.6197893023490906, acc: 0.6666666865348816)
[2025-02-17 17:05:08,450][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:08,666][root][INFO] - Training Epoch: 1/2, step 6867/107898 completed (loss: 2.228945255279541, acc: 0.6000000238418579)
[2025-02-17 17:05:08,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:08,965][root][INFO] - Training Epoch: 1/2, step 6868/107898 completed (loss: 0.4317593276500702, acc: 0.7777777910232544)
[2025-02-17 17:05:09,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:09,261][root][INFO] - Training Epoch: 1/2, step 6869/107898 completed (loss: 1.0042043924331665, acc: 0.8518518805503845)
[2025-02-17 17:05:09,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:09,565][root][INFO] - Training Epoch: 1/2, step 6870/107898 completed (loss: 0.41868963837623596, acc: 0.9354838728904724)
[2025-02-17 17:05:09,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:09,858][root][INFO] - Training Epoch: 1/2, step 6871/107898 completed (loss: 0.7469325661659241, acc: 1.0)
[2025-02-17 17:05:09,942][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:10,164][root][INFO] - Training Epoch: 1/2, step 6872/107898 completed (loss: 0.44293439388275146, acc: 0.9545454382896423)
[2025-02-17 17:05:10,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:10,467][root][INFO] - Training Epoch: 1/2, step 6873/107898 completed (loss: 0.37414732575416565, acc: 0.6666666865348816)
[2025-02-17 17:05:10,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:10,756][root][INFO] - Training Epoch: 1/2, step 6874/107898 completed (loss: 0.552413821220398, acc: 0.8571428656578064)
[2025-02-17 17:05:10,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:11,065][root][INFO] - Training Epoch: 1/2, step 6875/107898 completed (loss: 0.19371993839740753, acc: 1.0)
[2025-02-17 17:05:11,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:11,364][root][INFO] - Training Epoch: 1/2, step 6876/107898 completed (loss: 0.0518292635679245, acc: 1.0)
[2025-02-17 17:05:11,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:11,649][root][INFO] - Training Epoch: 1/2, step 6877/107898 completed (loss: 2.991236448287964, acc: 0.375)
[2025-02-17 17:05:11,725][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:11,934][root][INFO] - Training Epoch: 1/2, step 6878/107898 completed (loss: 0.11378639936447144, acc: 1.0)
[2025-02-17 17:05:12,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:12,233][root][INFO] - Training Epoch: 1/2, step 6879/107898 completed (loss: 0.03442514315247536, acc: 1.0)
[2025-02-17 17:05:12,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:12,551][root][INFO] - Training Epoch: 1/2, step 6880/107898 completed (loss: 0.19369743764400482, acc: 1.0)
[2025-02-17 17:05:12,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:12,890][root][INFO] - Training Epoch: 1/2, step 6881/107898 completed (loss: 0.03925379365682602, acc: 1.0)
[2025-02-17 17:05:12,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:13,220][root][INFO] - Training Epoch: 1/2, step 6882/107898 completed (loss: 0.14825168251991272, acc: 1.0)
[2025-02-17 17:05:13,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:13,546][root][INFO] - Training Epoch: 1/2, step 6883/107898 completed (loss: 1.6732218265533447, acc: 0.5)
[2025-02-17 17:05:13,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:13,843][root][INFO] - Training Epoch: 1/2, step 6884/107898 completed (loss: 0.46631208062171936, acc: 0.9333333373069763)
[2025-02-17 17:05:13,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:14,143][root][INFO] - Training Epoch: 1/2, step 6885/107898 completed (loss: 1.066421389579773, acc: 0.8235294222831726)
[2025-02-17 17:05:14,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:14,428][root][INFO] - Training Epoch: 1/2, step 6886/107898 completed (loss: 1.8523129224777222, acc: 0.6363636255264282)
[2025-02-17 17:05:14,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:14,752][root][INFO] - Training Epoch: 1/2, step 6887/107898 completed (loss: 0.4351940453052521, acc: 0.8888888955116272)
[2025-02-17 17:05:14,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:15,093][root][INFO] - Training Epoch: 1/2, step 6888/107898 completed (loss: 0.9942893981933594, acc: 0.7727272510528564)
[2025-02-17 17:05:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:15,416][root][INFO] - Training Epoch: 1/2, step 6889/107898 completed (loss: 1.4583193063735962, acc: 0.7777777910232544)
[2025-02-17 17:05:15,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:15,713][root][INFO] - Training Epoch: 1/2, step 6890/107898 completed (loss: 0.0026841782964766026, acc: 1.0)
[2025-02-17 17:05:15,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:16,003][root][INFO] - Training Epoch: 1/2, step 6891/107898 completed (loss: 0.48395439982414246, acc: 1.0)
[2025-02-17 17:05:16,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:16,305][root][INFO] - Training Epoch: 1/2, step 6892/107898 completed (loss: 1.277705192565918, acc: 0.7142857313156128)
[2025-02-17 17:05:16,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:16,606][root][INFO] - Training Epoch: 1/2, step 6893/107898 completed (loss: 0.08274548500776291, acc: 1.0)
[2025-02-17 17:05:16,671][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:16,893][root][INFO] - Training Epoch: 1/2, step 6894/107898 completed (loss: 2.3712258338928223, acc: 0.5714285969734192)
[2025-02-17 17:05:17,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:17,241][root][INFO] - Training Epoch: 1/2, step 6895/107898 completed (loss: 0.9328625202178955, acc: 0.6363636255264282)
[2025-02-17 17:05:17,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:17,561][root][INFO] - Training Epoch: 1/2, step 6896/107898 completed (loss: 0.11566833406686783, acc: 1.0)
[2025-02-17 17:05:17,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:17,879][root][INFO] - Training Epoch: 1/2, step 6897/107898 completed (loss: 0.4165129065513611, acc: 0.9166666865348816)
[2025-02-17 17:05:17,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:18,178][root][INFO] - Training Epoch: 1/2, step 6898/107898 completed (loss: 0.0023339265026152134, acc: 1.0)
[2025-02-17 17:05:18,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:18,476][root][INFO] - Training Epoch: 1/2, step 6899/107898 completed (loss: 0.600668728351593, acc: 0.8947368264198303)
[2025-02-17 17:05:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:18,796][root][INFO] - Training Epoch: 1/2, step 6900/107898 completed (loss: 0.019979897886514664, acc: 1.0)
[2025-02-17 17:05:18,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:19,147][root][INFO] - Training Epoch: 1/2, step 6901/107898 completed (loss: 0.06491415947675705, acc: 1.0)
[2025-02-17 17:05:19,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:19,504][root][INFO] - Training Epoch: 1/2, step 6902/107898 completed (loss: 2.04262638092041, acc: 0.6666666865348816)
[2025-02-17 17:05:19,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:19,833][root][INFO] - Training Epoch: 1/2, step 6903/107898 completed (loss: 3.0290184020996094, acc: 0.5)
[2025-02-17 17:05:19,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:20,177][root][INFO] - Training Epoch: 1/2, step 6904/107898 completed (loss: 0.026606477797031403, acc: 1.0)
[2025-02-17 17:05:20,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:20,527][root][INFO] - Training Epoch: 1/2, step 6905/107898 completed (loss: 8.346254348754883, acc: 0.0)
[2025-02-17 17:05:20,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:20,860][root][INFO] - Training Epoch: 1/2, step 6906/107898 completed (loss: 0.7103269100189209, acc: 0.5)
[2025-02-17 17:05:20,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:21,170][root][INFO] - Training Epoch: 1/2, step 6907/107898 completed (loss: 1.7295173406600952, acc: 0.739130437374115)
[2025-02-17 17:05:21,272][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:21,486][root][INFO] - Training Epoch: 1/2, step 6908/107898 completed (loss: 0.2453242838382721, acc: 1.0)
[2025-02-17 17:05:21,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:21,812][root][INFO] - Training Epoch: 1/2, step 6909/107898 completed (loss: 0.6095881462097168, acc: 0.8999999761581421)
[2025-02-17 17:05:21,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:22,120][root][INFO] - Training Epoch: 1/2, step 6910/107898 completed (loss: 4.137139320373535, acc: 0.5)
[2025-02-17 17:05:22,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:22,430][root][INFO] - Training Epoch: 1/2, step 6911/107898 completed (loss: 0.0738004520535469, acc: 1.0)
[2025-02-17 17:05:22,517][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:22,738][root][INFO] - Training Epoch: 1/2, step 6912/107898 completed (loss: 0.8133292198181152, acc: 0.8947368264198303)
[2025-02-17 17:05:22,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:23,095][root][INFO] - Training Epoch: 1/2, step 6913/107898 completed (loss: 1.3359744548797607, acc: 0.0)
[2025-02-17 17:05:23,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:23,376][root][INFO] - Training Epoch: 1/2, step 6914/107898 completed (loss: 2.329749584197998, acc: 0.5)
[2025-02-17 17:05:23,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:23,717][root][INFO] - Training Epoch: 1/2, step 6915/107898 completed (loss: 0.38419318199157715, acc: 1.0)
[2025-02-17 17:05:23,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:24,034][root][INFO] - Training Epoch: 1/2, step 6916/107898 completed (loss: 2.8605334758758545, acc: 0.5714285969734192)
[2025-02-17 17:05:24,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:24,336][root][INFO] - Training Epoch: 1/2, step 6917/107898 completed (loss: 0.04748459532856941, acc: 1.0)
[2025-02-17 17:05:24,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:24,637][root][INFO] - Training Epoch: 1/2, step 6918/107898 completed (loss: 1.7115012407302856, acc: 0.6666666865348816)
[2025-02-17 17:05:24,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:24,937][root][INFO] - Training Epoch: 1/2, step 6919/107898 completed (loss: 1.5864794254302979, acc: 0.6666666865348816)
[2025-02-17 17:05:25,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:25,256][root][INFO] - Training Epoch: 1/2, step 6920/107898 completed (loss: 0.1597534567117691, acc: 1.0)
[2025-02-17 17:05:25,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:25,538][root][INFO] - Training Epoch: 1/2, step 6921/107898 completed (loss: 0.2504999041557312, acc: 1.0)
[2025-02-17 17:05:25,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:25,840][root][INFO] - Training Epoch: 1/2, step 6922/107898 completed (loss: 1.5285415649414062, acc: 0.5)
[2025-02-17 17:05:25,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:26,137][root][INFO] - Training Epoch: 1/2, step 6923/107898 completed (loss: 5.121108531951904, acc: 0.3333333432674408)
[2025-02-17 17:05:26,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:26,445][root][INFO] - Training Epoch: 1/2, step 6924/107898 completed (loss: 4.510200500488281, acc: 0.21739129722118378)
[2025-02-17 17:05:26,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:26,709][root][INFO] - Training Epoch: 1/2, step 6925/107898 completed (loss: 0.33859431743621826, acc: 1.0)
[2025-02-17 17:05:26,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:27,016][root][INFO] - Training Epoch: 1/2, step 6926/107898 completed (loss: 4.211920261383057, acc: 0.375)
[2025-02-17 17:05:27,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:27,311][root][INFO] - Training Epoch: 1/2, step 6927/107898 completed (loss: 0.08821795135736465, acc: 1.0)
[2025-02-17 17:05:27,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:27,650][root][INFO] - Training Epoch: 1/2, step 6928/107898 completed (loss: 2.582960605621338, acc: 0.6666666865348816)
[2025-02-17 17:05:27,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:27,974][root][INFO] - Training Epoch: 1/2, step 6929/107898 completed (loss: 0.13573089241981506, acc: 1.0)
[2025-02-17 17:05:28,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:28,256][root][INFO] - Training Epoch: 1/2, step 6930/107898 completed (loss: 0.09838765859603882, acc: 1.0)
[2025-02-17 17:05:28,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:28,616][root][INFO] - Training Epoch: 1/2, step 6931/107898 completed (loss: 1.5711063146591187, acc: 0.7272727489471436)
[2025-02-17 17:05:28,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:28,950][root][INFO] - Training Epoch: 1/2, step 6932/107898 completed (loss: 0.7278501987457275, acc: 0.875)
[2025-02-17 17:05:29,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:29,276][root][INFO] - Training Epoch: 1/2, step 6933/107898 completed (loss: 0.6032034158706665, acc: 0.699999988079071)
[2025-02-17 17:05:29,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:29,576][root][INFO] - Training Epoch: 1/2, step 6934/107898 completed (loss: 0.7444396018981934, acc: 0.875)
[2025-02-17 17:05:29,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:29,914][root][INFO] - Training Epoch: 1/2, step 6935/107898 completed (loss: 0.26847466826438904, acc: 1.0)
[2025-02-17 17:05:30,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:05:30,252][root][INFO] - Training Epoch: 1/2, step 6936/107898 completed (loss: 2.0518786907196045, acc: 0.6363636255264282)
