model_config:
  llm_name: llama32_1b
  llm_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct
  llm_dim: 2048
  encoder_name: whisper
  normalize: true
  encoder_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt
  encoder2_name: ''
  encoder2_path: ''
  encoder_dim: 1280
  encoder_projector: linear
  encoder_projector_ds_rate: 5
  identifier: test_run_whisper_llama32_1b_linear_peft
dataset_config:
  normalize: true
  dataset: speech_dataset
  train_data_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/train.jsonl
  file: src/slam_llm/datasets/speech_dataset.py:get_speech_dataset
  val_data_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/validation.jsonl
  input_type: mel
  mel_size: 128
train_config:
  model_name: asr
  num_epochs: 4
  freeze_encoder: true
  freeze_encoder2: true
  freeze_llm: false
  batching_strategy: custom
  warmup_steps: 1000
  total_steps: 100000
  lr: 0.0001
  validation_interval: 2
  batch_size_training: 1
  val_batch_size: 1
  num_workers_dataloader: 1
  output_dir: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft
  use_fp16: true
  use_peft: true
  resume_epoch: 4
  resume_step: 5
log_config:
  use_wandb: true
  wandb_exp_name: test_run_whisper_llama32_1b_linear_peft
ckpt_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_4_step_5_loss_8.812807083129883/model.pt
