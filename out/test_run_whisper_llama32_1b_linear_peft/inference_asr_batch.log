[2025-02-15 19:25:37,563][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 19:25:37,563][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 19:25:37,563][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 19:25:58,822][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 19:25:58,824][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 19:25:58,827][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 19:25:58,828][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 19:26:02,768][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 19:26:02,769][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 19:26:02,770][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 19:26:02,888][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 19:26:02,890][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 19:26:03,028][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 19:26:03,028][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 19:26:03,029][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 19:26:03,504][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-15 19:26:03,507][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2025-02-15 19:26:06,337][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2025-02-15 19:26:06,564][root][INFO] - --> Training Set Length = 2
[2025-02-15 19:26:06,564][root][INFO] - =====================================
[2025-02-15 19:26:08,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-15 19:26:14,594][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_pred_20250215_192606
[2025-02-15 19:26:14,594][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_gt_20250215_192606
[2025-02-15 22:59:22,966][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 22:59:22,966][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 22:59:22,966][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 22:59:44,591][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 22:59:44,593][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 22:59:44,596][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 22:59:44,597][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 22:59:48,943][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 22:59:48,944][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 22:59:48,945][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 22:59:49,065][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 22:59:49,066][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 22:59:49,207][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 22:59:49,208][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 22:59:49,208][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 22:59:49,541][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-15 22:59:49,544][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2025-02-15 22:59:52,325][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2025-02-15 22:59:53,359][root][INFO] - --> Training Set Length = 2
[2025-02-15 22:59:53,359][root][INFO] - =====================================
[2025-02-15 22:59:55,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-15 23:00:02,437][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_pred_20250215_225953
[2025-02-15 23:00:02,437][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_gt_20250215_225953
[2025-02-15 23:18:51,058][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:18:51,058][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:18:51,058][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:19:13,032][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:19:13,034][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:19:13,037][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:19:13,038][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:19:17,567][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:19:17,569][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:19:17,570][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:19:17,695][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:19:17,697][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:19:17,838][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:19:17,838][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:19:17,839][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:19:18,098][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-15 23:19:18,101][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2025-02-15 23:19:20,819][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2025-02-15 23:19:21,285][root][INFO] - --> Training Set Length = 2
[2025-02-15 23:19:21,286][root][INFO] - =====================================
[2025-02-15 23:19:22,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-15 23:19:29,288][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_pred_20250215_231921
[2025-02-15 23:19:29,289][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_gt_20250215_231921
[2025-02-15 23:20:23,515][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:20:23,516][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:20:23,516][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:20:45,207][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:20:45,209][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:20:45,211][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:20:45,212][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:20:49,444][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:20:49,445][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:20:49,446][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:20:49,583][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:20:49,585][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:20:49,731][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:20:49,732][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:20:49,732][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:20:50,000][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-15 23:20:50,004][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2025-02-15 23:20:53,122][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2025-02-15 23:20:53,406][root][INFO] - --> Training Set Length = 2
[2025-02-15 23:20:53,407][root][INFO] - =====================================
[2025-02-15 23:20:55,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-15 23:21:01,798][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_pred_20250215_232053
[2025-02-15 23:21:01,799][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_gt_20250215_232053
[2025-02-15 23:27:03,374][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:27:03,374][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:27:03,375][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:27:25,693][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:27:25,696][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:27:25,698][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:27:25,699][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:27:29,634][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:27:29,634][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:27:29,635][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:27:29,758][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:27:29,760][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:27:29,907][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:27:29,908][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:27:29,908][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:27:30,208][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-15 23:27:30,212][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2025-02-15 23:27:32,744][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2025-02-15 23:27:32,993][root][INFO] - --> Training Set Length = 2
[2025-02-15 23:27:32,994][root][INFO] - =====================================
[2025-02-15 23:27:34,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-15 23:27:41,425][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_pred_test_run_whisper_llama32_1b_linear_peft_20250215_232732
[2025-02-15 23:27:41,425][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_gt_test_run_whisper_llama32_1b_linear_peft_20250215_232732
[2025-02-15 23:41:44,227][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:41:44,227][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:41:44,227][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:42:25,804][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:42:25,812][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:42:25,819][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:42:25,822][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:42:32,670][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:42:32,671][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:42:32,673][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:42:32,962][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:42:32,965][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:42:33,276][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:42:33,277][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:42:33,278][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:42:33,630][slam_model_asr.py][ERROR] - Checkpoint and model state_dict mismatch:
[2025-02-15 23:42:33,631][slam_model_asr.py][ERROR] - Missing keys: {'encoder.blocks.2.attn_ln.bias', 'llm.base_model.model.model.layers.15.self_attn.k_proj.weight', 'encoder.blocks.14.mlp.0.weight', 'encoder.blocks.0.mlp.2.bias', 'llm.base_model.model.model.layers.9.self_attn.o_proj.weight', 'encoder.blocks.15.mlp.0.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.weight', 'encoder.blocks.7.mlp.2.bias', 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.29.attn.value.bias', 'encoder.blocks.12.attn_ln.weight', 'encoder.blocks.23.attn.value.bias', 'encoder.blocks.12.mlp_ln.weight', 'encoder.blocks.19.attn.out.weight', 'encoder.blocks.1.attn.query.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.23.attn.query.bias', 'encoder.blocks.5.attn.out.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.23.mlp.0.bias', 'encoder.blocks.26.attn_ln.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.21.mlp.2.weight', 'encoder.blocks.15.attn.value.weight', 'encoder.blocks.18.attn.out.weight', 'encoder.blocks.11.mlp.0.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.17.mlp.2.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.23.attn.out.weight', 'encoder.blocks.5.attn.query.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.25.mlp_ln.weight', 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.5.attn_ln.bias', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.25.attn.value.bias', 'encoder.blocks.4.attn.query.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.15.input_layernorm.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.0.attn_ln.weight', 'encoder.blocks.12.attn.query.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.13.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.6.input_layernorm.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'encoder.conv2.bias', 'llm.base_model.model.model.layers.4.self_attn.k_proj.weight', 'encoder.blocks.18.attn.value.bias', 'llm.base_model.model.model.layers.3.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.11.mlp.up_proj.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.weight', 'encoder.blocks.17.mlp.0.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.input_layernorm.weight', 'encoder.blocks.9.mlp.2.bias', 'llm.base_model.model.model.layers.14.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.post_attention_layernorm.weight', 'encoder.positional_embedding', 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.15.attn.query.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.21.mlp_ln.weight', 'encoder.blocks.31.mlp_ln.bias', 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.10.attn.out.bias', 'encoder.blocks.7.mlp.0.bias', 'encoder.blocks.22.mlp_ln.weight', 'encoder.blocks.15.mlp_ln.weight', 'encoder.blocks.26.mlp.0.weight', 'encoder.blocks.31.mlp.2.bias', 'llm.base_model.model.model.layers.3.input_layernorm.weight', 'encoder.blocks.23.attn.query.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.weight', 'encoder.blocks.8.attn_ln.bias', 'llm.base_model.model.model.layers.4.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.18.mlp.0.bias', 'encoder.blocks.2.mlp.0.weight', 'encoder.blocks.24.attn.query.weight', 'encoder.blocks.29.mlp.2.bias', 'encoder.blocks.0.attn.out.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.14.attn.out.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.weight', 'encoder.blocks.25.attn.out.bias', 'encoder.blocks.29.mlp_ln.bias', 'llm.base_model.model.model.layers.2.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.3.mlp.0.bias', 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.14.attn.key.weight', 'encoder.blocks.9.mlp.0.bias', 'llm.base_model.model.model.layers.12.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.weight', 'encoder.blocks.29.attn.value.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.21.attn.value.weight', 'encoder.blocks.26.attn.query.bias', 'encoder.blocks.30.attn.value.weight', 'encoder.blocks.21.attn.value.bias', 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.25.mlp.0.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.input_layernorm.weight', 'encoder.blocks.26.attn.query.weight', 'encoder.blocks.5.mlp.0.bias', 'encoder.blocks.25.attn.key.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.13.attn_ln.weight', 'encoder.blocks.24.attn.value.weight', 'encoder.blocks.10.mlp_ln.bias', 'encoder.blocks.28.attn.value.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.5.mlp_ln.weight', 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.17.attn_ln.bias', 'encoder.blocks.14.mlp.2.bias', 'encoder.blocks.14.mlp.0.bias', 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.5.attn.query.bias', 'encoder.blocks.14.attn.value.bias', 'encoder.blocks.0.attn.key.weight', 'encoder.blocks.22.mlp.2.weight', 'encoder.blocks.30.attn.key.weight', 'encoder.blocks.29.mlp.0.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.4.mlp_ln.weight', 'encoder.blocks.6.mlp.2.weight', 'encoder.blocks.12.mlp.0.bias', 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.17.mlp.2.bias', 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.19.attn.query.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.weight', 'encoder.blocks.8.attn_ln.weight', 'encoder.blocks.0.mlp_ln.bias', 'encoder.blocks.21.attn.out.bias', 'encoder.blocks.28.attn_ln.bias', 'encoder.blocks.20.attn.value.weight', 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.input_layernorm.weight', 'encoder.blocks.8.attn.value.bias', 'encoder.blocks.11.attn.value.bias', 'encoder.blocks.2.attn.out.weight', 'encoder.blocks.17.attn.key.weight', 'encoder.blocks.28.attn.key.weight', 'llm.base_model.model.model.layers.8.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.3.attn.value.bias', 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.weight', 'encoder.blocks.3.attn.query.bias', 'encoder.blocks.14.mlp.2.weight', 'llm.base_model.model.model.layers.13.mlp.up_proj.weight', 'encoder.ln_post.bias', 'encoder.blocks.29.mlp.2.weight', 'encoder.blocks.15.attn_ln.weight', 'encoder.blocks.31.attn.key.weight', 'encoder.blocks.3.attn.out.bias', 'llm.base_model.model.model.layers.0.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.embed_tokens.weight', 'llm.base_model.model.model.layers.10.input_layernorm.weight', 'encoder.blocks.23.mlp.0.weight', 'encoder.blocks.15.attn.query.bias', 'encoder.blocks.13.mlp.0.weight', 'encoder.blocks.2.attn.query.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.30.attn_ln.bias', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.20.mlp_ln.weight', 'encoder.blocks.6.attn.value.bias', 'encoder.blocks.31.attn.value.weight', 'encoder.blocks.0.mlp_ln.weight', 'encoder.blocks.3.mlp.2.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.weight', 'encoder.blocks.17.attn.query.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.31.mlp.0.bias', 'llm.base_model.model.model.layers.1.self_attn.q_proj.weight', 'encoder.blocks.29.attn.query.bias', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.3.mlp_ln.bias', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.9.mlp_ln.weight', 'encoder.blocks.8.attn.query.weight', 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.9.attn.out.weight', 'encoder.blocks.30.mlp_ln.weight', 'encoder.blocks.30.attn.value.bias', 'encoder.blocks.18.mlp.2.weight', 'encoder.blocks.4.mlp.2.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.8.mlp.2.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.weight', 'encoder.blocks.0.mlp.2.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.weight', 'encoder.blocks.23.attn.key.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.12.mlp_ln.bias', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.14.mlp_ln.bias', 'encoder.blocks.23.attn.value.weight', 'encoder.blocks.11.attn.out.bias', 'encoder.blocks.30.attn.out.bias', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.19.attn_ln.bias', 'encoder.blocks.28.attn_ln.weight', 'encoder.blocks.25.attn.out.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.14.attn_ln.bias', 'encoder.blocks.7.mlp.0.weight', 'encoder.blocks.15.mlp.0.bias', 'encoder.blocks.26.attn.out.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.19.mlp.0.weight', 'encoder.blocks.11.mlp_ln.bias', 'encoder.blocks.24.mlp.0.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.26.mlp.0.bias', 'encoder.blocks.10.attn.query.bias', 'encoder.blocks.27.attn.query.weight', 'llm.base_model.model.model.layers.7.post_attention_layernorm.weight', 'encoder.blocks.19.attn.value.bias', 'encoder.blocks.28.mlp.0.weight', 'encoder.blocks.28.attn.query.bias', 'encoder.blocks.30.mlp.0.bias', 'encoder.blocks.16.attn.value.weight', 'encoder.blocks.0.attn.query.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.15.mlp_ln.bias', 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.4.attn.query.bias', 'encoder.blocks.13.attn.out.weight', 'encoder.blocks.18.mlp.0.weight', 'encoder.blocks.12.attn_ln.bias', 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.11.mlp.2.weight', 'encoder.blocks.17.mlp_ln.weight', 'encoder.blocks.1.mlp.0.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.11.attn.value.weight', 'encoder.blocks.7.mlp_ln.bias', 'encoder.blocks.26.attn_ln.bias', 'llm.base_model.model.model.layers.5.self_attn.o_proj.weight', 'encoder.blocks.19.attn.out.bias', 'llm.base_model.model.model.layers.12.self_attn.k_proj.weight', 'encoder.blocks.10.mlp_ln.weight', 'encoder.blocks.19.attn.value.weight', 'encoder.blocks.9.attn_ln.bias', 'llm.base_model.model.model.layers.14.mlp.up_proj.weight', 'encoder.blocks.31.attn_ln.weight', 'encoder.blocks.11.attn.out.weight', 'encoder.blocks.8.attn.out.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.gate_proj.weight', 'encoder.blocks.3.attn_ln.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.13.mlp.2.weight', 'encoder.blocks.22.attn.key.weight', 'encoder.blocks.24.mlp_ln.bias', 'llm.base_model.model.model.layers.2.self_attn.o_proj.weight', 'encoder.blocks.8.attn.query.bias', 'encoder.blocks.14.attn.query.bias', 'llm.base_model.model.model.layers.2.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.28.mlp_ln.bias', 'encoder.blocks.23.mlp_ln.bias', 'encoder.blocks.25.attn.query.weight', 'llm.base_model.model.model.layers.7.input_layernorm.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.weight', 'encoder.blocks.31.attn.query.bias', 'encoder.blocks.9.mlp.0.weight', 'encoder.blocks.28.attn.query.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.5.attn.out.bias', 'encoder.blocks.19.mlp_ln.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.26.attn.key.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.11.mlp.2.bias', 'encoder.blocks.11.mlp_ln.weight', 'llm.base_model.model.model.layers.6.self_attn.o_proj.weight', 'encoder.blocks.2.mlp.2.bias', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.10.mlp.0.bias', 'encoder.blocks.24.attn.out.weight', 'encoder.blocks.16.attn.query.bias', 'encoder.blocks.25.mlp.2.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.0.attn.value.weight', 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.weight', 'encoder.blocks.19.mlp_ln.bias', 'encoder.blocks.1.attn.query.bias', 'encoder.blocks.7.attn.query.bias', 'llm.base_model.model.model.layers.0.self_attn.v_proj.weight', 'encoder.blocks.11.attn.query.bias', 'encoder.blocks.22.attn_ln.weight', 'encoder.ln_post.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.weight', 'encoder.blocks.22.mlp.0.weight', 'encoder.blocks.3.attn.out.weight', 'encoder.blocks.27.attn_ln.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.12.attn.key.weight', 'encoder.blocks.2.mlp.0.bias', 'llm.base_model.model.model.layers.12.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.1.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.22.mlp_ln.bias', 'encoder.blocks.24.attn.out.bias', 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'encoder_projector.linear1.weight', 'encoder.blocks.23.attn_ln.bias', 'encoder.blocks.7.mlp.2.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.weight', 'encoder.blocks.9.attn.query.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.weight', 'encoder.blocks.19.mlp.0.bias', 'encoder.blocks.12.attn.out.bias', 'encoder.blocks.10.mlp.2.bias', 'encoder.blocks.11.attn.key.weight', 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.20.attn.out.bias', 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.6.mlp.2.bias', 'encoder.blocks.26.attn.out.bias', 'encoder.blocks.24.mlp.2.bias', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.5.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.1.mlp.2.weight', 'encoder.blocks.9.attn.key.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.weight', 'encoder.blocks.10.attn.value.bias', 'encoder.blocks.31.attn.out.bias', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.30.attn_ln.weight', 'encoder.blocks.25.mlp.0.bias', 'llm.base_model.model.model.layers.2.input_layernorm.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.21.attn.query.weight', 'encoder.blocks.17.attn.value.bias', 'encoder.blocks.27.attn.value.weight', 'encoder.blocks.4.attn.out.weight', 'encoder.blocks.29.attn.key.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.21.attn.key.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.2.mlp_ln.weight', 'encoder.blocks.6.attn.out.bias', 'encoder.blocks.7.attn_ln.bias', 'encoder.blocks.27.attn.key.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.25.attn.value.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.9.mlp_ln.bias', 'encoder.blocks.2.attn.query.bias', 'encoder.blocks.3.mlp_ln.weight', 'encoder.conv2.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.21.mlp.0.bias', 'encoder.blocks.2.attn.key.weight', 'encoder.blocks.2.mlp.2.weight', 'encoder.blocks.1.mlp.2.bias', 'encoder.blocks.22.attn.query.weight', 'encoder.blocks.7.attn.value.weight', 'encoder.blocks.29.attn.out.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.24.mlp_ln.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.23.mlp.2.bias', 'encoder.blocks.29.mlp.0.bias', 'llm.base_model.model.model.layers.8.mlp.up_proj.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.22.mlp.0.bias', 'encoder.blocks.28.attn.out.weight', 'encoder.blocks.1.attn.out.bias', 'encoder.blocks.10.attn.query.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.14.mlp_ln.weight', 'encoder.blocks.25.attn_ln.bias', 'encoder.blocks.5.mlp.2.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.15.mlp.up_proj.weight', 'encoder.blocks.6.attn.query.bias', 'llm.base_model.model.model.layers.5.input_layernorm.weight', 'encoder.blocks.10.mlp.0.weight', 'encoder.blocks.13.mlp.2.bias', 'llm.base_model.model.model.layers.10.mlp.gate_proj.weight', 'encoder.blocks.6.mlp.0.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.norm.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.7.attn.key.weight', 'encoder.blocks.23.attn_ln.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.5.attn.value.bias', 'encoder.blocks.16.attn.query.weight', 'encoder.blocks.13.mlp.0.bias', 'encoder.blocks.23.mlp_ln.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.11.attn_ln.weight', 'encoder.blocks.16.mlp.0.weight', 'encoder.blocks.27.mlp_ln.weight', 'encoder.blocks.29.attn_ln.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.29.attn_ln.bias', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.20.mlp.2.weight', 'encoder.blocks.30.attn.query.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.weight', 'encoder.blocks.20.attn_ln.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.weight', 'llm.base_model.model.model.layers.9.post_attention_layernorm.weight', 'encoder.blocks.1.mlp_ln.weight', 'encoder.blocks.10.attn_ln.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.weight', 'encoder.blocks.24.attn.query.bias', 'llm.base_model.model.model.layers.11.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.31.mlp_ln.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.9.attn.query.bias', 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.9.attn.out.bias', 'llm.base_model.model.model.layers.7.mlp.up_proj.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.weight', 'encoder.blocks.10.mlp.2.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.weight', 'encoder_projector.linear1.bias', 'encoder.blocks.23.mlp.2.weight', 'encoder.blocks.27.mlp_ln.bias', 'encoder.blocks.7.attn.out.weight', 'llm.base_model.model.model.layers.4.input_layernorm.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'encoder.conv1.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.weight', 'encoder.blocks.30.mlp.2.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.15.attn.value.bias', 'encoder.blocks.4.mlp.0.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.weight', 'encoder.blocks.16.attn.out.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.3.mlp.0.weight', 'encoder.blocks.0.mlp.0.weight', 'llm.base_model.model.model.layers.15.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.18.attn.query.bias', 'encoder.blocks.18.mlp_ln.bias', 'encoder.blocks.21.attn_ln.bias', 'encoder.blocks.6.attn.out.weight', 'encoder.blocks.13.attn.query.bias', 'encoder.blocks.17.attn.value.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.weight', 'encoder.blocks.8.mlp.0.bias', 'encoder.blocks.16.mlp.2.weight', 'encoder.blocks.8.mlp_ln.bias', 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.weight', 'encoder.blocks.2.attn_ln.weight', 'encoder.blocks.17.mlp.0.bias', 'llm.base_model.model.model.layers.3.self_attn.o_proj.weight', 'encoder.blocks.13.attn.value.bias', 'encoder.blocks.16.attn.value.bias', 'llm.base_model.model.model.layers.6.mlp.gate_proj.weight', 'encoder.blocks.21.attn_ln.weight', 'encoder.blocks.10.attn.value.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.3.attn.query.weight', 'encoder.blocks.9.attn.value.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.30.mlp.0.weight', 'encoder.blocks.27.mlp.0.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.20.attn.query.weight', 'encoder.blocks.12.attn.value.weight', 'encoder.blocks.27.attn.value.bias', 'encoder.blocks.27.attn.out.weight', 'encoder.blocks.28.attn.value.bias', 'encoder.blocks.29.attn.out.bias', 'encoder.blocks.20.attn.value.bias', 'encoder.blocks.19.mlp.2.weight', 'encoder.blocks.1.mlp.0.bias', 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.13.attn.out.bias', 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.28.mlp_ln.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.9.input_layernorm.weight', 'encoder.blocks.9.attn_ln.weight', 'encoder.blocks.28.attn.out.bias', 'encoder.blocks.20.attn.key.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.21.mlp.2.bias', 'encoder.blocks.19.attn_ln.weight', 'encoder.blocks.20.attn.out.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.lm_head.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.weight', 'encoder.blocks.25.mlp.2.bias', 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.6.attn.query.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.31.attn.out.weight', 'encoder.blocks.4.attn.key.weight', 'encoder.blocks.18.attn_ln.bias', 'encoder.blocks.11.attn_ln.bias', 'llm.base_model.model.model.layers.1.post_attention_layernorm.weight', 'encoder.blocks.13.attn_ln.bias', 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.5.attn.key.weight', 'encoder.blocks.12.attn.out.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.13.input_layernorm.weight', 'encoder.blocks.7.mlp_ln.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.input_layernorm.weight', 'encoder_projector.linear2.bias', 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.26.mlp_ln.bias', 'encoder.blocks.18.attn.query.weight', 'encoder.blocks.26.attn.value.weight', 'llm.base_model.model.model.layers.12.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.31.attn_ln.bias', 'encoder.blocks.10.attn.key.weight', 'encoder.blocks.6.mlp_ln.bias', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.15.mlp.2.bias', 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.20.attn_ln.bias', 'encoder.blocks.9.mlp.2.weight', 'encoder.blocks.16.mlp.0.bias', 'llm.base_model.model.model.layers.12.input_layernorm.weight', 'encoder.blocks.8.attn.value.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.weight', 'encoder.blocks.3.attn.key.weight', 'encoder.blocks.9.attn.value.bias', 'encoder.blocks.17.attn.query.bias', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.4.mlp.2.bias', 'encoder.blocks.1.attn.out.weight', 'encoder.blocks.12.mlp.0.weight', 'encoder.blocks.4.attn_ln.weight', 'encoder.blocks.4.attn.value.bias', 'encoder.blocks.27.attn_ln.bias', 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.29.mlp_ln.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.10.post_attention_layernorm.weight', 'encoder.blocks.10.attn_ln.bias', 'encoder.blocks.6.attn_ln.bias', 'llm.base_model.model.model.layers.3.mlp.up_proj.weight', 'encoder.blocks.5.mlp_ln.bias', 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.15.mlp.2.weight', 'llm.base_model.model.model.layers.0.mlp.up_proj.weight', 'encoder.blocks.4.attn.value.weight', 'encoder.blocks.18.mlp.2.bias', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.6.attn.key.weight', 'encoder.blocks.16.mlp.2.bias', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.weight', 'encoder.blocks.3.attn_ln.bias', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.13.attn.query.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.weight', 'encoder.blocks.17.mlp_ln.bias', 'encoder.blocks.5.attn.value.weight', 'encoder.blocks.6.attn.value.weight', 'encoder.blocks.15.attn.out.weight', 'encoder.blocks.20.mlp_ln.bias', 'encoder.blocks.27.mlp.2.bias', 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.20.attn.query.bias', 'encoder.blocks.13.attn.key.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.12.mlp.2.bias', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.31.mlp.2.weight', 'encoder.blocks.16.attn_ln.bias', 'encoder.blocks.18.attn.value.weight', 'encoder.blocks.5.attn_ln.weight', 'encoder.blocks.30.mlp.2.bias', 'llm.base_model.model.model.layers.2.mlp.up_proj.weight', 'encoder.blocks.18.attn.out.bias', 'llm.base_model.model.model.layers.8.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.5.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.21.attn.query.bias', 'encoder.blocks.20.mlp.0.weight', 'encoder.blocks.30.attn.out.weight', 'encoder.blocks.18.mlp_ln.weight', 'encoder.blocks.12.attn.value.bias', 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.3.attn.value.weight', 'encoder.blocks.6.attn_ln.weight', 'encoder.conv1.bias', 'llm.base_model.model.model.layers.13.self_attn.o_proj.weight', 'encoder.blocks.1.attn.key.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.weight', 'llm.base_model.model.model.layers.14.input_layernorm.weight', 'encoder.blocks.14.attn.query.weight', 'encoder.blocks.22.attn.value.weight', 'encoder.blocks.29.attn.query.weight', 'llm.base_model.model.model.layers.3.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.weight', 'encoder.blocks.1.attn_ln.bias', 'encoder.blocks.7.attn.out.bias', 'encoder.blocks.15.attn.out.bias', 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.28.mlp.2.weight', 'encoder.blocks.21.mlp_ln.bias', 'encoder.blocks.22.attn.out.weight', 'encoder.blocks.27.attn.query.bias', 'encoder.blocks.8.attn.key.weight', 'encoder.blocks.8.mlp_ln.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.2.attn.value.bias', 'encoder.blocks.0.attn.out.bias', 'encoder.blocks.28.mlp.0.bias', 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.7.attn.query.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.25.attn.query.bias', 'encoder.blocks.16.attn.out.bias', 'encoder.blocks.21.mlp.0.weight', 'encoder.blocks.27.mlp.0.bias', 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.8.mlp.0.weight', 'encoder.blocks.22.mlp.2.bias', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.7.attn_ln.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.24.attn.key.weight', 'encoder.blocks.18.attn.key.weight', 'encoder.blocks.14.attn_ln.weight', 'encoder.blocks.4.attn_ln.bias', 'encoder.blocks.7.attn.value.bias', 'encoder.blocks.13.mlp_ln.bias', 'encoder.blocks.30.attn.query.bias', 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.4.mlp.0.bias', 'llm.base_model.model.model.layers.2.mlp.down_proj.weight', 'encoder.blocks.17.attn.out.bias', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.8.mlp.2.bias', 'llm.base_model.model.model.layers.1.self_attn.o_proj.weight', 'encoder.blocks.19.mlp.2.bias', 'encoder.blocks.24.mlp.2.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.16.attn.key.weight', 'encoder.blocks.13.attn.value.weight', 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.weight', 'encoder.blocks.1.attn_ln.weight', 'encoder.blocks.26.mlp_ln.weight', 'encoder.blocks.20.mlp.0.bias', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.24.attn_ln.weight', 'encoder.blocks.4.attn.out.bias', 'encoder.blocks.21.attn.out.weight', 'encoder.blocks.30.mlp_ln.bias', 'encoder.blocks.11.attn.query.weight', 'encoder.blocks.26.attn.value.bias', 'encoder.blocks.26.mlp.2.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.k_proj.weight', 'encoder.blocks.27.mlp.2.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.4.mlp_ln.bias', 'encoder.blocks.31.mlp.0.weight', 'encoder.blocks.10.attn.out.weight', 'encoder.blocks.11.mlp.0.bias', 'encoder.blocks.2.mlp_ln.bias', 'encoder.blocks.1.attn.value.weight', 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.weight', 'encoder.blocks.22.attn.value.bias', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.16.mlp_ln.bias', 'llm.base_model.model.model.layers.10.self_attn.o_proj.weight', 'encoder.blocks.6.mlp_ln.weight', 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.0.mlp.0.bias', 'llm.base_model.model.model.layers.10.mlp.down_proj.weight', 'encoder.blocks.28.mlp.2.bias', 'llm.base_model.model.model.layers.12.mlp.up_proj.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.27.attn.out.bias', 'encoder.blocks.16.mlp_ln.weight', 'encoder.blocks.22.attn_ln.bias', 'encoder.blocks.25.attn_ln.weight', 'encoder.blocks.31.attn.query.weight', 'encoder.blocks.5.mlp.0.weight', 'encoder.blocks.18.attn_ln.weight', 'encoder.blocks.17.attn_ln.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.weight', 'encoder.blocks.26.mlp.2.bias', 'encoder.blocks.24.attn_ln.bias', 'encoder.blocks.19.attn.query.bias', 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.weight', 'encoder.blocks.15.attn.key.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'encoder_projector.linear2.weight', 'encoder.blocks.15.attn_ln.bias', 'encoder.blocks.22.attn.out.bias', 'encoder.blocks.16.attn_ln.weight', 'encoder.blocks.0.attn.value.bias', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.20.mlp.2.bias', 'encoder.blocks.25.mlp_ln.bias', 'encoder.blocks.8.attn.out.bias', 'encoder.blocks.2.attn.out.bias', 'encoder.blocks.24.attn.value.bias', 'encoder.blocks.0.attn_ln.bias', 'encoder.blocks.6.mlp.0.bias', 'llm.base_model.model.model.layers.3.mlp.down_proj.weight', 'llm.base_model.model.model.layers.5.mlp.up_proj.weight', 'encoder.blocks.19.attn.key.weight', 'encoder.blocks.0.attn.query.bias', 'encoder.blocks.23.attn.out.bias', 'encoder.blocks.2.attn.value.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.14.attn.value.weight', 'encoder.blocks.17.attn.out.weight', 'encoder.blocks.12.attn.query.bias', 'encoder.blocks.13.mlp_ln.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.31.attn.value.bias', 'llm.base_model.model.model.layers.11.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.1.mlp_ln.bias', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.3.mlp.2.bias', 'encoder.blocks.12.mlp.2.weight', 'encoder.blocks.14.attn.out.bias', 'encoder.blocks.22.attn.query.bias', 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.weight', 'encoder.blocks.1.attn.value.bias', 'encoder.blocks.24.mlp.0.bias', 'encoder.blocks.5.mlp.2.bias'}
[2025-02-15 23:42:33,635][slam_model_asr.py][ERROR] - Unexpected keys: {'best_val_loss', 'lr_scheduler_state', 'random_state', 'model', 'scaler_state', 'epoch', 'best_val_acc', 'config', 'step', 'cuda_random_state', 'optimizer_state'}
[2025-02-15 23:42:33,635][slam_model_asr.py][ERROR] - Error loading checkpoint from /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt: Checkpoint does not match model architecture. Missing or unexpected keys.
[2025-02-15 23:47:29,355][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:47:29,356][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:47:29,356][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:47:52,140][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:47:52,143][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:47:52,145][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:47:52,146][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:47:56,592][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:47:56,594][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:47:56,596][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:47:56,722][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:47:56,723][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:47:56,865][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:47:56,865][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:47:56,865][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:47:57,175][slam_model_asr.py][ERROR] - Checkpoint and model state_dict mismatch:
[2025-02-15 23:47:57,175][slam_model_asr.py][ERROR] - Missing keys: {'encoder.blocks.27.attn.out.bias', 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.4.attn.key.weight', 'encoder.blocks.22.mlp_ln.weight', 'encoder.blocks.26.attn.out.bias', 'encoder.blocks.2.attn.value.weight', 'encoder.blocks.19.mlp.0.bias', 'llm.base_model.model.model.layers.11.mlp.up_proj.weight', 'encoder.blocks.26.mlp.0.bias', 'encoder.blocks.24.attn.query.bias', 'encoder.blocks.1.mlp_ln.bias', 'encoder.blocks.0.attn_ln.weight', 'encoder.blocks.2.attn.query.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.1.attn.key.weight', 'llm.base_model.model.model.layers.12.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.weight', 'encoder.blocks.5.attn.out.weight', 'encoder.blocks.21.attn.out.bias', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.weight', 'encoder.blocks.15.attn.out.weight', 'encoder.blocks.21.attn.value.bias', 'llm.base_model.model.model.layers.12.input_layernorm.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.weight', 'encoder.blocks.21.attn.key.weight', 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.1.mlp_ln.weight', 'encoder.blocks.21.attn.query.weight', 'llm.base_model.model.model.layers.0.input_layernorm.weight', 'encoder.blocks.15.mlp.2.weight', 'llm.base_model.model.model.layers.5.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.11.mlp.0.weight', 'encoder.blocks.15.attn.out.bias', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.16.attn.query.weight', 'encoder.blocks.12.attn.query.bias', 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.23.attn_ln.bias', 'encoder.blocks.12.attn.value.weight', 'encoder.blocks.24.attn.out.bias', 'encoder.blocks.11.attn.value.weight', 'encoder.blocks.13.attn.query.weight', 'encoder.blocks.15.mlp.0.bias', 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.weight', 'encoder.blocks.29.mlp.0.bias', 'llm.base_model.model.model.layers.14.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.weight', 'encoder.blocks.24.attn.out.weight', 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.weight', 'encoder.blocks.3.mlp_ln.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.0.mlp.2.bias', 'encoder.blocks.17.attn.key.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.7.attn.query.bias', 'llm.base_model.model.model.layers.4.post_attention_layernorm.weight', 'encoder.conv1.weight', 'encoder.blocks.0.attn.value.weight', 'encoder.blocks.23.mlp_ln.weight', 'encoder.blocks.31.attn.query.weight', 'encoder.blocks.27.attn.query.bias', 'llm.base_model.model.model.layers.11.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.13.post_attention_layernorm.weight', 'encoder.blocks.1.attn.value.weight', 'encoder.blocks.22.attn_ln.weight', 'encoder.blocks.25.attn.out.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.3.attn_ln.bias', 'encoder.blocks.16.attn.query.bias', 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.input_layernorm.weight', 'encoder.blocks.12.mlp.2.bias', 'llm.base_model.model.model.layers.5.mlp.gate_proj.weight', 'encoder.blocks.11.attn.out.bias', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.9.attn.out.bias', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.26.mlp.0.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.weight', 'encoder.blocks.14.attn.value.bias', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.5.attn.out.bias', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.31.mlp_ln.weight', 'encoder.blocks.2.mlp.2.weight', 'encoder.blocks.29.attn.value.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.input_layernorm.weight', 'encoder.blocks.9.mlp_ln.weight', 'encoder.blocks.2.attn.out.bias', 'encoder.blocks.29.attn.out.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.24.mlp_ln.bias', 'encoder.blocks.6.mlp_ln.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.9.attn_ln.bias', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.10.attn.key.weight', 'encoder.blocks.26.attn_ln.bias', 'encoder.blocks.7.attn.out.bias', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.27.mlp_ln.weight', 'encoder.blocks.4.mlp.0.bias', 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.weight', 'encoder.blocks.28.attn.query.bias', 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.9.attn.value.bias', 'encoder.blocks.10.mlp.2.bias', 'encoder.blocks.9.mlp.2.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.weight', 'encoder.blocks.16.attn.out.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.weight', 'encoder.blocks.22.mlp.2.bias', 'llm.base_model.model.model.layers.2.post_attention_layernorm.weight', 'encoder.blocks.18.attn.out.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.18.mlp.0.weight', 'encoder.blocks.13.attn.query.bias', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.weight', 'encoder.blocks.30.attn.out.bias', 'llm.base_model.model.model.layers.1.mlp.up_proj.weight', 'encoder.blocks.1.attn.query.weight', 'encoder.blocks.5.attn.query.bias', 'llm.base_model.model.model.layers.3.mlp.up_proj.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.weight', 'encoder.blocks.17.attn.query.bias', 'encoder.blocks.22.attn.out.weight', 'llm.base_model.model.model.layers.2.input_layernorm.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.weight', 'encoder.blocks.29.attn_ln.bias', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.29.mlp_ln.bias', 'llm.base_model.model.model.layers.11.input_layernorm.weight', 'encoder.blocks.0.mlp.2.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.14.mlp_ln.bias', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.input_layernorm.weight', 'encoder.blocks.13.mlp.0.weight', 'encoder.blocks.3.attn.query.bias', 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.6.attn.value.bias', 'encoder.blocks.16.mlp_ln.bias', 'llm.base_model.model.model.layers.8.input_layernorm.weight', 'llm.base_model.model.model.layers.1.mlp.gate_proj.weight', 'encoder.blocks.31.attn_ln.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.9.attn_ln.weight', 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.10.mlp.2.weight', 'encoder.blocks.25.attn.query.bias', 'encoder.blocks.11.mlp_ln.bias', 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.11.attn.query.weight', 'encoder.blocks.11.attn_ln.weight', 'encoder.blocks.20.mlp.2.bias', 'encoder.blocks.5.attn_ln.bias', 'llm.base_model.model.model.layers.11.mlp.gate_proj.weight', 'encoder.blocks.5.mlp.0.weight', 'encoder_projector.linear2.bias', 'encoder.blocks.18.mlp_ln.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.3.attn.out.weight', 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.1.attn_ln.bias', 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.19.attn.query.weight', 'encoder.blocks.10.attn_ln.bias', 'llm.base_model.model.model.layers.2.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.17.mlp.2.weight', 'encoder.blocks.8.mlp_ln.weight', 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.embed_tokens.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.weight', 'encoder.blocks.6.mlp.2.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.8.mlp_ln.bias', 'encoder.blocks.12.attn.key.weight', 'encoder.blocks.17.mlp_ln.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.24.mlp_ln.weight', 'encoder.blocks.30.mlp_ln.bias', 'encoder.conv2.bias', 'encoder.blocks.0.attn.key.weight', 'encoder.blocks.11.mlp.2.weight', 'encoder.blocks.27.mlp.2.weight', 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.27.mlp.2.bias', 'llm.base_model.model.model.layers.0.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.weight', 'encoder.blocks.7.mlp.2.weight', 'encoder.blocks.17.attn_ln.bias', 'encoder.blocks.1.attn_ln.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.29.mlp.2.bias', 'llm.base_model.model.model.layers.5.self_attn.q_proj.weight', 'encoder.blocks.26.attn.value.bias', 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.10.mlp_ln.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.weight', 'encoder.blocks.0.attn.query.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.8.post_attention_layernorm.weight', 'encoder.blocks.7.attn.query.weight', 'encoder.blocks.12.attn_ln.weight', 'llm.base_model.model.model.layers.4.mlp.gate_proj.weight', 'encoder.blocks.7.mlp.0.bias', 'encoder.blocks.28.mlp_ln.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.weight', 'encoder.blocks.22.attn.value.bias', 'encoder.blocks.16.mlp.2.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.23.attn.value.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.0.attn.out.bias', 'llm.base_model.model.model.layers.12.mlp.gate_proj.weight', 'encoder.blocks.4.mlp_ln.bias', 'encoder.blocks.20.mlp_ln.weight', 'encoder.blocks.6.attn.out.bias', 'encoder.blocks.12.attn.out.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.17.attn.query.weight', 'encoder.blocks.25.mlp.2.weight', 'encoder.blocks.25.attn_ln.weight', 'encoder.blocks.22.attn.key.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.weight', 'llm.base_model.model.model.layers.12.mlp.up_proj.weight', 'encoder.blocks.10.attn.value.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.14.mlp.0.weight', 'llm.base_model.model.model.layers.1.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.weight', 'encoder.blocks.7.attn_ln.bias', 'llm.base_model.model.model.layers.14.input_layernorm.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.2.attn_ln.weight', 'encoder.blocks.9.attn.query.weight', 'encoder.blocks.25.attn.out.bias', 'encoder.blocks.25.mlp_ln.bias', 'llm.base_model.model.model.layers.15.post_attention_layernorm.weight', 'encoder.blocks.31.attn.query.bias', 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.25.attn.query.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.3.mlp_ln.bias', 'encoder.blocks.10.mlp_ln.bias', 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.weight', 'encoder.blocks.2.attn.value.bias', 'encoder.blocks.7.mlp.0.weight', 'encoder.blocks.14.attn.query.bias', 'encoder.blocks.19.mlp.0.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.weight', 'encoder.blocks.19.mlp.2.bias', 'encoder.blocks.2.attn.query.bias', 'encoder.blocks.19.attn.value.weight', 'encoder.blocks.14.mlp_ln.weight', 'encoder.blocks.24.attn.value.bias', 'encoder.blocks.31.mlp_ln.bias', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.9.mlp.0.bias', 'encoder.blocks.3.mlp.2.weight', 'encoder.blocks.13.mlp_ln.bias', 'encoder.blocks.18.attn.out.bias', 'encoder.blocks.22.attn.query.weight', 'encoder.blocks.19.attn.out.weight', 'encoder.ln_post.bias', 'encoder.blocks.21.attn.value.weight', 'encoder.blocks.22.attn_ln.bias', 'llm.base_model.model.model.layers.5.mlp.down_proj.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.29.attn_ln.weight', 'encoder.blocks.31.mlp.0.bias', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.26.attn.query.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.0.mlp_ln.bias', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.11.attn.key.weight', 'encoder.blocks.29.attn.query.bias', 'llm.base_model.model.model.layers.10.mlp.down_proj.weight', 'encoder.blocks.30.mlp.2.bias', 'encoder.blocks.15.attn_ln.weight', 'encoder.blocks.23.mlp.0.bias', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.weight', 'encoder.blocks.5.mlp_ln.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.5.mlp_ln.bias', 'encoder.blocks.24.mlp.2.weight', 'encoder.blocks.9.attn.query.bias', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.15.attn.query.bias', 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.16.attn.value.bias', 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.16.attn.value.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.27.attn.value.weight', 'encoder.blocks.21.attn_ln.bias', 'encoder.blocks.3.attn.query.weight', 'encoder.blocks.11.attn.out.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.23.mlp.2.weight', 'encoder.blocks.4.attn_ln.bias', 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.31.mlp.0.weight', 'encoder.blocks.18.attn.query.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.4.attn.query.bias', 'encoder.blocks.19.attn.value.bias', 'encoder.blocks.20.mlp.0.bias', 'encoder.blocks.7.attn.value.bias', 'llm.base_model.model.model.layers.5.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.25.mlp.0.bias', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.28.attn.query.weight', 'encoder.blocks.21.mlp.0.bias', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.3.attn.out.bias', 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.5.attn_ln.weight', 'encoder.blocks.30.attn.value.bias', 'encoder.blocks.8.attn.value.weight', 'encoder.blocks.26.attn.key.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.0.attn.value.bias', 'encoder.blocks.21.mlp.2.bias', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.26.attn.out.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.weight', 'encoder.blocks.4.mlp.0.weight', 'llm.base_model.model.model.layers.2.mlp.up_proj.weight', 'encoder.blocks.11.attn.query.bias', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.weight', 'encoder_projector.linear1.weight', 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.15.attn.value.weight', 'encoder.blocks.23.mlp.2.bias', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.weight', 'encoder.blocks.6.attn.value.weight', 'encoder.blocks.7.mlp_ln.bias', 'encoder.blocks.24.mlp.0.bias', 'encoder.ln_post.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.27.mlp.0.bias', 'encoder.blocks.30.mlp.0.bias', 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.16.mlp_ln.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.21.mlp_ln.weight', 'encoder.blocks.26.attn_ln.weight', 'encoder.blocks.2.mlp.0.bias', 'encoder.blocks.28.attn.key.weight', 'encoder.blocks.8.attn.key.weight', 'encoder.blocks.13.attn_ln.weight', 'llm.base_model.model.model.layers.13.mlp.gate_proj.weight', 'encoder.blocks.20.mlp.2.weight', 'encoder.blocks.20.attn.out.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.8.attn.out.weight', 'encoder.blocks.8.attn.query.weight', 'encoder.blocks.22.mlp.2.weight', 'llm.base_model.model.model.norm.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.weight', 'encoder.blocks.18.attn.value.weight', 'encoder.blocks.13.attn.key.weight', 'llm.base_model.model.model.layers.10.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.6.mlp.0.weight', 'encoder.blocks.11.mlp.2.bias', 'llm.base_model.model.model.layers.5.mlp.up_proj.weight', 'encoder.blocks.18.attn.key.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.24.attn.key.weight', 'llm.base_model.model.model.layers.15.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.6.post_attention_layernorm.weight', 'encoder.blocks.23.mlp.0.weight', 'encoder.blocks.18.attn.value.bias', 'llm.base_model.model.model.layers.2.self_attn.k_proj.weight', 'encoder.blocks.17.mlp.0.bias', 'encoder.blocks.19.mlp_ln.weight', 'llm.base_model.model.model.layers.9.input_layernorm.weight', 'encoder.blocks.9.attn.out.weight', 'encoder.conv1.bias', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.14.mlp.2.bias', 'encoder.blocks.15.mlp_ln.bias', 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.10.attn.value.bias', 'encoder.blocks.13.mlp.0.bias', 'encoder.blocks.19.attn_ln.bias', 'encoder.blocks.3.mlp.2.bias', 'encoder.blocks.1.mlp.2.weight', 'encoder.blocks.1.attn.out.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.input_layernorm.weight', 'encoder.blocks.10.mlp.0.weight', 'encoder.blocks.8.attn.out.bias', 'encoder.blocks.18.mlp_ln.bias', 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.20.mlp.0.weight', 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.8.attn_ln.bias', 'encoder.blocks.18.attn_ln.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.weight', 'encoder.blocks.11.mlp_ln.weight', 'encoder.blocks.31.attn_ln.bias', 'encoder.blocks.16.mlp.0.weight', 'encoder.blocks.31.attn.value.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.4.mlp.2.weight', 'encoder.blocks.8.mlp.0.bias', 'encoder.blocks.12.attn_ln.bias', 'encoder.blocks.2.mlp.2.bias', 'encoder.blocks.28.attn.value.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.26.attn.value.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.27.attn.query.weight', 'encoder.blocks.6.attn.query.weight', 'encoder.blocks.17.mlp_ln.bias', 'encoder.blocks.1.attn.out.bias', 'encoder.blocks.12.mlp.0.bias', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.9.mlp_ln.bias', 'encoder.blocks.18.attn_ln.bias', 'llm.base_model.model.model.layers.5.input_layernorm.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.weight', 'encoder.blocks.6.attn.key.weight', 'llm.base_model.model.model.layers.6.input_layernorm.weight', 'encoder.blocks.3.mlp.0.bias', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.6.attn.out.weight', 'encoder.blocks.31.attn.out.bias', 'encoder.blocks.13.attn.out.bias', 'encoder.blocks.14.attn_ln.bias', 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.weight', 'encoder.blocks.10.attn.out.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.weight', 'encoder.blocks.3.attn_ln.weight', 'encoder.blocks.27.attn.value.bias', 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.7.attn.key.weight', 'encoder.blocks.17.attn.value.weight', 'encoder.blocks.19.attn.query.bias', 'encoder.blocks.22.mlp_ln.bias', 'encoder.blocks.26.mlp.2.bias', 'encoder.blocks.31.mlp.2.bias', 'encoder.blocks.18.mlp.2.weight', 'encoder.blocks.25.mlp.0.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.25.attn.value.weight', 'encoder.blocks.0.attn.out.weight', 'encoder.blocks.15.mlp_ln.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.24.mlp.2.bias', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.mlp.up_proj.weight', 'encoder.blocks.1.attn.value.bias', 'encoder.blocks.19.attn_ln.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.weight', 'encoder.blocks.28.mlp.2.bias', 'encoder.blocks.11.attn.value.bias', 'encoder.blocks.27.mlp.0.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.31.attn.value.bias', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.22.mlp.0.bias', 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.30.attn_ln.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.weight', 'encoder.blocks.30.attn.out.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.weight', 'encoder.blocks.23.attn.value.bias', 'encoder.blocks.25.mlp_ln.weight', 'encoder.blocks.5.mlp.0.bias', 'encoder.blocks.17.attn_ln.weight', 'encoder.blocks.3.mlp.0.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.14.attn.out.weight', 'encoder.blocks.15.attn.query.weight', 'encoder.blocks.30.attn.query.bias', 'encoder.blocks.6.mlp_ln.bias', 'llm.base_model.model.model.layers.10.self_attn.o_proj.weight', 'encoder.blocks.25.attn.value.bias', 'encoder.blocks.5.attn.value.bias', 'encoder.blocks.5.attn.query.weight', 'encoder.blocks.19.mlp_ln.bias', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.0.mlp.0.weight', 'encoder.blocks.3.attn.key.weight', 'encoder.blocks.4.mlp.2.bias', 'encoder.blocks.4.attn.out.weight', 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.30.attn_ln.bias', 'llm.base_model.model.model.layers.7.mlp.up_proj.weight', 'encoder.blocks.19.attn.key.weight', 'encoder.blocks.22.mlp.0.weight', 'encoder.blocks.24.attn.value.weight', 'encoder.blocks.26.mlp.2.weight', 'encoder.blocks.28.attn.out.bias', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.12.mlp_ln.bias', 'llm.base_model.model.model.layers.1.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.weight', 'encoder.blocks.16.attn.key.weight', 'encoder.blocks.24.attn_ln.bias', 'encoder.blocks.0.mlp_ln.weight', 'llm.base_model.model.model.layers.6.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.9.post_attention_layernorm.weight', 'encoder.blocks.12.attn.value.bias', 'encoder.blocks.13.mlp.2.weight', 'encoder.blocks.8.attn_ln.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.13.mlp_ln.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.20.mlp_ln.bias', 'llm.base_model.model.model.layers.13.self_attn.k_proj.weight', 'encoder.blocks.12.mlp.0.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.29.attn.value.bias', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.weight', 'encoder.blocks.4.attn_ln.weight', 'encoder.blocks.14.attn.out.bias', 'encoder.blocks.12.attn.out.bias', 'encoder.blocks.26.mlp_ln.bias', 'encoder.blocks.28.attn_ln.bias', 'encoder.blocks.7.mlp_ln.weight', 'encoder.blocks.0.mlp.0.bias', 'encoder.blocks.14.mlp.0.bias', 'encoder.blocks.11.mlp.0.bias', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.13.self_attn.o_proj.weight', 'encoder.blocks.13.attn.value.bias', 'encoder.blocks.21.mlp.2.weight', 'llm.base_model.model.model.layers.3.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.5.mlp.2.weight', 'encoder.blocks.27.attn_ln.bias', 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.9.attn.key.weight', 'encoder.blocks.5.attn.value.weight', 'encoder.blocks.20.attn.out.bias', 'llm.base_model.model.lm_head.weight', 'encoder.blocks.21.mlp.0.weight', 'encoder.blocks.6.attn_ln.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.12.mlp_ln.weight', 'encoder.blocks.1.attn.query.bias', 'encoder.blocks.4.attn.value.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.28.mlp.0.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.weight', 'encoder.blocks.15.attn_ln.bias', 'llm.base_model.model.model.layers.0.mlp.up_proj.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.4.input_layernorm.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.9.attn.value.weight', 'llm.base_model.model.model.layers.15.input_layernorm.weight', 'encoder.blocks.23.attn.out.bias', 'encoder.blocks.10.attn_ln.weight', 'encoder.blocks.16.attn_ln.weight', 'encoder.blocks.15.attn.value.bias', 'encoder.blocks.5.attn.key.weight', 'encoder.blocks.20.attn_ln.bias', 'encoder.blocks.14.attn.value.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.28.mlp_ln.bias', 'encoder.blocks.2.mlp_ln.weight', 'encoder.blocks.18.mlp.2.bias', 'encoder.blocks.3.attn.value.weight', 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.1.mlp.0.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.16.attn.out.bias', 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.6.attn_ln.bias', 'encoder.blocks.6.mlp.2.bias', 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.30.attn.query.weight', 'encoder.blocks.18.attn.query.bias', 'llm.base_model.model.model.layers.12.self_attn.o_proj.weight', 'encoder.blocks.13.attn.value.weight', 'encoder.blocks.27.mlp_ln.bias', 'encoder.blocks.17.attn.value.bias', 'encoder.blocks.19.attn.out.bias', 'encoder.blocks.23.attn.query.bias', 'encoder.blocks.7.attn.out.weight', 'encoder.blocks.17.attn.out.bias', 'encoder.blocks.17.mlp.2.bias', 'llm.base_model.model.model.layers.1.self_attn.o_proj.weight', 'encoder.blocks.25.mlp.2.bias', 'llm.base_model.model.model.layers.10.self_attn.q_proj.weight', 'encoder.blocks.9.mlp.0.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.13.attn.out.weight', 'encoder.blocks.26.mlp_ln.weight', 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.20.attn_ln.weight', 'llm.base_model.model.model.layers.10.input_layernorm.weight', 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.2.mlp.0.weight', 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.14.attn_ln.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'encoder.blocks.27.attn_ln.weight', 'encoder.blocks.10.attn.out.bias', 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.weight', 'encoder.blocks.12.mlp.2.weight', 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.0.attn.query.bias', 'encoder.blocks.4.attn.value.bias', 'encoder.blocks.4.attn.out.bias', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.15.mlp.0.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.post_attention_layernorm.weight', 'encoder.blocks.28.attn.out.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'encoder.blocks.28.attn_ln.weight', 'encoder.blocks.21.attn.out.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.17.mlp.0.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.weight', 'encoder.blocks.12.attn.query.weight', 'encoder.blocks.13.attn_ln.bias', 'llm.base_model.model.model.layers.11.self_attn.o_proj.weight', 'encoder.blocks.1.mlp.2.bias', 'llm.base_model.model.model.layers.15.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.31.mlp.2.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'encoder.positional_embedding', 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.24.attn.query.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'encoder.blocks.29.mlp_ln.weight', 'encoder.blocks.31.attn.key.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'encoder.conv2.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.1.mlp.0.bias', 'encoder.blocks.8.attn.value.bias', 'encoder.blocks.19.mlp.2.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'encoder.blocks.16.mlp.0.bias', 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.11.attn_ln.bias', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.2.attn.out.weight', 'encoder.blocks.20.attn.query.weight', 'llm.base_model.model.model.layers.0.self_attn.k_proj.weight', 'encoder.blocks.22.attn.value.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.weight', 'encoder.blocks.13.mlp.2.bias', 'llm.base_model.model.model.layers.7.self_attn.o_proj.weight', 'encoder.blocks.7.attn_ln.weight', 'encoder.blocks.8.attn.query.bias', 'encoder.blocks.21.attn_ln.weight', 'encoder.blocks.30.mlp.0.weight', 'encoder.blocks.20.attn.value.weight', 'encoder.blocks.30.attn.value.weight', 'encoder.blocks.30.mlp_ln.weight', 'encoder.blocks.10.mlp.0.bias', 'llm.base_model.model.model.layers.12.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.5.mlp.2.bias', 'encoder.blocks.29.mlp.2.weight', 'encoder.blocks.22.attn.out.bias', 'encoder.blocks.8.mlp.2.bias', 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.22.attn.query.bias', 'encoder.blocks.10.attn.query.weight', 'encoder.blocks.23.attn_ln.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.weight', 'encoder.blocks.3.attn.value.bias', 'encoder.blocks.6.mlp.0.bias', 'encoder.blocks.29.mlp.0.weight', 'encoder.blocks.9.mlp.2.bias', 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.23.attn.query.weight', 'encoder.blocks.26.attn.query.bias', 'encoder.blocks.7.attn.value.weight', 'encoder.blocks.24.attn_ln.weight', 'encoder.blocks.29.attn.query.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'encoder.blocks.8.mlp.0.weight', 'encoder.blocks.27.attn.out.weight', 'encoder.blocks.15.mlp.2.bias', 'encoder.blocks.28.attn.value.bias', 'encoder.blocks.30.mlp.2.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.weight', 'encoder.blocks.10.attn.query.bias', 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'encoder.blocks.30.attn.key.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'encoder.blocks.16.attn_ln.bias', 'encoder.blocks.25.attn_ln.bias', 'encoder.blocks.24.mlp.0.weight', 'encoder.blocks.28.mlp.0.bias', 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'encoder.blocks.8.mlp.2.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.weight', 'encoder.blocks.17.attn.out.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.weight', 'encoder.blocks.2.attn.key.weight', 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'encoder.blocks.15.attn.key.weight', 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.21.mlp_ln.bias', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'encoder.blocks.4.attn.query.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.weight', 'llm.base_model.model.model.layers.15.mlp.up_proj.weight', 'llm.base_model.model.model.layers.0.post_attention_layernorm.weight', 'encoder.blocks.2.attn_ln.bias', 'encoder.blocks.29.attn.key.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.20.attn.value.bias', 'llm.base_model.model.model.layers.6.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'encoder.blocks.23.attn.key.weight', 'encoder.blocks.14.mlp.2.weight', 'encoder.blocks.7.mlp.2.bias', 'encoder.blocks.23.attn.out.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.14.attn.query.weight', 'encoder_projector.linear1.bias', 'encoder.blocks.14.attn.key.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.weight', 'encoder.blocks.25.attn.key.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.weight', 'encoder.blocks.2.mlp_ln.bias', 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'encoder.blocks.27.attn.key.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'encoder_projector.linear2.weight', 'encoder.blocks.28.mlp.2.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'encoder.blocks.20.attn.key.weight', 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'encoder.blocks.21.attn.query.bias', 'encoder.blocks.6.attn.query.bias', 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.weight', 'encoder.blocks.4.mlp_ln.weight', 'encoder.blocks.0.attn_ln.bias', 'llm.base_model.model.model.layers.10.post_attention_layernorm.weight', 'encoder.blocks.16.mlp.2.bias', 'encoder.blocks.23.mlp_ln.bias', 'encoder.blocks.31.attn.out.weight', 'encoder.blocks.20.attn.query.bias', 'encoder.blocks.29.attn.out.bias', 'encoder.blocks.18.mlp.0.bias'}
[2025-02-15 23:47:57,176][slam_model_asr.py][ERROR] - Unexpected keys: {'random_state', 'cuda_random_state', 'model', 'config', 'epoch', 'scaler_state', 'optimizer_state', 'best_val_acc', 'best_val_loss', 'step', 'lr_scheduler_state'}
[2025-02-15 23:47:57,176][slam_model_asr.py][ERROR] - Error loading checkpoint from /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt: name 'checkpoint' is not defined
[2025-02-15 23:49:34,187][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:49:34,188][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:49:34,188][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:49:56,201][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:49:56,204][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:49:56,206][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:49:56,207][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:50:00,134][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:50:00,135][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:50:00,137][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:50:00,267][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:50:00,269][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:50:00,418][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:50:00,418][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:50:00,419][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:50:00,685][slam_model_asr.py][ERROR] - Error loading checkpoint from /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt: name 'checkpoint' is not defined
[2025-02-15 23:51:15,314][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:51:15,314][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:51:15,314][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:51:37,009][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:51:37,012][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:51:37,014][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:51:37,015][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:51:40,887][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:51:40,888][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:51:40,889][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:51:41,013][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:51:41,015][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:51:41,118][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:51:41,118][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:51:41,118][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:51:41,405][slam_model_asr.py][INFO] - Model loaded successfully from checkpoint.
[2025-02-15 23:51:41,406][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-15 23:51:41,409][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2025-02-15 23:51:43,793][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2025-02-15 23:51:44,109][root][INFO] - --> Training Set Length = 2
[2025-02-15 23:51:44,110][root][INFO] - =====================================
[2025-02-15 23:51:45,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-15 23:51:52,214][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_pred_test_run_whisper_llama32_1b_linear_peft_20250215_235144
[2025-02-15 23:51:52,215][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_gt_test_run_whisper_llama32_1b_linear_peft_20250215_235144
[2025-02-15 23:57:19,809][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-15 23:57:19,809][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-15 23:57:19,809][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-15 23:57:41,850][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:57:41,854][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-15 23:57:41,856][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-15 23:57:41,857][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-15 23:57:45,923][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:57:45,924][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-15 23:57:45,926][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-15 23:57:46,048][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-15 23:57:46,050][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-15 23:57:46,193][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-15 23:57:46,194][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-15 23:57:46,194][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-15 23:57:46,462][slam_model_asr.py][ERROR] - Checkpoint and model state_dict mismatch:
[2025-02-15 23:57:46,462][slam_model_asr.py][ERROR] - Missing keys: {'encoder.blocks.11.attn.value.weight', 'encoder.blocks.30.attn_ln.bias', 'encoder.blocks.25.attn.query.weight', 'encoder.blocks.4.attn.value.bias', 'encoder.blocks.5.mlp.2.bias', 'encoder.blocks.24.attn.value.bias', 'llm.base_model.model.model.layers.0.mlp.up_proj.weight', 'encoder.blocks.9.attn.value.weight', 'encoder.blocks.1.attn.key.weight', 'encoder.blocks.18.mlp.0.bias', 'encoder.blocks.13.attn.key.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.weight', 'encoder.blocks.26.attn.query.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.weight', 'encoder.blocks.14.attn_ln.bias', 'encoder.blocks.8.attn.query.weight', 'encoder.blocks.1.attn_ln.weight', 'encoder.blocks.20.attn.out.bias', 'encoder.blocks.19.mlp.2.bias', 'encoder.blocks.31.mlp.2.weight', 'llm.base_model.model.model.layers.13.input_layernorm.weight', 'encoder.blocks.14.attn.key.weight', 'encoder.blocks.16.mlp_ln.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.weight', 'llm.base_model.model.model.layers.11.input_layernorm.weight', 'llm.base_model.model.model.layers.0.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.weight', 'encoder.blocks.4.attn.key.weight', 'encoder.blocks.7.attn.out.bias', 'llm.base_model.model.model.layers.0.self_attn.k_proj.weight', 'encoder.conv2.bias', 'llm.base_model.model.model.layers.1.post_attention_layernorm.weight', 'encoder.blocks.30.attn.query.bias', 'encoder.blocks.25.mlp.0.weight', 'encoder.blocks.12.attn.key.weight', 'encoder.blocks.22.mlp_ln.weight', 'encoder.blocks.28.mlp.2.bias', 'encoder.blocks.7.mlp.2.bias', 'encoder.blocks.15.mlp.0.bias', 'encoder.blocks.10.mlp.0.weight', 'encoder.blocks.5.attn.query.bias', 'llm.base_model.model.model.layers.4.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.weight', 'encoder.blocks.31.mlp_ln.bias', 'encoder.blocks.24.attn.query.bias', 'encoder.blocks.18.attn.value.bias', 'llm.base_model.model.model.layers.8.input_layernorm.weight', 'encoder.blocks.29.attn_ln.bias', 'encoder.blocks.11.attn.query.bias', 'encoder.blocks.3.attn_ln.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.weight', 'encoder.blocks.18.mlp.2.weight', 'encoder.blocks.25.mlp.2.weight', 'encoder.blocks.17.mlp_ln.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.weight', 'encoder.blocks.20.attn.value.weight', 'encoder.blocks.31.attn.key.weight', 'encoder.blocks.12.attn.out.bias', 'llm.base_model.model.model.layers.3.self_attn.q_proj.weight', 'encoder.blocks.10.attn.value.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.weight', 'encoder.blocks.0.attn.out.bias', 'encoder.blocks.22.attn.out.bias', 'encoder.blocks.17.attn_ln.weight', 'encoder.blocks.4.attn.out.weight', 'encoder.blocks.8.mlp_ln.bias', 'encoder.blocks.5.attn.out.bias', 'encoder.blocks.7.attn.key.weight', 'encoder.blocks.5.attn.value.weight', 'encoder.blocks.10.mlp.0.bias', 'encoder.blocks.24.attn.value.weight', 'encoder.blocks.14.attn.out.weight', 'encoder.blocks.19.attn.value.weight', 'encoder.blocks.13.attn.out.bias', 'encoder.blocks.7.attn_ln.weight', 'encoder.blocks.20.attn.out.weight', 'encoder.blocks.23.attn.query.bias', 'llm.base_model.model.model.layers.9.input_layernorm.weight', 'encoder.blocks.29.mlp.0.weight', 'encoder.blocks.8.attn_ln.bias', 'encoder.blocks.1.attn.value.bias', 'encoder.blocks.17.attn.query.weight', 'encoder.conv1.weight', 'llm.base_model.model.model.layers.4.mlp.gate_proj.weight', 'encoder.blocks.6.mlp.0.bias', 'encoder.blocks.13.attn.query.bias', 'llm.base_model.model.model.layers.1.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.weight', 'encoder.blocks.23.mlp_ln.weight', 'encoder.blocks.2.attn.key.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.weight', 'encoder.blocks.9.attn_ln.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.weight', 'encoder.blocks.9.mlp.2.bias', 'encoder.blocks.8.attn_ln.weight', 'encoder.blocks.19.mlp.2.weight', 'encoder.blocks.23.mlp.2.weight', 'encoder.blocks.16.attn.key.weight', 'encoder.blocks.14.mlp.0.bias', 'encoder.blocks.15.attn.out.bias', 'encoder.blocks.30.mlp.0.bias', 'encoder.blocks.13.attn.value.weight', 'encoder.blocks.26.attn.out.bias', 'encoder.blocks.24.mlp.0.weight', 'encoder.blocks.14.attn.value.bias', 'encoder.blocks.20.mlp_ln.bias', 'llm.base_model.model.model.layers.14.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.14.post_attention_layernorm.weight', 'encoder.blocks.27.attn.value.weight', 'encoder.blocks.23.attn.value.bias', 'llm.base_model.model.model.layers.8.mlp.gate_proj.weight', 'encoder.blocks.1.mlp_ln.weight', 'llm.base_model.model.model.layers.15.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.weight', 'encoder.blocks.1.attn.out.weight', 'encoder.blocks.17.attn.value.bias', 'encoder.blocks.12.mlp.0.bias', 'encoder.blocks.16.attn.out.weight', 'encoder.blocks.0.mlp.0.weight', 'encoder.blocks.28.mlp.0.weight', 'encoder.blocks.8.mlp.2.bias', 'llm.base_model.model.model.layers.7.self_attn.v_proj.weight', 'encoder.blocks.27.attn.key.weight', 'llm.base_model.model.model.layers.14.input_layernorm.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.weight', 'encoder.blocks.1.mlp.2.bias', 'llm.base_model.model.model.layers.5.post_attention_layernorm.weight', 'encoder.blocks.6.mlp.2.bias', 'encoder.blocks.26.attn.query.bias', 'encoder.blocks.21.attn_ln.bias', 'llm.base_model.model.model.layers.10.input_layernorm.weight', 'encoder.blocks.9.mlp_ln.bias', 'encoder.blocks.2.attn.query.weight', 'encoder.blocks.10.attn.query.weight', 'encoder.blocks.16.attn.value.bias', 'encoder.blocks.26.mlp.2.weight', 'encoder.blocks.13.mlp.2.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.weight', 'encoder.blocks.5.attn.key.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.weight', 'llm.base_model.model.model.norm.weight', 'encoder.blocks.16.mlp.0.bias', 'llm.base_model.model.model.layers.15.mlp.up_proj.weight', 'encoder.blocks.13.attn.value.bias', 'encoder.blocks.10.attn.out.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.weight', 'encoder.blocks.24.attn.query.weight', 'encoder.blocks.24.mlp_ln.weight', 'encoder.blocks.16.mlp.2.bias', 'encoder.blocks.27.mlp_ln.bias', 'encoder.blocks.23.attn.out.bias', 'encoder.blocks.17.mlp.2.weight', 'encoder.blocks.15.attn.query.bias', 'llm.base_model.model.model.layers.13.mlp.up_proj.weight', 'llm.base_model.model.model.layers.13.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.weight', 'encoder.blocks.22.mlp.0.weight', 'encoder.blocks.2.mlp_ln.bias', 'encoder.blocks.19.attn.query.bias', 'encoder.blocks.22.attn.value.bias', 'encoder.blocks.30.attn.out.weight', 'encoder.blocks.21.attn.key.weight', 'encoder.blocks.23.attn.key.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.weight', 'encoder.blocks.9.mlp.2.weight', 'encoder.blocks.30.mlp.2.weight', 'encoder.blocks.21.mlp.0.weight', 'encoder.blocks.22.attn.key.weight', 'encoder.blocks.26.attn_ln.weight', 'encoder.blocks.4.attn.query.bias', 'encoder.blocks.20.attn_ln.weight', 'encoder.blocks.20.attn_ln.bias', 'encoder.blocks.20.mlp.2.bias', 'llm.base_model.model.model.layers.13.self_attn.k_proj.weight', 'encoder.blocks.18.mlp_ln.weight', 'llm.base_model.model.model.embed_tokens.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.weight', 'encoder.blocks.21.attn.query.bias', 'encoder.blocks.16.attn.out.bias', 'llm.base_model.model.model.layers.15.post_attention_layernorm.weight', 'encoder.blocks.10.attn.out.bias', 'encoder.blocks.17.attn.query.bias', 'encoder.blocks.23.attn.out.weight', 'encoder.blocks.28.attn.query.weight', 'encoder.blocks.14.attn.query.bias', 'encoder.blocks.9.attn.query.weight', 'encoder.blocks.0.attn.query.weight', 'encoder.blocks.31.attn.query.bias', 'encoder.blocks.6.attn.query.weight', 'encoder.blocks.1.mlp.2.weight', 'encoder.blocks.9.attn.query.bias', 'encoder.blocks.12.attn.query.bias', 'llm.base_model.model.model.layers.4.input_layernorm.weight', 'encoder.blocks.19.attn.out.weight', 'encoder.blocks.23.attn_ln.weight', 'encoder.blocks.27.attn_ln.weight', 'encoder.blocks.14.mlp.2.bias', 'encoder.blocks.20.attn.query.bias', 'llm.base_model.model.model.layers.6.self_attn.k_proj.weight', 'encoder.blocks.27.attn.value.bias', 'encoder.blocks.11.mlp.0.weight', 'encoder.blocks.20.attn.query.weight', 'encoder.blocks.3.attn_ln.bias', 'encoder.blocks.19.attn.query.weight', 'encoder.blocks.28.attn.out.bias', 'encoder.blocks.8.attn.query.bias', 'encoder.blocks.27.attn.query.bias', 'encoder.blocks.28.attn_ln.bias', 'encoder.blocks.10.mlp.2.bias', 'encoder.blocks.11.mlp.2.bias', 'encoder.blocks.0.attn_ln.bias', 'llm.base_model.model.model.layers.8.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.weight', 'encoder.blocks.29.mlp.2.bias', 'encoder.blocks.0.mlp_ln.weight', 'encoder.blocks.24.mlp.2.bias', 'encoder.blocks.26.mlp.2.bias', 'llm.base_model.model.model.layers.0.self_attn.q_proj.weight', 'llm.base_model.model.model.layers.13.post_attention_layernorm.weight', 'encoder.blocks.4.mlp.2.weight', 'encoder.blocks.30.attn.value.bias', 'encoder.blocks.3.mlp.0.weight', 'encoder.blocks.25.attn.query.bias', 'llm.base_model.model.model.layers.11.self_attn.q_proj.weight', 'encoder.blocks.16.attn.query.bias', 'encoder.blocks.12.mlp.2.bias', 'encoder.blocks.10.mlp_ln.bias', 'encoder.blocks.15.attn_ln.bias', 'encoder.blocks.15.mlp.2.bias', 'encoder.blocks.28.attn.value.bias', 'llm.base_model.model.model.layers.5.self_attn.q_proj.weight', 'encoder.blocks.21.attn.out.weight', 'encoder.blocks.7.attn_ln.bias', 'encoder.blocks.16.attn.value.weight', 'encoder.blocks.22.mlp.2.bias', 'encoder.blocks.2.attn.query.bias', 'encoder.blocks.31.attn.out.bias', 'encoder.blocks.27.attn.query.weight', 'encoder.blocks.7.attn.value.bias', 'encoder.blocks.4.mlp.2.bias', 'encoder.blocks.13.attn_ln.bias', 'encoder.blocks.20.mlp.2.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.weight', 'encoder.blocks.24.attn.out.weight', 'encoder.blocks.25.attn.out.bias', 'encoder.blocks.30.mlp.2.bias', 'encoder.blocks.25.attn.value.bias', 'encoder.blocks.8.attn.out.weight', 'encoder.blocks.31.attn.value.bias', 'encoder.blocks.17.mlp_ln.bias', 'llm.base_model.model.model.layers.8.post_attention_layernorm.weight', 'encoder.blocks.0.mlp_ln.bias', 'encoder.blocks.2.attn_ln.bias', 'encoder.blocks.8.mlp_ln.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.weight', 'encoder.blocks.14.mlp.2.weight', 'encoder.blocks.22.attn_ln.bias', 'encoder.blocks.13.mlp.0.weight', 'llm.base_model.model.model.layers.10.mlp.gate_proj.weight', 'encoder.blocks.10.mlp_ln.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.weight', 'encoder.blocks.18.mlp.2.bias', 'llm.base_model.model.model.layers.13.mlp.gate_proj.weight', 'encoder.blocks.15.mlp.0.weight', 'encoder.blocks.22.attn_ln.weight', 'encoder.blocks.7.mlp_ln.bias', 'encoder.blocks.3.attn.out.bias', 'llm.base_model.model.model.layers.2.mlp.down_proj.weight', 'encoder.blocks.6.attn.key.weight', 'llm.base_model.model.model.layers.12.post_attention_layernorm.weight', 'encoder.blocks.15.attn_ln.weight', 'encoder.blocks.29.attn.out.weight', 'encoder.blocks.28.attn.query.bias', 'encoder.blocks.6.mlp_ln.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.weight', 'encoder.blocks.12.attn_ln.weight', 'encoder.blocks.22.mlp.0.bias', 'llm.base_model.model.model.layers.5.self_attn.k_proj.weight', 'encoder.blocks.19.mlp.0.weight', 'encoder.blocks.2.attn.out.weight', 'encoder.blocks.26.attn.value.weight', 'encoder.blocks.29.attn.key.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.weight', 'encoder.blocks.10.attn.key.weight', 'encoder.blocks.31.attn.out.weight', 'encoder.blocks.5.attn_ln.bias', 'encoder.blocks.11.mlp_ln.weight', 'encoder.blocks.2.mlp.0.bias', 'llm.base_model.model.model.layers.6.post_attention_layernorm.weight', 'encoder.blocks.7.mlp.0.bias', 'encoder.blocks.21.mlp.2.weight', 'encoder.blocks.6.mlp.2.weight', 'encoder.blocks.8.attn.value.weight', 'encoder.blocks.17.attn.value.weight', 'encoder.blocks.6.mlp_ln.bias', 'llm.base_model.model.model.layers.10.self_attn.k_proj.weight', 'encoder.blocks.5.mlp.0.weight', 'encoder.blocks.1.mlp_ln.bias', 'encoder.blocks.19.mlp_ln.weight', 'encoder.blocks.29.attn.query.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.weight', 'encoder.blocks.9.attn.key.weight', 'encoder.blocks.4.mlp.0.bias', 'encoder.blocks.19.attn.value.bias', 'llm.base_model.model.model.layers.9.self_attn.k_proj.weight', 'encoder.blocks.27.attn.out.bias', 'llm.base_model.model.model.layers.2.post_attention_layernorm.weight', 'encoder.ln_post.bias', 'encoder.blocks.4.mlp_ln.weight', 'encoder.blocks.24.attn_ln.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.weight', 'llm.base_model.model.model.layers.2.mlp.up_proj.weight', 'encoder.blocks.5.attn.value.bias', 'llm.base_model.model.model.layers.3.mlp.up_proj.weight', 'encoder.blocks.17.mlp.0.bias', 'encoder.blocks.6.attn.out.bias', 'encoder.blocks.26.attn.out.weight', 'llm.base_model.model.model.layers.3.input_layernorm.weight', 'encoder.blocks.27.mlp.0.bias', 'encoder.blocks.25.attn.key.weight', 'encoder.blocks.25.attn.out.weight', 'encoder.blocks.16.mlp_ln.bias', 'encoder.blocks.2.mlp.2.weight', 'encoder.blocks.22.attn.value.weight', 'encoder.blocks.29.mlp.2.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.weight', 'encoder.blocks.7.mlp.0.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.15.input_layernorm.weight', 'llm.base_model.model.model.layers.6.input_layernorm.weight', 'encoder.blocks.5.mlp_ln.bias', 'encoder.blocks.20.mlp.0.bias', 'encoder.blocks.25.attn_ln.weight', 'llm.base_model.model.model.layers.9.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.weight', 'encoder.blocks.12.attn.value.bias', 'encoder.blocks.15.mlp_ln.bias', 'llm.base_model.model.model.layers.5.self_attn.o_proj.weight', 'encoder.blocks.28.mlp.0.bias', 'encoder.blocks.31.attn_ln.weight', 'encoder.blocks.10.mlp.2.weight', 'encoder.blocks.15.mlp_ln.weight', 'encoder.blocks.21.attn.value.bias', 'encoder.blocks.17.attn.key.weight', 'encoder.blocks.2.attn_ln.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.weight', 'encoder.blocks.29.attn.out.bias', 'encoder.blocks.9.attn_ln.bias', 'llm.base_model.model.model.layers.6.self_attn.o_proj.weight', 'encoder.blocks.28.attn.value.weight', 'encoder.blocks.30.mlp_ln.bias', 'encoder.blocks.7.attn.query.bias', 'encoder.blocks.19.attn_ln.weight', 'encoder.blocks.14.mlp_ln.bias', 'encoder.blocks.21.mlp.2.bias', 'encoder.blocks.4.mlp.0.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.weight', 'encoder.blocks.13.attn.out.weight', 'encoder.blocks.14.attn.query.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.weight', 'encoder.blocks.18.mlp_ln.bias', 'encoder.blocks.27.mlp.2.weight', 'encoder.blocks.11.attn.query.weight', 'encoder.blocks.23.attn.query.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.weight', 'encoder.blocks.18.attn.out.bias', 'llm.base_model.model.model.layers.7.self_attn.k_proj.weight', 'encoder.blocks.2.attn.out.bias', 'llm.base_model.model.model.layers.1.self_attn.v_proj.weight', 'encoder.blocks.8.attn.out.bias', 'encoder.blocks.12.mlp_ln.weight', 'encoder.blocks.2.attn.value.bias', 'encoder.blocks.18.attn.key.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.weight', 'llm.base_model.model.model.layers.12.input_layernorm.weight', 'encoder.blocks.26.attn.key.weight', 'encoder.blocks.2.mlp.0.weight', 'encoder.blocks.31.mlp.0.weight', 'encoder.blocks.31.mlp.0.bias', 'encoder.blocks.6.attn.out.weight', 'encoder.blocks.12.mlp.0.weight', 'encoder.blocks.5.attn_ln.weight', 'encoder.blocks.11.attn.out.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.weight', 'encoder.blocks.28.mlp_ln.weight', 'encoder.blocks.16.attn_ln.bias', 'encoder.blocks.16.attn.query.weight', 'encoder.blocks.23.mlp_ln.bias', 'encoder.blocks.10.attn_ln.bias', 'encoder.blocks.3.mlp.0.bias', 'encoder.blocks.17.attn.out.weight', 'encoder.blocks.21.mlp.0.bias', 'encoder.blocks.9.mlp.0.weight', 'encoder.blocks.7.mlp_ln.weight', 'encoder.blocks.12.mlp.2.weight', 'encoder.blocks.12.attn.out.weight', 'encoder.blocks.19.attn.out.bias', 'encoder.blocks.23.attn_ln.bias', 'llm.base_model.model.model.layers.12.self_attn.k_proj.weight', 'llm.base_model.model.lm_head.weight', 'encoder.blocks.0.attn.out.weight', 'llm.base_model.model.model.layers.1.input_layernorm.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.weight', 'encoder.blocks.24.mlp.2.weight', 'encoder.blocks.27.attn.out.weight', 'encoder.blocks.6.mlp.0.weight', 'encoder.blocks.31.mlp.2.bias', 'llm.base_model.model.model.layers.14.mlp.up_proj.weight', 'encoder.blocks.26.mlp_ln.weight', 'encoder.blocks.3.attn.key.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.weight', 'encoder.blocks.29.attn.query.bias', 'encoder.blocks.12.mlp_ln.bias', 'llm.base_model.model.model.layers.2.self_attn.o_proj.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.weight', 'encoder.blocks.11.attn.key.weight', 'encoder.blocks.9.attn.out.weight', 'encoder.blocks.26.attn.value.bias', 'encoder.blocks.26.mlp_ln.bias', 'llm.base_model.model.model.layers.15.self_attn.q_proj.weight', 'encoder.blocks.17.mlp.0.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.weight', 'encoder.blocks.23.mlp.0.weight', 'encoder.blocks.30.attn.key.weight', 'encoder.blocks.10.attn.value.bias', 'encoder.blocks.3.attn.value.weight', 'encoder.blocks.26.mlp.0.bias', 'encoder.blocks.13.mlp.0.bias', 'encoder.blocks.13.mlp.2.bias', 'encoder.blocks.0.mlp.2.bias', 'llm.base_model.model.model.layers.5.mlp.up_proj.weight', 'encoder.blocks.11.mlp_ln.bias', 'llm.base_model.model.model.layers.11.post_attention_layernorm.weight', 'encoder.blocks.6.attn.value.weight', 'encoder.blocks.25.attn_ln.bias', 'encoder.blocks.30.attn.out.bias', 'llm.base_model.model.model.layers.10.post_attention_layernorm.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.weight', 'encoder.blocks.8.mlp.0.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.weight', 'encoder.blocks.6.attn.value.bias', 'llm.base_model.model.model.layers.6.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.weight', 'encoder.positional_embedding', 'llm.base_model.model.model.layers.11.self_attn.o_proj.weight', 'encoder.blocks.1.mlp.0.weight', 'encoder.blocks.15.attn.out.weight', 'encoder.blocks.4.attn.value.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.weight', 'encoder.blocks.28.attn.out.weight', 'encoder.blocks.9.mlp_ln.weight', 'encoder.blocks.15.attn.query.weight', 'encoder.blocks.10.attn_ln.weight', 'encoder.blocks.25.mlp.0.bias', 'encoder.blocks.28.mlp_ln.bias', 'encoder.blocks.19.mlp_ln.bias', 'encoder.blocks.9.mlp.0.bias', 'encoder.blocks.13.mlp_ln.bias', 'llm.base_model.model.model.layers.0.input_layernorm.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.weight', 'llm.base_model.model.model.layers.7.input_layernorm.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.weight', 'encoder.blocks.20.attn.key.weight', 'encoder.blocks.3.mlp_ln.bias', 'encoder.blocks.0.attn.value.bias', 'encoder.blocks.2.attn.value.weight', 'encoder.blocks.18.mlp.0.weight', 'encoder.blocks.3.attn.value.bias', 'llm.base_model.model.model.layers.10.mlp.down_proj.weight', 'encoder.blocks.27.mlp_ln.weight', 'encoder.blocks.23.attn.value.weight', 'encoder.blocks.10.attn.query.bias', 'llm.base_model.model.model.layers.2.input_layernorm.weight', 'encoder.blocks.16.mlp.2.weight', 'encoder.blocks.21.attn.query.weight', 'encoder.blocks.21.attn.value.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.weight', 'encoder.blocks.21.attn.out.bias', 'encoder.blocks.17.mlp.2.bias', 'llm.base_model.model.model.layers.5.input_layernorm.weight', 'encoder.blocks.20.attn.value.bias', 'encoder.blocks.18.attn.query.weight', 'encoder.blocks.2.mlp_ln.weight', 'encoder.blocks.6.attn_ln.weight', 'encoder.blocks.24.attn.key.weight', 'encoder.blocks.1.attn.value.weight', 'encoder.blocks.18.attn.value.weight', 'encoder.blocks.4.attn.out.bias', 'encoder.blocks.15.attn.key.weight', 'encoder.blocks.30.attn_ln.weight', 'encoder.blocks.8.mlp.2.weight', 'encoder.blocks.6.attn.query.bias', 'llm.base_model.model.model.layers.3.self_attn.v_proj.weight', 'encoder.blocks.22.attn.query.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.weight', 'encoder.blocks.14.mlp_ln.weight', 'encoder.blocks.3.mlp.2.weight', 'encoder.blocks.1.attn.query.bias', 'llm.base_model.model.model.layers.10.self_attn.v_proj.weight', 'encoder.blocks.27.mlp.2.bias', 'encoder.blocks.12.attn.value.weight', 'encoder.blocks.5.attn.query.weight', 'encoder.blocks.11.attn.out.bias', 'llm.base_model.model.model.layers.11.mlp.up_proj.weight', 'encoder.blocks.8.attn.value.bias', 'encoder.blocks.12.attn_ln.bias', 'encoder.blocks.11.attn.value.bias', 'encoder.blocks.22.attn.query.bias', 'encoder.blocks.31.attn.value.weight', 'encoder.blocks.22.attn.out.weight', 'encoder.blocks.4.attn_ln.weight', 'encoder.blocks.17.attn_ln.bias', 'encoder.blocks.2.mlp.2.bias', 'encoder.blocks.9.attn.value.bias', 'encoder.blocks.25.mlp_ln.bias', 'encoder.blocks.20.mlp_ln.weight', 'encoder.blocks.31.mlp_ln.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.weight', 'encoder.blocks.0.attn.value.weight', 'llm.base_model.model.model.layers.3.post_attention_layernorm.weight', 'encoder.blocks.0.attn.key.weight', 'encoder.blocks.21.attn_ln.weight', 'encoder.blocks.27.attn_ln.bias', 'encoder.blocks.11.attn_ln.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.weight', 'encoder.blocks.29.attn.value.weight', 'encoder.blocks.21.mlp_ln.bias', 'encoder.blocks.5.mlp_ln.weight', 'encoder.conv1.bias', 'encoder.blocks.3.mlp.2.bias', 'llm.base_model.model.model.layers.9.self_attn.q_proj.weight', 'encoder.blocks.30.mlp.0.weight', 'encoder.blocks.22.mlp_ln.bias', 'encoder.blocks.14.attn.out.bias', 'llm.base_model.model.model.layers.3.self_attn.k_proj.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.weight', 'encoder.blocks.14.attn.value.weight', 'encoder.blocks.24.mlp_ln.bias', 'encoder.blocks.7.attn.query.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.weight', 'encoder.blocks.4.attn_ln.bias', 'encoder.blocks.31.attn_ln.bias', 'encoder.blocks.7.attn.value.weight', 'encoder.blocks.26.mlp.0.weight', 'encoder.blocks.8.attn.key.weight', 'encoder.blocks.5.mlp.0.bias', 'encoder.blocks.25.mlp.2.bias', 'encoder.blocks.1.attn.out.bias', 'encoder.blocks.31.attn.query.weight', 'encoder.blocks.26.attn_ln.bias', 'llm.base_model.model.model.layers.13.mlp.down_proj.weight', 'encoder.blocks.30.attn.value.weight', 'encoder.blocks.5.attn.out.weight', 'encoder.blocks.3.attn.out.weight', 'encoder.blocks.9.attn.out.bias', 'encoder.blocks.23.mlp.2.bias', 'llm.base_model.model.model.layers.9.mlp.up_proj.weight', 'encoder.blocks.11.mlp.2.weight', 'encoder.blocks.4.attn.query.weight', 'encoder.blocks.11.attn_ln.bias', 'encoder.blocks.3.attn.query.bias', 'encoder.blocks.27.mlp.0.weight', 'encoder.blocks.0.attn_ln.weight', 'encoder.blocks.6.attn_ln.bias', 'llm.base_model.model.model.layers.12.mlp.up_proj.weight', 'encoder.blocks.8.mlp.0.bias', 'encoder.blocks.7.attn.out.weight', 'encoder.blocks.13.attn_ln.weight', 'encoder.blocks.1.mlp.0.bias', 'encoder.blocks.5.mlp.2.weight', 'encoder.blocks.20.mlp.0.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.weight', 'encoder.blocks.25.mlp_ln.weight', 'encoder.blocks.30.attn.query.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.weight', 'encoder.blocks.1.attn.query.weight', 'encoder.blocks.24.mlp.0.bias', 'encoder.blocks.22.mlp.2.weight', 'encoder.blocks.12.attn.query.weight', 'encoder.blocks.14.attn_ln.weight', 'encoder.blocks.21.mlp_ln.weight', 'encoder.blocks.15.attn.value.bias', 'encoder.blocks.23.mlp.0.bias', 'encoder.blocks.3.mlp_ln.weight', 'encoder.ln_post.weight', 'encoder.blocks.15.mlp.2.weight', 'encoder.blocks.28.attn.key.weight', 'encoder.blocks.4.mlp_ln.bias', 'encoder.blocks.25.attn.value.weight', 'encoder.blocks.18.attn_ln.weight', 'encoder.blocks.16.attn_ln.weight', 'encoder.blocks.18.attn.query.bias', 'encoder.blocks.24.attn.out.bias', 'encoder.blocks.14.mlp.0.weight', 'encoder.blocks.0.attn.query.bias', 'encoder.blocks.29.mlp_ln.weight', 'encoder.blocks.11.mlp.0.bias', 'encoder.blocks.13.mlp_ln.weight', 'encoder.blocks.29.mlp.0.bias', 'encoder.blocks.18.attn.out.weight', 'encoder.conv2.weight', 'encoder.blocks.17.attn.out.bias', 'llm.base_model.model.model.layers.7.mlp.gate_proj.weight', 'encoder.blocks.3.attn.query.weight', 'llm.base_model.model.model.layers.7.post_attention_layernorm.weight', 'encoder.blocks.0.mlp.2.weight', 'encoder.blocks.7.mlp.2.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.weight', 'encoder.blocks.29.attn.value.bias', 'encoder.blocks.15.attn.value.weight', 'encoder.blocks.16.mlp.0.weight', 'encoder.blocks.18.attn_ln.bias', 'encoder.blocks.0.mlp.0.bias', 'encoder.blocks.1.attn_ln.bias', 'encoder.blocks.19.attn_ln.bias', 'encoder.blocks.13.attn.query.weight', 'encoder.blocks.24.attn_ln.bias', 'encoder.blocks.29.attn_ln.weight', 'encoder.blocks.28.mlp.2.weight', 'encoder.blocks.19.mlp.0.bias', 'llm.base_model.model.model.layers.6.mlp.down_proj.weight', 'encoder.blocks.28.attn_ln.weight', 'encoder.blocks.30.mlp_ln.weight', 'encoder.blocks.29.mlp_ln.bias', 'encoder.blocks.19.attn.key.weight'}
[2025-02-15 23:57:46,463][slam_model_asr.py][ERROR] - Unexpected keys: {'random_state', 'cuda_random_state', 'config', 'optimizer_state', 'lr_scheduler_state', 'best_val_acc', 'step', 'best_val_loss', 'scaler_state', 'model', 'epoch'}
[2025-02-15 23:57:46,463][slam_model_asr.py][ERROR] - Error loading checkpoint from /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt: Checkpoint does not match model architecture. Missing or unexpected keys.
[2025-02-16 00:00:48,147][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-16 00:00:48,147][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-16 00:00:48,147][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'test_run_whisper_llama32_1b_linear_peft'}
[2025-02-16 00:01:11,090][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-16 00:01:11,092][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2025-02-16 00:01:11,095][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2025-02-16 00:01:11,096][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2025-02-16 00:01:15,319][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-16 00:01:15,320][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-16 00:01:15,321][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-16 00:01:15,446][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-16 00:01:15,448][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-16 00:01:15,594][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-16 00:01:15,594][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2025-02-16 00:01:15,594][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/asr_epoch_3_step_4_loss_8.908509254455566/model.pt
[2025-02-16 00:01:15,888][slam_model_asr.py][INFO] - Model loaded successfully from checkpoint.
[2025-02-16 00:01:15,888][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-16 00:01:15,891][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2025-02-16 00:01:18,340][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/test_run/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2025-02-16 00:01:18,564][root][INFO] - --> Training Set Length = 2
[2025-02-16 00:01:18,564][root][INFO] - =====================================
[2025-02-16 00:01:20,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 00:01:26,641][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_pred_test_run_whisper_llama32_1b_linear_peft_20250216_000118
[2025-02-16 00:01:26,642][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/test_run_whisper_llama32_1b_linear_peft/decode_test_beam4_gt_test_run_whisper_llama32_1b_linear_peft_20250216_000118
