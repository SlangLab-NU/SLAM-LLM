[2025-02-16 18:33:52,131][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_seperate_wavlm_llama32_1b_dual_peft_seed_42', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-16 18:33:52,131][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-16 18:33:52,131][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'ami_phoneme_seperate_wavlm_llama32_1b_dual_peft_seed_42'}
[2025-02-16 18:33:52,131][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_phoneme_seperate_wavlm_llama32_1b_dual_peft_seed_42', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2025-02-16_18-33-51.txt', 'log_interval': 5}
[2025-02-16 18:34:17,152][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-16 18:34:23,259][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-16 18:34:23,262][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-16 18:34:23,265][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-16 18:34:23,266][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-16 18:34:25,378][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-16 18:34:25,381][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-16 18:34:25,381][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-16 18:34:25,383][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-16 18:34:35,353][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-16 18:34:35,356][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-16 18:34:35,357][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-16 18:34:35,572][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-16 18:34:35,574][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-16 18:34:35,861][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-02-16 18:34:35,862][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-02-16 18:34:35,863][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-16 18:34:35,869][slam_llm.utils.train_utils][INFO] - --> asr has 346.244736 Million params

[2025-02-16 18:34:38,338][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_phoneme_seperate/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_phoneme_seperate/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-16 18:34:42,035][root][INFO] - --> Training Set Length = 133363
[2025-02-16 18:34:42,115][root][INFO] - --> Validation Set Length = 16697
[2025-02-16 18:34:42,115][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-16 18:34:42,116][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-16 18:34:45,195][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:46,573][root][INFO] - Training Epoch: 1/2, step 0/33340 completed (loss: 5.217530250549316, acc: 0.16993464529514313)
[2025-02-16 18:34:46,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:47,179][root][INFO] - Training Epoch: 1/2, step 1/33340 completed (loss: 5.068340301513672, acc: 0.15566037595272064)
[2025-02-16 18:34:47,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:47,797][root][INFO] - Training Epoch: 1/2, step 2/33340 completed (loss: 5.255768299102783, acc: 0.16230367124080658)
[2025-02-16 18:34:47,979][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:48,480][root][INFO] - Training Epoch: 1/2, step 3/33340 completed (loss: 4.62221097946167, acc: 0.21612903475761414)
[2025-02-16 18:34:48,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:48,962][root][INFO] - Training Epoch: 1/2, step 4/33340 completed (loss: 4.891026496887207, acc: 0.13548387587070465)
[2025-02-16 18:34:49,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:49,955][root][INFO] - Training Epoch: 1/2, step 5/33340 completed (loss: 5.179656982421875, acc: 0.17518247663974762)
[2025-02-16 18:34:50,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:50,808][root][INFO] - Training Epoch: 1/2, step 6/33340 completed (loss: 4.928962707519531, acc: 0.16574585437774658)
[2025-02-16 18:34:51,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:51,309][root][INFO] - Training Epoch: 1/2, step 7/33340 completed (loss: 5.086957931518555, acc: 0.1553398072719574)
[2025-02-16 18:34:51,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:51,856][root][INFO] - Training Epoch: 1/2, step 8/33340 completed (loss: 5.313490390777588, acc: 0.09734513610601425)
[2025-02-16 18:34:52,326][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:52,611][root][INFO] - Training Epoch: 1/2, step 9/33340 completed (loss: 4.740095138549805, acc: 0.17803029716014862)
[2025-02-16 18:34:53,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:53,541][root][INFO] - Training Epoch: 1/2, step 10/33340 completed (loss: 5.858230113983154, acc: 0.0776699036359787)
[2025-02-16 18:34:53,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:53,950][root][INFO] - Training Epoch: 1/2, step 11/33340 completed (loss: 4.749452590942383, acc: 0.20338982343673706)
[2025-02-16 18:34:54,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:54,453][root][INFO] - Training Epoch: 1/2, step 12/33340 completed (loss: 5.777559280395508, acc: 0.1066666692495346)
[2025-02-16 18:34:54,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:55,049][root][INFO] - Training Epoch: 1/2, step 13/33340 completed (loss: 5.199810028076172, acc: 0.19090908765792847)
[2025-02-16 18:34:55,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:55,568][root][INFO] - Training Epoch: 1/2, step 14/33340 completed (loss: 5.421621322631836, acc: 0.20952381193637848)
[2025-02-16 18:34:55,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:56,084][root][INFO] - Training Epoch: 1/2, step 15/33340 completed (loss: 7.506651401519775, acc: 0.0)
[2025-02-16 18:34:56,352][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:56,676][root][INFO] - Training Epoch: 1/2, step 16/33340 completed (loss: 5.09214448928833, acc: 0.18269230425357819)
[2025-02-16 18:34:56,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:57,222][root][INFO] - Training Epoch: 1/2, step 17/33340 completed (loss: 4.388286113739014, acc: 0.23456789553165436)
[2025-02-16 18:34:57,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-16 18:34:57,731][root][INFO] - Training Epoch: 1/2, step 18/33340 completed (loss: 4.527372360229492, acc: 0.2545454502105713)
