[2024-12-14 02:01:40,299][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-12-14 02:01:40,300][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 02:01:40,304][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'cov1d-linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 02:01:40,307][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-14_02-01-39.txt', 'log_interval': 5}
[2024-12-14 02:02:05,134][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 02:02:11,410][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:02:11,412][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 02:02:11,417][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:02:11,419][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 02:02:16,542][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:02:16,544][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 02:02:16,548][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 02:02:16,976][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:02:16,979][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 02:02:17,120][slam_llm.utils.train_utils][INFO] - --> Module cov1d-linear
[2024-12-14 02:02:17,120][slam_llm.utils.train_utils][INFO] - --> cov1d-linear has 11.539456 Million params

[2024-12-14 02:02:17,121][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 02:02:17,131][slam_llm.utils.train_utils][INFO] - --> asr has 17.175552 Million params

[2024-12-14 02:02:17,147][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 02:02:18,263][root][INFO] - --> Training Set Length = 2298
[2024-12-14 02:02:18,281][root][INFO] - --> Validation Set Length = 341
[2024-12-14 02:02:18,282][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 02:02:18,287][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 02:03:00,809][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-12-14 02:03:00,809][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 02:03:00,809][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'cov1d-linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 02:03:00,810][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-14_02-03-00.txt', 'log_interval': 5}
[2024-12-14 02:03:20,967][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 02:03:26,299][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:03:26,302][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 02:03:26,304][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:03:26,305][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 02:03:31,241][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:03:31,242][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 02:03:31,242][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 02:03:31,537][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:03:31,539][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 02:03:31,621][slam_llm.utils.train_utils][INFO] - --> Module cov1d-linear
[2024-12-14 02:03:31,622][slam_llm.utils.train_utils][INFO] - --> cov1d-linear has 11.539456 Million params

[2024-12-14 02:03:31,623][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 02:03:31,626][slam_llm.utils.train_utils][INFO] - --> asr has 17.175552 Million params

[2024-12-14 02:03:33,379][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 02:03:33,997][root][INFO] - --> Training Set Length = 2298
[2024-12-14 02:03:34,002][root][INFO] - --> Validation Set Length = 341
[2024-12-14 02:03:34,003][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 02:03:34,003][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 02:03:35,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:37,220][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-12-14 02:03:38,667][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 8.621565818786621, acc: 0.03703703731298447)
[2024-12-14 02:03:38,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:39,038][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 8.180122375488281, acc: 0.0)
[2024-12-14 02:03:39,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:39,461][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 7.728630065917969, acc: 0.0)
[2024-12-14 02:03:39,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:39,873][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 7.899242877960205, acc: 0.0)
[2024-12-14 02:03:39,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:40,400][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 6.8734540939331055, acc: 0.10810811072587967)
[2024-12-14 02:03:40,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:40,743][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 8.21481990814209, acc: 0.0)
[2024-12-14 02:03:40,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:41,100][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 8.179727554321289, acc: 0.0)
[2024-12-14 02:03:41,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:41,533][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 7.864510536193848, acc: 0.0)
[2024-12-14 02:03:41,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:41,991][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.21310806274414, acc: 0.0)
[2024-12-14 02:03:42,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:42,370][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 7.454379558563232, acc: 0.0)
[2024-12-14 02:03:42,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:42,786][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.167080879211426, acc: 0.03703703731298447)
[2024-12-14 02:03:42,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:43,213][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 7.0814208984375, acc: 0.0)
[2024-12-14 02:03:43,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:43,599][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 7.82857608795166, acc: 0.0)
[2024-12-14 02:03:43,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:43,994][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 6.806736946105957, acc: 0.043478261679410934)
[2024-12-14 02:03:44,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:44,426][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 7.391972064971924, acc: 0.0)
[2024-12-14 02:03:44,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:44,784][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 6.198968887329102, acc: 0.12244898080825806)
[2024-12-14 02:03:44,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:45,158][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.712297439575195, acc: 0.0)
[2024-12-14 02:03:45,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:45,538][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.23022174835205, acc: 0.0)
[2024-12-14 02:03:45,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:45,865][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.781171798706055, acc: 0.02777777798473835)
[2024-12-14 02:03:45,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:46,210][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 8.422083854675293, acc: 0.0)
[2024-12-14 02:03:46,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:46,602][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 8.026050567626953, acc: 0.03846153989434242)
[2024-12-14 02:03:46,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:47,026][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 7.235806465148926, acc: 0.03448275849223137)
[2024-12-14 02:03:47,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:47,418][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.489414691925049, acc: 0.0)
[2024-12-14 02:03:47,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:47,772][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 8.656981468200684, acc: 0.0476190485060215)
[2024-12-14 02:03:47,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:48,126][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.894583702087402, acc: 0.0)
[2024-12-14 02:03:48,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:48,502][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 6.244065284729004, acc: 0.03773584961891174)
[2024-12-14 02:03:48,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:48,862][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 5.649690628051758, acc: 0.09589041024446487)
[2024-12-14 02:03:49,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:50,212][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 4.121594429016113, acc: 0.22529643774032593)
[2024-12-14 02:03:50,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:50,548][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.630660057067871, acc: 0.04651162773370743)
[2024-12-14 02:03:50,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:50,878][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.41885232925415, acc: 0.14457830786705017)
[2024-12-14 02:03:51,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:51,239][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.221677303314209, acc: 0.12345679104328156)
[2024-12-14 02:03:51,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:51,606][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 7.4604411125183105, acc: 0.0)
[2024-12-14 02:03:51,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:51,987][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 7.227628231048584, acc: 0.0)
[2024-12-14 02:03:52,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:52,417][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 7.917994499206543, acc: 0.0)
[2024-12-14 02:03:52,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:52,854][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 5.212329864501953, acc: 0.1428571492433548)
[2024-12-14 02:03:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:53,220][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.497223377227783, acc: 0.16393442451953888)
[2024-12-14 02:03:53,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:53,639][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.860593318939209, acc: 0.0634920671582222)
[2024-12-14 02:03:53,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:54,058][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 6.32066535949707, acc: 0.050847455859184265)
[2024-12-14 02:03:54,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:54,442][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 4.922025680541992, acc: 0.2298850566148758)
[2024-12-14 02:03:54,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:54,785][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 7.6887664794921875, acc: 0.0)
[2024-12-14 02:03:54,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:55,207][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 6.908340930938721, acc: 0.03846153989434242)
[2024-12-14 02:03:55,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:55,609][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.051285743713379, acc: 0.22972972691059113)
[2024-12-14 02:03:55,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:56,022][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.2041015625, acc: 0.1846153885126114)
[2024-12-14 02:03:56,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:56,521][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.103582382202148, acc: 0.1818181872367859)
[2024-12-14 02:03:56,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:56,987][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.613938331604004, acc: 0.25773194432258606)
[2024-12-14 02:03:57,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:57,400][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 4.894407272338867, acc: 0.1617647111415863)
[2024-12-14 02:03:57,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:57,780][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 7.729205131530762, acc: 0.0)
[2024-12-14 02:03:57,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:58,122][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 7.000524997711182, acc: 0.03703703731298447)
[2024-12-14 02:03:58,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:58,518][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 7.122647285461426, acc: 0.0)
[2024-12-14 02:03:58,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:58,909][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.2030110359191895, acc: 0.02777777798473835)
[2024-12-14 02:03:59,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:59,320][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.286816120147705, acc: 0.21052631735801697)
[2024-12-14 02:03:59,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:03:59,754][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.327968597412109, acc: 0.1587301641702652)
[2024-12-14 02:03:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:00,147][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.301796913146973, acc: 0.15492957830429077)
[2024-12-14 02:04:00,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:00,661][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.614581108093262, acc: 0.25999999046325684)
[2024-12-14 02:04:00,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:01,128][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.52903413772583, acc: 0.027027027681469917)
[2024-12-14 02:04:01,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:01,549][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 7.140427589416504, acc: 0.0)
_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-12-14 02:04:01,336][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 02:04:01,336][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'cov1d-linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 02:04:01,336][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-14_02-04-00.txt', 'log_interval': 5}
[2024-12-14 02:04:03,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:04,541][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.370478391647339, acc: 0.35836178064346313)
[2024-12-14 02:04:05,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:05,860][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.735059976577759, acc: 0.29411765933036804)
[2024-12-14 02:04:06,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:06,524][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 4.013401985168457, acc: 0.2613636255264282)
[2024-12-14 02:04:06,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:07,106][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.296534538269043, acc: 0.19117647409439087)
[2024-12-14 02:04:07,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:07,680][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 3.976667881011963, acc: 0.23188406229019165)
[2024-12-14 02:04:07,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:08,138][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.24889612197876, acc: 0.30000001192092896)
[2024-12-14 02:04:08,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:08,489][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 5.895434856414795, acc: 0.029411764815449715)
[2024-12-14 02:04:08,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:08,858][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 5.878750324249268, acc: 0.0833333358168602)
[2024-12-14 02:04:08,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:09,221][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 4.011167526245117, acc: 0.28125)
[2024-12-14 02:04:09,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:09,581][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 4.965075492858887, acc: 0.27586206793785095)
[2024-12-14 02:04:09,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:09,930][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 4.531731605529785, acc: 0.25)
[2024-12-14 02:04:10,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:10,322][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 4.922064304351807, acc: 0.0833333358168602)
[2024-12-14 02:04:10,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:10,682][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 6.38623046875, acc: 0.0)
[2024-12-14 02:04:10,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:11,024][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 5.44488525390625, acc: 0.1388888955116272)
[2024-12-14 02:04:11,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:11,363][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 5.812061309814453, acc: 0.06060606241226196)
[2024-12-14 02:04:11,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:11,750][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 4.14073371887207, acc: 0.24264705181121826)
[2024-12-14 02:04:11,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:12,126][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 3.8082573413848877, acc: 0.2222222238779068)
[2024-12-14 02:04:12,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:12,576][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.138217449188232, acc: 0.23076923191547394)
[2024-12-14 02:04:12,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:12,875][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 4.879308223724365, acc: 0.10204081982374191)
[2024-12-14 02:04:12,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:13,218][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.528855800628662, acc: 0.14179104566574097)
[2024-12-14 02:04:13,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:13,617][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 3.680405855178833, acc: 0.2810218930244446)
[2024-12-14 02:04:13,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:14,006][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 6.12096643447876, acc: 0.0)
[2024-12-14 02:04:14,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:14,418][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 5.586557388305664, acc: 0.0833333358168602)
[2024-12-14 02:04:14,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:14,828][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 4.934035301208496, acc: 0.03030303120613098)
[2024-12-14 02:04:14,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:15,180][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 5.192331790924072, acc: 0.03846153989434242)
[2024-12-14 02:04:15,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:15,584][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 4.741358280181885, acc: 0.09615384787321091)
[2024-12-14 02:04:15,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:16,026][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 4.791391849517822, acc: 0.07692307978868484)
[2024-12-14 02:04:16,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:16,418][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 4.256313800811768, acc: 0.21875)
[2024-12-14 02:04:16,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:16,849][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 4.6431427001953125, acc: 0.17391304671764374)
[2024-12-14 02:04:16,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:17,289][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 4.401451587677002, acc: 0.2199999988079071)
[2024-12-14 02:04:17,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:17,689][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 5.23825740814209, acc: 0.08695652335882187)
[2024-12-14 02:04:17,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:18,209][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 4.150135040283203, acc: 0.2199999988079071)
[2024-12-14 02:04:18,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:18,608][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 3.57737398147583, acc: 0.3106796145439148)
[2024-12-14 02:04:18,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:19,727][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 3.4592769145965576, acc: 0.3689320385456085)
[2024-12-14 02:04:19,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:20,588][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 3.6506924629211426, acc: 0.2526881694793701)
[2024-12-14 02:04:20,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:21,398][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.2141664028167725, acc: 0.375)
[2024-12-14 02:04:21,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:22,153][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 3.4964921474456787, acc: 0.3052631616592407)
[2024-12-14 02:04:22,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:23,141][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 3.619610548019409, acc: 0.22772277891635895)
[2024-12-14 02:04:23,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:23,458][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 3.8130316734313965, acc: 0.19354838132858276)
[2024-12-14 02:04:23,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:23,765][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 02:04:29,621][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:04:29,623][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 02:04:29,625][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:04:29,627][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

01/574 completed (loss: 3.821962594985962, acc: 0.1818181872367859)
[2024-12-14 02:04:26,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:26,704][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 3.4273555278778076, acc: 0.1304347813129425)
[2024-12-14 02:04:26,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:27,092][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 3.356924295425415, acc: 0.25)
[2024-12-14 02:04:27,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:27,500][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 3.7904207706451416, acc: 0.18965516984462738)
[2024-12-14 02:04:27,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:27,848][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 3.728733539581299, acc: 0.13953489065170288)
[2024-12-14 02:04:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:28,194][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 3.32772159576416, acc: 0.2800000011920929)
[2024-12-14 02:04:28,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:28,575][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 3.5863888263702393, acc: 0.23529411852359772)
[2024-12-14 02:04:28,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:28,953][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 3.6868233680725098, acc: 0.26923078298568726)
[2024-12-14 02:04:29,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:29,364][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 3.932056188583374, acc: 0.190476194024086)
[2024-12-14 02:04:29,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:29,783][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 3.940547466278076, acc: 0.2461538463830948)
[2024-12-14 02:04:29,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:30,240][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 3.6193318367004395, acc: 0.2982456088066101)
[2024-12-14 02:04:30,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:30,702][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 3.321291923522949, acc: 0.28070175647735596)
[2024-12-14 02:04:30,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:31,071][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 3.9400904178619385, acc: 0.23076923191547394)
[2024-12-14 02:04:31,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:31,463][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 3.234636068344116, acc: 0.36734694242477417)
[2024-12-14 02:04:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:31,872][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 3.5775513648986816, acc: 0.27272728085517883)
[2024-12-14 02:04:32,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:32,317][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.1594386100769043, acc: 0.2539682686328888)
[2024-12-14 02:04:32,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:32,808][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.1840739250183105, acc: 0.2601625919342041)
[2024-12-14 02:04:32,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:33,193][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 3.208329677581787, acc: 0.33870968222618103)
[2024-12-14 02:04:38,609][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:04:38,614][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 02:04:38,615][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 02:04:38,929][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:04:38,931][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 02:04:39,022][slam_llm.utils.train_utils][INFO] - --> Module cov1d-linear
[2024-12-14 02:04:39,022][slam_llm.utils.train_utils][INFO] - --> cov1d-linear has 11.539456 Million params

[2024-12-14 02:04:39,023][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 02:04:39,027][slam_llm.utils.train_utils][INFO] - --> asr has 17.175552 Million params

65283203, acc: 0.125)
[2024-12-14 02:04:35,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:35,510][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 3.1570115089416504, acc: 0.21052631735801697)
[2024-12-14 02:04:35,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:35,893][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.29833984375, acc: 0.23312883079051971)
[2024-12-14 02:04:36,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:36,270][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 2.6167311668395996, acc: 0.4166666567325592)
[2024-12-14 02:04:36,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:36,634][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.1306004524230957, acc: 0.2083333283662796)
[2024-12-14 02:04:36,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:37,007][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.040029525756836, acc: 0.2380952388048172)
[2024-12-14 02:04:37,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:37,426][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.178504705429077, acc: 0.2666666805744171)
[2024-12-14 02:04:37,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:37,852][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 2.7341701984405518, acc: 0.36764705181121826)
[2024-12-14 02:04:37,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:38,212][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.549075126647949, acc: 0.1538461595773697)
[2024-12-14 02:04:38,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:38,545][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 2.773150682449341, acc: 0.30434781312942505)
[2024-12-14 02:04:38,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:38,926][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.6674964427948, acc: 0.1875)
[2024-12-14 02:04:39,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:39,326][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 2.505232334136963, acc: 0.30434781312942505)
[2024-12-14 02:04:39,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:39,753][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 2.7542245388031006, acc: 0.2857142984867096)
[2024-12-14 02:04:39,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:40,108][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 2.701447010040283, acc: 0.26923078298568726)
[2024-12-14 02:04:40,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:40,478][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.4096553325653076, acc: 0.2142857164144516)
[2024-12-14 02:04:40,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:40,827][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 2.3732120990753174, acc: 0.4000000059604645)
4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-12-14 02:04:40,704][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 02:04:40,704][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'cov1d-linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 02:04:40,704][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-14_02-04-39.txt', 'log_interval': 5}
[2024-12-14 02:04:41,011][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 02:04:42,723][root][INFO] - --> Training Set Length = 2298
[2024-12-14 02:04:42,740][root][INFO] - --> Validation Set Length = 341
[2024-12-14 02:04:42,740][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 02:04:42,741][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 02:04:44,555][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:04:46,582][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:04:48,623][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 8.621565818786621, acc: 0.03703703731298447)
[2024-12-14 02:04:48,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:49,085][slam_llm.models.slam_model][INFO] - modality encoder
                                        [2024-12-14 02:04:49,482][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                       [2024-12-14 02:04:49,843][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                       [2024-12-14 02:04:50,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:50,495][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:04:50,861][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                      [2024-12-14 02:04:51,316][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                       [2024-12-14 02:04:51,767][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                      [2024-12-14 02:04:52,189][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                      [2024-12-14 02:04:52,579][slam_llm.models.slam_model][INFO] - modality encoder
                                        [2024-12-14 02:04:52,920][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:04:53,296][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                      [2024-12-14 02:04:53,665][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                       [2024-12-14 02:04:54,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:54,303][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:04:54,591][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                        [2024-12-14 02:04:54,981][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:04:55,328][slam_llm.models.slam_model][INFO] - modality encoder
                                         [2024-12-14 02:04:55,648][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                       [2024-12-14 02:04:56,027][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:04:56,330][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                        [2024-12-14 02:04:56,785][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:04:57,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:04:57,448][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:04:57,815][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                        [2024-12-14 02:04:58,237][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:04:58,592][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                        [2024-12-14 02:04:58,969][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:04:59,283][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:04:59,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:00,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:00,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:01,020][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:05:01,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:01,855][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:05:02,249][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:05:02,628][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                       [2024-12-14 02:05:03,027][slam_llm.models.slam_model][INFO] - modality encoder
                                         [2024-12-14 02:05:03,362][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                        [2024-12-14 02:05:03,689][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:05:04,072][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:05:04,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:04,337][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 02:05:04,533][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.862399578094482, acc: 0.0634920671582222)
[2024-12-14 02:05:04,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:04,938][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 6.31829833984375, acc: 0.050847455859184265)
[2024-12-14 02:05:05,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:05,346][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 4.923478603363037, acc: 0.2298850566148758)
[2024-12-14 02:05:05,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:05,762][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 7.678971767425537, acc: 0.0)
[2024-12-14 02:05:05,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:06,214][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 6.918570518493652, acc: 0.03846153989434242)
[2024-12-14 02:05:06,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:06,658][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.055219650268555, acc: 0.22972972691059113)
[2024-12-14 02:05:06,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:07,108][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.203996181488037, acc: 0.1846153885126114)
[2024-12-14 02:05:07,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:07,615][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.107167720794678, acc: 0.1818181872367859)
[2024-12-14 02:05:07,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:08,084][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.614425182342529, acc: 0.25773194432258606)
[2024-12-14 02:05:08,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:08,555][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 4.88492488861084, acc: 0.1617647111415863)
[2024-12-14 02:05:08,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:08,905][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 7.7347517013549805, acc: 0.0)
[2024-12-14 02:05:09,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:09,298][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 6.994741439819336, acc: 0.03703703731298447)
[2024-12-14 02:05:09,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:09,732][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 7.129693508148193, acc: 0.0)
[2024-12-14 02:05:09,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:10,132][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.215939998626709, acc: 0.02777777798473835)
[2024-12-14 02:05:10,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:10,300][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:05:10,302][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 02:05:10,304][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 02:05:10,305][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 02:05:10,589][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.286271095275879, acc: 0.21052631735801697)
[2024-12-14 02:05:10,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:10,972][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.355207443237305, acc: 0.1428571492433548)
[2024-12-14 02:05:11,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:11,379][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.301954746246338, acc: 0.14084507524967194)
[2024-12-14 02:05:11,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:11,904][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.617626190185547, acc: 0.25999999046325684)
[2024-12-14 02:05:12,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:12,378][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.525289535522461, acc: 0.027027027681469917)
[2024-12-14 02:05:12,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:12,811][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 7.1157097816467285, acc: 0.0)
[2024-12-14 02:05:14,475][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:05:15,987][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.390915632247925, acc: 0.35836178064346313)
[2024-12-14 02:05:16,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:16,519][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:05:16,521][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 02:05:16,522][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 02:05:16,849][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 02:05:16,851][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 02:05:16,937][slam_llm.utils.train_utils][INFO] - --> Module cov1d-linear
[2024-12-14 02:05:16,937][slam_llm.utils.train_utils][INFO] - --> cov1d-linear has 11.539456 Million params

[2024-12-14 02:05:16,938][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 02:05:16,942][slam_llm.utils.train_utils][INFO] - --> asr has 17.175552 Million params

[2024-12-14 02:05:17,196][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.7395846843719482, acc: 0.2897603511810303)
                                                                                                                [2024-12-14 02:05:17,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:17,898][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 3.9881186485290527, acc: 0.27272728085517883)
                                                                                                                                                                                                                       [2024-12-14 02:05:18,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:18,477][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.307674407958984, acc: 0.18382352590560913)
 [2024-12-14 02:05:18,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:19,066][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 3.9829392433166504, acc: 0.23188406229019165)
 [2024-12-14 02:05:19,132][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 02:05:19,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:19,562][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.246064186096191, acc: 0.30000001192092896)
 [2024-12-14 02:05:19,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:19,925][root][INFO] -.24137930572032928)
[2024-12-14 02:05:19,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:20,139][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 2.6923928260803223, acc: 0.30434781312942505)
[2024-12-14 02:05:20,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:20,570][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 2.5031187534332275, acc: 0.32203391194343567)
                                                                                                                                                                                               [2024-12-14 02:05:20,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:20,976][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 3.2527806758880615, acc: 0.17543859779834747)
[2024-12-14 02:05:21,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:21,335][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 2.895069122314453, acc: 0.36486485600471497)
[2024-12-14 02:05:21,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:21,755][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 2.7823007106781006, acc: 0.5357142686843872)
[2024-12-14 02:05:21,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:22,147][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.3379249572753906, acc: 0.3913043439388275)
[2024-12-14 02:05:22,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:22,501][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 3.023921251296997, acc: 0.21052631735801697)
                                          [2024-12-14 02:05:23,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:24,214][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 2.912972927093506, acc: 0.37837839126586914)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:05:24,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:24,528][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 2.7547435760498047, acc: 0.37037035822868347)
[2024-12-14 02:05:24,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:25,005][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 2.9409029483795166, acc: 0.3488371968269348)
                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:05:25,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:25,627][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 2.727393627166748, acc: 0.38823530077934265)
                                                                                                                                                                                                     [2024-12-14 02:05:25,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:26,187][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 2.856297254562378, acc: 0.30337077379226685)
                                                                                                                                                                                                    [2024-12-14 02:05:26,297][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                       [2024-12-14 02:05:26,520][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 2.580709218978882, acc: 0.3863636255264282)
                                                                               [2024-12-14 02:05:26,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:26,915][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 2.67924165725708, acc: 0.3333333432674408)
                                                                                                                                                                                                     [2024-12-14 02:05:27,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:27,307][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 3.0797643661499023, acc: 0.2068965584039688)
                                                                                                                                                                                                      [2024-12-14 02:05:27,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:27,701][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 2.1869847774505615, acc: 0.4693877696990967)
                                                                                                                                                                                                     [2024-12-14 02:05:27,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:28,079][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 2.594769239425659, acc: 0.2800000011920929)
                                                                               [2024-12-14 02:05:28,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:28,491][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 2.528808116912842, acc: 0.3888888955116272)
                                                                                                                                                                                                     [2024-12-14 02:05:28,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:28,876][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 2.647878408432007, acc: 0.3137255012989044)
                                                                                                                                                                                       [2024-12-14 02:05:29,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:29,914][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 2.9899020195007324, acc: 0.3219178020954132)
ted (loss: 4.630029201507568, acc: 0.17391304671764374)
[2024-12-14 02:05:29,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:29,335][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 7.0814208984375, acc: 0.0)
[2024-12-14 02:05:29,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:29,496][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 4.3934526443481445, acc: 0.20000000298023224)
[2024-12-14 02:05:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:29,688][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 7.82857608795166, acc: 0.0)
[2024-12-14 02:05:29,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:29,877][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 5.227978706359863, acc: 0.08695652335882187)
[2024-12-14 02:05:30,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:30,090][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 6.806736946105957, acc: 0.043478261679410934)
[2024-12-14 02:05:30,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:30,392][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 4.146073341369629, acc: 0.2199999988079071)
[2024-12-14 02:05:30,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:30,530][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 7.391972064971924, acc: 0.0)
[2024-12-14 02:05:30,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:30,809][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 3.5846974849700928, acc: 0.3203883469104767)
[2024-12-14 02:05:30,914][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 6.198968887329102, acc: 0.12244898080825806)
[2024-12-14 02:05:31,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:31,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:31,266][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.712297439575195, acc: 0.0)
[2024-12-14 02:05:31,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:31,629][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.23022174835205, acc: 0.0)
[2024-12-14 02:05:31,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:31,968][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 3.466585397720337, acc: 0.3640776574611664)
[2024-12-14 02:05:32,058][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.781171798706055, acc: 0.02777777798473835)
[2024-12-14 02:05:32,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:32,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:32,481][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 8.422083854675293, acc: 0.0)
[2024-12-14 02:05:32,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:32,792][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 3.6594274044036865, acc: 0.2526881694793701)
[2024-12-14 02:05:32,904][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 8.026050567626953, acc: 0.03846153989434242)
[2024-12-14 02:05:33,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:33,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:33,292][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 7.235806465148926, acc: 0.03448275849223137)
[2024-12-14 02:05:33,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:33,605][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.2122442722320557, acc: 0.375)
[2024-12-14 02:05:33,654][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.489414691925049, acc: 0.0)
[2024-12-14 02:05:33,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:33,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:34,018][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 8.656981468200684, acc: 0.0476190485060215)
[2024-12-14 02:05:34,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:34,388][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 3.4967713356018066, acc: 0.3052631616592407)
[2024-12-14 02:05:34,442][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.894583702087402, acc: 0.0)
[2024-12-14 02:05:34,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:34,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:34,893][root][INFO] - Training Epoch: 1/[2024-12-14 02:05:34,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:35,182][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 2.5553886890411377, acc: 0.3199999928474426)
[2024-12-14 02:05:35,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:35,594][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 2.9684135913848877, acc: 0.2142857164144516)
                                                                             [2024-12-14 02:05:35,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:36,028][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 2.958486318588257, acc: 0.24390244483947754)
[2024-12-14 02:05:36,179][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:05:36,417][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 2.915306806564331, acc: 0.31419938802719116)
[2024-12-14 02:05:36,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:36,783][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 2.9914016723632812, acc: 0.24495677649974823)
                                                                             [2024-12-14 02:05:36,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:37,307][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.0017902851104736, acc: 0.2562499940395355)
                                                                                                                                                                                                                       [2024-12-14 02:05:37,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:37,853][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 2.7289955615997314, acc: 0.3151969909667969)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:05:38,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:38,303][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 2.748997926712036, acc: 0.30249109864234924)
                                                                                                                                                                                                                                                                                       [2024-12-14 02:05:38,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:38,682][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 3.3650753498077393, acc: 0.3199999928474426)
                                                                                                                        [2024-12-14 02:05:38,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:39,261][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 2.728222131729126, acc: 0.26744186878204346)
                                                                                                                                                                                                                                                                                     [2024-12-14 02:05:39,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:40,058][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 2.703977346420288, acc: 0.3333333432674408)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:05:40,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:40,972][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 2.6179819107055664, acc: 0.3863636255264282)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:05:41,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:41,734][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 2.370743751525879, acc: 0.48235294222831726)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:05:42,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:42,816][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 2.3732285499572754, acc: 0.40123456716537476)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:05:43,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:43,766][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 2.395599365234375, acc: 0.4354838728904724)
[2024-12-14 02:05:43,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:43,251][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.1075849533081055, acc: 0.1818181872367859)
[2024-12-14 02:05:43,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:43,460][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 3.946469783782959, acc: 0.25641027092933655)
[2024-12-14 02:05:43,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:43,711][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.6158342361450195, acc: 0.25773194432258606)
[2024-12-14 02:05:43,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:43,917][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 3.2360141277313232, acc: 0.36734694242477417)
[2024-12-14 02:05:44,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:44,162][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 4.884797096252441, acc: 0.1617647111415863)
[2024-12-14 02:05:44,283][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 3.571535348892212, acc: 0.22727273404598236)
[2024-12-14 02:05:44,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:44,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:44,531][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 7.732970237731934, acc: 0.0)
[2024-12-14 02:05:44,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:44,735][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.167456865310669, acc: 0.2380952388048172)
[2024-12-14 02:05:44,898][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 6.996291160583496, acc: 0.03703703731298447)
[2024-12-14 02:05:44,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:45,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:45,175][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.1878504753112793, acc: 0.2601625919342041)
[2024-12-14 02:05:45,274][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 7.128653526306152, acc: 0.0)
[2024-12-14 02:05:45,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:45,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:45,519][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 3.216862678527832, acc: 0.35483869910240173)
[2024-12-14 02:05:45,657][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.215758323669434, acc: 0.02777777798473835)
[2024-12-14 02:05:45,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:45,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:46,070][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.286930561065674, acc: 0.21052631735801697)
[2024-12-14 02:05:46,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:46,439][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.353036880493164, acc: 0.1428571492433548)
[2024-12-14 02:05:46,441][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.0225110054016113, acc: 0.32319390773773193)
[2024-12-14 02:05:46,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:46,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:46,804][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.301549911499023, acc: 0.14084507524967194)
[2024-12-14 02:05:46,863][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 3.100771427154541, acc: 0.3199999928474426)
[2024-12-14 02:05:47,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:47,503][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 2.76334810256958, acc: 0.3094170391559601)
1/10, step 121/574 completed (loss: 3.4188857078552246, acc: 0.3461538553237915)
[2024-12-14 02:05:47,346][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.618106842041016, acc: 0.25999999046325684)
[2024-12-14 02:05:47,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:47,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:47,669][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 3.9687607288360596, acc: 0.125)
[2024-12-14 02:05:47,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:47,843][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.518202304840088, acc: 0.027027027681469917)
[2024-12-14 02:05:48,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:48,107][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 3.15805983543396, acc: 0.15789473056793213)
[2024-12-14 02:05:48,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:48,340][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 7.122299671173096, acc: 0.0)
[2024-12-14 02:05:48,468][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.301145315170288, acc: 0.23926380276679993)
[2024-12-14 02:05:48,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:48,946][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 2.6144988536834717, acc: 0.4166666567325592)
[2024-12-14 02:05:49,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:49,338][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.1330416202545166, acc: 0.2083333283662796)
[2024-12-14 02:05:49,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:49,722][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.03596830368042, acc: 0.244047611951828)
[2024-12-14 02:05:49,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:50,107][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.1801507472991943, acc: 0.2769230902194977)
[2024-12-14 02:05:50,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:50,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:50,571][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 2.7321646213531494, acc: 0.36764705181121826)
[2024-12-14 02:05:50,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:50,914][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.565709114074707, acc: 0.1538461595773697)
[2024-12-14 02:05:51,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:51,339][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 2.767252206802368, acc: 0.30434781312942505)
[2024-12-14 02:05:51,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:51,708][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.3897228240966797, acc: 0.35494881868362427)
[2024-12-14 02:05:51,770][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.6760597229003906, acc: 0.1875)
[2024-12-14 02:05:51,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:52,140][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 2.5146732330322266, acc: 0.30434781312942505)
[2024-12-14 02:05:52,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:52,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:52,522][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 2.7574853897094727, acc: 0.2857142984867096)
[2024-12-14 02:05:52,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:52,889][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 2.7067296504974365, acc: 0.26923078298568726)
[2024-12-14 02:05:52,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:53,183][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.7388498783111572, acc: 0.29193899035453796)
[2024-12-14 02:05:53,260][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.400270700454712, acc: 0.2142857164144516)
[2024-12-14 02:05:53,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:53,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:53,680]59009, acc: 0.48148149251937866)
[2024-12-14 02:05:53,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:54,018][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 1.9427061080932617, acc: 0.3199999928474426)
                                                                              [2024-12-14 02:05:54,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:54,444][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 2.5530736446380615, acc: 0.3076923191547394)
 [2024-12-14 02:05:54,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:55,249][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 2.258248805999756, acc: 0.45108696818351746)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:05:55,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:55,811][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 2.567624092102051, acc: 0.3295454680919647)
                                                                                                                                                                                                                         [2024-12-14 02:05:55,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:56,291][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 2.6961700916290283, acc: 0.2978723347187042)
                                                                                                                                                                                                                        [2024-12-14 02:05:56,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:56,683][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 2.764739751815796, acc: 0.30188679695129395)
[2024-12-14 02:05:56,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:57,064][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 2.4569578170776367, acc: 0.4166666567325592)
                                                              [2024-12-14 02:05:57,173][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:05:57,448][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 2.0626981258392334, acc: 0.39534884691238403)
[2024-12-14 02:05:57,560][slam_llm.models.slam_model][INFO] - modality encoder
                                                                          [2024-12-14 02:05:57,774][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 2.268723726272583, acc: 0.4000000059604645)
[2024-12-14 02:05:57,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:58,240][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 2.8080039024353027, acc: 0.2526315748691559)
                    [2024-12-14 02:05:58,360][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                        [2024-12-14 02:05:58,618][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 2.3551721572875977, acc: 0.41111111640930176)
[2024-12-14 02:05:58,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:59,081][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 2.187718629837036, acc: 0.4833333194255829)
                                                                                                                                                                                                                                           [2024-12-14 02:05:59,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:05:59,615][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 2.2146825790405273, acc: 0.4587155878543854)
                                                                                                                                                             [2024-12-14 02:05:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:00,100][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 2.1401891708374023, acc: 0.4076923131942749)
                                                                             [2024-12-14 02:06:00,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:00,482][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 2.042055606842041, acc: 0.3684210479259491)
                                                                               [2024-12-14 02:06:00,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:00,877][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 2.076585054397583, acc: 0.4166666567325592)
 [2024-12-14 02:06:01,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:01,302][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 2.496520757675171, acc: 0.3181818127632141)
[2024-12-14 02:06:01,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:01,719][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 1.9880584478378296, acc: 0.4444444477558136)
                                                                                                                                                             [2024-12-14 02:06:01,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:02,090][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.152350902557373, acc: 0.4571428596973419)
                                                             [2024-12-14 02:06:02,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:02,500][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 1.929958462715149, acc: 0.3863636255264282)
                                                                             [2024-12-14 02:06:02,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:02,919][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 2.232060670852661, acc: 0.4545454680919647)
                                                                               [2024-12-14 02:06:03,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:03,592][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 2.32621693611145, acc: 0.3870967626571655)
                                                                                                                                                                                                                                             [2024-12-14 02:06:03,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:04,163][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 2.319443702697754, acc: 0.3636363744735718)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:06:04,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:04,488][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 1.9388431310653687, acc: 0.4285714328289032)
[2024-12-14 02:06:04,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:04,873][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 2.441591739654541, acc: 0.3076923191547394)
                                                               [2024-12-14 02:06:04,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:05,224][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 2.9145162105560303, acc: 0.16129031777381897)
                                                                              [2024-12-14 02:06:05,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:05,542][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.0374503135681152, acc: 0.5)
[2024-12-14 02:06:05,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:05,977][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 2.4335339069366455, acc: 0.4054054021835327)
                                   [2024-12-14 02:06:06,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:06,380][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 2.4300012588500977, acc: 0.3243243098258972)
[2024-12-14 02:06:06,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:06,752][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 2.555745840072632, acc: 0.3243243098258972)
                                                                            [2024-12-14 02:06:06,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:07,146][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 2.644951581954956, acc: 0.3382352888584137)
[2024-12-14 02:06:07,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:07,489][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 1.6839519739151, acc: 0.5609756112098694)
[2024-12-14 02:06:07,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:07,870][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 1.7345340251922607, acc: 0.5600000023841858)
[2024-12-14 02:06:07,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:08,244][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 1.5194278955459595, acc: 0.4000000059604645)
[2024-12-14 02:06:08,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:08,613][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 2.4405062198638916, acc: 0.35483869910240173)
[2024-12-14 02:06:08,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:09,002][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 2.525233268737793, acc: 0.3333333432674408)
[2024-12-14 02:06:09,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:09,405][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 2.586242914199829, acc: 0.3285714387893677)
[2024-12-14 02:06:09,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:09,810][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 2.3958261013031006, acc: 0.3947368562221527)
[2024-12-14 02:06:09,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:10,403][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 2.3469789028167725, acc: 0.38679245114326477)
[2024-12-14 02:06:10,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:11,012][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 2.390143632888794, acc: 0.375)
[2024-12-14 02:06:11,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:11,379][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 2.378547191619873, acc: 0.4722222089767456)
 [2024-12-14 02:06:11,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:11,800][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 2.7769439220428467, acc: 0.29032257199287415)
                                                                             [2024-12-14 02:06:11,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:12,173][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 2.8883774280548096, acc: 0.2800000011920929)
                                                                              [2024-12-14 02:06:12,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:12,584][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 2.5863912105560303, acc: 0.4166666567325592)
[2024-12-14 02:06:12,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:13,460][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 2.761110305786133, acc: 0.2800000011920929)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:06:13,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:13,793][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 2.513000011444092, acc: 0.3932584226131439)
[2024-12-14 02:06:13,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:14,171][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 2.5724239349365234, acc: 0.3378378450870514)
[2024-12-14 02:06:14,304][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:06:14,635][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 1.987339735031128, acc: 0.4482758641242981)
[2024-12-14 02:06:14,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:14,957][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 2.325090169906616, acc: 0.27272728085517883)
[2024-12-14 02:06:15,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:15,371][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 1.7540634870529175, acc: 0.4545454680919647)
                                                                                                    [2024-12-14 02:06:15,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:15,772][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 1.8605225086212158, acc: 0.46875)
                                                                           [2024-12-14 02:06:15,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:16,202][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 1.8962849378585815, acc: 0.46666666865348816)
                                                                              [2024-12-14 02:06:16,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:16,629][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 2.6060311794281006, acc: 0.36666667461395264)
                                                                                                                                                             [2024-12-14 02:06:16,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:17,007][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.2029001712799072, acc: 0.4375)
[2024-12-14 02:06:17,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:17,394][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 1.7479110956192017, acc: 0.5666666626930237)
            [2024-12-14 02:06:17,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:17,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:17,425][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 3.680760383605957, acc: 0.26923078298568726)
[2024-12-14 02:06:17,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:17,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:17,864][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 3.9308977127075195, acc: 0.190476194024086)
[2024-12-14 02:06:18,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:18,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:18,292][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 3.94569993019104, acc: 0.2461538463830948)
[2024-12-14 02:06:18,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:18,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:18,825][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 3.6184306144714355, acc: 0.2982456088066101)
[2024-12-14 02:06:18,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:19,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:19,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:19,267][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 3.3311352729797363, acc: 0.2982456088066101)
[2024-12-14 02:06:19,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:19,645][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 3.945692777633667, acc: 0.25641027092933655)
[2024-12-14 02:06:19,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:19,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:20,024][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 3.2424323558807373, acc: 0.36734694242477417)
[2024-12-14 02:06:20,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:20,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:20,445][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 3.5912842750549316, acc: 0.22727273404598236)
[2024-12-14 02:06:20,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:20,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:20,886][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.1548011302948, acc: 0.2539682686328888)
[2024-12-14 02:06:21,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:21,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:21,338][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.1816635131835938, acc: 0.24390244483947754)
[2024-12-14 02:06:21,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:21,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:21,703][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 3.199875831604004, acc: 0.35483869910240173)
[2024-12-14 02:06:21,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:22,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:22,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:22,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:22,654][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.0879406929016113, acc: 0.32319390773773193)
[2024-12-14 02:06:22,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:23,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:23,063][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 3.0924854278564453, acc: 0.3333333432674408)
[2024-12-14 02:06:23,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:23,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:23,527][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 3.4204723834991455, acc: 0.32692307233810425)
[2024-12-14 02:06:23,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:23,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:23,930][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 3.976539373397827, acc: 0.125)
[2024-12-14 02:06:24,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:24,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:24,324][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 3.1306259632110596, acc: 0.15789473056793213)
[2024-12-14 02:06:24,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:24,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:24,664][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.3005940914154053, acc: 0.21472392976284027)
[2024-12-14 02:06:24,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:24,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:25,063][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 2.6296753883361816, acc: 0.4166666567325592)
[2024-12-14 02:06:25,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:25,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:25,495][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.1391334533691406, acc: 0.2083333283662796)
[2024-12-14 02:06:25,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:25,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:25,906][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.040085554122925, acc: 0.255952388048172)
[2024-12-14 02:06:25,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:26,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:26,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:26,373][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.1804115772247314, acc: 0.2666666805744171)
[2024-12-14 02:06:26,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:26,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:26,844][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 2.7233664989471436, acc: 0.375)
[2024-12-14 02:06:27,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:27,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:27,283][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.561656951904297, acc: 0.1538461595773697)
[2024-12-14 02:06:27,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:27,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:27,662][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 2.7547919750213623, acc: 0.30434781312942505)
[2024-12-14 02:06:27,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:27,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:28,034][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.6612260341644287, acc: 0.1875)
[2024-12-14 02:06:28,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:28,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:28,378][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 2.520667314529419, acc: 0.30434781312942505)
[2024-12-14 02:06:28,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:28,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:28,726][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 2.7583017349243164, acc: 0.2857142984867096)
[2024-12-14 02:06:29,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:29,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:29,114][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 2.727449655532837, acc: 0.26923078298568726)
[2024-12-14 02:06:29,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:29,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:29,574][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.4041450023651123, acc: 0.2142857164144516)
[2024-12-14 02:06:29,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:29,963][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 2.373007297515869, acc: 0.4333333373069763)
[2024-12-14 02:06:30,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:30,217][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(20.2968, device='cuda:0') eval_epoch_loss=tensor(3.0105, device='cuda:0') eval_epoch_acc=tensor(0.2811, device='cuda:0')
[2024-12-14 02:06:30,219][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:06:30,219][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:06:30,340][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 2.5981857776641846, acc: 0.30434781312942505)
[2024-12-14 02:06:30,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:30,515][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_1_step_143_loss_3.0104615688323975/model.pt
[2024-12-14 02:06:30,518][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:06:30,518][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.0104615688323975
[2024-12-14 02:06:30,519][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.2810872197151184
[2024-12-14 02:06:30,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:30,798][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 3.496000289916992, acc: 0.2857142984867096)
[2024-12-14 02:06:30,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:31,116][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 2.376708507537842, acc: 0.44736841320991516)
[2024-12-14 02:06:31,178][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 3.017144203186035, acc: 0.42307692766189575)
[2024-12-14 02:06:31,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:31,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:31,571][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 2.311875343322754, acc: 0.447761207818985)
[2024-12-14 02:06:31,624][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 3.2663469314575195, acc: 0.22580644488334656)
[2024-12-14 02:06:31,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:31,945][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 2.9045443534851074, acc: 0.3163265287876129)
[2024-12-14 02:06:32,089][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.0992608070373535, acc: 0.2432432472705841)
[2024-12-14 02:06:32,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:32,441][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 2.7189557552337646, acc: 0.3404255211353302)
[2024-12-14 02:06:32,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:32,825][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 2.5286617279052734, acc: 0.4000000059604645)
[2024-12-14 02:06:32,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:33,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:33,179][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 3.3018171787261963, acc: 0.2142857164144516)
[2024-12-14 02:06:33,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:33,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:33,578][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 2.540487766265869, acc: 0.3913043439388275)
[2024-12-14 02:06:33,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:33,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:33,992][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 3.0597527027130127, acc: 0.24137930572032928)
[2024-12-14 02:06:34,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:34,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:34,435][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 2.6905455589294434, acc: 0.30434781312942505)
[2024-12-14 02:06:34,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:34,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:34,877][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 2.5121498107910156, acc: 0.32203391194343567)
[2024-12-14 02:06:34,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:35,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:35,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:35,245][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 3.255833625793457, acc: 0.19298245012760162)
[2024-12-14 02:06:35,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:35,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:35,664][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 2.8921592235565186, acc: 0.3513513505458832)
[2024-12-14 02:06:35,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:36,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:36,096][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 2.7665247917175293, acc: 0.5)
[2024-12-14 02:06:36,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:36,479][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.345266342163086, acc: 0.3913043439388275)
[2024-12-14 02:06:36,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:36,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:36,775][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 3.0067481994628906, acc: 0.21052631735801697)
[2024-12-14 02:06:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:37,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:37,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:37,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:38,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:38,565][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 2.9160866737365723, acc: 0.3918918967247009)
[2024-12-14 02:06:38,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:38,905][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 2.7515275478363037, acc: 0.37037035822868347)
[2024-12-14 02:06:39,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:39,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:39,368][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 2.9404778480529785, acc: 0.3604651093482971)
[2024-12-14 02:06:39,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:39,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:40,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:39,989][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 2.727511167526245, acc: 0.38823530077934265)
[2024-12-14 02:06:40,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:40,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:40,552][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 2.8530325889587402, acc: 0.31460675597190857)
[2024-12-14 02:06:40,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:40,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:40,905][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 2.5861477851867676, acc: 0.3863636255264282)
[2024-12-14 02:06:41,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:41,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:41,215][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 2.6872220039367676, acc: 0.3333333432674408)
[2024-12-14 02:06:41,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:41,588][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 3.0738887786865234, acc: 0.2068965584039688)
[2024-12-14 02:06:41,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:41,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:42,027][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 2.1844818592071533, acc: 0.4693877696990967)
[2024-12-14 02:06:42,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:42,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:42,450][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 2.590099573135376, acc: 0.30000001192092896)
[2024-12-14 02:06:42,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:42,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:42,877][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 2.5291669368743896, acc: 0.4166666567325592)
[2024-12-14 02:06:43,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:43,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:43,289][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 2.6510229110717773, acc: 0.3137255012989044)
[2024-12-14 02:06:43,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:43,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:43,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:44,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:44,340][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 2.9938223361968994, acc: 0.3287671208381653)
[2024-12-14 02:06:44,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:44,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:44,726][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 2.572390556335449, acc: 0.375)
[2024-12-14 02:06:44,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:45,114][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 3.1712276935577393, acc: 0.14814814925193787)
[2024-12-14 02:06:45,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:45,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:45,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:45,539][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 2.6814818382263184, acc: 0.2857142984867096)
[2024-12-14 02:06:45,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:45,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:46,215][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 2.2696003913879395, acc: 0.4601770043373108)
[2024-12-14 02:06:46,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:46,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:46,492][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 2.6234242916107178, acc: 0.30434781312942505)
[2024-12-14 02:06:46,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:46,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:46,879][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 2.8576695919036865, acc: 0.28409090638160706)
[2024-12-14 02:06:46,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:47,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:47,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:47,818][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 2.8769874572753906, acc: 0.28244274854660034)
[2024-12-14 02:06:47,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:48,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:48,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:48,489][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 2.93015718460083, acc: 0.22962963581085205)
[2024-12-14 02:06:48,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:48,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:48,800][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 2.751276731491089, acc: 0.2950819730758667)
[2024-12-14 02:06:48,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:48,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:49,155][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 2.287621021270752, acc: 0.3333333432674408)
[2024-12-14 02:06:49,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:49,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:49,484][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 2.556487798690796, acc: 0.3199999928474426)
[2024-12-14 02:06:49,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:49,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:49,807][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 2.973511219024658, acc: 0.2142857164144516)
[2024-12-14 02:06:50,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:50,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:50,262][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 2.9612269401550293, acc: 0.24390244483947754)
[2024-12-14 02:06:50,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:50,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:50,662][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 2.9167685508728027, acc: 0.3081570863723755)
[2024-12-14 02:06:50,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:50,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:50,976][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 2.9946155548095703, acc: 0.24783861637115479)
[2024-12-14 02:06:51,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:51,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:51,475][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.0047707557678223, acc: 0.2593750059604645)
[2024-12-14 02:06:51,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:51,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:51,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:52,014][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 2.731977939605713, acc: 0.3151969909667969)
nb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_1_step_286_loss_2.3733134269714355/model.pt
[2024-12-14 02:06:51,903][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:06:51,904][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.3733134269714355
[2024-12-14 02:06:51,905][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.3820682466030121
[2024-12-14 02:06:52,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:52,274][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 2.45768404006958, acc: 0.3046875)
[2024-12-14 02:06:52,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:52,650][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 2.683804512023926, acc: 0.23199999332427979)
[2024-12-14 02:06:52,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:53,018][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 2.2926158905029297, acc: 0.38461539149284363)
                               [2024-12-14 02:06:53,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:53,411][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 2.6269145011901855, acc: 0.30434781312942505)
[2024-12-14 02:06:53,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:53,849][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 2.7116611003875732, acc: 0.2989690601825714)
[2024-12-14 02:06:53,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:54,195][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 1.5929564237594604, acc: 0.6818181872367859)
[2024-12-14 02:06:54,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:54,557][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.36079740524292, acc: 0.380952388048172)
[2024-12-14 02:06:54,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:54,915][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 2.001530170440674, acc: 0.4655172526836395)
[2024-12-14 02:06:55,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:55,408][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 1.823388695716858, acc: 0.5454545617103577)
                                                                               [2024-12-14 02:06:55,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:55,971][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.1143810749053955, acc: 0.47422680258750916)
                                                                               [2024-12-14 02:06:56,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:56,303][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 2.474147081375122, acc: 0.37931033968925476)
[2024-12-14 02:06:56,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:56,706][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 2.12707781791687, acc: 0.48148149251937866)
[2024-12-14 02:06:56,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:57,074][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 2.269341230392456, acc: 0.44736841320991516)
[2024-12-14 02:06:57,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:57,502][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 2.4520723819732666, acc: 0.4464285671710968)
[2024-12-14 02:06:57,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:57,924][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 2.2821733951568604, acc: 0.40625)
           [2024-12-14 02:06:58,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:58,314][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 2.5044801235198975, acc: 0.35849055647850037)
                                                                              [2024-12-14 02:06:58,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:58,643][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 1.671690583229065, acc: 0.6226415038108826)
[2024-12-14 02:06:58,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:58,970][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 1.9882173538208008, acc: 0.529411792755127)
[2024-12-14 02:06:59,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:59,359][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 2.615497350692749, acc: 0.3125)
                                   [2024-12-14 02:06:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:06:59,736][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 1.9665911197662354, acc: 0.49180328845977783)
                                                                              [2024-12-14 02:06:59,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:00,118][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 1.5148406028747559, acc: 0.5666666626930237)
                                                                             [2024-12-14 02:07:00,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:00,478][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 1.3745750188827515, acc: 0.7368420958518982)
[2024-12-14 02:07:00,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:00,808][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 2.6929986476898193, acc: 0.3333333432674408)
                                                                                [2024-12-14 02:07:00,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:01,239][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.2404491901397705, acc: 0.4305555522441864)
                                                                                                                                                             [2024-12-14 02:07:01,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:01,653][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 2.24692702293396, acc: 0.3734939694404602)
                                                                                [2024-12-14 02:07:01,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:02,034][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 2.759345054626465, acc: 0.3205128312110901)
                                                                                [2024-12-14 02:07:02,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:02,406][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 2.7960450649261475, acc: 0.30612245202064514)
                                                                             [2024-12-14 02:07:02,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:02,765][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 1.0728029012680054, acc: 0.7916666865348816)
[2024-12-14 02:07:02,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:03,110][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 1.9219532012939453, acc: 0.5)
[2024-12-14 02:07:03,225][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                             [2024-12-14 02:07:03,502][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 2.0849249362945557, acc: 0.3870967626571655)
[2024-12-14 02:07:03,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:03,908][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 2.296267032623291, acc: 0.35483869910240173)
                     [2024-12-14 02:07:04,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:04,335][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 2.033928394317627, acc: 0.447761207818985)
                                                                                                                                                                [2024-12-14 02:07:04,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:04,700][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 1.816013216972351, acc: 0.48076921701431274)
                                                                              [2024-12-14 02:07:04,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:05,067][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 2.729674816131592, acc: 0.2222222238779068)
                                                                               [2024-12-14 02:07:05,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:05,484][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 2.2794277667999268, acc: 0.3709677457809448)
[2024-12-14 02:07:05,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:05,891][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 1.6270407438278198, acc: 0.6399999856948853)
[2024-12-14 02:07:06,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:06,290][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 3.0518157482147217, acc: 0.2222222238779068)
[2024-12-14 02:07:06,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:06,626][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 3.9685258865356445, acc: 0.08571428805589676)
                    [2024-12-14 02:07:06,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:07,047][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 2.896444082260132, acc: 0.23076923191547394)
                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:07:07,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:07,420][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 2.767601251602173, acc: 0.3414634168148041)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:07:07,534][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:07:07,770][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 2.3433923721313477, acc: 0.3947368562221527)
[2024-12-14 02:07:07,888][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:07:08,173][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 1.7723394632339478, acc: 0.4736842215061188)
[2024-12-14 02:07:08,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:08,538][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 1.7728627920150757, acc: 0.5)
ining Epoch: 1/10, step 219/574 completed (loss: 2.1540496349334717, acc: 0.42424243688583374)
[2024-12-14 02:07:08,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:08,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:08,663][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 2.017131805419922, acc: 0.48148149251937866)
[2024-12-14 02:07:08,732][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 2.9064042568206787, acc: 0.30612245202064514)
[2024-12-14 02:07:08,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:08,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:09,043][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 1.9256911277770996, acc: 0.3199999928474426)
[2024-12-14 02:07:09,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:09,241][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 2.7134039402008057, acc: 0.3297872245311737)
[2024-12-14 02:07:09,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:09,394][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 2.5584781169891357, acc: 0.3076923191547394)
[2024-12-14 02:07:09,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:09,656][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 2.540076494216919, acc: 0.4285714328289032)
[2024-12-14 02:07:09,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:10,070][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 3.299818754196167, acc: 0.25)
[2024-12-14 02:07:10,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:10,179][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 2.2499420642852783, acc: 0.45108696818351746)
[2024-12-14 02:07:10,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:10,433][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 2.532597303390503, acc: 0.3913043439388275)
[2024-12-14 02:07:10,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:10,782][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 2.5702168941497803, acc: 0.33522728085517883)
[2024-12-14 02:07:10,828][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 3.0670318603515625, acc: 0.24137930572032928)
[2024-12-14 02:07:10,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:11,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:11,241][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 2.6830406188964844, acc: 0.3085106313228607)
[2024-12-14 02:07:11,262][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 2.6905455589294434, acc: 0.32608696818351746)
[2024-12-14 02:07:11,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:11,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:11,671][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 2.4959707260131836, acc: 0.33898305892944336)
[2024-12-14 02:07:11,674][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 2.763495683670044, acc: 0.30188679695129395)
[2024-12-14 02:07:11,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:11,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:12,079][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 3.233290910720825, acc: 0.19298245012760162)
[2024-12-14 02:07:12,112][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 2.4474987983703613, acc: 0.4166666567325592)
[2024-12-14 02:07:12,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:12,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:12,653][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 2.6327598094940186, acc: 0.3614457845687866)
[2024-12-14 02:07:12,545][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 2.042398452758789, acc: 0.39534884691238403)
[2024-12-14 02:07:12,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:12,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:12,846][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 2.78214430809021, acc: 0.5)
[2024-12-14 02:07:12,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:12,959][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 2.284834861755371, acc: 0.4000000059604645)
[2024-12-14 02:07:13,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:13,191][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.349097490310669, acc: 0.3913043439388275)
[2024-12-14 02:07:13,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:13,362][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 2.8117215633392334, acc: 0.2526315748691559)
[2024-12-14 02:07:13,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:13,529][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 3.0346438884735107, acc: 0.21052631735801697)
[2024-12-14 02:07:13,759][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 2.356825351715088, acc: 0.41111111640930176)
[2024-12-14 02:07:13,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:14,234][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 2.1789915561676025, acc: 0.47777777910232544)
[2024-12-14 02:07:14,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:14,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:14,726][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 2.21846866607666, acc: 0.4541284441947937)
[2024-12-14 02:07:14,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:15,218][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 2.1383090019226074, acc: 0.4076923131942749)
[2024-12-14 02:07:15,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:15,375][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 2.942781448364258, acc: 0.36486485600471497)
[2024-12-14 02:07:15,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:15,577][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 2.02705717086792, acc: 0.42105263471603394)
[2024-12-14 02:07:15,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:15,728][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 2.7529408931732178, acc: 0.35185185074806213)
[2024-12-14 02:07:15,953][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 2.069199800491333, acc: 0.4166666567325592)
[2024-12-14 02:07:16,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:16,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:16,270][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 2.955455780029297, acc: 0.3604651093482971)
[2024-12-14 02:07:16,352][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 2.4924118518829346, acc: 0.3181818127632141)
[2024-12-14 02:07:16,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:16,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:16,784][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 1.9879004955291748, acc: 0.4444444477558136)
[2024-12-14 02:07:16,921][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 2.7107009887695312, acc: 0.4117647111415863)
[2024-12-14 02:07:16,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:17,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:17,190][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.150080442428589, acc: 0.4571428596973419)
[2[2024-12-14 02:07:17,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:17,746][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 2.3612027168273926, acc: 0.3777777850627899)
                                                                                                                                                                                                                      [2024-12-14 02:07:17,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:18,148][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 1.4689732789993286, acc: 0.47826087474823)
                                                                                                                                                                                                                         [2024-12-14 02:07:18,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:18,572][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 2.8093113899230957, acc: 0.3461538553237915)
[2024-12-14 02:07:18,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:18,995][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 2.725236177444458, acc: 0.3076923191547394)
                                                                                                                                                                                                                      [2024-12-14 02:07:19,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:19,535][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.244563102722168, acc: 0.3913043439388275)
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:07:19,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:19,907][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 2.4351727962493896, acc: 0.32608696818351746)
[2024-12-14 02:07:20,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:20,258][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 2.4393982887268066, acc: 0.36734694242477417)
                                                                                                                                                                                                                    [2024-12-14 02:07:20,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:20,677][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 1.0201570987701416, acc: 0.7083333134651184)
                                                                                                                                                                                                                        [2024-12-14 02:07:20,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:21,054][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 1.9764436483383179, acc: 0.38461539149284363)
[2024-12-14 02:07:21,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:21,436][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 2.356098175048828, acc: 0.3414634168148041)
 [2024-12-14 02:07:21,583][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:07:21,822][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 2.0848984718322754, acc: 0.4444444477558136)
                                                                  [2024-12-14 02:07:21,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:22,196][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 2.4681363105773926, acc: 0.3815789520740509)
                                                                                                                                                                                                                       [2024-12-14 02:07:22,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:22,527][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 2.4731028079986572, acc: 0.39024388790130615)
                                                                                                                                                                                                                       [2024-12-14 02:07:22,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:22,862][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 2.426703691482544, acc: 0.39393940567970276)
[2024-12-14 02:07:22,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:23,221][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 1.2228912115097046, acc: 0.625)
                                                                                                                                                    [2024-12-14 02:07:23,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:23,565][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 1.0638091564178467, acc: 0.739130437374115)
                                                                                                                                                                                                                          [2024-12-14 02:07:23,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:23,923][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 1.6862366199493408, acc: 0.5)
                                                                                                                                                                                                                                        [2024-12-14 02:07:24,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:24,317][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 1.9204515218734741, acc: 0.375)
                                                                                             [2024-12-14 02:07:24,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:24,960][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 2.3259403705596924, acc: 0.42424243688583374)
                                                                                                                                                                                                                       [2024-12-14 02:07:25,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:25,904][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 1.7167034149169922, acc: 0.6037735939025879)
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:07:26,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:26,305][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.1376521587371826, acc: 0.42222222685813904)
[2024-12-14 02:07:26,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:26,664][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 2.2191147804260254, acc: 0.4464285671710968)
                                                                                                                                                                                                         [2024-12-14 02:07:26,814][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:07:27,054][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 1.3256858587265015, acc: 0.6857143044471741)
                     [2024-12-14 02:07:27,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:27,454][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 0.9567935466766357, acc: 0.7200000286102295)
                                                                                                                                        [2024-12-14 02:07:27,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:27,880][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 1.1584901809692383, acc: 0.695652186870575)
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:07:28,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:28,305][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 2.728856325149536, acc: 0.2708333432674408)
                                                                                [2024-12-14 02:07:28,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:28,772][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 2.1357481479644775, acc: 0.46315789222717285)
                                                                                                                                       [2024-12-14 02:07:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:29,379][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.049114227294922, acc: 0.485029935836792)
                                                                                                                                                                                                                         [2024-12-14 02:07:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:29,805][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 1.9641118049621582, acc: 0.4736842215061188)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:07:30,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:31,139][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 2.0792603492736816, acc: 0.4491978585720062)
eted (loss: 2.752713680267334, acc: 0.2918149530887604)
[2024-12-14 02:07:29,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:30,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:30,241][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 2.382268190383911, acc: 0.22727273404598236)
[2024-12-14 02:07:30,317][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 3.3344621658325195, acc: 0.3199999928474426)
[2024-12-14 02:07:30,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:30,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:30,657][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 1.7610424757003784, acc: 0.4545454680919647)
[2024-12-14 02:07:30,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:30,925][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 2.7368993759155273, acc: 0.26744186878204346)
[2024-12-14 02:07:31,008][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 1.8900278806686401, acc: 0.5)
[2024-12-14 02:07:31,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:31,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:31,433][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 1.9023303985595703, acc: 0.46666666865348816)
[2024-12-14 02:07:31,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:31,828][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 2.6917195320129395, acc: 0.3253968358039856)
[2024-12-14 02:07:31,839][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 2.6293439865112305, acc: 0.38333332538604736)
[2024-12-14 02:07:31,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:32,114][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.2217154502868652, acc: 0.4375)
[2024-12-14 02:07:32,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:32,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:32,499][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 1.7431753873825073, acc: 0.5666666626930237)
[2024-12-14 02:07:32,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:32,804][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 2.6281604766845703, acc: 0.3712121248245239)
[2024-12-14 02:07:32,933][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 2.1521520614624023, acc: 0.3103448152542114)
[2024-12-14 02:07:33,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:33,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:33,269][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 1.9775811433792114, acc: 0.4399999976158142)
[2024-12-14 02:07:33,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:33,607][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 2.366960287094116, acc: 0.47058823704719543)
[2024-12-14 02:07:33,650][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 2.634420871734619, acc: 0.3404255211353302)
[2024-12-14 02:07:33,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:34,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:34,092][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 2.148554563522339, acc: 0.4166666567325592)
[2024-12-14 02:07:34,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:34,534][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.0543391704559326, acc: 0.4318181872367859)
[2024-12-14 02:07:34,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:34,804][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 2.358323574066162, acc: 0.43209877610206604)
[2024-12-14 02:07:34,991][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 2.6203339099884033, acc: 0.3614457845687866)
[2024-12-14 02:07:35,119][slam_llm.models.slam_model][INFO] - modality encoder
[[2024-12-14 02:07:35,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:35,867][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.1786348819732666, acc: 0.4485294222831726)
2024-12-14 02:07:35,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:35,747][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 2.6517064571380615, acc: 0.31578946113586426)
[2024-12-14 02:07:35,805][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 2.3841357231140137, acc: 0.4354838728904724)
[2024-12-14 02:07:35,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:35,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:36,114][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 2.5732789039611816, acc: 0.2647058963775635)
[2024-12-14 02:07:36,209][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 2.2798469066619873, acc: 0.3214285671710968)
[2024-12-14 02:07:36,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:36,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:36,470][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 2.375828981399536, acc: 0.2750000059604645)
[2024-12-14 02:07:36,590][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 2.9313242435455322, acc: 0.25)
[2024-12-14 02:07:36,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:36,970][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 3.06195330619812, acc: 0.30882352590560913)
[2024-12-14 02:07:37,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:37,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:37,406][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 2.572216749191284, acc: 0.38235294818878174)
[2024-12-14 02:07:37,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:37,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:37,857][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 2.736727476119995, acc: 0.33898305892944336)
[2024-12-14 02:07:38,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:38,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:38,297][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 2.673431634902954, acc: 0.38805970549583435)
[2024-12-14 02:07:38,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:38,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:38,678][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 2.7923877239227295, acc: 0.28155338764190674)
[2024-12-14 02:07:38,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:38,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:39,030][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 2.5584402084350586, acc: 0.3492063581943512)
[2024-12-14 02:07:39,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:39,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:39,383][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 2.6157748699188232, acc: 0.3076923191547394)
[2024-12-14 02:07:39,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:39,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:39,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:39,851][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 2.7650346755981445, acc: 0.31838566064834595)
[2024-12-14 02:07:40,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:40,107][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:07:40,305][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 2.5883758068084717, acc: 0.374015748500824)
[2024-12-14 02:07:40,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:40,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:40,644][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 2.6745851039886475, acc: 0.3232758641242981)
[20ted (loss: 1.013846516609192, acc: 0.7599999904632568)
[2024-12-14 02:07:41,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:41,266][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 1.2384361028671265, acc: 0.6388888955116272)
                      [2024-12-14 02:07:41,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:41,634][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.3396334648132324, acc: 0.5555555820465088)
                                                                               [2024-12-14 02:07:41,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:41,984][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.6750861406326294, acc: 0.6153846383094788)
                                                                                                                                                              [2024-12-14 02:07:42,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:42,323][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 1.7100141048431396, acc: 0.5344827771186829)
[2024-12-14 02:07:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:42,702][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 1.1452381610870361, acc: 0.6785714030265808)
                                                               [2024-12-14 02:07:42,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:43,071][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 1.4703757762908936, acc: 0.6000000238418579)
                                                                              [2024-12-14 02:07:43,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:43,450][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 1.7901784181594849, acc: 0.4848484992980957)
[2024-12-14 02:07:43,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:43,792][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 1.984711766242981, acc: 0.3181818127632141)
[2024-12-14 02:07:43,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:44,188][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.408026695251465, acc: 0.47058823704719543)
[2024-12-14 02:07:44,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:44,590][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 2.2453367710113525, acc: 0.42307692766189575)
[2024-12-14 02:07:44,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:44,968][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 1.8321855068206787, acc: 0.6111111044883728)
[2024-12-14 02:07:45,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:45,362][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.0625109672546387, acc: 0.5)
                                                                                                                                          [2024-12-14 02:07:45,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:45,678][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 3.6758320331573486, acc: 0.3499999940395355)
[2024-12-14 02:07:45,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:45,991][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 1.2597495317459106, acc: 0.5714285969734192)
[2024-12-14 02:07:46,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:46,346][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 2.3064815998077393, acc: 0.4000000059604645)
                                                                                                      [2024-12-14 02:07:46,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:46,720][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 1.863928198814392, acc: 0.46875)
                                                                                           [2024-12-14 02:07:46,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:47,082][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 1.9472908973693848, acc: 0.4444444477558136)
[2024-12-14 02:07:47,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:47,401][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 2.040015697479248, acc: 0.37037035822868347)
                                                                               [2024-12-14 02:07:47,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:47,809][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 1.8161770105361938, acc: 0.42424243688583374)
[2024-12-14 02:07:47,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:48,179][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.5486434698104858, acc: 0.5652173757553101)
[2024-12-14 02:07:48,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:48,513][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.7593191862106323, acc: 0.5405405163764954)
[2024-12-14 02:07:48,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:48,821][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 1.4327398538589478, acc: 0.7037037014961243)
                     [2024-12-14 02:07:49,517][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:07:49,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:50,024][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:07:50,354][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:07:50,683][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:07:50,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:51,260][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:07:51,564][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:07:51,907][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:07:52,365][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:07:52,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:52,717][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 2.230020046234131, acc: 0.4403669834136963)
[2024-12-14 02:07:52,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:52,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:53,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:53,274][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 2.1472699642181396, acc: 0.4153846204280853)
[2024-12-14 02:07:53,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:53,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:53,700][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 2.012655735015869, acc: 0.4736842215061188)
[2024-12-14 02:07:53,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:54,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:54,122][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 2.0682876110076904, acc: 0.4166666567325592)
[2024-12-14 02:07:54,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:54,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:54,531][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 2.4911670684814453, acc: 0.3181818127632141)
[2024-12-14 02:07:54,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:54,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:54,945][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 2.0018343925476074, acc: 0.4444444477558136)
[2024-12-14 02:07:55,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:55,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:55,313][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.1478772163391113, acc: 0.4571428596973419)
[2024-12-14 02:07:55,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:55,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:55,754][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 1.942574381828308, acc: 0.4318181872367859)
[2024-12-14 02:07:55,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:55,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:56,140][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 2.2136428356170654, acc: 0.47727271914482117)
[2024-12-14 02:07:56,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:56,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:56,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:56,792][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 2.3414361476898193, acc: 0.35483869910240173)
[2024-12-14 02:07:56,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:56,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:57,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:57,363][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 2.2534191608428955, acc: 0.34090909361839294)
[2024-12-14 02:07:57,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:57,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:57,754][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 1.9515516757965088, acc: 0.4285714328289032)
[2024-12-14 02:07:57,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:57,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:58,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:58,169][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 2.400423526763916, acc: 0.3076923191547394)
[2024-12-14 02:07:58,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:58,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:58,574][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 2.953238010406494, acc: 0.19354838132858276)
[2024-12-14 02:07:58,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:58,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:58,949][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.04727840423584, acc: 0.5)
[2024-12-14 02:07:59,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:59,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:59,401][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 2.447554588317871, acc: 0.4054054021835327)
[2024-12-14 02:07:59,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:59,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:07:59,767][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 2.4640650749206543, acc: 0.3243243098258972)
[2024-12-14 02:07:59,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:00,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:00,128][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 2.601320505142212, acc: 0.29729729890823364)
[2024-12-14 02:08:00,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:00,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:00,586][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 2.6645772457122803, acc: 0.36764705181121826)
[2024-12-14 02:08:00,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:00,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:00,979][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 1.7022483348846436, acc: 0.5121951103210449)
[2024-12-14 02:08:01,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:01,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:01,338][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 1.7924931049346924, acc: 0.5199999809265137)
[2024-12-14 02:08:01,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:01,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:01,703][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 1.4775713682174683, acc: 0.4399999976158142)
[2024-12-14 02:08:01,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:01,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:02,073][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 2.4466817378997803, acc: 0.32258063554763794)
[2024-12-14 02:08:02,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:02,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:02,470][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 2.4938058853149414, acc: 0.3333333432674408)
[2024-12-14 02:08:02,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:02,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:02,916][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 2.5357296466827393, acc: 0.3285714387893677)
[2024-12-14 02:08:03,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:03,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:03,318][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 2.3728084564208984, acc: 0.3947368562221527)
[2024-12-14 02:08:03,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:03,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:03,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:04,065][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 2.2991063594818115, acc: 0.4150943458080292)
[2024-12-14 02:08:03,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:04,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:04,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:04,554][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 2.3868136405944824, acc: 0.3916666805744171)
[2024-12-14 02:08:04,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:04,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:04,897][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 2.430752754211426, acc: 0.4444444477558136)
[2024-12-14 02:08:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:05,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:05,217][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 2.8444154262542725, acc: 0.25806450843811035)
[2024-12-14 02:08:05,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:05,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:05,650][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 2.8599929809570312, acc: 0.30666667222976685)
[2024-12-14 02:08:05,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:05,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:06,003][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 2.6156504154205322, acc: 0.3958333432674408)
[2024-12-14 02:08:06,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:06,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:06,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:06,953][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 2.736694097518921, acc: 0.2800000011920929)
[2024-12-14 02:08:06,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:07,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:07,381][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 2.5365829467773438, acc: 0.3932584226131439)
[2024-12-14 02:08:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:07,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:07,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:07,796][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 2.556910276412964, acc: 0.3513513505458832)
[2024-12-14 02:08:07,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:08,283][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 1.9745054244995117, acc: 0.4655172526836395)
[2024-12-14 02:08:08,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:08,837][slam_llm.models.slam_model][INFO] - modality encoder
10.7120, device='cuda:0') eval_epoch_loss=tensor(2.3714, device='cuda:0') eval_epoch_acc=tensor(0.3823, device='cuda:0')
[2024-12-14 02:08:08,420][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:08:08,420][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:08:08,621][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 2.314014196395874, acc: 0.3181818127632141)
[2024-12-14 02:08:08,695][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_1_step_286_loss_2.371363878250122/model.pt
[2024-12-14 02:08:08,699][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:08:08,700][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.371363878250122
[2024-12-14 02:08:08,700][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.38231727480888367
[2024-12-14 02:08:08,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:08,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:09,021][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 1.749495267868042, acc: 0.40909090638160706)
[2024-12-14 02:08:09,064][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 2.4713821411132812, acc: 0.3125)
[2024-12-14 02:08:09,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:09,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:09,379][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 2.697298765182495, acc: 0.23999999463558197)
[2024-12-14 02:08:09,403][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 1.8486303091049194, acc: 0.5)
[2024-12-14 02:08:09,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:09,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:09,725][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 2.2844836711883545, acc: 0.38461539149284363)
[2024-12-14 02:08:09,740][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 1.9054982662200928, acc: 0.46666666865348816)
[2024-12-14 02:08:09,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:09,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:10,065][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 2.6249611377716064, acc: 0.2857142984867096)
[2024-12-14 02:08:10,159][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 2.5928971767425537, acc: 0.36666667461395264)
[2024-12-14 02:08:10,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:10,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:10,477][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 2.7123897075653076, acc: 0.2886597812175751)
[2024-12-14 02:08:10,543][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.1466739177703857, acc: 0.4375)
[2024-12-14 02:08:10,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:10,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:10,950][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 1.5658015012741089, acc: 0.6363636255264282)
[2024-12-14 02:08:10,986][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 1.7281886339187622, acc: 0.6000000238418579)
[2024-12-14 02:08:11,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:11,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:11,339][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.358912229537964, acc: 0.380952388048172)
[2024-12-14 02:08:11,411][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 2.1253011226654053, acc: 0.3103448152542114)
[2024-12-14 02:08:11,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:11,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:11,701][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 1.99054753780365, acc: 0.48275861144065857)
[2024-12-14 02:08:11,814][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 1.9438214302062988, acc: 0.4000000059604645)
[2024-12-14 02:08:11,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:11,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:12,177][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 2.614839553833008, acc: 0.3404255211353302)
[2024-12-14 02:08:12,209][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 1.8147891759872437, acc: 0.5454545617103577)
[2024-12-14 02:08:12,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:12,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:12,551][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 2.156965732574463, acc: 0.4375)
[2024-12-14 02:08:12,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:13,074][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:08:13,516][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:08:13,941][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:08:14,288][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:08:14,586][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                        [2024-12-14 02:08:14,943][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:08:15,263][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:08:15,601][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:08:16,022][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                          [2024-12-14 02:08:16,413][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:08:16,690][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:08:17,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:17,106][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 1.3382781744003296, acc: 0.7368420958518982)
[2024-12-14 02:08:17,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:17,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:17,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:17,452][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 2.7043826580047607, acc: 0.3333333432674408)
[2024-12-14 02:08:17,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:17,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:17,888][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.2507874965667725, acc: 0.4166666567325592)
[2024-12-14 02:08:18,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:18,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:18,290][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 2.251620292663574, acc: 0.3614457845687866)
[2024-12-14 02:08:18,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:18,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:18,680][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 2.7715251445770264, acc: 0.29487180709838867)
[2024-12-14 02:08:18,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:18,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:19,125][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 2.798419952392578, acc: 0.30612245202064514)
[2024-12-14 02:08:19,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:19,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:19,488][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 1.049742579460144, acc: 0.7916666865348816)
[2024-12-14 02:08:19,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:19,648][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:08:19,863][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 1.9417823553085327, acc: 0.5)
[2024-12-14 02:08:20,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:20,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:20,236][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 2.0761382579803467, acc: 0.3870967626571655)
[2024-12-14 02:08:20,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:20,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:20,572][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 2.2679615020751953, acc: 0.35483869910240173)
[2024-12-14 02:08:20,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:20,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:20,984][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 2.03439998626709, acc: 0.447761207818985)
[2024-12-14 02:08:21,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:21,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:21,369][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 1.8326499462127686, acc: 0.4711538553237915)
[2024-12-14 02:08:21,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:21,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:21,759][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 2.7278616428375244, acc: 0.24444444477558136)
[2024-12-14 02:08:21,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:21,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:22,176][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 2.286905288696289, acc: 0.32258063554763794)
[2024-12-14 02:08:22,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:22,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:22,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:22,587][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 1.6366314888000488, acc: 0.6200000047683716)
[2024-12-14 02:08:22,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:22,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:22,995][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 3.0248963832855225, acc: 0.2222222238779068)
[2024-12-14 02:08:23,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:23,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:23,345][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 3.942913293838501, acc: 0.08571428805589676)
[2024-12-14 02:08:23,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:23,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:23,797][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 2.9010677337646484, acc: 0.20512820780277252)
[2024-12-14 02:08:23,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:24,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:24,210][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 2.746685266494751, acc: 0.3658536672592163)
[2024-12-14 02:08:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:24,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:24,634][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 2.359546184539795, acc: 0.3947368562221527)
[2024-12-14 02:08:24,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:24,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:25,035][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 1.7781084775924683, acc: 0.42105263471603394)
[2024-12-14 02:08:25,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:25,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:25,401][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 1.7890393733978271, acc: 0.4642857015132904)
[2024-12-14 02:08:25,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:25,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:25,742][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 2.3746347427368164, acc: 0.25925925374031067)
[2024-12-14 02:08:25,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:26,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:26,079][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 1.6203022003173828, acc: 0.46875)
[2024-12-14 02:08:26,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:26,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:26,550][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 2.3453798294067383, acc: 0.3870967626571655)
[2024-12-14 02:08:26,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:26,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:27,231][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 1.6786556243896484, acc: 0.5227272510528564)
                                                                                [2024-12-14 02:08:27,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:27,592][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.2535886764526367, acc: 0.47826087474823)
[2024-12-14 02:08:27,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:27,939][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 2.0024478435516357, acc: 0.5384615659713745)
                                                                                                                                                    [2024-12-14 02:08:28,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:28,262][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.777422308921814, acc: 0.5357142686843872)
 [2024-12-14 02:08:28,366][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:08:28,643][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.684901475906372, acc: 0.3283582031726837)
  [2024-12-14 02:08:28,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:29,003][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.187997579574585, acc: 0.4722222089767456)
                                                                                [2024-12-14 02:08:29,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:29,421][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 2.515089511871338, acc: 0.32608696818351746)
                                                                                                                                                              [2024-12-14 02:08:29,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:29,853][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.5719480514526367, acc: 0.3333333432674408)
                                                                               [2024-12-14 02:08:30,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:30,227][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.6262407302856445, acc: 0.3947368562221527)
                                                                             [2024-12-14 02:08:30,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:30,573][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 1.9466676712036133, acc: 0.5102040767669678)
 [2024-12-14 02:08:30,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:30,902][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 1.739736557006836, acc: 0.5757575631141663)
                                                                                [2024-12-14 02:08:31,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:31,317][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.346226692199707, acc: 0.30927833914756775)
                                                                               [2024-12-14 02:08:31,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:31,730][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.21413516998291, acc: 0.3857142925262451)
                                                                                  [2024-12-14 02:08:31,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:32,144][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.348209857940674, acc: 0.36627906560897827)
                                                                              [2024-12-14 02:08:32,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:32,447][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.504171371459961, acc: 0.3035714328289032)
/10, step 346/574 completed (loss: 2.7596523761749268, acc: 0.34328359365463257)
[2024-12-14 02:08:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:32,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:32,806][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 1.945229172706604, acc: 0.6000000238418579)
[2024-12-14 02:08:32,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:32,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:33,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:33,202][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 1.951533555984497, acc: 0.5199999809265137)
[2024-12-14 02:08:33,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:33,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:33,619][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 1.7309529781341553, acc: 0.5833333134651184)
[2024-12-14 02:08:33,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:33,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:33,963][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 2.4071943759918213, acc: 0.39534884691238403)
[2024-12-14 02:08:34,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:34,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:34,336][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 2.2762186527252197, acc: 0.38461539149284363)
[2024-12-14 02:08:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:34,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:34,751][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 2.3530495166778564, acc: 0.35555556416511536)
[2024-12-14 02:08:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:35,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:35,160][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 1.4701553583145142, acc: 0.47826087474823)
[2024-12-14 02:08:35,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:35,563][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 2.810770273208618, acc: 0.3461538553237915)
[2024-12-14 02:08:35,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:35,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:35,951][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 2.728299140930176, acc: 0.3076923191547394)
[2024-12-14 02:08:35,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:36,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:36,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:36,498][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.2428488731384277, acc: 0.3913043439388275)
[2024-12-14 02:08:36,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:36,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:36,868][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 2.4297873973846436, acc: 0.31521740555763245)
[2024-12-14 02:08:37,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:37,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:37,236][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 2.426558017730713, acc: 0.3469387888908386)
[2024-12-14 02:08:37,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:37,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:37,606][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 1.0182946920394897, acc: 0.6666666865348816)
[2024-12-14 02:08:37,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:37,968][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 2.340517282485962, acc: 0.375)
[2024-12-14 02:08:38,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:38,331][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.398911952972412, acc: 0.3251533806324005)
[2024-12-14 02:08:38,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:38,732][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 2.577357292175293, acc: 0.3309352397918701)
[2024-12-14 02:08:38,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:39,207][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 2.424856424331665, acc: 0.3819095492362976)
                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:08:39,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:39,583][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 1.7263433933258057, acc: 0.5555555820465088)
[2024-12-14 02:08:39,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:39,949][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 1.7270790338516235, acc: 0.5151515007019043)
[2024-12-14 02:08:40,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:40,273][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 1.9082646369934082, acc: 0.37037035822868347)
[2024-12-14 02:08:40,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:40,648][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 1.9824230670928955, acc: 0.4000000059604645)
                                                                                       [2024-12-14 02:08:40,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:41,042][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 0.915440559387207, acc: 0.699999988079071)
                                                                               [2024-12-14 02:08:41,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:41,463][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 1.9060368537902832, acc: 0.517241358757019)
                                                                 [2024-12-14 02:08:41,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:41,832][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 1.5682995319366455, acc: 0.6774193644523621)
                                                                    [2024-12-14 02:08:41,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:42,208][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.143760323524475, acc: 0.7894737124443054)
 [2024-12-14 02:08:42,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:42,592][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.3674306869506836, acc: 0.5185185074806213)
[2024-12-14 02:08:42,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:42,986][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.4123692512512207, acc: 0.3333333432674408)
[2024-12-14 02:08:43,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:43,330][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 1.7561718225479126, acc: 0.5)
[2024-12-14 02:08:43,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:43,738][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.1088743209838867, acc: 0.4153846204280853)
[2024-12-14 02:08:43,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:44,140][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 1.6469753980636597, acc: 0.5666666626930237)
                                                         [2024-12-14 02:08:44,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:44,460][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 1.7795381546020508, acc: 0.517241358757019)
                                                                                [2024-12-14 02:08:44,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:44,752][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.2438602447509766, acc: 0.3921568691730499)
                                                                              [2024-12-14 02:08:44,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:45,093][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 1.9028702974319458, acc: 0.48275861144065857)
                                                                            [2024-12-14 02:08:45,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:45,472][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 0.9516752362251282, acc: 0.7368420958518982)
[2024-12-14 02:08:45,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:45,885][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.144071340560913, acc: 0.21052631735801697)
                                                                                [2024-12-14 02:08:46,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:46,288][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.2279887199401855, acc: 0.4375)
[2024-12-14 02:08:46,408][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                           [2024-12-14 02:08:46,688][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.1612625122070312, acc: 0.42696627974510193)
[2024-12-14 02:08:46,796][slam_llm.models.slam_model][INFO] - modality encoder
                                                                             [2024-12-14 02:08:47,071][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.503478527069092, acc: 0.3595505654811859)
[2024-12-14 02:08:47,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:47,467][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.5098989009857178, acc: 0.3404255211353302)
[2024-12-14 02:08:47,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:47,851][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.575824499130249, acc: 0.33695653080940247)
[2024-12-14 02:08:47,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:48,220][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 1.0377994775772095, acc: 0.7200000286102295)
                                                                                               [2024-12-14 02:08:48,318][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:08:48,530][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 1.3176493644714355, acc: 0.7307692170143127)
[2024-12-14 02:08:48,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:48,844][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 1.2133870124816895, acc: 0.7407407164573669)
                                                                     [2024-12-14 02:08:48,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:49,223][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 2.049283742904663, acc: 0.48148149251937866)
                                                                                                                                                                                                                         [2024-12-14 02:08:49,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:49,628][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 1.9284480810165405, acc: 0.5283018946647644)
                                                                               [2024-12-14 02:08:49,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:49,990][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 1.585193157196045, acc: 0.5517241358757019)
                                                                                                                               [2024-12-14 02:08:50,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:50,601][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.2499992847442627, acc: 0.4054054021835327)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:08:50,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:51,089][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 2.220031499862671, acc: 0.39436620473861694)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:08:51,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:51,455][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 0.5582683682441711, acc: 0.8500000238418579)
                                                                                                                          [2024-12-14 02:08:51,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:51,811][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 0.983172595500946, acc: 0.800000011920929)
                                                                                                                                                                                                                         [2024-12-14 02:08:51,940][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:08:52,215][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 1.501627802848816, acc: 0.5384615659713745)
                      [2024-12-14 02:08:53,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:54,958][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 2.3805346488952637, acc: 0.3928571343421936)
leted (loss: 2.6197187900543213, acc: 0.3689320385456085)
[2024-12-14 02:08:52,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:52,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:52,819][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.185666799545288, acc: 0.4485294222831726)
[2024-12-14 02:08:52,874][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.119144916534424, acc: 0.4639175236225128)
[2024-12-14 02:08:52,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:53,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:53,232][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 2.522106885910034, acc: 0.3799999952316284)
[2024-12-14 02:08:53,324][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 2.4829397201538086, acc: 0.37931033968925476)
[2024-12-14 02:08:53,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:53,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:53,663][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.434887170791626, acc: 0.4027777910232544)
[2024-12-14 02:08:53,761][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 2.112352132797241, acc: 0.48148149251937866)
[2024-12-14 02:08:53,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:53,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:54,032][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 2.3579256534576416, acc: 0.4883720874786377)
[2024-12-14 02:08:54,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:54,158][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 2.2354769706726074, acc: 0.44736841320991516)
[2024-12-14 02:08:54,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:54,352][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 1.5768862962722778, acc: 0.5416666865348816)
[2024-12-14 02:08:54,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:54,617][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 2.4880783557891846, acc: 0.3928571343421936)
[2024-12-14 02:08:54,745][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 1.9710469245910645, acc: 0.4651162922382355)
[2024-12-14 02:08:54,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:54,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:55,030][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 2.2718143463134766, acc: 0.4375)
[2024-12-14 02:08:55,101][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 2.266347885131836, acc: 0.4399999976158142)
[2024-12-14 02:08:55,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:55,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:55,391][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 2.520918607711792, acc: 0.3396226465702057)
[2024-12-14 02:08:55,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:55,674][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 2.1896297931671143, acc: 0.47058823704719543)
[2024-12-14 02:08:55,747][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 1.6707075834274292, acc: 0.6226415038108826)
[2024-12-14 02:08:55,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:55,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:56,086][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 2.016258478164673, acc: 0.529411792755127)
[2024-12-14 02:08:56,093][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.0894412994384766, acc: 0.46666666865348816)
[2024-12-14 02:08:56,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:56,610][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 1.8638815879821777, acc: 0.5)
ining Epoch: 1/10, step 304/574 completed (loss: 2.5835886001586914, acc: 0.3125)
[2024-12-14 02:08:56,503][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 1.66621994972229, acc: 0.6060606241226196)
[2024-12-14 02:08:56,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:56,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:56,845][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 1.9993010759353638, acc: 0.4848484992980957)
[2024-12-14 02:08:56,875][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 1.9394325017929077, acc: 0.49180328845977783)
[2024-12-14 02:08:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:57,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:57,266][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 1.6921052932739258, acc: 0.4516128897666931)
[2024-12-14 02:08:57,280][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 1.50733482837677, acc: 0.5333333611488342)
[2024-12-14 02:08:57,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:57,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:57,652][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 1.417605996131897, acc: 0.7368420958518982)
[2024-12-14 02:08:57,670][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 2.3114664554595947, acc: 0.40740740299224854)
[2024-12-14 02:08:57,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:57,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:57,993][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 1.0213123559951782, acc: 0.7599999904632568)
[2024-12-14 02:08:58,048][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 2.68076229095459, acc: 0.3478260934352875)
[2024-12-14 02:08:58,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:58,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:58,317][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 1.238339900970459, acc: 0.6388888955116272)
[2024-12-14 02:08:58,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:58,510][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.246572256088257, acc: 0.4166666567325592)
[2024-12-14 02:08:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:58,697][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.3726977109909058, acc: 0.5555555820465088)
[2024-12-14 02:08:58,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:58,887][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 2.2551121711730957, acc: 0.3614457845687866)
[2024-12-14 02:08:59,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:59,067][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.6993002891540527, acc: 0.6153846383094788)
[2024-12-14 02:08:59,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:59,239][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 2.739680051803589, acc: 0.3205128312110901)
[2024-12-14 02:08:59,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:59,441][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 1.706044316291809, acc: 0.5344827771186829)
[2024-12-14 02:08:59,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:59,611][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 2.796994924545288, acc: 0.29591837525367737)
[2024-12-14 02:08:59,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:59,795][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 1.21462082862854, acc: 0.6785714030265808)
[2024-12-14 02:08:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:08:59,954][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 1.0796064138412476, acc: 0.8333333134651184)
[2024-12-14 02:09:00,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:00,507][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.3321595191955566, acc: 0.37226277589797974)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:09:00,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:01,121][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.137486219406128, acc: 0.4399999976158142)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:09:01,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:01,469][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.3718698024749756, acc: 0.35185185074806213)
                                                                                                                                                                                                                       [2024-12-14 02:09:01,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:01,818][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.0784926414489746, acc: 0.42307692766189575)
                                                                                                                                                                                                         [2024-12-14 02:09:01,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:02,141][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.599778413772583, acc: 0.2380952388048172)
 [2024-12-14 02:09:02,277][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:09:02,553][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 3.031040906906128, acc: 0.19672131538391113)
                                                               [2024-12-14 02:09:02,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:02,895][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.040196657180786, acc: 0.47457626461982727)
[2024-12-14 02:09:02,993][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:09:03,217][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 2.537102699279785, acc: 0.3255814015865326)
                                                                                 [2024-12-14 02:09:03,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:03,618][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.381859302520752, acc: 0.4545454680919647)
                                                                                                                                                                                                                         [2024-12-14 02:09:03,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:04,000][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.533938407897949, acc: 0.3207547068595886)
                                                                                                                                                                                                                         [2024-12-14 02:09:04,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:04,406][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.257028341293335, acc: 0.5227272510528564)
                                                                                                                                                                                                         [2024-12-14 02:09:04,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:04,772][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 1.8054770231246948, acc: 0.5199999809265137)
                                                                                                                                                                                                         [2024-12-14 02:09:04,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:05,167][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 1.984461784362793, acc: 0.550000011920929)
                                                                                  [2024-12-14 02:09:05,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:05,572][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 1.5498076677322388, acc: 0.5454545617103577)
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:09:05,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:05,994][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 2.189748764038086, acc: 0.4307692348957062)
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:09:06,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:06,379][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 2.0033583641052246, acc: 0.453125)
                                                                             [2024-12-14 02:09:06,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:06,792][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 1.4240485429763794, acc: 0.59375)
[2024-12-14 02:09:06,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:07,162][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 2.18873929977417, acc: 0.3636363744735718)
            [2024-12-14 02:09:07,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:07,551][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 0.9816892147064209, acc: 0.6875)
                                                                                           [2024-12-14 02:09:07,630][slam_llm.models.slam_model][INFO] - modality encoder
                                               [2024-12-14 02:09:07,847][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 1.3317773342132568, acc: 0.5806451439857483)
                     [2024-12-14 02:09:07,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:08,210][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 0.87994384765625, acc: 0.695652186870575)
                                                                                  [2024-12-14 02:09:08,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:08,582][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 2.3622958660125732, acc: 0.4000000059604645)
[2024-12-14 02:09:08,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:08,979][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 1.9861174821853638, acc: 0.3658536672592163)
                                                                                                                                                              [2024-12-14 02:09:09,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:09,377][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 1.3288962841033936, acc: 0.6000000238418579)
[2024-12-14 02:09:09,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:09,775][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 1.8188875913619995, acc: 0.5526315569877625)
                                                                              [2024-12-14 02:09:09,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:10,132][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 1.9339550733566284, acc: 0.5483871102333069)
                                                                               [2024-12-14 02:09:10,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:10,478][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 1.0182241201400757, acc: 0.6800000071525574)
                                                                                                                                                            [2024-12-14 02:09:10,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:10,848][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.6625205278396606, acc: 0.5151515007019043)
                                                                              [2024-12-14 02:09:10,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:11,185][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 1.4349992275238037, acc: 0.6000000238418579)
[2024-12-14 02:09:11,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:11,515][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.7239772081375122, acc: 0.5)
[2024-12-14 02:09:11,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:11,944][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.598140001296997, acc: 0.30656933784484863)
                                    [2024-12-14 02:09:12,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:12,363][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.2142090797424316, acc: 0.4689655303955078)
                                                                               [2024-12-14 02:09:12,492][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:12,725][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.940237283706665, acc: 0.22857142984867096)
[2024-12-14 02:09:12,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:13,107][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.9104678630828857, acc: 0.1986754983663559)
[2024-12-14 02:09:13,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:13,512][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 2.3575918674468994, acc: 0.39316239953041077)
[2024-12-14 02:09:13,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:13,835][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 0.82485032081604, acc: 0.800000011920929)
                                                                                                   [2024-12-14 02:09:13,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:14,252][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.6974080801010132, acc: 0.5769230723381042)
                                                                              [2024-12-14 02:09:14,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:14,652][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.3391823768615723, acc: 0.5769230723381042)
                                                                                [2024-12-14 02:09:14,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:15,033][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 1.99552583694458, acc: 0.4615384638309479)
                                                                                [2024-12-14 02:09:15,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:15,402][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 1.9557029008865356, acc: 0.4555555582046509)
[2024-12-14 02:09:15,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:15,737][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.214773416519165, acc: 0.37662336230278015)
                     [2024-12-14 02:09:15,837][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:09:16,052][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.124680995941162, acc: 0.375)
                                   [2024-12-14 02:09:16,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:16,388][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.2855677604675293, acc: 0.4137931168079376)
[2024-12-14 02:09:16,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:16,718][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.1395013332366943, acc: 0.380952388048172)
                                                                                [2024-12-14 02:09:16,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:16,997][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.8978670835494995, acc: 0.3684210479259491)
[2024-12-14 02:09:17,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:17,412][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 2.0047287940979004, acc: 0.37037035822868347)
[2024-12-14 02:09:17,601][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:09:17,863][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.3005218505859375, acc: 0.3743315637111664)
[2024-12-14 02:09:18,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:18,276][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 1.8946962356567383, acc: 0.5)
[2024-12-14 02:09:18,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:18,722][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 2.3458170890808105, acc: 0.4017094075679779)
                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:09:19,487][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:09:19,775][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:20,108][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:09:20,453][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:09:20,755][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:09:21,121][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                           [2024-12-14 02:09:21,461][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:09:21,859][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:22,193][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                            [2024-12-14 02:09:22,629][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:09:22,933][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:09:23,354][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:09:23,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:24,102][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:09:24,515][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:09:24,844][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:25,222][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:09:25,584][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:25,961][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:26,287][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:09:26,653][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:09:27,041][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:09:27,406][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:27,742][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:09:28,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:28,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:28,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:29,241][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:09:29,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:29,954][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:09:30,324][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:09:30,736][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:09:31,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:31,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:31,323][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 2.2997140884399414, acc: 0.4166666567325592)
[2024-12-14 02:09:31,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:31,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:31,703][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 1.9774636030197144, acc: 0.3947368562221527)
[2024-12-14 02:09:31,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:32,065][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 1.7488131523132324, acc: 0.5454545617103577)
[2024-12-14 02:09:32,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:32,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:32,423][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 2.0309391021728516, acc: 0.5)
[2024-12-14 02:09:32,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:32,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:32,811][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 2.1001288890838623, acc: 0.380952388048172)
[2024-12-14 02:09:32,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:32,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:33,151][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 2.615974187850952, acc: 0.3333333432674408)
[2024-12-14 02:09:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:33,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:33,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:33,541][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 2.6411635875701904, acc: 0.3689320385456085)
[2024-12-14 02:09:33,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:33,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:34,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:34,144][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.1800522804260254, acc: 0.44117647409439087)
[2024-12-14 02:09:34,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:34,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:34,562][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 2.5331883430480957, acc: 0.3733333349227905)
[2024-12-14 02:09:34,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:34,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:35,024][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.4396514892578125, acc: 0.3958333432674408)
[2024-12-14 02:09:35,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:35,416][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 2.3643879890441895, acc: 0.4883720874786377)
[2024-12-14 02:09:35,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:35,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:35,838][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 1.5768752098083496, acc: 0.5833333134651184)
[2024-12-14 02:09:35,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:35,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:36,245][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 1.9699143171310425, acc: 0.4883720874786377)
[2024-12-14 02:09:36,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:36,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:36,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:36,682][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 2.2556235790252686, acc: 0.4399999976158142)
[2024-12-14 02:09:36,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:37,462][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:09:37,811][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:09:38,225][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:09:38,521][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:09:38,823][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:09:39,224][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:09:39,526][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:09:39,838][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:09:40,196][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.2523655891418457, acc: 0.6388888955116272)
[2024-12-14 02:09:40,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:40,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:40,309][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 0.7484149932861328, acc: 0.800000011920929)
[2024-12-14 02:09:40,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:40,451][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.37680983543396, acc: 0.5185185074806213)
[2024-12-14 02:09:40,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:40,671][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 1.6813817024230957, acc: 0.5454545617103577)
[2024-12-14 02:09:40,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:40,855][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.6731597185134888, acc: 0.6153846383094788)
[2024-12-14 02:09:41,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:41,070][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 1.5999282598495483, acc: 0.5555555820465088)
[2024-12-14 02:09:41,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:41,322][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 1.7085158824920654, acc: 0.5344827771186829)
[2024-12-14 02:09:41,432][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 1.8087238073349, acc: 0.5681818127632141)
[2024-12-14 02:09:41,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:41,751][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 1.2031012773513794, acc: 0.7142857313156128)
[2024-12-14 02:09:41,757][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 0.5963326692581177, acc: 0.8095238208770752)
[2024-12-14 02:09:41,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:41,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:42,128][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 1.4829928874969482, acc: 0.5666666626930237)
[2024-12-14 02:09:42,184][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 2.474353790283203, acc: 0.41025641560554504)
[2024-12-14 02:09:42,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:42,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:42,485][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 1.8693803548812866, acc: 0.4545454680919647)
[2024-12-14 02:09:42,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:42,707][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.1720197200775146, acc: 0.40909090638160706)
[2024-12-14 02:09:42,866][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 1.99811589717865, acc: 0.3181818127632141)
[2024-12-14 02:09:43,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:43,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:43,275][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.4319121837615967, acc: 0.45098039507865906)
[2024-12-14 02:09:43,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:43,532][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 2.8178672790527344, acc: 0.29600000381469727)
[2024-12-14 02:09:43,655][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 2.177173376083374, acc: 0.42307692766189575)
[2024-12-14 02:09:43,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:43,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:43,978][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 2.580240249633789, acc: 0.32258063554763794)
[2024-12-14 02:09:44,055][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 1.8075101375579834, acc: 0.6111111044883728)
[2024-12-14 02:09:44,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:44,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:44,525][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.0795695781707764, acc: 0.5)
[2024-12-14 02:09:44,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:44,668][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 2.5870845317840576, acc: 0.3283582031726837)
[2024-12-14 02:09:44,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:44,892][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 3.668090343475342, acc: 0.3499999940395355)
[2024-12-14 02:09:45,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:45,056][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.4754061698913574, acc: 0.37735849618911743)
[2024-12-14 02:09:45,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:45,290][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 1.3005502223968506, acc: 0.5714285969734192)
[2024-12-14 02:09:45,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:45,509][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 1.7000731229782104, acc: 0.5909090638160706)
[2024-12-14 02:09:45,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:45,688][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 2.3900437355041504, acc: 0.4000000059604645)
[2024-12-14 02:09:45,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:45,901][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.199526309967041, acc: 0.43478259444236755)
[2024-12-14 02:09:46,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:46,051][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 1.981610894203186, acc: 0.46875)
[2024-12-14 02:09:46,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:46,295][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 1.966517686843872, acc: 0.5384615659713745)
[2024-12-14 02:09:46,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:46,426][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 1.9839102029800415, acc: 0.4166666567325592)
[2024-12-14 02:09:46,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:46,643][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.8310641050338745, acc: 0.5)
[2024-12-14 02:09:46,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:46,769][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 2.0017566680908203, acc: 0.4444444477558136)
[2024-12-14 02:09:46,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:46,979][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.6607589721679688, acc: 0.35820895433425903)
[2024-12-14 02:09:47,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:47,171][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 1.7943131923675537, acc: 0.5151515007019043)
[2024-12-14 02:09:47,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:47,420][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.217344045639038, acc: 0.4722222089767456)
[2024-12-14 02:09:47,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:47,590][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.5739734172821045, acc: 0.5652173757553101)
[2024-12-14 02:09:47,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:47,796][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 2.474072217941284, acc: 0.33695653080940247)
[2024-12-14 02:09:48,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:47,979][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.8489820957183838, acc: 0.5405405163764954)
[2024-12-14 02:09:48,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:48,222][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.5270161628723145, acc: 0.3589743673801422)
[2024-12-14 02:09:48,357][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 1.4763035774230957, acc: 0.6666666865348816)
[2024-12-14 02:09:48,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:48,647][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.615640163421631, acc: 0.3947368562221527)
[2024-12-14 02:09:48,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:48,996][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 1.954665184020996, acc: 0.5306122303009033)
[2024-12-14 02:09:49,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:49,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:49,317][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 1.713199496269226, acc: 0.6060606241226196)
[2024-12-14 02:09:49,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:49,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:49,650][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.3580055236816406, acc: 0.3195876181125641)
[2024-12-14 02:09:49,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:49,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:50,051][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.2083237171173096, acc: 0.4000000059604645)
[2024-12-14 02:09:50,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:50,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:50,507][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.30843186378479, acc: 0.3720930218696594)
[2024-12-14 02:09:50,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:50,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:50,918][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.5183238983154297, acc: 0.3035714328289032)
[2024-12-14 02:09:50,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:51,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:51,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:51,284][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 2.297898292541504, acc: 0.3333333432674408)
[2024-12-14 02:09:51,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:51,598][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 1.874092698097229, acc: 0.4444444477558136)
[2024-12-14 02:09:51,651][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                         [2024-12-14 02:09:51,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:51,910][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 1.8101654052734375, acc: 0.53125)
[2024-12-14 02:09:52,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:52,026][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                 [2024-12-14 02:09:52,247][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 1.9295551776885986, acc: 0.5)
[2024-12-14 02:09:52,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:52,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:52,624][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 2.2031004428863525, acc: 0.43478259444236755)
[2024-12-14 02:09:52,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:53,124][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 2.273859739303589, acc: 0.3199999928474426)
                                                                    [2024-12-14 02:09:53,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:53,488][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 2.89760684967041, acc: 0.3513513505458832)
                                                                                   [2024-12-14 02:09:53,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:53,881][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 2.5542259216308594, acc: 0.2368421107530594)
                                                                                 [2024-12-14 02:09:53,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:54,276][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 2.149679660797119, acc: 0.4324324429035187)
                                                                                 [2024-12-14 02:09:54,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:54,613][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.1681771278381348, acc: 0.3214285671710968)
                                                                                  [2024-12-14 02:09:54,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:55,022][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.415428400039673, acc: 0.36734694242477417)
                                                                                 [2024-12-14 02:09:55,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:55,366][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 2.0855960845947266, acc: 0.3333333432674408)
[2024-12-14 02:09:55,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:55,784][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 0.545085608959198, acc: 0.9090909361839294)
[2024-12-14 02:09:55,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:56,129][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 0.9240387678146362, acc: 0.7307692170143127)
             [2024-12-14 02:09:56,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:56,491][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 1.361199975013733, acc: 0.5185185074806213)
   [2024-12-14 02:09:56,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:56,847][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.0892512798309326, acc: 0.41025641560554504)
                                                                               [2024-12-14 02:09:56,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:57,198][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.7711102962493896, acc: 0.5151515007019043)
                                                                              [2024-12-14 02:09:57,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:57,612][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 1.947177529335022, acc: 0.45652174949645996)
                                                                                                                                                              [2024-12-14 02:09:57,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:57,974][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.2812979221343994, acc: 0.4313725531101227)
                                                                               [2024-12-14 02:09:58,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:58,367][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 1.8951741456985474, acc: 0.44897958636283875)
[2024-12-14 02:09:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:58,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:58,455][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 1.8119432926177979, acc: 0.5151515007019043)
[2024-12-14 02:09:58,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:58,796][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 1.9037902355194092, acc: 0.37037035822868347)
[2024-12-14 02:09:58,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:58,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:59,160][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 2.0352773666381836, acc: 0.5)
[2024-12-14 02:09:59,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:59,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:59,553][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 0.9529582262039185, acc: 0.699999988079071)
[2024-12-14 02:09:59,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:59,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:09:59,975][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 1.9139533042907715, acc: 0.48275861144065857)
[2024-12-14 02:10:00,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:00,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:00,301][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 1.5284037590026855, acc: 0.6451612710952759)
[2024-12-14 02:10:00,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:00,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:00,661][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.1311291456222534, acc: 0.7894737124443054)
[2024-12-14 02:10:00,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:00,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:01,020][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.4065358638763428, acc: 0.5185185074806213)
[2024-12-14 02:10:01,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:01,411][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.4400577545166016, acc: 0.3333333432674408)
[2024-12-14 02:10:01,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:01,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:01,777][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 1.7842121124267578, acc: 0.4545454680919647)
[2024-12-14 02:10:01,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:01,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:02,171][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.1329894065856934, acc: 0.4000000059604645)
[2024-12-14 02:10:02,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:02,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:03,694][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 2.5694377422332764, acc: 0.32015809416770935)
[2024-12-14 02:10:02,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:02,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:02,949][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 1.7306725978851318, acc: 0.517241358757019)
[2024-12-14 02:10:03,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:03,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:03,292][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.2410082817077637, acc: 0.37254902720451355)
[2024-12-14 02:10:03,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:03,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:03,672][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 1.9029730558395386, acc: 0.517241358757019)
[2024-12-14 02:10:03,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:03,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:04,076][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 0.8666847348213196, acc: 0.7368420958518982)
[2024-12-14 02:10:04,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:04,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:04,480][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.223578453063965, acc: 0.21052631735801697)
[2024-12-14 02:10:04,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:04,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:04,886][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.206871271133423, acc: 0.4285714328289032)
[2024-12-14 02:10:05,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:05,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:05,317][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.172205686569214, acc: 0.40449437499046326)
[2024-12-14 02:10:05,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:05,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:05,680][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.4786155223846436, acc: 0.3595505654811859)
[2024-12-14 02:10:05,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:05,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:06,008][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.504729986190796, acc: 0.347517728805542)
[2024-12-14 02:10:06,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:06,416][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.5511794090270996, acc: 0.3586956560611725)
[2024-12-14 02:10:06,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:06,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:06,793][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 1.0214401483535767, acc: 0.7599999904632568)
[2024-12-14 02:10:06,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:06,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:07,180][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 1.3206690549850464, acc: 0.7307692170143127)
[2024-12-14 02:10:07,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:07,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:07,581][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 1.1967648267745972, acc: 0.7037037014961243)
[2024-12-14 02:10:07,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:07,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:07,932][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 2.057429790496826, acc: 0.4444444477558136)
[2024-12-14 02:10:08,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:08,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:08,247][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 1.8880481719970703, acc: 0.5471698045730591)
[2024-12-14 02:10:08,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:08,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:08,945][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 2.769416570663452, acc: 0.3378378450870514)
)
[2024-12-14 02:10:08,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:08,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:09,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:09,256][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.217723846435547, acc: 0.3963963985443115)
[2024-12-14 02:10:09,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:09,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:09,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:09,745][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 2.1758882999420166, acc: 0.39436620473861694)
[2024-12-14 02:10:09,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:10,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:10,136][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 0.5672029256820679, acc: 0.8999999761581421)
[2024-12-14 02:10:10,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:10,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:10,506][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 1.0255959033966064, acc: 0.7333333492279053)
[2024-12-14 02:10:10,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:10,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:10,844][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 1.4901015758514404, acc: 0.5384615659713745)
[2024-12-14 02:10:11,146][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:10:11,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:11,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:11,965][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:10:12,208][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                               [2024-12-14 02:10:12,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:13,069][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:10:13,256][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 2.268781900405884, acc: 0.4285714328289032)
[2024-12-14 02:10:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:13,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:13,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:14,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:14,034][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 2.2966673374176025, acc: 0.460317462682724)
[2024-12-14 02:10:14,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:14,366][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 1.8680058717727661, acc: 0.5357142686843872)
[2024-12-14 02:10:15,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:14,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:14,723][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 1.8756235837936401, acc: 0.4833333194255829)
[2024-12-14 02:10:14,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:14,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:15,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:15,422][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.0708937644958496, acc: 0.5138888955116272)
[2024-12-14 02:10:15,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:15,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:15,750][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 0.6669045090675354, acc: 0.7692307829856873)
[2024-12-14 02:10:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:15,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:16,078][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 2.2129404544830322, acc: 0.4838709533214569)
[2024-12-14 02:10:16,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:16,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:16,453][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 2.7207980155944824, acc: 0.44999998807907104)
[2024-12-14 02:10:16,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:16,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:16,885][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.2849843502044678, acc: 0.40740740299224854)
[2024-12-14 02:10:16,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:17,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:17,362][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:10:17,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:17,913][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.2489657402038574, acc: 0.41101694107055664)
[2024-12-14 02:10:18,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:18,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:18,320][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.278944253921509, acc: 0.4029850661754608)
[2024-12-14 02:10:18,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:18,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:18,714][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.3298628330230713, acc: 0.37226277589797974)
[2024-12-14 02:10:18,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:18,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:19,292][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.1405954360961914, acc: 0.42500001192092896)
[2024-12-14 02:10:19,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:19,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:19,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:19,675][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.342782497406006, acc: 0.35185185074806213)
[2024-12-14 02:10:19,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:19,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:20,100][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.0924313068389893, acc: 0.48076921701431274)
[2024-12-14 02:10:20,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:20,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:20,498][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.5696897506713867, acc: 0.190476194024086)
[2024-12-14 02:10:20,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:20,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:20,875][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 3.063119649887085, acc: 0.1803278625011444)
[2024-12-14 02:10:21,000][slam_llm.models.slam_modeoch: 2/10, step 62/574 completed (loss: 1.5778446197509766, acc: 0.529411792755127)
[2024-12-14 02:10:21,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:21,602][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 2.072535514831543, acc: 0.4444444477558136)
                                                                                                                                                                                                                                                                [2024-12-14 02:10:21,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:21,946][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 1.9562931060791016, acc: 0.53125)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:10:22,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:22,232][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 1.076261043548584, acc: 0.7586206793785095)
                                                                                                                                                                                                                          [2024-12-14 02:10:22,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:22,551][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 2.475950241088867, acc: 0.3571428656578064)
                                                                                                                                                                                                                          [2024-12-14 02:10:22,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:22,884][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 2.300739049911499, acc: 0.4166666567325592)
                                                                                                                                                                                                                          [2024-12-14 02:10:22,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:23,206][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 0.9941902756690979, acc: 0.6800000071525574)
                                                                                                                                        [2024-12-14 02:10:23,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:23,527][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 1.5367382764816284, acc: 0.6111111044883728)
                                                                               [2024-12-14 02:10:23,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:23,826][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 1.6524332761764526, acc: 0.5454545617103577)
 [2024-12-14 02:10:23,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:24,228][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 2.2616591453552246, acc: 0.44117647409439087)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:10:24,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:24,622][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.161992311477661, acc: 0.4047619104385376)
                                                                                                                                           [2024-12-14 02:10:24,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:24,971][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.433529853820801, acc: 0.3589743673801422)
                                                                                                                                                                                                               [2024-12-14 02:10:25,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:25,266][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.1776175498962402, acc: 0.3979591727256775)
                                                                                                                                                                                                            [2024-12-14 02:10:25,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:25,627][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.6143367290496826, acc: 0.28358209133148193)
                                                                                                                                                                                                                       [2024-12-14 02:10:25,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:26,037][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.355559825897217, acc: 0.37226277589797974)
                                                                                                                                                                                                              [2024-12-14 02:10:26,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:26,395][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.861860454082489, acc: 0.761904776096344)
   [2024-12-14 02:10:26,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:26,700][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 0.7522545456886292, acc: 0.8333333134651184)
                                                                                                                                         [2024-12-14 02:10:26,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:27,021][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.3092461824417114, acc: 0.5757575631141663)
                                                                                 [2024-12-14 02:10:27,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:27,416][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.266602873802185, acc: 0.6538461446762085)
                                                                                                                                            [2024-12-14 02:10:27,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:27,765][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 2.0217976570129395, acc: 0.4615384638309479)
[2024-12-14 02:10:27,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:28,135][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.3975203037261963, acc: 0.38461539149284363)
[2024-12-14 02:10:28,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:28,466][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 1.7750658988952637, acc: 0.46875)
                                                                                          [2024-12-14 02:10:28,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:28,473][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 1.9278945922851562, acc: 0.5483871102333069)
[2024-12-14 02:10:28,505][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 2.5203917026519775, acc: 0.35820895433425903)
[2024-12-14 02:10:28,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:28,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:28,799][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 0.9762359857559204, acc: 0.7599999904632568)
[2024-12-14 02:10:28,890][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.483510971069336, acc: 0.37735849618911743)
[2024-12-14 02:10:28,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:29,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:29,183][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.670651912689209, acc: 0.5151515007019043)
[2024-12-14 02:10:29,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:29,346][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 1.7113345861434937, acc: 0.5227272510528564)
[2024-12-14 02:10:29,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:29,536][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 1.4314719438552856, acc: 0.6000000238418579)
[2024-12-14 02:10:29,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:29,685][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.2802512645721436, acc: 0.43478259444236755)
[2024-12-14 02:10:29,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:29,900][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.7246140241622925, acc: 0.48571428656578064)
[2024-12-14 02:10:30,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:30,068][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 2.003770589828491, acc: 0.5769230723381042)
[2024-12-14 02:10:30,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:30,272][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.613713502883911, acc: 0.30656933784484863)
[2024-12-14 02:10:30,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:30,430][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.8597307205200195, acc: 0.4642857015132904)
[2024-12-14 02:10:30,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:30,624][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.24694561958313, acc: 0.4275861978530884)
[2024-12-14 02:10:30,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:30,802][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.642552614212036, acc: 0.34328359365463257)
[2024-12-14 02:10:30,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:30,980][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.9893269538879395, acc: 0.20000000298023224)
[2024-12-14 02:10:31,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:31,219][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.1726179122924805, acc: 0.4861111044883728)
[2024-12-14 02:10:31,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:31,409][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.911243200302124, acc: 0.19205297529697418)
[2024-12-14 02:10:31,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:32,369][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.1661784648895264, acc: 0.39247313141822815)

[2024-12-14 02:10:31,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:31,817][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 2.3642706871032715, acc: 0.4017094075679779)
[2024-12-14 02:10:31,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:32,021][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.554987907409668, acc: 0.3205128312110901)
[2024-12-14 02:10:32,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:32,174][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 0.840361475944519, acc: 0.8399999737739563)
[2024-12-14 02:10:32,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:32,431][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.6254825592041016, acc: 0.3815789520740509)
[2024-12-14 02:10:32,552][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.6973737478256226, acc: 0.5769230723381042)
[2024-12-14 02:10:32,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:32,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:32,895][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 1.9600239992141724, acc: 0.5102040767669678)
[2024-12-14 02:10:32,949][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.3581042289733887, acc: 0.5769230723381042)
[2024-12-14 02:10:33,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:33,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:33,286][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 1.7107610702514648, acc: 0.5757575631141663)
[2024-12-14 02:10:33,340][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 2.0178489685058594, acc: 0.4871794879436493)
[2024-12-14 02:10:33,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:33,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:33,697][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.376887798309326, acc: 0.30927833914756775)
[2024-12-14 02:10:33,761][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 1.9531315565109253, acc: 0.4888888895511627)
[2024-12-14 02:10:33,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:33,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:34,082][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.2152843475341797, acc: 0.3857142925262451)
[2024-12-14 02:10:34,104][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.213712692260742, acc: 0.3896103799343109)
[2024-12-14 02:10:34,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:34,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:34,424][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.1392858028411865, acc: 0.375)
[2024-12-14 02:10:34,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:34,535][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.3123490810394287, acc: 0.3604651093482971)
[2024-12-14 02:10:34,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:34,762][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.3018202781677246, acc: 0.3965517282485962)
[2024-12-14 02:10:34,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:34,950][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.546008586883545, acc: 0.3214285671710968)
[2024-12-14 02:10:35,098][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.112168312072754, acc: 0.3928571343421936)
[2024-12-14 02:10:35,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:35,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:35,355][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 2.297351360321045, acc: 0.3580246865749359)
[2024-12-14 02:10:35,492][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.8794927597045898, acc: 0.42105263471603394)
[2024-12-14 02:10:35,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:35,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:36,065][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 2.6913716793060303, acc: 0.23529411852359772)
                                                                                                                                                                                                                         [2024-12-14 02:10:36,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:36,478][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.7589738368988037, acc: 0.2211538404226303)
                                                                                                                                                                                                              [2024-12-14 02:10:36,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:36,890][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.5796456336975098, acc: 0.34306567907333374)
                                                                                                                                                                                                                                                                         [2024-12-14 02:10:37,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:37,272][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 2.6953036785125732, acc: 0.2537313401699066)
[2024-12-14 02:10:37,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:37,646][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 1.6283960342407227, acc: 0.6499999761581421)
                                                                                                                                          [2024-12-14 02:10:37,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:38,031][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 1.196526288986206, acc: 0.6818181872367859)
                                                                               [2024-12-14 02:10:38,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:38,412][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.2928855419158936, acc: 0.695652186870575)
                                                                                [2024-12-14 02:10:38,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:38,787][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 1.8184070587158203, acc: 0.4545454680919647)
[2024-12-14 02:10:38,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:39,145][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.1472017765045166, acc: 0.4482758641242981)
                                                                                                                                                             [2024-12-14 02:10:39,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:39,430][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 2.140864610671997, acc: 0.3720930218696594)
[2024-12-14 02:10:39,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:39,726][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.6500195264816284, acc: 0.6000000238418579)
[2024-12-14 02:10:39,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:40,076][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.7738706469535828, acc: 0.7058823704719543)
[2024-12-14 02:10:40,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:40,455][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.6102351546287537, acc: 0.8461538553237915)
[2024-12-14 02:10:40,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:40,807][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.9489431381225586, acc: 0.4285714328289032)
[2024-12-14 02:10:40,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:41,157][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.025024175643921, acc: 0.4769230782985687)
                                                                                [2024-12-14 02:10:41,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:41,561][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.088001012802124, acc: 0.42105263471603394)
                                                                               [2024-12-14 02:10:41,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:41,909][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 1.9582207202911377, acc: 0.4035087823867798)
[2024-12-14 02:10:42,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:42,220][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.259518623352051, acc: 0.41025641560554504)
                      [2024-12-14 02:10:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:42,592][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.5387635231018066, acc: 0.7142857313156128)
                                                                               [2024-12-14 02:10:42,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:42,939][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 0.5970418453216553, acc: 0.8181818127632141)
[2024-12-14 02:10:43,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:43,247][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.2113394737243652, acc: 0.3968254029750824)
                                                                              [2024-12-14 02:10:43,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:43,557][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.1648192405700684, acc: 0.4878048896789551)
                                                                                [2024-12-14 02:10:43,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:43,958][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.8497583866119385, acc: 0.5322580933570862)
                                                                                                                                                              [2024-12-14 02:10:44,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:44,808][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.1383469104766846, acc: 0.4486691951751709)
                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:10:44,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:45,143][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.8628251552581787, acc: 0.5199999809265137)
                                                                              [2024-12-14 02:10:45,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:45,566][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.6560872793197632, acc: 0.5961538553237915)
                                                                               [2024-12-14 02:10:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:45,943][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 1.0471924543380737, acc: 0.7916666865348816)
                                                                                [2024-12-14 02:10:46,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:46,283][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.917644739151001, acc: 0.4736842215061188)
[2024-12-14 02:10:46,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:46,632][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.3002729415893555, acc: 0.38650307059288025)
                    [2024-12-14 02:10:46,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:47,040][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 1.9409465789794922, acc: 0.5138888955116272)
                                                                [2024-12-14 02:10:47,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:47,419][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.360353708267212, acc: 0.3333333432674408)
                                                                               [2024-12-14 02:10:47,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:47,798][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.414128065109253, acc: 0.3214285671710968)
 [2024-12-14 02:10:47,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:48,154][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.21624755859375, acc: 0.4307692348957062)
                                                                               [2024-12-14 02:10:48,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:48,559][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 1.9849624633789062, acc: 0.49264705181121826)
                                                                                                                                                                                                                                             [2024-12-14 02:10:48,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:48,884][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.3064243793487549, acc: 0.6153846383094788)
                                                                                [2024-12-14 02:10:48,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:49,185][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 0.8932624459266663, acc: 0.695652186870575)
                                                                                [2024-12-14 02:10:49,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:49,543][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 1.7702759504318237, acc: 0.46875)
           [2024-12-14 02:10:49,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:49,924][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 2.0279905796051025, acc: 0.43478259444236755)
                                                                                                                                                            [2024-12-14 02:10:50,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:50,306][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 1.5394898653030396, acc: 0.5714285969734192)
[2024-12-14 02:10:50,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:50,673][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 1.439335584640503, acc: 0.5384615659713745)
                                                                                [2024-12-14 02:10:50,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:51,029][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 2.3351526260375977, acc: 0.3095238208770752)
                                                                              [2024-12-14 02:10:51,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:51,387][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 1.6935898065567017, acc: 0.5)
[2024-12-14 02:10:51,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:51,741][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.9112548828125, acc: 0.43478259444236755)
                                                                                 [2024-12-14 02:10:51,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:52,111][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 2.3692760467529297, acc: 0.4761904776096344)
                                                                               [2024-12-14 02:10:52,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:52,430][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 2.384115219116211, acc: 0.42307692766189575)
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:10:53,204][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:10:53,628][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:10:54,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:54,395][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:10:54,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:55,163][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:10:55,541][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:10:55,848][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:10:56,123][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:10:56,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:56,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:57,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:57,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:57,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:57,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:58,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:58,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:59,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:59,294][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 2.3052544593811035, acc: 0.4214285612106323)
[2024-12-14 02:10:59,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:10:59,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:00,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:00,180][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 2.31552791595459, acc: 0.4523809552192688)
[2024-12-14 02:11:00,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:00,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:00,599][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 1.9195842742919922, acc: 0.5)
[2024-12-14 02:11:00,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:00,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:00,970][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 1.8354016542434692, acc: 0.4833333194255829)
[2024-12-14 02:11:01,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:01,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:01,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:01,782][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.087225914001465, acc: 0.5)
[2024-12-14 02:11:01,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:01,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:02,150][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 0.7227874398231506, acc: 0.7307692170143127)
[2024-12-14 02:11:02,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:02,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:02,546][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 2.1803600788116455, acc: 0.5161290168762207)
[2024-12-14 02:11:02,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:02,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:02,960][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 2.614989757537842, acc: 0.44999998807907104)
[2024-12-14 02:11:03,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:03,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:03,329][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.2253425121307373, acc: 0.40740740299224854)
[2024-12-14 02:11:03,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:03,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:04,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:04,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:04,466][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.2550389766693115, acc: 0.41525423526763916)
[2024-12-14 02:11:04,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:04,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:04,837][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.2860217094421387, acc: 0.4029850661754608)
[2024-12-14 02:11:05,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:05,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:05,280][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.3264122009277344, acc: 0.37956205010414124)
[2024-12-14 02:11:05,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:05,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:05,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:05,878][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.1532726287841797, acc: 0.42500001192092896)
[2024-12-14 02:11:05,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:06,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:06,249][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.3517494201660156, acc: 0.31481480598449707)
[2024-12-14 02:11:06,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:06,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:06,671][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.1081624031066895, acc: 0.4615384638309479)
[2024-12-14 02:11:06,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:06,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:07,049][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.5841333866119385, acc: 0.2380952388048172)
[2024-12-14 02:11:07,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:07,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:07,443][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 3.057628631591797, acc: 0.1803278625011444)
[2024-12-14 02:11:07,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:07,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:07,817][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.024111032485962, acc: 0.508474588394165)
[2024-12-14 02:11:07,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:08,063][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.6843, device='cuda:0') eval_epoch_loss=tensor(2.0392, device='cuda:0') eval_epoch_acc=tensor(0.4613, device='cuda:0')
[2024-12-14 02:11:08,065][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:11:08,065][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:11:08,163][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 2.5393357276916504, acc: 0.302325576543808)
[2024-12-14 02:11:08,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:08,295][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_1_step_572_loss_2.0391759872436523/model.pt
[2024-12-14 02:11:08,299][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:11:08,299][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.0391759872436523
[2024-12-14 02:11:08,300][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.4612591564655304
[2024-12-14 02:11:08,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:08,502][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.358616828918457, acc: 0.47727271914482117)
[2024-12-14 02:11:08,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:08,657][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 2.5228686332702637, acc: 0.3163265287876129)
[2024-12-14 02:11:08,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:08,832][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.55230975151062, acc: 0.30188679695129395)
[2024-12-14 02:11:08,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:09,026][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 2.397278308868408, acc: 0.3396226465702057)
[2024-12-14 02:11:09,167][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.191498279571533, acc: 0.5)
[2024-12-14 02:11:09,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:09,689][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:11:09,996][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:11:10,325][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:11:10,689][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:11:11,058][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                    [2024-12-14 02:11:11,373][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                           [2024-12-14 02:11:11,704][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:11:12,093][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:11:12,586][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                               [2024-12-14 02:11:12,941][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:11:13,354][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:11:13,794][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:11:14,230][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:11:14,562][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:11:14,957][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:11:15,455][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                     [2024-12-14 02:11:15,744][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:11:16,113][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:11:16,472][slam_llm.models.slam_model][INFO] - modality encoder
eted (loss: 1.180759072303772, acc: 0.7368420958518982)
[2024-12-14 02:11:16,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:16,452][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.7136695384979248, acc: 0.4714285731315613)
[2024-12-14 02:11:16,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:16,661][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 2.0842270851135254, acc: 0.375)
[2024-12-14 02:11:16,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:16,801][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.600670576095581, acc: 0.32116788625717163)
[2024-12-14 02:11:16,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:17,018][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.5705721378326416, acc: 0.3333333432674408)
[2024-12-14 02:11:17,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:17,150][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.2280752658843994, acc: 0.4275861978530884)
[2024-12-14 02:11:17,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:17,365][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 2.137679100036621, acc: 0.4736842215061188)
[2024-12-14 02:11:17,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:17,538][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.9987220764160156, acc: 0.20000000298023224)
[2024-12-14 02:11:17,737][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 2.1368181705474854, acc: 0.38461539149284363)
[2024-12-14 02:11:17,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:17,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:17,989][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.911954402923584, acc: 0.1986754983663559)
[2024-12-14 02:11:18,135][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 2.114128589630127, acc: 0.4482758641242981)
[2024-12-14 02:11:18,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:18,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:18,376][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 2.362126111984253, acc: 0.4017094075679779)
[2024-12-14 02:11:18,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:18,534][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 1.9447482824325562, acc: 0.4000000059604645)
[2024-12-14 02:11:18,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:18,768][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 0.8148319721221924, acc: 0.800000011920929)
[2024-12-14 02:11:18,920][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 1.0866670608520508, acc: 0.7142857313156128)
[2024-12-14 02:11:18,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:19,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:19,144][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.7045319080352783, acc: 0.6153846383094788)
[2024-12-14 02:11:19,270][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 2.084895610809326, acc: 0.375)
[2024-12-14 02:11:19,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:19,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:19,542][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.3463497161865234, acc: 0.5769230723381042)
[2024-12-14 02:11:19,620][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 2.8374075889587402, acc: 0.22641509771347046)
[2024-12-14 02:11:19,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:20,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:19,930][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 1.9822903871536255, acc: 0.4871794879436493)
[2024-12-14 02:11:19,988][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.5121042728424072, acc: 0.34246575832366943)
[2024-12-14 02:11:20,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:20,345][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 1.9623016119003296, acc: 0.47777777910232544)
[2024-12-14 02:11:20,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:20,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:20,680][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.199025869369507, acc: 0.3896103799343109)
[2024-12-14 02:11:20,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:21,011][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.1152560710906982, acc: 0.375)
[2024-12-14 02:11:21,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:21,187][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 2.5936574935913086, acc: 0.3083004057407379)
[2024-12-14 02:11:21,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:21,389][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.3096413612365723, acc: 0.37931033968925476)
[2024-12-14 02:11:21,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:21,536][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 2.2968432903289795, acc: 0.39534884691238403)
[2024-12-14 02:11:21,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:21,739][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.1151843070983887, acc: 0.3928571343421936)
[2024-12-14 02:11:21,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:21,928][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 2.351450204849243, acc: 0.3614457845687866)
[2024-12-14 02:11:22,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:22,098][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.8647394180297852, acc: 0.42105263471603394)
[2024-12-14 02:11:22,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:22,282][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.3725833892822266, acc: 0.3580246865749359)
[2024-12-14 02:11:22,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:22,445][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 2.0130562782287598, acc: 0.40740740299224854)
[2024-12-14 02:11:22,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:22,669][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 2.4146251678466797, acc: 0.3214285671710968)
[2024-12-14 02:11:22,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:22,924][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.278796434402466, acc: 0.34224599599838257)
[2024-12-14 02:11:23,028][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 1.7611595392227173, acc: 0.5925925970077515)
[2024-12-14 02:11:23,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:23,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:23,389][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 1.915138840675354, acc: 0.5161290168762207)
[2024-12-14 02:11:23,422][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 1.6787351369857788, acc: 0.52173912525177)
[2024-12-14 02:11:23,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:23,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:23,757][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 2.3252174854278564, acc: 0.4188034236431122)
[2024-12-14 02:11:23,831][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 2.2687063217163086, acc: 0.3781512677669525)
                                                                             [2024-12-14 02:11:23,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:24,182][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.960712194442749, acc: 0.22580644488334656)
[2024-12-14 02:11:24,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:24,532][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 2.467440605163574, acc: 0.3513513505458832)
[2024-12-14 02:11:24,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:25,056][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.323857307434082, acc: 0.3333333432674408)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:11:25,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:25,443][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.9503251314163208, acc: 0.49253731966018677)
                                                                             [2024-12-14 02:11:25,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:25,852][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.465754985809326, acc: 0.37755101919174194)
                                                                                                                                                             [2024-12-14 02:11:25,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:26,291][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.2226948738098145, acc: 0.3191489279270172)
                                                                             [2024-12-14 02:11:26,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:26,640][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.027294158935547, acc: 0.4285714328289032)
                                                                               [2024-12-14 02:11:26,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:27,006][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 2.450570821762085, acc: 0.5)
                                                                                              [2024-12-14 02:11:27,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:27,359][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.6096065044403076, acc: 0.5652173757553101)
[2024-12-14 02:11:27,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:27,694][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.189896583557129, acc: 0.27586206793785095)
                                                                              [2024-12-14 02:11:27,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:28,104][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.2286250591278076, acc: 0.41304346919059753)
                                                                             [2024-12-14 02:11:28,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:28,509][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.1572844982147217, acc: 0.38983049988746643)
                                                                             [2024-12-14 02:11:28,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:28,858][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.4842214584350586, acc: 0.3684210479259491)
                                                                              [2024-12-14 02:11:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:29,177][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.0265026092529297, acc: 0.47297295928001404)
0, step 48/574 completed (loss: 1.4580990076065063, acc: 0.5357142686843872)
[2024-12-14 02:11:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:29,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:29,413][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 1.4093822240829468, acc: 0.5833333134651184)
[2024-12-14 02:11:29,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:29,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:29,791][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 1.6421581506729126, acc: 0.5789473652839661)
[2024-12-14 02:11:29,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:29,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:30,203][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 1.7615406513214111, acc: 0.5079365372657776)
[2024-12-14 02:11:30,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:30,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:30,626][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.2249364852905273, acc: 0.43661972880363464)
[2024-12-14 02:11:30,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:30,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:30,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:31,085][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 2.583120822906494, acc: 0.40666666626930237)
[2024-12-14 02:11:31,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:31,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:31,420][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 1.4092823266983032, acc: 0.6756756901741028)
[2024-12-14 02:11:31,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:31,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:31,801][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 0.7563378214836121, acc: 0.7307692170143127)
[2024-12-14 02:11:31,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:32,100][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:11:32,500][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:11:32,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:33,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:33,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:33,656][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                     [2024-12-14 02:11:34,079][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                          [2024-12-14 02:11:34,492][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:11:34,835][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 2.109198808670044, acc: 0.467576801776886)
[2024-12-14 02:11:34,887][slam_llm.models.slam_model][INFO] - modality encoder
   [2024-12-14 02:11:35,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:35,206][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:11:35,648][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 2.010744094848633, acc: 0.5)
[2024-12-14 02:11:35,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:35,921][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.7905820608139038, acc: 0.5138888955116272)
[2024-12-14 02:11:36,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:36,302][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.117061138153076, acc: 0.45098039507865906)
[2024-12-14 02:11:36,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:37,329][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.5035431385040283, acc: 0.3767123222351074)
                                                                                                                                                                                                                                                                                                           [2024-12-14 02:11:37,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:37,632][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.273335337638855, acc: 0.7083333134651184)
[2024-12-14 02:11:37,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:37,994][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 1.2527066469192505, acc: 0.5925925970077515)
                      [2024-12-14 02:11:38,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:38,350][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.7536052465438843, acc: 0.5)
                                                                                           [2024-12-14 02:11:38,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:38,894][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 1.9744588136672974, acc: 0.4955752193927765)
                                                                                                                                                            [2024-12-14 02:11:38,980][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:11:39,219][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 1.9177500009536743, acc: 0.47826087474823)
                       [2024-12-14 02:11:39,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:39,622][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 2.0463755130767822, acc: 0.4204545319080353)
                                                                 [2024-12-14 02:11:39,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:40,532][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 2.4892160892486572, acc: 0.35114502906799316)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:11:40,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:41,202][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 2.374222993850708, acc: 0.34074074029922485)
                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:11:41,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:41,568][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 1.7275208234786987, acc: 0.5081967115402222)
                                                                              [2024-12-14 02:11:41,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:41,892][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 0.9824163317680359, acc: 0.75)
[2024-12-14 02:11:41,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:42,217][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 1.7429102659225464, acc: 0.5600000023841858)
[2024-12-14 02:11:42,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:42,523][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 1.47832190990448, acc: 0.6428571343421936)
                                  [2024-12-14 02:11:42,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:42,895][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 2.258167028427124, acc: 0.3414634168148041)
                                                                              [2024-12-14 02:11:43,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:43,328][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 2.446253538131714, acc: 0.3504531681537628)
[2024-12-14 02:11:43,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:43,704][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.5401759147644043, acc: 0.3285302519798279)
                                                                              [2024-12-14 02:11:43,833][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:11:44,192][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.533356189727783, acc: 0.36250001192092896)
[2024-12-14 02:11:44,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:44,721][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.3193395137786865, acc: 0.36397749185562134)
                                                                                                                                                          [2024-12-14 02:11:44,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:45,121][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.3093066215515137, acc: 0.38078293204307556)
                                                                             [2024-12-14 02:11:45,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:45,502][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 2.5910820960998535, acc: 0.47999998927116394)
                                                                            [2024-12-14 02:11:45,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:46,049][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.4282050132751465, acc: 0.38372093439102173)
                                                                                                                                                            [2024-12-14 02:11:46,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:46,850][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.085563898086548, acc: 0.5158730149269104)

[2024-12-14 02:11:46,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:46,468][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 1.7281025648117065, acc: 0.5)
[2024-12-14 02:11:46,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:46,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:46,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:46,855][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 2.254265546798706, acc: 0.43478259444236755)
[2024-12-14 02:11:46,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:47,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:47,212][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.7117668390274048, acc: 0.5)
[2024-12-14 02:11:47,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:47,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:47,569][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 2.2775683403015137, acc: 0.3478260934352875)
[2024-12-14 02:11:47,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:47,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:48,036][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.7471923828125, acc: 0.30000001192092896)
[2024-12-14 02:11:48,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:48,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:48,386][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 2.04148006439209, acc: 0.4757281541824341)
[2024-12-14 02:11:48,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:48,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:48,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:49,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:49,435][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 1.9855965375900269, acc: 0.5291262269020081)
[2024-12-14 02:11:49,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:49,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:49,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:50,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:50,260][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.1704893112182617, acc: 0.4139784872531891)
[2024-12-14 02:11:50,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:50,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:50,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:51,066][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 1.9747942686080933, acc: 0.5258620977401733)
 [2024-12-14 02:11:51,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:51,254][slam_llm.models.slam_model][INFO] - modality encoder
                                           [2024-12-14 02:11:51,567][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:11:51,809][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 1.7378571033477783, acc: 0.5157894492149353)
[2024-12-14 02:11:51,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:52,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:52,235][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:11:52,548][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:11:52,798][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 2.4335427284240723, acc: 0.2871287167072296)
[2024-12-14 02:11:52,870][slam_llm.models.slam_model][INFO] - modality encoder
[2[2024-12-14 02:11:53,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:53,461][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 2.160349130630493, acc: 0.4126984179019928)
                                                                                                                                                                                                                                                                                                    [2024-12-14 02:11:53,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:53,833][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 2.096693754196167, acc: 0.4285714328289032)
                                                                                [2024-12-14 02:11:53,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:54,210][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.272231340408325, acc: 0.3901345431804657)
                                                                                [2024-12-14 02:11:54,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:54,624][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.13743257522583, acc: 0.4645669162273407)
  [2024-12-14 02:11:54,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:55,022][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 2.199045181274414, acc: 0.42241379618644714)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:11:55,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:55,384][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.1204750537872314, acc: 0.4420289993286133)
                                                                                                                                                                                                                       [2024-12-14 02:11:55,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:55,780][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.302278757095337, acc: 0.3540855944156647)
                                                                                                                                          [2024-12-14 02:11:55,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:56,172][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.4195563793182373, acc: 0.3913043439388275)
[2024-12-14 02:11:56,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:56,518][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.5445886850357056, acc: 0.6521739363670349)
98909679055214s
[2024-12-14 02:11:56,275][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-14 02:11:56,275][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:11:56,275][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-14 02:11:56,275][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 3
[2024-12-14 02:11:56,276][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:11:56,378][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 1.806505560874939, acc: 0.4545454680919647)
[2024-12-14 02:11:56,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:56,745][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.159128427505493, acc: 0.43103447556495667)
[2024-12-14 02:11:56,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:56,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:57,095][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 2.1288294792175293, acc: 0.41860464215278625)
[2024-12-14 02:11:57,174][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 1.6747459173202515, acc: 0.48148149251937866)
[2024-12-14 02:11:57,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:57,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:57,447][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.600001335144043, acc: 0.6000000238418579)
[2024-12-14 02:11:57,494][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 2.2123918533325195, acc: 0.36000001430511475)
[2024-12-14 02:11:57,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:57,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:57,798][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.7225747108459473, acc: 0.7647058963775635)
[2024-12-14 02:11:57,815][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 2.88092303276062, acc: 0.3243243098258972)
[2024-12-14 02:11:57,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:57,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:58,153][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 2.5074353218078613, acc: 0.2368421107530594)
[2024-12-14 02:11:58,185][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.5888125896453857, acc: 0.8461538553237915)
[2024-12-14 02:11:58,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:58,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:58,523][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 2.1001980304718018, acc: 0.45945945382118225)
[2024-12-14 02:11:58,524][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.9251234531402588, acc: 0.4285714328289032)
[2024-12-14 02:11:58,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:58,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:58,886][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.1265034675598145, acc: 0.3214285671710968)
[2024-12-14 02:11:58,924][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.0371830463409424, acc: 0.4615384638309479)
[2024-12-14 02:11:58,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:59,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:59,229][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.405618906021118, acc: 0.3877550959587097)
[2024-12-14 02:11:59,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:59,365][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.074281692504883, acc: 0.4385964870452881)
[2024-12-14 02:11:59,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:59,542][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 2.1018056869506836, acc: 0.3333333432674408)
[2024-12-14 02:11:59,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:59,989][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 0.9445174336433411, acc: 0.6666666865348816)

[2024-12-14 02:11:59,832][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 0.5491963028907776, acc: 0.9090909361839294)
[2024-12-14 02:11:59,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:11:59,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:00,075][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 0.932643473148346, acc: 0.7307692170143127)
[2024-12-14 02:12:00,116][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.2627968788146973, acc: 0.38461539149284363)
[2024-12-14 02:12:00,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:00,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:00,430][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 1.344549298286438, acc: 0.5185185074806213)
[2024-12-14 02:12:00,486][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.5748213529586792, acc: 0.6734693646430969)
[2024-12-14 02:12:00,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:00,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:00,759][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.053497076034546, acc: 0.41025641560554504)
[2024-12-14 02:12:00,840][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 0.568622350692749, acc: 0.8636363744735718)
[2024-12-14 02:12:00,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:00,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:01,150][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.7688727378845215, acc: 0.5454545617103577)
[2024-12-14 02:12:01,252][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.174790382385254, acc: 0.380952388048172)
[2024-12-14 02:12:01,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:01,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:01,520][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 1.9284805059432983, acc: 0.43478259444236755)
[2024-12-14 02:12:01,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:01,646][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.1683707237243652, acc: 0.4878048896789551)
[2024-12-14 02:12:01,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:01,880][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.234675645828247, acc: 0.47058823704719543)
[2024-12-14 02:12:02,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:02,015][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.8176201581954956, acc: 0.5483871102333069)
[2024-12-14 02:12:02,241][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 1.8990637063980103, acc: 0.44897958636283875)
[2024-12-14 02:12:02,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:02,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:02,550][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.157057523727417, acc: 0.7368420958518982)
[2024-12-14 02:12:02,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:02,910][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.165806531906128, acc: 0.4524714946746826)
[2024-12-14 02:12:02,923][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 2.040189027786255, acc: 0.375)
[2024-12-14 02:12:03,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:03,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:03,275][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.863410234451294, acc: 0.4933333396911621)
[2024-12-14 02:12:03,279][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.518503427505493, acc: 0.3333333432674408)
[2024-12-14 02:12:03,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:03,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:03,648][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 2.0640816688537598, acc: 0.4736842215061188)
[2024-12-14 02:12:03,686][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.6888222694396973, acc: 0.5961538553237915)
[2024-12-14 02:12:03,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:03,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:04,043][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 2.158503532409668, acc: 0.38461539149284363)
[2024-12-14 02:12:04,056][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 1.039979100227356, acc: 0.8333333134651184)
[2024-12-14 02:12:04,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:04,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:04,408][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.9186118841171265, acc: 0.4736842215061188)
[2024-12-14 02:12:04,423][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 2.100667715072632, acc: 0.48275861144065857)
[2024-12-14 02:12:04,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:04,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:04,734][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 1.9611010551452637, acc: 0.4000000059604645)
[2024-12-14 02:12:04,759][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.2850589752197266, acc: 0.38036808371543884)
[2024-12-14 02:12:04,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:04,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:05,063][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 1.0752828121185303, acc: 0.7142857313156128)
[2024-12-14 02:12:05,136][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 1.959706425666809, acc: 0.4861111044883728)
[2024-12-14 02:12:05,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:05,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:05,382][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 2.0862467288970947, acc: 0.3125)
[2024-12-14 02:12:05,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:05,535][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.3535614013671875, acc: 0.3499999940395355)
[2024-12-14 02:12:05,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:05,803][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 2.800205945968628, acc: 0.22641509771347046)
[2024-12-14 02:12:05,898][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.409335136413574, acc: 0.3273809552192688)
[2024-12-14 02:12:05,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:06,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:06,174][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.508802652359009, acc: 0.34246575832366943)
[2024-12-14 02:12:06,300][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.209681987762451, acc: 0.43589743971824646)
[2024-12-14 02:12:06,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:06,735][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 1.9938735961914062, acc: 0.49264705181121826)
[2024-12-14 02:12:06,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:06,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:07,107][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.2844810485839844, acc: 0.6153846383094788)
[2024-12-14 02:12:07,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:07,443][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 0.9250689148902893, acc: 0.6086956262588501)
[2024-12-14 02:12:07,649][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.7710756063461304, acc: 0.40740740299224854)
                                                                                                                                                           [2024-12-14 02:12:07,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:07,993][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.5739158391952515, acc: 0.6000000238418579)
                                                                                                                           [2024-12-14 02:12:08,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:08,392][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.5962715148925781, acc: 0.5454545617103577)
                                                                                                                                                                                                                    [2024-12-14 02:12:08,482][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:12:08,761][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 1.9599120616912842, acc: 0.5)
                                                                                              [2024-12-14 02:12:08,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:09,343][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.007783889770508, acc: 0.3870967626571655)
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:12:09,504][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:12:09,868][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 1.6770457029342651, acc: 0.5454545617103577)
                                                                           [2024-12-14 02:12:09,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:10,197][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 0.8257082104682922, acc: 0.8095238208770752)
                                                                                                                                                                                                                        [2024-12-14 02:12:10,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:10,552][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.438578724861145, acc: 0.6538461446762085)
                                                                                                                                                                                                                        [2024-12-14 02:12:10,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:10,894][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.565735101699829, acc: 0.5483871102333069)
                                                                                                                                         [2024-12-14 02:12:10,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:11,209][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.1246193647384644, acc: 0.44999998807907104)
[2024-12-14 02:12:11,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:11,578][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.550519347190857, acc: 0.5675675868988037)
                                                                            [2024-12-14 02:12:11,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:11,930][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.6166284084320068, acc: 0.45945945382118225)
[2024-12-14 02:12:12,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:12,257][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.4807497262954712, acc: 0.5675675868988037)
[2024-12-14 02:12:12,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:12,641][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 2.0237135887145996, acc: 0.45588234066963196)
                 [2024-12-14 02:12:12,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:13,006][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 0.805689811706543, acc: 0.7804877758026123)
                                                                                [2024-12-14 02:12:13,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:13,357][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 0.5459609627723694, acc: 0.800000011920929)
                                                                               [2024-12-14 02:12:13,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:13,718][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.4903828799724579, acc: 0.9200000166893005)
[2024-12-14 02:12:13,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:14,061][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 0.6487301588058472, acc: 0.8709677457809448)
                                                                                                                                                           [2024-12-14 02:12:14,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:14,427][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 1.96102774143219, acc: 0.5263158082962036)
[2024-12-14 02:12:14,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:14,744][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 1.9943692684173584, acc: 0.5)
[2024-12-14 02:12:14,833][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                          [2024-12-14 02:12:15,065][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.6545593738555908, acc: 0.5921052694320679)
[2024-12-14 02:12:15,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:15,627][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 1.976203441619873, acc: 0.43396225571632385)
                                                                                                                                                                                                                                           [2024-12-14 02:12:15,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:16,207][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 2.042693853378296, acc: 0.5)
                                                                                                                                                                             [2024-12-14 02:12:16,280][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:12:16,494][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 1.5150718688964844, acc: 0.5555555820465088)
[2024-12-14 02:12:16,605][slam_llm.models.slam_moot][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 1.755966067314148, acc: 0.5079365372657776)
[2024-12-14 02:12:16,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:16,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:16,989][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.2394938468933105, acc: 0.4225352108478546)
[2024-12-14 02:12:17,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:17,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:17,452][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 2.5799386501312256, acc: 0.4000000059604645)
[2024-12-14 02:12:17,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:17,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:17,781][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 1.3982239961624146, acc: 0.6756756901741028)
[2024-12-14 02:12:17,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:17,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:18,187][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 0.7680777907371521, acc: 0.7307692170143127)
[2024-12-14 02:12:18,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:18,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:18,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:19,331][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                    [2024-12-14 02:12:19,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:19,748][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:12:20,005][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:12:20,423][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:12:20,803][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                           [2024-12-14 02:12:21,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:21,234][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 2.0923454761505127, acc: 0.4744027256965637)
[2024-12-14 02:12:21,505][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:12:21,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:21,825][slam_llm.models.slam_model][INFO] - modality encoder
                                          [2024-12-14 02:12:22,100][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:12:22,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:22,575][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 2.6652538776397705, acc: 0.37037035822868347)
                                                                               [2024-12-14 02:12:22,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:22,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:23,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:23,208][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.1671767234802246, acc: 0.46590909361839294)
[2024-12-14 02odels.slam_model][INFO] - modality encoder
[2024-12-14 02:12:23,596][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.8990707397460938, acc: 0.5)
[2024-12-14 02:12:23,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:23,952][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 1.7389616966247559, acc: 0.5681818127632141)
[2024-12-14 02:12:24,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:24,375][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.3169455528259277, acc: 0.3855421543121338)
[2024-12-14 02:12:24,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:24,757][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 2.1547160148620605, acc: 0.46296295523643494)
[2024-12-14 02:12:24,875][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                               [2024-12-14 02:12:25,135][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 2.524604320526123, acc: 0.2631579041481018)
                                                                                                                                                             [2024-12-14 02:12:25,900][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:12:26,341][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:12:26,690][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:12:27,072][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:12:27,462][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:12:27,867][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:12:28,254][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:12:28,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:28,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:28,795][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.1739697456359863, acc: 0.420634925365448)
[2024-12-14 02:12:28,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:28,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:29,209][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.4264416694641113, acc: 0.3641025722026825)
[2024-12-14 02:12:29,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:29,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:29,568][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.185163736343384, acc: 0.3877550959587097)
[2024-12-14 02:12:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:29,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:29,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:29,918][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.6211490631103516, acc: 0.28358209133148193)
[2024-12-14 02:12:30,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:30,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:30,324][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.359431028366089, acc: 0.3686131238937378)
[2024-12-14 02:12:30,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:30,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:30,637][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.8999691009521484, acc: 0.761904776096344)
[2024-12-14 02:12:30,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:30,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:30,980][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 0.7312424778938293, acc: 0.8333333134651184)
[2024-12-14 02:12:31,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:31,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:31,383][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.3273874521255493, acc: 0.6060606241226196)
[2024-12-14 02:12:31,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:31,731][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.2779948711395264, acc: 0.6153846383094788)
[2024-12-14 02:12:31,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:31,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:32,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:32,079][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 2.0176076889038086, acc: 0.4615384638309479)
[2024-12-14 02:12:32,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:32,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:32,420][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.381711483001709, acc: 0.38461539149284363)
[2024-12-14 02:12:32,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:32,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:32,806][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 1.7249786853790283, acc: 0.46875)
[2024-12-14 02:12:32,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:33,165][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 2.254244804382324, acc: 0.4202898442745209)
[2024-12-14 02:12:33,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:33,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:33,564][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.7243986129760742, acc: 0.47999998927116394)
[2024-12-14 02:12:33,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:33,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:33,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:33,953][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 2.2889955043792725, acc: 0.3478260934352875)
[2024-12-14 02:12:34,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:34,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:34,425][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.706373691558838, acc: 0.30000001192092896)
[2024-12-14 02:12:34,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:34,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:34,831][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 2.0647757053375244, acc: 0.4660194218158722)
[2024-12-14 02:12:34,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:35,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:35,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:35,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:35,947][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 1.998203158378601, acc: 0.5194174647331238)
[2024-12-14 02:12:36,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:36,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:36,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:36,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:36,771][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.1838035583496094, acc: 0.4139784872531891)
[2024-12-14 02:12:36,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:37,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:37,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:37,574][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 1.9737919569015503, acc: 0.5215517282485962)
[2024-12-14 02:12:37,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:37,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:38,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:38,319][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 1.718000054359436, acc: 0.5157894492149353)
[2024-12-14 02:12:38,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:38,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:38,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:39,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:39,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:39,311][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 2.4275763034820557, acc: 0.30693069100379944)
[2024-12-14 02:12:39,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:39,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:39,710][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 2.4557080268859863, acc: 0.30645161867141724)
[2024-12-14 02:12:39,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:40,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:40,114][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.664602756500244, acc: 0.3478260934352875)
[2024-12-14 02:12:40,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:40,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:40,487][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 2.6689069271087646, acc: 0.22689075767993927)
[2024-12-14 02:12:40,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:40,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:40,879][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.7426400184631348, acc: 0.2211538404226303)
[2024-12-14 02:12:40,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:41,268][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.565880537033081, acc: 0.35766422748565674)
[2024-12-14 02:12:41,280][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.0219, device='cuda:0') eval_epoch_loss=tensor(2.0822, device='cuda:0') eval_epoch_acc=tensor(0.4426, device='cuda:0')
[2024-12-14 02:12:41,281][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:12:41,282][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:12:41,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:41,492][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_141_loss_2.08217716217041/model.pt
[2024-12-14 02:12:41,495][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:12:41,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:41,593][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 2.68987774848938, acc: 0.28358209133148193)
[2024-12-14 02:12:41,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:41,802][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 3.0097920894622803, acc: 0.22580644488334656)
[2024-12-14 02:12:41,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:41,990][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 1.5278109312057495, acc: 0.699999988079071)
[2024-12-14 02:12:42,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:42,116][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 2.5053911209106445, acc: 0.3513513505458832)
[2024-12-14 02:12:42,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:42,378][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 1.144429087638855, acc: 0.6818181872367859)
[2024-12-14 02:12:42,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:42,649][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.3477671146392822, acc: 0.34210526943206787)
[2024-12-14 02:12:42,728][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.274275779724121, acc: 0.6521739363670349)
[2024-12-14 02:12:42,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:43,052][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.9536643028259277, acc: 0.4701492488384247)
[2024-12-14 02:12:43,081][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 1.7901266813278198, acc: 0.40909090638160706)
[2024-12-14 02:12:43,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:43,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:43,403][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.4514520168304443, acc: 0.3571428656578064)
[2024-12-14 02:12:43,428][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.1461873054504395, acc: 0.43103447556495667)
[2024-12-14 02:12:43,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:43,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:43,734][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 2.153074264526367, acc: 0.41860464215278625)
[2024-12-14 02:12:43,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:43,841][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.2040774822235107, acc: 0.3404255211353302)
[2024-12-14 02:12:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:44,049][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.5791449546813965, acc: 0.6000000238418579)
[2024-12-14 02:12:44,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:44,174][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.027784824371338, acc: 0.4285714328289032)
[2024-12-14 02:12:44,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:44,369][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.7720370292663574, acc: 0.7058823704719543)
[2024-12-14 02:12:44,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:44,538][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 2.463209390640259, acc: 0.5)
[2024-12-14 02:12:44,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:44,728][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.626450777053833, acc: 0.8461538553237915)
[2024-12-14 02:12:44,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:44,947][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.5841946601867676, acc: 0.5652173757553101)
[2024-12-14 02:12:45,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:45,080][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.9224493503570557, acc: 0.4285714328289032)
[2024-12-14 02:12:45,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:45,329][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.2017366886138916, acc: 0.27586206793785095)
[2024-12-14 02:12:45,428][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.0315499305725098, acc: 0.4769230782985687)
[2024-12-14 02:12:45,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:45,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:45,725][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.210482120513916, acc: 0.43478259444236755)
[2024-12-14 02:12:45,828][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.1712777614593506, acc: 0.38596490025520325)
[2024-12-14 02:12:45,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:45,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:46,124][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.1414661407470703, acc: 0.37288135290145874)
[2024-12-14 02:12:46,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:46,227][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 1.9220043420791626, acc: 0.4385964870452881)
[2024-12-14 02:12:46,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:46,461][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.4895308017730713, acc: 0.4035087823867798)
[2024-12-14 02:12:46,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:46,589][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.280463695526123, acc: 0.38461539149284363)
[2024-12-14 02:12:46,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:46,776][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.046112060546875, acc: 0.45945945382118225)
[2024-12-14 02:12:46,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:46,975][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.5682786703109741, acc: 0.6938775777816772)
[2024-12-14 02:12:47,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:47,099][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.916503667831421, acc: 0.5714285969734192)
[2024-12-14 02:12:47,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:47,568][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.5681023001670837, acc: 0.8636363744735718)
[2024-12-14 02:12:47,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:47,473][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.4949064254760742, acc: 0.6086956262588501)
[2024-12-14 02:12:47,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:47,747][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.1853742599487305, acc: 0.4126984179019928)
[2024-12-14 02:12:47,816][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 2.193265676498413, acc: 0.31578946113586426)
[2024-12-14 02:12:47,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:48,179][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.171562433242798, acc: 0.4878048896789551)
[2024-12-14 02:12:48,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:48,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:48,584][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.8423224687576294, acc: 0.5161290168762207)
[2024-12-14 02:12:48,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:49,436][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 1.8651597499847412, acc: 0.5270270109176636)
[2024-12-14 02:12:49,494][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.153127908706665, acc: 0.4524714946746826)
[2024-12-14 02:12:49,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:49,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:49,740][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.090050220489502, acc: 0.46296295523643494)
[2024-12-14 02:12:49,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:49,883][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.8390874862670898, acc: 0.5066666603088379)
[2024-12-14 02:12:50,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:50,149][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 2.0667829513549805, acc: 0.38372093439102173)
[2024-12-14 02:12:50,303][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.6841375827789307, acc: 0.5769230723381042)
[2024-12-14 02:12:50,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:50,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:50,728][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 1.049798846244812, acc: 0.8333333134651184)
[2024-12-14 02:12:50,786][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 1.9583076238632202, acc: 0.43529412150382996)
[2024-12-14 02:12:50,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:50,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:51,121][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.9142062664031982, acc: 0.4736842215061188)
[2024-12-14 02:12:51,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:51,352][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 2.254328966140747, acc: 0.42696627974510193)
[2024-12-14 02:12:51,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:51,556][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.3087313175201416, acc: 0.3619631826877594)
[2024-12-14 02:12:51,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:51,703][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 1.9220924377441406, acc: 0.5)
[2024-12-14 02:12:51,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:51,935][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 1.946286916732788, acc: 0.5069444179534912)
[2024-12-14 02:12:52,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:52,075][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 1.8174848556518555, acc: 0.4285714328289032)
[2024-12-14 02:12:52,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:52,285][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.371971368789673, acc: 0.34166666865348816)
[2024-12-14 02:12:52,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:52,424][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 2.072904348373413, acc: 0.4137931168079376)
[2024-12-14 02:12:52,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:52,640][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.4182446002960205, acc: 0.3273809552192688)
[2024-12-14 02:12:52,744][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.6382344961166382, acc: 0.5510203838348389)
[2024-12-14 02:12:52,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:52,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:53,012][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.2012410163879395, acc: 0.4307692348957062)
[2024-12-14 02:12:53,081][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 1.9886506795883179, acc: 0.47999998927116394)
[2024-12-14 02:12:53,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:53,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:53,418][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 1.9648834466934204, acc: 0.4852941036224365)
[2024-12-14 02:12:53,484][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.791740894317627, acc: 0.5)
[2024-12-14 02:12:53,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:53,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:53,755][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.2730969190597534, acc: 0.6153846383094788)
[2024-12-14 02:12:53,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:53,862][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.1067817211151123, acc: 0.44117647409439087)
[2024-12-14 02:12:54,104][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 0.8481627702713013, acc: 0.739130437374115)
[2024-12-14 02:12:54,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:54,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:54,473][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 1.8115813732147217, acc: 0.46875)
[2024-12-14 02:12:54,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:54,816][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 2.0255277156829834, acc: 0.43478259444236755)
[2024-12-14 02:12:54,887][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.4633517265319824, acc: 0.3767123222351074)
[2024-12-14 02:12:54,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:54,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:55,096][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 1.5547541379928589, acc: 0.5714285969734192)
[2024-12-14 02:12:55,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:55,185][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.2974153757095337, acc: 0.7083333134651184)
[2024-12-14 02:12:55,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:55,376][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 1.4591656923294067, acc: 0.5384615659713745)
[2024-12-14 02:12:55,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:55,535][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 1.2371450662612915, acc: 0.5925925970077515)
[2024-12-14 02:12:55,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:55,721][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 2.3350672721862793, acc: 0.3095238208770752)
[2024-12-14 02:12:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:56,195][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.8552, device='cuda:0') eval_epoch_loss=tensor(1.9250, device='cuda:0') eval_epoch_acc=tensor(0.4948, device='cuda:0')
[2024-12-14 02:12:56,196][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:12:56,196][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:12:56,591][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_284_loss_1.9250080585479736/model.pt
[2024-12-14 02:12:56,598][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:12:56,599][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.9250080585479736
[2024-12-14 02:12:56,599][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.4947579503059387
[2024-12-14 02:12:56,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:57,056][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 2.438504695892334, acc: 0.3235294222831726)
                                                                                [2024-12-14 02:12:57,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:57,491][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 2.2128376960754395, acc: 0.2750000059604645)
                                                                                                                                         [2024-12-14 02:12:57,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:57,868][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.226627826690674, acc: 0.3671875)
[2024-12-14 02:12:57,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:58,226][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 2.4415838718414307, acc: 0.335999995470047)
[2024-12-14 02:12:58,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:58,539][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 2.049773931503296, acc: 0.4615384638309479)
[2024-12-14 02:12:58,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:58,916][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 2.47152042388916, acc: 0.3354037404060364)
[2024-12-14 02:12:59,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:59,301][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.4682626724243164, acc: 0.3298968970775604)
                        [2024-12-14 02:12:59,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:12:59,667][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.0274673700332642, acc: 0.6818181872367859)
                                                                               [2024-12-14 02:12:59,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:00,017][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 2.0845584869384766, acc: 0.5)
                                                                                                                                                                                                                                      [2024-12-14 02:13:00,110][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:13:00,348][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.5950403213500977, acc: 0.6206896305084229)
[2024-12-14 02:13:00,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:00,821][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.4450606107711792, acc: 0.6000000238418579)
, step 184/574 completed (loss: 2.466797351837158, acc: 0.3564954698085785)
[2024-12-14 02:13:00,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:00,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:01,171][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.544936180114746, acc: 0.319884717464447)
[2024-12-14 02:13:01,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:01,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:01,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:01,660][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.5187106132507324, acc: 0.359375)
[2024-12-14 02:13:01,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:02,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:02,189][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.3263399600982666, acc: 0.3583489656448364)
[2024-12-14 02:13:02,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:02,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:02,599][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.3078393936157227, acc: 0.3772242069244385)
[2024-12-14 02:13:02,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:02,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:02,956][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 2.630134344100952, acc: 0.47999998927116394)
[2024-12-14 02:13:03,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:03,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:03,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:03,504][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.40786075592041, acc: 0.40697672963142395)
[2024-12-14 02:13:03,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:03,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:03,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:04,297][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.0928614139556885, acc: 0.523809552192688)
[2024-12-14 02:13:04,299][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:13:04,557][slam_llm.models.slam_model][INFO] - modality encoder
                                               [2024-12-14 02:13:04,749][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:13:05,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:05,211][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.216259479522705, acc: 0.4015151560306549)
[2024-12-14 02:13:05,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:05,551][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:13:05,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:05,952][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 1.983786940574646, acc: 0.5411764979362488)
[2024-12-14 02:13:06,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:06,270][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:13:06,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:06,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:07,023][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 1.879652976989746, acc: 0.48765432834625244)
[2024-12-14 02:13:07,292][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:13:07,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:07,537][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 2.401881217956543, acc: 0.3877550959587097)
[2024-12-14 02:13:07,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:07,905][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.3115871250629425, acc: 0.9583333134651184)
[2024-12-14 02:13:08,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:08,252][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 1.488988995552063, acc: 0.625)
[2024-12-14 02:13:08,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:08,608][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 1.0436114072799683, acc: 0.7096773982048035)
                                   [2024-12-14 02:13:08,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:08,966][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 1.4697719812393188, acc: 0.5483871102333069)
                                                                               [2024-12-14 02:13:09,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:09,339][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 1.4911216497421265, acc: 0.5671641826629639)
                                                                                [2024-12-14 02:13:09,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:09,720][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 1.5609358549118042, acc: 0.5769230723381042)
                                                                                                                                                              [2024-12-14 02:13:09,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:10,063][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 2.157163381576538, acc: 0.42222222685813904)
[2024-12-14 02:13:10,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:10,360][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 1.72343111038208, acc: 0.4838709533214569)
  [2024-12-14 02:13:10,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:10,732][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 1.1368969678878784, acc: 0.7200000286102295)
                                                                                                                                                                                                                                             [2024-12-14 02:13:10,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:11,035][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.5262227058410645, acc: 0.37037035822868347)
[2024-12-14 02:13:11,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:11,426][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.273130416870117, acc: 0.11428571492433548)
                                                                             [2024-12-14 02:13:11,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:11,778][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 2.5251379013061523, acc: 0.20512820780277252)
                                                                              [2024-12-14 02:13:11,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:12,141][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 2.510897397994995, acc: 0.4146341383457184)
[2024-12-14 02:13:12,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:12,485][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.23435378074646, acc: 0.3684210479259491)
[2024-12-14 02:13:12,559][slam_llm.models.slam_model][INFO] - modality encoder
2/10, step 207/574 completed (loss: 2.1896002292633057, acc: 0.4181034564971924)
[2024-12-14 02:13:12,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:12,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:12,894][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.1056108474731445, acc: 0.4528985619544983)
[2024-12-14 02:13:12,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:13,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:13,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:13,323][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.2953710556030273, acc: 0.3501945436000824)
[2024-12-14 02:13:13,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:13,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:13,676][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.4474310874938965, acc: 0.3804347813129425)
[2024-12-14 02:13:13,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:13,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:14,010][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.4939247369766235, acc: 0.695652186870575)
[2024-12-14 02:13:14,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:14,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:14,291][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 1.9103144407272339, acc: 0.5357142686843872)
[2024-12-14 02:13:14,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:14,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:14,604][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.6149117946624756, acc: 0.4893617033958435)
[2024-12-14 02:13:14,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:14,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:15,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:15,281][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 1.9335694313049316, acc: 0.45384615659713745)
[2024-12-14 02:13:15,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:15,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:15,605][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 1.7658084630966187, acc: 0.5)
[2024-12-14 02:13:15,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:15,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:15,921][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 1.8387563228607178, acc: 0.4883720874786377)
[2024-12-14 02:13:16,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:16,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:16,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:16,454][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 1.8813613653182983, acc: 0.5135135054588318)
[2024-12-14 02:13:16,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:16,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:16,865][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 1.7725228071212769, acc: 0.5444444417953491)
[2024-12-14 02:13:16,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:17,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:17,212][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 0.9470149278640747, acc: 0.6666666865348816)
[2024-12-14 02:13:17,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:17,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:17,577][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.5352122783660889, acc: 0.8518518805503845)
[2024-12-14 02:13:17,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:18,013][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 2.163939952850342, acc: 0.4871794879436493)
                                                                               [2024-12-14 02:13:18,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:18,338][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 2.549377202987671, acc: 0.3614457845687866)
[2024-12-14 02:13:18,422][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                 [2024-12-14 02:13:18,677][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 1.8811264038085938, acc: 0.5471698045730591)
[2024-12-14 02:13:18,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:19,015][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 2.078542470932007, acc: 0.4430379867553711)
[2024-12-14 02:13:19,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:19,380][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 1.9717741012573242, acc: 0.5098039507865906)
[2024-12-14 02:13:19,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:19,753][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.5152111053466797, acc: 0.28358209133148193)
[2024-12-14 02:13:19,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:20,144][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 1.1431620121002197, acc: 0.699999988079071)
  [2024-12-14 02:13:20,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:20,486][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 1.5970176458358765, acc: 0.5600000023841858)
                                                                                                                                                              [2024-12-14 02:13:20,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:20,897][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.5353310108184814, acc: 0.6111111044883728)
                                                                                [2024-12-14 02:13:20,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:21,263][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.9972286224365234, acc: 0.4883720874786377)
                                                                                                                                                             [2024-12-14 02:13:21,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:21,648][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 1.929612398147583, acc: 0.4615384638309479)
[2024-12-14 02:13:21,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:22,022][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 2.0141351222991943, acc: 0.46666666865348816)
                                                                           [2024-12-14 02:13:22,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:22,362][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.9922040700912476, acc: 0.6521739363670349)
[2024-12-14 02:13:22,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:22,730][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.4956140518188477, acc: 0.42307692766189575)
                                                              [2024-12-14 02:13:22,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:23,137][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.411012887954712, acc: 0.37362638115882874)
                                                                              [2024-12-14 02:13:23,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:23,634][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 1.9785325527191162, acc: 0.5043478012084961)
                                                                                                                                                              [2024-12-14 02:13:23,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:23,965][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 2.0798709392547607, acc: 0.41304346919059753)
                                                                              [2024-12-14 02:13:24,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:24,347][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 2.1619575023651123, acc: 0.4285714328289032)
                                                                               [2024-12-14 02:13:24,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:24,693][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.4677914083003998, acc: 0.9166666865348816)
                                                                               [2024-12-14 02:13:24,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:25,035][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 1.0899581909179688, acc: 0.6538461446762085)
                                                                                [2024-12-14 02:13:25,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:25,333][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.821189284324646, acc: 0.5609756112098694)
                                                                                [2024-12-14 02:13:25,443][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:13:25,694][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 1.936042308807373, acc: 0.5333333611488342)
[2024-12-14 02:13:25,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:26,054][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 2.0277259349823, acc: 0.43421053886413574)
[2024-12-14 02:13:26,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:26,450][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 2.038723945617676, acc: 0.46341463923454285)
                       [2024-12-14 02:13:26,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:26,792][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 1.998351812362671, acc: 0.42424243688583374)
[2024-12-14 02:13:26,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:27,160][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.8164315819740295, acc: 0.7916666865348816)
[2024-12-14 02:13:27,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:27,522][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.5062342286109924, acc: 0.8695651888847351)
                                                                                                                                                             [2024-12-14 02:13:27,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:27,849][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.8012841939926147, acc: 0.75)
[2024-12-14 02:13:27,928][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:13:28,180][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.3669205904006958, acc: 0.53125)
oint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_141_loss_2.0735158920288086/model.pt
[2024-12-14 02:13:28,083][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:13:28,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:28,215][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.6508893966674805, acc: 0.5483871102333069)
[2024-12-14 02:13:28,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:28,498][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.0884146690368652, acc: 0.5)
[2024-12-14 02:13:28,524][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.9908478260040283, acc: 0.22580644488334656)
[2024-12-14 02:13:28,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:28,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:28,849][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.5378092527389526, acc: 0.5945945978164673)
[2024-12-14 02:13:28,902][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 2.476564884185791, acc: 0.37837839126586914)
[2024-12-14 02:13:28,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:29,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:29,115][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.6298121213912964, acc: 0.45945945382118225)
[2024-12-14 02:13:29,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:29,410][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.5057106018066406, acc: 0.5675675868988037)
[2024-12-14 02:13:29,458][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.3629512786865234, acc: 0.359649121761322)
[2024-12-14 02:13:29,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:29,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:29,778][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 2.019747495651245, acc: 0.44117647409439087)
[2024-12-14 02:13:29,804][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.9637963771820068, acc: 0.4776119291782379)
[2024-12-14 02:13:29,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:29,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:30,125][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 0.7786681652069092, acc: 0.8048780560493469)
[2024-12-14 02:13:30,191][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.4641222953796387, acc: 0.37755101919174194)
[2024-12-14 02:13:30,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:30,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:30,482][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 0.5167904496192932, acc: 0.8399999737739563)
[2024-12-14 02:13:30,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:30,642][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.2268154621124268, acc: 0.3191489279270172)
[2024-12-14 02:13:30,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:30,862][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.514053463935852, acc: 0.9200000166893005)
[2024-12-14 02:13:30,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:31,044][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.0060646533966064, acc: 0.44285714626312256)
[2024-12-14 02:13:31,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:31,209][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 0.6333723664283752, acc: 0.8709677457809448)
[2024-12-14 02:13:31,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:31,383][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 2.4343676567077637, acc: 0.5)
[2024-12-14 02:13:31,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:31,594][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 1.9364289045333862, acc: 0.5263158082962036)
[2024-12-14 02:13:31,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:31,772][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.5938117504119873, acc: 0.5652173757553101)
[2024-12-14 02:13:31,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:31,924][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 1.9667166471481323, acc: 0.5142857432365417)
[2024-12-14 02:13:32,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:32,114][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.184258460998535, acc: 0.27586206793785095)
[2024-12-14 02:13:32,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:32,335][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.6625468730926514, acc: 0.5657894611358643)
[2024-12-14 02:13:32,434][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.1874051094055176, acc: 0.41304346919059753)
[2024-12-14 02:13:32,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:32,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:32,773][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.149496555328369, acc: 0.4067796468734741)
[2024-12-14 02:13:32,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:32,896][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 2.008046865463257, acc: 0.4150943458080292)
[2024-12-14 02:13:33,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:33,107][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.4821512699127197, acc: 0.3684210479259491)
[2024-12-14 02:13:33,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:33,475][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 2.036071538925171, acc: 0.4583333432674408)
[2024-12-14 02:13:33,480][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.039146900177002, acc: 0.47297295928001404)
[2024-12-14 02:13:33,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:33,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:33,849][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 1.435770034790039, acc: 0.6388888955116272)
[2024-12-14 02:13:33,857][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.9220945835113525, acc: 0.5714285969734192)
[2024-12-14 02:13:33,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:33,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:34,190][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.5011210441589355, acc: 0.6086956262588501)
[2024-12-14 02:13:34,227][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 2.1368327140808105, acc: 0.5161290168762207)
[2024-12-14 02:13:34,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:34,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:34,529][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 2.2013657093048096, acc: 0.31578946113586426)
[2024-12-14 02:13:34,612][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 2.958179235458374, acc: 0.30666667222976685)
[2024-12-14 02:13:34,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:34,992][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 2.489638566970825, acc: 0.3541666567325592)
[2024-12-14 02:13:35,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:35,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:35,815][rootning Epoch: 2/10, step 384/574 completed (loss: 0.8112331628799438, acc: 0.8214285969734192)
[2024-12-14 02:13:35,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:35,869][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 1.411096453666687, acc: 0.65625)
[2024-12-14 02:13:35,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:36,227][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 1.3934447765350342, acc: 0.6111111044883728)
[2024-12-14 02:13:36,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:36,572][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 1.339202642440796, acc: 0.6578947305679321)
                                                                                                                            [2024-12-14 02:13:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:36,926][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.8354007601737976, acc: 0.6818181872367859)
                                                                                                                                                                                                                      [2024-12-14 02:13:37,024][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:13:37,257][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 1.3927881717681885, acc: 0.550000011920929)
                                                                                [2024-12-14 02:13:37,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:37,557][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.3966070413589478, acc: 0.6190476417541504)
[2024-12-14 02:13:37,657][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:13:37,943][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 2.638124465942383, acc: 0.40740740299224854)
                                                                                                                                                  [2024-12-14 02:13:38,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:38,349][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 2.415107488632202, acc: 0.3980582654476166)
                                                                                                                                                                                                                         [2024-12-14 02:13:38,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:38,876][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 1.9375706911087036, acc: 0.5073529481887817)
                                                                                                                                                                                                         [2024-12-14 02:13:38,975][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:13:39,258][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 2.31791090965271, acc: 0.4466666579246521)
                                                                  [2024-12-14 02:13:39,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:39,672][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 2.1886816024780273, acc: 0.4444444477558136)
2024-12-14 02:13:39,428][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 1.1178324222564697, acc: 0.6666666865348816)
[2024-12-14 02:13:39,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:39,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:39,753][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.6528440713882446, acc: 0.5510203838348389)
[2024-12-14 02:13:39,758][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 1.6327956914901733, acc: 0.6206896305084229)
[2024-12-14 02:13:39,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:39,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:40,073][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 1.4961655139923096, acc: 0.6399999856948853)
[2024-12-14 02:13:40,073][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 2.0027730464935303, acc: 0.47999998927116394)
[2024-12-14 02:13:40,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:40,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:40,381][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 2.1965081691741943, acc: 0.40425533056259155)
[2024-12-14 02:13:40,449][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.7715389728546143, acc: 0.4722222089767456)
[2024-12-14 02:13:40,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:40,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:40,714][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.8942294120788574, acc: 0.5)
[2024-12-14 02:13:40,808][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.0662174224853516, acc: 0.45098039507865906)
[2024-12-14 02:13:40,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:41,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:41,100][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 1.7156420946121216, acc: 0.5454545617103577)
[2024-12-14 02:13:41,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:41,518][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.3314082622528076, acc: 0.3855421543121338)
[2024-12-14 02:13:41,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:41,836][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.461542844772339, acc: 0.3904109597206116)
[2024-12-14 02:13:41,902][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 2.112901449203491, acc: 0.46296295523643494)
[2024-12-14 02:13:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:41,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:42,205][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.2966891527175903, acc: 0.7083333134651184)
[2024-12-14 02:13:42,223][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 2.5501790046691895, acc: 0.28947368264198303)
[2024-12-14 02:13:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:42,585][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 1.2614386081695557, acc: 0.5925925970077515)
[2024-12-14 02:13:42,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:42,915][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.7442471981048584, acc: 0.5357142686843872)
[2024-12-14 02:13:42,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:43,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:43,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:43,457][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 1.9577467441558838, acc: 0.5044247508049011)
[2024-12-14 02:13:43,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:43,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:43,800][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 1.9740912914276123, acc: 0.4637681245803833)
[2024-12-14 02:13:43,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:44,169][root]llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:44,288][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 0.9818298816680908, acc: 0.7037037014961243)
[2024-12-14 02:13:44,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:44,665][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 1.125468134880066, acc: 0.7307692170143127)
[2024-12-14 02:13:44,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:45,013][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.4582325220108032, acc: 0.6379310488700867)
[2024-12-14 02:13:45,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:45,339][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 1.0750848054885864, acc: 0.75)
[2024-12-14 02:13:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:45,733][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 1.101821780204773, acc: 0.7666666507720947)
[2024-12-14 02:13:45,853][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:13:46,113][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.2043975591659546, acc: 0.6363636255264282)
                                                                               [2024-12-14 02:13:46,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:46,460][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 0.9980191588401794, acc: 0.6363636255264282)
[2024-12-14 02:13:46,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:46,803][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 2.2297301292419434, acc: 0.4901960790157318)
[2024-12-14 02:13:46,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:47,116][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 2.1327240467071533, acc: 0.5384615659713745)
       [2024-12-14 02:13:47,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:47,433][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 1.90536630153656, acc: 0.5555555820465088)
  [2024-12-14 02:13:47,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:47,802][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 1.8006614446640015, acc: 0.574999988079071)
                                                                                                                                                              [2024-12-14 02:13:47,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:48,156][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 2.593796730041504, acc: 0.4000000059604645)
                                                                                [2024-12-14 02:13:48,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:48,545][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.5562891960144043, acc: 0.8095238208770752)
 [2024-12-14 02:13:48,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:48,913][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.5070818662643433, acc: 0.6333333253860474)
                                                                                [2024-12-14 02:13:49,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:49,286][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.4210468530654907, acc: 0.5625)
                                                                                           [2024-12-14 02:13:49,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:49,649][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 1.9043469429016113, acc: 0.4722222089767456)
[2024-12-14 02:13:49,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:49,939][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 1.5291649103164673, acc: 0.5925925970077515)
                      [2024-12-14 02:13:50,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:50,291][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 1.4272743463516235, acc: 0.6060606241226196)
[2024-12-14 02:13:50,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:50,563][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 1.3121496438980103, acc: 0.6521739363670349)
                                                                                                                                                                                                                                            [2024-12-14 02:13:51,306][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:13:51,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:51,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:52,237][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:13:52,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:52,961][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:13:53,311][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:13:53,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:54,146][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:13:54,574][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:13:54,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:55,222][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:13:55,580][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:13:55,920][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:13:56,302][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:13:56,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:56,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:56,776][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 2.40319561958313, acc: 0.37288135290145874)
[2024-12-14 02:13:56,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:56,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:57,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:57,155][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 2.4369349479675293, acc: 0.4029850661754608)
[2024-12-14 02:13:57,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:57,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:57,521][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.3636653423309326, acc: 0.35922330617904663)
[2024-12-14 02:13:57,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:57,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:57,900][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 2.157702684402466, acc: 0.460317462682724)
[2024-12-14 02:13:57,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:58,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:58,197][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 2.129044532775879, acc: 0.4395604431629181)
[2024-12-14 02:13:58,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:58,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:58,564][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.254852771759033, acc: 0.3901345431804657)
[2024-12-14 02:13:58,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:58,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:58,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:58,976][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.1461238861083984, acc: 0.4409448802471161)
[2024-12-14 02:13:59,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:59,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:59,320][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 2.203310489654541, acc: 0.42241379618644714)
[2024-12-14 02:13:59,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:59,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:59,724][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.11733341217041, acc: 0.4420289993286133)
[2024-12-14 02:13:59,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:13:59,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:00,133][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.2901554107666016, acc: 0.3463034927845001)
[2024-12-14 02:14:00,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:00,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:00,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:00,527][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.425189733505249, acc: 0.3804347813129425)
[2024-12-14 02:14:00,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:00,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:00,889][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.4280154705047607, acc: 0.695652186870575)
[2024-12-14 02:14:00,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:01,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:01,245][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 1.9422475099563599, acc: 0.5)
[2024-12-14 02:14:01,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:01,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:01,625][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.56308114528656, acc: 0.5106382966041565)
[2024-12-14 02:14:01,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:01,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:02,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:02,300][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 1.8951072692871094, acc: 0.4769230782985687)
[2024-12-14 02:14:02,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:02,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:02,704][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 1.7549580335617065, acc: 0.5135135054588318)
[2024-12-14 02:14:02,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:03,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:03,069][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 1.7995784282684326, acc: 0.5348837375640869)
[2024-12-14 02:14:03,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:03,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:03,614][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 1.872199535369873, acc: 0.5405405163764954)
[2024-12-14 02:14:03,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:03,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:04,040][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 1.7490789890289307, acc: 0.5333333611488342)
[2024-12-14 02:14:04,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:04,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:04,412][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 0.956394612789154, acc: 0.6969696879386902)
[2024-12-14 02:14:04,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:04,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:04,758][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.5167629718780518, acc: 0.8518518805503845)
[2024-12-14 02:14:04,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:04,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:05,093][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 1.01876699924469, acc: 0.6399999856948853)
[2024-12-14 02:14:05,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:05,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:05,485][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 2.1248342990875244, acc: 0.4038461446762085)
[2024-12-14 02:14:05,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:05,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:05,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:06,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:06,273][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 1.7876790761947632, acc: 0.54347825050354)
[2024-12-14 02:14:06,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:06,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:06,827][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 2.047626256942749, acc: 0.4261363744735718)
[2024-12-14 02:14:06,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:07,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:07,293][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 2.25343656539917, acc: 0.39361703395843506)
[2024-12-14 02:14:07,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:07,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:07,689][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 1.7965151071548462, acc: 0.43396225571632385)
[2024-12-14 02:14:07,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:07,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:08,086][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 2.115968704223633, acc: 0.4833333194255829)
[2024-12-14 02:14:08,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:08,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:08,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:08,507][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.4372949600219727, acc: 0.6511628031730652)
[2024-12-14 02:14:08,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:08,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:08,843][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 1.3513083457946777, acc: 0.6333333253860474)
[2024-12-14 02:14:08,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:09,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:09,256][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 2.3859238624572754, acc: 0.38947367668151855)
[2024-12-14 02:14:09,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:09,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:09,621][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 1.8387218713760376, acc: 0.5222222208976746)
[2024-12-14 02:14:09,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:09,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:10,038][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 1.671187162399292, acc: 0.550000011920929)
[2024-12-14 02:14:10,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:10,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:10,533][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 1.8126474618911743, acc: 0.5504587292671204)
[2024-12-14 02:14:10,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:10,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:11,001][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 1.7149218320846558, acc: 0.5307692289352417)
[2024-12-14 02:14:11,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:11,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:11,316][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 1.6725565195083618, acc: 0.5263158082962036)
[2024-12-14 02:14:11,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:11,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:11,636][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.6375435590744019, acc: 0.5833333134651184)
[2024-12-14 02:14:11,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:11,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:11,997][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 3.0399575233459473, acc: 0.1818181872367859)
[2024-12-14 02:14:12,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:12,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:12,360][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.7931808233261108, acc: 0.37037035822868347)
[2024-12-14 02:14:12,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:12,737][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.525624394416809, acc: 0.6571428775787354)
[2024-12-14 02:14:13,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:12,889][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7727, device='cuda:0') eval_epoch_loss=tensor(1.9129, device='cuda:0') eval_epoch_acc=tensor(0.4998, device='cuda:0')
[2024-12-14 02:14:12,890][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:14:12,891][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:14:13,091][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.561201572418213, acc: 0.5909090638160706)
[2024-12-14 02:14:13,118][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_284_loss_1.9128977060317993/model.pt
[2024-12-14 02:14:13,122][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:14:13,123][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.9128977060317993
[2024-12-14 02:14:13,123][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.49977216124534607
[2024-12-14 02:14:13,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:13,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:13,378][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 1.9026007652282715, acc: 0.4318181872367859)
[2024-12-14 02:14:13,520][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 2.4621503353118896, acc: 0.3235294222831726)
[2024-12-14 02:14:13,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:13,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:13,888][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 2.1955714225769043, acc: 0.3499999940395355)
[2024-12-14 02:14:13,954][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.06996750831604, acc: 0.4032258093357086)
[2024-12-14 02:14:13,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:14,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:14,294][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.229276657104492, acc: 0.359375)
[2024-12-14 02:14:14,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:14,493][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 1.6628223657608032, acc: 0.5681818127632141)
[2024-12-14 02:14:14,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:14,657][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 2.452991247177124, acc: 0.328000009059906)
[2024-12-14 02:14:14,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:14,839][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 0.7634797692298889, acc: 0.8095238208770752)
[2024-12-14 02:14:14,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:15,064][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 2.0426225662231445, acc: 0.48351648449897766)
[2024-12-14 02:14:15,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:15,190][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.4038467407226562, acc: 0.692307710647583)
[2024-12-14 02:14:15,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:15,396][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 2.458096981048584, acc: 0.3229813575744629)
[2024-12-14 02:14:15,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:15,532][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.6373080015182495, acc: 0.5806451439857483)
[2024-12-14 02:14:15,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:15,743][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.4558300971984863, acc: 0.3195876181125641)
[2024-12-14 02:14:15,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:15,882][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.1008074283599854, acc: 0.44999998807907104)
[2024-12-14 02:14:16,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:16,107][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.0061092376708984, acc: 0.6818181872367859)
[2024-12-14 02:14:16,198][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.4927390813827515, acc: 0.5675675868988037)
[2024-12-14 02:14:16,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:16,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:16,425][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 2.068791627883911, acc: 0.523809552192688)
[2024-12-14 02:14:16,519][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.6290041208267212, acc: 0.45945945382118225)
[2024-12-14 02:14:16,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:16,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:16,796][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.5318511724472046, acc: 0.5675675868988037)
[2024-12-14 02:14:16,826][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.5571966171264648, acc: 0.6379310488700867)
[2024-12-14 02:14:16,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:16,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:17,132][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 2.057938814163208, acc: 0.4264705777168274)
[2024-12-14 02:14:17,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:17,289][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.4569082260131836, acc: 0.6181818246841431)
[2024-12-14 02:14:17,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:17,492][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 0.8439843058586121, acc: 0.7560975551605225)
[2024-12-14 02:14:17,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:17,823][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 0.5335230827331543, acc: 0.8399999737739563)
[2024-12-14 02:14:17,840][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 1.9381606578826904, acc: 0.5103092789649963)
[2024-12-14 02:14:17,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:17,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:18,144][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 2.2512173652648926, acc: 0.4137931168079376)
[2024-12-14 02:14:18,204][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.5356609225273132, acc: 0.9200000166893005)
[2024-12-14 02:14:18,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:18,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:18,505][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 1.994720220565796, acc: 0.4444444477558136)
[2024-12-14 02:14:18,525][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 0.6886969208717346, acc: 0.8709677457809448)
[2024-12-14 02:14:18,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:18,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:18,842][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 1.9317545890808105, acc: 0.5438596606254578)
[2024-12-14 02:14:18,846][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 1.9884605407714844, acc: 0.4736842215061188)
[2024-12-14 02:14:18,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:18,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:19,160][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 1.9960192441940308, acc: 0.5142857432365417)
[2024-12-14 02:14:19,286][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:14:19,612][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                     [2024-12-14 02:14:19,961][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:14:20,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:20,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:21,017][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:14:21,722][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.0066, device='cuda:0') eval_epoch_loss=tensor(2.0803, device='cuda:0') eval_epoch_acc=tensor(0.4375, device='cuda:0')
[2024-12-14 02:14:21,723][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:14:21,723][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:14:21,927][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_427_loss_2.080264091491699/model.pt
[2024-12-14 02:14:21,930][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:14:22,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:22,342][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 1.4696147441864014, acc: 0.6486486196517944)
                                                                                                                                   [2024-12-14 02:14:22,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:22,725][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 1.03340744972229, acc: 0.7777777910232544)
[2024-12-14 02:14:22,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:23,079][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 1.5864779949188232, acc: 0.43478259444236755)
2024-12-14 02:14:22,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:23,112][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 1.7815226316452026, acc: 0.5301204919815063)
[2024-12-14 02:14:23,121][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 2.183131217956543, acc: 0.3820224702358246)
[2024-12-14 02:14:23,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:23,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:23,484][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 2.326368570327759, acc: 0.3589743673801422)
[2024-12-14 02:14:23,492][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 2.2670581340789795, acc: 0.45945945382118225)
[2024-12-14 02:14:23,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:23,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:23,872][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 2.413606882095337, acc: 0.36734694242477417)
[2024-12-14 02:14:23,960][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 1.449047565460205, acc: 0.5517241358757019)
[2024-12-14 02:14:23,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:24,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:24,242][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.3216407001018524, acc: 0.9166666865348816)
[2024-12-14 02:14:24,311][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 1.4600474834442139, acc: 0.6818181872367859)
[2024-12-14 02:14:24,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:24,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:24,580][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 1.45687735080719, acc: 0.5833333134651184)
[2024-12-14 02:14:24,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:24,685][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 1.2609081268310547, acc: 0.5454545617103577)
[2024-12-14 02:14:24,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:24,890][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 0.9732555747032166, acc: 0.7096773982048035)
[2024-12-14 02:14:25,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:25,071][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 1.1258840560913086, acc: 0.6875)
[2024-12-14 02:14:25,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:25,281][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 1.4307060241699219, acc: 0.5483871102333069)
[2024-12-14 02:14:25,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:25,451][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 1.3118482828140259, acc: 0.6333333253860474)
[2024-12-14 02:14:25,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:25,671][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 1.5027745962142944, acc: 0.5671641826629639)
[2024-12-14 02:14:25,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:25,894][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 2.1686012744903564, acc: 0.4000000059604645)
[2024-12-14 02:14:26,012][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 1.5508078336715698, acc: 0.5769230723381042)
[2024-12-14 02:14:26,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:26,268][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 1.7883728742599487, acc: 0.5)
[2024-12-14 02:14:26,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:26,373][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 2.1794722080230713, acc: 0.42222222685813904)
[2024-12-14 02:14:26,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:26,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:26,991][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 2.2235918045043945, acc: 0.4545454680919647)
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:14:27,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:27,675][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.6836392879486084, acc: 0.30399999022483826)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:14:27,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:28,097][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.3693318367004395, acc: 0.3629032373428345)
                                                                                                                                                                                                                       [2024-12-14 02:14:28,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:28,779][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 2.2804417610168457, acc: 0.3781094551086426)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:14:28,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:29,152][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 2.1177029609680176, acc: 0.4150943458080292)
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:14:29,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:29,573][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.3787130117416382, acc: 0.6590909361839294)
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:14:29,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:29,913][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 1.7261712551116943, acc: 0.5652173757553101)
[2024-12-14 02:14:30,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:30,310][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.8879344463348389, acc: 0.4615384638309479)
                                                                     [2024-12-14 02:14:30,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:30,685][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 1.2449920177459717, acc: 0.7857142686843872)
                                                                              [2024-12-14 02:14:30,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:31,023][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 2.1410319805145264, acc: 0.43283581733703613)
[2024-12-14 02:14:31,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:31,433][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 1.8549790382385254, acc: 0.5138888955116272)
                                                                               [2024-12-14 02:14:31,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:31,772][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 2.085885524749756, acc: 0.45652174949645996)
                                                                    [2024-12-14 02:14:31,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:32,146][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 2.2205631732940674, acc: 0.41025641560554504)
                                                                              [2024-12-14 02:14:32,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:32,476][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 2.425987958908081, acc: 0.3684210479259491)
  [2024-12-14 02:14:32,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:32,849][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.8218684196472168, acc: 0.5306122303009033)
                                                                                                                                                              [2024-12-14 02:14:32,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:33,189][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.6294218301773071, acc: 0.5454545617103577)
[2024-12-14 02:14:33,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:33,554][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 2.1601383686065674, acc: 0.3711340129375458)
                                                                                                                                                             [2024-12-14 02:14:33,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:33,880][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.946925401687622, acc: 0.4571428596973419)
 [2024-12-14 02:14:33,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:34,258][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 2.1107492446899414, acc: 0.47093021869659424)
                                                                                                                                                             [2024-12-14 02:14:34,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:34,637][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 2.3927195072174072, acc: 0.3571428656578064)
                                                                              [2024-12-14 02:14:34,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:35,000][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 2.058809995651245, acc: 0.4691357910633087)
                                                                               [2024-12-14 02:14:35,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:35,313][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.7206721305847168, acc: 0.5)
698045730591)
[2024-12-14 02:14:35,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:35,532][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 2.072125196456909, acc: 0.4430379867553711)
[2024-12-14 02:14:35,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:35,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:35,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:35,916][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 1.9696060419082642, acc: 0.47058823704719543)
[2024-12-14 02:14:36,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:36,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:36,254][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.5257155895233154, acc: 0.26865673065185547)
[2024-12-14 02:14:36,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:36,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:36,640][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 1.09006667137146, acc: 0.699999988079071)
[2024-12-14 02:14:36,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:36,982][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 1.5668214559555054, acc: 0.5600000023841858)
[2024-12-14 02:14:37,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:37,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:37,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:37,384][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.5272053480148315, acc: 0.6111111044883728)
[2024-12-14 02:14:37,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:37,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:37,782][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.952168345451355, acc: 0.5116279125213623)
[2024-12-14 02:14:37,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:37,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:38,161][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 1.9566839933395386, acc: 0.43589743971824646)
[2024-12-14 02:14:38,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:38,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:38,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:38,557][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 1.9878053665161133, acc: 0.46666666865348816)
[2024-12-14 02:14:38,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:38,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:38,931][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.9671611189842224, acc: 0.6521739363670349)
[2024-12-14 02:14:39,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:39,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:39,313][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.5386242866516113, acc: 0.4615384638309479)
[2024-12-14 02:14:39,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:39,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:39,674][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.4398715496063232, acc: 0.38461539149284363)
[2024-12-14 02:14:39,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:39,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:40,170][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 1.960598349571228, acc: 0.5043478012084961)
[2024-12-14 02:14:40,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:40,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:40,566][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 2.1018166542053223, acc: 0.43478259444236755)
[2024-12-14 02:14:40,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:40,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:40,952][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 2.106832265853882, acc: 0.44897958636283875)
[2024-12-14 02:14:40,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:41,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:41,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:41,300][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.4648672640323639, acc: 0.9166666865348816)
[2024-12-14 02:14:41,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:41,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:41,691][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 1.0874444246292114, acc: 0.6538461446762085)
[2024-12-14 02:14:41,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:41,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:42,088][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.7731300592422485, acc: 0.5609756112098694)
[2024-12-14 02:14:42,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:42,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:42,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:42,468][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 1.9727458953857422, acc: 0.5111111402511597)
[2024-12-14 02:14:42,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:42,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:42,851][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 2.068972110748291, acc: 0.40789473056793213)
[2024-12-14 02:14:42,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:43,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:43,209][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 2.0464136600494385, acc: 0.5121951103210449)
[2024-12-14 02:14:43,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:43,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:43,548][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 2.0115809440612793, acc: 0.42424243688583374)
[2024-12-14 02:14:43,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:43,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:43,879][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.8574002385139465, acc: 0.7083333134651184)
[2024-12-14 02:14:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:44,195][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.5825821161270142, acc: 0.8260869383811951)
[2024-12-14 02:14:44,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:44,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:44,499][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.8419310450553894, acc: 0.7857142686843872)
[2024-12-14 02:14:44,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:44,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:44,853][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.463369607925415, acc: 0.5625)
[2024-12-14 02:14:44,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:45,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:45,452][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 1.960172176361084, acc: 0.5030303001403809)
[2024-12-14 02:14:45,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:45,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:45,964][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:14:46,302][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.472035527229309, acc: 0.6320754885673523)
[2024-12-14 02:14:46,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:46,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:46,660][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.7903969287872314, acc: 0.5222222208976746)
[2024-12-14 02:14:46,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:46,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:47,028][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 1.776833415031433, acc: 0.5178571343421936)
[2024-12-14 02:14:47,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:47,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:47,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:47,402][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 1.1846166849136353, acc: 0.6857143044471741)
[2024-12-14 02:14:47,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:47,821][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.5023139715194702, acc: 0.9200000166893005)
[2024-12-14 02:14:47,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:48,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:48,205][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.7765466570854187, acc: 0.695652186870575)
[2024-12-14 02:14:48,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:48,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:48,535][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 2.1302406787872314, acc: 0.4375)
[2024-12-14 02:14:48,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:48,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:48,911][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 1.848940134048462, acc: 0.5368421077728271)
[2024-12-14 02:14:49,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:49,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:49,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:49,484][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 1.893587589263916, acc: 0.5269461274147034)
[2024-12-14 02:14:49,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:49,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:49,919][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.801398754119873, acc: 0.5338345766067505)
[2024-12-14 02:14:50,078][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:14:50,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:50,391][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:14:50,762][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:14:51,162][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.854203701019287, acc: 0.48663100600242615)
[2024-12-14 02:14:51,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:51,294][slot][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.3633954524993896, acc: 0.5862069129943848)
[2024-12-14 02:14:51,660][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:14:52,078][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 2.0855042934417725, acc: 0.45045045018196106)
[2024-12-14 02:14:52,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:52,521][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.8141546249389648, acc: 0.5352112650871277)
                                                                                                                                                                                                                              [2024-12-14 02:14:52,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:52,871][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.4753507673740387, acc: 0.8999999761581421)
                                                                                                                                                   [2024-12-14 02:14:52,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:53,220][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.66169273853302, acc: 0.8666666746139526)
                                                                               [2024-12-14 02:14:53,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:53,549][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 1.1447125673294067, acc: 0.692307710647583)
 [2024-12-14 02:14:55,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:56,343][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.090418815612793, acc: 0.44999998807907104)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:14:56,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:57,106][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 2.0371005535125732, acc: 0.523809552192688)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:14:57,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:57,406][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.469326376914978, acc: 0.6071428656578064)
[2024-12-14 02:14:57,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:57,724][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 1.6998423337936401, acc: 0.5833333134651184)
                                                                 [2024-12-14 02:14:57,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:58,413][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.7050265073776245, acc: 0.625)
                                                                                            [2024-12-14 02:14:58,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:58,724][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.46413910388946533, acc: 0.807692289352417)
                                                                                                                                                               [2024-12-14 02:14:58,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:59,031][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 1.5875399112701416, acc: 0.5161290168762207)
[2024-12-14 02:14:59,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:14:59,330][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 2.008453130722046, acc: 0.550000011920929)
[2024-12-14 02:14:59,408][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                 [2024-12-14 02:14:59,698][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 2.05293869972229, acc: 0.5185185074806213)
[2024-12-14 02:14:59,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:00,735][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 2.1332271099090576, acc: 0.45338982343673706)
2024-12-14 02:15:00,057][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7288, device='cuda:0') eval_epoch_loss=tensor(1.9064, device='cuda:0') eval_epoch_acc=tensor(0.4995, device='cuda:0')
[2024-12-14 02:15:00,058][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:15:00,058][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:15:00,158][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 0.996854305267334, acc: 0.774193525314331)
[2024-12-14 02:15:00,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:00,256][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_284_loss_1.9063992500305176/model.pt
[2024-12-14 02:15:00,259][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:15:00,259][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.9063992500305176
[2024-12-14 02:15:00,260][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.49951180815696716
[2024-12-14 02:15:00,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:00,452][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 1.462652564048767, acc: 0.5925925970077515)
[2024-12-14 02:15:00,539][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 2.4604074954986572, acc: 0.3235294222831726)
[2024-12-14 02:15:00,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:00,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:00,793][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 0.8165057897567749, acc: 0.7599999904632568)
[2024-12-14 02:15:00,875][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 2.2026641368865967, acc: 0.32499998807907104)
[2024-12-14 02:15:00,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:00,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:01,126][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 0.9815007448196411, acc: 0.6666666865348816)
[2024-12-14 02:15:01,186][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.212103843688965, acc: 0.375)
[2024-12-14 02:15:01,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:01,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:01,413][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 0.9730391502380371, acc: 0.7037037014961243)
[2024-12-14 02:15:01,508][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 2.4677040576934814, acc: 0.3199999928474426)
[2024-12-14 02:15:01,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:01,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:01,785][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 1.205802321434021, acc: 0.7307692170143127)
[2024-12-14 02:15:01,872][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 2.026806354522705, acc: 0.48351648449897766)
[2024-12-14 02:15:01,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:01,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:02,128][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.4730398654937744, acc: 0.6206896305084229)
[2024-12-14 02:15:02,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:02,219][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 2.478755235671997, acc: 0.3478260934352875)
[2024-12-14 02:15:02,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:02,438][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 1.0482317209243774, acc: 0.75)
[2024-12-14 02:15:02,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:02,562][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.443549394607544, acc: 0.3505154550075531)
[2024-12-14 02:15:02,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:02,758][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 1.1342641115188599, acc: 0.7333333492279053)
[2024-12-14 02:15:02,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:02,900][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 0.9663427472114563, acc: 0.6818181872367859)
[2024-12-14 02:15:02,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:03,109][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.2727044820785522, acc: 0.6363636255264282)
[2024-12-14 02:15:03,166][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 2.0799686908721924, acc: 0.4761904776096344)
[2024-12-14 02:15:03,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:03,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:03,480][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.5700018405914307, acc: 0.6034482717514038)
[2024-12-14 02:15:03,486][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 1.0085821151733398, acc: 0.6363636255264282)
[2024-12-14 02:15:03,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:03,888][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 1.8534749746322632, acc: 0.5762711763381958)
                                                                              [2024-12-14 02:15:03,981][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:15:04,241][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.482333183288574, acc: 0.41860464215278625)
                                                                               [2024-12-14 02:15:04,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:04,606][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 2.2967069149017334, acc: 0.5)
                                                                                                                                                                                                                                       [2024-12-14 02:15:04,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:04,967][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.344928741455078, acc: 0.4150943458080292)
                                                                                                                                                                                                                        [2024-12-14 02:15:05,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:05,315][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.8283753395080566, acc: 0.6590909361839294)
                                                                                                                                                                                                                         [2024-12-14 02:15:05,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:05,662][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.6341594457626343, acc: 0.5600000023841858)
                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:05,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:06,059][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 1.7344005107879639, acc: 0.5)
                                                                                                                                                                                                                           [2024-12-14 02:15:06,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:06,403][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 1.2618874311447144, acc: 0.6363636255264282)
                                                                                                                                                                                                                                                                                          [2024-12-14 02:15:06,514][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:06,790][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 1.9365915060043335, acc: 0.5076923370361328)
[2024-12-14 02:15:06,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:07,121][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 1.8592537641525269, acc: 0.546875)
                                                                                         [2024-12-14 02:15:07,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:07,535][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 1.2845730781555176, acc: 0.6875)
                                                                                                                                                                                                                      [2024-12-14 02:15:07,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:07,899][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 1.8345085382461548, acc: 0.5151515007019043)
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:15:08,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:08,258][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.8121592998504639, acc: 0.8125)
                                                                                           [2024-12-14 02:15:08,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:08,617][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 0.8814073801040649, acc: 0.774193525314331)
                                                                                [2024-12-14 02:15:08,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:08,985][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.6921560168266296, acc: 0.782608687877655)
                                                                                [2024-12-14 02:15:09,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:09,360][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 2.0068631172180176, acc: 0.46666666865348816)
                                                                                                                                                                                                                      [2024-12-14 02:15:09,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:09,708][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 1.5975968837738037, acc: 0.46341463923454285)
                                                                              [2024-12-14 02:15:09,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:10,053][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 1.1383920907974243, acc: 0.6571428775787354)
                                                                               [2024-12-14 02:15:10,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:10,402][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 1.3955273628234863, acc: 0.6315789222717285)
                                                                                                                                                 [2024-12-14 02:15:10,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:10,700][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 1.4898983240127563, acc: 0.6129032373428345)
[2024-12-14 02:15:10,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:11,041][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.7795578241348267, acc: 0.800000011920929)
                                                                               [2024-12-14 02:15:11,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:11,405][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 1.4469811916351318, acc: 0.6363636255264282)
                                                                                                                                                              [2024-12-14 02:15:11,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:11,755][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 1.1535639762878418, acc: 0.625)
[2024-12-14 02:15:11,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:12,111][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 1.3905298709869385, acc: 0.5428571701049805)
            [2024-12-14 02:15:12,204][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:15:12,419][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 2.2817184925079346, acc: 0.38686132431030273)
[2024-12-14 02:15:12,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:12,818][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.8750962018966675, acc: 0.5310344696044922)
                                                                                                                                                             [2024-12-14 02:15:12,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:13,181][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 2.5377275943756104, acc: 0.37142857909202576)
                                                                               [2024-12-14 02:15:13,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:13,539][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 2.4310131072998047, acc: 0.3245033025741577)
                                                                                [2024-12-14 02:15:13,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:13,841][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 1.9204429388046265, acc: 0.504273533821106)
                                                                                 [2024-12-14 02:15:13,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:14,169][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.5361174941062927, acc: 0.8799999952316284)
                                                                                                                                                               [2024-12-14 02:15:14,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:14,485][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 1.3310166597366333, acc: 0.6153846383094788)
[2024-12-14 02:15:14,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:14,817][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.8898912668228149, acc: 0.7692307829856873)
[2024-12-14 02:15:14,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:15,208][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.639683723449707, acc: 0.5384615659713745)
                                                                                                                                                              [2024-12-14 02:15:15,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:15,594][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.764003872871399, acc: 0.4888888895511627)
                                                                                                                                                               [2024-12-14 02:15:15,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:15,944][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.798386573791504, acc: 0.48051947355270386)
[2024-12-14 02:15:16,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:16,306][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 1.7191494703292847, acc: 0.5)
   [2024-12-14 02:15:16,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:16,654][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 1.7403203248977661, acc: 0.5517241358757019)
                                                                                                                                                                                                                                             [2024-12-14 02:15:16,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:17,022][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.8006010055541992, acc: 0.4642857015132904)
                                                                   [2024-12-14 02:15:17,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:17,387][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 1.6236560344696045, acc: 0.5263158082962036)
                                                                               [2024-12-14 02:15:17,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:17,714][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 1.5305272340774536, acc: 0.5555555820465088)
                                                                                [2024-12-14 02:15:17,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:18,099][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 1.9351259469985962, acc: 0.4545454680919647)
                                                                                                                                                                                                                                                                                                         [2024-12-14 02:15:18,821][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:15:19,155][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:15:19,551][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:15:19,893][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:15:20,310][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:15:20,731][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:15:21,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:21,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:21,127][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 2.0578060150146484, acc: 0.4430379867553711)
[2024-12-14 02:15:21,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:21,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:21,508][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 1.9859607219696045, acc: 0.5098039507865906)
[2024-12-14 02:15:21,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:21,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:21,867][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.509045362472534, acc: 0.28358209133148193)
[2024-12-14 02:15:21,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:22,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:22,247][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 1.1065115928649902, acc: 0.699999988079071)
[2024-12-14 02:15:22,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:22,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:22,644][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 1.5698269605636597, acc: 0.5600000023841858)
[2024-12-14 02:15:22,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:23,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:23,052][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.5116910934448242, acc: 0.5833333134651184)
[2024-12-14 02:15:23,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:23,354][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.9374237060546875, acc: 0.5116279125213623)
[2024-12-14 02:15:23,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:23,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:23,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:23,756][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 1.9876288175582886, acc: 0.4615384638309479)
[2024-12-14 02:15:23,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:24,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:24,132][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 1.9398531913757324, acc: 0.46666666865348816)
[2024-12-14 02:15:24,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:24,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:24,418][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.9721826314926147, acc: 0.6521739363670349)
[2024-12-14 02:15:24,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:24,712][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.4014978408813477, acc: 0.4615384638309479)
[2024-12-14 02:15:24,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:24,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:25,034][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.4648516178131104, acc: 0.4065934121608734)
[2024-12-14 02:15:25,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:25,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:25,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:25,546][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 1.9583446979522705, acc: 0.48695650696754456)
[2024-12-14 02:15:25,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:25,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:25,930][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 2.0462327003479004, acc: 0.44565218687057495)
[2024-12-14 02:15:26,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:26,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:26,523][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:15:26,861][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:27,202][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:15:27,595][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:15:27,955][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:15:28,310][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:15:28,696][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:15:29,005][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                          [2024-12-14 02:15:29,371][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:15:29,741][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:15:30,078][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                            [2024-12-14 02:15:30,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:30,765][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:15:31,101][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:15:31,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:31,545][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.4755373001098633, acc: 0.6320754885673523)
[2024-12-14 02:15:31,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:31,885][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.7446727752685547, acc: 0.5222222208976746)
[2024-12-14 02:15:31,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:32,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:32,266][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 1.7295595407485962, acc: 0.5178571343421936)
[2024-12-14 02:15:32,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:32,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:32,615][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 1.2033672332763672, acc: 0.6571428775787354)
[2024-12-14 02:15:32,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:32,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:32,905][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.5008040070533752, acc: 0.8799999952316284)
[2024-12-14 02:15:32,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:33,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:33,225][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.8006846308708191, acc: 0.695652186870575)
[2024-12-14 02:15:33,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:33,548][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 2.134690046310425, acc: 0.3958333432674408)
[2024-12-14 02:15:33,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:33,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:33,860][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 1.8388582468032837, acc: 0.5368421077728271)
[2024-12-14 02:15:33,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:33,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:34,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:34,431][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 1.8847687244415283, acc: 0.538922131061554)
[2024-12-14 02:15:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:34,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:34,885][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.7928916215896606, acc: 0.548872172832489)
[2024-12-14 02:15:34,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:35,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:35,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:35,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:35,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:36,141][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.8269290924072266, acc: 0.49197861552238464)
[2024-12-14 02:15:36,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:36,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:36,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:36,705][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 1.5221596956253052, acc: 0.6126126050949097)
[2024-12-14 02:15:36,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:36,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:37,028][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 0.9552121758460999, acc: 0.75)
[2024-12-14 02:15:37,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:37,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:37,334][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 0.8313102126121521, acc: 0.7857142686843872)
[2024-12-14 02:15:37,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:37,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:37,705][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 1.475208044052124, acc: 0.59375)
[2024-12-14 02:15:37,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:37,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:38,055][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 1.341085433959961, acc: 0.5833333134651184)
[2024-12-14 02:15:38,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:38,370][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 1.3456722497940063, acc: 0.6578947305679321)
[2024-12-14 02:15:38,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:38,625][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.5850, device='cuda:0') eval_epoch_loss=tensor(2.0262, device='cuda:0') eval_epoch_acc=tensor(0.4510, device='cuda:0')
[2024-12-14 02:15:38,626][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:15:38,627][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:15:38,685][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.794689953327179, acc: 0.7272727489471436)
[2024-12-14 02:15:38,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:38,898][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_427_loss_2.0261683464050293/model.pt
[2024-12-14 02:15:38,902][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:15:38,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:39,052][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 1.276596188545227, acc: 0.6000000238418579)
[2024-12-14 02:15:39,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:39,262][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 1.415503978729248, acc: 0.6486486196517944)
[2024-12-14 02:15:39,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:39,414][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.2432941198349, acc: 0.6190476417541504)
[2024-12-14 02:15:39,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:39,644][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 1.0951564311981201, acc: 0.7037037014961243)
[2024-12-14 02:15:39,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:39,805][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 2.654675006866455, acc: 0.3888888955116272)
[2024-12-14 02:15:39,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:39,969][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 1.6053342819213867, acc: 0.52173912525177)
[2024-12-14 02:15:40,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:40,183][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 2.386216402053833, acc: 0.40776699781417847)
[2024-12-14 02:15:40,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:40,328][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.6994158625602722, acc: 0.8888888955116272)
[2024-12-14 02:15:40,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:40,662][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.7272438406944275, acc: 0.8148148059844971)
[2024-12-14 02:15:40,703][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 1.9088068008422852, acc: 0.529411792755127)
[2024-12-14 02:15:40,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:40,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:40,999][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:41,321][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:15:41,767][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:42,087][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:15:42,404][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:15:42,775][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:43,137][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:43,611][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                               [2024-12-14 02:15:44,012][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:15:44,485][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:15:44,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:44,740][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 1.6626982688903809, acc: 0.5757575631141663)
[2024-12-14 02:15:44,769][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.5960748195648193, acc: 0.328000009059906)
[2024-12-14 02:15:44,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:44,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:45,051][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 0.958362340927124, acc: 0.774193525314331)
[2024-12-14 02:15:45,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:45,199][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.371262311935425, acc: 0.3629032373428345)
[2024-12-14 02:15:45,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:45,420][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 1.4567762613296509, acc: 0.6296296119689941)
[2024-12-14 02:15:45,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:45,753][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 0.8116392493247986, acc: 0.7599999904632568)
[2024-12-14 02:15:45,850][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 2.2851924896240234, acc: 0.3980099558830261)
[2024-12-14 02:15:45,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:45,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:46,121][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 0.9098100662231445, acc: 0.75)
[2024-12-14 02:15:46,216][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 2.1110823154449463, acc: 0.4150943458080292)
[2024-12-14 02:15:46,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:46,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:46,494][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 0.9951399564743042, acc: 0.7407407164573669)
[2024-12-14 02:15:46,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:46,645][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.279099941253662, acc: 0.6363636255264282)
[2024-12-14 02:15:46,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:46,869][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 1.0687530040740967, acc: 0.692307710647583)
[2024-12-14 02:15:46,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:47,011][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 1.9079864025115967, acc: 0.5652173757553101)
[2024-12-14 02:15:47,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:47,214][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.4474714994430542, acc: 0.6724137663841248)
[2024-12-14 02:15:47,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:47,352][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.8341419696807861, acc: 0.5)
[2024-12-14 02:15:47,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:47,585][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 1.120012640953064, acc: 0.6785714030265808)
[2024-12-14 02:15:47,631][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 1.191219449043274, acc: 0.75)
[2024-12-14 02:15:47,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,786][slam_llm.models.slam_model][INFO] - modality encoder
448394775, acc: 0.41791045665740967)
[2024-12-14 02:15:48,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,304][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.1935521364212036, acc: 0.6969696879386902)
[2024-12-14 02:15:48,328][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 1.8793184757232666, acc: 0.5138888955116272)
[2024-12-14 02:15:48,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,615][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 0.9451538324356079, acc: 0.6363636255264282)
[2024-12-14 02:15:48,688][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 2.1217126846313477, acc: 0.42391303181648254)
[2024-12-14 02:15:48,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:48,996][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 2.145031690597534, acc: 0.4901960790157318)
[2024-12-14 02:15:49,066][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 2.255962371826172, acc: 0.38461539149284363)
[2024-12-14 02:15:49,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:49,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:49,357][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 2.0066308975219727, acc: 0.6153846383094788)
[2024-12-14 02:15:49,431][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 2.408332109451294, acc: 0.3947368562221527)
[2024-12-14 02:15:49,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:49,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:49,740][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 1.823038101196289, acc: 0.5555555820465088)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:15:49,769][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.8754063844680786, acc: 0.5510203838348389)
[2024-12-14 02:15:49,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:49,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:50,111][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 1.74591863155365, acc: 0.6000000238418579)
[2024-12-14 02:15:50,123][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.5789858102798462, acc: 0.5757575631141663)
[2024-12-14 02:15:50,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:50,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:50,464][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 2.4702563285827637, acc: 0.44999998807907104)
[2024-12-14 02:15:50,491][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 2.158277988433838, acc: 0.41237112879753113)
[2024-12-14 02:15:50,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:50,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:50,804][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.5295752286911011, acc: 0.8095238208770752)
[2024-12-14 02:15:50,880][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.9837803840637207, acc: 0.4285714328289032)
[2024-12-14 02:15:50,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:50,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:51,122][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.4518662691116333, acc: 0.6333333253860474)
[2024-12-14 02:15:51,357][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=6.1626, train_epoch_loss=1.8185, epoch time 359.50010829791427s
[2024-12-14 02:15:51,357][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-14 02:15:51,357][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:15:51,357][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-14 02:15:51,357][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-12-14 02:15:51,358][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:15:51,885][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:15:52,193][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.5060534477233887, acc: 0.5185185074806213)
                                                                                 [2024-12-14 02:15:52,292][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:15:52,565][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 2.252093553543091, acc: 0.3199999928474426)
                                                                      [2024-12-14 02:15:52,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:52,877][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 2.622060537338257, acc: 0.3243243098258972)
[2024-12-14 02:15:52,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:53,204][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 2.1504862308502197, acc: 0.3684210479259491)
    [2024-12-14 02:15:53,304][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:15:53,565][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 2.078934669494629, acc: 0.45945945382118225)
[2024-12-14 02:15:53,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:53,955][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 1.9873011112213135, acc: 0.3928571343421936)
                                                                                                                                                                                                                                                [2024-12-14 02:15:54,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:54,343][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 2.2945966720581055, acc: 0.40816327929496765)
[2024-12-14 02:15:54,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:54,735][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 1.5820503234863281, acc: 0.5)
[2024-12-14 02:15:54,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:55,092][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.3804616928100586, acc: 0.8636363744735718)
                                           [2024-12-14 02:15:55,170][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:15:55,414][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.6695111989974976, acc: 0.807692289352417)
[2024-12-14 02:15:55,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:55,779][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 1.0102934837341309, acc: 0.7777777910232544)
                        [2024-12-14 02:15:55,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:56,159][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 1.7447861433029175, acc: 0.5641025900840759)

[2024-12-14 02:15:55,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:56,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:56,258][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 2.2856881618499756, acc: 0.37254902720451355)
[2024-12-14 02:15:56,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:56,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:56,626][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 2.3533883094787598, acc: 0.375545859336853)
[2024-12-14 02:15:56,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:56,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:57,006][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 2.2172303199768066, acc: 0.3958333432674408)
[2024-12-14 02:15:57,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:57,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:57,408][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 2.24253249168396, acc: 0.3680981695652008)
[2024-12-14 02:15:57,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:57,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:57,813][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 2.264874219894409, acc: 0.3741007149219513)
[2024-12-14 02:15:57,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:57,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:58,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:58,222][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 2.2668650150299072, acc: 0.42211055755615234)
[2024-12-14 02:15:58,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:58,566][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.4012750387191772, acc: 0.5833333134651184)
[2024-12-14 02:15:58,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:58,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:58,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:58,916][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.4621331691741943, acc: 0.5454545617103577)
[2024-12-14 02:15:59,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:59,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:59,233][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.3428109884262085, acc: 0.5925925970077515)
[2024-12-14 02:15:59,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:59,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:59,595][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.643284797668457, acc: 0.5)
[2024-12-14 02:15:59,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:59,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:15:59,985][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 0.8332154154777527, acc: 0.800000011920929)
[2024-12-14 02:16:00,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:00,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:00,353][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.6258381605148315, acc: 0.517241358757019)
[2024-12-14 02:16:00,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:00,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:00,659][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 1.3199067115783691, acc: 0.7096773982048035)
[2024-12-14 02:16:00,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:00,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:01,227][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 2.436920166015625, acc: 0.3396226465702057)
                                                                                 [2024-12-14 02:16:01,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:01,579][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 2.2466418743133545, acc: 0.4383561611175537)
                                                                                                                                                               [2024-12-14 02:16:02,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:02,868][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.3286561965942383, acc: 0.38735178112983704)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:16:02,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:03,236][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 1.9406284093856812, acc: 0.4883720874786377)
                                                                                [2024-12-14 02:16:03,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:03,626][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 2.023930311203003, acc: 0.4819277226924896)
                                                                                 [2024-12-14 02:16:03,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:04,029][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 2.0767629146575928, acc: 0.4197530746459961)
                                                                                                                                                              [2024-12-14 02:16:04,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:04,413][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 2.318603515625, acc: 0.3928571343421936)
     [2024-12-14 02:16:04,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:04,799][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 1.624699592590332, acc: 0.4444444477558136)
                                                                                 [2024-12-14 02:16:04,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:05,177][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 1.2255980968475342, acc: 0.5652173757553101)
                                                                                                                                                               [2024-12-14 02:16:05,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:05,568][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 1.9911375045776367, acc: 0.462184876203537)
                                                                                                                                                               [2024-12-14 02:16:05,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:05,978][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 1.786651372909546, acc: 0.4590163826942444)
 [2024-12-14 02:16:06,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:06,347][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.3524258136749268, acc: 0.3758865296840668)
[2024-12-14 02:16:06,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:06,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:06,509][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 2.410565137863159, acc: 0.3695652186870575)
[2024-12-14 02:16:06,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:06,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:06,818][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.7199397087097168, acc: 0.8399999737739563)
[2024-12-14 02:16:06,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:06,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:07,127][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 0.9726165533065796, acc: 0.692307710647583)
[2024-12-14 02:16:07,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:07,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:07,515][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 0.7767773866653442, acc: 0.7407407164573669)
[2024-12-14 02:16:07,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:07,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:07,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:07,896][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 1.866276741027832, acc: 0.48148149251937866)
[2024-12-14 02:16:07,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:08,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:08,177][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.6589348316192627, acc: 0.5471698045730591)
[2024-12-14 02:16:08,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:08,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:08,517][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.4405382871627808, acc: 0.5862069129943848)
[2024-12-14 02:16:08,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:08,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:09,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:09,104][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 2.0479373931884766, acc: 0.44144144654273987)
[2024-12-14 02:16:09,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:09,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:09,543][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.7852482795715332, acc: 0.5211267471313477)
[2024-12-14 02:16:09,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:09,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:09,848][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.4557109475135803, acc: 0.8500000238418579)
[2024-12-14 02:16:09,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:10,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:10,208][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.6404260396957397, acc: 0.8333333134651184)
[2024-12-14 02:16:10,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:10,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:10,543][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 1.1617605686187744, acc: 0.6538461446762085)
[2024-12-14 02:16:10,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:10,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:11,246][slam_llm.models.slam_model][INFO] - modality encoder
26][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 0.9663364887237549, acc: 0.7777777910232544)
[2024-12-14 02:16:11,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:11,634][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.3848236799240112, acc: 0.6491228342056274)
[2024-12-14 02:16:11,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:12,051][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.4651991128921509, acc: 0.5873016119003296)
[2024-12-14 02:16:12,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:12,422][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 2.0656447410583496, acc: 0.49295774102211)
[2024-12-14 02:16:12,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:12,860][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 2.327012538909912, acc: 0.47333332896232605)
[2024-12-14 02:16:12,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:13,178][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.2348788976669312, acc: 0.6756756901741028)
 [2024-12-14 02:16:13,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:13,593][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.5821899175643921, acc: 0.8846153616905212)
[2024-12-14 02:16:15,131][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:16:16,621][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 1.9076128005981445, acc: 0.5153583884239197)
                                                                                                                                                               [2024-12-14 02:16:17,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:17,891][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 2.4353137016296387, acc: 0.413943350315094)
                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:16:18,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:18,530][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 1.9176020622253418, acc: 0.5340909361839294)
                                                                                                                                                                                                                          [2024-12-14 02:16:18,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:19,104][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 2.205076217651367, acc: 0.45588234066963196)
                                                                                                                                                               [2024-12-14 02:16:19,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:19,666][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 2.2786574363708496, acc: 0.39855071902275085)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:16:19,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:20,091][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.7248897552490234, acc: 0.6000000238418579)
                                                                               [2024-12-14 02:16:20,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:20,477][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 1.411636233329773, acc: 0.5882353186607361)
                                                                             [2024-12-14 02:16:20,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:20,827][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 1.650794506072998, acc: 0.5833333134651184)
                                                                                 [2024-12-14 02:16:20,926][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:16:21,232][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 1.6258095502853394, acc: 0.59375)
                                 [2024-12-14 02:16:21,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:21,591][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 0.798147439956665, acc: 0.7241379022598267)
[2024-12-14 02:16:21,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:21,922][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 2.3214528560638428, acc: 0.4285714328289032)
[2024-12-14 02:16:22,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:22,260][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 2.0574543476104736, acc: 0.4000000059604645)
                                                                                                                                                [2024-12-14 02:16:22,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:22,638][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.612535297870636, acc: 0.7200000286102295)
  [2024-12-14 02:16:22,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:23,014][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.3193625211715698, acc: 0.6388888955116272)
                                                                                                                                                              [2024-12-14 02:16:23,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:23,420][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 1.612157940864563, acc: 0.5757575631141663)
  [2024-12-14 02:16:23,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:23,782][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 2.0406205654144287, acc: 0.47058823704719543)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:16:23,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:24,145][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 1.9212262630462646, acc: 0.4365079402923584)
                                                                                                                                                                                                               [2024-12-14 02:16:24,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:24,503][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 2.2550642490386963, acc: 0.3589743673801422)
                                                                                                                                                                                                           [2024-12-14 02:16:24,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:24,893][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 1.9417318105697632, acc: 0.4693877696990967)
                                                                                                                                                                                                                                                                                                    [2024-12-14 02:16:25,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:25,282][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 2.4303300380706787, acc: 0.29104477167129517)
                                                                                                                             [2024-12-14 02:16:25,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:25,699][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.2315595149993896, acc: 0.3905109465122223)
                                                                                                                                                                                                                        [2024-12-14 02:16:25,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:26,071][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.557170033454895, acc: 0.8571428656578064)
                                                                                                                                                                                                                        [2024-12-14 02:16:26,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:26,427][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.5001142621040344, acc: 0.875)
333373069763)
[2024-12-14 02:16:26,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:26,296][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 1.5319448709487915, acc: 0.6111111044883728)
[2024-12-14 02:16:26,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:26,496][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 1.5582120418548584, acc: 0.46341463923454285)
[2024-12-14 02:16:26,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:26,608][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 1.0146452188491821, acc: 0.6399999856948853)
[2024-12-14 02:16:26,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:26,835][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 1.0378406047821045, acc: 0.6857143044471741)
[2024-12-14 02:16:26,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:26,944][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 1.5808405876159668, acc: 0.5757575631141663)
[2024-12-14 02:16:27,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:27,145][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 1.3019472360610962, acc: 0.6315789222717285)
[2024-12-14 02:16:27,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:27,283][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 1.540919542312622, acc: 0.5555555820465088)
[2024-12-14 02:16:27,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:27,492][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 1.3898686170578003, acc: 0.5806451439857483)
[2024-12-14 02:16:27,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:27,667][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 1.4819178581237793, acc: 0.6818181872367859)
[2024-12-14 02:16:27,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:27,851][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.7589597105979919, acc: 0.800000011920929)
[2024-12-14 02:16:27,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:28,059][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.7058296203613281, acc: 0.761904776096344)
[2024-12-14 02:16:28,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:28,192][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 1.3820438385009766, acc: 0.6666666865348816)
[2024-12-14 02:16:28,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:28,467][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 2.353118658065796, acc: 0.4615384638309479)
[2024-12-14 02:16:28,578][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 1.1557304859161377, acc: 0.699999988079071)
[2024-12-14 02:16:28,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:28,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:28,914][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 2.1594796180725098, acc: 0.43939393758773804)
[2024-12-14 02:16:28,962][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 1.3174653053283691, acc: 0.6000000238418579)
[2024-12-14 02:16:29,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:29,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:29,358][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 2.248623847961426, acc: 0.40145984292030334)
[2024-12-14 02:16:29,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:29,591][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.598905563354492, acc: 0.328000009059906)
[2024-12-14 02:16:29,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:29,710][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.8906887769699097, acc: 0.517241358757019)
[2024-12-14 02:16:29,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:29,988][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.3461930751800537, acc: 0.3629032373428345)
[2024-12-14 02:16:30,043][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 2.5833847522735596, acc: 0.3499999940395355)
[2024-12-14 02:16:30,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:30,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:30,357][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 2.4364583492279053, acc: 0.33112582564353943)
[2024-12-14 02:16:30,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:30,650][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 2.2850759029388428, acc: 0.4129353165626526)
[2024-12-14 02:16:30,701][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 1.863290786743164, acc: 0.5470085740089417)
[2024-12-14 02:16:30,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:30,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:31,014][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.5404396653175354, acc: 0.8399999737739563)
[2024-12-14 02:16:31,038][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 2.18173885345459, acc: 0.4150943458080292)
[2024-12-14 02:16:31,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:31,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:31,387][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 1.3533024787902832, acc: 0.5769230723381042)
[2024-12-14 02:16:31,461][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.36541748046875, acc: 0.6363636255264282)
[2024-12-14 02:16:31,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:31,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:31,737][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.8943144679069519, acc: 0.7307692170143127)
[2024-12-14 02:16:31,789][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 1.6647143363952637, acc: 0.5652173757553101)
[2024-12-14 02:16:31,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:31,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:32,056][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.8391419649124146, acc: 0.5384615659713745)
[2024-12-14 02:16:32,103][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.6457345485687256, acc: 0.5384615659713745)
[2024-12-14 02:16:32,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:32,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:32,308][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 1.2254655361175537, acc: 0.75)
[2024-12-14 02:16:32,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:32,515][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.8087921142578125, acc: 0.47777777910232544)
[2024-12-14 02:16:32,607][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 2.1806893348693848, acc: 0.41791045665740967)
[2024-12-14 02:16:32,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:32,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:32,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:33,526][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.533021330833435, acc: 0.5684210658073425)
mpleted (loss: 1.8733274936676025, acc: 0.5138888955116272)
[2024-12-14 02:16:32,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:32,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:33,213][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 2.126354694366455, acc: 0.44565218687057495)
[2024-12-14 02:16:33,233][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 1.75112783908844, acc: 0.5208333134651184)
[2024-12-14 02:16:33,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:33,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:33,559][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 1.728338599205017, acc: 0.5344827771186829)
[2024-12-14 02:16:33,578][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 2.2198002338409424, acc: 0.42307692766189575)
[2024-12-14 02:16:33,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:33,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:33,875][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.7907060384750366, acc: 0.4761904776096344)
[2024-12-14 02:16:33,907][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 2.310110330581665, acc: 0.40789473056793213)
[2024-12-14 02:16:33,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:33,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:34,145][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 1.6405267715454102, acc: 0.5)
[2024-12-14 02:16:34,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:34,221][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.7939261198043823, acc: 0.5714285969734192)
[2024-12-14 02:16:34,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:34,464][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 1.4287594556808472, acc: 0.5925925970077515)
[2024-12-14 02:16:34,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:34,615][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.6051018238067627, acc: 0.6363636255264282)
[2024-12-14 02:16:34,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:34,855][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 1.983444094657898, acc: 0.4545454680919647)
[2024-12-14 02:16:35,022][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 2.1516401767730713, acc: 0.4020618498325348)
[2024-12-14 02:16:35,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:35,419][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.9510024785995483, acc: 0.4571428596973419)
[2024-12-14 02:16:35,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:35,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:35,819][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 2.0871050357818604, acc: 0.4651162922382355)
[2024-12-14 02:16:35,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:36,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:36,159][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 2.375502109527588, acc: 0.3392857015132904)
[2024-12-14 02:16:36,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:36,472][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 2.0664143562316895, acc: 0.4444444477558136)
[2024-12-14 02:16:36,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:36,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:36,801][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.738741397857666, acc: 0.5277777910232544)
[2024-12-14 02:16:36,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:36,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:37,163][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 1.429530382156372, acc: 0.59375)
[2024-12-14 02:16:37,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:37,540][root][INFO] - Training Epoch: 2/10, modality encoder
[2024-12-14 02:16:37,755][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.8929778337478638, acc: 0.782608687877655)
                                                                                [2024-12-14 02:16:37,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:38,124][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 1.4041810035705566, acc: 0.5227272510528564)
                                                                             [2024-12-14 02:16:38,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:38,490][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 1.8748605251312256, acc: 0.48275861144065857)
                                                                             [2024-12-14 02:16:38,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:38,852][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 1.5528923273086548, acc: 0.5813953280448914)
                                                                               [2024-12-14 02:16:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:39,218][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 1.3540453910827637, acc: 0.6800000071525574)
                                                                              [2024-12-14 02:16:39,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:39,581][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.5088810920715332, acc: 0.8235294222831726)
                                                                               [2024-12-14 02:16:39,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:39,998][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.43950849771499634, acc: 0.8461538553237915)
                                                                              [2024-12-14 02:16:40,098][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:16:40,364][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 1.5471506118774414, acc: 0.5476190447807312)
                                                                              [2024-12-14 02:16:40,456][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:16:40,745][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 1.7768348455429077, acc: 0.5538461804389954)
[2024-12-14 02:16:40,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:41,169][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.771391749382019, acc: 0.5438596606254578)
                                                                              [2024-12-14 02:16:41,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:41,527][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.644052505493164, acc: 0.5087719559669495)
                                                                                                                                                  [2024-12-14 02:16:41,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:41,917][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.8575359582901, acc: 0.5384615659713745)
                                                                                  [2024-12-14 02:16:42,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:42,297][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 1.4496492147445679, acc: 0.6530612111091614)
                                                                               [2024-12-14 02:16:42,378][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 2.243318796157837, acc: 0.4070351719856262)
[2024-12-14 02:16:42,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:42,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:42,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:42,721][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.4057116508483887, acc: 0.5555555820465088)
[2024-12-14 02:16:42,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:43,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:43,085][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.5520246028900146, acc: 0.5454545617103577)
[2024-12-14 02:16:43,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:43,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:43,454][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.4574193954467773, acc: 0.5555555820465088)
[2024-12-14 02:16:43,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:43,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:43,834][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.654234528541565, acc: 0.44999998807907104)
[2024-12-14 02:16:43,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:44,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:44,194][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 0.8213117718696594, acc: 0.8500000238418579)
[2024-12-14 02:16:44,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:44,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:44,579][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.679510235786438, acc: 0.517241358757019)
[2024-12-14 02:16:44,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:44,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:44,958][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 1.2594668865203857, acc: 0.7419354915618896)
[2024-12-14 02:16:45,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:45,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:45,302][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 0.9958324432373047, acc: 0.7894737124443054)
[2024-12-14 02:16:45,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:45,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:45,608][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 1.975473165512085, acc: 0.5185185074806213)
[2024-12-14 02:16:45,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:45,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:45,901][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 2.1770331859588623, acc: 0.380952388048172)
[2024-12-14 02:16:45,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:46,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:46,212][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 1.6222764253616333, acc: 0.5)
[2024-12-14 02:16:46,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:46,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:46,606][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 2.062627077102661, acc: 0.446153849363327)
[2024-12-14 02:16:46,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:46,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:46,907][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 1.4331936836242676, acc: 0.6333333253860474)
[2024-12-14 02:16:47,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:47,402][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 2.2048897743225098, acc: 0.375)
                                                                                           [2024-12-14 02:16:47,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:47,766][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.144575834274292, acc: 0.363095223903656)
                                                                                [2024-12-14 02:16:47,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:48,111][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.9494390487670898, acc: 0.482051283121109)
                                                                                                                                                               [2024-12-14 02:16:48,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:48,530][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.8600077629089355, acc: 0.5073529481887817)
                                                                               [2024-12-14 02:16:48,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:48,904][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 1.1411370038986206, acc: 0.6538461446762085)
[2024-12-14 02:16:49,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:49,252][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.5634487271308899, acc: 0.739130437374115)
                                                                               [2024-12-14 02:16:49,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:49,589][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 1.4365544319152832, acc: 0.59375)
                                                                                         [2024-12-14 02:16:49,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:49,971][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.8478515148162842, acc: 0.5652173757553101)
                                                                               [2024-12-14 02:16:50,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:50,323][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.2133070230484009, acc: 0.6285714507102966)
                                                                             [2024-12-14 02:16:50,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:50,638][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.136423110961914, acc: 0.6153846383094788)
[2024-12-14 02:16:50,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:50,954][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 2.042308807373047, acc: 0.4047619104385376)
[2024-12-14 02:16:51,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:51,308][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.443681001663208, acc: 0.5333333611488342)
 [2024-12-14 02:16:51,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:51,639][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 1.703636646270752, acc: 0.3478260934352875)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:16:52,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:52,187][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 1.8189069032669067, acc: 0.48148149251937866)
[2024-12-14 02:16:52,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:52,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:52,509][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.6032383441925049, acc: 0.5283018946647644)
[2024-12-14 02:16:52,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:52,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:52,817][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.3310436010360718, acc: 0.5862069129943848)
[2024-12-14 02:16:52,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:52,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:53,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:53,403][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 2.0354597568511963, acc: 0.45045045018196106)
[2024-12-14 02:16:53,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:53,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:53,864][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.8274482488632202, acc: 0.5352112650871277)
[2024-12-14 02:16:53,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:54,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:54,258][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.4761190414428711, acc: 0.8999999761581421)
[2024-12-14 02:16:54,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:54,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:54,621][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.637345552444458, acc: 0.8666666746139526)
[2024-12-14 02:16:54,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:54,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:55,035][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 1.137022614479065, acc: 0.6538461446762085)
[2024-12-14 02:16:55,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:55,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:55,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:56,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:56,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:56,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:56,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:56,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:57,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:57,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:58,099][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.0233840942382812, acc: 0.4928571283817291)
[2024-12-14 02:16:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:58,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:58,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:58,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:58,865][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 2.0461530685424805, acc: 0.523809552192688)
[2024-12-14 02:16:58,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:59,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:59,264][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.5317493677139282, acc: 0.5714285969734192)
[2024-12-14 02:16:59,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:59,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:59,651][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 1.7018909454345703, acc: 0.5833333134651184)
[2024-12-14 02:17:00,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:16:59,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:00,375][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.758650302886963, acc: 0.5694444179534912)
[2024-12-14 02:17:00,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:00,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:00,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:00,777][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.4471149444580078, acc: 0.807692289352417)
[2024-12-14 02:17:00,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:01,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:01,117][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 1.5720947980880737, acc: 0.5483871102333069)
[2024-12-14 02:17:01,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:01,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:01,474][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 2.0172781944274902, acc: 0.550000011920929)
[2024-12-14 02:17:01,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:01,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:01,805][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 1.9923830032348633, acc: 0.5555555820465088)
[2024-12-14 02:17:02,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:02,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:02,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:02,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:02,798][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 2.1496500968933105, acc: 0.42796608805656433)
[2024-12-14 02:17:02,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:02,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:03,153][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 2.2294116020202637, acc: 0.41044774651527405)
[2024-12-14 02:17:03,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:03,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:03,531][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 2.2687737941741943, acc: 0.37956205010414124)
[2024-12-14 02:17:03,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:04,139][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 2.0453920364379883, acc: 0.4350000023841858)
[2024-12-14 02:17:04,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:04,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:04,518][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 2.1269471645355225, acc: 0.42592594027519226)
[2024-12-14 02:17:04,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:04,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:04,903][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 1.8669681549072266, acc: 0.48076921701431274)
[2024-12-14 02:17:05,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:05,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:05,244][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 2.3234076499938965, acc: 0.2380952388048172)
[2024-12-14 02:17:05,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:05,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:05,603][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.8938136100769043, acc: 0.26229506731033325)
[2024-12-14 02:17:05,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:05,979][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 1.8377436399459839, acc: 0.5593220591545105)
[2024-12-14 02:17:06,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:06,265][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7891, device='cuda:0') eval_epoch_loss=tensor(1.9153, device='cuda:0') eval_epoch_acc=tensor(0.4921, device='cuda:0')
[2024-12-14 02:17:06,266][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:17:06,267][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:17:06,318][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.4295096397399902, acc: 0.44186046719551086)
[2024-12-14 02:17:06,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:06,483][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_2_step_570_loss_1.9153176546096802/model.pt
[2024-12-14 02:17:06,486][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:17:06,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:06,646][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 2.269613265991211, acc: 0.5)
[2024-12-14 02:17:06,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:06,872][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 1.5465171337127686, acc: 0.5645161271095276)
[2024-12-14 02:17:06,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:06,978][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.439222574234009, acc: 0.3962264060974121)
[2024-12-14 02:17:07,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:07,180][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 2.0362911224365234, acc: 0.4188034236431122)
[2024-12-14 02:17:07,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:07,298][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.7962806224822998, acc: 0.6590909361839294)
[2024-12-14 02:17:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:07,494][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 2.329371929168701, acc: 0.3520408272743225)
[2024-12-14 02:17:07,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:07,678][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.5554533004760742, acc: 0.6000000238418579)
[2024-12-14 02:17:07,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:07,827][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 2.2110562324523926, acc: 0.402515709400177)
[2024-12-14 02:17:08,014][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 1.7063524723052979, acc: 0.5)
[2024-12-14 02:17:08,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:08,237][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=6.1413, train_epoch_loss=1.8150, epoch time 358.63628623634577s
[2024-12-14 02:17:08,237][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-14 02:17:08,237][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:17:08,238][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-14 02:17:08,238][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-12-14 02:17:08,238][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 02:17:08,401][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 1.2420660257339478, acc: 0.5909090638160706)
[2024-12-14 02:17:08,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:09,010][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:17:09,355][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:17:09,690][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:17:10,039][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:17:10,362][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:17:10,709][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:17:11,200][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:17:11,618][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:17:12,023][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:17:12,373][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:17:12,685][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:17:12,987][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:17:13,292][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:17:13,637][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:17:14,045][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:17:14,563][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:17:14,897][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:17:15,363][slam_llm.models.slam_model][INFO] - modality encoder
eted (loss: 1.5872021913528442, acc: 0.5)
[2024-12-14 02:17:15,227][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 2.5355966091156006, acc: 0.3571428656578064)
[2024-12-14 02:17:15,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:15,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:15,523][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 2.1157422065734863, acc: 0.3611111044883728)
[2024-12-14 02:17:15,572][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 2.395808696746826, acc: 0.3708609342575073)
[2024-12-14 02:17:15,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:15,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:15,862][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 1.4322715997695923, acc: 0.6315789222717285)
[2024-12-14 02:17:15,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:15,943][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 1.8431246280670166, acc: 0.504273533821106)
[2024-12-14 02:17:16,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:16,180][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 1.4403018951416016, acc: 0.6153846383094788)
[2024-12-14 02:17:16,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:16,289][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.5461023449897766, acc: 0.8399999737739563)
[2024-12-14 02:17:16,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:16,496][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 1.6077362298965454, acc: 0.5862069129943848)
[2024-12-14 02:17:16,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:16,625][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 1.342040777206421, acc: 0.5769230723381042)
[2024-12-14 02:17:16,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:16,874][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 1.5741130113601685, acc: 0.4399999976158142)
[2024-12-14 02:17:16,951][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.9219081401824951, acc: 0.7307692170143127)
[2024-12-14 02:17:16,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:17,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:17,205][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 0.7592538595199585, acc: 0.761904776096344)
[2024-12-14 02:17:17,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:17,308][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.6318126916885376, acc: 0.5641025900840759)
[2024-12-14 02:17:17,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:17,583][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 1.779081106185913, acc: 0.4375)
[2024-12-14 02:17:17,673][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.7734462022781372, acc: 0.47777777910232544)
[2024-12-14 02:17:17,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:17,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:17,939][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 2.4700193405151367, acc: 0.3962264060974121)
[2024-12-14 02:17:18,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:18,079][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.7482999563217163, acc: 0.5064935088157654)
[2024-12-14 02:17:18,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:18,259][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 2.2644824981689453, acc: 0.39726027846336365)
[2024-12-14 02:17:18,415][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 1.7758005857467651, acc: 0.4375)
[2024-12-14 02:17:18,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:18,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:18,790][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 1.7430533170700073, acc: 0.5517241358757019)
[2024-12-14 02:17:18,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:19,174][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.8060293197631836, acc: 0.4642857015132904)
[2024-12-14 02:17:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:19,457][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.2651865482330322, acc: 0.36758893728256226)
[2024-12-14 02:17:19,521][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 1.6878961324691772, acc: 0.5263158082962036)
[2024-12-14 02:17:19,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:19,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:19,818][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 1.4226816892623901, acc: 0.5925925970077515)
[2024-12-14 02:17:19,859][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 1.9335664510726929, acc: 0.4651162922382355)
[2024-12-14 02:17:19,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:19,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:20,204][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 2.012561082839966, acc: 0.4491978585720062)
[2024-12-14 02:17:20,262][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 1.989668369293213, acc: 0.4819277226924896)
[2024-12-14 02:17:20,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:20,616][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 2.068850517272949, acc: 0.395061731338501)
[2024-12-14 02:17:20,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:20,939][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 2.2744905948638916, acc: 0.4285714328289032)
[2024-12-14 02:17:20,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:21,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:21,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:21,323][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 1.4331251382827759, acc: 0.5555555820465088)
[2024-12-14 02:17:21,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:21,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:21,735][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 1.204375982284546, acc: 0.6086956262588501)
[2024-12-14 02:17:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:21,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:22,128][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 2.0447235107421875, acc: 0.45378151535987854)
[2024-12-14 02:17:22,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:22,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:22,457][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 1.733687162399292, acc: 0.49180328845977783)
[2024-12-14 02:17:22,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:22,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:22,775][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 2.0150742530822754, acc: 0.4761904776096344)
[2024-12-14 02:17:22,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:22,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:23,105][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 2.1190104484558105, acc: 0.4576271176338196)
[2024-12-14 02:17:23,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:23,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:23,466][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 1.409584879875183, acc: 0.5977011322975159)
[2024-12-14 02:17:23,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:23,600][slam_llm.models.slam_model][INFO] - modality encoder
ft/asr_epoch_3_step_139_loss_1.8832035064697266/model.pt
[2024-12-14 02:17:23,742][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:17:23,743][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.8832035064697266
[2024-12-14 02:17:23,808][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:17:24,145][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.9474105834960938, acc: 0.523809552192688)
                                                                                                                                                              [2024-12-14 02:17:24,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:24,513][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 2.133089542388916, acc: 0.42307692766189575)
                                                                              [2024-12-14 02:17:24,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:24,901][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 2.6898419857025146, acc: 0.22580644488334656)
                                                                             [2024-12-14 02:17:24,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:25,278][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 2.228778839111328, acc: 0.4054054021835327)
[2024-12-14 02:17:25,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:25,805][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 2.11348295211792, acc: 0.3684210479259491)
                                                                                                                                                                                                                                             [2024-12-14 02:17:25,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:26,148][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.7990264892578125, acc: 0.5373134613037109)
                                                                             [2024-12-14 02:17:26,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:26,496][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 2.3069639205932617, acc: 0.3571428656578064)
[2024-12-14 02:17:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:26,941][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 2.104243755340576, acc: 0.3617021143436432)
                                                                                                                                                             [2024-12-14 02:17:27,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:27,303][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.783799171447754, acc: 0.5)
                                                                                                                                                                             [2024-12-14 02:17:27,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:27,638][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 2.348987340927124, acc: 0.5357142686843872)
                                                                               [2024-12-14 02:17:27,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:27,991][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.3170390129089355, acc: 0.6521739363670349)
[2024-12-14 02:17:28,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:28,341][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 1.8521422147750854, acc: 0.4137931168079376)
[2024-12-14 02:17:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:28,735][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 2.0323822498321533, acc: 0.5)
                                  [2024-12-14 02:17:28,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:29,123][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 2.013300657272339, acc: 0.508474588394165)
[2024-12-14 02:17:29,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:29,516][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 2.2515645027160645, acc: 0.4385964870452881)
                                                                                                                                                                                                                                            [2024-12-14 02:17:29,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:29,853][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.8941388130187988, acc: 0.45945945382118225)
                                                                             [2024-12-14 02:17:29,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:30,211][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 1.6805113554000854, acc: 0.6071428656578064)
[2024-12-14 02:17:30,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:30,624][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 1.2799651622772217, acc: 0.6086956262588501)
[2024-12-14 02:17:30,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:30,972][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 1.9056872129440308, acc: 0.3684210479259491)
[2024-12-14 02:17:31,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:32,676][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 1.7153759002685547, acc: 0.5945945978164673)
                                                                                                                                                                                   [2024-12-14 02:17:32,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:33,004][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 1.964739441871643, acc: 0.48148149251937866)
[2024-12-14 02:17:33,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:33,436][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 1.7285650968551636, acc: 0.5)
[2024-12-14 02:17:33,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:34,027][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 1.6399414539337158, acc: 0.5529412031173706)
[2024-12-14 02:17:34,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:34,582][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 2.02101731300354, acc: 0.4606741666793823)
                                                                                [2024-12-14 02:17:34,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:34,893][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 1.6508464813232422, acc: 0.5681818127632141)
[2024-12-14 02:17:35,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:35,245][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 1.40328049659729, acc: 0.5714285969734192)
[2024-12-14 02:17:35,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:35,542][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.5604546070098877, acc: 0.48275861144065857)
[2024-12-14 02:17:35,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:35,922][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 1.3119655847549438, acc: 0.5714285969734192)
[2024-12-14 02:17:35,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:36,263][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 1.7873594760894775, acc: 0.47999998927116394)
[2024-12-14 02:17:36,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:36,667][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 1.6667311191558838, acc: 0.5277777910232544)
[2024-12-14 02:17:36,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:36,991][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 1.8676069974899292, acc: 0.5098039507865906)
                                                                                                                                                       [2024-12-14 02:17:37,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:38,019][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.339982032775879, acc: 0.4452054798603058)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:17:38,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:38,356][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 0.9729292392730713, acc: 0.7083333134651184)
[2024-12-14 02:17:38,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:38,727][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 1.0533024072647095, acc: 0.6666666865348816)
                                                                          [2024-12-14 02:17:38,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:39,086][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.2839850187301636, acc: 0.7142857313156128)
                                                                              [2024-12-14 02:17:39,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:39,626][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.8167686462402344, acc: 0.5221238732337952)
                                                                                                                                                             [2024-12-14 02:17:39,711][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:17:39,949][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.6823866367340088, acc: 0.5072463750839233)
                     [2024-12-14 02:17:40,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:40,348][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 1.8021270036697388, acc: 0.5113636255264282)
                                                                              [2024-12-14 02:17:40,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:41,258][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.3639132976531982, acc: 0.37404578924179077)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:17:41,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:41,928][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 2.192659378051758, acc: 0.385185182094574)
3/10, step 75/574 completed (loss: 2.403189182281494, acc: 0.29104477167129517)
[2024-12-14 02:17:41,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:41,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:41,809][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.196894884109497, acc: 0.4124087691307068)
[2024-12-14 02:17:41,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:42,178][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.5507921576499939, acc: 0.8571428656578064)
[2024-12-14 02:17:42,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:42,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:42,525][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.4958638846874237, acc: 0.875)
[2024-12-14 02:17:42,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:42,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:42,900][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 1.1610043048858643, acc: 0.6363636255264282)
[2024-12-14 02:17:42,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:43,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:43,272][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.8652724623680115, acc: 0.692307710647583)
[2024-12-14 02:17:43,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:43,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:43,646][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 1.7311714887619019, acc: 0.5384615659713745)
[2024-12-14 02:17:43,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:43,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:44,046][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 2.0900766849517822, acc: 0.48076921701431274)
[2024-12-14 02:17:44,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:44,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:44,408][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 1.4695180654525757, acc: 0.5625)
[2024-12-14 02:17:44,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:44,751][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 1.9879825115203857, acc: 0.4492753744125366)
[2024-12-14 02:17:44,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:44,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:45,107][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.4620866775512695, acc: 0.5400000214576721)
[2024-12-14 02:17:45,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:45,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:45,422][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 1.4942363500595093, acc: 0.6521739363670349)
[2024-12-14 02:17:45,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:45,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:45,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:45,880][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 2.1391310691833496, acc: 0.36000001430511475)
[2024-12-14 02:17:46,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:46,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:46,299][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.9668114185333252, acc: 0.5048543810844421)
[2024-12-14 02:17:46,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:46,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:47,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:47,637][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 1.906324028968811, acc: 0.5634920597076416)
                                                                                                                                                                                                                                             [2024-12-14 02:17:47,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:48,553][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 2.0350348949432373, acc: 0.4469696879386902)
                                                                              [2024-12-14 02:17:48,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:49,295][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 1.7256988286972046, acc: 0.6000000238418579)
                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:17:49,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:50,371][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 1.669001817703247, acc: 0.5370370149612427)
                                                                               [2024-12-14 02:17:50,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:51,324][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 1.3308525085449219, acc: 0.6129032373428345)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:17:51,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:51,682][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.7974086999893188, acc: 0.7857142686843872)
                                                                                                                                                                                                                       [2024-12-14 02:17:51,806][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:17:52,077][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 1.3730720281600952, acc: 0.6499999761581421)
                                                                               [2024-12-14 02:17:52,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:52,427][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 1.8746001720428467, acc: 0.47058823704719543)
[2024-12-14 02:17:52,518][slam_llm.models.slam_model][INFO] - modality encoder
eted (loss: 2.301431894302368, acc: 0.3622449040412903)
[2024-12-14 02:17:52,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:52,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:52,528][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 2.323840618133545, acc: 0.40145984292030334)
[2024-12-14 02:17:52,581][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 2.1856861114501953, acc: 0.3962264060974121)
[2024-12-14 02:17:52,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:52,848][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 2.430243730545044, acc: 0.3283582031726837)
[2024-12-14 02:17:52,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:53,038][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=6.1047, train_epoch_loss=1.8091, epoch time 356.7613434381783s
[2024-12-14 02:17:53,039][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-14 02:17:53,039][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:17:53,039][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-14 02:17:53,039][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-12-14 02:17:53,039][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:17:53,172][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 0.9738969802856445, acc: 0.75)
[2024-12-14 02:17:53,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:53,516][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.775696337223053, acc: 0.8636363744735718)
[2024-12-14 02:17:53,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:53,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:53,885][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.8977317214012146, acc: 0.782608687877655)
[2024-12-14 02:17:53,979][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.4566154479980469, acc: 0.5185185074806213)
[2024-12-14 02:17:54,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:54,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:54,273][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 1.3686096668243408, acc: 0.5681818127632141)
[2024-12-14 02:17:54,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:54,382][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 2.1268908977508545, acc: 0.4000000059604645)
[2024-12-14 02:17:54,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:54,630][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 1.885876178741455, acc: 0.48275861144065857)
[2024-12-14 02:17:54,730][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 2.555927276611328, acc: 0.3513513505458832)
[2024-12-14 02:17:54,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:54,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:55,016][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 1.5718674659729004, acc: 0.5581395626068115)
[2024-12-14 02:17:55,098][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 2.1266653537750244, acc: 0.3947368562221527)
[2024-12-14 02:17:55,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:55,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:55,397][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 1.3441340923309326, acc: 0.6800000071525574)
[2024-12-14 02:17:55,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:55,841][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 2.022402048110962, acc: 0.44396552443504333)
024-12-14 02:17:55,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:55,777][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.48663973808288574, acc: 0.8823529481887817)
[2024-12-14 02:17:55,878][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 1.9282257556915283, acc: 0.3928571343421936)
[2024-12-14 02:17:55,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:56,163][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.4229164719581604, acc: 0.8461538553237915)
[2024-12-14 02:17:56,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:56,274][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 2.254735231399536, acc: 0.4285714328289032)
[2024-12-14 02:17:56,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:56,493][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 1.515091061592102, acc: 0.5714285969734192)
[2024-12-14 02:17:56,582][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 1.625579595565796, acc: 0.5)
[2024-12-14 02:17:56,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:56,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:56,883][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 1.8306033611297607, acc: 0.5230769515037537)
[2024-12-14 02:17:56,982][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.3848014771938324, acc: 0.9090909361839294)
[2024-12-14 02:17:57,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:57,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:57,290][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.7999579906463623, acc: 0.5263158082962036)
[2024-12-14 02:17:57,351][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.6800620555877686, acc: 0.807692289352417)
[2024-12-14 02:17:57,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:57,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:57,679][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.621848225593567, acc: 0.5263158082962036)
[2024-12-14 02:17:57,689][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 1.0159776210784912, acc: 0.7407407164573669)
[2024-12-14 02:17:57,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:57,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:58,037][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.8970235586166382, acc: 0.5128205418586731)
[2024-12-14 02:17:58,071][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 1.748266339302063, acc: 0.5128205418586731)
[2024-12-14 02:17:58,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:58,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:58,407][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 1.3568999767303467, acc: 0.6734693646430969)
[2024-12-14 02:17:58,463][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 1.5456550121307373, acc: 0.5454545617103577)
[2024-12-14 02:17:58,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:58,675][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.48978549242019653, acc: 0.8636363744735718)
[2024-12-14 02:17:58,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:58,813][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 1.5858891010284424, acc: 0.5652173757553101)
[2024-12-14 02:17:58,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:59,015][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 2.1033010482788086, acc: 0.4444444477558136)
[2024-12-14 02:17:59,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:17:59,570][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 1.475772738456726, acc: 0.604651153087616)
                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:17:59,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:00,106][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 1.688869833946228, acc: 0.5945945978164673)
                                                                                                                                                                                                                       [2024-12-14 02:18:00,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:00,489][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 1.6054390668869019, acc: 0.5666666626930237)
[2024-12-14 02:18:00,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:00,858][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.7933804988861084, acc: 0.7575757503509521)
                                                                                                                                                                                                                     [2024-12-14 02:18:00,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:01,197][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.35178685188293457, acc: 0.8888888955116272)
                                                                                                                                                                                                                                                                                                   [2024-12-14 02:18:01,281][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:18:01,490][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.641689121723175, acc: 0.800000011920929)
                                                                                                                                                                [2024-12-14 02:18:01,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:01,817][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 1.9331063032150269, acc: 0.4615384638309479)
                                                                                                                                       [2024-12-14 02:18:02,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:02,575][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 1.6237764358520508, acc: 0.5597826242446899)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:18:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:03,123][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 1.8636268377304077, acc: 0.4375)
2024-12-14 02:18:02,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:02,922][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.7577604055404663, acc: 0.5277777910232544)
[2024-12-14 02:18:03,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:03,118][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 2.4332473278045654, acc: 0.3207547068595886)
[2024-12-14 02:18:03,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:03,304][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 2.211597204208374, acc: 0.375)
[2024-12-14 02:18:03,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:03,517][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 2.2073047161102295, acc: 0.4383561611175537)
[2024-12-14 02:18:03,621][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.1301960945129395, acc: 0.375)
[2024-12-14 02:18:03,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:03,959][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.970172643661499, acc: 0.47179487347602844)
[2024-12-14 02:18:04,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:04,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:04,375][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.8634706735610962, acc: 0.5147058963775635)
[2024-12-14 02:18:04,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:04,700][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 1.0789705514907837, acc: 0.6538461446762085)
[2024-12-14 02:18:04,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:04,845][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.313359498977661, acc: 0.38735178112983704)
[2024-12-14 02:18:04,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:05,031][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.5592288374900818, acc: 0.739130437374115)
[2024-12-14 02:18:05,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:05,236][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 1.9543087482452393, acc: 0.4883720874786377)
[2024-12-14 02:18:05,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:05,377][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 1.3501019477844238, acc: 0.59375)
[2024-12-14 02:18:05,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:05,625][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 1.95840322971344, acc: 0.4819277226924896)
[2024-12-14 02:18:05,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:05,759][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.7760034799575806, acc: 0.6086956262588501)
[2024-12-14 02:18:05,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:05,969][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 2.0723607540130615, acc: 0.45679011940956116)
[2024-12-14 02:18:06,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:06,112][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.2695724964141846, acc: 0.5714285969734192)
[2024-12-14 02:18:06,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:06,323][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 2.2177212238311768, acc: 0.3928571343421936)
[2024-12-14 02:18:06,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:06,452][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.1007534265518188, acc: 0.6153846383094788)
[2024-12-14 02:18:06,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:06,680][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 1.51094651222229, acc: 0.5925925970077515)
[2024-12-14 02:18:06,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:07,173][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 1.474010705947876, acc: 0.5769230723381042)
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:18:07,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:07,538][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 1.322178840637207, acc: 0.6315789222717285)
                                                                                                                                         [2024-12-14 02:18:07,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:07,896][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 1.1564202308654785, acc: 0.625)
            [2024-12-14 02:18:08,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:08,237][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 2.225301504135132, acc: 0.3181818127632141)
[2024-12-14 02:18:08,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:08,569][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.649162769317627, acc: 0.5185185074806213)
[2024-12-14 02:18:08,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:08,959][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 1.3268097639083862, acc: 0.5714285969734192)
                    [2024-12-14 02:18:09,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:09,371][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.4619534015655518, acc: 0.5454545617103577)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:18:09,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:09,762][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.9011712074279785, acc: 0.5681818127632141)
                                                               [2024-12-14 02:18:09,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:10,343][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 1.9766390323638916, acc: 0.4354838728904724)
                                                                               [2024-12-14 02:18:10,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:10,873][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.5110740661621094, acc: 0.5909090638160706)
                                                                                                                                                                                                                                            [2024-12-14 02:18:10,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:11,180][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.4418554902076721, acc: 0.8571428656578064)
[2024-12-14 02:18:11,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:11,503][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.0435103178024292, acc: 0.7307692170143127)
[2024-12-14 02:18:11,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:11,892][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.2532157897949219, acc: 0.7096773982048035)
                                                                                                                                                           [2024-12-14 02:18:11,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:12,169][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.8338552713394165, acc: 0.7692307829856873)
[2024-12-14 02:18:12,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:12,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:12,538][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.9030429720878601, acc: 0.8148148059844971)
[2024-12-14 02:18:12,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:12,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:12,860][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 1.3317023515701294, acc: 0.5714285969734192)
[2024-12-14 02:18:12,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:12,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:13,249][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 0.903245210647583, acc: 0.75)
[2024-12-14 02:18:13,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:13,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:13,612][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.3598694801330566, acc: 0.6491228342056274)
[2024-12-14 02:18:13,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:13,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:14,004][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.42278254032135, acc: 0.5873016119003296)
[2024-12-14 02:18:14,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:14,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:14,354][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 2.126619338989258, acc: 0.4507042169570923)
[2024-12-14 02:18:14,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:14,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:14,627][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:18:14,826][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 2.294412612915039, acc: 0.4466666579246521)
[2024-12-14 02:18:14,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:14,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:15,180][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.1500723361968994, acc: 0.7027027010917664)
[2024-12-14 02:18:15,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:15,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:15,564][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.5275694727897644, acc: 0.8461538553237915)
[2024-12-14 02:18:15,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:15,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:16,323][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:18:16,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:17,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:17,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:17,395][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                  [2024-12-14 02:18:17,771][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:18:18,107][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:18:18,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:18,640][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 2.707453727722168, acc: 0.3199999928474426)
[2024-12-14 02:18:18,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:19,013][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 2.2316458225250244, acc: 0.4166666567325592)
[2024-12-14 02:18:19,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:19,868][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 2.4447247982025146, acc: 0.42399999499320984)
[2024-12-14 02:18:19,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:20,237][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 2.160418748855591, acc: 0.3932584226131439)
[2024-12-14 02:18:20,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:20,626][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 2.321969985961914, acc: 0.4054054021835327)
[2024-12-14 02:18:20,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:21,088][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.3417714834213257, acc: 0.5862069129943848)
[2024-12-14 02:18:21,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:21,439][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 1.0602704286575317, acc: 0.7727272510528564)
                                                             [2024-12-14 02:18:21,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:21,805][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 1.0320320129394531, acc: 0.6818181872367859)
[2024-12-14 02:18:21,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:22,143][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.9547650814056396, acc: 0.75)
[2024-12-14 02:18:22,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:22,523][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 1.0792336463928223, acc: 0.7333333492279053)
                                [2024-12-14 02:18:22,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:22,923][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 1.923965334892273, acc: 0.44999998807907104)
                                                                              [2024-12-14 02:18:23,001][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                         [2024-12-14 02:18:23,227][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 1.371397614479065, acc: 0.59375)
[2024-12-14 02:18:23,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:23,562][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.9013801217079163, acc: 0.699999988079071)
                      [2024-12-14 02:18:23,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:23,919][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 1.3325390815734863, acc: 0.7241379022598267)
                                                                              [2024-12-14 02:18:23,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:24,195][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 1.1959760189056396, acc: 0.6000000238418579)
[2024-12-14 02:18:24,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:24,550][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 2.070155143737793, acc: 0.4680851101875305)
                                                                                                                                                          [2024-12-14 02:18:24,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:24,942][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 1.718563199043274, acc: 0.5833333134651184)
                                                                               [2024-12-14 02:18:25,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:25,283][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 1.602196216583252, acc: 0.6590909361839294)
                                                                              [2024-12-14 02:18:25,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:25,700][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 2.1552555561065674, acc: 0.42168673872947693)
                                                                                                                                                            [2024-12-14 02:18:26,429][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:18:26,890][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:18:27,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:27,582][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:18:27,961][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:18:28,270][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:18:28,720][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                           [2024-12-14 02:18:29,067][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:18:29,381][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:18:29,702][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:18:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:29,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:30,084][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 2.0656442642211914, acc: 0.4615384638309479)
[2024-12-14 02:18:30,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:30,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:30,395][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 1.520896315574646, acc: 0.5625)
[2024-12-14 02:18:30,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:30,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:30,760][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 2.0133869647979736, acc: 0.43478259444236755)
[2024-12-14 02:18:30,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:30,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:31,109][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.4395235776901245, acc: 0.5799999833106995)
[2024-12-14 02:18:31,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:31,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:31,455][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 1.5228089094161987, acc: 0.52173912525177)
[2024-12-14 02:18:31,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:31,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:31,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:31,937][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 2.1499245166778564, acc: 0.46000000834465027)
[2024-12-14 02:18:32,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:32,326][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.976172685623169, acc: 0.5145630836486816)
[2024-12-14 02:18:32,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:32,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:32,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:32,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:33,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:33,436][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 1.8320577144622803, acc: 0.5194174647331238)
[2024-12-14 02:18:33,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:33,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:34,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:34,263][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 2.033533811569214, acc: 0.4354838728904724)
[2024-12-14 02:18:34,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:34,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:34,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:35,069][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 1.8242276906967163, acc: 0.5517241358757019)
[2024-12-14 02:18:35,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:35,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:35,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:35,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:35,815][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.4765981435775757, acc: 0.5894736647605896)
[2024-12-14 02:18:36,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:36,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:36,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:36,810][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 2.313352584838867, acc: 0.3564356565475464)
[2024-12-14 02:18:37,039][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:18:37,328][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:18:37,677][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:18:38,032][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:18:38,353][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:18:38,663][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:18:38,976][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:18:39,364][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                    [2024-12-14 02:18:39,721][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:18:40,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:40,050][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.9322571158409119, acc: 0.739130437374115)
[2024-12-14 02:18:40,147][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.7698382139205933, acc: 0.5298507213592529)
[2024-12-14 02:18:40,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:40,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:40,431][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 1.3573116064071655, acc: 0.5681818127632141)
[2024-12-14 02:18:40,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:40,554][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 2.3193070888519287, acc: 0.3469387888908386)
[2024-12-14 02:18:40,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:40,784][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 1.8843965530395508, acc: 0.48275861144065857)
[2024-12-14 02:18:40,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:40,995][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 2.080845832824707, acc: 0.38297873735427856)
[2024-12-14 02:18:41,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:41,155][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 1.6306017637252808, acc: 0.5581395626068115)
[2024-12-14 02:18:41,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:41,361][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.817555546760559, acc: 0.5285714268684387)
[2024-12-14 02:18:41,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:41,543][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 1.2320204973220825, acc: 0.7599999904632568)
[2024-12-14 02:18:41,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:41,690][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 2.169912815093994, acc: 0.5357142686843872)
[2024-12-14 02:18:41,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:41,911][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.5041178464889526, acc: 0.8235294222831726)
[2024-12-14 02:18:42,010][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.3732818365097046, acc: 0.6086956262588501)
[2024-12-14 02:18:42,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:42,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:42,305][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.4446428716182709, acc: 0.8461538553237915)
[2024-12-14 02:18:42,338][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 1.8362969160079956, acc: 0.3103448152542114)
[2024-12-14 02:18:42,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:42,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:42,646][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 1.5355883836746216, acc: 0.5714285969734192)
[2024-12-14 02:18:42,710][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 1.9840444326400757, acc: 0.54347825050354)
[2024-12-14 02:18:42,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:42,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:43,046][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 1.9972418546676636, acc: 0.5254237055778503)
[2024-12-14 02:18:43,080][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 1.8085633516311646, acc: 0.5230769515037537)
[2024-12-14 02:18:43,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:43,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:43,384][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 2.1991171836853027, acc: 0.4912280738353729)
[2024-12-14 02:18:43,484][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.7828764915466309, acc: 0.5087719559669495)
[2024-12-14 02:18:43,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:43,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:43,767][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.8921020030975342, acc: 0.4864864945411682)
[2024-12-14 02:18:43,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:43,903][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.5740891695022583, acc: 0.5263158082962036)
[2024-12-14 02:18:44,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:44,099][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 1.6595017910003662, acc: 0.5714285969734192)
[2024-12-14 02:18:44,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:44,332][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.9227007627487183, acc: 0.5128205418586731)
[2024-12-14 02:18:44,411][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 1.3462533950805664, acc: 0.6086956262588501)
[2024-12-14 02:18:44,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:44,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:44,704][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 1.3657636642456055, acc: 0.6326530575752258)
[2024-12-14 02:18:44,771][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 1.8980891704559326, acc: 0.42105263471603394)
[2024-12-14 02:18:44,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:45,006][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.4368841350078583, acc: 0.9090909361839294)
[2024-12-14 02:18:45,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:45,340][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 2.0048553943634033, acc: 0.460317462682724)
[2024-12-14 02:18:45,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:45,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:45,675][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 2.023904800415039, acc: 0.5447154641151428)
[2024-12-14 02:18:45,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:46,031][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 1.6342341899871826, acc: 0.5322580933570862)
[2024-12-14 02:18:46,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:46,412][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 1.6929805278778076, acc: 0.5945945978164673)
[2024-12-14 02:18:46,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:46,768][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 1.9959893226623535, acc: 0.48148149251937866)
[2024-12-14 02:18:46,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:46,932][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 2.0168938636779785, acc: 0.4600760340690613)
[2024-12-14 02:18:47,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:47,181][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 1.7583218812942505, acc: 0.4883720874786377)
[2024-12-14 02:18:47,297][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 1.561463475227356, acc: 0.54666668176651)
[2024-12-14 02:18:47,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:47,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:47,732][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 1.5271512269973755, acc: 0.5961538553237915)
[2024-12-14 02:18:47,774][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 1.623254418373108, acc: 0.5411764979362488)
[2024-12-14 02:18:47,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:48,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:48,129][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.8361101746559143, acc: 0.8333333134651184)
[2024-12-14 02:18:48,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:48,331][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 1.9916996955871582, acc: 0.449438214302063)
[2024-12-14 02:18:48,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:48,526][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 1.3098000288009644, acc: 0.6842105388641357)
[2024-12-14 02:18:48,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:48,689][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 1.5895377397537231, acc: 0.5909090638160706)
[2024-12-14 02:18:48,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:48,950][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 2.1652450561523438, acc: 0.42331287264823914)
[2024-12-14 02:18:49,059][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 1.3756170272827148, acc: 0.5714285969734192)
[2024-12-14 02:18:49,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:49,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:49,404][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.7919921875, acc: 0.5416666865348816)
[2024-12-14 02:18:49,456][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.5663214921951294, acc: 0.5517241358757019)
[2024-12-14 02:18:49,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:49,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:49,762][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 2.221688747406006, acc: 0.38333332538604736)
[2024-12-14 02:18:49,850][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 1.331284761428833, acc: 0.5306122303009033)
[2024-12-14 02:18:49,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:49,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:50,161][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.114595413208008, acc: 0.375)
[2024-12-14 02:18:50,211][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 1.7719855308532715, acc: 0.47999998927116394)
[2024-12-14 02:18:50,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:50,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:50,565][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.9857319593429565, acc: 0.47179487347602844)
[2024-12-14 02:18:50,634][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 1.618812084197998, acc: 0.5555555820465088)
[2024-12-14 02:18:50,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:50,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:50,973][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.9087730646133423, acc: 0.49264705181121826)
[2024-12-14 02:18:51,016][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 1.9034560918807983, acc: 0.5)
[2024-12-14 02:18:51,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:51,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:51,325][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 1.1196236610412598, acc: 0.6538461446762085)
[2024-12-14 02:18:51,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:51,677][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.5358561277389526, acc: 0.739130437374115)
[2024-12-14 02:18:51,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:52,047][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.4570337533950806, acc: 0.5625)
[2024-12-14 02:18:52,043][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.3222734928131104, acc: 0.4109589159488678)
[2024-12-14 02:18:52,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:52,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:52,376][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.7668625116348267, acc: 0.52173912525177)
[2024-12-14 02:18:52,407][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 0.9260620474815369, acc: 0.75)
[2024-12-14 02:18:52,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:52,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:52,720][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.2487643957138062, acc: 0.6571428775787354)
[2024-12-14 02:18:52,778][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 0.9556936621665955, acc: 0.7037037014961243)
[2024-12-14 02:18:52,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:52,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:53,097][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.1568944454193115, acc: 0.6153846383094788)
[2024-12-14 02:18:53,155][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.2880098819732666, acc: 0.6785714030265808)
[2024-12-14 02:18:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:53,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:53,440][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 2.06921124458313, acc: 0.380952388048172)
[2024-12-14 02:18:53,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:53,699][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.8040566444396973, acc: 0.5044247508049011)
[2024-12-14 02:18:53,806][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.4476155042648315, acc: 0.6000000238418579)
[2024-12-14 02:18:53,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:53,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:54,107][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.7183692455291748, acc: 0.52173912525177)
[2024-12-14 02:18:54,155][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 1.6864471435546875, acc: 0.47826087474823)
[2024-12-14 02:18:54,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:54,467][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 1.8197780847549438, acc: 0.5113636255264282)
[2024-12-14 02:18:54,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:54,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:55,442][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.3528099060058594, acc: 0.39694657921791077)
[2024-12-14 02:18:55,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:55,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:55,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:56,112][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 2.178262948989868, acc: 0.3629629611968994)
[2024-12-14 02:18:56,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:56,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:56,419][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 1.5291037559509277, acc: 0.5409836173057556)
[2024-12-14 02:18:56,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:56,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:56,761][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.9015341401100159, acc: 0.7083333134651184)
[2024-12-14 02:18:57,139][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.6121, device='cuda:0') eval_epoch_loss=tensor(1.8889, device='cuda:0') eval_epoch_acc=tensor(0.5027, device='cuda:0')
[2024-12-14 02:18:57,140][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:18:57,141][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:18:57,331][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_3_step_282_loss_1.8889002799987793/model.pt
[2024-12-14 02:18:57,334][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:18:57,334][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5026639699935913
[2024-12-14 02:18:57,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:57,755][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 2.084266424179077, acc: 0.4722222089767456)
[2024-12-14 02:18:57,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:58,082][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 2.341621160507202, acc: 0.34210526943206787)
[2024-12-14 02:18:58,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:58,409][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 2.276663303375244, acc: 0.3529411852359772)
[2024-12-14 02:18:58,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:58,800][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 1.86978280544281, acc: 0.4000000059604645)
                                                                                                         [2024-12-14 02:18:58,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:59,196][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 2.057188034057617, acc: 0.3984375)
                                                                                         [2024-12-14 02:18:59,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:59,555][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 2.2865960597991943, acc: 0.36800000071525574)
[2024-12-14 02:18:59,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:18:59,936][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 1.8591445684432983, acc: 0.4395604431629181)
 [2024-12-14 02:19:00,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:00,287][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 2.26943039894104, acc: 0.39751553535461426)
                                                                                [2024-12-14 02:19:00,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:00,624][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 2.306975841522217, acc: 0.36082473397254944)
[2024-12-14 02:19:00,700][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:19:00,978][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.8083438873291016, acc: 0.6818181872367859)
[2024-12-14 02:19:01,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:01,348][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 1.7488951683044434, acc: 0.5476190447807312)
[2024-12-14 02:19:01,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:01,690][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 1.342452883720398, acc: 0.6551724076271057)
[2024-12-14 02:19:01,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:02,203][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 1.2350579500198364, acc: 0.6727272868156433)
[2024-12-14 02:19:02,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:02,763][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.7192753553390503, acc: 0.5773195624351501)
                      [2024-12-14 02:19:02,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:03,105][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 2.027418851852417, acc: 0.4655172526836395)
[2024-12-14 02:19:03,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:03,461][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 1.6360670328140259, acc: 0.5185185074806213)
[2024-12-14 02:19:03,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:03,800][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 1.7380406856536865, acc: 0.5)
[2024-12-14 02:19:03,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:04,178][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 1.4333114624023438, acc: 0.6071428656578064)
[2024-12-14 02:19:04,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:04,567][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 1.6092644929885864, acc: 0.5625)
            [2024-12-14 02:19:04,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:04,965][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 1.655083179473877, acc: 0.5471698045730591)
[2024-12-14 02:19:05,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:05,316][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 0.9360105991363525, acc: 0.7169811129570007)
[2024-12-14 02:19:05,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:05,626][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 1.1292855739593506, acc: 0.7647058963775635)
[2024-12-14 02:19:05,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:05,939][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 1.7154191732406616, acc: 0.5625)
[2024-12-14 02:19:06,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:06,256][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.3206735849380493, acc: 0.6065573692321777)
                                       [2024-12-14 02:19:06,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:06,609][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.7095339298248291, acc: 0.7666666507720947)
[2024-12-14 02:19:06,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:06,955][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.5751093029975891, acc: 0.8421052694320679)
                                                                              [2024-12-14 02:19:07,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:07,358][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 1.916532039642334, acc: 0.47826087474823)
                                                                                                                                                                 [2024-12-14 02:19:07,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:07,776][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 1.6813464164733887, acc: 0.5833333134651184)
                                                                               [2024-12-14 02:19:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:08,093][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 1.517030119895935, acc: 0.5783132314682007)
                                                                                                                                                               [2024-12-14 02:19:08,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:08,447][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 2.101640462875366, acc: 0.41025641560554504)
[2024-12-14 02:19:08,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:08,822][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 2.2464230060577393, acc: 0.3979591727256775)
 [2024-12-14 02:19:08,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:09,185][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.22078216075897217, acc: 0.9583333134651184)
                                                                              [2024-12-14 02:19:09,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:09,500][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 0.9944920539855957, acc: 0.75)
                                                                                             [2024-12-14 02:19:09,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:09,841][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 1.1513519287109375, acc: 0.7096773982048035)
[2024-12-14 02:19:09,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:10,176][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 1.1163041591644287, acc: 0.6129032373428345)
                     [2024-12-14 02:19:10,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:10,502][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 1.339491367340088, acc: 0.641791045665741)
[2024-12-14 02:19:10,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:10,874][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 1.3411071300506592, acc: 0.6538461446762085)
                                                                                                                                                               [2024-12-14 02:19:10,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:11,211][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 1.7650068998336792, acc: 0.5111111402511597)
 [2024-12-14 02:19:11,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:11,530][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 1.4718284606933594, acc: 0.5967742204666138)
                                                                               [2024-12-14 02:19:11,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:11,845][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.921183168888092, acc: 0.800000011920929)
                                                                                                                                                                [2024-12-14 02:19:11,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:12,210][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 2.1108081340789795, acc: 0.37037035822868347)
[2024-12-14 02:19:12,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:12,577][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.7567155361175537, acc: 0.22857142984867096)
[2024-12-14 02:19:12,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:12,961][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 2.049341917037964, acc: 0.41025641560554504)
                                                                                                   [2024-12-14 02:19:13,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:13,301][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.223248243331909, acc: 0.4146341383457184)
                                                                                [2024-12-14 02:19:13,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:13,624][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 2.0036580562591553, acc: 0.4736842215061188)
[2024-12-14 02:19:13,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:13,927][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 0.8029276132583618, acc: 0.7368420958518982)
[2024-12-14 02:19:14,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:14,232][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.618075430393219, acc: 0.7857142686843872)
[2024-12-14 02:19:14,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:14,590][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 1.6304682493209839, acc: 0.5185185074806213)
                     [2024-12-14 02:19:14,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:14,959][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.8054955005645752, acc: 0.78125)
           [2024-12-14 02:19:15,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:15,365][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 1.7757134437561035, acc: 0.5645161271095276)
                                                                                                                                                               [2024-12-14 02:19:15,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:15,768][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 1.659435510635376, acc: 0.5087719559669495)
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:19:15,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:16,149][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 2.218956232070923, acc: 0.40625)
[2024-12-14 02:19:16,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:16,507][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 0.9947581887245178, acc: 0.7333333492279053)
                                [2024-12-14 02:19:16,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:16,828][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 1.6936733722686768, acc: 0.42105263471603394)
[2024-12-14 02:19:16,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:17,179][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 2.1669139862060547, acc: 0.3799999952316284)
[2024-12-14 02:19:17,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:17,502][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 2.180818796157837, acc: 0.39080458879470825)
[2024-12-14 02:19:17,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:17,864][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 2.3200252056121826, acc: 0.38297873735427856)
                                                                              [2024-12-14 02:19:17,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:18,197][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 2.372650623321533, acc: 0.3855421543121338)
                                                                                [2024-12-14 02:19:18,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:18,592][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.8538187146186829, acc: 0.739130437374115)
                                                                               [2024-12-14 02:19:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:18,930][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 1.9056603908538818, acc: 0.5128205418586731)
                                                                               [2024-12-14 02:19:19,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:19,299][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 2.2819440364837646, acc: 0.4337349534034729)
10, step 230/574 completed (loss: 2.2038896083831787, acc: 0.42105263471603394)
[2024-12-14 02:19:19,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:19,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:19,681][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 1.7213115692138672, acc: 0.5222222208976746)
[2024-12-14 02:19:19,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:19,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:20,098][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 1.465678095817566, acc: 0.605555534362793)
[2024-12-14 02:19:20,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:20,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:20,592][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 1.6506049633026123, acc: 0.5825688242912292)
[2024-12-14 02:19:20,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:20,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:21,070][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 1.4902589321136475, acc: 0.5769230723381042)
[2024-12-14 02:19:21,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:21,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:21,378][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 1.2940648794174194, acc: 0.6315789222717285)
[2024-12-14 02:19:21,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:21,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:21,724][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 1.0397578477859497, acc: 0.75)
[2024-12-14 02:19:21,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:21,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:22,061][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 2.2237164974212646, acc: 0.3636363744735718)
[2024-12-14 02:19:22,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:22,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:22,382][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.6102252006530762, acc: 0.5185185074806213)
[2024-12-14 02:19:22,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:22,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:22,768][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 1.2984131574630737, acc: 0.6285714507102966)
[2024-12-14 02:19:22,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:22,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:23,136][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.4340342283248901, acc: 0.5681818127632141)
[2024-12-14 02:19:23,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:23,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:23,488][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.9133816957473755, acc: 0.5681818127632141)
[2024-12-14 02:19:23,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:23,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:23,873][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:19:24,073][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 1.9452799558639526, acc: 0.4193548262119293)
[2024-12-14 02:19:24,205][slam_llm.models.slam_model][INFO] - modality encode[2024-12-14 02:19:24,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:24,875][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 1.8469775915145874, acc: 0.532608687877655)
 3/10, step 243/574 completed (loss: 1.550673007965088, acc: 0.6136363744735718)
[2024-12-14 02:19:24,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:24,959][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.5160740613937378, acc: 0.8571428656578064)
[2024-12-14 02:19:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:25,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:25,292][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.0340616703033447, acc: 0.7307692170143127)
[2024-12-14 02:19:25,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:25,602][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.3111032247543335, acc: 0.6774193644523621)
[2024-12-14 02:19:25,696][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.4284, device='cuda:0') eval_epoch_loss=tensor(1.8607, device='cuda:0') eval_epoch_acc=tensor(0.4902, device='cuda:0')
[2024-12-14 02:19:25,699][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:19:25,700][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:19:25,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:25,965][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_3_step_139_loss_1.860718846321106/model.pt
[2024-12-14 02:19:25,968][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:19:25,969][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.860718846321106
[2024-12-14 02:19:25,980][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 0.8577332496643066, acc: 0.6000000238418579)
[2024-12-14 02:19:26,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:26,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:26,345][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 1.2383068799972534, acc: 0.6486486196517944)
[2024-12-14 02:19:26,383][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.9425241947174072, acc: 0.523809552192688)
[2024-12-14 02:19:26,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:26,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:26,645][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 1.35207200050354, acc: 0.5675675868988037)
[2024-12-14 02:19:26,706][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 2.0459141731262207, acc: 0.42307692766189575)
[2024-12-14 02:19:26,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:26,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:26,947][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 1.2202301025390625, acc: 0.5675675868988037)
[2024-12-14 02:19:26,968][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 2.6058545112609863, acc: 0.22580644488334656)
[2024-12-14 02:19:27,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:27,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:27,286][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 1.6665934324264526, acc: 0.5735294222831726)
[2024-12-14 02:19:27,335][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 2.201613426208496, acc: 0.45945945382118225)
[2024-12-14 02:19:27,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:27,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:27,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:28,011][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.6558626294136047, acc: 0.8333333134651184)
[2024-12-14 02:19:27,865][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 2.0017833709716797, acc: 0.38596490025520325)
[2024-12-14 02:19:27,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:28,006][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.45028722286224365, acc: 0.9200000166893005)
[2024-12-14 02:19:28,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:28,256][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.7673903703689575, acc: 0.5149253606796265)
[2024-12-14 02:19:28,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:28,367][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.47730109095573425, acc: 0.8799999952316284)
[2024-12-14 02:19:28,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:28,608][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 2.3135995864868164, acc: 0.3571428656578064)
[2024-12-14 02:19:28,728][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.49108991026878357, acc: 0.9032257795333862)
[2024-12-14 02:19:28,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:28,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:29,043][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 2.067587375640869, acc: 0.3723404109477997)
[2024-12-14 02:19:29,123][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 1.3707596063613892, acc: 0.6315789222717285)
[2024-12-14 02:19:29,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:29,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:29,394][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.7747654914855957, acc: 0.5142857432365417)
[2024-12-14 02:19:29,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:29,515][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 1.549025058746338, acc: 0.6000000238418579)
[2024-12-14 02:19:29,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:29,749][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 2.2518246173858643, acc: 0.5357142686843872)
[2024-12-14 02:19:29,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:29,866][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 1.333238959312439, acc: 0.6710526347160339)
[2024-12-14 02:19:30,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:30,090][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.3125470876693726, acc: 0.6086956262588501)
[2024-12-14 02:19:30,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:30,428][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.6954874992370605, acc: 0.5)
[2024-12-14 02:19:30,457][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 1.8021776676177979, acc: 0.4137931168079376)
[2024-12-14 02:19:30,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:30,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:30,813][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 1.9606010913848877, acc: 0.54347825050354)
[2024-12-14 02:19:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:31,013][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 1.7455024719238281, acc: 0.5333333611488342)
[2024-12-14 02:19:31,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:31,174][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 1.9922007322311401, acc: 0.47457626461982727)
[2024-12-14 02:19:31,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:31,657][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.9148016571998596, acc: 0.7428571581840515)
[2024-12-14 02:19:31,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:31,522][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 2.210487127304077, acc: 0.45614033937454224)
[2024-12-14 02:19:31,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:31,765][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 1.422785997390747, acc: 0.6129032373428345)
[2024-12-14 02:19:31,867][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.8593758344650269, acc: 0.5)
[2024-12-14 02:19:31,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:31,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:32,086][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 2.7193806171417236, acc: 0.3199999928474426)
[2024-12-14 02:19:32,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:32,202][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 1.6510087251663208, acc: 0.6071428656578064)
[2024-12-14 02:19:32,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:32,411][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 2.1974053382873535, acc: 0.3958333432674408)
[2024-12-14 02:19:32,605][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 1.2126529216766357, acc: 0.6521739363670349)
[2024-12-14 02:19:32,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:32,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:32,963][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 1.8638536930084229, acc: 0.3684210479259491)
[2024-12-14 02:19:33,228][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 2.483941078186035, acc: 0.4000000059604645)
[2024-12-14 02:19:33,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:33,611][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 2.178075075149536, acc: 0.42696627974510193)
[2024-12-14 02:19:33,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:33,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:33,995][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 2.187905788421631, acc: 0.4189189076423645)
[2024-12-14 02:19:34,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:34,455][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.3763134479522705, acc: 0.568965494632721)
[2024-12-14 02:19:34,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:34,628][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 1.687883973121643, acc: 0.6081081032752991)
[2024-12-14 02:19:34,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:34,825][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 0.9682626724243164, acc: 0.7727272510528564)
[2024-12-14 02:19:34,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:34,988][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 1.9737070798873901, acc: 0.5)
[2024-12-14 02:19:35,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:35,168][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 1.0292227268218994, acc: 0.5909090638160706)
[2024-12-14 02:19:35,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:35,367][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 1.7446303367614746, acc: 0.4883720874786377)
[2024-12-14 02:19:35,469][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.8950391411781311, acc: 0.78125)
[2024-12-14 02:19:35,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:35,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:35,783][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 1.076650857925415, acc: 0.7333333492279053)
[2024-12-14 02:19:35,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:36,178][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 0.6512316465377808, acc: 0.8214285969734192)
                                                                                                                                                                                                                      [2024-12-14 02:19:36,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:36,475][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.6549897193908691, acc: 0.8214285969734192)
[2024-12-14 02:19:36,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:36,836][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 0.9369882941246033, acc: 0.75)
 [2024-12-14 02:19:36,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:37,210][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 1.0225540399551392, acc: 0.7222222089767456)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:19:37,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:37,597][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 1.0335593223571777, acc: 0.7105262875556946)
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:19:37,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:37,974][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.5979270935058594, acc: 0.7727272510528564)
                                                                                                                                         [2024-12-14 02:19:38,083][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:19:38,321][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 0.9125986099243164, acc: 0.6499999761581421)
                                                                               [2024-12-14 02:19:38,430][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:19:38,707][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 0.6996369957923889, acc: 0.8095238208770752)
                                                                               [2024-12-14 02:19:38,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:39,055][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 2.5657291412353516, acc: 0.42592594027519226)
                                                                                                                                                                                                                     [2024-12-14 02:19:39,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:39,486][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 2.329911947250366, acc: 0.43689319491386414)
[2024-12-14 02:19:39,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:40,009][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 1.894788384437561, acc: 0.5514705777168274)
[2024-12-14 02:19:40,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:40,380][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 2.2354142665863037, acc: 0.46666666865348816)
                                                                [2024-12-14 02:19:40,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:40,752][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 2.143139600753784, acc: 0.4583333432674408)
                                                                                                                                                               [2024-12-14 02:19:40,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:41,124][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 1.6240649223327637, acc: 0.6511628031730652)
[2024-12-14 02:19:41,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:41,489][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 0.8292415738105774, acc: 0.75)
[2024-12-14 02:19:41,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:41,842][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 1.3495038747787476, acc: 0.6279069781303406)
                                                                                                                                                                           [2024-12-14 02:19:41,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:42,200][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 1.2747341394424438, acc: 0.6000000238418579)
                                                                               [2024-12-14 02:19:42,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:42,732][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 1.6801090240478516, acc: 0.5588235259056091)
[2024-12-14 02:19:42,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:43,082][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 1.6053727865219116, acc: 0.5600000023841858)
 [2024-12-14 02:19:43,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:43,429][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 1.2743332386016846, acc: 0.6666666865348816)
[2024-12-14 02:19:43,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:43,803][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 1.2500884532928467, acc: 0.6363636255264282)
[2024-12-14 02:19:43,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:44,171][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.696144163608551, acc: 0.8064516186714172)
                      [2024-12-14 02:19:44,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:44,521][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 1.0780483484268188, acc: 0.6666666865348816)
                                                                               [2024-12-14 02:19:44,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:44,882][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.6714295148849487, acc: 0.8399999737739563)
                                                                               [2024-12-14 02:19:45,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:45,246][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.7987352013587952, acc: 0.7777777910232544)
                                                                                                                                                             [2024-12-14 02:19:45,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:45,624][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.8609926700592041, acc: 0.8518518805503845)
                                                                              [2024-12-14 02:19:45,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:45,972][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.7141656875610352, acc: 0.7692307829856873)
                                                                                [2024-12-14 02:19:46,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:46,314][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 1.1980663537979126, acc: 0.6379310488700867)
                                                                               [2024-12-14 02:19:46,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:46,611][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.9307734370231628, acc: 0.6785714030265808)
[2024-12-14 02:19:46,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:46,927][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.7928799986839294, acc: 0.8333333134651184)
[2024-12-14 02:19:47,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:47,274][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.9649790525436401, acc: 0.7575757503509521)
           [2024-12-14 02:19:47,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:47,607][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.6609606146812439, acc: 0.8181818127632141)
[2024-12-14 02:19:47,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:47,970][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 1.7907150983810425, acc: 0.529411792755127)
                                                                               [2024-12-14 02:19:48,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:48,330][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 1.449216365814209, acc: 0.6538461446762085)
[2024-12-14 02:19:48,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:48,675][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 1.1109132766723633, acc: 0.7777777910232544)
[2024-12-14 02:19:48,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:49,013][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 1.642082929611206, acc: 0.574999988079071)
[2024-12-14 02:19:49,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:49,365][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 1.3172128200531006, acc: 0.550000011920929)
[2024-12-14 02:19:49,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:49,728][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.3599608838558197, acc: 0.8571428656578064)
[2024-12-14 02:19:49,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:50,084][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 1.1361299753189087, acc: 0.699999988079071)
[2024-12-14 02:19:50,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:50,412][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 1.1912733316421509, acc: 0.6875)
[2024-12-14 02:19:50,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:50,785][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.9915937185287476, acc: 0.5)
[2024-12-14 02:19:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:51,163][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 1.4830430746078491, acc: 0.6296296119689941)
                                    [2024-12-14 02:19:51,882][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:19:52,231][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:19:52,591][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:19:53,078][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:19:53,516][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:19:53,950][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:19:54,279][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:19:54,657][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:19:54,992][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:19:55,372][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:19:55,872][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:19:56,301][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:19:56,663][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:19:57,041][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:19:57,398][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:19:57,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:19:58,134][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:19:58,552][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:19:58,978][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:19:59,379][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:19:59,754][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:20:00,042][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:20:00,395][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:20:00,751][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:20:01,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:01,508][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:20:01,861][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                     [2024-12-14 02:20:02,214][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:20:02,559][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:20:02,957][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:20:03,288][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.9090805053710938, acc: 0.5384615659713745)
[2024-12-14 02:20:03,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:03,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:03,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:03,934][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 1.6192162036895752, acc: 0.5760869383811951)
[2024-12-14 02:20:04,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:04,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:04,472][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 1.8497436046600342, acc: 0.4545454680919647)
[2024-12-14 02:20:04,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:04,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:04,895][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 2.083561897277832, acc: 0.41489362716674805)
[2024-12-14 02:20:04,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:04,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:05,262][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 1.4423959255218506, acc: 0.5849056839942932)
[2024-12-14 02:20:05,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:05,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:05,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:05,615][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 1.7194557189941406, acc: 0.5166666507720947)
[2024-12-14 02:20:05,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:05,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:05,944][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 1.058954119682312, acc: 0.7209302186965942)
[2024-12-14 02:20:06,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:06,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:06,308][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 1.3173301219940186, acc: 0.6333333253860474)
[2024-12-14 02:20:06,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:06,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:06,683][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 2.193117141723633, acc: 0.46315789222717285)
[2024-12-14 02:20:06,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:06,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:07,016][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 1.6627612113952637, acc: 0.5444444417953491)
[2024-12-14 02:20:07,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:07,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:07,422][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 1.4569669961929321, acc: 0.6000000238418579)
[2024-12-14 02:20:07,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:07,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:07,907][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 1.6826311349868774, acc: 0.5917431116104126)
[2024-12-14 02:20:07,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:08,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:08,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:08,369][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 1.4620509147644043, acc: 0.6153846383094788)
[2024-12-14 02:20:08,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:08,936][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.2017430067062378, acc: 0.7368420958518982)
[2024-12-14 02:20:08,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:08,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:09,128][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 1.0989636182785034, acc: 0.6666666865348816)
[2024-12-14 02:20:09,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:09,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:09,451][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 2.2800369262695312, acc: 0.5)
[2024-12-14 02:20:09,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:09,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:09,735][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.7982739210128784, acc: 0.4444444477558136)
[2024-12-14 02:20:09,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:10,074][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 1.316757321357727, acc: 0.5714285969734192)
[2024-12-14 02:20:10,110][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.2138, device='cuda:0') eval_epoch_loss=tensor(1.8268, device='cuda:0') eval_epoch_acc=tensor(0.5175, device='cuda:0')
[2024-12-14 02:20:10,112][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:20:10,112][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:20:10,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:10,308][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_3_step_282_loss_1.8267682790756226/model.pt
[2024-12-14 02:20:10,313][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:20:10,313][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.8267682790756226
[2024-12-14 02:20:10,314][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5175062417984009
[2024-12-14 02:20:10,395][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.5042389631271362, acc: 0.5454545617103577)
[2024-12-14 02:20:10,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:10,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:10,745][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 2.046997308731079, acc: 0.48148149251937866)
[2024-12-14 02:20:10,768][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.8371436595916748, acc: 0.5454545617103577)
[2024-12-14 02:20:10,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:10,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:11,077][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 2.2469124794006348, acc: 0.3947368562221527)
[2024-12-14 02:20:11,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:11,349][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 1.9368650913238525, acc: 0.4677419364452362)
[2024-12-14 02:20:11,363][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 2.3181967735290527, acc: 0.4117647111415863)
[2024-12-14 02:20:11,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:11,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:11,713][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 1.8356844186782837, acc: 0.44999998807907104)
[2024-12-14 02:20:11,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:11,878][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.441182255744934, acc: 0.5909090638160706)
[2024-12-14 02:20:12,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:12,096][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 2.0890119075775146, acc: 0.40625)
[2024-12-14 02:20:12,170][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.40961796045303345, acc: 0.9047619104385376)
[2024-12-14 02:20:12,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:12,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:12,469][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.0351542234420776, acc: 0.7692307829856873)
[2024-12-14 02:20:12,499][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 2.238881826400757, acc: 0.36800000071525574)
[2024-12-14 02:20:12,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:12,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:12,767][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.3142744302749634, acc: 0.6129032373428345)
[2024-12-14 02:20:12,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:12,901][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 1.781268835067749, acc: 0.5384615659713745)
[2024-12-14 02:20:13,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:13,121][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 0.9352051615715027, acc: 0.699999988079071)
[2024-12-14 02:20:13,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:13,281][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 2.237670660018921, acc: 0.42236024141311646)
[2024-12-14 02:20:13,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:13,522][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 1.2590786218643188, acc: 0.6756756901741028)
[2024-12-14 02:20:13,649][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 2.2959861755371094, acc: 0.3711340129375458)
[2024-12-14 02:20:13,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:13,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:13,908][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 1.4214383363723755, acc: 0.5945945978164673)
[2024-12-14 02:20:14,013][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.6552510857582092, acc: 0.8181818127632141)
[2024-12-14 02:20:14,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:14,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:14,279][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 1.317767858505249, acc: 0.5675675868988037)
[2024-12-14 02:20:14,395][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 1.8512440919876099, acc: 0.5)
[2024-12-14 02:20:14,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:14,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:14,685][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 1.6827683448791504, acc: 0.5588235259056091)
[2024-12-14 02:20:14,788][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 1.2599185705184937, acc: 0.6896551847457886)
[2024-12-14 02:20:14,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:14,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:15,026][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.6956152319908142, acc: 0.7804877758026123)
[2024-12-14 02:20:15,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:15,241][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 1.251686930656433, acc: 0.7090908885002136)
[2024-12-14 02:20:15,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:15,394][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.34286361932754517, acc: 0.9200000166893005)
[2024-12-14 02:20:15,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:15,833][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.3991272449493408, acc: 0.9599999785423279)
[2024-12-14 02:20:15,786][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.7181971073150635, acc: 0.5824742317199707)
[2024-12-14 02:20:15,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:15,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:16,094][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 2.0590431690216064, acc: 0.4655172526836395)
[2024-12-14 02:20:16,114][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.49102795124053955, acc: 0.9032257795333862)
[2024-12-14 02:20:16,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:16,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:16,479][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 1.6260271072387695, acc: 0.5555555820465088)
[2024-12-14 02:20:16,491][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 1.3602317571640015, acc: 0.6315789222717285)
[2024-12-14 02:20:16,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:16,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:16,836][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 1.4696400165557861, acc: 0.6000000238418579)
[2024-12-14 02:20:16,850][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 1.6740658283233643, acc: 0.6315789222717285)
[2024-12-14 02:20:16,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:16,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:17,158][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 1.353598952293396, acc: 0.6315789222717285)
[2024-12-14 02:20:17,211][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 1.3742790222167969, acc: 0.625)
[2024-12-14 02:20:17,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:17,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:17,560][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 1.6732298135757446, acc: 0.625)
[2024-12-14 02:20:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:17,745][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.6233441829681396, acc: 0.5377358198165894)
[2024-12-14 02:20:17,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:17,933][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 1.6445398330688477, acc: 0.5660377144813538)
[2024-12-14 02:20:18,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:18,329][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 1.736694097518921, acc: 0.5416666865348816)
[2024-12-14 02:20:18,333][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 0.9725956916809082, acc: 0.698113203048706)
[2024-12-14 02:20:18,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:18,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:18,641][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 1.174938678741455, acc: 0.7222222089767456)
[2024-12-14 02:20:18,725][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 1.1085575819015503, acc: 0.7352941036224365)
[2024-12-14 02:20:18,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:18,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:19,058][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 1.473673701286316, acc: 0.6129032373428345)
[2024-12-14 02:20:19,093][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 1.5954759120941162, acc: 0.59375)
[2024-12-14 02:20:19,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:19,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:19,409][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 2.695741891860962, acc: 0.3333333432674408)
[2024-12-14 02:20:19,426][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.2346516847610474, acc: 0.6393442749977112)
[2024-12-14 02:20:19,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:19,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:19,702][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 2.084441661834717, acc: 0.4583333432674408)
[2024-12-14 02:20:19,741][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.7066246271133423, acc: 0.800000011920929)
[2024-12-14 02:20:19,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:19,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:20,109][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.4896450936794281, acc: 0.8421052694320679)
[2024-12-14 02:20:20,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:20,486][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 1.952555775642395, acc: 0.47826087474823)
[2024-12-14 02:20:20,530][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 2.446225881576538, acc: 0.37599998712539673)
[2024-12-14 02:20:20,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:20,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:20,854][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 2.1599173545837402, acc: 0.37078651785850525)
[2024-12-14 02:20:20,930][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 1.8155370950698853, acc: 0.5416666865348816)
[2024-12-14 02:20:20,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:21,194][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 2.100325107574463, acc: 0.44594594836235046)
[2024-12-14 02:20:21,296][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 1.5823402404785156, acc: 0.5783132314682007)
[2024-12-14 02:20:21,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:21,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:21,628][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 2.133074998855591, acc: 0.42307692766189575)
[2024-12-14 02:20:21,653][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.3263357877731323, acc: 0.6206896305084229)
[2024-12-14 02:20:21,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:21,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:21,976][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 1.096242904663086, acc: 0.7727272510528564)
[2024-12-14 02:20:21,992][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 2.2074739933013916, acc: 0.40816327929496765)
[2024-12-14 02:20:22,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:22,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:22,254][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 1.168906331062317, acc: 0.5454545617103577)
[2024-12-14 02:20:22,323][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.22474153339862823, acc: 0.9583333134651184)
[2024-12-14 02:20:22,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:22,761][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.5591, device='cuda:0') eval_epoch_loss=tensor(2.1470, device='cuda:0') eval_epoch_acc=tensor(0.4947, device='cuda:0')
[2024-12-14 02:20:22,762][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:20:22,762][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:20:22,994][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_3_step_425_loss_2.1469979286193848/model.pt
[2024-12-14 02:20:23,000][sla - Training Epoch: 3/10, step 272/574 completed (loss: 1.0273163318634033, acc: 0.7666666507720947)
[2024-12-14 02:20:23,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:23,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:23,269][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 1.0086662769317627, acc: 0.6774193644523621)
[2024-12-14 02:20:23,313][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 1.913358211517334, acc: 0.44999998807907104)
[2024-12-14 02:20:23,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:23,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:23,608][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 1.387094259262085, acc: 0.65625)
[2024-12-14 02:20:23,655][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 1.36600661277771, acc: 0.6567164063453674)
[2024-12-14 02:20:23,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:23,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:23,880][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.8271188735961914, acc: 0.800000011920929)
[2024-12-14 02:20:23,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:23,989][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 1.3776923418045044, acc: 0.6538461446762085)
[2024-12-14 02:20:24,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:24,148][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 1.4176446199417114, acc: 0.6896551847457886)
[2024-12-14 02:20:24,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:24,355][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 1.740882158279419, acc: 0.4888888895511627)
[2024-12-14 02:20:24,432][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 1.260299801826477, acc: 0.5600000023841858)
[2024-12-14 02:20:24,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:24,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:24,688][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 1.4721152782440186, acc: 0.5967742204666138)
[2024-12-14 02:20:24,744][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 1.9056153297424316, acc: 0.42553192377090454)
[2024-12-14 02:20:24,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:24,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:25,007][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.9342411160469055, acc: 0.7599999904632568)
[2024-12-14 02:20:25,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:25,128][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 1.7649174928665161, acc: 0.5625)
[2024-12-14 02:20:25,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:25,328][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 2.0562689304351807, acc: 0.4444444477558136)
[2024-12-14 02:20:25,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:25,482][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 1.4227968454360962, acc: 0.6818181872367859)
[2024-12-14 02:20:25,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:25,670][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.6593101024627686, acc: 0.22857142984867096)
[2024-12-14 02:20:25,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:25,875][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 2.1364076137542725, acc: 0.4337349534034729)
[2024-12-14 02:20:26,018][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 2.2149646282196045, acc: 0.38461539149284363)
[2024-12-14 02:20:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:26,363][root][INFO] - Training Epoch:NFO] - modality encoder
[2024-12-14 02:20:26,571][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.5987091660499573, acc: 0.8399999737739563)
[2024-12-14 02:20:26,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:26,913][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 1.1036574840545654, acc: 0.7272727489471436)
                                                                                 [2024-12-14 02:20:27,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:27,287][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 1.2924232482910156, acc: 0.6111111044883728)
                                                                                                                                                              [2024-12-14 02:20:27,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:27,661][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 1.4653637409210205, acc: 0.6136363744735718)
                                                                                                                                                                                                                         [2024-12-14 02:20:27,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:28,040][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.4223795533180237, acc: 0.8571428656578064)
                                                                    [2024-12-14 02:20:28,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:28,429][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 1.8672930002212524, acc: 0.5384615659713745)
                                                                                                                                               [2024-12-14 02:20:28,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:28,893][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 1.9893479347229004, acc: 0.5303030014038086)
                                                                               [2024-12-14 02:20:29,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:29,571][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 2.339162826538086, acc: 0.37599998712539673)
                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:20:29,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:29,974][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 2.050286054611206, acc: 0.4677419364452362)
                                                                                 [2024-12-14 02:20:30,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:30,624][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 2.0285074710845947, acc: 0.45771142840385437)
                                                                                                                                                                                                                        [2024-12-14 02:20:30,700][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:20:30,939][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 1.9749242067337036, acc: 0.4716981053352356)
                                                                               [2024-12-14 02:20:31,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:31,357][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 0.9252511858940125, acc: 0.7045454382896423)
                                                                               [2024-12-14 02:20:31,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:31,681][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 1.303074836730957, acc: 0.6521739363670349)
[2024-12-14 02:20:31,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:32,077][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 1.4456106424331665, acc: 0.6538461446762085)
                                                                                                                                                              [2024-12-14 02:20:32,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:32,484][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.9112685918807983, acc: 0.7857142686843872)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:20:32,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:32,815][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 1.8236056566238403, acc: 0.5223880410194397)
[2024-12-14 02:20:32,904][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:20:33,150][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 1.6009076833724976, acc: 0.5833333134651184)
[2024-12-14 02:20:33,230][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:20:33,477][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 1.6325289011001587, acc: 0.5)
                                    [2024-12-14 02:20:33,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:33,825][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 1.780820369720459, acc: 0.5128205418586731)
                                                                                [2024-12-14 02:20:33,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:34,175][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 2.081819534301758, acc: 0.46052631735801697)
                                                                               [2024-12-14 02:20:34,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:34,500][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 1.73048996925354, acc: 0.5510203838348389)
                                                                                 [2024-12-14 02:20:34,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:34,848][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 1.3728113174438477, acc: 0.6666666865348816)
                                                                               [2024-12-14 02:20:34,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:35,190][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 2.0453898906707764, acc: 0.4536082446575165)
[2024-12-14 02:20:35,274][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:20:35,517][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 1.6746786832809448, acc: 0.5571428537368774)
[2024-12-14 02:20:35,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:35,888][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.955787181854248, acc: 0.4651162922382355)
/10, step 352/574 completed (loss: 1.8278623819351196, acc: 0.5111111402511597)
[2024-12-14 02:20:35,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:35,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:36,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:36,123][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.7023216485977173, acc: 0.739130437374115)
[2024-12-14 02:20:36,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:36,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:36,502][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 1.8269442319869995, acc: 0.5)
[2024-12-14 02:20:36,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:36,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:36,859][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 2.309169292449951, acc: 0.4065934121608734)
[2024-12-14 02:20:36,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:36,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:37,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:37,353][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.9032667875289917, acc: 0.52173912525177)
[2024-12-14 02:20:37,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:37,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:37,726][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 1.8376845121383667, acc: 0.510869562625885)
[2024-12-14 02:20:37,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:37,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:38,123][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 2.070997476577759, acc: 0.4285714328289032)
[2024-12-14 02:20:38,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:38,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:38,487][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.3374766409397125, acc: 0.875)
[2024-12-14 02:20:38,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:38,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:38,800][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.8541349172592163, acc: 0.7307692170143127)
[2024-12-14 02:20:38,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:38,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:39,097][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.4574121236801147, acc: 0.707317054271698)
[2024-12-14 02:20:39,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:39,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:39,424][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 1.6712260246276855, acc: 0.5555555820465088)
[2024-12-14 02:20:39,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:39,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:39,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:39,819][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 1.8208160400390625, acc: 0.4868420958518982)
[2024-12-14 02:20:39,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:40,004][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:20:40,214][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 1.7193922996520996, acc: 0.6097561120986938)
[2024-12-14 02:20:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:40,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:40,572][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 1.5596064329147339, acc: 0.5454545617103577)
[2024-12-14 02:20:40,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:41,209][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 2.286323308944702, acc: 0.4104803502559662)
                                                                                                                                                                                                                                              [2024-12-14 02:20:41,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:41,570][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 2.1324448585510254, acc: 0.4270833432674408)
                                                                               [2024-12-14 02:20:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:41,933][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 2.183884620666504, acc: 0.4049079716205597)
                                                                                [2024-12-14 02:20:42,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:42,259][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 2.1315789222717285, acc: 0.40287768840789795)
[2024-12-14 02:20:42,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:42,655][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 2.2884979248046875, acc: 0.39698493480682373)
                                                              [2024-12-14 02:20:42,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:43,054][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 1.0401599407196045, acc: 0.7222222089767456)
                     [2024-12-14 02:20:43,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:43,408][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 1.1695016622543335, acc: 0.6666666865348816)
[2024-12-14 02:20:43,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:43,738][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 0.919680655002594, acc: 0.7407407164573669)
[2024-12-14 02:20:43,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:44,122][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 1.2537678480148315, acc: 0.550000011920929)
[2024-12-14 02:20:44,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:44,476][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 0.7037418484687805, acc: 0.8500000238418579)
[2024-12-14 02:20:44,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:44,882][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 1.3322360515594482, acc: 0.6034482717514038)
                                                                                        [2024-12-14 02:20:44,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:45,201][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 0.874514639377594, acc: 0.774193525314331)
                                                                                  [2024-12-14 02:20:45,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:45,516][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.5419974327087402, acc: 0.8947368264198303)
                                                                               [2024-12-14 02:20:45,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:45,902][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 1.581352949142456, acc: 0.6666666865348816)
                                                                    [2024-12-14 02:20:46,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:46,290][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 1.4036561250686646, acc: 0.523809552192688)
                                                                               [2024-12-14 02:20:46,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:46,669][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 1.242537498474121, acc: 0.5)
                [2024-12-14 02:20:46,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:47,051][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.8596317768096924, acc: 0.5076923370361328)
                                                                               [2024-12-14 02:20:47,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:47,428][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 1.0733646154403687, acc: 0.699999988079071)
[2024-12-14 02:20:47,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:47,731][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 1.3443058729171753, acc: 0.6206896305084229)
[2024-12-14 02:20:47,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:48,086][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 1.6661068201065063, acc: 0.5490196347236633)
[2024-12-14 02:20:48,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:48,444][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 1.464581847190857, acc: 0.517241358757019)
[2024-12-14 02:20:48,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:48,811][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.4947441518306732, acc: 0.8421052694320679)
[2024-12-14 02:20:48,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:49,180][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 1.9674664735794067, acc: 0.5263158082962036)
[2024-12-14 02:20:49,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:49,557][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.8002146482467651, acc: 0.4732142984867096)
                     [2024-12-14 02:20:49,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:49,963][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 1.888721227645874, acc: 0.47191011905670166)
                                                                                                                                                                                                             [2024-12-14 02:20:50,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:50,281][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 2.109910011291504, acc: 0.4606741666793823)
                                                                                [2024-12-14 02:20:50,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:50,633][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.3268649578094482, acc: 0.39007091522216797)
                                                                                                                                                             [2024-12-14 02:20:50,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:51,038][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 2.291221857070923, acc: 0.4021739065647125)
                                                                                [2024-12-14 02:20:51,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:51,422][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.5933733582496643, acc: 0.8399999737739563)
                                                                             [2024-12-14 02:20:51,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:51,801][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.7280927896499634, acc: 0.807692289352417)
                                                                                                                                                               [2024-12-14 02:20:51,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:52,130][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.64998459815979, acc: 0.7407407164573669)
                                                                                 [2024-12-14 02:20:52,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:52,469][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 1.9006682634353638, acc: 0.48148149251937866)
                                                                              [2024-12-14 02:20:52,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:52,789][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 1.4603559970855713, acc: 0.5849056839942932)
[2024-12-14 02:20:52,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:53,128][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 1.0916295051574707, acc: 0.6896551847457886)
[2024-12-14 02:20:53,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:53,713][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.848305583000183, acc: 0.477477490901947)
                                                                                                                                                               [2024-12-14 02:20:53,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:54,153][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.6502107381820679, acc: 0.6056337952613831)
                                                                                                                                                              [2024-12-14 02:20:54,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:54,462][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.6355942487716675, acc: 0.8999999761581421)
[2024-12-14 02:20:54,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:54,794][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.39108091592788696, acc: 0.8999999761581421)
                                                                [2024-12-14 02:20:54,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:55,175][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.8768078684806824, acc: 0.807692289352417)
                                                                               [2024-12-14 02:20:56,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:57,853][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 1.936315655708313, acc: 0.4714285731315613)
evice='cuda:0') eval_epoch_acc=tensor(0.5114, device='cuda:0')
[2024-12-14 02:20:55,564][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:20:55,565][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:20:55,620][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 1.6648188829421997, acc: 0.5441176295280457)
[2024-12-14 02:20:55,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:55,933][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_3_step_282_loss_1.8453893661499023/model.pt
[2024-12-14 02:20:55,936][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:20:55,937][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.8453893661499023
[2024-12-14 02:20:55,937][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5113601088523865
[2024-12-14 02:20:55,982][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 1.6743401288986206, acc: 0.5600000023841858)
[2024-12-14 02:20:56,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:56,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:56,352][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 2.0241916179656982, acc: 0.4722222089767456)
[2024-12-14 02:20:56,360][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 1.0207990407943726, acc: 0.6969696879386902)
[2024-12-14 02:20:56,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:56,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:56,630][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 2.13820481300354, acc: 0.3684210479259491)
[2024-12-14 02:20:56,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:56,710][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 1.3357551097869873, acc: 0.6363636255264282)
[2024-12-14 02:20:56,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:56,884][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 2.2442610263824463, acc: 0.3529411852359772)
[2024-12-14 02:20:56,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:57,068][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.7086123824119568, acc: 0.8064516186714172)
[2024-12-14 02:20:57,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:57,173][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 1.8346021175384521, acc: 0.42500001192092896)
[2024-12-14 02:20:57,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:57,447][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 1.0778757333755493, acc: 0.7407407164573669)
[2024-12-14 02:20:57,525][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 2.083789825439453, acc: 0.390625)
[2024-12-14 02:20:57,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:57,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:57,791][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.8906164765357971, acc: 0.800000011920929)
[2024-12-14 02:20:57,875][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 2.2888476848602295, acc: 0.36000001430511475)
[2024-12-14 02:20:57,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:57,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:58,143][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.9354138970375061, acc: 0.75)
[2024-12-14 02:20:58,170][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 1.8242980241775513, acc: 0.47252747416496277)
[2024-12-14 02:20:58,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:58,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:58,483][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 1.0407841205596924, acc: 0.6666666865348816)
[2024-12-14 02:20:58,514][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 2.3043246269226074, acc: 0.40993788838386536)
[2024-12-14 02:20:58,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:58,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:58,838][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.7928940653800964, acc: 0.7692307829856873)
[2024-12-14 02:20:58,921][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 2.3158373832702637, acc: 0.37628865242004395)
[2024-12-14 02:20:58,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:59,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:59,392][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 1.4845725297927856, acc: 0.5833333134651184)
[2024-12-14 02:20:59,256][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.6848575472831726, acc: 0.8181818127632141)
[2024-12-14 02:20:59,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:59,505][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.883712649345398, acc: 0.7142857313156128)
[2024-12-14 02:20:59,580][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 1.8987103700637817, acc: 0.5714285969734192)
[2024-12-14 02:20:59,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:59,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:20:59,781][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.8363720774650574, acc: 0.8333333134651184)
[2024-12-14 02:20:59,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:00,011][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 1.2954604625701904, acc: 0.6896551847457886)
[2024-12-14 02:21:00,088][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.9394726157188416, acc: 0.7575757503509521)
[2024-12-14 02:21:00,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:00,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:00,387][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.6752480864524841, acc: 0.8181818127632141)
[2024-12-14 02:21:00,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:00,519][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 1.2381535768508911, acc: 0.6727272868156433)
[2024-12-14 02:21:00,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:00,699][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 1.9519760608673096, acc: 0.47058823704719543)
[2024-12-14 02:21:00,778][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:21:01,011][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 1.4142922163009644, acc: 0.6538461446762085)
[2024-12-14 02:21:01,078][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.7421530485153198, acc: 0.561855673789978)
[2024-12-14 02:21:01,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:01,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:01,331][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 1.102411150932312, acc: 0.7222222089767456)
[2024-12-14 02:21:01,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:01,450][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 2.075198173522949, acc: 0.4655172526836395)
[2024-12-14 02:21:01,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:01,664][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 1.8062260150909424, acc: 0.574999988079071)
[2024-12-14 02:21:01,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:01,837][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 1.611461877822876, acc: 0.5925925970077515)
[2024-12-14 02:21:01,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:02,026][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 1.4356212615966797, acc: 0.6000000238418579)
[2024-12-14 02:21:02,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:02,220][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 1.6942965984344482, acc: 0.6052631735801697)
[2024-12-14 02:21:02,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:02,394][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.34143850207328796, acc: 0.8571428656578064)
[2024-12-14 02:21:02,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:02,812][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 2.1243889331817627, acc: 0.4552238881587982)
2024-12-14 02:21:02,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:02,739][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 1.3420734405517578, acc: 0.699999988079071)
[2024-12-14 02:21:02,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:02,955][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 1.6306737661361694, acc: 0.5625)
[2024-12-14 02:21:03,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:03,076][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 0.9274576306343079, acc: 0.75)
[2024-12-14 02:21:03,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:03,329][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 1.5859766006469727, acc: 0.5849056839942932)
[2024-12-14 02:21:03,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:03,454][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.7177609205245972, acc: 0.5833333134651184)
[2024-12-14 02:21:03,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:03,654][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 1.0047898292541504, acc: 0.698113203048706)
[2024-12-14 02:21:03,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:03,777][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 1.2018731832504272, acc: 0.7037037014961243)
[2024-12-14 02:21:03,974][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 1.0725774765014648, acc: 0.7352941036224365)
[2024-12-14 02:21:04,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:04,324][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 1.6116490364074707, acc: 0.59375)
[2024-12-14 02:21:04,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:04,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:04,701][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.2726116180419922, acc: 0.6229507923126221)
[2024-12-14 02:21:04,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:04,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:05,008][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.6602427363395691, acc: 0.8666666746139526)
[2024-12-14 02:21:05,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:05,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:05,342][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.4569407105445862, acc: 0.8947368264198303)
[2024-12-14 02:21:05,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:05,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:05,686][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 1.8799195289611816, acc: 0.49275362491607666)
[2024-12-14 02:21:05,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:05,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:06,103][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 1.6886299848556519, acc: 0.5555555820465088)
[2024-12-14 02:21:06,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:06,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:06,439][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 1.5006532669067383, acc: 0.5783132314682007)
[2024-12-14 02:21:06,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:06,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:06,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:06,790][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 2.0860791206359863, acc: 0.42307692766189575)
[2024-12-14 02:21:06,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:07,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:07,347][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 1.2967207431793213, acc: 0.6000000238418579)
                                                                               [2024-12-14 02:21:07,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:07,670][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 1.2063567638397217, acc: 0.699999988079071)
                                                                                 [2024-12-14 02:21:07,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:08,020][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 0.8528029918670654, acc: 0.7272727489471436)
                                                                               [2024-12-14 02:21:08,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:08,410][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.704537272453308, acc: 0.5846154093742371)
                                                                                [2024-12-14 02:21:08,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:08,801][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 1.7222331762313843, acc: 0.5625)
                                                                                           [2024-12-14 02:21:08,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:09,233][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 1.140931487083435, acc: 0.75)
               [2024-12-14 02:21:09,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:09,601][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.777233600616455, acc: 0.5757575631141663)
                                                                                [2024-12-14 02:21:09,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:09,971][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.621350109577179, acc: 0.8125)
                                                                                             [2024-12-14 02:21:10,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:10,306][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.7031846046447754, acc: 0.774193525314331)
                                                                                                                                                               [2024-12-14 02:21:10,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:10,642][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.36290907859802246, acc: 0.8695651888847351)
                                                                              [2024-12-14 02:21:10,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:10,991][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 1.5640813112258911, acc: 0.5333333611488342)
                                                                              [2024-12-14 02:21:11,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:11,392][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 1.392423152923584, acc: 0.5853658318519592)
                                                                                 [2024-12-14 02:21:11,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:11,753][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 0.8972296118736267, acc: 0.7714285850524902)
                                                                               [2024-12-14 02:21:11,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:12,126][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 0.9567328095436096, acc: 0.7368420958518982)
                                                                               [2024-12-14 02:21:12,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:12,481][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 1.918765664100647, acc: 0.44736841320991516)
[2024-12-14 02:21:12,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:12,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:12,548][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 0.8103375434875488, acc: 0.6842105388641357)
[2024-12-14 02:21:12,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:12,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:12,889][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.5839190483093262, acc: 0.7857142686843872)
[2024-12-14 02:21:13,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:13,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:13,279][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 1.7546091079711914, acc: 0.40740740299224854)
[2024-12-14 02:21:13,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:13,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:13,635][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.8541747331619263, acc: 0.71875)
[2024-12-14 02:21:13,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:13,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:13,991][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 1.7981491088867188, acc: 0.5806451439857483)
[2024-12-14 02:21:14,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:14,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:14,352][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 1.62590754032135, acc: 0.5614035129547119)
[2024-12-14 02:21:14,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:14,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:14,663][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 2.0600690841674805, acc: 0.40625)
[2024-12-14 02:21:14,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:15,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:15,046][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 1.0374075174331665, acc: 0.7666666507720947)
[2024-12-14 02:21:15,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:15,392][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 1.7973089218139648, acc: 0.42105263471603394)
[2024-12-14 02:21:15,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:15,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:15,746][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 2.143017530441284, acc: 0.47999998927116394)
[2024-12-14 02:21:15,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:15,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:16,138][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 2.1792235374450684, acc: 0.40229883790016174)
[2024-12-14 02:21:16,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:16,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:16,530][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 2.2971277236938477, acc: 0.3191489279270172)
[2024-12-14 02:21:16,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:16,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:16,916][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 2.3190481662750244, acc: 0.39759036898612976)
[2024-12-14 02:21:16,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:17,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:17,316][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.9191113114356995, acc: 0.695652186870575)
[2024-12-14 02:74 completed (loss: 1.5604000091552734, acc: 0.5194805264472961)
[2024-12-14 02:21:17,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:17,921][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 1.1901918649673462, acc: 0.6666666865348816)
                                                                             [2024-12-14 02:21:18,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:18,281][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 1.3069612979888916, acc: 0.6724137663841248)
                                                                              [2024-12-14 02:21:18,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:18,663][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 1.5873357057571411, acc: 0.488095223903656)
                                                                                                                                                               [2024-12-14 02:21:18,765][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:21:19,006][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 1.379449725151062, acc: 0.5789473652839661)
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:21:19,674][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:21:20,030][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:21:20,430][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:21:20,852][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:21:21,337][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:21:21,778][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:21:22,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:22,015][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 1.7412822246551514, acc: 0.5)
[2024-12-14 02:21:22,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:22,353][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 2.3081343173980713, acc: 0.4065934121608734)
[2024-12-14 02:21:22,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:22,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:22,853][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.8262767791748047, acc: 0.530434787273407)
[2024-12-14 02:21:22,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:22,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:23,216][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 1.783124566078186, acc: 0.52173912525177)
[2024-12-14 02:21:23,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:23,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:23,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:23,549][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 2.0823707580566406, acc: 0.44897958636283875)
[2024-12-14 02:21:23,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:23,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:23,928][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.27288520336151123, acc: 0.875)
[2024-12-14 02:21:24,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:24,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:24,249][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.8856874704360962, acc: 0.692307710647583)
[2024-12-14 02:21:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:24,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:24,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:24,616][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.4661922454833984, acc: 0.6829268336296082)
[2024-12-14 02:21:24,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:24,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:24,974][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 1.7598637342453003, acc: 0.5555555820465088)
[2024-12-14 02:21:25,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:25,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:25,331][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 1.8701491355895996, acc: 0.44736841320991516)
[2024-12-14 02:21:25,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:25,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:25,710][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 1.5807247161865234, acc: 0.5853658318519592)
[2024-12-14 02:21:25,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:26,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:26,050][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 1.5701016187667847, acc: 0.5757575631141663)
[2024-12-14 02:21:26,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:26,411][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.5665540099143982, acc: 0.8333333134651184)
[2024-12-14 02:21:26,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:26,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:26,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:26,782][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.31198498606681824, acc: 0.9130434989929199)
[2024-12-14 02:21:26,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:27,288][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.6452270746231079, acc: 0.8214285969734192)
[2024-12-14 02:21:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:27,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:27,517][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 0.893795371055603, acc: 0.78125)
[2024-12-14 02:21:27,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:27,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:27,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:28,124][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 1.8808315992355347, acc: 0.4909090995788574)
[2024-12-14 02:21:28,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:28,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:28,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:29,012][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 1.3778492212295532, acc: 0.6792452931404114)
[2024-12-14 02:21:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:29,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:29,366][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 1.6084394454956055, acc: 0.5333333611488342)
[2024-12-14 02:21:29,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:29,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:29,731][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 1.570389747619629, acc: 0.5357142686843872)
[2024-12-14 02:21:29,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:29,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:30,069][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.8495483994483948, acc: 0.800000011920929)
[2024-12-14 02:21:30,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:30,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:30,488][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.27551281452178955, acc: 0.9200000166893005)
[2024-12-14 02:21:30,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:30,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:30,875][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.5177845358848572, acc: 0.8695651888847351)
[2024-12-14 02:21:31,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:31,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:31,271][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 1.5419845581054688, acc: 0.6041666865348816)
[2024-12-14 02:21:31,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:31,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:31,609][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 1.670915126800537, acc: 0.5263158082962036)
[2024-12-14 02:21:31,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:31,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:32,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:32,178][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 1.800019383430481, acc: 0.56886225938797)
[2024-12-14 02:21:32,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:32,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:32,624][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 1.6290619373321533, acc: 0.5413534045219421)
[2024-12-14 02:21:32,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:33,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:33,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:33,835][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:21:34,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:34,560][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:21:34,977][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:21:35,335][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:21:35,731][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:21:36,083][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:21:36,545][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:21:36,879][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:21:37,209][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:21:37,564][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                       [2024-12-14 02:21:37,906][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:21:38,230][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:21:38,588][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:21:38,987][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:21:39,290][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:21:39,614][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:21:39,913][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:21:40,320][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:21:40,679][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:21:41,083][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:21:41,416][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:21:41,744][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:21:42,151][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:21:42,680][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:21:42,960][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:21:43,244][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:21:43,614][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:21:44,015][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                  [2024-12-14 02:21:44,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:44,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:44,350][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 1.1339077949523926, acc: 0.6724137663841248)
[2024-12-14 02:21:44,371][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.9021062850952148, acc: 0.75)
[2024-12-14 02:21:44,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:44,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:44,748][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.7754022479057312, acc: 0.7142857313156128)
[2024-12-14 02:21:44,770][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 1.7921496629714966, acc: 0.5522388219833374)
[2024-12-14 02:21:44,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:44,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:45,130][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.7976287603378296, acc: 0.800000011920929)
[2024-12-14 02:21:45,169][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 1.612542986869812, acc: 0.5833333134651184)
[2024-12-14 02:21:45,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:45,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:45,458][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.8891657590866089, acc: 0.7575757503509521)
[2024-12-14 02:21:45,529][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 1.7117114067077637, acc: 0.489130437374115)
[2024-12-14 02:21:45,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:45,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:45,805][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.5490151047706604, acc: 0.8181818127632141)
[2024-12-14 02:21:45,918][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 1.8305257558822632, acc: 0.4871794879436493)
[2024-12-14 02:21:45,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:46,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:46,151][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 1.771857738494873, acc: 0.529411792755127)
[2024-12-14 02:21:46,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:46,268][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 2.0684287548065186, acc: 0.4868420958518982)
[2024-12-14 02:21:46,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:46,499][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 1.2688052654266357, acc: 0.6538461446762085)
[2024-12-14 02:21:46,613][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 1.7558577060699463, acc: 0.5918367505073547)
[2024-12-14 02:21:46,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:46,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:46,880][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 1.4173556566238403, acc: 0.5)
[2024-12-14 02:21:46,978][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 1.188119888305664, acc: 0.6666666865348816)
[2024-12-14 02:21:46,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:47,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:47,256][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 1.7997047901153564, acc: 0.6000000238418579)
[2024-12-14 02:21:47,329][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 2.0074219703674316, acc: 0.4329896867275238)
[2024-12-14 02:21:47,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:47,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:47,608][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 1.3977853059768677, acc: 0.6000000238418579)
[2024-12-14 02:21:47,701][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 1.7200793027877808, acc: 0.5)
[2024-12-14 02:21:47,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:47,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:47,979][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.16235654056072235, acc: 0.9523809552192688)
[2024-12-14 02:21:48,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:48,102][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.9610315561294556, acc: 0.44186046719551086)
[2024-12-14 02:21:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:48,371][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 1.462287187576294, acc: 0.6666666865348816)
[2024-12-14 02:21:48,434][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 2.0241522789001465, acc: 0.4285714328289032)
[2024-12-14 02:21:48,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:48,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:48,713][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 1.2835180759429932, acc: 0.6875)
[2024-12-14 02:21:48,751][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 1.9218981266021729, acc: 0.48148149251937866)
[2024-12-14 02:21:48,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:48,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:49,116][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 1.5715296268463135, acc: 0.5555555820465088)
[2024-12-14 02:21:49,121][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.6263388395309448, acc: 0.5555555820465088)
[2024-12-14 02:21:49,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:49,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:49,456][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 1.1789032220840454, acc: 0.71875)
[2024-12-14 02:21:49,458][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 1.1290011405944824, acc: 0.7407407164573669)
[2024-12-14 02:21:49,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:49,833][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 1.2964081764221191, acc: 0.6153846383094788)
[2024-12-14 02:21:49,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:50,174][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 1.6817206144332886, acc: 0.6086956262588501)
[2024-12-14 02:21:50,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:50,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:50,539][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 1.6744353771209717, acc: 0.4642857015132904)
[2024-12-14 02:21:50,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:50,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:50,925][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 2.074364185333252, acc: 0.4457831382751465)
[2024-12-14 02:21:50,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:51,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:51,294][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 1.5643800497055054, acc: 0.5675675868988037)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:21:51,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:51,631][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 0.8090991973876953, acc: 0.7407407164573669)
[2024-12-14 02:21:51,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:52,067][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 1.8419878482818604, acc: 0.5080214142799377)
                                                                                                                                                                                                                                            [2024-12-14 02:21:52,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:52,422][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 1.2478221654891968, acc: 0.6290322542190552)
                                                                               [2024-12-14 02:21:52,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:52,762][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 1.6408662796020508, acc: 0.5213675498962402)
[2024-12-14 02:21:52,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:53,093][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 2.1554384231567383, acc: 0.4030612111091614)
[2024-12-14 02:21:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:53,453][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 2.0651447772979736, acc: 0.43396225571632385)
                                                                                                                                                                                                                                             [2024-12-14 02:21:53,851][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=4.7625, train_epoch_loss=1.5608, epoch time 362.49209190905094s
[2024-12-14 02:21:53,851][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:21:53,851][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-14 02:21:53,852][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:21:53,852][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-12-14 02:21:53,852][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:21:54,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:54,693][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 1.2223386764526367, acc: 0.6296296119689941)
                                                                                                                                                                                                                                                                                                          [2024-12-14 02:21:54,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:55,031][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 1.5546549558639526, acc: 0.5199999809265137)
                                                                                 [2024-12-14 02:21:55,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:55,378][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 2.2502083778381348, acc: 0.4054054021835327)
                                                                                 [2024-12-14 02:21:55,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:55,708][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 1.998762845993042, acc: 0.31578946113586426)
[2024-12-14 02:21:55,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:56,085][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 1.9789282083511353, acc: 0.5405405163764954)
[2024-12-14 02:21:56,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:56,481][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 1.6516435146331787, acc: 0.4642857015132904)
                                                                                                                                                                                                                                                  [2024-12-14 02:21:56,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:56,876][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 2.0433006286621094, acc: 0.4693877696990967)
                                                                                 [2024-12-14 02:21:56,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:57,187][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 1.2645561695098877, acc: 0.6333333253860474)
                                                                                 [2024-12-14 02:21:57,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:57,566][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.3001972734928131, acc: 0.9090909361839294)
                                                                                [2024-12-14 02:21:57,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:57,907][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.5791066884994507, acc: 0.8461538553237915)
                                                                                [2024-12-14 02:21:58,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:58,303][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.8099271059036255, acc: 0.8148148059844971)
                                                                                                                                                               [2024-12-14 02:21:58,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:58,692][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 1.598459005355835, acc: 0.5641025900840759)
  [2024-12-14 02:21:58,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:59,056][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 1.2778632640838623, acc: 0.6060606241226196)
                                                                 [2024-12-14 02:21:59,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:59,413][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 1.5808165073394775, acc: 0.6304348111152649)
                                                                               [2024-12-14 02:21:59,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:21:59,742][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 1.8541470766067505, acc: 0.4901960790157318)
                                                                                                                                                              [2024-12-14 02:21:59,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:00,125][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 1.36440110206604, acc: 0.5918367505073547)
                                                                                  [2024-12-14 02:22:00,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:00,477][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.542589008808136, acc: 0.8421052694320679)
                                                                                [2024-12-14 02:22:00,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:00,866][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 1.2851064205169678, acc: 0.5833333134651184)
                                                                                [2024-12-14 02:22:00,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:01,215][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.62470543384552, acc: 0.8421052694320679)
[2024-12-14 02:22:01,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:01,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:01,421][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 1.9112117290496826, acc: 0.4736842215061188)
[2024-12-14 02:22:01,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:01,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:01,794][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.666058897972107, acc: 0.4732142984867096)
[2024-12-14 02:22:01,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:02,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:02,142][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 1.8079783916473389, acc: 0.5056179761886597)
[2024-12-14 02:22:02,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:02,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:02,451][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 2.0722904205322266, acc: 0.4606741666793823)
[2024-12-14 02:22:02,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:02,818][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.269817352294922, acc: 0.39716312289237976)
[2024-12-14 02:22:02,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:03,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:03,161][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 2.2268335819244385, acc: 0.4021739065647125)
[2024-12-14 02:22:03,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:03,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:03,477][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.7534272074699402, acc: 0.8799999952316284)
[2024-12-14 02:22:03,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:03,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:03,802][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.6461557149887085, acc: 0.8846153616905212)
[2024-12-14 02:22:03,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:04,119][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.6513118743896484, acc: 0.7777777910232544)
[2024-12-14 02:22:04,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:04,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:04,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:04,472][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 1.746795654296875, acc: 0.5185185074806213)
[2024-12-14 02:22:04,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:04,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:04,818][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 1.3807902336120605, acc: 0.6226415038108826)
[2024-12-14 02:22:04,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:05,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:05,121][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 1.160651683807373, acc: 0.6206896305084229)
[2024-12-14 02:22:05,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:05,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:05,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:05,703][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.8926236629486084, acc: 0.477477490901947)
[2024-12-14 02:22:05,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:05,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:06,141][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.5959614515304565, acc: 0.577464759349823)
[2024-12-14 02:22:06,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:06,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:06,440][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.28532224893569946, acc: 0.949999988079071)
[2024-12-14 02:22:06,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:06,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:06,769][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.4710359573364258, acc: 0.8999999761581421)
[2024-12-14 02:22:06,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:07,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:07,120][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.8822753429412842, acc: 0.807692289352417)
[2024-12-14 02:22:07,392][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:22:07,744][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:22:08,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:08,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:08,484][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:22:08,793][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:22:09,130][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:22:09,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:09,538][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 1.959655523300171, acc: 0.4642857015132904)
[2024-12-14 02:22:09,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:09,801][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:22:10,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:10,306][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 1.8571736812591553, acc: 0.5476190447807312)
                                                                              [2024-12-14 02:22:10,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:10,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:10,673][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 1.2408241033554077, acc: 0.5714285969734192)
[2024-12-14 02:22:10,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:10,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:11,027][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 1.570299506187439, acc: 0.5666666626930237)
[2024-12-14 02:22:11,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:11,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:11,718][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 1.505678653717041, acc: 0.6111111044883728)
[2024-12-14 02:22:11,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:11,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:12,120][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.4101901054382324, acc: 0.8461538553237915)
[2024-12-14 02:22:12,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:12,544][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.6983762979507446, acc: 0.8846153616905212)
                                                                                [2024-12-14 02:22:12,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:12,920][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.47126591205596924, acc: 0.8888888955116272)
                                                                                                                                                              [2024-12-14 02:22:13,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:13,314][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 1.1175785064697266, acc: 0.6428571343421936)
 [2024-12-14 02:22:13,390][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:22:13,631][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.6954810619354248, acc: 0.7222222089767456)
[2024-12-14 02:22:13,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:14,046][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 1.2106870412826538, acc: 0.6842105388641357)
[2024-12-14 02:22:14,169][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:22:14,462][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.3107984066009521, acc: 0.682539701461792)
                                                                                                                                                               [2024-12-14 02:22:14,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:14,842][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.9363499879837036, acc: 0.49295774102211)
                                                                                  [2024-12-14 02:22:15,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:15,311][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.1451575756073, acc: 0.47333332896232605)
[2024-12-14 02:22:15,396][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:22:15,612][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 1.0256038904190063, acc: 0.7567567825317383)
[2024-12-14 02:22:15,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:15,965][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.3612859845161438, acc: 0.8846153616905212)
[2024-12-14 02:22:17,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:18,947][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.879228949546814, acc: 0.511945366859436)
 acc: 0.557692289352417)
[2024-12-14 02:22:16,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:16,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:16,424][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 1.7276357412338257, acc: 0.4285714328289032)
[2024-12-14 02:22:16,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:16,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:16,778][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 2.8116960525512695, acc: 0.2295081913471222)
[2024-12-14 02:22:16,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:16,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:17,149][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 1.6875782012939453, acc: 0.5932203531265259)
[2024-12-14 02:22:17,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:17,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:17,527][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 2.223137855529785, acc: 0.4883720874786377)
[2024-12-14 02:22:17,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:17,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:17,866][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 2.041677713394165, acc: 0.5)
[2024-12-14 02:22:17,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:17,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:18,184][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 2.2844302654266357, acc: 0.4150943458080292)
[2024-12-14 02:22:18,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:18,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:18,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:18,564][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 1.554226279258728, acc: 0.6363636255264282)
[2024-12-14 02:22:18,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:18,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:18,937][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 1.1398719549179077, acc: 0.7200000286102295)
[2024-12-14 02:22:19,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:19,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:19,331][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 1.261895775794983, acc: 0.6499999761581421)
[2024-12-14 02:22:19,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:19,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:19,731][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 0.9615799188613892, acc: 0.6818181872367859)
[2024-12-14 02:22:19,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:19,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:20,145][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.7770990133285522, acc: 0.5846154093742371)
[2024-12-14 02:22:20,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:20,422][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.4564, device='cuda:0') eval_epoch_loss=tensor(1.8651, device='cuda:0') eval_epoch_acc=tensor(0.5064, device='cuda:0')
[2024-12-14 02:22:20,423][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:22:20,424][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:22:20,497][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 1.6667625904083252, acc: 0.59375)
[2024-12-14 02:22:20,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:20,686][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_3_step_425_loss_1.865074872970581/model.pt
[2024-12-14 02:22:20,690][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:22:20,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:20,916][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 1.1046301126480103, acc: 0.78125)
[2024-12-14 02:22:21,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:21,115][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 1.0586600303649902, acc: 0.7272727489471436)
[2024-12-14 02:22:21,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:21,267][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.5752052068710327, acc: 0.6363636255264282)
[2024-12-14 02:22:21,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:22,014][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 2.18981671333313, acc: 0.4057970941066742)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:22:22,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:22,421][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 1.564703345298767, acc: 0.6000000238418579)
                                                                                                                                                                                                                          [2024-12-14 02:22:22,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:22,780][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 1.2338793277740479, acc: 0.6470588445663452)
                                                                                                                                                                                                                         [2024-12-14 02:22:22,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:23,188][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 1.815359115600586, acc: 0.5833333134651184)
                                                                                                                                                                                                                          [2024-12-14 02:22:23,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:23,575][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 1.3248729705810547, acc: 0.640625)
                                                                                                                                                                                                                                  [2024-12-14 02:22:23,675][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:22:23,941][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.6435787081718445, acc: 0.7586206793785095)
                                                                                [2024-12-14 02:22:24,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:24,305][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 2.0132527351379395, acc: 0.4642857015132904)
                                                                                                                                                                                                                        [2024-12-14 02:22:24,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:24,650][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 1.7968518733978271, acc: 0.5)
                                                                                                                                                                                                                                         [2024-12-14 02:22:24,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:25,031][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.4184883236885071, acc: 0.8399999737739563)

[2024-12-14 02:22:24,902][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 0.8504971861839294, acc: 0.7575757503509521)
[2024-12-14 02:22:24,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:24,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:25,180][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 1.2093981504440308, acc: 0.5833333134651184)
[2024-12-14 02:22:25,244][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.852032482624054, acc: 0.7749999761581421)
[2024-12-14 02:22:25,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:25,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:25,501][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 1.3273413181304932, acc: 0.6590909361839294)
[2024-12-14 02:22:25,583][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 1.1400856971740723, acc: 0.6571428775787354)
[2024-12-14 02:22:25,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:25,848][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.47548624873161316, acc: 0.8571428656578064)
[2024-12-14 02:22:25,924][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 2.1047885417938232, acc: 0.46715328097343445)
[2024-12-14 02:22:25,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:26,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:26,165][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 1.7931619882583618, acc: 0.5897436141967773)
[2024-12-14 02:22:26,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:26,327][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 1.6886672973632812, acc: 0.5517241358757019)
[2024-12-14 02:22:26,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:26,627][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 1.9589850902557373, acc: 0.5303030014038086)
[2024-12-14 02:22:26,712][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 2.3369405269622803, acc: 0.4285714328289032)
[2024-12-14 02:22:26,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:26,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:27,064][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 2.093179941177368, acc: 0.41059601306915283)
[2024-12-14 02:22:27,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:27,347][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 2.304246664047241, acc: 0.36800000071525574)
[2024-12-14 02:22:27,418][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 1.7277706861495972, acc: 0.5470085740089417)
[2024-12-14 02:22:27,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:27,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:27,765][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 2.1394894123077393, acc: 0.4193548262119293)
[2024-12-14 02:22:27,781][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.3464730978012085, acc: 0.8399999737739563)
[2024-12-14 02:22:27,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:27,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:28,132][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.8747920393943787, acc: 0.692307710647583)
[2024-12-14 02:22:28,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:28,472][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 2.1052329540252686, acc: 0.46268656849861145)
[2024-12-14 02:22:28,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:28,848][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.3823949098587036, acc: 0.9166666865348816)
r
[2024-12-14 02:22:28,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:28,803][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 1.864814281463623, acc: 0.5094339847564697)
[2024-12-14 02:22:28,883][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 1.407663345336914, acc: 0.5641025900840759)
[2024-12-14 02:22:28,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:28,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:29,215][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 1.5779956579208374, acc: 0.5444444417953491)
[2024-12-14 02:22:29,263][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 1.083387851715088, acc: 0.6590909361839294)
[2024-12-14 02:22:29,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:29,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:29,566][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 1.5595332384109497, acc: 0.5454545617103577)
[2024-12-14 02:22:29,617][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 1.3981044292449951, acc: 0.6086956262588501)
[2024-12-14 02:22:29,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:29,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:29,924][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 1.2729333639144897, acc: 0.6458333134651184)
[2024-12-14 02:22:29,957][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 1.731080174446106, acc: 0.5)
[2024-12-14 02:22:30,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:30,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:30,253][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 1.3622716665267944, acc: 0.6551724076271057)
[2024-12-14 02:22:30,347][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.9631842970848083, acc: 0.7142857313156128)
[2024-12-14 02:22:30,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:30,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:30,577][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 1.6523358821868896, acc: 0.4761904776096344)
[2024-12-14 02:22:30,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:30,703][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 1.7578566074371338, acc: 0.5970149040222168)
[2024-12-14 02:22:30,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:30,951][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 1.2749253511428833, acc: 0.6052631735801697)
[2024-12-14 02:22:31,074][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 1.591723918914795, acc: 0.5972222089767456)
[2024-12-14 02:22:31,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:31,426][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 1.7913241386413574, acc: 0.44565218687057495)
[2024-12-14 02:22:31,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:31,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:31,764][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 1.8913644552230835, acc: 0.5128205418586731)
[2024-12-14 02:22:31,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:32,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:32,095][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 2.1410579681396484, acc: 0.5)
[2024-12-14 02:22:32,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:32,404][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 1.6886869668960571, acc: 0.5510203838348389)
[2024-12-14 02:22:32,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:32,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:32,756][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.7962758541107178, acc: 0.5339806079864502)
 [2024-12-14 02:22:33,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:33,897][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.7668513059616089, acc: 0.5436893105506897)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:22:34,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:34,724][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.96254563331604, acc: 0.45698925852775574)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:22:34,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:35,529][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.7815269231796265, acc: 0.5474137663841248)
                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:22:35,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:36,271][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.4620780944824219, acc: 0.5684210658073425)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:22:36,542][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:22:37,261][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 2.2129271030426025, acc: 0.3861386179924011)
                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:22:37,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:37,554][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 2.016781806945801, acc: 0.4677419364452362)
                                                                                [2024-12-14 02:22:37,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:37,945][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 2.134068250656128, acc: 0.4202898442745209)
3/10, step 469/574 completed (loss: 1.5177706480026245, acc: 0.6016260385513306)
[2024-12-14 02:22:37,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:38,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:38,068][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 1.2689424753189087, acc: 0.6666666865348816)
[2024-12-14 02:22:38,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:38,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:38,390][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 1.8238162994384766, acc: 0.3214285671710968)
[2024-12-14 02:22:38,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:38,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:38,802][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 2.070289373397827, acc: 0.44117647409439087)
[2024-12-14 02:22:38,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:38,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:39,172][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 2.3197221755981445, acc: 0.3711790442466736)
[2024-12-14 02:22:39,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:39,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:39,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:39,571][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 2.128171920776367, acc: 0.40625)
[2024-12-14 02:22:39,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:39,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:39,998][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 2.157768487930298, acc: 0.38650307059288025)
[2024-12-14 02:22:40,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:40,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:40,360][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 2.1151108741760254, acc: 0.4316546618938446)
[2024-12-14 02:22:40,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:40,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:40,719][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 2.247692823410034, acc: 0.38693466782569885)
[2024-12-14 02:22:40,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:40,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:41,061][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 1.1048489809036255, acc: 0.6666666865348816)
[2024-12-14 02:22:41,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:41,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:41,415][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 1.2118693590164185, acc: 0.6969696879386902)
[2024-12-14 02:22:41,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:41,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:41,763][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 0.9133565425872803, acc: 0.7037037014961243)
[2024-12-14 02:22:41,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:42,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:42,104][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 1.4774806499481201, acc: 0.550000011920929)
[2024-12-14 02:22:42,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:42,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:42,474][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 0.7108959555625916, acc: 0.800000011920929)
[2024-12-14 02:22:42,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:42,756][slam_llm.mod 1.0)
[2024-12-14 02:22:42,895][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                            [2024-12-14 02:22:43,160][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 1.2298674583435059, acc: 0.6190476417541504)
[2024-12-14 02:22:43,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:43,525][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 1.6315265893936157, acc: 0.5692307949066162)
                                                                                                                                                              [2024-12-14 02:22:43,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:43,949][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 1.520195722579956, acc: 0.6491228342056274)
                                                                                                                                                              [2024-12-14 02:22:44,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:44,346][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 1.3398349285125732, acc: 0.5614035129547119)
                                                                              [2024-12-14 02:22:44,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:44,707][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 1.6431223154067993, acc: 0.5384615659713745)
                                                                              [2024-12-14 02:22:44,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:45,093][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 1.260999321937561, acc: 0.6734693646430969)
                                                                                [2024-12-14 02:22:45,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:45,493][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.320484459400177, acc: 0.9090909361839294)
                                                                                [2024-12-14 02:22:45,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:45,859][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 1.7034505605697632, acc: 0.5396825671195984)
                                                                               [2024-12-14 02:22:45,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:46,219][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 1.8306827545166016, acc: 0.577235758304596)
                                                                                [2024-12-14 02:22:46,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:46,632][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 1.4143261909484863, acc: 0.6451612710952759)
                                                                                                                                                             [2024-12-14 02:22:46,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:47,546][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.975541353225708, acc: 0.47148290276527405)
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:22:47,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:47,964][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 1.3423566818237305, acc: 0.6399999856948853)
[2024-12-14 02:22:47,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:47,937][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 1.8382916450500488, acc: 0.49438202381134033)
[2024-12-14 02:22:47,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:48,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:48,337][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 2.13362455368042, acc: 0.449438214302063)
[2024-12-14 02:22:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:48,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:48,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:48,734][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.3355653285980225, acc: 0.39716312289237976)
[2024-12-14 02:22:48,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:48,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:49,098][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 2.2957499027252197, acc: 0.3804347813129425)
[2024-12-14 02:22:49,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:49,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:49,409][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.7004583477973938, acc: 0.8399999737739563)
[2024-12-14 02:22:49,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:49,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:49,693][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.7250356674194336, acc: 0.7692307829856873)
[2024-12-14 02:22:49,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:49,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:50,044][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.6618794202804565, acc: 0.7777777910232544)
[2024-12-14 02:22:50,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:50,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:50,396][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 1.670590877532959, acc: 0.5185185074806213)
[2024-12-14 02:22:50,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:50,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:50,740][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 1.5392606258392334, acc: 0.6226415038108826)
[2024-12-14 02:22:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:51,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:51,046][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 1.1737391948699951, acc: 0.6896551847457886)
[2024-12-14 02:22:51,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:51,438][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:22:51,675][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.853947639465332, acc: 0.4864864945411682)
[2024-12-14 02:22:51,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:51,823][slam_llm.models.slam_model][INFO] - modality encoder
 [2024-12-14 02:22:52,123][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.6985719203948975, acc: 0.5492957830429077)
[2024-12-14 02:22:52,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:52,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:52,443][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.38970649242401123, acc: 0.949999988079071)
[2024-12-14 02:22:52,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:52,881][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 1.1946743726730347, acc: 0.695652186870575)
/10, step 510/574 completed (loss: 0.5211929678916931, acc: 0.8333333134651184)
[2024-12-14 02:22:52,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:52,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:53,145][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.9013490676879883, acc: 0.8461538553237915)
[2024-12-14 02:22:53,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:53,646][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:22:54,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:54,440][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:22:54,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:54,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:55,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:55,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:55,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:56,171][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 1.885290503501892, acc: 0.4928571283817291)
[2024-12-14 02:22:56,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:56,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:56,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:56,950][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 1.7939378023147583, acc: 0.5873016119003296)
[2024-12-14 02:22:56,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:57,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:57,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:57,318][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 1.3539273738861084, acc: 0.6071428656578064)
[2024-12-14 02:22:57,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:57,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:57,694][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 1.512342095375061, acc: 0.5833333134651184)
[2024-12-14 02:22:57,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:57,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:58,425][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 1.545731782913208, acc: 0.625)
[2024-12-14 02:22:58,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:58,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:58,797][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.5184898376464844, acc: 0.7692307829856873)
[2024-12-14 02:22:58,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:59,124][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 1.1171551942825317, acc: 0.7096773982048035)
[2024-12-14 02:22:59,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:59,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:59,481][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 1.329359769821167, acc: 0.6499999761581421)
[2024-12-14 02:22:59,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:59,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:22:59,831][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 1.611505389213562, acc: 0.5555555820465088)
[2024-12-14 02:22:59,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:00,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:00,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:00,709][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:23:01,109][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:23:01,466][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:23:01,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:02,254][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:23:02,675][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:23:02,967][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:23:03,263][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:23:03,657][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:23:03,985][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:23:04,301][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.6297056674957275, acc: 0.5555555820465088)
[2024-12-14 02:23:04,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:04,209][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 2.1435251235961914, acc: 0.4883720874786377)
[2024-12-14 02:23:04,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:04,386][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 2.2030322551727295, acc: 0.4183673560619354)
[2024-12-14 02:23:04,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:04,587][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 2.106687307357788, acc: 0.5)
[2024-12-14 02:23:04,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:04,724][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 2.0369935035705566, acc: 0.4150943458080292)
[2024-12-14 02:23:04,922][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 2.2843546867370605, acc: 0.4150943458080292)
[2024-12-14 02:23:05,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:05,180][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=4.7027, train_epoch_loss=1.5481, epoch time 356.94150337204337s
[2024-12-14 02:23:05,181][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:23:05,181][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-14 02:23:05,181][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:23:05,181][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-12-14 02:23:05,181][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 02:23:05,248][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 1.4745007753372192, acc: 0.6363636255264282)
[2024-12-14 02:23:05,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:05,609][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 1.265030026435852, acc: 0.6399999856948853)
[2024-12-14 02:23:05,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:05,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:06,011][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 1.2529319524765015, acc: 0.6499999761581421)
[2024-12-14 02:23:06,099][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 1.2518502473831177, acc: 0.5185185074806213)
[2024-12-14 02:23:06,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:06,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:06,376][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 1.0175954103469849, acc: 0.6818181872367859)
[2024-12-14 02:23:06,430][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 1.570512294769287, acc: 0.5600000023841858)
[2024-12-14 02:23:06,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:06,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:06,793][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 2.1877622604370117, acc: 0.4324324429035187)
[2024-12-14 02:23:06,797][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.7192084789276123, acc: 0.5692307949066162)
[2024-12-14 02:23:06,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:06,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:07,137][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 1.6095799207687378, acc: 0.609375)
[2024-12-14 02:23:07,147][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 2.076735734939575, acc: 0.34210526943206787)
[2024-12-14 02:23:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:07,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:07,459][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 1.8978420495986938, acc: 0.45945945382118225)
[2024-12-14 02:23:07,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:07,572][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 1.1384837627410889, acc: 0.75)
[2024-12-14 02:23:07,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:07,781][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 1.5750752687454224, acc: 0.3928571343421936)
[2024-12-14 02:23:07,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:07,942][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.5842211246490479, acc: 0.6666666865348816)
[2024-12-14 02:23:08,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:08,108][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 1.9688513278961182, acc: 0.5306122303009033)
[2024-12-14 02:23:08,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:08,278][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.7377691864967346, acc: 0.8125)
[2024-12-14 02:23:08,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:08,445][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 1.219298243522644, acc: 0.6666666865348816)
[2024-12-14 02:23:08,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:08,615][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.7814489603042603, acc: 0.774193525314331)
[2024-12-14 02:23:08,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:08,851][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.32260483503341675, acc: 0.9090909361839294)
[2024-12-14 02:23:08,937][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.3406809866428375, acc: 0.9130434989929199)
[2024-12-14 02:23:08,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:09,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:09,189][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.6655002236366272, acc: 0.807692289352417)
[2024-12-14 02:23:09,263][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 1.4876564741134644, acc: 0.5666666626930237)
[2024-12-14 02:23:09,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:09,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:09,541][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.8643319010734558, acc: 0.7777777910232544)
[2024-12-14 02:23:09,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:09,676][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 1.43130362033844, acc: 0.5365853905677795)
[2024-12-14 02:23:09,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:09,933][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 1.5290683507919312, acc: 0.5897436141967773)
[2024-12-14 02:23:10,051][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 0.9385179877281189, acc: 0.7142857313156128)
[2024-12-14 02:23:10,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:10,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:10,325][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 1.201866626739502, acc: 0.6060606241226196)
[2024-12-14 02:23:10,372][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 0.9634876251220703, acc: 0.7105262875556946)
[2024-12-14 02:23:10,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:10,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:10,697][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 1.4304245710372925, acc: 0.6086956262588501)
[2024-12-14 02:23:10,725][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 0.9764463305473328, acc: 0.6774193644523621)
[2024-12-14 02:23:11,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:10,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:11,054][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 1.8023157119750977, acc: 0.5098039507865906)
[2024-12-14 02:23:11,066][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.37771692872047424, acc: 0.8799999952316284)
[2024-12-14 02:23:11,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:11,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:11,425][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 1.5022094249725342, acc: 0.5102040767669678)
[2024-12-14 02:23:11,471][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 0.8740162253379822, acc: 0.7575757503509521)
[2024-12-14 02:23:11,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:11,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:11,751][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.7630007266998291, acc: 0.8421052694320679)
[2024-12-14 02:23:11,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:11,841][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.8984535336494446, acc: 0.75)
[2024-12-14 02:23:11,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:12,113][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 1.267549991607666, acc: 0.5833333134651184)
[2024-12-14 02:23:12,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:12,197][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 1.0823407173156738, acc: 0.6571428775787354)
[2024-12-14 02:23:12,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:12,472][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.6927728652954102, acc: 0.5833333134651184)
[2024-12-14 02:23:12,530][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 2.2212984561920166, acc: 0.43065693974494934)
[2024-12-14 02:23:12,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:12,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:12,844][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 1.7443619966506958, acc: 0.5379310250282288)
[2024-12-14 02:23:12,847][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 1.272748589515686, acc: 0.6315789222717285)
[2024-12-14 02:23:12,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:12,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:13,165][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 2.368762969970703, acc: 0.4000000059604645)
[2024-12-14 02:23:13,209][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 1.2220730781555176, acc: 0.6153846383094788)
[2024-12-14 02:23:13,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:13,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:13,515][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 2.093461751937866, acc: 0.41059601306915283)
[2024-12-14 02:23:13,581][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 1.2819210290908813, acc: 0.7241379022598267)
[2024-12-14 02:23:13,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:13,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:13,883][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 1.724487066268921, acc: 0.5811966061592102)
[2024-12-14 02:23:13,963][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 1.0462844371795654, acc: 0.6000000238418579)
[2024-12-14 02:23:13,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:14,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:14,208][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.3477134704589844, acc: 0.9200000166893005)
[2024-12-14 02:23:14,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:14,361][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.5434232950210571, acc: 0.8571428656578064)
[2024-12-14 02:23:14,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:14,605][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.9155013561248779, acc: 0.692307710647583)
[2024-12-14 02:23:14,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:14,749][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 0.9722954034805298, acc: 0.6875)
[2024-12-14 02:23:14,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:14,994][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.5347322821617126, acc: 0.8461538553237915)
[2024-12-14 02:23:15,095][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 2.2251980304718018, acc: 0.37735849618911743)
[2024-12-14 02:23:15,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:15,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:15,344][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 1.3928076028823853, acc: 0.5897436141967773)
[2024-12-14 02:23:15,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:15,488][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 2.079155206680298, acc: 0.42465752363204956)
[2024-12-14 02:23:15,706][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 1.5245354175567627, acc: 0.5444444417953491)
[2024-12-14 02:23:15,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:15,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:16,075][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 1.4222958087921143, acc: 0.5714285969734192)
[2024-12-14 02:23:16,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:16,443][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 1.2815371751785278, acc: 0.625)
[2024-12-14 02:23:16,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:16,714][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 2.086052656173706, acc: 0.4387351870536804)
[2024-12-14 02:23:16,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:16,833][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 1.3508403301239014, acc: 0.6551724076271057)
[2024-12-14 02:23:16,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:17,026][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 1.5979359149932861, acc: 0.5581395626068115)
[2024-12-14 02:23:17,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:17,178][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 1.6040540933609009, acc: 0.5357142686843872)
[2024-12-14 02:23:17,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:17,423][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 1.8453294038772583, acc: 0.4819277226924896)
[2024-12-14 02:23:17,558][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 1.1648441553115845, acc: 0.6842105388641357)
[2024-12-14 02:23:17,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:17,846][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 1.9093554019927979, acc: 0.48148149251937866)
[2024-12-14 02:23:17,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:18,220][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 1.9019969701766968, acc: 0.5)
[2024-12-14 02:23:18,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:18,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:18,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:18,605][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 1.0788377523422241, acc: 0.6296296119689941)
[2024-12-14 02:23:18,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:18,990][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.6381655931472778, acc: 0.8695651888847351)
[2024-12-14 02:23:19,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:19,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:19,389][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 1.9953135251998901, acc: 0.4789915978908539)
[2024-12-14 02:23:19,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:19,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:19,776][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 1.5589829683303833, acc: 0.5245901346206665)
[2024-12-14 02:23:19,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:19,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:20,147][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 1.8304588794708252, acc: 0.5079365372657776)
[2024-12-14 02:23:20,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:20,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:20,463][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 1.909968376159668, acc: 0.49152541160583496)
[2024-12-14 02:23:20,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:20,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:20,870][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 1.331699013710022, acc: 0.5977011322975159)
[2024-12-14 02:23:20,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:21,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:21,255][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.6677969098091125, acc: 0.8095238208770752)
[2024-12-14 02:23:21,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:21,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:21,636][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 1.1888353824615479, acc: 0.6153846383094788)
[2024-12-14 02:23:21,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:21,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:22,071][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 2.215364933013916, acc: 0.44594594836235046)
[2024-12-14 02:23:22,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:22,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:22,426][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 1.689030647277832, acc: 0.5538461804389954)
[2024-12-14 02:23:22,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:22,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:22,873][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 2.0146241188049316, acc: 0.5151515007019043)
[2024-12-14 02:23:22,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:23,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:23,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:23,311][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 1.6505496501922607, acc: 0.5670102834701538)
[2024-12-14 02:23:23,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:23,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:23,738][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 1.9082822799682617, acc: 0.4852941036224365)
[2024-12-14 02:23:23,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:24,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:24,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:25,051][sdel][INFO] - modality encoder
[2024-12-14 02:23:24,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:24,388][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.4584277868270874, acc: 0.8888888955116272)
[2024-12-14 02:23:24,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:24,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:24,675][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 0.9901019930839539, acc: 0.6785714030265808)
[2024-12-14 02:23:24,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:24,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:25,020][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.6396093368530273, acc: 0.8055555820465088)
[2024-12-14 02:23:25,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:25,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:25,364][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 1.152329683303833, acc: 0.7017543911933899)
[2024-12-14 02:23:25,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:25,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:25,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:25,755][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.3186421394348145, acc: 0.60317462682724)
[2024-12-14 02:23:25,872][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:23:25,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:26,154][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.9422460794448853, acc: 0.43661972880363464)
[2024-12-14 02:23:26,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:26,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:26,613][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.126950263977051, acc: 0.47999998927116394)
[2024-12-14 02:23:26,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:26,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:26,986][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 1.0292911529541016, acc: 0.7567567825317383)
[2024-12-14 02:23:27,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:27,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:27,338][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.44392919540405273, acc: 0.8461538553237915)
[2024-12-14 02:23:27,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:27,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:28,049][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                    [2024-12-14 02:23:28,398][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:23:28,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:28,972][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:23:29,304][slam_llm.models.slam_model][INFO] - moda 145/574 completed (loss: 2.190221071243286, acc: 0.3877550959587097)
[2024-12-14 02:23:29,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:29,708][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 1.949495792388916, acc: 0.42553192377090454)
[2024-12-14 02:23:29,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:30,091][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 1.789387822151184, acc: 0.5142857432365417)
[2024-12-14 02:23:30,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:30,440][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 2.1027677059173584, acc: 0.4642857015132904)
[2024-12-14 02:23:30,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:30,790][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 1.4346199035644531, acc: 0.43478259444236755)
[2024-12-14 02:23:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:31,174][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 1.7110587358474731, acc: 0.48275861144065857)
[2024-12-14 02:23:31,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:31,521][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 1.845964789390564, acc: 0.5869565010070801)
[2024-12-14 02:23:31,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:31,910][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 1.8326693773269653, acc: 0.5593220591545105)
                                                                             [2024-12-14 02:23:32,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:32,297][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 1.954858422279358, acc: 0.4912280738353729)
[2024-12-14 02:23:32,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:32,652][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 1.7524572610855103, acc: 0.5)
[2024-12-14 02:23:32,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:33,004][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 1.534765601158142, acc: 0.5)
[2024-12-14 02:23:33,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:33,350][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 1.4290335178375244, acc: 0.5652173757553101)
                                                  [2024-12-14 02:23:33,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:33,678][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 1.445537805557251, acc: 0.5263158082962036)
[2024-12-14 02:23:34,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:35,400][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.5738437175750732, acc: 0.6081081032752991)
 - modality encoder
[2024-12-14 02:23:34,166][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 1.1899524927139282, acc: 0.6764705777168274)
[2024-12-14 02:23:34,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:34,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:34,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:34,552][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 1.448606252670288, acc: 0.5277777910232544)
[2024-12-14 02:23:34,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:34,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:34,905][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 1.3031525611877441, acc: 0.640625)
[2024-12-14 02:23:34,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:35,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:35,262][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.6527803540229797, acc: 0.7931034564971924)
[2024-12-14 02:23:35,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:35,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:35,638][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 1.9388418197631836, acc: 0.4464285671710968)
[2024-12-14 02:23:35,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:35,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:36,009][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 1.7819900512695312, acc: 0.46666666865348816)
[2024-12-14 02:23:36,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:36,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:36,343][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.5142894983291626, acc: 0.8799999952316284)
[2024-12-14 02:23:36,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:36,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:36,712][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 1.1104220151901245, acc: 0.7222222089767456)
[2024-12-14 02:23:36,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:37,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:37,140][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 1.1611577272415161, acc: 0.6969696879386902)
[2024-12-14 02:23:37,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:37,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:37,508][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 1.9480745792388916, acc: 0.5073529481887817)
[2024-12-14 02:23:37,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:37,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:37,903][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 1.8636226654052734, acc: 0.4682539701461792)
[2024-12-14 02:23:38,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:38,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:38,312][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 2.181637763977051, acc: 0.38461539149284363)
[2024-12-14 02:23:38,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:38,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:38,708][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 1.8819547891616821, acc: 0.5)
[2024-12-14 02:23:38,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:39,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:39,093][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 2.3174033164978027, acc: 0.3731343150138855)
[2024-12-14 02:23:39,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:39,478][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 2.1249356269836426, acc: 0.4270072877407074)
[2024-12-14 02:23:39,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:39,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:39,827][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.36998555064201355, acc: 0.8571428656578064)
[2024-12-14 02:23:40,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:40,864][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 2.2942276000976562, acc: 0.4383561611175537)
10, step 78/574 completed (loss: 0.35309311747550964, acc: 0.9166666865348816)
[2024-12-14 02:23:40,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:40,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:40,495][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.9871196150779724, acc: 0.6969696879386902)
[2024-12-14 02:23:40,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:40,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:40,860][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.459741473197937, acc: 0.8846153616905212)
[2024-12-14 02:23:40,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:40,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:41,251][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 1.5517183542251587, acc: 0.5769230723381042)
[2024-12-14 02:23:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:41,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:41,663][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 1.9772661924362183, acc: 0.5)
[2024-12-14 02:23:41,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:41,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:42,039][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 1.214005947113037, acc: 0.6875)
[2024-12-14 02:23:42,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:42,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:42,425][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 1.7701263427734375, acc: 0.5072463750839233)
[2024-12-14 02:23:42,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:42,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:42,808][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 1.315332293510437, acc: 0.6399999856948853)
[2024-12-14 02:23:42,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:43,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:43,203][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 1.3539797067642212, acc: 0.6086956262588501)
[2024-12-14 02:23:43,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:43,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:43,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:43,662][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.9702517986297607, acc: 0.4000000059604645)
[2024-12-14 02:23:43,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:43,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:44,075][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.8193652629852295, acc: 0.49514561891555786)
[2024-12-14 02:23:44,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:44,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:44,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:44,915][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:23:45,152][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.7327252626419067, acc: 0.553398072719574)
[2024-12-14 02:23:45,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:45,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:45,536][slam_llm.models.slam_model][INFO] - modality encoder
                                                            [2024-12-14 02:23:45,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:45,977][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.8742998838424683, acc: 0.4784946143627167)
[2024-12-14 02:23:46,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:46,195][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:23:46,515][slam_llm.models.slam_model][INFO] - modality encoder
                                           [2024-12-14 02:23:46,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:46,866][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 2.0602967739105225, acc: 0.4350453317165375)
[2024-12-14 02:23:46,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:47,196][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 2.2006733417510986, acc: 0.4207492768764496)
[2024-12-14 02:23:47,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:47,673][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 2.2602827548980713, acc: 0.41874998807907104)
[2024-12-14 02:23:47,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:48,199][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 2.0789146423339844, acc: 0.4446529150009155)
[2024-12-14 02:23:48,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:48,612][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 1.991931676864624, acc: 0.4483985900878906)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:23:48,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:48,976][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 1.5494035482406616, acc: 0.6000000238418579)
                                                                                                                                                                                                                       [2024-12-14 02:23:49,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:49,530][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 2.070808172225952, acc: 0.45348837971687317)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:23:49,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:50,332][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.7602488994598389, acc: 0.5476190447807312)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:23:50,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:51,248][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.9334594011306763, acc: 0.469696968793869)

[2024-12-14 02:23:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:50,416][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 2.233734607696533, acc: 0.41605839133262634)
[2024-12-14 02:23:50,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:50,615][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 2.0087125301361084, acc: 0.42138364911079407)
[2024-12-14 02:23:50,781][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 2.2333478927612305, acc: 0.35820895433425903)
[2024-12-14 02:23:50,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:51,027][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=4.7132, train_epoch_loss=1.5504, epoch time 357.98710191622376s
[2024-12-14 02:23:51,027][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:23:51,028][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-14 02:23:51,028][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:23:51,028][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-12-14 02:23:51,028][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:23:51,142][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.5345560312271118, acc: 0.8999999761581421)
[2024-12-14 02:23:51,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:51,490][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.4582838714122772, acc: 0.9090909361839294)
[2024-12-14 02:23:51,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:51,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:51,866][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.7471317648887634, acc: 0.739130437374115)
[2024-12-14 02:23:51,898][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 1.1923890113830566, acc: 0.5555555820465088)
[2024-12-14 02:23:51,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:51,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:52,221][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 1.15932297706604, acc: 0.6590909361839294)
[2024-12-14 02:23:52,283][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 1.5482378005981445, acc: 0.6000000238418579)
[2024-12-14 02:23:52,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:52,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:52,577][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 1.7544887065887451, acc: 0.5)
[2024-12-14 02:23:52,664][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 2.190917730331421, acc: 0.45945945382118225)
[2024-12-14 02:23:52,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:52,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:52,934][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 1.2081291675567627, acc: 0.6279069781303406)
[2024-12-14 02:23:52,981][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 1.881439447402954, acc: 0.3684210479259491)
[2024-12-14 02:23:53,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:53,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:53,323][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 1.1413897275924683, acc: 0.800000011920929)
[2024-12-14 02:23:53,333][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 1.9686106443405151, acc: 0.5405405163764954)
[2024-12-14 02:23:53,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:53,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:53,661][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 1.4757022857666016, acc: 0.5)
[2024-12-14 02:23:53,714][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.30433133244514465, acc: 0.9411764740943909)
[2024-12-14 02:23:53,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:54,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:54,373][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.6286028027534485, acc: 0.8571428656578064)
                                                                                                                                                                                                                                                                                       [2024-12-14 02:23:54,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:54,774][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 1.173863410949707, acc: 0.675000011920929)
                                                                                                                                       [2024-12-14 02:23:54,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:55,178][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 1.5723249912261963, acc: 0.5735294222831726)
                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:23:55,287][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:23:55,573][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 1.790533185005188, acc: 0.5367646813392639)
                                                                                                                                                              [2024-12-14 02:23:55,685][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:23:55,964][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 1.9906989336013794, acc: 0.4830508530139923)
                                                                                                                                                             [2024-12-14 02:23:56,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:56,328][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 2.0957531929016113, acc: 0.43283581733703613)
                                                                                                                                       [2024-12-14 02:23:56,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:56,741][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 2.0447020530700684, acc: 0.446601927280426)
                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:23:56,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:57,093][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 1.7347378730773926, acc: 0.4761904776096344)
                                                                                                                                                                                                                      [2024-12-14 02:23:57,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:57,445][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 1.6751288175582886, acc: 0.5604395866394043)
024-12-14 02:23:57,343][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 1.8110871315002441, acc: 0.5691056847572327)
[2024-12-14 02:23:57,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:57,615][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.6749336123466492, acc: 0.8947368264198303)
[2024-12-14 02:23:57,680][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 1.4209648370742798, acc: 0.6129032373428345)
[2024-12-14 02:23:57,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:57,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:57,967][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 1.1599256992340088, acc: 0.5833333134651184)
[2024-12-14 02:23:58,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:58,248][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.8325449228286743, acc: 0.5555555820465088)
[2024-12-14 02:23:58,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:58,555][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.9281716346740723, acc: 0.4524714946746826)
[2024-12-14 02:23:58,588][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 1.228561282157898, acc: 0.6315789222717285)
[2024-12-14 02:23:58,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:58,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:58,919][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 1.4209538698196411, acc: 0.653333306312561)
[2024-12-14 02:23:58,942][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 1.2699910402297974, acc: 0.6538461446762085)
[2024-12-14 02:23:59,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:59,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:59,284][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 1.1586164236068726, acc: 0.7241379022598267)
[2024-12-14 02:23:59,307][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 1.2948492765426636, acc: 0.6153846383094788)
[2024-12-14 02:23:59,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:59,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:59,628][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.6318305730819702, acc: 0.875)
[2024-12-14 02:23:59,645][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 1.068151831626892, acc: 0.6399999856948853)
[2024-12-14 02:23:59,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:23:59,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:00,010][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.8245708346366882, acc: 0.7368420958518982)
[2024-12-14 02:24:00,042][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.7337005734443665, acc: 0.8095238208770752)
[2024-12-14 02:24:00,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:00,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:00,408][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 1.1979520320892334, acc: 0.4375)
[2024-12-14 02:24:00,424][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 2.072701930999756, acc: 0.43558281660079956)
[2024-12-14 02:24:00,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:00,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:00,783][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 2.4112842082977295, acc: 0.3207547068595886)
[2024-12-14 02:24:00,829][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.6841182708740234, acc: 0.5277777910232544)
[2024-12-14 02:24:00,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:01,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:01,654][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 1.5501646995544434, acc: 0.5461538434028625)
2024-12-14 02:24:01,225][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 2.0740532875061035, acc: 0.3916666805744171)
[2024-12-14 02:24:01,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:01,574][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 1.932560920715332, acc: 0.4226190447807312)
[2024-12-14 02:24:01,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:01,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:01,987][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.8607252836227417, acc: 0.5025641322135925)
[2024-12-14 02:24:02,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:02,406][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.7848150730133057, acc: 0.5441176295280457)
[2024-12-14 02:24:02,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:02,615][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 2.1431362628936768, acc: 0.39920949935913086)
[2024-12-14 02:24:02,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:02,748][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 0.76990807056427, acc: 0.807692289352417)
[2024-12-14 02:24:02,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:02,985][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 1.6593976020812988, acc: 0.4651162922382355)
[2024-12-14 02:24:03,086][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.5006662607192993, acc: 0.8260869383811951)
[2024-12-14 02:24:03,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:03,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:03,363][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 1.9014372825622559, acc: 0.4939759075641632)
[2024-12-14 02:24:03,439][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 1.1354389190673828, acc: 0.625)
[2024-12-14 02:24:03,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:03,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:03,744][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 1.8641548156738281, acc: 0.4691357910633087)
[2024-12-14 02:24:03,756][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 1.5028657913208008, acc: 0.5652173757553101)
[2024-12-14 02:24:03,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:03,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:04,108][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 1.0243602991104126, acc: 0.6000000238418579)
[2024-12-14 02:24:04,138][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 1.8299745321273804, acc: 0.4642857015132904)
[2024-12-14 02:24:04,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:04,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:04,495][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.9205809831619263, acc: 0.692307710647583)
[2024-12-14 02:24:04,532][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 1.0989857912063599, acc: 0.6666666865348816)
[2024-12-14 02:24:04,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:04,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:04,836][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 1.652191400527954, acc: 0.5)
[2024-12-14 02:24:04,847][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.7343510389328003, acc: 0.8260869383811951)
[2024-12-14 02:24:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:05,250][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 1.909290075302124, acc: 0.48739495873451233)
[2024-12-14 02:24:05,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:05,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:06,091][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 1.7507472038269043, acc: 0.5056818127632141)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:24:06,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:06,528][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 1.9525305032730103, acc: 0.41489362716674805)
                                                                            [2024-12-14 02:24:06,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:06,929][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 1.2914183139801025, acc: 0.6226415038108826)
                                                                                                                                                             [2024-12-14 02:24:07,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:07,275][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 1.4981014728546143, acc: 0.550000011920929)
                                                                               [2024-12-14 02:24:07,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:07,651][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.9418408870697021, acc: 0.7209302186965942)
                                                                              [2024-12-14 02:24:07,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:08,029][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 0.7210962772369385, acc: 0.7666666507720947)
                                                                             [2024-12-14 02:24:08,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:08,465][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 2.085801839828491, acc: 0.4736842215061188)
                                                                               [2024-12-14 02:24:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:08,810][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 1.6979871988296509, acc: 0.5333333611488342)
[2024-12-14 02:24:08,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:09,222][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 1.3624799251556396, acc: 0.6388888955116272)
                                                                             [2024-12-14 02:24:09,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:09,716][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 1.65187406539917, acc: 0.5963302850723267)
                                                                                [2024-12-14 02:24:09,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:10,185][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 1.4726343154907227, acc: 0.6000000238418579)
                                                                                                                                                             [2024-12-14 02:24:10,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:10,547][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 1.0621076822280884, acc: 0.6315789222717285)
                                                                               [2024-12-14 02:24:10,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:10,853][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.730116605758667, acc: 0.8333333134651184)
[2024-12-14 02:24:10,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:11,230][root][INFO] - .slam_model][INFO] - modality encoder
[2024-12-14 02:24:11,129][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.6886296272277832, acc: 0.8055555820465088)
[2024-12-14 02:24:11,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:11,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:11,533][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 1.1909832954406738, acc: 0.6842105388641357)
[2024-12-14 02:24:11,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:11,891][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.273139238357544, acc: 0.6666666865348816)
[2024-12-14 02:24:11,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:12,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:12,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:12,279][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.8823622465133667, acc: 0.5070422291755676)
[2024-12-14 02:24:12,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:12,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:12,741][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.1314539909362793, acc: 0.46666666865348816)
[2024-12-14 02:24:12,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:12,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:13,092][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 1.026320219039917, acc: 0.7837837934494019)
[2024-12-14 02:24:13,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:13,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:13,470][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.43049556016921997, acc: 0.807692289352417)
[2024-12-14 02:24:13,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:13,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:14,140][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:24:14,577][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:24:14,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:15,077][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:24:15,237][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:24:15,586][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:24:15,914][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:24:16,233][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:24:16,567][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.7462300062179565, acc: 0.5392491221427917)
[2024-12-14 02:24:16,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:17,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:17,038][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:24:17,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:17,440][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.2419070601463318, acc: 0.8799999952316284)
[2024-12-14 02:24:17,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:17,809][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.20491866767406464, acc: 0.9599999785423279)
[2024-12-14 02:24:17,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:18,187][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.36918672919273376, acc: 0.8709677457809448)
[2024-12-14 02:24:18,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:18,532][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 1.1637614965438843, acc: 0.719298243522644)
                                                                               [2024-12-14 02:24:18,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:18,920][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 1.3234963417053223, acc: 0.6571428775787354)
[2024-12-14 02:24:19,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:19,267][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 1.348701000213623, acc: 0.6578947305679321)
[2024-12-14 02:24:19,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:19,830][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 1.4425609111785889, acc: 0.5849056839942932)
                                                                                                                                               [2024-12-14 02:24:19,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:20,425][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 1.6739277839660645, acc: 0.574999988079071)
                                                                  [2024-12-14 02:24:20,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:20,768][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 0.9223612546920776, acc: 0.75)
                                                                                            [2024-12-14 02:24:20,854][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:24:21,084][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 1.3185261487960815, acc: 0.6129032373428345)
[2024-12-14 02:24:21,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:21,417][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 2.5088541507720947, acc: 0.3866666555404663)
                                                                                     [2024-12-14 02:24:21,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:21,777][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 1.9036264419555664, acc: 0.5)
                                                                                            [2024-12-14 02:24:22,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:22,647][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 2.366035223007202, acc: 0.36800000071525574)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:24:22,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:23,032][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 2.036402702331543, acc: 0.4606741666793823)
                                                                               [2024-12-14 02:24:23,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:23,422][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 1.9623076915740967, acc: 0.5)
[2024-12-14 02:24:23,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:23,869][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 1.3522672653198242, acc: 0.6379310488700867)
                                                                                                                                                                                                                                                          [2024-12-14 02:24:24,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:24,267][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.5586414337158203, acc: 0.7727272510528564)
                                                                              [2024-12-14 02:24:24,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:24,657][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.5902073979377747, acc: 0.8636363744735718)
                                                                             [2024-12-14 02:24:24,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:25,049][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.7917894124984741, acc: 0.78125)
                                                                                                                                                                        [2024-12-14 02:24:25,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:25,353][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 0.944956362247467, acc: 0.7333333492279053)
[2024-12-14 02:24:25,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:25,739][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 1.6621582508087158, acc: 0.5166666507720947)
                                                                             [2024-12-14 02:24:25,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:26,087][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 1.0264513492584229, acc: 0.6875)
                                                                                          [2024-12-14 02:24:26,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:26,417][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.6710940599441528, acc: 0.800000011920929)
                                                                               [2024-12-14 02:24:26,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:26,726][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 0.9343168139457703, acc: 0.7586206793785095)
[2024-12-14 02:24:26,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:27,035][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 0.6582846641540527, acc: 0.800000011920929)
[2024-12-14 02:24:27,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:27,411][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 1.6910637617111206, acc: 0.5319148898124695)
                    [2024-12-14 02:24:27,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:27,740][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 1.5176901817321777, acc: 0.5625)
23381042)
[2024-12-14 02:24:27,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:27,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:27,824][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 1.922021746635437, acc: 0.48076921701431274)
[2024-12-14 02:24:27,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:28,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:28,188][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 1.3462625741958618, acc: 0.53125)
[2024-12-14 02:24:28,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:28,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:28,562][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 1.821016788482666, acc: 0.5072463750839233)
[2024-12-14 02:24:28,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:28,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:28,951][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 1.3237379789352417, acc: 0.6600000262260437)
[2024-12-14 02:24:28,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:29,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:29,291][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 1.3115452527999878, acc: 0.6521739363670349)
[2024-12-14 02:24:29,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:29,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:29,766][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.776634693145752, acc: 0.4399999976158142)
[2024-12-14 02:24:29,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:29,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:30,136][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.712114691734314, acc: 0.5339806079864502)
[2024-12-14 02:24:30,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:30,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:30,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:30,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:31,248][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.7615039348602295, acc: 0.5631067752838135)
[2024-12-14 02:24:31,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:31,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:31,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:32,066][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.9142452478408813, acc: 0.4677419364452362)
[2024-12-14 02:24:32,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:32,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:32,869][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.7484599351882935, acc: 0.5344827771186829)
[2024-12-14 02:24:33,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:33,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:33,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:33,620][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.3996171951293945, acc: 0.6000000238418579)
[2024-12-14 02:24:33,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:33,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:34,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:34,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:34,615][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 2.2755930423736572, acc: 0.40594059228897095)
[2024-12-14 02:24:34,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:34,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:34,992][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 1.9830840826034546, acc: 0.4516128897666931)
[2024-12-14 02:24:35,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:35,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:35,319][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 2.1985621452331543, acc: 0.4202898442745209)
[2024-12-14 02:24:35,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:35,584][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.4882, device='cuda:0') eval_epoch_loss=tensor(1.7026, device='cuda:0') eval_epoch_acc=tensor(0.5503, device='cuda:0')
[2024-12-14 02:24:35,585][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:24:35,585][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:24:35,708][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 2.321709394454956, acc: 0.3193277418613434)
[2024-12-14 02:24:35,802][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_137_loss_1.7025941610336304/model.pt
[2024-12-14 02:24:35,806][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:24:35,806][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.7025941610336304
[2024-12-14 02:24:35,807][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.550268828868866
[2024-12-14 02:24:35,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:35,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:36,053][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 2.268022060394287, acc: 0.3365384638309479)
[2024-12-14 02:24:36,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:36,222][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 1.1817278861999512, acc: 0.6333333253860474)
[2024-12-14 02:24:36,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:36,489][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 2.169095516204834, acc: 0.40145984292030334)
[2024-12-14 02:24:36,583][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 1.231946349143982, acc: 0.695652186870575)
[2024-12-14 02:24:36,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:36,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:36,846][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 2.234027624130249, acc: 0.3731343150138855)
[2024-12-14 02:24:36,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:36,953][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 1.3324631452560425, acc: 0.6190476417541504)
[2024-12-14 02:24:37,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:37,216][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.7916873693466187, acc: 0.75)
[2024-12-14 02:24:37,316][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 1.607604742050171, acc: 0.5)
[2024-12-14 02:24:37,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:37,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:37,610][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.6188465356826782, acc: 0.8636363744735718)
[2024-12-14 02:24:37,691][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 2.248859167098999, acc: 0.32258063554763794)
[2024-12-14 02:24:37,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:37,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:37,980][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.8007660508155823, acc: 0.8260869383811951)
[2024-12-14 02:24:38,225][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:24:38,595][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:24:38,945][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:24:39,319][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:24:39,631][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:24:39,940][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 02:24:40,350][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:24:40,813][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:24:41,180][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:24:41,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:41,576][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 1.88923180103302, acc: 0.5652173757553101)
[2024-12-14 02:24:41,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:41,705][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 1.315076231956482, acc: 0.6491228342056274)
[2024-12-14 02:24:41,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:41,929][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 1.7630559206008911, acc: 0.5423728823661804)
[2024-12-14 02:24:42,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:42,097][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 1.648167371749878, acc: 0.5897436141967773)
[2024-12-14 02:24:42,222][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 2.0143730640411377, acc: 0.4385964870452881)
[2024-12-14 02:24:42,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:42,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:42,517][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 1.1741509437561035, acc: 0.6938775777816772)
[2024-12-14 02:24:42,616][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 1.8258625268936157, acc: 0.5)
[2024-12-14 02:24:42,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:42,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:42,883][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.2732805907726288, acc: 0.9090909361839294)
[2024-12-14 02:24:42,949][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 1.550379753112793, acc: 0.5357142686843872)
[2024-12-14 02:24:43,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:43,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:43,245][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 1.1430797576904297, acc: 0.6086956262588501)
[2024-12-14 02:24:43,316][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 1.5830349922180176, acc: 0.5714285969734192)
[2024-12-14 02:24:43,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:43,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:43,602][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 1.33277428150177, acc: 0.4736842215061188)
[2024-12-14 02:24:43,690][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 1.7584948539733887, acc: 0.5691056847572327)
[2024-12-14 02:24:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:44,054][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 1.4860517978668213, acc: 0.5645161271095276)
[2024-12-14 02:24:44,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:44,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:44,931][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.9455060958862305, acc: 0.48288974165916443)
[2024-12-14 02:24:45,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:45,277][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.6111730337142944, acc: 0.5810810923576355)
[2024-12-14 02:24:45,277][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 1.3464781045913696, acc: 0.6133333444595337)
[2024-12-14 02:24:45,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:45,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:45,594][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 1.894776701927185, acc: 0.48148149251937866)
[2024-12-14 02:24:45,676][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 1.2198808193206787, acc: 0.6730769276618958)
[2024-12-14 02:24:45,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:45,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:45,984][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.6755965352058411, acc: 0.8333333134651184)
[2024-12-14 02:24:46,176][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.4843412637710571, acc: 0.604651153087616)
[2024-12-14 02:24:46,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:46,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:46,343][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.6350862383842468, acc: 0.7894737124443054)
[2024-12-14 02:24:46,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:46,615][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 1.3860747814178467, acc: 0.5411764979362488)
[2024-12-14 02:24:46,712][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 2.0226731300354004, acc: 0.4171779155731201)
[2024-12-14 02:24:46,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:46,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:47,105][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.6828166246414185, acc: 0.5486111044883728)
[2024-12-14 02:24:47,176][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 1.872602105140686, acc: 0.47191011905670166)
[2024-12-14 02:24:47,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:47,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:47,459][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 2.1085093021392822, acc: 0.38333332538604736)
[2024-12-14 02:24:47,573][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 1.3673352003097534, acc: 0.6818181872367859)
[2024-12-14 02:24:47,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:47,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:47,865][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 1.939600944519043, acc: 0.3928571343421936)
[2024-12-14 02:24:47,911][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 1.2081334590911865, acc: 0.7142857313156128)
[2024-12-14 02:24:47,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:48,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:48,225][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 1.4571938514709473, acc: 0.5862069129943848)
[2024-12-14 02:24:48,308][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.8794835805892944, acc: 0.5128205418586731)
[2024-12-14 02:24:48,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:48,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:48,592][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 1.0686076879501343, acc: 0.6530612111091614)
[2024-12-14 02:24:48,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:48,740][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.6937609910964966, acc: 0.5661764740943909)
[2024-12-14 02:24:48,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:48,928][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 1.5128295421600342, acc: 0.5199999809265137)
[2024-12-14 02:24:49,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:49,132][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 0.8205525279045105, acc: 0.8461538553237915)
[2024-12-14 02:24:49,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:49,378][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 1.4772250652313232, acc: 0.6111111044883728)
[2024-12-14 02:24:49,792][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.37041306495666504, acc: 0.8260869383811951)
[2024-12-14 02:24:49,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:49,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:49,723][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 1.7761112451553345, acc: 0.5)
[2024-12-14 02:24:49,822][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 1.072283387184143, acc: 0.65625)
[2024-12-14 02:24:49,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:50,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:50,165][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 1.2153598070144653, acc: 0.695652186870575)
[2024-12-14 02:24:50,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:50,519][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 1.0134016275405884, acc: 0.6857143044471741)
[2024-12-14 02:24:50,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:50,747][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 2.271505355834961, acc: 0.4178082048892975)
[2024-12-14 02:24:50,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:50,857][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 1.0117243528366089, acc: 0.5769230723381042)
[2024-12-14 02:24:50,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:51,061][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.6304180026054382, acc: 0.8333333134651184)
[2024-12-14 02:24:51,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:51,159][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 1.5641239881515503, acc: 0.4761904776096344)
[2024-12-14 02:24:51,368][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.6610178351402283, acc: 0.8518518805503845)
[2024-12-14 02:24:51,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:51,672][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 1.1673402786254883, acc: 0.7142857313156128)
[2024-12-14 02:24:51,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:52,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:52,209][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.5966200828552246, acc: 0.5752212405204773)
[2024-12-14 02:24:52,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:52,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:52,540][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 1.4592262506484985, acc: 0.5942028760910034)
[2024-12-14 02:24:52,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:52,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:52,946][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 1.6663894653320312, acc: 0.5568181872367859)
[2024-12-14 02:24:53,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:53,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:53,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:53,856][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 2.2146196365356445, acc: 0.39694657921791077)
[2024-12-14 02:24:53,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:54,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:54,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:54,526][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 2.0352652072906494, acc: 0.43703705072402954)
[2024-12-14 02:24:54,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:54,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:54,901][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 1.4359066486358643, acc: 0.6557376980781555)
[2024-12-14 02:24:54,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:55,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:55,229][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.6262198686599731, acc: 0.7916666865348816)
[2024-12-14 02:24:55,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:55,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:55,552][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 1.022763967514038, acc: 0.7599999904632568)
[2024-12-14 02:24:55,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:55,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:55,892][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.8893238306045532, acc: 0.6785714030265808)
[2024-12-14 02:24:55,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:55,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:56,282][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 1.7985767126083374, acc: 0.5243902206420898)
[2024-12-14 02:24:56,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:56,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:56,672][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 2.04543137550354, acc: 0.43202418088912964)
[2024-12-14 02:24:56,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:56,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:57,061][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 2.1987295150756836, acc: 0.41786742210388184)
[2024-12-14 02:24:57,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:57,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:57,535][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 2.2802319526672363, acc: 0.40312498807907104)
[2024-12-14 02:24:57,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:57,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:57,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:58,059][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 2.0844216346740723, acc: 0.42964354157447815)
[2024-12-14 02:24:58,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:58,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:58,513][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 1.9546194076538086, acc: 0.4661921560764313)
[2024-12-14 02:24:58,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:58,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:58,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:58,903][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 1.4718618392944336, acc: 0.6399999856948853)
                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:24:59,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:59,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:59,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:59,457][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 2.0618391036987305, acc: 0.4651162922382355)
[2024-12-14 02:24:59,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:24:59,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:00,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:00,259][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.7920491695404053, acc: 0.579365074634552)
[2024-12-14 02:25:00,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:00,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:00,786][slam_llm.models.slam_model][INFO] - modality encoder
                       [2024-12-14 02:25:01,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:01,047][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 1.3534915447235107, acc: 0.675000011920929)
[2024-12-14 02:25:01,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:01,336][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 2.036618232727051, acc: 0.40625)
[2024-12-14 02:25:01,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:01,691][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 2.2482547760009766, acc: 0.3840000033378601)
[2024-12-14 02:25:01,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:02,077][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 1.8022065162658691, acc: 0.5384615659713745)
[2024-12-14 02:25:02,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:02,418][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 2.171959161758423, acc: 0.4037266969680786)
[2024-12-14 02:25:02,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:02,802][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 2.2165729999542236, acc: 0.37628865242004395)
[2024-12-14 02:25:02,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:03,227][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.4202215075492859, acc: 0.8636363744735718)
[2024-12-14 02:25:03,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:03,608][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 1.682206153869629, acc: 0.5952380895614624)
[2024-12-14 02:25:03,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:03,942][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 1.072239637374878, acc: 0.6896551847457886)
[2024-12-14 02:25:04,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:04,401][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 1.142442226409912, acc: 0.6727272868156433)
                                                                                                                                                                [2024-12-14 02:25:04,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:04,948][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.651715636253357, acc: 0.5360824465751648)
                                                                                                                                                              [2024-12-14 02:25:05,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:05,310][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 1.7947888374328613, acc: 0.517241358757019)
                                                                                [2024-12-14 02:25:05,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:05,703][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 1.2895407676696777, acc: 0.6666666865348816)
[2024-12-14 02:25:05,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:06,091][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 1.3258085250854492, acc: 0.5789473652839661)
                                                                                                                                                             [2024-12-14 02:25:06,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:06,431][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 1.382114291191101, acc: 0.6071428656578064)
 [2024-12-14 02:25:06,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:06,770][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 1.2641605138778687, acc: 0.65625)
g Epoch: 4/10, step 202/574 completed (loss: 2.0163865089416504, acc: 0.446601927280426)
[2024-12-14 02:25:06,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:06,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:06,902][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 1.6226056814193726, acc: 0.5873016119003296)
[2024-12-14 02:25:06,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:06,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:07,266][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 1.6651216745376587, acc: 0.5274725556373596)
[2024-12-14 02:25:07,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:07,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:07,683][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 1.9660670757293701, acc: 0.4529148042201996)
[2024-12-14 02:25:07,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:07,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:08,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:08,124][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 1.9717261791229248, acc: 0.5078740119934082)
[2024-12-14 02:25:08,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:08,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:08,550][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 1.920440673828125, acc: 0.4698275923728943)
[2024-12-14 02:25:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:08,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:08,955][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 1.951906681060791, acc: 0.49637681245803833)
[2024-12-14 02:25:09,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:09,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:09,339][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 2.0228521823883057, acc: 0.42023345828056335)
[2024-12-14 02:25:09,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:09,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:09,727][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 2.0135929584503174, acc: 0.42391303181648254)
[2024-12-14 02:25:09,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:09,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:10,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:10,126][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 0.7639272809028625, acc: 0.782608687877655)
[2024-12-14 02:25:10,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:10,462][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 1.0793906450271606, acc: 0.7857142686843872)
[2024-12-14 02:25:10,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:10,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:10,788][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 0.9652795791625977, acc: 0.7659574747085571)
[2024-12-14 02:25:10,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:10,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:11,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:11,470][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 1.5330449342727661, acc: 0.5692307949066162)
 [2024-12-14 02:25:11,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:11,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:11,861][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 1.2875896692276, acc: 0.662162184715271)
   [2024-12-14 02:25:11,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:11,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:12,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:12,398][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 0.8388457298278809, acc: 0.7419354915618896)
[2024-12-14 02:25:12,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:12,763][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 1.2074707746505737, acc: 0.6716417670249939)
                                                                              [2024-12-14 02:25:12,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:13,118][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 1.3132736682891846, acc: 0.6538461446762085)
[2024-12-14 02:25:13,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:13,464][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 1.4034733772277832, acc: 0.5111111402511597)
[2024-12-14 02:25:13,557][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:25:13,836][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 1.291497826576233, acc: 0.6290322542190552)
[2024-12-14 02:25:13,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:14,220][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.7101346850395203, acc: 0.800000011920929)
                                                                                                                                                                                                                                               [2024-12-14 02:25:14,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:14,597][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 1.8837109804153442, acc: 0.4444444477558136)
[2024-12-14 02:25:14,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:14,969][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 2.2728683948516846, acc: 0.3142857253551483)
[2024-12-14 02:25:15,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:15,341][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.7728420495986938, acc: 0.4871794879436493)
[2024-12-14 02:25:15,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:15,714][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 1.946545124053955, acc: 0.4878048896789551)
[2024-12-14 02:25:15,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:16,061][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.9365695714950562, acc: 0.5263158082962036)
[2024-12-14 02:25:16,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:16,427][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.637730062007904, acc: 0.8421052694320679)
[2024-12-14 02:25:16,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:16,821][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.31024566292762756, acc: 0.8928571343421936)
                                                                                                                                                            [2024-12-14 02:25:16,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:17,152][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 1.025043249130249, acc: 0.6666666865348816)
                                                                                                                                                              [2024-12-14 02:25:17,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:17,517][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.44266411662101746, acc: 0.9375)
                                                                                          [2024-12-14 02:25:17,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:17,907][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 1.5981614589691162, acc: 0.6290322542190552)
                                                                             [2024-12-14 02:25:18,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:18,288][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 1.4528987407684326, acc: 0.5964912176132202)
                                                                               [2024-12-14 02:25:18,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:18,661][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 1.7242722511291504, acc: 0.5)
                                                                                              [2024-12-14 02:25:18,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:18,981][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 0.8981347680091858, acc: 0.7333333492279053)
[2024-12-14 02:25:19,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:19,325][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 1.2772316932678223, acc: 0.5789473652839661)
[2024-12-14 02:25:19,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:19,686][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 2.090172052383423, acc: 0.4000000059604645)
                     [2024-12-14 02:25:19,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:20,091][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 2.164090394973755, acc: 0.39080458879470825)
                                                                                                                                                              [2024-12-14 02:25:20,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:20,468][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 2.2267792224884033, acc: 0.38297873735427856)
                                                                              [2024-12-14 02:25:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:20,791][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 2.4068188667297363, acc: 0.3734939694404602)
[2024-12-14 02:25:20,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:21,123][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.7098960876464844, acc: 0.739130437374115)
                                                    [2024-12-14 02:25:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:21,447][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 1.5910612344741821, acc: 0.5641025900840759)
                                                                                                                                                               [2024-12-14 02:25:21,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:21,818][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 2.1440935134887695, acc: 0.42168673872947693)
[2024-12-14 02:25:21,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:22,191][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 1.6871808767318726, acc: 0.5660377144813538)
21,782][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:25:21,782][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:25:21,968][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 1.2083796262741089, acc: 0.6136363744735718)
[2024-12-14 02:25:22,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:22,134][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_137_loss_1.731001615524292/model.pt
[2024-12-14 02:25:22,138][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:25:22,138][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.731001615524292
[2024-12-14 02:25:22,139][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.5590724349021912
[2024-12-14 02:25:22,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:22,290][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 1.5169918537139893, acc: 0.5909090638160706)
[2024-12-14 02:25:22,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:22,551][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 1.1509532928466797, acc: 0.6333333253860474)
[2024-12-14 02:25:22,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:22,867][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.7569597959518433, acc: 0.4677419364452362)
[2024-12-14 02:25:22,930][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 1.1304579973220825, acc: 0.739130437374115)
[2024-12-14 02:25:23,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:23,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:23,283][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 1.2719541788101196, acc: 0.6666666865348816)
[2024-12-14 02:25:23,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:23,395][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 1.417351245880127, acc: 0.6136363744735718)
[2024-12-14 02:25:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:23,649][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 1.6885172128677368, acc: 0.5)
                [2024-12-14 02:25:23,687][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.29442545771598816, acc: 0.9047619104385376)
[2024-12-14 02:25:23,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:23,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:24,035][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 2.409822940826416, acc: 0.32258063554763794)
[2024-12-14 02:25:24,053][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 0.7456650137901306, acc: 0.7692307829856873)
[2024-12-14 02:25:24,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:24,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:24,395][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.9701704382896423, acc: 0.774193525314331)
[2024-12-14 02:25:24,454][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 1.974208116531372, acc: 0.4324324429035187)
[2024-12-14 02:25:24,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:24,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:24,738][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.5539814233779907, acc: 0.800000011920929)
[2024-12-14 02:25:24,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:24,999][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 1.8745334148406982, acc: 0.42105263471603394)
[2024-12-14 02:25:25,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:25,107][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 1.048927903175354, acc: 0.6486486196517944)
[2024-12-14 02:25:25,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:25,383][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 1.658932089805603, acc: 0.5522388219833374)
[2024-12-14 02:25:25,455][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 1.0532721281051636, acc: 0.6756756901741028)
[2024-12-14 02:25:25,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:25,769][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.5372833013534546, acc: 0.782608687877655)
[2024-12-14 02:25:25,875][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:25:26,149][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 1.1620979309082031, acc: 0.6538461446762085)
                                                                                                                                                              [2024-12-14 02:25:26,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:26,568][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 2.251173973083496, acc: 0.37362638115882874)
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:25:26,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:27,069][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 1.8592219352722168, acc: 0.539130449295044)
                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:25:27,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:27,386][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 1.8114936351776123, acc: 0.554347813129425)
                                                                                                                            [2024-12-14 02:25:27,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:27,767][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 1.836435079574585, acc: 0.5102040767669678)
                                                                                                                                                                                                                         [2024-12-14 02:25:27,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:28,109][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.0639178454875946, acc: 1.0)
                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:25:28,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:28,474][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.5579238533973694, acc: 0.807692289352417)
                                                                                                                                        [2024-12-14 02:25:28,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:28,852][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 1.1770813465118408, acc: 0.7317073345184326)
                                                                                                                                                                                                                        [2024-12-14 02:25:28,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:29,231][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 1.5021294355392456, acc: 0.644444465637207)
[2024-12-14 02:25:29,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:29,570][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 1.6702574491500854, acc: 0.4736842215061188)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:25:29,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:29,925][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 1.4246954917907715, acc: 0.5609756112098694)
                                                                                                                                       [2024-12-14 02:25:30,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:30,238][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 1.367093801498413, acc: 0.5757575631141663)
 [2024-12-14 02:25:30,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:30,605][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.5104095935821533, acc: 0.875)
                                                                                                                                       [2024-12-14 02:25:30,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:30,948][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.14442101120948792, acc: 0.95652174949646)
                                                                                [2024-12-14 02:25:31,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:31,266][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.5557898283004761, acc: 0.7857142686843872)
[2024-12-14 02:25:31,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:31,629][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 0.857628345489502, acc: 0.75)
[2024-12-14 02:25:31,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:32,231][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 1.6611871719360352, acc: 0.5454545617103577)
                                                                                                                                                                                                                        [2024-12-14 02:25:32,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:33,092][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 1.2722971439361572, acc: 0.6603773832321167)
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:25:33,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:33,453][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 1.5028815269470215, acc: 0.6333333253860474)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:25:33,578][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:25:33,818][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 1.3928029537200928, acc: 0.5178571343421936)
                                                                             [2024-12-14 02:25:33,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:34,154][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.7490764856338501, acc: 0.7714285850524902)
                                                                                                                                                                                                                        [2024-12-14 02:25:34,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:34,501][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.20748022198677063, acc: 0.9200000166893005)
                                                                                                                                                                                                           [2024-12-14 02:25:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:34,875][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.400877982378006, acc: 0.8695651888847351)
                                                                                                                                                                                                                        [2024-12-14 02:25:35,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:35,256][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 1.2940584421157837, acc: 0.6458333134651184)
                                                                                                                                                                                                                        [2024-12-14 02:25:35,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:35,656][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 1.4584401845932007, acc: 0.6000000238418579)
                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:25:35,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:36,234][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 1.7093290090560913, acc: 0.5808383226394653)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:25:36,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:36,646][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 1.556815266609192, acc: 0.5563910007476807)
                                                                                                                                                                                                                        [2024-12-14 02:25:37,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:37,881][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 1.6032519340515137, acc: 0.5561497211456299)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:25:38,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:38,445][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 1.198489641][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.759262204170227, acc: 0.7407407164573669)
[2024-12-14 02:25:38,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:38,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:38,521][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 1.0226448774337769, acc: 0.6428571343421936)
[2024-12-14 02:25:38,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:38,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:38,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:39,062][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.6256574392318726, acc: 0.5575221180915833)
                                                          [2024-12-14 02:25:39,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:39,193][slam_llm.models.slam_model][INFO] - modality encoder
                                            [2024-12-14 02:25:39,501][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 1.5907468795776367, acc: 0.52173912525177)
[2024-12-14 02:25:39,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:39,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:39,851][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 1.6569594144821167, acc: 0.5340909361839294)
[2024-12-14 02:25:39,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:40,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:40,269][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:25:40,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:40,798][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 2.2165985107421875, acc: 0.442748099565506)
[2024-12-14 02:25:40,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:41,046][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:25:41,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:41,469][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 2.067563772201538, acc: 0.4000000059604645)
  [2024-12-14 02:25:41,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:41,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:41,846][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 1.379766821861267, acc: 0.6229507923126221)
[2024-12-14 02:25:41,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:42,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:42,187][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.6608954071998596, acc: 0.7916666865348816)
[2024-12-14 02:25:42,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:42,559][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 0.9703601598739624, acc: 0.7200000286102295)
[2024-12-14 02:25:42,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:42,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:42,931][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.9574967622756958, acc: 0.7142857313156128)
[2024-12-14 02:25:42,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:43,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:43,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:43,330][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 1.9241336584091187, acc: 0.46341463923454285)
[2024-12-14 02:25:43,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:43,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:43,748][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 2.122069835662842, acc: 0.42296072840690613)
[2024-12-14 02:25:43,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:43,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:44,081][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 2.2259464263916016, acc: 0.4005763828754425)
[2024-12-14 02:25:44,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:44,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:44,570][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 2.2345783710479736, acc: 0.43437498807907104)
[2024-12-14 02:25:44,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:44,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:44,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:45,103][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 2.0806539058685303, acc: 0.4127579629421234)
[2024-12-14 02:25:45,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:45,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:45,492][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 1.9614177942276, acc: 0.4661921560764313)
[2024-12-14 02:25:45,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:45,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:45,816][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 1.4734420776367188, acc: 0.5600000023841858)
[2024-12-14 02:25:45,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:45,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:46,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:46,368][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 1.9733527898788452, acc: 0.4651162922382355)
[2024-12-14 02:25:46,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:46,623][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:25:46,907][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:25:47,202][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.7390291690826416, acc: 0.5873016119003296)
[2024-12-14 02:25:47,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:47,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:47,652][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:25:47,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:48,119][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.903221845626831, acc: 0.5303030014038086)
[2024-12-14 02:25:48,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:48,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:48,717][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                      [2024-12-14 02:25:48,873][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 1.5665627717971802, acc: 0.6235294342041016)
[2024-12-14 02:25:49,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:49,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:49,408][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:25:49,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:49,770][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.46539995074272156, acc: 0.8636363744735718)
[2024-12-14 02:25:49,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:50,091][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 1.554694652557373, acc: 0.5882353186607361)
 [2024-12-14 02:25:50,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:50,458][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 1.1850247383117676, acc: 0.6538461446762085)
[2024-12-14 02:25:50,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:50,833][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 0.9726291298866272, acc: 0.6666666865348816)
[2024-12-14 02:25:50,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:51,233][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 1.2097266912460327, acc: 0.7250000238418579)
                                                                               [2024-12-14 02:25:51,323][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:25:51,588][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 0.6962557435035706, acc: 0.75)
                                                                                                                                                                           [2024-12-14 02:25:51,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:51,939][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.16578669846057892, acc: 0.9523809552192688)
[2024-12-14 02:25:52,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:52,307][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.8348475694656372, acc: 0.7333333492279053)
[2024-12-14 02:25:52,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:52,641][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.5458561778068542, acc: 0.84375)
                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:25:53,378][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:25:53,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:54,100][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:25:54,469][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:25:54,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:55,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:55,051][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 2.002950429916382, acc: 0.4803149700164795)
[2024-12-14 02:25:55,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:55,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:55,462][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 1.906558632850647, acc: 0.4612068831920624)
[2024-12-14 02:25:55,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:55,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:55,836][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 1.944385051727295, acc: 0.5181159377098083)
[2024-12-14 02:25:55,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:55,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:56,191][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 2.0440402030944824, acc: 0.443579763174057)
[2024-12-14 02:25:56,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:56,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:56,609][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 1.966368317604065, acc: 0.46739131212234497)
[2024-12-14 02:25:56,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:56,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:57,018][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 0.6669660210609436, acc: 0.739130437374115)
[2024-12-14 02:25:57,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:57,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:57,346][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 0.9959660172462463, acc: 0.75)
[2024-12-14 02:25:57,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:57,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:57,759][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 0.9144039750099182, acc: 0.7872340679168701)
[2024-12-14 02:25:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:57,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:58,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:58,442][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 1.5325570106506348, acc: 0.5692307949066162)
[2024-12-14 02:25:58,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:58,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:58,773][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 1.3454560041427612, acc: 0.6216216087341309)
[2024-12-14 02:25:58,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:59,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:59,176][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 1.3142669200897217, acc: 0.6511628031730652)
[2024-12-14 02:25:59,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:59,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:25:59,708][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 1.4329248666763306, acc: 0.6036036014556885)
[2024-12-14 02:25:59,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:00,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:00,117][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 1.4222123622894287, acc: 0.6000000238418579)
[2024-12-14 02:26:00,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:00,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:00,478][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.7009962201118469, acc: 0.7272727489471436)
[2024-12-14 02:26:00,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:00,945][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:26:01,397][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:26:01,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:02,157][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:26:02,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:02,792][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:26:03,140][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:26:03,444][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:26:03,771][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:26:04,135][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                         [2024-12-14 02:26:04,500][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:26:04,852][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:26:05,237][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:26:05,532][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:26:05,892][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:26:06,270][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.662309169769287, acc: 0.6100917458534241)
[2024-12-14 02:26:06,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:06,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:06,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:06,656][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 1.4010381698608398, acc: 0.6153846383094788)
[2024-12-14 02:26:06,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:06,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:07,004][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 0.9154559969902039, acc: 0.6842105388641357)
[2024-12-14 02:26:07,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:07,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:07,329][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.9376007914543152, acc: 0.7916666865348816)
[2024-12-14 02:26:07,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:07,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:07,648][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 1.5082412958145142, acc: 0.5454545617103577)
[2024-12-14 02:26:07,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:07,963][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 1.4504469633102417, acc: 0.48148149251937866)
[2024-12-14 02:26:08,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:08,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:08,335][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 1.024722933769226, acc: 0.6857143044471741)
[2024-12-14 02:26:08,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:08,631][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.1085, device='cuda:0') eval_epoch_loss=tensor(1.8097, device='cuda:0') eval_epoch_acc=tensor(0.5384, device='cuda:0')
[2024-12-14 02:26:08,632][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:26:08,632][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:26:08,701][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 1.379892349243164, acc: 0.5909090638160706)
[2024-12-14 02:26:08,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:08,861][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_280_loss_1.809674859046936/model.pt
[2024-12-14 02:26:08,865][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:26:08,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:09,015][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 1.6957858800888062, acc: 0.5909090638160706)
[2024-12-14 02:26:09,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:09,305][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 1.3186752796173096, acc: 0.6818181872367859)
[2024-12-14 02:26:09,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:09,610][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.8687351942062378, acc: 0.4838709533214569)
[2024-12-14 02:26:09,733][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 2.017352819442749, acc: 0.4819277226924896)
[2024-12-14 02:26:09,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:10,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:10,089][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 1.9193528890609741, acc: 0.48148149251937866)
[2024-12-14 02:26:10,149][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 1.3967057466506958, acc: 0.5909090638160706)
[2024-12-14 02:26:10,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:10,463][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.21327686309814453, acc: 0.9523809552192688)
[2024-12-14 02:26:10,479][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 1.6292434930801392, acc: 0.5789473652839661)
[2024-12-14 02:26:10,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:10,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:10,822][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 0.6997567415237427, acc: 0.8461538553237915)
[2024-12-14 02:26:10,856][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 1.70551598072052, acc: 0.5)
[2024-12-14 02:26:10,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:10,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:11,173][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.7084334492683411, acc: 0.8064516186714172)
[2024-12-14 02:26:11,213][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 1.4058961868286133, acc: 0.574999988079071)
[2024-12-14 02:26:11,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:11,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:11,541][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.5875954031944275, acc: 0.75)
[2024-12-14 02:26:11,631][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 2.039278268814087, acc: 0.3828125)
[2024-12-14 02:26:11,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:11,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:11,901][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 1.1855909824371338, acc: 0.7027027010917664)
[2024-12-14 02:26:11,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:12,024][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 2.174441337585449, acc: 0.41600000858306885)
[2024-12-14 02:26:12,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:12,270][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 1.2112228870391846, acc: 0.6216216087341309)
[2024-12-14 02:26:12,346][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 1.7652171850204468, acc: 0.5714285969734192)
[2024-12-14 02:26:12,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:12,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:12,669][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 1.1276938915252686, acc: 0.5945945978164673)
[2024-12-14 02:26:12,679][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 2.1309871673583984, acc: 0.4658385217189789)
[2024-12-14 02:26:12,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:12,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:13,040][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 1.4856936931610107, acc: 0.5441176295280457)
[2024-12-14 02:26:13,045][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 2.2266685962677, acc: 0.4020618498325348)
[2024-12-14 02:26:13,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:13,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:13,396][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.45958003401756287, acc: 0.7727272510528564)
[2024-12-14 02:26:13,428][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.550521194934845, acc: 0.8536585569381714)
[2024-12-14 02:26:13,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:13,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:13,755][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 1.7186377048492432, acc: 0.6190476417541504)
[2024-12-14 02:26:13,763][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.18497104942798615, acc: 0.9599999785423279)
[2024-12-14 02:26:13,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:13,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:14,078][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 1.104817271232605, acc: 0.6379310488700867)
[2024-12-14 02:26:14,092][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.14358192682266235, acc: 1.0)
[2024-12-14 02:26:14,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:14,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:14,455][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.3144736886024475, acc: 0.9677419066429138)
[2024-12-14 02:26:14,533][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 1.0395420789718628, acc: 0.7636363506317139)
[2024-12-14 02:26:14,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:14,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:14,819][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 1.1367576122283936, acc: 0.6842105388641357)
[2024-12-14 02:26:14,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:15,077][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.655211091041565, acc: 0.5773195624351501)
[2024-12-14 02:26:15,144][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 1.4138047695159912, acc: 0.6000000238418579)
[2024-12-14 02:26:15,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:15,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:15,369][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 1.89405357837677, acc: 0.4655172526836395)
[2024-12-14 02:26:15,452][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 1.1711763143539429, acc: 0.6973684430122375)
[2024-12-14 02:26:15,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:15,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:15,703][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 1.2236864566802979, acc: 0.6296296119689941)
[2024-12-14 02:26:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:16,042][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 1.4577178955078125, acc: 0.5377358198165894)
[2024-12-14 02:26:16,088][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 1.4186997413635254, acc: 0.5789473652839661)
[2024-12-14 02:26:16,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:16,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:16,471][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 1.205297589302063, acc: 0.6964285969734192)
[2024-12-14 02:26:16,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:16,631][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 1.6712154150009155, acc: 0.5249999761581421)
[2024-12-14 02:26:16,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:16,805][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 1.167673945426941, acc: 0.65625)
[2024-12-14 02:26:16,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:16,969][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 0.9194937944412231, acc: 0.7222222089767456)
[2024-12-14 02:26:17,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:17,183][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 1.2435766458511353, acc: 0.698113203048706)
[2024-12-14 02:26:17,377][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.1744296550750732, acc: 0.6129032373428345)
[2024-12-14 02:26:17,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:17,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:17,538][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.7691664695739746, acc: 0.7735849022865295)
[2024-12-14 02:26:17,606][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 2.5453453063964844, acc: 0.3866666555404663)
[2024-12-14 02:26:17,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:17,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:17,928][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 0.9590290188789368, acc: 0.7058823704719543)
[2024-12-14 02:26:17,945][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 1.8530850410461426, acc: 0.5208333134651184)
[2024-12-14 02:26:18,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:18,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:18,283][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 1.229123830795288, acc: 0.6875)
[2024-12-14 02:26:18,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:18,657][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 1.1204420328140259, acc: 0.7213114500045776)
[2024-12-14 02:26:18,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:18,766][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 2.2676377296447754, acc: 0.4000000059604645)
[2024-12-14 02:26:18,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:19,004][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.5621095895767212, acc: 0.9333333373069763)
[2024-12-14 02:26:19,032][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 2.0560410022735596, acc: 0.43820226192474365)
[2024-12-14 02:26:19,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:19,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:19,345][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.37298405170440674, acc: 0.9473684430122375)
[2024-12-14 02:26:19,398][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 2.012115001678467, acc: 0.4864864945411682)
[2024-12-14 02:26:19,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:19,731][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 1.6760759353637695, acc: 0.52173912525177)
[2024-12-14 02:26:19,851][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 1.2920477390289307, acc: 0.6034482717514038)
[2024-12-14 02:26:19,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:19,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:20,144][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 1.4046626091003418, acc: 0.6527777910232544)
[2024-12-14 02:26:20,147][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.6603512167930603, acc: 0.8181818127632141)
[2024-12-14 02:26:20,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:20,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:20,428][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.53681880235672, acc: 0.8636363744735718)
[2024-12-14 02:26:20,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:20,526][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 1.3096978664398193, acc: 0.6265060305595398)
[2024-12-14 02:26:20,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:20,736][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.8022183179855347, acc: 0.8125)
[2024-12-14 02:26:20,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:20,877][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 1.9097989797592163, acc: 0.44871795177459717)
[2024-12-14 02:26:20,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:21,054][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 0.8070693612098694, acc: 0.800000011920929)
[2024-12-14 02:26:21,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:21,253][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 1.9355577230453491, acc: 0.5102040767669678)
[2024-12-14 02:26:21,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:21,401][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 1.5017257928848267, acc: 0.5833333134651184)
[2024-12-14 02:26:21,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:21,614][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.1564035266637802, acc: 0.9583333134651184)
[2024-12-14 02:26:21,676][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 1.0053703784942627, acc: 0.6875)
[2024-12-14 02:26:21,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:21,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:21,987][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.5841517448425293, acc: 0.9166666865348816)
[2024-12-14 02:26:21,989][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.6213499903678894, acc: 0.8333333134651184)
[2024-12-14 02:26:22,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:22,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:22,231][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 0.9693325757980347, acc: 0.7931034564971924)
[2024-12-14 02:26:22,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:22,368][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.7303333878517151, acc: 0.8064516186714172)
[2024-12-14 02:26:22,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:22,519][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 0.592567503452301, acc: 0.8399999737739563)
[2024-12-14 02:26:22,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:22,725][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 0.8785437345504761, acc: 0.6774193644523621)
[2024-12-14 02:26:22,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:22,869][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 1.7399964332580566, acc: 0.44680851697921753)
[2024-12-14 02:26:22,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:23,113][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 1.2108590602874756, acc: 0.6865671873092651)
[2024-12-14 02:26:23,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:23,248][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 1.4602603912353516, acc: 0.5625)
[2024-12-14 02:26:23,464][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 1.3112841844558716, acc: 0.6634615659713745)
[2024-12-14 02:26:23,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:23,796][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 1.3518519401550293, acc: 0.5555555820465088)
[2024-12-14 02:26:23,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:24,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:24,141][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 1.263145923614502, acc: 0.6774193644523621)
                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:26:24,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:24,529][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 0.8388330936431885, acc: 0.8055555820465088)
                                                                               [2024-12-14 02:26:24,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:24,900][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 0.6677818894386292, acc: 0.8518518805503845)
                                                                                [2024-12-14 02:26:25,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:25,300][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 1.3584150075912476, acc: 0.6969696879386902)
                                                                              [2024-12-14 02:26:25,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:25,621][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 1.274928092956543, acc: 0.6521739363670349)
                                                                                [2024-12-14 02:26:25,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:25,971][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 1.2557178735733032, acc: 0.6216216087341309)
                                                                                                                                                              [2024-12-14 02:26:26,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:26,297][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 0.8688542246818542, acc: 0.7037037014961243)
                                                                               [2024-12-14 02:26:26,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:26,649][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.7504866123199463, acc: 0.782608687877655)
 [2024-12-14 02:26:26,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:26,975][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.23059028387069702, acc: 0.9259259104728699)
                                                                                                                                                              [2024-12-14 02:26:27,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:27,329][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.33959633111953735, acc: 0.8888888955116272)
                                                                              [2024-12-14 02:26:27,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:27,701][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.74102783203125, acc: 0.782608687877655)
                                                                      [2024-12-14 02:26:27,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:28,102][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 1.0709261894226074, acc: 0.7222222089767456)
                                                                              [2024-12-14 02:26:28,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:28,447][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.49317798018455505, acc: 0.8799999952316284)
[2024-12-14 02:26:28,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:28,823][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 0.9798364639282227, acc: 0.6969696879386902)
                                                                                                                                                 [2024-12-14 02:26:28,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:29,194][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 1.2412774562835693, acc: 0.6388888955116272)
2024-12-14 02:26:29,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:29,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:29,402][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 1.2255674600601196, acc: 0.6842105388641357)
[2024-12-14 02:26:29,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:29,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:29,758][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 2.0705161094665527, acc: 0.41999998688697815)
[2024-12-14 02:26:29,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:29,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:30,133][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 2.1933577060699463, acc: 0.39080458879470825)
[2024-12-14 02:26:30,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:30,486][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 2.2564024925231934, acc: 0.40425533056259155)
[2024-12-14 02:26:30,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:30,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:30,839][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 2.326336622238159, acc: 0.3855421543121338)
[2024-12-14 02:26:30,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:30,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:31,167][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.6479920744895935, acc: 0.782608687877655)
[2024-12-14 02:26:31,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:31,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:31,478][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 1.569144606590271, acc: 0.5641025900840759)
[2024-12-14 02:26:31,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:31,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:31,783][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 2.0882906913757324, acc: 0.4457831382751465)
[2024-12-14 02:26:31,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:32,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:32,139][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 1.7246472835540771, acc: 0.5660377144813538)
[2024-12-14 02:26:32,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:32,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:32,469][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 1.5493115186691284, acc: 0.5569620132446289)
[2024-12-14 02:26:32,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:32,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:32,793][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 1.5542093515396118, acc: 0.5686274766921997)
[2024-12-14 02:26:32,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:33,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:33,126][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 2.08734393119812, acc: 0.4029850661754608)
[2024-12-14 02:26:33,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:33,487][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.38176625967025757, acc: 0.8999999761581421)
[2024-12-14 02:26:33,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:33,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:33,801][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 0.943744957447052, acc: 0.6800000071525574)
[2024-12-14 02:26:33,939][slamm_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:34,407][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.8500452041625977, acc: 0.7142857313156128)
                                                                                                                                                             [2024-12-14 02:26:34,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:34,728][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 1.5354551076889038, acc: 0.611940324306488)
                                                                                [2024-12-14 02:26:34,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:35,105][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 1.4089250564575195, acc: 0.5833333134651184)
[2024-12-14 02:26:35,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:35,437][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 1.506384253501892, acc: 0.532608687877655)
                                                                                                                                                               [2024-12-14 02:26:35,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:35,800][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 1.6233711242675781, acc: 0.5897436141967773)
                                                                               [2024-12-14 02:26:35,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:36,133][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 1.8187651634216309, acc: 0.5789473652839661)
                                                                               [2024-12-14 02:26:36,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:36,486][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 1.6696587800979614, acc: 0.5714285969734192)
                                                                                [2024-12-14 02:26:36,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:36,769][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 0.9724341630935669, acc: 0.7575757503509521)
[2024-12-14 02:26:36,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:37,147][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 1.9474951028823853, acc: 0.4845360815525055)
[2024-12-14 02:26:37,230][slam_llm.models.slam_model][INFO] - modality encoder
                                                                             [2024-12-14 02:26:37,472][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 1.4864745140075684, acc: 0.5571428537368774)
[2024-12-14 02:26:37,574][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:26:37,879][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 1.9225958585739136, acc: 0.48255813121795654)
                                                                [2024-12-14 02:26:37,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:38,230][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 1.8528416156768799, acc: 0.5)
                                                                                              [2024-12-14 02:26:38,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:38,576][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 1.8119527101516724, acc: 0.48148149251937866)
                                                                              [2024-12-14 02:26:38,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:38,916][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 1.3419140577316284, acc: 0.6388888955116272)
[2024-12-14 02:26:39,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:39,235][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 1.0724409818649292, acc: 0.75)
                                 [2024-12-14 02:26:39,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:39,575][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 0.9692543745040894, acc: 0.692307710647583)
                                                                                [2024-12-14 02:26:39,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:39,911][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 1.0250957012176514, acc: 0.739130437374115)
                                                                                [2024-12-14 02:26:39,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:40,206][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 1.6105806827545166, acc: 0.4642857015132904)
[2024-12-14 02:26:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:40,516][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.8953447341918945, acc: 0.4939759075641632)
[2024-12-14 02:26:40,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:40,853][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 1.4529461860656738, acc: 0.5765765905380249)
                                                                                                                                                [2024-12-14 02:26:40,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:41,186][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.6891396045684814, acc: 0.5631067752838135)
 [2024-12-14 02:26:41,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:41,553][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 1.3567988872528076, acc: 0.6260162591934204)
                                                                    [2024-12-14 02:26:41,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:41,907][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 0.8082325458526611, acc: 0.75)
[2024-12-14 02:26:42,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:42,282][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 1.2854249477386475, acc: 0.6785714030265808)
[2024-12-14 02:26:42,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:42,715][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 2.0131845474243164, acc: 0.44117647409439087)
[2024-12-14 02:26:42,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:43,078][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 2.1776373386383057, acc: 0.4104803502559662)
[2024-12-14 02:26:43,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:43,415][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 1.9433202743530273, acc: 0.46875)
                                                                                          [2024-12-14 02:26:43,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:43,848][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 2.0375263690948486, acc: 0.44171780347824097)
                                                                                                                                                             [2024-12-14 02:26:43,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:44,239][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 1.9944781064987183, acc: 0.4748201370239258)
                                                                              [2024-12-14 02:26:44,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:44,605][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 2.220601797103882, acc: 0.3919597864151001)
)
[2024-12-14 02:26:44,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:44,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:44,681][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.25546354055404663, acc: 0.9130434989929199)
[2024-12-14 02:26:44,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:44,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:44,983][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 1.2279072999954224, acc: 0.6666666865348816)
[2024-12-14 02:26:45,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:45,379][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 1.5013946294784546, acc: 0.6105263233184814)
[2024-12-14 02:26:45,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:45,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:45,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:45,965][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 1.6390082836151123, acc: 0.598802387714386)
[2024-12-14 02:26:46,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:46,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:46,397][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 1.3870341777801514, acc: 0.61654132604599)
[2024-12-14 02:26:46,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:46,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:46,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:47,284][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                   [2024-12-14 02:26:47,652][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 1.6304848194122314, acc: 0.5721924901008606)
                                                                               [2024-12-14 02:26:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:47,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:48,216][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 1.284274935722351, acc: 0.6666666865348816)
[2024-12-14 02:26:48,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:48,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:48,539][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.5655226111412048, acc: 0.8571428656578064)
[2024-12-14 02:26:48,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:48,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:48,875][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.5061272978782654, acc: 0.8928571343421936)
[2024-12-14 02:26:48,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:49,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:49,217][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 0.813947319984436, acc: 0.78125)
[2024-12-14 02:26:49,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:49,582][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.6550739407539368, acc: 0.8333333134651184)
[2024-12-14 02:26:49,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:49,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:49,900][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.6527772545814514, acc: 0.8157894611358643)
[2024-12-14 02:26:50,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:50,400][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 1.0766870975494385, acc: 0.6551724076271057)
10, step 388/574 completed (loss: 0.33236488699913025, acc: 0.8636363744735718)
[2024-12-14 02:26:50,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:50,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:50,615][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.6332663893699646, acc: 0.75)
[2024-12-14 02:26:50,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:50,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:50,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:50,979][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.5326011776924133, acc: 0.8571428656578064)
[2024-12-14 02:26:51,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:51,334][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 2.1567189693450928, acc: 0.46296295523643494)
[2024-12-14 02:26:51,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:51,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:51,725][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 2.1571438312530518, acc: 0.48543688654899597)
[2024-12-14 02:26:51,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:51,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:52,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:52,247][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 1.824209213256836, acc: 0.5441176295280457)
[2024-12-14 02:26:52,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:52,631][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 2.1288645267486572, acc: 0.4533333480358124)
[2024-12-14 02:26:52,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:52,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:53,019][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 2.1007134914398193, acc: 0.4583333432674408)
[2024-12-14 02:26:53,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:53,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:53,381][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 1.3696027994155884, acc: 0.7209302186965942)
[2024-12-14 02:26:53,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:53,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:53,738][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.5318084955215454, acc: 0.8333333134651184)
[2024-12-14 02:26:53,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:53,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:54,138][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 1.24998140335083, acc: 0.6976743936538696)
[2024-12-14 02:26:54,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:54,528][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 1.003495454788208, acc: 0.800000011920929)
[2024-12-14 02:26:54,619][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.0193, device='cuda:0') eval_epoch_loss=tensor(1.7950, device='cuda:0') eval_epoch_acc=tensor(0.5497, device='cuda:0')
[2024-12-14 02:26:54,620][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:26:54,620][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:26:54,944][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 1.0777807235717773, acc: 0.6896551847457886)
r][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_280_loss_1.7949726581573486/model.pt
[2024-12-14 02:26:54,823][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:26:54,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:55,061][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 1.5480544567108154, acc: 0.5735294222831726)
[2024-12-14 02:26:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:55,249][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 1.3238823413848877, acc: 0.6818181872367859)
[2024-12-14 02:26:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:55,458][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 1.523929476737976, acc: 0.5600000023841858)
[2024-12-14 02:26:55,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:55,671][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 1.9452283382415771, acc: 0.5060241222381592)
[2024-12-14 02:26:55,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:55,801][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 0.9933855533599854, acc: 0.6969696879386902)
[2024-12-14 02:26:55,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:55,989][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 1.8552610874176025, acc: 0.5185185074806213)
[2024-12-14 02:26:56,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:56,122][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 0.6079912781715393, acc: 0.8181818127632141)
[2024-12-14 02:26:56,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:56,368][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 1.4865318536758423, acc: 0.5526315569877625)
[2024-12-14 02:26:56,469][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.5410841107368469, acc: 0.8387096524238586)
[2024-12-14 02:26:56,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:56,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:56,749][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 1.6494474411010742, acc: 0.5588235259056091)
[2024-12-14 02:26:56,776][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.7794184684753418, acc: 0.8148148059844971)
[2024-12-14 02:26:56,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:56,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:58,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:59,588][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 1.8261786699295044, acc: 0.5071428418159485)
077905058860779, acc: 0.8399999737739563)
[2024-12-14 02:26:57,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:57,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:57,447][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 2.054868698120117, acc: 0.4140625)
[2024-12-14 02:26:57,478][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.7277076840400696, acc: 0.75)
[2024-12-14 02:26:57,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:57,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:57,811][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 2.149367570877075, acc: 0.40799999237060547)
[2024-12-14 02:26:57,843][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.685967743396759, acc: 0.7407407164573669)
[2024-12-14 02:26:57,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:57,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:58,131][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 1.6496108770370483, acc: 0.5824176073074341)
[2024-12-14 02:26:58,200][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.48118704557418823, acc: 0.807692289352417)
[2024-12-14 02:26:58,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:58,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:58,471][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 2.160331964492798, acc: 0.42236024141311646)
[2024-12-14 02:26:58,555][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 1.1153013706207275, acc: 0.6896551847457886)
[2024-12-14 02:26:58,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:58,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:58,832][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 2.250561475753784, acc: 0.37628865242004395)
[2024-12-14 02:26:58,893][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.5248671174049377, acc: 0.8928571343421936)
[2024-12-14 02:26:58,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:58,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:59,145][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.3805027902126312, acc: 0.8636363744735718)
[2024-12-14 02:26:59,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:59,257][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.788179337978363, acc: 0.800000011920929)
[2024-12-14 02:26:59,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:59,495][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 1.6160125732421875, acc: 0.5952380895614624)
[2024-12-14 02:26:59,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:59,663][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.47301506996154785, acc: 0.8787878751754761)
[2024-12-14 02:26:59,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:26:59,792][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 1.2615448236465454, acc: 0.6379310488700867)
[2024-12-14 02:26:59,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:00,027][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.6097246408462524, acc: 0.8181818127632141)
[2024-12-14 02:27:00,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:00,263][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 1.1511701345443726, acc: 0.7272727489471436)
[2024-12-14 02:27:00,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:00,419][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 1.6221423149108887, acc: 0.5490196347236633)
[2024-12-14 02:27:00,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:00,754][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 1.2755413055419922, acc: 0.7307692170143127)
[2024-12-14 02:27:00,821][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.6271867752075195, acc: 0.6030927896499634)
[2024-12-14 02:27:00,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:00,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:01,051][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 0.9281639456748962, acc: 0.6666666865348816)
[2024-12-14 02:27:01,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:01,770][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 1.2482272386550903, acc: 0.7083333134651184)

[2024-12-14 02:27:01,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:01,424][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 1.1711773872375488, acc: 0.675000011920929)
[2024-12-14 02:27:01,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:01,531][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 1.3005125522613525, acc: 0.6666666865348816)
[2024-12-14 02:27:01,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:01,746][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 0.5205605626106262, acc: 0.8999999761581421)
[2024-12-14 02:27:01,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:01,876][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 1.4619137048721313, acc: 0.6578947305679321)
[2024-12-14 02:27:01,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:02,099][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.11622518301010132, acc: 0.9523809552192688)
[2024-12-14 02:27:02,202][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 1.0821454524993896, acc: 0.7142857313156128)
[2024-12-14 02:27:02,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:02,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:02,449][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.6588097214698792, acc: 0.8333333134651184)
[2024-12-14 02:27:02,566][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 1.175325870513916, acc: 0.6875)
[2024-12-14 02:27:02,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:02,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:02,833][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.8249595761299133, acc: 0.65625)
[2024-12-14 02:27:02,919][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 1.3594757318496704, acc: 0.6603773832321167)
[2024-12-14 02:27:03,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:03,323][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.7836065292358398, acc: 0.7735849022865295)
[2024-12-14 02:27:03,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:03,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:03,654][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 0.9760267734527588, acc: 0.7058823704719543)
[2024-12-14 02:27:03,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:03,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:03,995][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 1.3562407493591309, acc: 0.625)
[2024-12-14 02:27:04,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:04,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:04,318][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 1.0696825981140137, acc: 0.7049180269241333)
[2024-12-14 02:27:04,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:04,623][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.44681692123413086, acc: 0.8666666746139526)
[2024-12-14 02:27:04,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:04,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:04,930][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.2364574670791626, acc: 0.8947368264198303)
[2024-12-14 02:27:05,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:05,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:05,293][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 1.7559642791748047, acc: 0.5072463750839233)
[2024-12-14 02:27:05,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:05,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:05,743][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 1.384002447128296, acc: 0.6388888955116272)
[2024-12-14 02:27:05,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:05,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:06,076][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 1.3602782487869263, acc: 0.5903614163398743)
[2024-12-14 02:27:06,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:06,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:06,610][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 1.3208354711532593, acc: 0.6190476417541504)
[2024-12-14 02:27:06,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:06,994][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 2.390549421310425, acc: 0.4262295067310333)
                                                                                [2024-12-14 02:27:07,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:07,340][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 1.529037594795227, acc: 0.6101694703102112)
                                                                                                                                                                [2024-12-14 02:27:07,422][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                            [2024-12-14 02:27:07,696][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.8500405550003052, acc: 0.5116279125213623)
[2024-12-14 02:27:07,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:08,087][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 1.753160834312439, acc: 0.5454545617103577)
                                                                                                                                                                                                                                           [2024-12-14 02:27:08,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:08,473][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 2.031128406524658, acc: 0.4716981053352356)
                                                                                                                                                               [2024-12-14 02:27:08,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:08,860][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 1.4819172620773315, acc: 0.6363636255264282)
                                                                              [2024-12-14 02:27:08,968][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:09,194][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 1.1006158590316772, acc: 0.6399999856948853)
[2024-12-14 02:27:09,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:09,473][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.7825061082839966, acc: 0.800000011920929)
[2024-12-14 02:27:09,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:09,878][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.5794119238853455, acc: 0.8636363744735718)
                                                                                                     [2024-12-14 02:27:10,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:10,278][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 1.5528678894042969, acc: 0.5692307949066162)
[2024-12-14 02:27:10,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:10,613][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 1.5729457139968872, acc: 0.625)
                                                                                            [2024-12-14 02:27:10,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:11,010][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 0.9261472225189209, acc: 0.875)
                                                                                           [2024-12-14 02:27:11,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:11,377][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 1.3754757642745972, acc: 0.6060606241226196)
                                                                                [2024-12-14 02:27:11,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:11,714][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.8410943746566772, acc: 0.8125)
                                                                                           [2024-12-14 02:27:11,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:12,091][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.5152156352996826, acc: 0.8387096524238586)
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:27:12,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:12,446][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.13152386248111725, acc: 1.0)
              [2024-12-14 02:27:12,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:12,810][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 1.7062541246414185, acc: 0.6000000238418579)
                                                                                                                                                  [2024-12-14 02:27:12,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:13,212][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 1.2025399208068848, acc: 0.6585366129875183)
                                                                               [2024-12-14 02:27:13,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:13,558][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.8535195589065552, acc: 0.800000011920929)
                                                                                [2024-12-14 02:27:13,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:13,905][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.8015526533126831, acc: 0.8157894611358643)
[2024-12-14 02:27:14,001][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                            [2024-12-14 02:27:14,243][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.9457626938819885, acc: 0.7096773982048035)
[2024-12-14 02:27:14,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:14,603][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.3427251875400543, acc: 0.9200000166893005)
                                                                               [2024-12-14 02:27:14,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:14,953][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.6623589992523193, acc: 0.7575757503509521)
                                                                               [2024-12-14 02:27:15,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:15,319][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.7630239129066467, acc: 0.7250000238418579)
                                                                               [2024-12-14 02:27:15,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:15,756][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 0.9281693696975708, acc: 0.7142857313156128)
                                                                               [2024-12-14 02:27:15,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:16,168][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 2.049046754837036, acc: 0.47445255517959595)
                                                                                                                                                              [2024-12-14 02:27:16,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:16,552][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 1.548688530921936, acc: 0.5586206912994385)
                                                                               [2024-12-14 02:27:16,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:16,903][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 2.2993323802948, acc: 0.4214285612106323)
                                                                                  [2024-12-14 02:27:17,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:17,249][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 1.9650501012802124, acc: 0.46357616782188416)
                                                                               [2024-12-14 02:27:17,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:17,632][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 1.6385940313339233, acc: 0.5555555820465088)
                                                                               [2024-12-14 02:27:17,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:17,942][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.2887621521949768, acc: 0.9200000166893005)
[2024-12-14 02:27:18,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:18,306][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.686642050743103, acc: 0.807692289352417)
                                                                                [2024-12-14 02:27:18,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:18,642][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.41684362292289734, acc: 0.8846153616905212)
                                                                              [2024-12-14 02:27:18,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:19,024][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 1.2407211065292358, acc: 0.692307710647583)
                                                                                [2024-12-14 02:27:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:19,394][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 1.2993688583374023, acc: 0.6111111044883728)
                                                                                                                                                              [2024-12-14 02:27:19,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:19,744][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 1.3265113830566406, acc: 0.5974025726318359)
[2024-12-14 02:27:19,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:20,110][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 0.875342607498169, acc: 0.7916666865348816)
                                                                               [2024-12-14 02:27:20,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:20,488][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 0.9571300148963928, acc: 0.7241379022598267)
                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:27:21,169][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:27:21,511][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:21,828][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:27:22,142][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:22,527][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:27:22,856][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:23,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:23,489][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:27:23,899][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:27:24,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:24,530][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:27:24,892][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:25,361][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:27:25,713][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                             [2024-12-14 02:27:26,057][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:27:26,488][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:26,937][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                         [2024-12-14 02:27:27,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:27,531][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:27:27,802][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:27:28,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:28,383][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:27:28,748][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:29,086][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:27:29,466][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:27:29,932][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:30,318][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:27:30,693][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:30,989][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 02:27:31,309][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:27:31,648][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:27:31,989][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:27:32,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:32,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:33,137][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:27:33,564][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:27:33,988][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:27:34,359][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:27:34,839][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:27:35,133][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:27:35,459][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:27:35,743][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:27:36,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:35,983][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 1.7576323747634888, acc: 0.739130437374115)
[2024-12-14 02:27:36,016][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.705210268497467, acc: 0.699999988079071)
[2024-12-14 02:27:36,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:36,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:36,318][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 1.2929539680480957, acc: 0.6756756901741028)
[2024-12-14 02:27:36,351][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.4357340633869171, acc: 0.9523809552192688)
[2024-12-14 02:27:36,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:36,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:36,649][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 0.6297886371612549, acc: 0.8518518805503845)
[2024-12-14 02:27:36,680][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 2.133646011352539, acc: 0.48148149251937866)
[2024-12-14 02:27:36,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:36,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:36,988][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.776555597782135, acc: 0.782608687877655)
[2024-12-14 02:27:37,012][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 2.140105962753296, acc: 0.43689319491386414)
[2024-12-14 02:27:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:37,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:37,337][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.2804541289806366, acc: 0.9629629850387573)
[2024-12-14 02:27:37,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:37,537][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 1.8260648250579834, acc: 0.5441176295280457)
[2024-12-14 02:27:37,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:37,719][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.3582759201526642, acc: 0.9259259104728699)
[2024-12-14 02:27:37,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:37,905][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 2.1063003540039062, acc: 0.47999998927116394)
[2024-12-14 02:27:38,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:38,048][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 1.0898634195327759, acc: 0.695652186870575)
[2024-12-14 02:27:38,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:38,290][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 2.088073492050171, acc: 0.4791666567325592)
[2024-12-14 02:27:38,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:38,429][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 1.0707554817199707, acc: 0.7222222089767456)
[2024-12-14 02:27:38,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:38,670][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 1.411813735961914, acc: 0.6744186282157898)
[2024-12-14 02:27:38,762][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.5538551211357117, acc: 0.8399999737739563)
[2024-12-14 02:27:38,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:38,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:38,998][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.5755414366722107, acc: 0.875)
[2024-12-14 02:27:39,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:39,137][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 1.120201587677002, acc: 0.6969696879386902)
[2024-12-14 02:27:39,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:39,413][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 1.3582763671875, acc: 0.6511628031730652)
[2024-12-14 02:27:39,466][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 1.1810132265090942, acc: 0.7222222089767456)
[2024-12-14 02:27:39,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:39,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:39,805][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 1.0836169719696045, acc: 0.6800000071525574)
[2024-12-14 02:27:39,845][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 1.0347803831100464, acc: 0.7272727489471436)
[2024-12-14 02:27:39,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:39,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:40,173][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.3681888282299042, acc: 0.9523809552192688)
[2024-12-14 02:27:40,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:40,342][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 1.6426892280578613, acc: 0.5735294222831726)
[2024-12-14 02:27:40,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:40,572][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 1.5799800157546997, acc: 0.6153846383094788)
[2024-12-14 02:27:40,660][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 1.6096348762512207, acc: 0.5333333611488342)
[2024-12-14 02:27:40,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:40,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:41,037][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 0.9950940608978271, acc: 0.6969696879386902)
[2024-12-14 02:27:41,039][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 1.7882094383239746, acc: 0.5454545617103577)
[2024-12-14 02:27:41,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:41,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:41,406][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 0.9467805624008179, acc: 0.8181818127632141)
[2024-12-14 02:27:41,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:41,733][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 2.1675221920013428, acc: 0.42399999499320984)
[2024-12-14 02:27:41,752][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.37470829486846924, acc: 0.9032257795333862)
[2024-12-14 02:27:41,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:41,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:42,116][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.9289318323135376, acc: 0.7777777910232544)
[2024-12-14 02:27:42,145][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 2.019681930541992, acc: 0.49193549156188965)
[2024-12-14 02:27:42,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:42,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:42,511][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.4466266632080078, acc: 0.9200000166893005)
[2024-12-14 02:27:42,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:42,792][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 1.9535703659057617, acc: 0.46766167879104614)
[2024-12-14 02:27:42,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:42,902][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.7036159038543701, acc: 0.7777777910232544)
[2024-12-14 02:27:43,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:43,110][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 1.5957282781600952, acc: 0.5849056839942932)
[2024-12-14 02:27:43,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:43,267][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.7082821130752563, acc: 0.7777777910232544)
[2024-12-14 02:27:43,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:43,536][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 0.7395187020301819, acc: 0.7727272510528564)
[2024-12-14 02:27:43,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:43,625][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.3641202747821808, acc: 0.8846153616905212)
[2024-12-14 02:27:43,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:43,820][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 0.7641940116882324, acc: 0.782608687877655)
[2024-12-14 02:27:43,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:43,969][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 1.0744361877441406, acc: 0.6896551847457886)
[2024-12-14 02:27:44,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:44,114][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 0.895541250705719, acc: 0.7692307829856873)
[2024-12-14 02:27:44,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:44,273][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.6525295972824097, acc: 0.8214285969734192)
[2024-12-14 02:27:44,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:44,472][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.690546989440918, acc: 0.7857142686843872)
[2024-12-14 02:27:44,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:44,628][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.5547282099723816, acc: 0.8666666746139526)
[2024-12-14 02:27:44,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:44,807][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 1.706294059753418, acc: 0.5522388219833374)
[2024-12-14 02:27:44,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:44,953][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.6150798201560974, acc: 0.8787878751754761)
[2024-12-14 02:27:45,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:45,147][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 1.3966374397277832, acc: 0.6666666865348816)
[2024-12-14 02:27:45,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:45,242][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.5079155564308167, acc: 0.8181818127632141)
[2024-12-14 02:27:45,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:45,482][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 1.516880989074707, acc: 0.52173912525177)
[2024-12-14 02:27:45,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:45,606][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 1.5058530569076538, acc: 0.6078431606292725)
[2024-12-14 02:27:45,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:45,878][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 1.6045995950698853, acc: 0.5128205418586731)
[2024-12-14 02:27:45,941][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 1.4182976484298706, acc: 0.6538461446762085)
[2024-12-14 02:27:45,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:46,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:46,226][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 1.8160734176635742, acc: 0.5263158082962036)
[2024-12-14 02:27:46,263][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 1.0854078531265259, acc: 0.6111111044883728)
[2024-12-14 02:27:46,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:46,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:46,588][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:27:47,009][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:27:47,334][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:27:47,702][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:27:47,996][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:27:48,334][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:27:48,639][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:27:49,043][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:27:49,314][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                           [2024-12-14 02:27:49,640][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:27:50,043][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:27:50,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:50,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:51,011][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.6196118593215942, acc: 0.4761904776096344)
[2024-12-14 02:27:50,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:50,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:50,904][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.8161426782608032, acc: 0.5060241222381592)
[2024-12-14 02:27:51,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:51,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:51,322][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 1.4371435642242432, acc: 0.5675675868988037)
[2024-12-14 02:27:51,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:51,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:51,685][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.6548317670822144, acc: 0.5631067752838135)
[2024-12-14 02:27:51,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:51,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:52,044][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 1.4009071588516235, acc: 0.6097561120986938)
                                                                                                                                                                                                                                               [2024-12-14 02:27:52,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:52,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:52,418][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 0.8709016442298889, acc: 0.75)
[2024-12-14 02:27:52,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:52,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:52,769][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 1.226164698600769, acc: 0.6071428656578064)
[2024-12-14 02:27:52,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:53,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:53,187][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 1.9884889125823975, acc: 0.4117647111415863)
[2024-12-14 02:27:53,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:53,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:53,547][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 2.1450040340423584, acc: 0.39737990498542786)
[2024-12-14 02:27:53,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:53,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:53,898][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 1.8991061449050903, acc: 0.5)
[2024-12-14 02:27:54,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:54,252][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 2.029733180999756, acc: 0.42944785952568054)
[2024-12-14 02:27:54,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:54,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:54,600][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 2.0510261058807373, acc: 0.4460431635379791)
[2024-12-14 02:27:54,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:54,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:54,944][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 2.183865547180176, acc: 0.4170854389667511)
[2024-12-14 02:27:55,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:55,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:55,195][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 0.8566638231277466, acc: 0.7777777910232544)
[2024-12-14 02:27:55,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:55,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:55,500][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 0.9386026263237, acc: 0.7272727489471436)
                                                                 [2024-12-14 02:27:55,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:55,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:55,835][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.6593635678291321, acc: 0.8888888955116272)
[2024-12-14 02:27:55,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:55,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:56,232][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 1.1059755086898804, acc: 0.6499999761581421)
[2024-12-14 02:27:56,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:56,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:56,571][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 0.5571748614311218, acc: 0.8999999761581421)
[2024-12-14 02:27:56,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:56,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:56,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:56,964][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 1.151208519935608, acc: 0.6206896305084229)
[2024-12-14 02:27:57,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:57,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:57,278][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.6798675060272217, acc: 0.8709677457809448)
[2024-12-14 02:27:57,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:57,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:57,623][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.3926536738872528, acc: 0.8947368264198303)
[2024-12-14 02:27:57,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:57,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:57,949][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 1.197292447090149, acc: 0.6666666865348816)
[2024-12-14 02:27:58,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:58,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:58,314][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 1.0293269157409668, acc: 0.6666666865348816)
[2024-12-14 02:27:58,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:58,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:58,712][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 0.978904664516449, acc: 0.6363636255264282)
[2024-12-14 02:27:58,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:59,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:59,068][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.7626631259918213, acc: 0.4923076927661896)
[2024-12-14 02:27:59,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:59,466][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 1.0831177234649658, acc: 0.6333333253860474)
[2024-12-14 02:27:59,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:59,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:59,845][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 0.9817286133766174, acc: 0.7241379022598267)
[2024-12-14 02:27:59,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:27:59,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:00,250][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 1.6206542253494263, acc: 0.5490196347236633)
[2024-12-14 02:28:00,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:00,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:00,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:00,644][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 1.154513955116272, acc: 0.6551724076271057)
[2024-12-14 02:28:00,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:00,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:00,993][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.42629843950271606, acc: 0.8421052694320679)
[2024-12-14 02:28:01,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:01,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:01,380][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 1.2416529655456543, acc: 0.7368420958518982)
[2024-12-14 02:28:01,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:01,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:01,765][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 1.5985515117645264, acc: 0.5714285969734192)
[2024-12-14 02:28:01,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:01,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:02,215][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 1.7589854001998901, acc: 0.5280898809432983)
[2024-12-14 02:28:02,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:02,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:02,594][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 1.9507442712783813, acc: 0.4606741666793823)
[2024-12-14 02:28:02,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:02,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:02,946][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 2.1633224487304688, acc: 0.39007091522216797)
[2024-12-14 02:28:03,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:03,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:03,340][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 2.1527581214904785, acc: 0.42391303181648254)
[2024-12-14 02:28:03,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:03,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:03,677][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.6452131867408752, acc: 0.8399999737739563)
[2024-12-14 02:28:03,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:04,022][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.557783305644989, acc: 0.8461538553237915)
[2024-12-14 02:28:04,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:04,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:04,403][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.5586232542991638, acc: 0.8888888955116272)
[2024-12-14 02:28:04,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:04,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:04,730][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 1.4641070365905762, acc: 0.5925925970077515)
[2024-12-14 02:28:04,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:05,074][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 1.1201204061508179, acc: 0.6603773832321167)
[2024-12-14 02:28:05,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:05,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:05,380][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 0.903732180595398, acc: 0.7241379022598267)
[2024-12-14 02:28:05,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:06,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:06,977][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 2.092341423034668, acc: 0.47035571932792664)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:28:07,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:07,254][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 1.5027813911437988, acc: 0.5581395626068115)
                                                                               [2024-12-14 02:28:07,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:07,630][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 1.7506828308105469, acc: 0.5060241222381592)
 [2024-12-14 02:28:07,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:08,055][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 1.7627668380737305, acc: 0.48148149251937866)
[2024-12-14 02:28:08,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:08,392][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 1.220590591430664, acc: 0.5714285969734192)
[2024-12-14 02:28:08,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:08,764][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.8758243322372437, acc: 0.7037037014961243)
[2024-12-14 02:28:08,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:09,133][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.3984428942203522, acc: 0.9130434989929199)
[2024-12-14 02:28:09,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:09,568][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 1.8477455377578735, acc: 0.5042017102241516)
[2024-12-14 02:28:09,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:09,963][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 1.3502484560012817, acc: 0.6229507923126221)
  [2024-12-14 02:28:10,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:10,329][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 1.9050933122634888, acc: 0.460317462682724)
[2024-12-14 02:28:10,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:10,756][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 1.6322556734085083, acc: 0.508474588394165)
                                                                                 [2024-12-14 02:28:10,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:11,173][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 1.2548598051071167, acc: 0.6091954112052917)
[2024-12-14 02:28:11,263][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                           [2024-12-14 02:28:11,509][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.4121287763118744, acc: 0.8571428656578064)
[2024-12-14 02:28:11,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:11,922][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 1.0761810541152954, acc: 0.692307710647583)
                                                                                [2024-12-14 02:28:12,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:12,353][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 1.9400137662887573, acc: 0.5270270109176636)
                                                                                                                                                               [2024-12-14 02:28:12,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:12,760][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 1.6746058464050293, acc: 0.5538461804389954)
                                                                                [2024-12-14 02:28:12,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:13,213][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 1.8898215293884277, acc: 0.4848484992980957)
                                                                              [2024-12-14 02:28:13,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:13,630][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 1.5742745399475098, acc: 0.5360824465751648)
                                                                                [2024-12-14 02:28:13,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:14,029][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 1.884312391281128, acc: 0.5220588445663452)
[2024-12-14 02:28:14,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:14,396][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.7174485325813293, acc: 0.807692289352417)
[2024-12-14 02:28:14,502][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                    [2024-12-14 02:28:14,765][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.26752403378486633, acc: 0.9259259104728699)
[2024-12-14 02:28:14,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:15,046][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 1.1669578552246094, acc: 0.7142857313156128)
[2024-12-14 02:28:15,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:15,330][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.4945372939109802, acc: 0.8611111044883728)
[2024-12-14 02:28:15,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:15,634][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 1.0303705930709839, acc: 0.7368420958518982)
[2024-12-14 02:28:15,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:16,030][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 1.1224385499954224, acc: 0.6984127163887024)
                                                                               [2024-12-14 02:28:16,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:16,389][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 1.7625315189361572, acc: 0.5211267471313477)
[2024-12-14 02:28:16,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:16,849][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 2.0504908561706543, acc: 0.4933333396911621)
                                                                                                                                                                                                                               [2024-12-14 02:28:16,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:17,169][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.9397427439689636, acc: 0.6756756901741028)
                                                                              [2024-12-14 02:28:17,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:17,553][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.2860718369483948, acc: 0.9230769276618958)
 [2024-12-14 02:28:19,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:20,557][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 1.7090855836868286, acc: 0.5392491221427917)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:28:20,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:21,815][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 2.3169822692871094, acc: 0.40522876381874084)
2:28:20,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:20,911][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 1.4160667657852173, acc: 0.6666666865348816)
[2024-12-14 02:28:21,016][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 1.008263111114502, acc: 0.8125)
[2024-12-14 02:28:21,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:21,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:21,280][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 1.6469906568527222, acc: 0.5555555820465088)
[2024-12-14 02:28:21,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:21,424][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 1.1646571159362793, acc: 0.6969696879386902)
[2024-12-14 02:28:21,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:21,650][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 1.8849470615386963, acc: 0.6666666865348816)
[2024-12-14 02:28:21,761][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.6535587906837463, acc: 0.8125)
[2024-12-14 02:28:21,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:21,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:22,042][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 2.067493200302124, acc: 0.739130437374115)
[2024-12-14 02:28:22,141][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.5563732981681824, acc: 0.8709677457809448)
[2024-12-14 02:28:22,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:22,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:22,454][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 1.403482437133789, acc: 0.6216216087341309)
[2024-12-14 02:28:22,524][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.17119912803173065, acc: 0.95652174949646)
[2024-12-14 02:28:22,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:22,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:22,834][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 1.5648783445358276, acc: 0.699999988079071)
[2024-12-14 02:28:22,862][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 1.0611010789871216, acc: 0.6666666865348816)
[2024-12-14 02:28:22,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:22,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:23,159][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 1.1150208711624146, acc: 0.7317073345184326)
[2024-12-14 02:28:23,213][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.9375205636024475, acc: 0.782608687877655)
[2024-12-14 02:28:23,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:23,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:23,521][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.34055015444755554, acc: 0.8888888955116272)
[2024-12-14 02:28:23,527][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.7350097894668579, acc: 0.800000011920929)
[2024-12-14 02:28:23,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:23,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:23,814][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.9543406963348389, acc: 0.7105262875556946)
[2024-12-14 02:28:23,860][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.3250535726547241, acc: 0.8888888955116272)
[2024-12-14 02:28:23,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:23,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:24,110][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.9282569885253906, acc: 0.7096773982048035)
[2024-12-14 02:28:24,150][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.9095272421836853, acc: 0.739130437374115)
[2024-12-14 02:28:24,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:24,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:24,396][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.19518980383872986, acc: 0.9599999785423279)
[2024-12-14 02:28:24,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:24,469][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 1.0238977670669556, acc: 0.7222222089767456)
[2024-12-14 02:28:24,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:24,694][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.5954537391662598, acc: 0.8181818127632141)
[2024-12-14 02:28:24,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:24,819][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.44367462396621704, acc: 0.8799999952316284)
[2024-12-14 02:28:24,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:25,073][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.7214306592941284, acc: 0.800000011920929)
[2024-12-14 02:28:25,164][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 1.1452314853668213, acc: 0.6969696879386902)
[2024-12-14 02:28:25,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:25,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:25,461][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 1.0715724229812622, acc: 0.7285714149475098)
[2024-12-14 02:28:25,529][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 1.1690394878387451, acc: 0.6944444179534912)
[2024-12-14 02:28:25,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:25,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:25,785][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 2.1194915771484375, acc: 0.41605839133262634)
[2024-12-14 02:28:25,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:25,898][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 1.126036524772644, acc: 0.7272727489471436)
[2024-12-14 02:28:26,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:26,104][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 1.6746314764022827, acc: 0.5241379141807556)
[2024-12-14 02:28:26,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:26,301][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.193757563829422, acc: 0.9523809552192688)
[2024-12-14 02:28:26,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:26,436][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 2.2955920696258545, acc: 0.4000000059604645)
[2024-12-14 02:28:26,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:26,686][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 1.5604583024978638, acc: 0.6666666865348816)
[2024-12-14 02:28:26,752][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 1.9818490743637085, acc: 0.42384105920791626)
[2024-12-14 02:28:26,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:26,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:27,058][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 1.725929617881775, acc: 0.5299145579338074)
[2024-12-14 02:28:27,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:27,202][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 1.7134597301483154, acc: 0.5303030014038086)
[2024-12-14 02:28:27,359][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.2153564989566803, acc: 0.9599999785423279)
[2024-12-14 02:28:27,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:27,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:27,739][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.774739146232605, acc: 0.7692307829856873)
[2024-12-14 02:28:27,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:27,969][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 2.2453835010528564, acc: 0.40799999237060547)
[2024-12-14 02:28:28,082][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.33808931708335876, acc: 0.8461538553237915)
[2024-12-14 02:28:28,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:28,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:28,534][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 2.0602288246154785, acc: 0.4205128252506256)
                                                                                                                                                                                                                        [2024-12-14 02:28:28,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:28,905][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.6777400970458984, acc: 0.5204081535339355)
                                                                                [2024-12-14 02:28:29,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:29,299][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 2.2823338508605957, acc: 0.34328359365463257)
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:28:29,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:29,695][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 2.0911710262298584, acc: 0.4416058361530304)
 [2024-12-14 02:28:29,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:30,001][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.3722998797893524, acc: 0.8571428656578064)
                                                                                                                                                                                                                         [2024-12-14 02:28:30,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:30,319][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.2282722145318985, acc: 0.9166666865348816)
 [2024-12-14 02:28:30,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:30,657][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.7468064427375793, acc: 0.8484848737716675)
                                                                               [2024-12-14 02:28:30,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:31,034][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.38486701250076294, acc: 0.8461538553237915)
                                                                               [2024-12-14 02:28:31,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:31,448][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 1.3606607913970947, acc: 0.6153846383094788)
                                                                                [2024-12-14 02:28:31,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:31,823][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 1.7346408367156982, acc: 0.5769230723381042)
                                                                                [2024-12-14 02:28:31,910][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:28:32,155][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 0.9823192358016968, acc: 0.6875)
[2024-12-14 02:28:32,243][slam_llm.models.slam_model][INFO] - modality encoder
             [2024-12-14 02:28:32,498][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 1.6525121927261353, acc: 0.52173912525177)
                        [2024-12-14 02:28:32,590][slam_llm.models.slam_model][INFO] - modality encoder
                                           [2024-12-14 02:28:32,876][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 1.1388744115829468, acc: 0.6800000071525574)
                      [2024-12-14 02:28:32,990][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.4433436393737793, acc: 0.5918367505073547)
[2024-12-14 02:28:32,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:33,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:33,258][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 0.9887022376060486, acc: 0.6969696879386902)
[2024-12-14 02:28:33,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:33,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:33,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:33,602][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 1.9461818933486938, acc: 0.4639175236225128)
[2024-12-14 02:28:33,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:33,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:33,998][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 1.4758070707321167, acc: 0.5857142806053162)
[2024-12-14 02:28:34,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:34,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:34,407][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 1.8946555852890015, acc: 0.5058139562606812)
[2024-12-14 02:28:34,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:34,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:34,746][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 1.8338557481765747, acc: 0.5)
[2024-12-14 02:28:34,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:35,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:35,151][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 1.703069806098938, acc: 0.5555555820465088)
[2024-12-14 02:28:35,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:35,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:35,522][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 1.3669071197509766, acc: 0.6388888955116272)
[2024-12-14 02:28:35,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:35,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:35,904][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 1.010310173034668, acc: 0.71875)
[2024-12-14 02:28:35,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:36,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:36,255][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 0.9378334879875183, acc: 0.7307692170143127)
[2024-12-14 02:28:36,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:36,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:36,645][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 1.3084694147109985, acc: 0.6521739363670349)
[2024-12-14 02:28:36,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:36,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:36,998][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 1.694891095161438, acc: 0.488095223903656)
[2024-12-14 02:28:37,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:37,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:37,311][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.939504623413086, acc: 0.45783132314682007)
[2024-12-14 02:28:37,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:37,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:38,644][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 2.0566837787628174, acc: 0.4356435537338257)

[2024-12-14 02:28:37,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:37,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:38,044][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.6582684516906738, acc: 0.582524299621582)
[2024-12-14 02:28:38,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:38,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:38,413][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 1.4087824821472168, acc: 0.6178861856460571)
[2024-12-14 02:28:38,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:38,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:38,765][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 1.5010806322097778, acc: 0.6666666865348816)
[2024-12-14 02:28:38,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:38,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:39,061][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 1.1709325313568115, acc: 0.6428571343421936)
[2024-12-14 02:28:39,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:39,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:39,478][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 2.0807559490203857, acc: 0.46078431606292725)
[2024-12-14 02:28:39,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:39,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:39,840][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 2.1483428478240967, acc: 0.39737990498542786)
[2024-12-14 02:28:39,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:40,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:40,180][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 1.9882160425186157, acc: 0.4791666567325592)
[2024-12-14 02:28:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:40,516][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 2.039548635482788, acc: 0.43558281660079956)
[2024-12-14 02:28:40,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:40,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:40,849][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 2.0770163536071777, acc: 0.4316546618938446)
[2024-12-14 02:28:40,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:40,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:41,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:41,241][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 2.170159339904785, acc: 0.4070351719856262)
[2024-12-14 02:28:41,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:41,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:41,641][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 1.0586777925491333, acc: 0.7222222089767456)
[2024-12-14 02:28:41,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:41,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:41,956][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 1.0917308330535889, acc: 0.6969696879386902)
[2024-12-14 02:28:42,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:42,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:42,295][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.7720651030540466, acc: 0.6666666865348816)
[2024-12-14 02:28:42,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:42,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:42,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:42,975][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 1.1495800018310547, acc: 0.6511628031730652)
[2024-12-14 02:28:42,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:43,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:43,025][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 0.5990387797355652, acc: 0.8500000238418579)
[2024-12-14 02:28:43,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:43,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:43,438][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 1.1776484251022339, acc: 0.6206896305084229)
[2024-12-14 02:28:43,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:43,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:43,824][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.8104944825172424, acc: 0.8387096524238586)
[2024-12-14 02:28:43,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:44,138][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.5000252723693848, acc: 0.8421052694320679)
[2024-12-14 02:28:44,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:44,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:44,490][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 1.2396811246871948, acc: 0.6296296119689941)
[2024-12-14 02:28:44,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:44,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:44,851][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 1.4027891159057617, acc: 0.523809552192688)
[2024-12-14 02:28:44,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:44,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:45,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:45,242][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 0.8667770028114319, acc: 0.6818181872367859)
[2024-12-14 02:28:45,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:45,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:45,654][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.7490439414978027, acc: 0.5384615659713745)
[2024-12-14 02:28:45,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:45,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:46,047][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 1.0423277616500854, acc: 0.699999988079071)
[2024-12-14 02:28:46,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:46,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:46,378][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 0.9321905374526978, acc: 0.7241379022598267)
[2024-12-14 02:28:46,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:46,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:46,767][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 1.6055039167404175, acc: 0.5490196347236633)
[2024-12-14 02:28:46,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:46,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:47,120][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 1.0805354118347168, acc: 0.6896551847457886)
[2024-12-14 02:28:47,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:47,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:47,451][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.31102824211120605, acc: 0.8947368264198303)
[2024-12-14 02:28:47,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:47,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:47,835][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 1.1106239557266235, acc: 0.7368420958518982)
[2024-12-14 02:28:48,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:48,741][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.8975962400436401, acc: 0.4752851724624634)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:28:48,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:49,079][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 1.2167047262191772, acc: 0.653333306312561)
  [2024-12-14 02:28:49,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:49,485][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 0.932243287563324, acc: 0.7692307829856873)
                                                                                 [2024-12-14 02:28:49,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:49,886][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.3642735779285431, acc: 0.875)
                                                                                                                                                                                                                                                          [2024-12-14 02:28:49,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:50,282][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.4638611674308777, acc: 0.8421052694320679)
 [2024-12-14 02:28:50,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:50,658][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 1.8641518354415894, acc: 0.453987717628479)
                                                                                                                                                               [2024-12-14 02:28:50,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:51,091][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.5818487405776978, acc: 0.5902777910232544)
                                                                               [2024-12-14 02:28:51,185][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:28:51,456][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 1.8394614458084106, acc: 0.4749999940395355)
[2024-12-14 02:28:51,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:51,863][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 1.7752480506896973, acc: 0.4821428656578064)
                                                                                                                                                              [2024-12-14 02:28:51,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:52,221][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 1.7165719270706177, acc: 0.5230769515037537)
[2024-12-14 02:28:52,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:52,634][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 1.6554545164108276, acc: 0.5588235259056091)
                                                                               [2024-12-14 02:28:52,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:53,031][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.5894268751144409, acc: 0.8461538553237915)
                                                                              [2024-12-14 02:28:53,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:53,416][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.22527076303958893, acc: 0.9130434989929199)
[2024-12-14 02:28:53,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:53,810][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.6560213565826416, acc: 0.78125)
                                                                                                                                                                                                                                                       [2024-12-14 02:28:53,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:54,162][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.8773425817489624, acc: 0.782608687877655)
 [2024-12-14 02:28:54,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:54,493][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 0.9143819808959961, acc: 0.7428571581840515)
[2024-12-14 02:28:55,317][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:28:55,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:56,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:56,399][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:28:56,835][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:28:57,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:28:57,500][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:28:57,812][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                          [2024-12-14 02:28:58,195][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:28:58,559][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:28:59,037][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:28:59,401][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:28:59,776][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:29:00,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:00,205][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 0.9157323241233826, acc: 0.7037037014961243)
[2024-12-14 02:29:00,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:00,482][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.8509, device='cuda:0') eval_epoch_loss=tensor(1.7666, device='cuda:0') eval_epoch_acc=tensor(0.5710, device='cuda:0')
[2024-12-14 02:29:00,483][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:29:00,483][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:29:00,782][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_566_loss_1.7666029930114746/model.pt
[2024-12-14 02:29:00,786][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:29:00,786][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.5710272789001465
[2024-12-14 02:29:00,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:01,194][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 1.393136739730835, acc: 0.523809552192688)
[2024-12-14 02:29:01,200][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 1.9873952865600586, acc: 0.4406779706478119)
[2024-12-14 02:29:01,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:01,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:01,574][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 1.9251258373260498, acc: 0.5074626803398132)
[2024-12-14 02:29:01,651][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 0.8020126819610596, acc: 0.7631579041481018)
[2024-12-14 02:29:01,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:01,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:02,001][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 1.9292994737625122, acc: 0.48175182938575745)
[2024-12-14 02:29:02,038][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.5098860263824463, acc: 0.8518518805503845)
[2024-12-14 02:29:02,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:02,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:02,414][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 1.7274463176727295, acc: 0.5508021116256714)
[2024-12-14 02:29:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:02,562][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 1.8323065042495728, acc: 0.48500001430511475)
[2024-12-14 02:29:02,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:02,704][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 1.1117441654205322, acc: 0.725806474685669)
[2024-12-14 02:29:02,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:02,939][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 1.4705702066421509, acc: 0.5740740895271301)
[2024-12-14 02:29:02,996][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 1.3262760639190674, acc: 0.6068376302719116)
[2024-12-14 02:29:03,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:03,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:03,309][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 2.090878486633301, acc: 0.45408162474632263)
[2024-12-14 02:29:03,334][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 1.4159815311431885, acc: 0.5769230723381042)
[2024-12-14 02:29:03,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:03,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:03,758][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 2.0340335369110107, acc: 0.4591194987297058)
[2024-12-14 02:29:03,715][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 1.7254480123519897, acc: 0.3333333432674408)
[2024-12-14 02:29:03,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:04,085][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 2.529667854309082, acc: 0.31147539615631104)
[2024-12-14 02:29:04,121][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=3.8162, train_epoch_loss=1.3393, epoch time 358.93872601538897s
[2024-12-14 02:29:04,121][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:29:04,121][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:29:04,121][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:29:04,121][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 12
[2024-12-14 02:29:04,121][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 02:29:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:04,462][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 1.4770175218582153, acc: 0.5932203531265259)
[2024-12-14 02:29:04,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:04,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:04,827][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.853663444519043, acc: 0.5581395626068115)
[2024-12-14 02:29:04,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:05,029][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 0.9702953100204468, acc: 0.7407407164573669)
[2024-12-14 02:29:05,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:05,186][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 1.8102494478225708, acc: 0.5909090638160706)
[2024-12-14 02:29:05,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:05,333][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 1.268256664276123, acc: 0.6800000071525574)
[2024-12-14 02:29:05,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:05,549][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 2.012014389038086, acc: 0.4150943458080292)
[2024-12-14 02:29:05,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:05,737][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 1.4718654155731201, acc: 0.6216216087341309)
[2024-12-14 02:29:05,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:05,943][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 1.2249979972839355, acc: 0.7045454382896423)
[2024-12-14 02:29:06,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:06,113][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 1.7435262203216553, acc: 0.44736841320991516)
[2024-12-14 02:29:06,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:06,284][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 0.8623948097229004, acc: 0.6800000071525574)
[2024-12-14 02:29:06,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:06,550][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 1.781419038772583, acc: 0.4864864945411682)
[2024-12-14 02:29:06,603][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.8387567400932312, acc: 0.800000011920929)
[2024-12-14 02:29:06,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:06,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:06,956][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 1.35044264793396, acc: 0.4642857015132904)
[2024-12-14 02:29:07,006][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.587726354598999, acc: 0.8181818127632141)
[2024-12-14 02:29:07,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:07,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:07,295][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 1.8781355619430542, acc: 0.4897959232330322)
[2024-12-14 02:29:07,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:07,440][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 1.4370713233947754, acc: 0.6461538672447205)
[2024-12-14 02:29:07,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:07,666][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 1.2061951160430908, acc: 0.699999988079071)
[2024-12-14 02:29:07,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:07,800][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 1.5146077871322632, acc: 0.578125)
[2024-12-14 02:29:07,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:08,053][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.3301631212234497, acc: 0.9090909361839294)
[2024-12-14 02:29:08,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:08,209][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 1.0873053073883057, acc: 0.8125)
[2024-12-14 02:29:08,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:08,398][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.3979189991950989, acc: 0.8461538553237915)
[2024-12-14 02:29:08,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:08,549][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 1.2821961641311646, acc: 0.6363636255264282)
[2024-12-14 02:29:08,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:08,768][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.4771569073200226, acc: 0.8518518805503845)
[2024-12-14 02:29:08,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:08,919][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.6429297924041748, acc: 0.8125)
[2024-12-14 02:29:09,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:09,140][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 1.3227299451828003, acc: 0.6410256624221802)
[2024-12-14 02:29:09,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:09,267][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.6032558083534241, acc: 0.8387096524238586)
[2024-12-14 02:29:09,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:09,544][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 0.9145004153251648, acc: 0.6969696879386902)
[2024-12-14 02:29:09,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:09,625][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.18104049563407898, acc: 0.95652174949646)
[2024-12-14 02:29:09,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:09,911][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 1.4416791200637817, acc: 0.6086956262588501)
[2024-12-14 02:29:09,978][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 1.4207980632781982, acc: 0.5666666626930237)
[2024-12-14 02:29:10,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:10,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:10,272][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 1.5924944877624512, acc: 0.5882353186607361)
[2024-12-14 02:29:10,318][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 1.1567142009735107, acc: 0.6829268336296082)
[2024-12-14 02:29:10,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:10,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:10,832][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.5661440491676331, acc: 0.8857142925262451)
[2024-12-14 02:29:10,690][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 1.350325345993042, acc: 0.5714285969734192)
[2024-12-14 02:29:10,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:10,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:11,053][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.8015366196632385, acc: 0.8157894611358643)
[2024-12-14 02:29:11,123][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.38610541820526123, acc: 0.8421052694320679)
[2024-12-14 02:29:11,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:11,383][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.8427491188049316, acc: 0.774193525314331)
[2024-12-14 02:29:11,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:11,476][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 0.844308078289032, acc: 0.75)
[2024-12-14 02:29:11,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:11,665][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.379350483417511, acc: 0.9200000166893005)
[2024-12-14 02:29:11,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:11,838][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 1.1422241926193237, acc: 0.6944444179534912)
[2024-12-14 02:29:11,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:11,942][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.6317073702812195, acc: 0.7878788113594055)
[2024-12-14 02:29:12,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:12,178][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.8120900988578796, acc: 0.6842105388641357)
[2024-12-14 02:29:12,235][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.8906116485595703, acc: 0.699999988079071)
[2024-12-14 02:29:12,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:12,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:12,514][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 0.8848723769187927, acc: 0.692307710647583)
[2024-12-14 02:29:12,533][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 0.9816056489944458, acc: 0.7142857313156128)
[2024-12-14 02:29:12,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:12,838][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 2.1294057369232178, acc: 0.42335766553878784)
[2024-12-14 02:29:12,903][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 0.9937705993652344, acc: 0.6896551847457886)
[2024-12-14 02:29:12,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:12,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:13,174][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 1.5392202138900757, acc: 0.5931034684181213)
[2024-12-14 02:29:13,226][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.6662265658378601, acc: 0.8399999737739563)
[2024-12-14 02:29:13,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:13,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:13,543][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.651806116104126, acc: 0.8095238208770752)
[2024-12-14 02:29:13,571][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 2.2265751361846924, acc: 0.4357142746448517)
[2024-12-14 02:29:13,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:14,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:13,937][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 0.7606333494186401, acc: 0.9375)
[2024-12-14 02:29:14,001][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 2.0019612312316895, acc: 0.443708598613739)
[2024-12-14 02:29:14,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:14,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:14,303][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 1.8952828645706177, acc: 0.35849055647850037)
[2024-12-14 02:29:14,380][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 1.6576430797576904, acc: 0.5555555820465088)
[2024-12-14 02:29:14,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:14,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:14,661][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 1.9084280729293823, acc: 0.4794520437717438)
[2024-12-14 02:29:14,778][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.30647677183151245, acc: 0.9200000166893005)
[2024-12-14 02:29:14,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:15,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:15,180][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.5794156789779663, acc: 0.8461538553237915)
[2024-12-14 02:29:15,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:15,565][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.4322410821914673, acc: 0.9230769276618958)
[2024-12-14 02:29:15,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:15,888][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 2.1106455326080322, acc: 0.4466403126716614)
[2024-12-14 02:29:15,959][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 1.1799814701080322, acc: 0.7435897588729858)
[2024-12-14 02:29:15,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:16,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:16,264][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 1.643425703048706, acc: 0.604651153087616)
[2024-12-14 02:29:16,301][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 1.2816907167434692, acc: 0.6333333253860474)
[2024-12-14 02:29:16,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:16,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:16,634][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 1.2353341579437256, acc: 0.6363636255264282)
[2024-12-14 02:29:16,652][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 1.8313411474227905, acc: 0.4819277226924896)
[2024-12-14 02:29:16,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:16,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:16,938][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 0.9260470867156982, acc: 0.75)
[2024-12-14 02:29:17,019][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 1.6844583749771118, acc: 0.4938271641731262)
[2024-12-14 02:29:17,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:17,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:17,279][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 1.0122734308242798, acc: 0.7068965435028076)
[2024-12-14 02:29:17,359][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 1.2203799486160278, acc: 0.5357142686843872)
[2024-12-14 02:29:17,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:17,736][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.9967449307441711, acc: 0.6296296119689941)
[2024-12-14 02:29:17,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:18,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:18,108][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.40995049476623535, acc: 0.9130434989929199)
[2024-12-14 02:29:18,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:18,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:18,527][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 1.8152211904525757, acc: 0.5042017102241516)
[2024-12-14 02:29:18,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:18,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:18,910][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 1.2955504655838013, acc: 0.6065573692321777)
[2024-12-14 02:29:19,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:19,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:19,274][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 1.7114148139953613, acc: 0.5079365372657776)
[2024-12-14 02:29:19,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:19,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:19,665][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 1.6664608716964722, acc: 0.5423728823661804)
[2024-12-14 02:29:19,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:19,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:20,036][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 1.155867576599121, acc: 0.6321839094161987)
[2024-12-14 02:29:20,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:20,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:20,367][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.39453500509262085, acc: 0.9047619104385376)
[2024-12-14 02:29:20,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:20,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:20,749][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 1.2045807838439941, acc: 0.5769230723381042)
[2024-12-14 02:29:20,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:21,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:21,134][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 1.8967986106872559, acc: 0.47297295928001404)
[2024-12-14 02:29:21,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:21,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:21,537][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 1.5339776277542114, acc: 0.6153846383094788)
[2024-12-14 02:29:21,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:21,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:21,950][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 1.7979788780212402, acc: 0.5353535413742065)
[2024-12-14 02:29:22,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:22,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:22,377][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 1.4879916906356812, acc: 0.5567010045051575)
[2024-12-14 02:29:22,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:22,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:22,781][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 1.7823772430419922, acc: 0.5147058963775635)
[2024-12-14 02:29:22,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:22,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:23,106][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.5525594353675842, acc: 0.9230769276618958)
[2024-12-14 02:29:23,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:23,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:23,490][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.2485935389995575, acc: 0.9629629850387573)
[2024-12-14 02:29:23,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:23,886][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.9083317518234253, acc: 0.6785714030265808)
[2024-12-14 02:29:23,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:24,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:24,161][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.42498695850372314, acc: 0.9444444179534912)
[2024-12-14 02:29:24,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:24,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:24,578][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 1.1316090822219849, acc: 0.7368420958518982)
[2024-12-14 02:29:24,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:24,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:24,954][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 1.1821752786636353, acc: 0.6349206566810608)
[2024-12-14 02:29:25,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:25,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:25,304][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 1.8552099466323853, acc: 0.5070422291755676)
[2024-12-14 02:29:25,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:25,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:25,755][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 1.9958772659301758, acc: 0.47999998927116394)
[2024-12-14 02:29:25,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:25,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:26,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:26,090][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.8614439964294434, acc: 0.7027027010917664)
[2024-12-14 02:29:26,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:26,413][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.35595613718032837, acc: 0.8846153616905212)
[2024-12-14 02:29:26,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:26,929][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:29:27,369][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:29:27,687][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:29:27,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:27,998][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:29:28,368][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:29:28,807][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.1974598169326782, acc: 0.6538461446762085)
[2024-12-14 02:29:28,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:29,177][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 1.8668773174285889, acc: 0.4193548262119293)
[2024-12-14 02:29:29,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:29,549][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 1.517018437385559, acc: 0.5675675868988037)
[2024-12-14 02:29:29,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:30,077][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 1.7460017204284668, acc: 0.429824560880661)
[2024-12-14 02:29:30,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:30,422][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 1.5008715391159058, acc: 0.5895522236824036)
[2024-12-14 02:29:30,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:30,770][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 2.096691131591797, acc: 0.3469387888908386)
[2024-12-14 02:29:30,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:31,216][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 1.926985263824463, acc: 0.39361703395843506)
[2024-12-14 02:29:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:31,557][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 1.5274280309677124, acc: 0.6142857074737549)
[2024-12-14 02:29:31,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:31,912][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 1.6355524063110352, acc: 0.5357142686843872)
[2024-12-14 02:29:32,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:32,262][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 1.1181797981262207, acc: 0.6086956262588501)
[2024-12-14 02:29:32,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:32,626][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 1.3792115449905396, acc: 0.5517241358757019)
[2024-12-14 02:29:32,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:33,023][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 1.699294090270996, acc: 0.54347825050354)
                                                                                                                                                               [2024-12-14 02:29:33,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:33,347][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 1.7465251684188843, acc: 0.49152541160583496)
                                                                             [2024-12-14 02:29:33,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:33,588][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 1.81119966506958, acc: 0.4912280738353729)
[2024-12-14 02:29:33,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:33,929][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 1.5653830766677856, acc: 0.6081081032752991)
[2024-12-14 02:29:34,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:34,290][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 1.0327880382537842, acc: 0.7142857313156128)
[2024-12-14 02:29:34,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:34,665][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 1.0012061595916748, acc: 0.6521739363670349)
                                                                                                                                                  [2024-12-14 02:29:34,740][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:29:34,993][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 1.6093119382858276, acc: 0.6499999761581421)
 [2024-12-14 02:29:35,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:35,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:35,332][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.22919915616512299, acc: 0.9599999785423279)
[2024-12-14 02:29:35,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:35,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:35,641][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 0.7884204387664795, acc: 0.7777777910232544)
[2024-12-14 02:29:35,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:35,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:35,958][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 0.7987446188926697, acc: 0.8181818127632141)
[2024-12-14 02:29:36,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:36,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:36,270][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 1.8670281171798706, acc: 0.5220588445663452)
[2024-12-14 02:29:36,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:36,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:36,661][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 1.7763326168060303, acc: 0.523809552192688)
[2024-12-14 02:29:36,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:36,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:37,015][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 2.0732176303863525, acc: 0.4256410300731659)
[2024-12-14 02:29:37,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:37,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:37,398][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.6753231287002563, acc: 0.5408163070678711)
[2024-12-14 02:29:37,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:37,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:37,775][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 2.313433885574341, acc: 0.3731343150138855)
[2024-12-14 02:29:37,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:37,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:38,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:38,211][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 2.0848143100738525, acc: 0.4416058361530304)
[2024-12-14 02:29:38,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:38,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:38,580][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.35361823439598083, acc: 0.8571428656578064)
[2024-12-14 02:29:38,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:38,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:38,989][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.23405449092388153, acc: 0.9583333134651184)
[2024-12-14 02:29:39,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:39,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:39,407][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.6968226432800293, acc: 0.7878788113594055)
[2024-12-14 02:29:39,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:39,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:39,721][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.34874120354652405, acc: 0.8461538553237915)
[2024-12-14 02:29:39,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:39,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:40,349][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 1.2169688940048218, acc: 0.5799999833106995)
                                                                             [2024-12-14 02:29:40,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:40,790][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 1.3071149587631226, acc: 0.6388888955116272)
                                                                              [2024-12-14 02:29:40,904][slam_llm.models.slam_model][INFO] - modality encoder
                                             [2024-12-14 02:29:41,190][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.5663676261901855, acc: 0.5980392098426819)
                     [2024-12-14 02:29:41,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:42,218][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 2.2800867557525635, acc: 0.4794520437717438)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:29:42,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:42,533][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.5133418440818787, acc: 0.7916666865348816)
[2024-12-14 02:29:42,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:42,906][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.7202842235565186, acc: 0.7037037014961243)
[2024-12-14 02:29:43,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:43,293][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.8155803084373474, acc: 0.75)
[2024-12-14 02:29:43,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:43,834][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.6148792505264282, acc: 0.6106194853782654)
[2024-12-14 02:29:43,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:44,128][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 1.2932825088500977, acc: 0.6231883764266968)
[2024-12-14 02:29:44,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:44,492][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 1.5324769020080566, acc: 0.5795454382896423)
[2024-12-14 02:29:44,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:45,406][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 2.1825337409973145, acc: 0.3893129825592041)
                    [2024-12-14 02:29:45,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:46,075][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 1.9128793478012085, acc: 0.4592592716217041)
                                                                                                                                                            [2024-12-14 02:29:46,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:46,437][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 1.3792065382003784, acc: 0.6065573692321777)
                                                                              [2024-12-14 02:29:46,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:46,783][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.4583777189254761, acc: 0.9166666865348816)
[2024-12-14 02:29:46,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:47,099][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.8319661021232605, acc: 0.7599999904632568)
[2024-12-14 02:29:47,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:47,411][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.6722183227539062, acc: 0.7857142686843872)
                                                                             [2024-12-14 02:29:47,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:47,779][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 1.7035213708877563, acc: 0.5365853905677795)
                                                                             [2024-12-14 02:29:47,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:48,207][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 2.036724328994751, acc: 0.44712990522384644)
                                                                              [2024-12-14 02:29:48,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:48,596][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 2.1090219020843506, acc: 0.42939481139183044)
                                                                            [2024-12-14 02:29:48,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:49,089][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 2.1316797733306885, acc: 0.4312500059604645)
[2024-12-14 02:29:49,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:49,624][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 2.011280059814453, acc: 0.4352720379829407)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:29:49,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:50,026][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 1.8933498859405518, acc: 0.46975088119506836)
                                                                                                                                                                                                                        [2024-12-14 02:29:50,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:50,349][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 1.0175573825836182, acc: 0.7599999904632568)
                                                                                                                                                                                                                       [2024-12-14 02:29:50,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:50,899][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 1.9281718730926514, acc: 0.4651162922382355)
[2024-12-14 02:29:50,615][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.5072733163833618, acc: 0.8260869383811951)
[2024-12-14 02:29:50,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:50,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:51,007][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 0.9296737909317017, acc: 0.7272727489471436)
[2024-12-14 02:29:51,012][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 1.7579445838928223, acc: 0.529411792755127)
[2024-12-14 02:29:51,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:51,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:51,373][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 1.1713218688964844, acc: 0.6774193644523621)
[2024-12-14 02:29:51,414][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 1.6457570791244507, acc: 0.5344827771186829)
[2024-12-14 02:29:51,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:51,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:51,709][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 1.3934001922607422, acc: 0.6495726704597473)
[2024-12-14 02:29:51,743][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 0.9368362426757812, acc: 0.7209302186965942)
[2024-12-14 02:29:51,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:51,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:52,018][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 2.0331504344940186, acc: 0.4336734712123871)
[2024-12-14 02:29:52,087][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 0.8672885298728943, acc: 0.7200000286102295)
[2024-12-14 02:29:52,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:52,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:52,353][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 1.9262012243270874, acc: 0.4779874086380005)
[2024-12-14 02:29:52,417][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.2596004903316498, acc: 0.8823529481887817)
[2024-12-14 02:29:52,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:52,704][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.10240790247917175, acc: 1.0)
[2024-12-14 02:29:52,774][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=3.8291, train_epoch_loss=1.3426, epoch time 361.74560103192925s
[2024-12-14 02:29:52,775][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:29:52,775][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:29:52,775][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:29:52,775][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 12
[2024-12-14 02:29:52,775][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:29:52,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:52,996][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 0.935744047164917, acc: 0.7142857313156128)
[2024-12-14 02:29:53,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:53,368][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 1.5009996891021729, acc: 0.5846154093742371)
[2024-12-14 02:29:53,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:54,459][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 1.4484682083129883, acc: 0.6172839403152466)
10, step 0/574 completed (loss: 1.0512892007827759, acc: 0.7037037014961243)
[2024-12-14 02:29:53,793][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 1.4239635467529297, acc: 0.6666666865348816)
[2024-12-14 02:29:53,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:53,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:54,157][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 1.325885534286499, acc: 0.6140350699424744)
[2024-12-14 02:29:54,160][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 1.1030064821243286, acc: 0.6399999856948853)
[2024-12-14 02:29:54,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:54,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:54,491][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 1.3648422956466675, acc: 0.5384615659713745)
[2024-12-14 02:29:54,518][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 1.6636295318603516, acc: 0.6216216087341309)
[2024-12-14 02:29:54,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:54,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:54,865][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 1.1071921586990356, acc: 0.6734693646430969)
[2024-12-14 02:29:54,901][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 1.6269134283065796, acc: 0.3947368562221527)
[2024-12-14 02:29:54,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:55,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:55,172][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.17329911887645721, acc: 0.9090909361839294)
[2024-12-14 02:29:55,259][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 1.7198486328125, acc: 0.5675675868988037)
[2024-12-14 02:29:55,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:55,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:55,512][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 1.464611530303955, acc: 0.5714285969734192)
[2024-12-14 02:29:55,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:55,639][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 1.152384877204895, acc: 0.5357142686843872)
[2024-12-14 02:29:55,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:55,855][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 1.6847211122512817, acc: 0.5691056847572327)
[2024-12-14 02:29:55,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:56,004][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 1.7964376211166382, acc: 0.5102040767669678)
[2024-12-14 02:29:56,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:56,270][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 1.3899962902069092, acc: 0.6129032373428345)
[2024-12-14 02:29:56,337][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 0.9716127514839172, acc: 0.7333333492279053)
[2024-12-14 02:29:56,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:56,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:56,705][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.19414691627025604, acc: 0.9545454382896423)
[2024-12-14 02:29:56,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:57,008][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.3110412061214447, acc: 0.9615384340286255)
[2024-12-14 02:29:57,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:57,163][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.9845787286758423, acc: 0.4600760340690613)
[2024-12-14 02:29:57,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:57,413][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.5389129519462585, acc: 0.8518518805503845)
[2024-12-14 02:29:57,491][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 1.2459079027175903, acc: 0.6800000071525574)
[2024-12-14 02:29:57,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:57,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:58,085][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 1.8618744611740112, acc: 0.446601927280426)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:29:58,165][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:29:58,404][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 1.489403247833252, acc: 0.60317462682724)
                                                                                  [2024-12-14 02:29:58,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:58,747][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 1.492794156074524, acc: 0.5494505763053894)
                                                                                                                                                                                                                        [2024-12-14 02:29:58,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:29:59,118][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 1.8671029806137085, acc: 0.4798206388950348)
                                                                                                                                                                                                                       [2024-12-14 02:29:59,219][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:29:59,508][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 1.956223964691162, acc: 0.5196850299835205)
                                                                                [2024-12-14 02:29:59,596][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:29:59,856][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 1.8601301908493042, acc: 0.5)
                                    [2024-12-14 02:29:59,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:00,227][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 1.8289114236831665, acc: 0.52173912525177)
                                              [2024-12-14 02:30:00,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:00,587][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 1.99077570438385, acc: 0.4474708139896393)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:30:00,684][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:30:00,978][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 1.8169306516647339, acc: 0.510869562625885)
                      [2024-12-14 02:30:01,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:01,322][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.6026721000671387, acc: 0.8260869383811951)
                                                                                                                                      [2024-12-14 02:30:01,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:01,390][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.8888267278671265, acc: 0.7692307829856873)
[2024-12-14 02:30:01,441][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 0.888870894908905, acc: 0.7931034564971924)
[2024-12-14 02:30:01,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:01,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:01,765][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.5859256982803345, acc: 0.782608687877655)
[2024-12-14 02:30:01,776][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.7141205668449402, acc: 0.7599999904632568)
[2024-12-14 02:30:01,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:01,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:02,134][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.44751548767089844, acc: 0.8571428656578064)
[2024-12-14 02:30:02,181][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.7236623764038086, acc: 0.8125)
[2024-12-14 02:30:02,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:02,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:02,449][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 0.4823789596557617, acc: 0.9375)
[2024-12-14 02:30:02,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:02,560][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.9882833957672119, acc: 0.695652186870575)
[2024-12-14 02:30:02,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:02,813][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 1.8126014471054077, acc: 0.43396225571632385)
[2024-12-14 02:30:02,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:02,961][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 1.1242629289627075, acc: 0.5714285969734192)
[2024-12-14 02:30:03,192][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 1.9436532258987427, acc: 0.465753436088562)
[2024-12-14 02:30:03,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:03,826][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:30:04,139][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:30:04,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:04,581][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 2.0011918544769287, acc: 0.4624505937099457)
 [2024-12-14 02:30:04,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:04,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:04,956][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 1.4951565265655518, acc: 0.5813953280448914)
  [2024-12-14 02:30:05,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:05,143][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:30:05,344][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 1.9228895902633667, acc: 0.5662650465965271)
[[2024-12-14 02:30:05,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:06,192][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 1.294716477394104, acc: 0.6304348111152649)
10, step 30/574 completed (loss: 1.7435543537139893, acc: 0.45679011940956116)
[2024-12-14 02:30:05,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:05,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:06,033][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 1.3205369710922241, acc: 0.5357142686843872)
[2024-12-14 02:30:06,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:06,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:06,369][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 1.0406041145324707, acc: 0.6666666865348816)
[2024-12-14 02:30:06,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:06,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:06,795][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.5681815147399902, acc: 0.8695651888847351)
[2024-12-14 02:30:06,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:06,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:07,211][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 1.7893612384796143, acc: 0.5042017102241516)
[2024-12-14 02:30:07,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:07,566][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 1.3406792879104614, acc: 0.6393442749977112)
[2024-12-14 02:30:07,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:07,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:07,958][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 1.8910212516784668, acc: 0.4761904776096344)
[2024-12-14 02:30:08,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:08,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:08,360][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 1.5677144527435303, acc: 0.5593220591545105)
[2024-12-14 02:30:08,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:08,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:08,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:08,770][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 1.272199273109436, acc: 0.5862069129943848)
[2024-12-14 02:30:08,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:09,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:09,101][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.43872684240341187, acc: 0.9047619104385376)
[2024-12-14 02:30:09,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:09,432][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 1.1848618984222412, acc: 0.6538461446762085)
[2024-12-14 02:30:09,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:09,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:09,821][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 1.9316731691360474, acc: 0.5135135054588318)
[2024-12-14 02:30:09,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:09,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:10,166][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 1.7550029754638672, acc: 0.5076923370361328)
[2024-12-14 02:30:10,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:10,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:10,574][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 1.8447445631027222, acc: 0.5353535413742065)
[2024-12-14 02:30:10,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:10,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:11,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:11,080][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 1.554354190826416, acc: 0.5567010045051575)
[2024-12-14 02:30:11,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:11,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:11,545][root][INFO] - Training Epoch: 5/[2024-12-14 02:30:11,605][rloss: 1.8633540868759155, acc: 0.5073529481887817)
[2024-12-14 02:30:11,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:11,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:11,924][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.5711766481399536, acc: 0.8461538553237915)
[2024-12-14 02:30:12,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:12,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:12,263][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.2780732810497284, acc: 0.9259259104728699)
[2024-12-14 02:30:12,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:12,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:12,675][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 1.0051066875457764, acc: 0.75)
[2024-12-14 02:30:12,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:12,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:13,071][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.5863574743270874, acc: 0.8333333134651184)
[2024-12-14 02:30:13,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:13,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:13,437][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 1.1470813751220703, acc: 0.6666666865348816)
[2024-12-14 02:30:13,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:13,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:13,785][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 1.1778991222381592, acc: 0.6507936716079712)
[2024-12-14 02:30:13,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:14,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:14,102][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 1.8275748491287231, acc: 0.4647887349128723)
[2024-12-14 02:30:14,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:14,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:14,562][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 2.018404722213745, acc: 0.4933333396911621)
[2024-12-14 02:30:14,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:14,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:14,877][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 1.0840868949890137, acc: 0.7027027010917664)
[2024-12-14 02:30:14,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:15,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:15,205][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.37470266222953796, acc: 0.8846153616905212)
[2024-12-14 02:30:15,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:15,684][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:30:15,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:16,313][slam_llm.models.slam_model][INFO] - modality encoder
                                            [2024-12-14 02:30:16,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:16,832][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:30:17,083][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:30:17,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:17,401][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 1.552273154258728, acc: 0.6029411554336548)
[2024-12-14 02:30:17,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:17,786][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.41102492809295654, acc: 0.7804877758026123)
[2024-12-14 02:30:17,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:18,095][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.1053440272808075, acc: 0.9599999785423279)
[2024-12-14 02:30:18,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:18,413][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.06051308289170265, acc: 1.0)
[2024-12-14 02:30:18,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:18,759][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.32655155658721924, acc: 0.8709677457809448)
[2024-12-14 02:30:18,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:19,135][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 0.9188575148582458, acc: 0.7894737124443054)
[2024-12-14 02:30:19,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:19,515][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 1.109834909439087, acc: 0.6714285612106323)
[2024-12-14 02:30:19,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:19,901][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 1.0979688167572021, acc: 0.7105262875556946)
[2024-12-14 02:30:20,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:20,467][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 1.3291717767715454, acc: 0.5849056839942932)
                   [2024-12-14 02:30:20,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:21,050][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 1.5896027088165283, acc: 0.550000011920929)
                                                                                                                                                              [2024-12-14 02:30:21,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:21,352][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.7432720065116882, acc: 0.7777777910232544)
[2024-12-14 02:30:21,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:21,683][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 0.9386216402053833, acc: 0.7096773982048035)
                                                                              [2024-12-14 02:30:21,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:22,041][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 2.257634162902832, acc: 0.4000000059604645)
                                                                              [2024-12-14 02:30:22,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:22,381][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 1.6697012186050415, acc: 0.5833333134651184)
                                                                              [2024-12-14 02:30:22,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:23,239][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 2.139901876449585, acc: 0.4320000112056732)
                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:30:23,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:23,650][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 2.140925645828247, acc: 0.3932584226131439)
                                                                              [2024-12-14 02:30:23,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:24,047][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 1.80806303024292, acc: 0.5270270109176636)
                                                                                                                                                               [2024-12-14 02:30:24,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:24,509][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 1.2518960237503052, acc: 0.6551724076271057)
                                                                             [2024-12-14 02:30:24,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:24,772][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.3997977375984192, acc: 0.8636363744735718)
                                                                             [2024-12-14 02:30:24,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:25,123][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.40174034237861633, acc: 0.9090909361839294)
                                                                             [2024-12-14 02:30:25,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:25,514][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.5022502541542053, acc: 0.8125)
           [2024-12-14 02:30:25,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:25,868][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.601872980594635, acc: 0.8666666746139526)
                                                                                                                                                            [2024-12-14 02:30:26,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:26,287][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 1.3607134819030762, acc: 0.5666666626930237)
                                                                              [2024-12-14 02:30:26,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:26,657][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.7955256104469299, acc: 0.78125)
                                                                                       [2024-12-14 02:30:26,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:27,017][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.3809370696544647, acc: 0.8999999761581421)
                                                                             [2024-12-14 02:30:27,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:27,329][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 1.0116260051727295, acc: 0.7586206793785095)
                                                                             [2024-12-14 02:30:27,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:27,670][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.48799756169319153, acc: 0.800000011920929)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:30:28,447][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:30:28,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:28,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:28,729][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.6108500361442566, acc: 0.8484848737716675)
[2024-12-14 02:30:28,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:28,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:29,076][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.4053167700767517, acc: 0.8846153616905212)
[2024-12-14 02:30:29,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:29,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:29,437][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 1.425246000289917, acc: 0.557692289352417)
[2024-12-14 02:30:29,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:29,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:29,788][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 1.8441135883331299, acc: 0.5)
[2024-12-14 02:30:29,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:29,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:30,114][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 1.1344932317733765, acc: 0.71875)
[2024-12-14 02:30:30,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:30,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:30,513][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 1.5841060876846313, acc: 0.52173912525177)
[2024-12-14 02:30:30,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:30,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:30,930][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 1.17544686794281, acc: 0.6800000071525574)
[2024-12-14 02:30:30,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:31,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:31,247][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 1.0150291919708252, acc: 0.739130437374115)
[2024-12-14 02:30:31,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:31,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:31,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:31,770][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 1.6079250574111938, acc: 0.5600000023841858)
[2024-12-14 02:30:31,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:31,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:32,225][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 1.5758038759231567, acc: 0.553398072719574)
[2024-12-14 02:30:32,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:32,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:32,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:32,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:33,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:33,358][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 1.7896496057510376, acc: 0.5097087621688843)
[2024-12-14 02:30:33,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:33,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:34,201][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 1.8884470462799072, acc: 0.47311827540397644)
[2024-12-14 02:30:34,290][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.5467, device='cuda:0') eval_epoch_loss=tensor(1.7132, device='cuda:0') eval_epoch_acc=tensor(0.5699, device='cuda:0')
[2024-12-14 02:30:34,291][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:30:34,291][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:30:34,702][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:30:35,031][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:30:35,429][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:30:35,798][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:30:36,115][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:30:36,426][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:30:36,748][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                  [2024-12-14 02:30:37,020][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:30:37,410][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:30:37,755][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:30:38,103][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:30:38,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:38,418][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 1.6070663928985596, acc: 0.5671641826629639)
[2024-12-14 02:30:38,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:38,548][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 2.0927605628967285, acc: 0.43065693974494934)
[2024-12-14 02:30:38,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:38,784][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 2.1149446964263916, acc: 0.36734694242477417)
[2024-12-14 02:30:38,859][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 1.9249852895736694, acc: 0.5074626803398132)
[2024-12-14 02:30:38,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:38,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:39,223][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 1.9991239309310913, acc: 0.38297873735427856)
[2024-12-14 02:30:39,233][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.5795061588287354, acc: 0.8999999761581421)
[2024-12-14 02:30:39,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:39,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:39,563][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.3286624550819397, acc: 0.9090909361839294)
[2024-12-14 02:30:39,574][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 1.6124590635299683, acc: 0.5428571701049805)
[2024-12-14 02:30:39,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:39,945][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.5426774024963379, acc: 0.782608687877655)
[2024-12-14 02:30:39,967][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 1.4667705297470093, acc: 0.6071428656578064)
[2024-12-14 02:30:40,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:40,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:40,309][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 0.7874283194541931, acc: 0.782608687877655)
[2024-12-14 02:30:40,338][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 1.0136624574661255, acc: 0.7045454382896423)
[2024-12-14 02:30:40,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:40,679][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 1.373510718345642, acc: 0.4482758641242981)
[2024-12-14 02:30:40,699][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 1.613280177116394, acc: 0.5517241358757019)
[2024-12-14 02:30:40,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:40,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:41,080][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 0.9860410690307617, acc: 0.6976743936538696)
[2024-12-14 02:30:41,088][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 1.5209722518920898, acc: 0.6304348111152649)
[2024-12-14 02:30:41,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:41,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:41,428][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 0.7278438806533813, acc: 0.7599999904632568)
[2024-12-14 02:30:41,465][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 1.5783817768096924, acc: 0.508474588394165)
[2024-12-14 02:30:41,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:41,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:41,757][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.18061169981956482, acc: 1.0)
[2024-12-14 02:30:41,806][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 1.750246286392212, acc: 0.5438596606254578)
[2024-12-14 02:30:42,037][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:30:42,423][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:30:42,892][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:30:43,264][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:30:43,658][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:30:44,068][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:30:44,465][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:30:44,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:45,214][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:30:45,494][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:30:45,899][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:30:46,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:46,269][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 1.160540223121643, acc: 0.6352941393852234)
[2024-12-14 02:30:46,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:46,830][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 1.8414448499679565, acc: 0.5056179761886597)
[2024-12-14 02:30:46,884][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.9198769330978394, acc: 0.4372623562812805)
[2024-12-14 02:30:46,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:46,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:47,227][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 1.2237467765808105, acc: 0.7045454382896423)
[2024-12-14 02:30:47,258][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 1.2782769203186035, acc: 0.653333306312561)
[2024-12-14 02:30:47,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:47,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:47,526][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 0.8426825404167175, acc: 0.6666666865348816)
[2024-12-14 02:30:47,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:47,681][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 1.1698424816131592, acc: 0.7307692170143127)
[2024-12-14 02:30:47,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:47,817][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 1.0911226272583008, acc: 0.6551724076271057)
[2024-12-14 02:30:47,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:48,063][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.39877447485923767, acc: 0.9166666865348816)
[2024-12-14 02:30:48,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:48,204][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 0.8149701952934265, acc: 0.7346938848495483)
[2024-12-14 02:30:48,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:48,417][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.5159766674041748, acc: 0.8947368264198303)
[2024-12-14 02:30:48,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:48,576][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 1.2733240127563477, acc: 0.6000000238418579)
[2024-12-14 02:30:48,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:48,809][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 1.827852725982666, acc: 0.4907975494861603)
[2024-12-14 02:30:48,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:48,989][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 1.2655682563781738, acc: 0.6527777910232544)
[2024-12-14 02:30:49,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:49,236][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.53946053981781, acc: 0.5694444179534912)
[2024-12-14 02:30:49,337][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.561926245689392, acc: 0.5490196347236633)
[2024-12-14 02:30:49,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:49,591][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 1.8858014345169067, acc: 0.4416666626930237)
[2024-12-14 02:30:49,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:49,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:49,954][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 1.8546667098999023, acc: 0.4464285671710968)
[2024-12-14 02:30:50,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:50,449][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.8008774518966675, acc: 0.5128205418586731)
[2024-12-14 02:30:50,365][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 2.1741645336151123, acc: 0.465753436088562)
[2024-12-14 02:30:50,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:50,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:50,668][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.49883827567100525, acc: 0.875)
[2024-12-14 02:30:50,747][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 1.629777193069458, acc: 0.5808823704719543)
[2024-12-14 02:30:50,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:51,002][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.7232331037521362, acc: 0.6666666865348816)
[2024-12-14 02:30:51,069][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.7638244032859802, acc: 0.7692307829856873)
[2024-12-14 02:30:51,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:51,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:51,280][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.7877627015113831, acc: 0.7857142686843872)
[2024-12-14 02:30:51,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:51,421][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.30585047602653503, acc: 0.8260869383811951)
[2024-12-14 02:30:51,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:51,765][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.6245536208152771, acc: 0.8125)
[2024-12-14 02:30:51,825][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.4809926748275757, acc: 0.6371681690216064)
[2024-12-14 02:30:51,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:51,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:52,115][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.6786451935768127, acc: 0.782608687877655)
[2024-12-14 02:30:52,178][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 1.380929946899414, acc: 0.6231883764266968)
[2024-12-14 02:30:52,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:52,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:52,453][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 0.9197971820831299, acc: 0.7142857313156128)
[2024-12-14 02:30:52,511][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 1.5970020294189453, acc: 0.5681818127632141)
[2024-12-14 02:30:52,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:53,422][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 2.189788818359375, acc: 0.42748090624809265)
[2024-12-14 02:30:53,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:53,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:53,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:54,090][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 1.9488731622695923, acc: 0.46666666865348816)
[2024-12-14 02:30:54,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:54,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:54,417][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 1.3321363925933838, acc: 0.6557376980781555)
[2024-12-14 02:30:54,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:54,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:54,765][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.5987155437469482, acc: 0.8333333134651184)
[2024-12-14 02:30:54,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:54,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:55,131][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.8049132823944092, acc: 0.7599999904632568)
[2024-12-14 02:30:55,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:55,412][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:30:55,725][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:30:56,110][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:30:56,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:56,796][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:30:57,153][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:30:57,495][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:30:57,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:58,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:58,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:30:58,885][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:30:59,516][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.2740, device='cuda:0') eval_epoch_loss=tensor(1.8364, device='cuda:0') eval_epoch_acc=tensor(0.5657, device='cuda:0')
[2024-12-14 02:30:59,518][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:30:59,518][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:30:59,831][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_5_step_278_loss_1.836410403251648/model.pt
[2024-12-14 02:30:59,835][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:30:59,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:00,176][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 1.6123600006103516, acc: 0.5319148898124695)
[2024-12-14 02:31:00,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:00,524][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 1.331250786781311, acc: 0.6458333134651184)
[2024-12-14 02:31:00,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:00,865][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 1.167786717414856, acc: 0.7045454382896423)
[2024-12-14 02:31:00,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:01,284][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 1.791139006614685, acc: 0.5783132314682007)
[2024-12-14 02:31:01,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:01,648][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 1.689634084701538, acc: 0.5833333134651184)
[2024-12-14 02:31:01,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:01,984][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 1.0371158123016357, acc: 0.6842105388641357)
[2024-12-14 02:31:02,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:02,350][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 1.2009719610214233, acc: 0.6470588445663452)
[2024-12-14 02:31:02,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:02,710][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 1.0509834289550781, acc: 0.6000000238418579)
[2024-12-14 02:31:02,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:03,064][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 1.95481276512146, acc: 0.4296875)
[2024-12-14 02:31:03,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:03,451][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 2.064828872680664, acc: 0.3919999897480011)
                                                                                [2024-12-14 02:31:03,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:03,859][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 1.6265754699707031, acc: 0.5164835453033447)
[2024-12-14 02:31:03,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:04,254][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 2.07822322845459, acc: 0.44720497727394104)
                                                                                                                                                                                                                                              [2024-12-14 02:31:04,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:04,616][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 2.1977133750915527, acc: 0.3814432919025421)
                                                                               [2024-12-14 02:31:04,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:05,003][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.28784748911857605, acc: 0.9090909361839294)
                                                                             [2024-12-14 02:31:05,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:05,388][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 1.442255973815918, acc: 0.5952380895614624)
                                                                              [2024-12-14 02:31:05,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:05,739][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 1.0649876594543457, acc: 0.6724137663841248)
                                                                               [2024-12-14 02:31:05,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:06,200][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 1.1407512426376343, acc: 0.6727272868156433)
                                                                                [2024-12-14 02:31:06,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:06,748][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.6363412141799927, acc: 0.5670102834701538)
[2024-12-14 02:31:06,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:06,611][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 1.4884945154190063, acc: 0.6043956279754639)
[2024-12-14 02:31:06,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:06,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:06,946][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 1.8580952882766724, acc: 0.5022421479225159)
[2024-12-14 02:31:07,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:07,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:07,345][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 1.891958475112915, acc: 0.5236220359802246)
[2024-12-14 02:31:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:07,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:07,758][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 1.8405269384384155, acc: 0.5043103694915771)
[2024-12-14 02:31:07,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:08,170][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 1.8395830392837524, acc: 0.5181159377098083)
[2024-12-14 02:31:08,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:08,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:08,579][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 1.9630110263824463, acc: 0.4474708139896393)
[2024-12-14 02:31:08,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:08,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:08,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:08,964][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 1.7986992597579956, acc: 0.54347825050354)
[2024-12-14 02:31:09,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:09,252][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.3866994380950928, acc: 0.8260869383811951)
[2024-12-14 02:31:09,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:09,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:09,578][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 0.7213371992111206, acc: 0.7857142686843872)
[2024-12-14 02:31:09,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:09,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:09,899][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.6711596846580505, acc: 0.8085106611251831)
[2024-12-14 02:31:10,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:10,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:10,319][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:31:10,574][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 1.3882524967193604, acc: 0.6153846383094788)
[2024-12-14 02:31:10,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:10,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:11,009][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 1.1547284126281738, acc: 0.6756756901741028)
[2024-12-14 02:31:11,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:11,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:11,382][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 1.2552672624588013, acc: 0.6511628031730652)
[2024-12-14 02:31:11,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:11,718][slam_llm.models.slam_model][INFO[2024-12-14 02:31:11,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:12,161][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 1.0838104486465454, acc: 0.6385542154312134)
                     [2024-12-14 02:31:12,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:12,464][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 1.575223445892334, acc: 0.5769230723381042)
 [2024-12-14 02:31:12,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:12,853][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 1.7346699237823486, acc: 0.5714285969734192)
                                                                                                                                                              [2024-12-14 02:31:12,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:13,229][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.1366860717535019, acc: 0.9583333134651184)
                                                                                [2024-12-14 02:31:13,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:13,622][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.47077831625938416, acc: 0.875)
                                                                                                                                                                          [2024-12-14 02:31:13,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:14,025][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.4637851119041443, acc: 0.8387096524238586)
[2024-12-14 02:31:14,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:14,410][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 0.6518829464912415, acc: 0.8709677457809448)
[2024-12-14 02:31:14,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:14,759][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 1.048129677772522, acc: 0.7014925479888916)
[2024-12-14 02:31:14,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:15,151][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 1.2135859727859497, acc: 0.6634615659713745)
[2024-12-14 02:31:15,261][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:31:15,525][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 1.01283860206604, acc: 0.7111111283302307)
  [2024-12-14 02:31:15,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:15,883][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 1.0442299842834473, acc: 0.6774193644523621)
[2024-12-14 02:31:16,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:16,286][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.618591845035553, acc: 0.8600000143051147)
                      [2024-12-14 02:31:16,393][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:31:16,669][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 1.4050699472427368, acc: 0.48148149251937866)
[2024-12-14 02:31:16,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:17,035][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 1.499137282371521, acc: 0.6285714507102966)
                     [2024-12-14 02:31:17,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:17,378][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 1.169613003730774, acc: 0.6410256624221802)
                                                                                [2024-12-14 02:31:17,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:17,694][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 1.6150060892105103, acc: 0.4878048896789551)
                                                                              [2024-12-14 02:31:17,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:18,086][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 1.251531958580017, acc: 0.6052631735801697)
                                                                                [2024-12-14 02:31:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:18,486][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.3470461070537567, acc: 0.8947368264198303)
                                                                              [2024-12-14 02:31:18,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:18,879][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.2144061028957367, acc: 0.9285714030265808)
                                                                               [2024-12-14 02:31:18,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:19,270][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 0.8321314454078674, acc: 0.8148148059844971)
[2024-12-14 02:31:19,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:19,683][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.47696995735168457, acc: 0.90625)
                                                                                                                                                                                                                                                        [2024-12-14 02:31:19,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:20,071][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 1.3302772045135498, acc: 0.6774193644523621)
                                                                  [2024-12-14 02:31:20,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:20,468][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 1.0499536991119385, acc: 0.719298243522644)
                                                                 [2024-12-14 02:31:20,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:20,843][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 1.2952927350997925, acc: 0.5625)
                                                                                           [2024-12-14 02:31:20,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:21,245][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.6359277367591858, acc: 0.7666666507720947)
                                                                               [2024-12-14 02:31:21,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:21,606][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.7510128021240234, acc: 0.7368420958518982)
                                                                               [2024-12-14 02:31:21,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:22,039][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 1.6939152479171753, acc: 0.46000000834465027)
[2024-12-14 02:31:22,176][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:31:22,443][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 2.2069249153137207, acc: 0.39080458879470825)
                                                                              [2024-12-14 02:31:22,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:22,825][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 2.342635154724121, acc: 0.39361703395843506)
[2024-12-14 02:31:22,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:23,155][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 2.414299249649048, acc: 0.3855421543121338)
[2024-12-14 02:31:23,252][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                [2024-12-14 02:31:23,527][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 0.3117818534374237, acc: 0.8695651888847351)
[2024-12-14 02:31:23,625][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                [2024-12-14 02:31:23,854][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 1.0753720998764038, acc: 0.6153846383094788)
[2024-12-14 02:31:23,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:24,234][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 1.94871187210083, acc: 0.46987950801849365)
[2024-12-14 02:31:24,343][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:31:24,634][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 1.5801862478256226, acc: 0.5660377144813538)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:31:24,741][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:31:25,008][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 1.4489041566848755, acc: 0.5822784900665283)
                                                                              [2024-12-14 02:31:25,124][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:31:25,411][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 1.512955904006958, acc: 0.6078431606292725)
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:31:25,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:25,792][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 2.0091147422790527, acc: 0.447761207818985)
                                                                                                                                                                                                                       [2024-12-14 02:31:25,895][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:31:26,167][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.4045698642730713, acc: 0.8999999761581421)
                                                                                [2024-12-14 02:31:26,276][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:31:26,549][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 0.4229829013347626, acc: 0.9200000166893005)
                                                                                                                                                [2024-12-14 02:31:26,672][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:31:26,944][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 0.9784788489341736, acc: 0.75)
                                                                                                                                                                             [2024-12-14 02:31:27,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:27,324][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 1.3244010210037231, acc: 0.5813953280448914)
                                                                                                                                                                                                                         [2024-12-14 02:31:27,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:27,692][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 1.126228928565979, acc: 0.6666666865348816)
                                                                                                                                                                                                                       [2024-12-14 02:31:27,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:28,062][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 1.4035966396331787, acc: 0.6222222447395325)
                                                                                                                                                                                                                         [2024-12-14 02:31:28,143][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:31:28,426][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.4902893006801605, acc: 0.782608687877655)
                                                                                                                                                               [2024-12-14 02:31:28,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:28,832][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.988712728023529, acc: 0.6538461446762085)
                                                                                                                                         [2024-12-14 02:31:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:29,189][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 2.062115430831909, acc: 0.450549453496933)
                                                                                  [2024-12-14 02:31:29,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:29,697][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 1.7901086807250977, acc: 0.539130449295044)
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:31:29,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:30,058][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 1.6949690580368042, acc: 0.532608687877655)
                                                                                                                                                                                                          [2024-12-14 02:31:30,160][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:31:30,427][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 1.6679860353469849, acc: 0.5918367505073547)
                                                                                                                                                             [2024-12-14 02:31:30,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:30,730][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.09883975237607956, acc: 1.0)
                                                                                                                                                       [2024-12-14 02:31:30,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:31,013][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.24660661816596985, acc: 1.0)
              [2024-12-14 02:31:31,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:31,374][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.80693519115448, acc: 0.8048780560493469)
  [2024-12-14 02:31:31,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:31,724][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 1.1160173416137695, acc: 0.7111111283302307)
                                                                                                                                                                                                                        [2024-12-14 02:31:31,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:32,102][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 1.3165192604064941, acc: 0.5921052694320679)
                                                                                                                                                                                                                        [2024-12-14 02:31:32,228][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:31:32,495][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 1.120894432067871, acc: 0.6829268336296082)
[2024-12-14 02:31:32,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:32,883][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 1.0897085666656494, acc: 0.6666666865348816)
                                                                                                                                                               [2024-12-14 02:31:33,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:33,244][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.44665321707725525, acc: 0.8333333134651184)
                                                                                                                                        [2024-12-14 02:31:33,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:33,622][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.12895558774471283, acc: 0.95652174949646)
  [2024-12-14 02:31:33,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:33,990][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.3874831199645996, acc: 0.8928571343421936)
[2024-12-14 02:31:34,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:34,379][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.5351263284683228, acc: 0.875)
                                                                                 [2024-12-14 02:31:34,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:34,998][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 1.5778577327728271, acc: 0.6000000238418579)
                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:31:35,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:35,890][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 1.1451585292816162, acc: 0.7169811129570007)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:31:36,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:36,305][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 1.2819762229919434, acc: 0.6888889074325562)
                                                         [2024-12-14 02:31:36,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:36,683][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 0.9101936221122742, acc: 0.6607142686843872)
                                                                                [2024-12-14 02:31:36,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:37,079][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.6674178242683411, acc: 0.7142857313156128)
                                                                 [2024-12-14 02:31:37,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:37,442][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.1703355610370636, acc: 0.9599999785423279)
                                                                               [2024-12-14 02:31:37,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:37,787][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.17447486519813538, acc: 0.95652174949646)
                                                                                [2024-12-14 02:31:37,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:38,175][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 0.9537644386291504, acc: 0.7291666865348816)
                                                                               [2024-12-14 02:31:38,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:38,519][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 1.3308883905410767, acc: 0.6736842393875122)
                                                                             [2024-12-14 02:31:38,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:39,097][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 1.567797064781189, acc: 0.5868263244628906)
02:31:38,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:38,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:39,042][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.6861069202423096, acc: 0.5588235259056091)
[2024-12-14 02:31:39,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:39,367][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:31:39,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:40,073][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 2.2036781311035156, acc: 0.4178082048892975)
[2024-12-14 02:31:40,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:40,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:40,396][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.409299373626709, acc: 0.875)
[2024-12-14 02:31:40,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:40,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:40,786][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.6107731461524963, acc: 0.8148148059844971)
[2024-12-14 02:31:40,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:41,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:41,124][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.730735719203949, acc: 0.7857142686843872)
[2024-12-14 02:31:41,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:41,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:41,669][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.5328717231750488, acc: 0.5752212405204773)
[2024-12-14 02:31:41,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:41,992][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 1.5741727352142334, acc: 0.6086956262588501)
[2024-12-14 02:31:42,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:42,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:42,348][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 1.699785590171814, acc: 0.5681818127632141)
[2024-12-14 02:31:42,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:42,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:42,666][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:31:42,966][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:31:43,256][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 2.2683990001678467, acc: 0.4198473393917084)
[2024-12-14 02:31:43,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:43,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:43,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:43,925][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 2.094341278076172, acc: 0.43703705072402954)
[2024-12-14 02:31:44,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:44,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:44,286][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 1.4189260005950928, acc: 0.6393442749977112)
[2024-12-14 02:31:44,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:44,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:44,675][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.3978769779205322, acc: 0.875)
[2024-12-14 02:31:44,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:45,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:45,016][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.8897846937179565, acc: 0.7200000286102295)
[2024-12-14 02:31:45,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:45,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:45,357][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.8271256685256958, acc: 0.75)
[2024-12-14 02:31:45,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:45,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:45,693][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 1.6785801649093628, acc: 0.5365853905677795)
[2024-12-14 02:31:45,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:45,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:46,069][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 2.0185341835021973, acc: 0.45619335770606995)
[2024-12-14 02:31:46,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:46,377][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 2.153303384780884, acc: 0.4265129566192627)
[2024-12-14 02:31:46,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:46,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:46,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:46,861][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 2.1821060180664062, acc: 0.40625)
[2024-12-14 02:31:46,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:47,142][slam_llm.models.slam_model][INFO] - modality encoder
                                                                     [2024-12-14 02:31:47,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:47,406][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 2.04478120803833, acc: 0.44840526580810547)
[2024-12-14 02:31:47,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:47,792][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 1.9259865283966064, acc: 0.47686833143234253)
[2024-12-14 02:31:47,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:47,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:48,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:48,140][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 0.9495528936386108, acc: 0.6800000071525574)
[2024-12-14 02:31:48,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:48,438][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:31:48,697][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 1.8686598539352417, acc: 0.5)
[2024-12-14 02:31:48,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:48,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:49,155][slam_llm.models.slam_model][INFO] - modality encoder
                                                                        [2024-12-14 02:31:49,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:49,517][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 1.6746838092803955, acc: 0.5634920597076416)
[2024-12-14 02:31:49,778][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:31:49,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:50,186][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:31:50,436][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 1.8057842254638672, acc: 0.5)
[2024-12-14 02:31:50,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:50,639][slam_llm.mod4][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:50,857][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.630529522895813, acc: 0.8148148059844971)
[2024-12-14 02:31:50,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:51,204][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.21871455013751984, acc: 0.9615384340286255)
[2024-12-14 02:31:51,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:51,591][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 0.946575939655304, acc: 0.7068965435028076)
[2024-12-14 02:31:51,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:51,978][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.37206125259399414, acc: 0.8571428656578064)
[2024-12-14 02:31:52,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:52,368][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.49997439980506897, acc: 0.8999999761581421)
[2024-12-14 02:31:52,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:52,732][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.39136970043182373, acc: 0.8484848737716675)
[2024-12-14 02:31:52,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:53,071][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.6135952472686768, acc: 0.8181818127632141)
[2024-12-14 02:31:53,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:53,415][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 1.3774617910385132, acc: 0.5882353186607361)
                                                                              [2024-12-14 02:31:53,525][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:31:53,808][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 1.160180926322937, acc: 0.692307710647583)
                       [2024-12-14 02:31:53,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:54,187][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 0.9337107539176941, acc: 0.7222222089767456)
                                                                               [2024-12-14 02:31:54,304][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:31:54,530][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 0.9989696741104126, acc: 0.7250000238418579)
[2024-12-14 02:31:54,604][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:31:54,803][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 0.4536660611629486, acc: 0.75)
[2024-12-14 02:31:54,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:55,168][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.12261642515659332, acc: 1.0)
                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:31:56,083][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.8451728820800781, acc: 0.4660194218158722)
[2024-12-14 02:31:55,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:55,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:56,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:56,119][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 1.3244613409042358, acc: 0.6190476417541504)
[2024-12-14 02:31:56,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:56,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:56,453][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 1.5010066032409668, acc: 0.5494505763053894)
[2024-12-14 02:31:56,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:56,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:56,822][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 1.883641242980957, acc: 0.4798206388950348)
[2024-12-14 02:31:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:57,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:57,218][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 1.9438954591751099, acc: 0.4606299102306366)
[2024-12-14 02:31:57,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:57,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:57,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:57,642][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 1.816319227218628, acc: 0.5)
[2024-12-14 02:31:57,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:57,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:58,004][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 1.8652182817459106, acc: 0.49275362491607666)
[2024-12-14 02:31:58,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:58,397][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 1.969943642616272, acc: 0.4630350172519684)
[2024-12-14 02:31:58,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:58,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:58,744][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 1.8725707530975342, acc: 0.489130437374115)
[2024-12-14 02:31:58,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:58,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:59,116][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.3927013874053955, acc: 0.8260869383811951)
[2024-12-14 02:31:59,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:59,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:59,492][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 0.8845183253288269, acc: 0.75)
[2024-12-14 02:31:59,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:59,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:59,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:31:59,890][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.7847275137901306, acc: 0.8085106611251831)
[2024-12-14 02:32:00,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:00,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:00,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:00,581][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 1.4199329614639282, acc: 0.5923076868057251)
[2024-12-14 02:32:00,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:00,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:01,020][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 1.2392165660858154, acc: 0.662162184715271)
[2024-12-14 02:32:01,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:01,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:01,433][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 1.174492359161377, acc: 0.6744186282157898)
[2024-12-14 02:32:01,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:01,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:02,101][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:32:02,433][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:32:02,753][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:32:03,133][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:32:03,482][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:32:03,759][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:32:04,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:04,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:04,774][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:32:05,131][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:32:05,628][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:32:05,970][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:32:06,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:06,724][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:32:07,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:07,387][slam_llm.models.slam_model][INFO] - modality encoder
5.8516, device='cuda:0') eval_epoch_loss=tensor(1.7667, device='cuda:0') eval_epoch_acc=tensor(0.5752, device='cuda:0')
[2024-12-14 02:32:07,106][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:32:07,107][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:32:07,284][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 1.8757975101470947, acc: 0.49473685026168823)
[2024-12-14 02:32:07,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:07,433][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_5_step_278_loss_1.766707181930542/model.pt
[2024-12-14 02:32:07,438][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:32:07,439][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.5752381682395935
[2024-12-14 02:32:07,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:07,569][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 1.557641625404358, acc: 0.5888888835906982)
[2024-12-14 02:32:07,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:07,887][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 1.5044604539871216, acc: 0.5957446694374084)
[2024-12-14 02:32:07,990][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 1.2750080823898315, acc: 0.644444465637207)
[2024-12-14 02:32:07,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:08,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:08,296][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 1.1562000513076782, acc: 0.6875)
[2024-12-14 02:32:08,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:08,503][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 1.5811735391616821, acc: 0.6376146674156189)
[2024-12-14 02:32:08,624][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 0.8863996267318726, acc: 0.8181818127632141)
[2024-12-14 02:32:08,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:08,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:08,988][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 1.3203233480453491, acc: 0.6307692527770996)
[2024-12-14 02:32:09,055][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 1.7318406105041504, acc: 0.5421686768531799)
[2024-12-14 02:32:09,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:09,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:09,320][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 0.5912198424339294, acc: 0.7894737124443054)
[2024-12-14 02:32:09,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:09,428][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 1.7381106615066528, acc: 0.5648148059844971)
[2024-12-14 02:32:09,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:09,674][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.309895783662796, acc: 0.9166666865348816)
[2024-12-14 02:32:09,787][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 1.3047798871994019, acc: 0.5789473652839661)
[2024-12-14 02:32:09,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:09,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:10,087][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 0.9425327181816101, acc: 0.6818181872367859)
[2024-12-14 02:32:10,110][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 1.0259464979171753, acc: 0.7058823704719543)
[2024-12-14 02:32:10,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:10,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:10,487][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:32:10,928][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:32:11,335][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:32:11,736][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:32:12,113][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:32:12,504][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:32:12,858][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:32:13,230][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:32:13,560][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 02:32:13,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:13,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:14,096][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.6354297399520874, acc: 0.75)
[2024-12-14 02:32:14,179][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.6293840408325195, acc: 0.5670102834701538)
[2024-12-14 02:32:14,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:14,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:14,476][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 0.890505313873291, acc: 0.6756756901741028)
[2024-12-14 02:32:14,501][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 1.5266051292419434, acc: 0.5517241358757019)
[2024-12-14 02:32:14,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:14,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:14,769][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 1.135963797569275, acc: 0.6756756901741028)
[2024-12-14 02:32:14,849][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 1.1098366975784302, acc: 0.7037037014961243)
[2024-12-14 02:32:14,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:14,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:15,158][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 0.930234432220459, acc: 0.6486486196517944)
[2024-12-14 02:32:15,224][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 1.210996150970459, acc: 0.6578947305679321)
[2024-12-14 02:32:15,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:15,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:15,500][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 1.4373462200164795, acc: 0.6029411554336548)
[2024-12-14 02:32:15,612][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 0.7849715352058411, acc: 0.7678571343421936)
[2024-12-14 02:32:15,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:15,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:15,886][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.42635345458984375, acc: 0.8048780560493469)
[2024-12-14 02:32:15,991][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.8255205154418945, acc: 0.71875)
[2024-12-14 02:32:15,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:16,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:16,264][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.13945461809635162, acc: 0.9200000166893005)
[2024-12-14 02:32:16,337][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 1.2119332551956177, acc: 0.698113203048706)
[2024-12-14 02:32:16,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:16,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:16,588][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.1398794949054718, acc: 0.9599999785423279)
[2024-12-14 02:32:16,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:16,740][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.5788798332214355, acc: 0.7735849022865295)
[2024-12-14 02:32:16,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:16,921][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.17871418595314026, acc: 0.9677419066429138)
[2024-12-14 02:32:17,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:17,135][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.6270227432250977, acc: 0.8529411554336548)
[2024-12-14 02:32:17,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:17,245][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 0.9694353342056274, acc: 0.7368420958518982)
[2024-12-14 02:32:17,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:17,633][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.9452878832817078, acc: 0.6875)
[2024-12-14 02:32:17,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:17,555][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 1.1990885734558105, acc: 0.6714285612106323)
[2024-12-14 02:32:17,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:17,824][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 0.9994879364967346, acc: 0.7049180269241333)
[2024-12-14 02:32:17,900][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 1.1513549089431763, acc: 0.6578947305679321)
[2024-12-14 02:32:17,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:18,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:18,125][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.4610586166381836, acc: 0.8666666746139526)
[2024-12-14 02:32:18,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:18,426][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.24097520112991333, acc: 0.8947368264198303)
[2024-12-14 02:32:18,484][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 1.3858435153961182, acc: 0.5566037893295288)
[2024-12-14 02:32:18,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:18,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:18,718][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 1.5884416103363037, acc: 0.47826087474823)
[2024-12-14 02:32:18,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:19,065][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 1.6345235109329224, acc: 0.5333333611488342)
[2024-12-14 02:32:19,144][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 1.3278886079788208, acc: 0.625)
[2024-12-14 02:32:19,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:19,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:19,391][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.8623983860015869, acc: 0.75)
[2024-12-14 02:32:19,414][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 1.0599708557128906, acc: 0.6867470145225525)
[2024-12-14 02:32:19,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:19,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:19,716][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 0.7668672204017639, acc: 0.8064516186714172)
[2024-12-14 02:32:19,720][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 1.6467489004135132, acc: 0.4871794879436493)
[2024-12-14 02:32:19,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:19,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:20,104][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 1.6723154783248901, acc: 0.5510203838348389)
[2024-12-14 02:32:20,159][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 2.378009557723999, acc: 0.4266666769981384)
[2024-12-14 02:32:20,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:20,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:20,456][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.08483872562646866, acc: 0.9583333134651184)
[2024-12-14 02:32:20,509][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 1.5562456846237183, acc: 0.6041666865348816)
[2024-12-14 02:32:20,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:20,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:20,781][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.45217737555503845, acc: 0.9166666865348816)
[2024-12-14 02:32:20,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:21,146][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.607589840888977, acc: 0.774193525314331)
[2024-12-14 02:32:21,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:21,347][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 2.1186399459838867, acc: 0.4320000112056732)
[2024-12-14 02:32:21,372][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 0.7067746520042419, acc: 0.8064516186714172)
[2024-12-14 02:32:21,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:21,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:21,663][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 2.0416676998138428, acc: 0.4157303273677826)
[2024-12-14 02:32:21,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:21,763][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 1.113189935684204, acc: 0.6716417670249939)
[2024-12-14 02:32:21,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:22,002][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 1.8628935813903809, acc: 0.5135135054588318)
[2024-12-14 02:32:22,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:22,171][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 1.1503019332885742, acc: 0.692307710647583)
[2024-12-14 02:32:22,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:22,447][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 1.212796688079834, acc: 0.6724137663841248)
[2024-12-14 02:32:22,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:22,549][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 1.0027713775634766, acc: 0.644444465637207)
[2024-12-14 02:32:22,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:22,806][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.4403507113456726, acc: 0.8181818127632141)
[2024-12-14 02:32:22,867][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 1.0684397220611572, acc: 0.6935483813285828)
[2024-12-14 02:32:22,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:22,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:23,162][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.3679935336112976, acc: 0.8636363744735718)
[2024-12-14 02:32:23,189][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.596365213394165, acc: 0.8399999737739563)
[2024-12-14 02:32:23,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:23,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:23,500][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.6058696508407593, acc: 0.8125)
[2024-12-14 02:32:23,565][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 1.7324228286743164, acc: 0.40740740299224854)
[2024-12-14 02:32:23,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:23,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:23,850][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 1.5678852796554565, acc: 0.5428571701049805)
[2024-12-14 02:32:23,880][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.5828784704208374, acc: 0.8333333134651184)
[2024-12-14 02:32:23,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:24,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:24,197][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 1.2849340438842773, acc: 0.5897436141967773)
[2024-12-14 02:32:24,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:24,303][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 1.3316740989685059, acc: 0.6000000238418579)
[2024-12-14 02:32:24,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:24,535][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 1.6385716199874878, acc: 0.5853658318519592)
[2024-12-14 02:32:24,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:24,707][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.6153751015663147, acc: 0.78125)
[2024-12-14 02:32:24,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:24,852][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 1.2527875900268555, acc: 0.6842105388641357)
[2024-12-14 02:32:24,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:25,067][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.6220976114273071, acc: 0.8333333134651184)
[2024-12-14 02:32:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:25,215][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.4264288544654846, acc: 0.8421052694320679)
[2024-12-14 02:32:25,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:25,425][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 0.8108295798301697, acc: 0.8275862336158752)
[2024-12-14 02:32:25,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:25,568][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.36684542894363403, acc: 0.8928571343421936)
[2024-12-14 02:32:25,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:25,818][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.4568469226360321, acc: 0.8799999952316284)
[2024-12-14 02:32:25,921][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 1.4340806007385254, acc: 0.6666666865348816)
[2024-12-14 02:32:26,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:26,231][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.5532450079917908, acc: 0.875)
[2024-12-14 02:32:26,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:26,622][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 1.3859630823135376, acc: 0.6451612710952759)
[2024-12-14 02:32:26,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:26,745][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:32:26,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:27,041][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 1.156263828277588, acc: 0.6666666865348816)
[2024-12-14 02:32:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:27,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:27,445][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 1.304687738418579, acc: 0.59375)
[2024-12-14 02:32:27,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:27,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:27,801][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.6903275847434998, acc: 0.699999988079071)
[2024-12-14 02:32:27,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:27,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:28,205][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.7764689922332764, acc: 0.7368420958518982)
[2024-12-14 02:32:28,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:28,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:28,632][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 1.771822452545166, acc: 0.5)
[2024-12-14 02:32:28,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:28,807][slam_llm.models.slam_model][INF[2024-12-14 02:32:29,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:29,332][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 1.1463993787765503, acc: 0.6756756901741028)
                       [2024-12-14 02:32:29,436][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:32:29,686][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.49966347217559814, acc: 0.8148148059844971)
[2024-12-14 02:32:29,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:30,054][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.3650968670845032, acc: 0.95652174949646)
                       [2024-12-14 02:32:30,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:30,410][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.29524171352386475, acc: 0.9259259104728699)
                                                                              [2024-12-14 02:32:30,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:30,772][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.24471108615398407, acc: 0.9259259104728699)
                                                                              [2024-12-14 02:32:30,868][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:32:31,102][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.7028085589408875, acc: 0.8695651888847351)
[2024-12-14 02:32:31,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:31,471][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 1.0215480327606201, acc: 0.6944444179534912)
                     [2024-12-14 02:32:31,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:31,845][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.34440234303474426, acc: 0.8799999952316284)
                                                                             [2024-12-14 02:32:31,965][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:32:32,269][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.796413004398346, acc: 0.7272727489471436)
[2024-12-14 02:32:32,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:32,581][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 1.1424496173858643, acc: 0.75)
                                   [2024-12-14 02:32:32,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:32,937][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 0.8983196020126343, acc: 0.7727272510528564)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:32:33,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:33,322][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.2857755124568939, acc: 0.9047619104385376)
[2024-12-14 02:32:33,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:33,667][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 1.453705072402954, acc: 0.692307710647583)
[2024-12-14 02:32:33,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:34,145][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 1.60784113407135, acc: 0.5909090638160706)
                         [2024-12-14 02:32:34,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:34,157][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 1.346913456916809, acc: 0.6410256624221802)
[2024-12-14 02:32:34,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:34,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:34,548][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 1.4234411716461182, acc: 0.644444465637207)
[2024-12-14 02:32:34,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:34,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:34,914][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.3605310320854187, acc: 0.9130434989929199)
[2024-12-14 02:32:35,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:35,320][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.9872512817382812, acc: 0.6538461446762085)
[2024-12-14 02:32:35,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:35,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:35,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:35,742][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 1.9585946798324585, acc: 0.4615384638309479)
[2024-12-14 02:32:35,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:36,042][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:32:36,238][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 1.8279684782028198, acc: 0.530434787273407)
[2024-12-14 02:32:36,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:36,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:36,573][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 1.7410762310028076, acc: 0.6086956262588501)
[2024-12-14 02:32:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:36,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:36,931][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 1.666323184967041, acc: 0.5306122303009033)
[2024-12-14 02:32:36,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:37,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:37,274][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.246633842587471, acc: 0.9166666865348816)
[2024-12-14 02:32:37,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:37,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:37,652][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.3643536865711212, acc: 0.8846153616905212)
[2024-12-14 02:32:37,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:37,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:38,038][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.8294865489006042, acc: 0.8048780560493469)
[2024-12-14 02:32:38,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:38,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:38,403][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 1.2016197443008423, acc: 0.7111111283302307)
[2024-12-14 02:32:38,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:38,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:38,721][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 1.4030201435089111, acc: 0.5789473652839661)
[2024-12-14 02:32:38,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:38,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024 (loss: 1.3916617631912231, acc: 0.6282051205635071)
[2024-12-14 02:32:39,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:39,348][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 1.4903638362884521, acc: 0.5131579041481018)
[2024-12-14 02:32:39,436][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:32:39,677][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 1.2026323080062866, acc: 0.5714285969734192)
                                                                                                                                                               [2024-12-14 02:32:39,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:40,008][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 0.7320791482925415, acc: 0.7272727489471436)
                                                                 [2024-12-14 02:32:40,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:40,396][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 1.7820380926132202, acc: 0.5154638886451721)
                                                                              [2024-12-14 02:32:40,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:40,778][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 1.1612478494644165, acc: 0.6714285612106323)
[2024-12-14 02:32:40,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:41,171][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 1.7041665315628052, acc: 0.5406976938247681)
          [2024-12-14 02:32:41,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:41,541][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 1.5763098001480103, acc: 0.5)
              [2024-12-14 02:32:41,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:41,912][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 1.6400504112243652, acc: 0.5679012537002563)
[2024-12-14 02:32:42,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:42,243][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 0.9683396220207214, acc: 0.6944444179534912)
[2024-12-14 02:32:42,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:42,566][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.7440670728683472, acc: 0.78125)
[2024-12-14 02:32:42,672][slam_llm.models.slam_model][INFO] - modality encoder
                              [2024-12-14 02:32:42,922][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.6821078658103943, acc: 0.8461538553237915)
[2024-12-14 02:32:43,027][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:32:43,259][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 0.8641728758811951, acc: 0.717391312122345)
[2024-12-14 02:32:43,349][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:32:43,588][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 1.4170448780059814, acc: 0.5833333134651184)
                                                                                                                                                               [2024-12-14 02:32:43,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:43,927][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 1.6004652976989746, acc: 0.5421686768531799)
[2024-12-14 02:32:44,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:44,272][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 1.2285445928573608, acc: 0.6216216087341309)
                    [2024-12-14 02:32:44,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:44,653][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 1.5035560131072998, acc: 0.6116504669189453)
                                                                               [2024-12-14 02:32:44,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:45,050][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 1.2326815128326416, acc: 0.6260162591934204)
                                                                               [2024-12-14 02:32:45,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:45,365][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.5883986949920654, acc: 0.8333333134651184)
[2024-12-14 02:32:45,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:45,711][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.7276197075843811, acc: 0.7857142686843872)
                                                                              [2024-12-14 02:32:45,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:46,119][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 1.8323742151260376, acc: 0.5098039507865906)
[2024-12-14 02:32:46,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:46,451][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 2.0053775310516357, acc: 0.4628821015357971)
[2024-12-14 02:32:46,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:46,817][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 1.8229986429214478, acc: 0.53125)
[2024-12-14 02:32:46,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:47,252][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 1.9758464097976685, acc: 0.47239264845848083)
[2024-12-14 02:32:47,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:47,606][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 1.9208780527114868, acc: 0.49640288949012756)
                                                                          [2024-12-14 02:32:47,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:48,005][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 2.0608556270599365, acc: 0.402010053396225)
                                                                                 [2024-12-14 02:32:48,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:48,351][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.730379045009613, acc: 0.8055555820465088)
 [2024-12-14 02:32:48,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:48,679][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.8921235203742981, acc: 0.7878788113594055)
                                                                    [2024-12-14 02:32:48,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:49,071][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.4332526624202728, acc: 0.8888888955116272)
                                                                               [2024-12-14 02:32:49,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:49,460][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 0.8015239834785461, acc: 0.699999988079071)
                                                                                 [2024-12-14 02:32:49,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:49,829][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 0.368281751871109, acc: 0.8999999761581421)
                                                                                                                                                               [2024-12-14 02:32:49,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:50,207][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 1.157955288887024, acc: 0.6034482717514038)
                                                                               [2024-12-14 02:32:50,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:50,590][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.6170156598091125, acc: 0.8064516186714172)
                                                                               [2024-12-14 02:32:50,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:50,917][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.35199427604675293, acc: 0.8947368264198303)
                                                               [2024-12-14 02:32:51,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:51,288][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 0.9770111441612244, acc: 0.6296296119689941)
                                                                              [2024-12-14 02:32:51,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:51,650][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 0.7063607573509216, acc: 0.8095238208770752)
[2024-12-14 02:32:51,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:52,044][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 0.6112361550331116, acc: 0.8181818127632141)
[2024-12-14 02:32:52,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:52,400][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 1.640982747077942, acc: 0.5076923370361328)
                     [2024-12-14 02:32:52,490][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:32:52,723][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 0.8897960782051086, acc: 0.8666666746139526)
                     [2024-12-14 02:32:52,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:53,073][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 0.8117266297340393, acc: 0.7586206793785095)
                                                                               [2024-12-14 02:32:53,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:53,410][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 1.4808435440063477, acc: 0.5490196347236633)
                                                                               [2024-12-14 02:32:53,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:53,774][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 1.0092871189117432, acc: 0.6896551847457886)
                                                                               [2024-12-14 02:32:53,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:54,153][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.487370103597641, acc: 0.9473684430122375)
 [2024-12-14 02:32:54,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:54,545][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 0.6964024901390076, acc: 0.7368420958518982)
                                                                               [2024-12-14 02:32:54,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:54,919][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 1.4689542055130005, acc: 0.6160714030265808)
                                                                            [2024-12-14 02:32:55,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:55,361][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 1.4186906814575195, acc: 0.5955055952072144)
] - modality encoder
[2024-12-14 02:32:55,193][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 0.8875234127044678, acc: 0.7272727489471436)
[2024-12-14 02:32:55,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:55,546][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 0.7042368650436401, acc: 0.8484848737716675)
[2024-12-14 02:32:55,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:55,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:55,876][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.4671608507633209, acc: 0.9032257795333862)
[2024-12-14 02:32:55,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:55,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:56,248][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 0.5778775811195374, acc: 0.8148148059844971)
[2024-12-14 02:32:56,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:56,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:56,620][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.524669349193573, acc: 0.800000011920929)
[2024-12-14 02:32:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:56,931][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.8045, device='cuda:0') eval_epoch_loss=tensor(1.7586, device='cuda:0') eval_epoch_acc=tensor(0.5701, device='cuda:0')
[2024-12-14 02:32:56,933][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:32:56,933][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:32:56,967][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.5410028696060181, acc: 0.8611111044883728)
[2024-12-14 02:32:57,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:57,239][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_5_step_278_loss_1.75862717628479/model.pt
[2024-12-14 02:32:57,247][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:32:57,286][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.574164867401123, acc: 0.8888888955116272)
[2024-12-14 02:32:57,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:57,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:57,600][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.24740831553936005, acc: 0.9230769276618958)
[2024-12-14 02:32:57,632][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 1.356501817703247, acc: 0.6170212626457214)
[2024-12-14 02:32:57,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:57,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:57,907][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 0.9549420475959778, acc: 0.7413793206214905)
[2024-12-14 02:32:57,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:58,032][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 1.1974129676818848, acc: 0.6458333134651184)
[2024-12-14 02:32:58,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:58,264][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.35956868529319763, acc: 0.8928571343421936)
[2024-12-14 02:32:58,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:58,407][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 1.0075405836105347, acc: 0.7727272510528564)
[2024-12-14 02:32:58,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:58,601][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.45222488045692444, acc: 0.8999999761581421)
[2024-12-14 02:32:58,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:58,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:59,348][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 1.6450974941253662, acc: 0.5315315127372742)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:32:59,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:32:59,794][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 1.3251045942306519, acc: 0.6338028311729431)
                                                                                                                                                                                                                       [2024-12-14 02:32:59,868][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:33:00,165][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.12743143737316132, acc: 0.8999999761581421)
                                                                            [2024-12-14 02:33:00,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:00,536][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.34470102190971375, acc: 0.8999999761581421)
                                                                                                                                                                                                                                                                                        [2024-12-14 02:33:00,642][slam_llm.models.slam_model][INFO] - modality encoder
                                                [2024-12-14 02:33:00,870][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.6188122630119324, acc: 0.8846153616905212)
                                                                                                                                                            [2024-12-14 02:33:02,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:03,570][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.7962687015533447, acc: 0.5571428537368774)
eted (loss: 2.1015312671661377, acc: 0.36000001430511475)
[2024-12-14 02:33:01,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:01,332][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.10390669852495193, acc: 1.0)
[2024-12-14 02:33:01,343][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 1.6905452013015747, acc: 0.5604395866394043)
[2024-12-14 02:33:01,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:01,715][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 2.104785919189453, acc: 0.44720497727394104)
[2024-12-14 02:33:01,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:02,131][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 2.2510733604431152, acc: 0.4175257682800293)
[2024-12-14 02:33:02,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:02,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:02,482][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.6135551929473877, acc: 0.7727272510528564)
[2024-12-14 02:33:02,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:02,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:02,846][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 1.662724256515503, acc: 0.523809552192688)
[2024-12-14 02:33:02,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:03,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:03,248][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 1.0654189586639404, acc: 0.7241379022598267)
[2024-12-14 02:33:03,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:03,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:03,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:03,718][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 0.9791006445884705, acc: 0.7636363506317139)
[2024-12-14 02:33:03,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:04,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:04,268][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.5570966005325317, acc: 0.6030927896499634)
[2024-12-14 02:33:04,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:04,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:04,558][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 1.71132230758667, acc: 0.48275861144065857)
[2024-12-14 02:33:04,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:04,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:04,970][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 0.9836848378181458, acc: 0.8148148059844971)
[2024-12-14 02:33:05,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:05,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:05,322][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 1.2642160654067993, acc: 0.6842105388641357)
[2024-12-14 02:33:05,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:05,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:05,712][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 1.0913094282150269, acc: 0.6964285969734192)
[2024-12-14 02:33:05,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:05,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:06,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:06,095][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.9055628776550293, acc: 0.75)
[2024-12-14 02:33:06,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:06,492][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 1.2003642320632935, acc: 0.6603773832321167)
[2024-12-14 02:33:06,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:06,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:06,847][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.7879832983016968, acc: 0.7547169923782349)
[2024-12-14 02:33:06,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:06,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:07,127][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.6666984558105469, acc: 0.8529411554336548)
[2024-12-14 02:33:07,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:07,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:07,450][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 1.1039280891418457, acc: 0.65625)
[2024-12-14 02:33:07,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:07,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:07,818][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 1.0134038925170898, acc: 0.6721311211585999)
[2024-12-14 02:33:07,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:08,217][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 1.9330817461013794, acc: 0.47457626461982727)
                                                                                                                                                             [2024-12-14 02:33:08,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:08,558][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 1.74966561794281, acc: 0.5223880410194397)
                                                                                  [2024-12-14 02:33:08,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:08,974][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 1.7734591960906982, acc: 0.5036496520042419)
                                                                              [2024-12-14 02:33:09,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:09,534][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 1.7181591987609863, acc: 0.5199999809265137)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:33:09,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:09,861][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 1.2985974550247192, acc: 0.5925925970077515)
                                                                        [2024-12-14 02:33:09,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:10,239][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 1.2926682233810425, acc: 0.557692289352417)
                                                                               [2024-12-14 02:33:10,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:10,603][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 0.9838792681694031, acc: 0.5714285969734192)
                                                                 [2024-12-14 02:33:10,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:10,981][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 2.0558292865753174, acc: 0.39344263076782227)
                                                                 [2024-12-14 02:33:11,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:11,302][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 1.2187353372573853, acc: 0.6610169410705566)
                                                                                                                                                              [2024-12-14 02:33:11,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:11,705][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 1.6064112186431885, acc: 0.604651153087616)
                                                                                [2024-12-14 02:33:11,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:12,091][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 1.355159878730774, acc: 0.6818181872367859)
                                                                                [2024-12-14 02:33:12,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:12,448][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.6880632638931274, acc: 0.5849056839942932)
                                                                              [2024-12-14 02:33:12,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:12,832][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 1.059294581413269, acc: 0.7272727489471436)
                                                                                [2024-12-14 02:33:12,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:13,210][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.6663033366203308, acc: 0.800000011920929)
                                                                                [2024-12-14 02:33:13,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:13,607][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.5358720421791077, acc: 0.8999999761581421)
                                                                              [2024-12-14 02:33:13,715][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:33:13,978][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.29908937215805054, acc: 0.8636363744735718)
                    [2024-12-14 02:33:14,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:14,393][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 1.1965196132659912, acc: 0.7076923251152039)
                                                                               [2024-12-14 02:33:14,499][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:33:14,790][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 1.3036837577819824, acc: 0.65625)
                                [2024-12-14 02:33:14,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:15,198][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.7484772801399231, acc: 0.84375)
                                                                                                                                                                                                                                   [2024-12-14 02:33:15,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:15,563][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.9619417190551758, acc: 0.6363636255264282)
                                                                                [2024-12-14 02:33:15,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:15,921][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.448393315076828, acc: 0.875)
                                                                                                                                                                            [2024-12-14 02:33:16,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:16,282][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.5036290884017944, acc: 0.8709677457809448)
[2024-12-14 02:33:16,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:16,628][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.11174692958593369, acc: 0.95652174949646)
                                                                   [2024-12-14 02:33:16,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:17,020][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 1.009722113609314, acc: 0.6666666865348816)
                                                                                [2024-12-14 02:33:17,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:17,419][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 1.0766801834106445, acc: 0.6829268336296082)
                                                                                                                                                              [2024-12-14 02:33:17,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:17,801][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.5137544274330139, acc: 0.8857142925262451)
                                                                    [2024-12-14 02:33:17,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:18,142][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.6651427149772644, acc: 0.7368420958518982)
                                                                               [2024-12-14 02:33:18,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:18,486][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.530541718006134, acc: 0.9032257795333862)
                                                                                [2024-12-14 02:33:18,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:18,779][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.29713231325149536, acc: 0.800000011920929)
[2024-12-14 02:33:18,868][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:33:19,122][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.4480808675289154, acc: 0.8787878751754761)
[2024-12-14 02:33:19,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:19,387][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.568548858165741, acc: 0.800000011920929)
[2024-12-14 02:33:19,475][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                 [2024-12-14 02:33:19,749][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 1.0059140920639038, acc: 0.6857143044471741)
[2024-12-14 02:33:19,885][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 02:33:20,143][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 1.9817466735839844, acc: 0.43795621395111084)
                                                                               [2024-12-14 02:33:20,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:20,514][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 1.4496177434921265, acc: 0.6068965792655945)
                                                                                                                                                              [2024-12-14 02:33:20,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:20,871][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 2.194499969482422, acc: 0.4214285612106323)
 [2024-12-14 02:33:20,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:21,196][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 1.7797907590866089, acc: 0.4900662302970886)
[2024-12-14 02:33:21,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:21,509][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 1.513384461402893, acc: 0.5811966061592102)
[2024-12-14 02:33:21,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:21,860][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.29232683777809143, acc: 0.9200000166893005)
[2024-12-14 02:33:21,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:22,239][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.44136565923690796, acc: 0.7692307829856873)
                    [2024-12-14 02:33:22,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:22,590][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.36908552050590515, acc: 0.8846153616905212)
                                                                                                                                                             [2024-12-14 02:33:22,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:22,964][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 1.0535705089569092, acc: 0.692307710647583)
 [2024-12-14 02:33:23,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:23,367][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 1.1590982675552368, acc: 0.6111111044883728)
                                                                               [2024-12-14 02:33:23,489][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:33:23,777][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 1.0526615381240845, acc: 0.7142857313156128)
                                                                                                                                                                                                                                             [2024-12-14 02:33:24,513][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:33:24,887][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:33:25,244][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:33:25,624][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:33:25,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:26,286][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:33:26,583][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:33:26,948][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:33:27,430][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:33:27,711][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:33:28,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:27,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:27,980][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.9209976196289062, acc: 0.7560975551605225)
[2024-12-14 02:33:28,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:28,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:28,369][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 1.2520415782928467, acc: 0.6222222447395325)
[2024-12-14 02:33:28,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:28,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:28,732][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 1.4411174058914185, acc: 0.6447368264198303)
[2024-12-14 02:33:28,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:28,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:29,084][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 1.164845585823059, acc: 0.6097561120986938)
[2024-12-14 02:33:29,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:29,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:29,397][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 1.0253697633743286, acc: 0.6666666865348816)
[2024-12-14 02:33:29,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:29,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:29,697][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.13123643398284912, acc: 0.9583333134651184)
[2024-12-14 02:33:29,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:29,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:30,014][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.11285317689180374, acc: 1.0)
[2024-12-14 02:33:30,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:30,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:30,373][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.5156023502349854, acc: 0.8214285969734192)
[2024-12-14 02:33:30,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:30,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:30,703][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.6597297191619873, acc: 0.8125)
[2024-12-14 02:33:30,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:31,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:31,300][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 1.6468428373336792, acc: 0.5454545617103577)
[2024-12-14 02:33:31,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:31,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:31,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:32,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:32,145][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 1.2119836807250977, acc: 0.650943398475647)
[2024-12-14 02:33:32,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:32,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:32,488][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 1.433478593826294, acc: 0.6111111044883728)
[2024-12-14 02:33:32,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:32,909][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.1395963430404663, acc: 0.6964285969734192)
[2024-12-14 02:33:32,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:33,065][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.0765, device='cuda:0') eval_epoch_loss=tensor(2.0890, device='cuda:0') eval_epoch_acc=tensor(0.5372, device='cuda:0')
[2024-12-14 02:33:33,066][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:33:33,067][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:33:33,122][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.8995975255966187, acc: 0.7428571581840515)
[2024-12-14 02:33:33,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:33,392][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_5_step_421_loss_2.0889525413513184/model.pt
[2024-12-14 02:33:33,396][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:33:33,456][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.29844000935554504, acc: 0.8799999952316284)
[2024-12-14 02:33:33,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:33,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:33,738][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.6838762760162354, acc: 0.7666666507720947)
[2024-12-14 02:33:33,825][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.1207725778222084, acc: 1.0)
[2024-12-14 02:33:33,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:33,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:34,096][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.49787747859954834, acc: 0.875)
[2024-12-14 02:33:34,124][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 1.1440216302871704, acc: 0.6666666865348816)
[2024-12-14 02:33:34,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:34,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:34,462][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.650714635848999, acc: 0.75)
[2024-12-14 02:33:34,516][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 1.3251514434814453, acc: 0.6105263233184814)
[2024-12-14 02:33:34,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:34,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:34,828][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.5163723826408386, acc: 0.7777777910232544)
[2024-12-14 02:33:34,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:35,100][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 1.4787523746490479, acc: 0.598802387714386)
[2024-12-14 02:33:35,235][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.6579652428627014, acc: 0.8484848737716675)
[2024-12-14 02:33:35,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:35,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:35,542][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 1.1778367757797241, acc: 0.6766917109489441)
[2024-12-14 02:33:35,562][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 0.9826698303222656, acc: 0.8260869383811951)
[2024-12-14 02:33:35,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:35,927][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 1.3590519428253174, acc: 0.6756756901741028)
[2024-12-14 02:33:36,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:36,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:36,221][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.5704512000083923, acc: 0.8148148059844971)
[2024-12-14 02:33:36,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:36,531][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.8084056973457336, acc: 0.739130437374115)
[2024-12-14 02:33:36,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:36,849][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 1.4714982509613037, acc: 0.6042780876159668)
[2024-12-14 02:33:36,987][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.20336586236953735, acc: 0.9259259104728699)
[2024-12-14 02:33:36,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:37,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:37,304][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.3028598725795746, acc: 0.9259259104728699)
[2024-12-14 02:33:37,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:37,416][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 1.1409417390823364, acc: 0.7117117047309875)
[2024-12-14 02:33:37,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:37,586][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 1.098201036453247, acc: 0.782608687877655)
[2024-12-14 02:33:37,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:37,754][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.44655275344848633, acc: 0.8928571343421936)
[2024-12-14 02:33:37,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:37,932][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 1.2195031642913818, acc: 0.6944444179534912)
[2024-12-14 02:33:38,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:38,129][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.5522173643112183, acc: 0.8928571343421936)
[2024-12-14 02:33:38,214][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.4983161985874176, acc: 0.8399999737739563)
[2024-12-14 02:33:38,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:38,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:38,515][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 1.169912338256836, acc: 0.6666666865348816)
[2024-12-14 02:33:38,531][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 0.5309760570526123, acc: 0.84375)
[2024-12-14 02:33:38,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:38,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:38,868][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 1.050415277481079, acc: 0.6944444179534912)
[2024-12-14 02:33:38,904][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.49223068356513977, acc: 0.8888888955116272)
[2024-12-14 02:33:38,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:39,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:39,263][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 1.0163556337356567, acc: 0.7272727489471436)
[2024-12-14 02:33:39,304][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.5145053863525391, acc: 0.8684210777282715)
[2024-12-14 02:33:39,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:39,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:39,646][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.17722170054912567, acc: 0.9523809552192688)
[2024-12-14 02:33:39,679][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.0850970447063446, acc: 0.9545454382896423)
[2024-12-14 02:33:39,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:39,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:39,980][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 1.2699776887893677, acc: 0.6410256624221802)
[2024-12-14 02:33:40,052][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.31040072441101074, acc: 0.8500000238418579)
[2024-12-14 02:33:40,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:40,569][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.44915539026260376, acc: 0.9047619104385376)
[2024-12-14 02:33:40,463][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 1.6289031505584717, acc: 0.6212121248245239)
[2024-12-14 02:33:40,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:40,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:40,787][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 1.8229354619979858, acc: 0.5)
[2024-12-14 02:33:40,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:41,144][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 2.136723756790161, acc: 0.40776699781417847)
[2024-12-14 02:33:41,157][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 2.1434977054595947, acc: 0.40799999237060547)
[2024-12-14 02:33:41,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:41,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:41,575][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 1.9801905155181885, acc: 0.47580644488334656)
[2024-12-14 02:33:41,662][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 1.8363516330718994, acc: 0.5367646813392639)
[2024-12-14 02:33:41,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:41,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:42,086][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 2.054760456085205, acc: 0.46666666865348816)
[2024-12-14 02:33:42,227][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 1.858681559562683, acc: 0.4726368188858032)
[2024-12-14 02:33:42,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:42,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:42,498][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 2.059170961380005, acc: 0.4236111044883728)
[2024-12-14 02:33:42,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:42,641][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 1.4429724216461182, acc: 0.6037735939025879)
[2024-12-14 02:33:42,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:42,918][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 1.2132576704025269, acc: 0.6976743936538696)
[2024-12-14 02:33:43,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:43,051][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 0.8651561737060547, acc: 0.7954545617103577)
[2024-12-14 02:33:43,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:43,323][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.5147971510887146, acc: 0.7916666865348816)
[2024-12-14 02:33:43,441][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 0.6656434535980225, acc: 0.8260869383811951)
[2024-12-14 02:33:43,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:43,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:43,713][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 0.937946081161499, acc: 0.7441860437393188)
[2024-12-14 02:33:43,837][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 0.6848624348640442, acc: 0.8846153616905212)
[2024-12-14 02:33:43,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:43,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:44,114][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 0.8589372038841248, acc: 0.8399999737739563)
[2024-12-14 02:33:44,154][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.6290544271469116, acc: 0.7857142686843872)
[2024-12-14 02:33:44,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:44,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:44,446][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 1.3537734746932983, acc: 0.6716417670249939)
[2024-12-14 02:33:44,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:44,773][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:33:45,118][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:33:45,468][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:33:45,912][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:33:46,340][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:33:46,619][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                   [2024-12-14 02:33:47,047][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:33:47,412][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:33:47,755][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:33:48,136][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:33:48,582][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:33:48,988][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:33:49,330][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:33:49,588][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:33:50,006][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:33:50,352][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:33:50,665][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:33:50,941][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:33:51,379][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.5337616205215454, acc: 0.6310679316520691)
[2024-12-14 02:33:51,430][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 0.5375064015388489, acc: 0.8500000238418579)
[2024-12-14 02:33:51,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:51,752][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 1.2394747734069824, acc: 0.642276406288147)
[2024-12-14 02:33:51,812][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.07498466968536377, acc: 1.0)
[2024-12-14 02:33:51,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:52,150][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.5361292958259583, acc: 0.875)
[2024-12-14 02:33:52,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:52,475][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.7975637316703796, acc: 0.8214285969734192)
[2024-12-14 02:33:52,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:52,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:52,886][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 1.917667031288147, acc: 0.44117647409439087)
[2024-12-14 02:33:52,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:52,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:53,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:53,291][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 2.041018009185791, acc: 0.4628821015357971)
[2024-12-14 02:33:53,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:53,648][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 1.7738538980484009, acc: 0.5625)
[2024-12-14 02:33:53,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:53,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:53,965][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 1.9415676593780518, acc: 0.453987717628479)
[2024-12-14 02:33:54,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:54,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:54,342][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 1.9222633838653564, acc: 0.49640288949012756)
[2024-12-14 02:33:54,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:54,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:54,707][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 2.1001038551330566, acc: 0.4170854389667511)
[2024-12-14 02:33:54,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:54,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:55,022][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.7874636054039001, acc: 0.7777777910232544)
[2024-12-14 02:33:55,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:55,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:55,371][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.6700814366340637, acc: 0.8181818127632141)
                                                                                                                                  [2024-12-14 02:33:55,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:55,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:55,717][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.435560941696167, acc: 0.8888888955116272)
[2024-12-14 02:33:55,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:56,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:56,094][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 0.5960119366645813, acc: 0.8500000238418579)
[2024-12-14 02:33:56,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:56,396][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.43520984053611755, acc: 0.8999999761581421)
[2024-12-14 02:33:56,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:56,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:56,757][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 0.9902023077011108, acc: 0.6551724076271057)
[2024-12-14 02:33:56,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:56,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:57,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:57,117][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.5334404110908508, acc: 0.8064516186714172)
[2024-12-14 02:33:57,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:57,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:57,464][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.42547330260276794, acc: 0.7894737124443054)
[2024-12-14 02:33:57,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:57,738][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 0.98082435131073, acc: 0.6666666865348816)
[2024-12-14 02:33:57,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:57,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:58,048][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 0.9204919934272766, acc: 0.761904776096344)
[2024-12-14 02:33:58,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:58,401][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 0.7846550345420837, acc: 0.7727272510528564)
[2024-12-14 02:33:58,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:58,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:58,715][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 1.5435917377471924, acc: 0.6000000238418579)
[2024-12-14 02:33:58,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:58,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:59,062][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 0.7501937747001648, acc: 0.8333333134651184)
[2024-12-14 02:33:59,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:59,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:59,436][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 0.5461471676826477, acc: 0.8620689511299133)
                                                                                                                                            [2024-12-14 02:33:59,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:59,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:59,777][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 1.4207812547683716, acc: 0.6078431606292725)
[2024-12-14 02:33:59,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:33:59,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:00,121][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 1.0406405925750732, acc: 0.6551724076271057)
[2024-12-14 02:34:00,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:00,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:00,443][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.3673822581768036, acc: 0.9473684430122375)
[2024-12-14 02:34:00,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:00,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:00,745][slam_llm.models.slam_model][IN[2024-12-14 02:34:00,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:01,121][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 0.9800453186035156, acc: 0.7105262875556946)
                         [2024-12-14 02:34:01,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:01,524][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 1.3628166913986206, acc: 0.5945945978164673)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:34:01,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:01,923][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.7972973585128784, acc: 0.6785714030265808)
  [2024-12-14 02:34:02,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:02,263][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 1.3311471939086914, acc: 0.5714285969734192)
[2024-12-14 02:34:02,340][slam_llm.models.slam_model][INFO] - modality encoder
   [2024-12-14 02:34:02,602][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.5504711866378784, acc: 0.8333333134651184)
                       [2024-12-14 02:34:02,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:03,004][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.08082105964422226, acc: 1.0)
                                                                                               [2024-12-14 02:34:03,102][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:34:03,347][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.15975068509578705, acc: 1.0)
                                     [2024-12-14 02:34:03,438][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:34:03,739][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.6239796876907349, acc: 0.7777777910232544)
[2024-12-14 02:34:03,837][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                [2024-12-14 02:34:04,091][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 0.940153956413269, acc: 0.7179487347602844)
                                                                                                                                                               [2024-12-14 02:34:04,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:04,420][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.765977680683136, acc: 0.7878788113594055)
[2024-12-14 02:34:04,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:04,832][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 1.1681947708129883, acc: 0.6304348111152649)
                                                                                                                                                                 [2024-12-14 02:34:04,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:05,180][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 1.40513277053833, acc: 0.5686274766921997)
[2024-12-14 02:34:05,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:05,558][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 1.3028345108032227, acc: 0.6122449040412903)
                         [2024-12-14 02:34:05,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:05,935][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.3245311975479126, acc: 0.8947368264198303)
 [2024-12-14 02:34:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:06,327][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.6521684587][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.09145570546388626, acc: 1.0)
[2024-12-14 02:34:06,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:06,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:06,517][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.4246025085449219, acc: 0.8333333134651184)
[2024-12-14 02:34:06,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:06,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:06,888][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.7390202283859253, acc: 0.807692289352417)
[2024-12-14 02:34:07,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:07,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:07,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:07,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:08,020][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                   [2024-12-14 02:34:08,268][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:34:08,655][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:34:09,003][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                            [2024-12-14 02:34:09,312][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.8512178659439087, acc: 0.5142857432365417)
[2024-12-14 02:34:09,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:09,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:09,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:09,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:10,076][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 1.6181341409683228, acc: 0.5634920597076416)
[2024-12-14 02:34:10,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:10,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:10,438][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.723011314868927, acc: 0.8214285969734192)
[2024-12-14 02:34:10,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:10,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:10,838][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 1.1907609701156616, acc: 0.6499999761581421)
[2024-12-14 02:34:11,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:11,094][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:34:11,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:11,529][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 1.2410354614257812, acc: 0.7222222089767456)
[2024-12-14 02:34:11,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:11,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:11,851][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.2854757308959961, acc: 0.9230769276618958)
[2024-12-14 02:34:11,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:12,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:12,120][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 1.0098589658737183, acc: 0.774193525314331)
[2024-12-14 02:34:12,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:12,530][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 0.5681170225143433, acc: 0.8518518805503845)
                                                                  [2024-12-14 02:34:12,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:12,859][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.32746991515159607, acc: 0.9130434989929199)
                                                                               [2024-12-14 02:34:12,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:13,247][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 1.7658026218414307, acc: 0.4957983195781708)
[2024-12-14 02:34:13,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:13,637][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 1.1368725299835205, acc: 0.7377049326896667)
[2024-12-14 02:34:13,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:13,997][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 1.5155695676803589, acc: 0.5873016119003296)
                      [2024-12-14 02:34:14,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:14,380][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 1.6002836227416992, acc: 0.5254237055778503)
[2024-12-14 02:34:14,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:14,830][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 1.1033722162246704, acc: 0.6896551847457886)
                                                                                                                                                                 [2024-12-14 02:34:14,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:15,163][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.18484367430210114, acc: 0.9523809552192688)
[2024-12-14 02:34:15,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:15,463][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.9125878810882568, acc: 0.7307692170143127)
[2024-12-14 02:34:15,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:15,802][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 1.622846007347107, acc: 0.5540540814399719)
[2024-12-14 02:34:15,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:16,192][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 1.4966330528259277, acc: 0.6153846383094788)
                                                                                 [2024-12-14 02:34:16,313][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:34:16,607][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 1.6791337728500366, acc: 0.5656565427780151)
[2024-12-14 02:34:16,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:17,033][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 1.398529052734375, acc: 0.6391752362251282)
                         [2024-12-14 02:34:17,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:17,437][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 1.7230280637741089, acc: 0.5147058963775635)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:34:17,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:17,793][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.422934889793396, acc: 0.9230769276618958)
)
[2024-12-14 02:34:17,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:17,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:18,061][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.6979628801345825, acc: 0.5471698045730591)
[2024-12-14 02:34:18,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:18,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:18,411][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 0.9475748538970947, acc: 0.7727272510528564)
[2024-12-14 02:34:18,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:18,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:18,781][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.7562779784202576, acc: 0.800000011920929)
[2024-12-14 02:34:18,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:19,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:19,098][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.6279157400131226, acc: 0.8500000238418579)
[2024-12-14 02:34:19,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:19,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:19,472][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.3250143826007843, acc: 0.9545454382896423)
[2024-12-14 02:34:19,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:19,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:19,918][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 1.1824461221694946, acc: 0.7230769395828247)
[2024-12-14 02:34:20,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:20,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:20,278][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 1.222975730895996, acc: 0.6875)
[2024-12-14 02:34:20,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:20,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:20,710][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.7138206958770752, acc: 0.84375)
[2024-12-14 02:34:20,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:20,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:21,066][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.9676710963249207, acc: 0.7575757503509521)
[2024-12-14 02:34:21,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:22,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:21,474][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.6253519058227539, acc: 0.875)
[2024-12-14 02:34:21,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:21,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:21,843][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.41768068075180054, acc: 0.8709677457809448)
[2024-12-14 02:34:21,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:21,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:22,218][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.12067704647779465, acc: 0.95652174949646)
[2024-12-14 02:34:22,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:22,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:22,522][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.7509610652923584, acc: 0.800000011920929)
[2024-12-14 02:34:22,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:22,883][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 0.8664838075637817, acc: 0.7317073345184326)
[2024-12-14 02:34:22,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:23,050][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.0955, device='cuda:0') eval_epoch_loss=tensor(2.0913, device='cuda:0') eval_epoch_acc=tensor(0.5403, device='cuda:0')
[2024-12-14 02:34:23,052][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:34:23,052][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:34:23,261][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.45422443747520447, acc: 0.8857142925262451)
[2024-12-14 02:34:23,292][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_5_step_421_loss_2.0913076400756836/model.pt
[2024-12-14 02:34:23,297][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:34:23,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:23,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:23,645][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.6576352715492249, acc: 0.7631579041481018)
[2024-12-14 02:34:23,700][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.725547194480896, acc: 0.7333333492279053)
[2024-12-14 02:34:23,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:23,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:23,980][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.5682860612869263, acc: 0.8709677457809448)
[2024-12-14 02:34:24,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:24,068][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.5400500297546387, acc: 0.8125)
[2024-12-14 02:34:24,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:24,299][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.1595028042793274, acc: 0.8799999952316284)
[2024-12-14 02:34:24,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:24,396][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.8127425909042358, acc: 0.7777777910232544)
[2024-12-14 02:34:24,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:24,656][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.3981790244579315, acc: 0.8787878751754761)
[2024-12-14 02:34:24,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:24,776][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.7973463535308838, acc: 0.7777777910232544)
[2024-12-14 02:34:24,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:25,048][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.603994607925415, acc: 0.800000011920929)
[2024-12-14 02:34:25,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:25,180][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.9501994848251343, acc: 0.7575757503509521)
[2024-12-14 02:34:25,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:25,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:26,081][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 1.7697018384933472, acc: 0.5511363744735718)
pleted (loss: 1.520462989807129, acc: 0.695652186870575)
[2024-12-14 02:34:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:25,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:25,772][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 1.8584526777267456, acc: 0.49635037779808044)
[2024-12-14 02:34:25,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:25,884][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 1.3686681985855103, acc: 0.6756756901741028)
[2024-12-14 02:34:26,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:26,082][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 1.4602829217910767, acc: 0.6137930750846863)
[2024-12-14 02:34:26,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:26,280][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.8589189052581787, acc: 0.7407407164573669)
[2024-12-14 02:34:26,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:26,411][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 2.1858747005462646, acc: 0.4214285612106323)
[2024-12-14 02:34:26,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:26,618][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.557319164276123, acc: 0.8260869383811951)
[2024-12-14 02:34:26,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:26,826][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 2.004150390625, acc: 0.45695364475250244)
[2024-12-14 02:34:26,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:26,952][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.13726796209812164, acc: 0.9629629850387573)
[2024-12-14 02:34:27,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:27,168][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 1.5171327590942383, acc: 0.5555555820465088)
[2024-12-14 02:34:27,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:27,324][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.12310037016868591, acc: 0.9629629850387573)
[2024-12-14 02:34:27,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:27,478][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.16608352959156036, acc: 0.9599999785423279)
[2024-12-14 02:34:27,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:27,689][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.8478806614875793, acc: 0.782608687877655)
[2024-12-14 02:34:27,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:27,854][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.570968747138977, acc: 0.7692307829856873)
[2024-12-14 02:34:27,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:28,062][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 1.2059242725372314, acc: 0.6666666865348816)
[2024-12-14 02:34:28,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:28,248][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.3264673948287964, acc: 0.8846153616905212)
[2024-12-14 02:34:28,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:28,376][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.6777036190032959, acc: 0.7599999904632568)
[2024-12-14 02:34:28,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:28,601][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 0.879024088382721, acc: 0.8205128312110901)
[2024-12-14 02:34:28,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:28,780][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.9121158123016357, acc: 0.6969696879386902)
[2024-12-14 02:34:28,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:29,005][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 1.1956664323806763, acc: 0.6222222447395325)
[2024-12-14 02:34:29,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:29,152][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 1.3354626893997192, acc: 0.6944444179534912)
[2024-12-14 02:34:29,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:29,330][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 1.0859425067901611, acc: 0.6753[2024-12-14 02:34:29,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:29,901][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 1.477674961090088, acc: 0.6000000238418579)
                                                                                                                                           [2024-12-14 02:34:30,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:30,263][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.12158726900815964, acc: 0.9599999785423279)
                                                                               [2024-12-14 02:34:30,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:30,583][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.818064272403717, acc: 0.6944444179534912)
[2024-12-14 02:34:30,684][slam_llm.models.slam_model][INFO] - modality encoder
  [2024-12-14 02:34:30,933][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.5560854077339172, acc: 0.8181818127632141)
[2024-12-14 02:34:31,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:31,243][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 1.7001076936721802, acc: 0.5588235259056091)
[2024-12-14 02:34:31,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:31,596][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 1.6610397100448608, acc: 0.4920634925365448)
[2024-12-14 02:34:31,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:32,003][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 1.97535240650177, acc: 0.4512820541858673)
                                                                                 [2024-12-14 02:34:32,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:32,349][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 1.5489157438278198, acc: 0.6122449040412903)
[2024-12-14 02:34:32,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:32,652][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 2.1145787239074707, acc: 0.3507462739944458)
[2024-12-14 02:34:32,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:33,033][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 2.0357108116149902, acc: 0.47445255517959595)
                       [2024-12-14 02:34:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:33,401][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.29982027411460876, acc: 0.9047619104385376)
                                                                             [2024-12-14 02:34:33,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:33,773][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.22755515575408936, acc: 0.9583333134651184)
                                                                              [2024-12-14 02:34:33,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:34,134][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.6407395601272583, acc: 0.8181818127632141)
                                                                               [2024-12-14 02:34:34,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:34,489][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.25075724720954895, acc: 0.9615384340286255)
                                                                               [2024-12-14 02:34:34,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:34,879][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 1.0475564002990723, acc: 0.75)
                                                                                              [2024-12-14 02:34:34,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:35,258][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 1.3343709707260132, acc: 0.6346153616905212)
                                                                               [2024-12-14 02:34:35,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:35,648][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.6324651837348938, acc: 0.8125)
                                                                                          [2024-12-14 02:34:35,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:36,041][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 1.5339778661727905, acc: 0.49275362491607666)
                                                                                                                                                             [2024-12-14 02:34:36,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:36,430][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 0.9290066361427307, acc: 0.7599999904632568)
[2024-12-14 02:34:36,524][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:34:36,753][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 0.5877732038497925, acc: 0.739130437374115)
[2024-12-14 02:34:36,870][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                 [2024-12-14 02:34:37,222][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 1.4527924060821533, acc: 0.5799999833106995)
                                                                                                                                                                [2024-12-14 02:34:37,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:37,609][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 1.3108097314834595, acc: 0.6601941585540771)
                                                                                [2024-12-14 02:34:37,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:38,745][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 1.680350422859192, acc: 0.5582524538040161)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:34:38,953][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:34:39,570][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.7486844062805176, acc: 0.5053763389587402)
[2024-12-14 02:34:39,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:40,381][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 1.5934332609176636, acc: 0.5991379022598267)
463/574 completed (loss: 0.8420146703720093, acc: 0.692307710647583)
[2024-12-14 02:34:39,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:39,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:40,079][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 0.8885563015937805, acc: 0.717391312122345)
[2024-12-14 02:34:40,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:40,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:40,385][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 1.5573418140411377, acc: 0.488095223903656)
[2024-12-14 02:34:40,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:40,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:40,697][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 1.5443732738494873, acc: 0.5421686768531799)
[2024-12-14 02:34:40,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:40,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:41,034][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 1.2193818092346191, acc: 0.6666666865348816)
[2024-12-14 02:34:41,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:41,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:41,387][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 1.4374583959579468, acc: 0.6116504669189453)
[2024-12-14 02:34:41,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:41,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:41,782][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 1.2682552337646484, acc: 0.642276406288147)
[2024-12-14 02:34:41,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:41,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:42,099][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.6237103343009949, acc: 0.7916666865348816)
[2024-12-14 02:34:42,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:42,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:42,401][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 1.158370852470398, acc: 0.6785714030265808)
[2024-12-14 02:34:42,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:42,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:42,836][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 1.85580313205719, acc: 0.4803921580314636)
[2024-12-14 02:34:42,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:42,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:43,189][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 2.1107380390167236, acc: 0.41484716534614563)
[2024-12-14 02:34:43,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:43,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:43,611][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 1.812764048576355, acc: 0.5208333134651184)
[2024-12-14 02:34:43,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:43,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:44,037][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 1.897828221321106, acc: 0.48466256260871887)
[2024-12-14 02:34:44,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:44,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:44,436][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 1.8916711807250977, acc: 0.46043166518211365)
[2024-12-14 02:34:44,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:44,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:44,822][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 2.0994954109191895, acc: 0.43216079473495483)
[2024-12-14 02:34:44,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:44,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:45,124][slam_llm.models.slam_model][INFO] - modality encoder
                                           [2024-12-14 02:34:45,387][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.35955411195755005, acc: 0.9130434989929199)
[2024-12-14 02:34:45,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:45,782][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.7881031036376953, acc: 0.7727272510528564)
                                                                                                   [2024-12-14 02:34:45,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:46,159][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 1.4377726316452026, acc: 0.5517241358757019)
                                                                               [2024-12-14 02:34:46,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:46,543][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.8700720071792603, acc: 0.7441860437393188)
                                                                               [2024-12-14 02:34:46,650][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:34:46,903][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 0.5872162580490112, acc: 0.8799999952316284)
[2024-12-14 02:34:47,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:47,245][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.16249142587184906, acc: 0.9411764740943909)
                    [2024-12-14 02:34:47,331][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:34:47,569][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.04975990578532219, acc: 1.0)
[2024-12-14 02:34:47,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:47,923][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.6539671421051025, acc: 0.7857142686843872)
                                                                                                                   [2024-12-14 02:34:48,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:48,331][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 1.3939136266708374, acc: 0.6461538672447205)
                                                                             [2024-12-14 02:34:48,441][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:34:48,735][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 1.3241362571716309, acc: 0.7017543911933899)
[2024-12-14 02:34:48,851][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 02:34:49,106][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 1.0521658658981323, acc: 0.6842105388641357)
[2024-12-14 02:34:49,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:49,458][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 1.1130942106246948, acc: 0.6666666865348816)
[2024-12-14 02:34:49,549][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:34:49,828][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 0.9430709481239319, acc: 0.7755101919174194)
[2024-12-14 02:34:49,908][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:34:50,111][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.06302550435066223, acc: 1.0)
[2024-12-14 02:34:50,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:50,414][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 1.2755316495895386, acc: 0.6349206566810608)
                                  [2024-12-14 02:34:50,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:50,817][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 1.526051640510559, acc: 0.6016260385513306)
 [2024-12-14 02:34:50,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:51,233][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 1.1624466180801392, acc: 0.6290322542190552)
                                                                                                                                                              [2024-12-14 02:34:51,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:52,135][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 1.886165738105774, acc: 0.46768060326576233)
                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:34:52,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:52,471][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 1.0919103622436523, acc: 0.7200000286102295)
                                                                               [2024-12-14 02:34:52,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:52,885][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 0.9415655136108398, acc: 0.7115384340286255)
                                                                                [2024-12-14 02:34:52,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:53,153][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.32219430804252625, acc: 0.875)
                                                                                                                                                                          [2024-12-14 02:34:53,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:53,515][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.3948217034339905, acc: 0.8421052694320679)
 [2024-12-14 02:34:53,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:53,875][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 1.792385220527649, acc: 0.47852760553359985)
                                                                               [2024-12-14 02:34:53,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:54,232][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.503101110458374, acc: 0.6041666865348816)
  [2024-12-14 02:34:54,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:54,614][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 1.6274583339691162, acc: 0.5666666626930237)
                                                                                                                                                              [2024-12-14 02:34:54,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:55,050][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 1.722808599472046, acc: 0.494047611951828)
                                                                                 [2024-12-14 02:34:55,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:55,445][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 1.5986592769622803, acc: 0.5384615659713745)
                                                                                                                                                             [2024-12-14 02:34:55,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:55,872][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 1.4854345321655273, acc: 0.5808823704719543)
                                                                               [2024-12-14 02:34:55,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:56,237][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.7158138751983643, acc: 0.8461538553237915)
[2024-12-14 02:34:56,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:56,615][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.29077526926994324, acc: 0.9130434989929199)
                                                                              [2024-12-14 02:34:56,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:56,991][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.5455027222633362, acc: 0.84375)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:34:57,794][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:34:58,144][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:34:58,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:58,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:59,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:34:59,648][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:34:59,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:00,265][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:35:00,558][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:35:00,950][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:35:01,369][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:35:01,761][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:02,111][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:35:02,433][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:35:02,796][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:03,161][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:03,517][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:35:03,879][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                   [2024-12-14 02:35:04,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:04,610][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:35:04,984][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.9784822463989258, acc: 0.4576271176338196)
[2024-12-14 02:35:04,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:04,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:05,213][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 1.7436670064926147, acc: 0.48507463932037354)
[2024-12-14 02:35:05,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:05,344][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 0.45843398571014404, acc: 0.8148148059844971)
[2024-12-14 02:35:05,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:05,629][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 1.810312032699585, acc: 0.525547444820404)
[2024-12-14 02:35:05,687][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.4638214111328125, acc: 0.8399999737739563)
[2024-12-14 02:35:05,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:05,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:06,012][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 1.0107840299606323, acc: 0.6756756901741028)
[2024-12-14 02:35:06,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:06,193][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 1.740290641784668, acc: 0.5)
[2024-12-14 02:35:06,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:06,363][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 1.1440227031707764, acc: 0.6315789222717285)
[2024-12-14 02:35:06,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:06,517][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 1.240472435951233, acc: 0.6851851940155029)
[2024-12-14 02:35:06,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:06,754][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 1.510650634765625, acc: 0.6216216087341309)
[2024-12-14 02:35:06,813][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 1.185595989227295, acc: 0.5961538553237915)
[2024-12-14 02:35:06,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:06,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:07,160][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.749328076839447, acc: 0.7142857313156128)
[2024-12-14 02:35:07,193][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 0.7488468885421753, acc: 0.7142857313156128)
[2024-12-14 02:35:07,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:07,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:07,566][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 2.1214146614074707, acc: 0.4262295067310333)
[2024-12-14 02:35:07,567][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 1.46630859375, acc: 0.5714285969734192)
[2024-12-14 02:35:07,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:07,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:07,898][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.8999158143997192, acc: 0.7333333492279053)
[2024-12-14 02:35:07,909][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 1.2410509586334229, acc: 0.6610169410705566)
[2024-12-14 02:35:07,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:08,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:08,260][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 1.5607422590255737, acc: 0.5813953280448914)
[2024-12-14 02:35:08,264][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.16185186803340912, acc: 0.9545454382896423)
[2024-12-14 02:35:08,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:08,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:08,599][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.2133173793554306, acc: 0.9615384340286255)
[2024-12-14 02:35:08,615][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 1.4091702699661255, acc: 0.5681818127632141)
[2024-12-14 02:35:08,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:08,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:08,924][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.48279890418052673, acc: 0.8518518805503845)
[2024-12-14 02:35:09,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:09,014][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.5782055854797363, acc: 0.6037735939025879)
[2024-12-14 02:35:09,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:09,283][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 0.9133103489875793, acc: 0.692307710647583)
[2024-12-14 02:35:09,384][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 1.0540411472320557, acc: 0.75)
[2024-12-14 02:35:09,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:09,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:09,710][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.6449713110923767, acc: 0.8181818127632141)
[2024-12-14 02:35:09,760][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.6504231095314026, acc: 0.800000011920929)
[2024-12-14 02:35:09,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:09,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:10,144][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 0.9875713586807251, acc: 0.717391312122345)
[2024-12-14 02:35:10,167][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.4624943733215332, acc: 0.949999988079071)
[2024-12-14 02:35:10,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:10,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:10,514][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.3104468882083893, acc: 0.9090909361839294)
[2024-12-14 02:35:10,534][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 1.1575474739074707, acc: 0.6666666865348816)
[2024-12-14 02:35:10,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:10,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:10,879][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 1.1796988248825073, acc: 0.6326530575752258)
[2024-12-14 02:35:10,909][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 1.2046103477478027, acc: 0.692307710647583)
[2024-12-14 02:35:10,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:11,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:11,192][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.406107634305954, acc: 0.8947368264198303)
[2024-12-14 02:35:11,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:11,288][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 1.154801845550537, acc: 0.640625)
[2024-12-14 02:35:11,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:11,568][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.6333795189857483, acc: 0.7916666865348816)
[2024-12-14 02:35:11,669][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.7862395644187927, acc: 0.8125)
[2024-12-14 02:35:11,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:11,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:11,930][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.952631413936615, acc: 0.7777777910232544)
[2024-12-14 02:35:11,970][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.9140899777412415, acc: 0.7272727489471436)
[2024-12-14 02:35:12,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:12,346][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:35:12,667][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:13,006][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:35:13,372][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:35:13,697][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:35:14,024][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:35:14,474][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:14,866][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:35:15,226][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:35:15,674][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                           [2024-12-14 02:35:16,008][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:16,393][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:35:16,748][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:35:17,004][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:35:17,328][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:17,661][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:35:17,934][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:35:18,241][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:35:18,568][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:35:19,071][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:35:19,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:19,445][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 1.0617012977600098, acc: 0.7435897588729858)
[2024-12-14 02:35:19,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:19,682][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 1.458996295928955, acc: 0.5593220591545105)
[2024-12-14 02:35:19,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:19,808][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 1.1972057819366455, acc: 0.6555555462837219)
[2024-12-14 02:35:19,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:20,051][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 1.1541401147842407, acc: 0.6206896305084229)
[2024-12-14 02:35:20,129][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 1.1156668663024902, acc: 0.6363636255264282)
[2024-12-14 02:35:20,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:20,371][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.24420370161533356, acc: 0.9047619104385376)
[2024-12-14 02:35:20,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:20,682][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.7980636954307556, acc: 0.7692307829856873)
[2024-12-14 02:35:20,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:20,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:21,071][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 1.7312158346176147, acc: 0.5405405163764954)
[2024-12-14 02:35:21,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:21,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:21,451][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 1.4484810829162598, acc: 0.5846154093742371)
[2024-12-14 02:35:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:21,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:21,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:21,905][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 1.6944984197616577, acc: 0.5959596037864685)
[2024-12-14 02:35:22,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:22,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:22,317][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 1.412596583366394, acc: 0.6082473993301392)
[2024-12-14 02:35:22,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:22,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:22,744][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 1.6743574142456055, acc: 0.5367646813392639)
[2024-12-14 02:35:22,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:22,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:23,088][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.45021945238113403, acc: 0.8846153616905212)
[2024-12-14 02:35:23,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:23,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:23,453][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.24661998450756073, acc: 0.9629629850387573)
[2024-12-14 02:35:23,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:23,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:23,815][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.6516677141189575, acc: 0.7142857313156128)
[2024-12-14 02:35:24,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:23,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:24,179][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.4395207464694977, acc: 0.8888888955116272)
[2024-12-14 02:35:24,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:24,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:24,603][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 0.8363422155380249, acc: 0.7017543911933899)
[2024-12-14 02:35:24,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:24,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:25,009][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 1.0283403396606445, acc: 0.7301587462425232)
[2024-12-14 02:35:25,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:25,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:25,359][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 1.495518684387207, acc: 0.5352112650871277)
[2024-12-14 02:35:25,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:25,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:25,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:25,817][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.894496202468872, acc: 0.5199999809265137)
[2024-12-14 02:35:25,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:26,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:26,150][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.765192985534668, acc: 0.8108108043670654)
[2024-12-14 02:35:26,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:26,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:26,560][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.13708990812301636, acc: 0.9615384340286255)
[2024-12-14 02:35:26,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:27,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:27,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:27,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:28,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:28,362][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:35:28,624][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:35:28,894][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:35:29,276][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:35:29,643][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 1.6293965578079224, acc: 0.5597269535064697)
[2024-12-14 02:35:29,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:29,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:30,028][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:35:30,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:30,360][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.5928583741188049, acc: 0.695652186870575)
[2024-12-14 02:35:30,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:30,706][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.5108842253684998, acc: 0.761904776096344)
[2024-12-14 02:35:30,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:31,088][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 0.9097865223884583, acc: 0.7307692170143127)
[2024-12-14 02:35:31,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:31,401][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 1.346472144126892, acc: 0.5806451439857483)
[2024-12-14 02:35:31,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:31,718][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 1.3361365795135498, acc: 0.6486486196517944)
[2024-12-14 02:35:31,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:32,277][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 1.6586271524429321, acc: 0.4912280738353729)
                                                                                                   [2024-12-14 02:35:32,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:32,643][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 1.5248619318008423, acc: 0.5820895433425903)
[2024-12-14 02:35:32,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:33,042][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 2.074211359024048, acc: 0.3979591727256775)
                                                                             [2024-12-14 02:35:33,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:33,486][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 2.015977621078491, acc: 0.457446813583374)
                                                                                 [2024-12-14 02:35:33,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:33,861][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 1.4471114873886108, acc: 0.6428571343421936)
                                                                              [2024-12-14 02:35:33,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:34,170][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 1.7084578275680542, acc: 0.5357142686843872)
                                                                [2024-12-14 02:35:34,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:34,516][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.7678555846214294, acc: 0.739130437374115)
                                                                                [2024-12-14 02:35:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:34,848][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 1.0161093473434448, acc: 0.6551724076271057)
[2024-12-14 02:35:34,929][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:35:35,221][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 1.5125856399536133, acc: 0.6521739363670349)
[2024-12-14 02:35:35,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:35,584][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 1.6224161386489868, acc: 0.5254237055778503)
                    [2024-12-14 02:35:35,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:35,968][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 1.8770798444747925, acc: 0.5087719559669495)
                                                                [2024-12-14 02:35:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:36,348][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.8242745995521545, acc: 0.6944444179534912)
[2024-12-14 02:35:36,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:36,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:36,459][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.5739172697067261, acc: 0.8787878751754761)
[2024-12-14 02:35:36,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:36,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:36,854][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 1.7542619705200195, acc: 0.5367646813392639)
[2024-12-14 02:35:36,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:37,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:37,203][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 1.5742170810699463, acc: 0.5555555820465088)
[2024-12-14 02:35:37,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:37,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:37,614][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 2.0299880504608154, acc: 0.44102564454078674)
[2024-12-14 02:35:37,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:37,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:37,900][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 1.5533603429794312, acc: 0.5714285969734192)
[2024-12-14 02:35:38,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:38,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:38,274][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 2.0992627143859863, acc: 0.4029850661754608)
[2024-12-14 02:35:38,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:38,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:38,665][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 2.0397543907165527, acc: 0.45255473256111145)
[2024-12-14 02:35:38,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:38,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:39,022][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.15918901562690735, acc: 0.9523809552192688)
[2024-12-14 02:35:39,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:39,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:39,367][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.22350718080997467, acc: 0.9583333134651184)
[2024-12-14 02:35:39,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:39,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:39,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:39,723][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.45375490188598633, acc: 0.8181818127632141)
[2024-12-14 02:35:39,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:40,070][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.1542782038450241, acc: 0.9615384340286255)
[2024-12-14 02:35:40,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:40,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:40,449][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 1.156126856803894, acc: 0.6730769276618958)
[2024-12-14 02:35:40,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:40,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:40,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:40,804][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 1.500706434249878, acc: 0.6153846383094788)
[2024-12-14 02:35:40,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:41,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:41,440][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.9420533776283264, acc: 0.7954545617103577)
                                                                 [2024-12-14 02:35:41,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:41,782][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 1.1053377389907837, acc: 0.6666666865348816)
                                                                             [2024-12-14 02:35:41,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:42,100][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 1.0984742641448975, acc: 0.6896551847457886)
                                                                              [2024-12-14 02:35:42,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:42,436][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.6723714470863342, acc: 0.7346938848495483)
[2024-12-14 02:35:42,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:42,822][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 1.317784070968628, acc: 0.6000000238418579)
[2024-12-14 02:35:42,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:43,249][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 1.275153398513794, acc: 0.6388888955116272)
                                                                                                                                                             [2024-12-14 02:35:43,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:43,594][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.4131336212158203, acc: 0.5784313678741455)
[2024-12-14 02:35:43,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:44,630][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 2.1063802242279053, acc: 0.4794520437717438)
                                                                                                                                                                                                                                           [2024-12-14 02:35:44,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:44,942][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.44369402527809143, acc: 0.8333333134651184)
[2024-12-14 02:35:45,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:45,248][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.6171607375144958, acc: 0.8148148059844971)
[2024-12-14 02:35:45,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:45,564][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.5228791832923889, acc: 0.8571428656578064)
[2024-12-14 02:35:45,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:46,104][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.462034821510315, acc: 0.6194690465927124)
                    [2024-12-14 02:35:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:46,454][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 1.196537733078003, acc: 0.6521739363670349)
[2024-12-14 02:35:46,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:46,844][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 1.4139431715011597, acc: 0.6363636255264282)
[2024-12-14 02:35:47,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:47,755][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 2.0033512115478516, acc: 0.45038166642189026)
                                                                                                                                                                                [2024-12-14 02:35:47,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:48,424][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 1.8385871648788452, acc: 0.4296296238899231)
                                                                                                                                                            [2024-12-14 02:35:48,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:48,735][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 1.1432383060455322, acc: 0.6393442749977112)
                                                                            [2024-12-14 02:35:48,814][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:35:49,048][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.3759715259075165, acc: 0.8333333134651184)
[2024-12-14 02:35:49,133][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:35:49,410][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.5782684683799744, acc: 0.8799999952316284)
[2024-12-14 02:35:49,514][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:35:49,754][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.4063997268676758, acc: 0.8571428656578064)
[2024-12-14 02:35:49,842][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:35:50,072][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 1.5272005796432495, acc: 0.5853658318519592)
[2024-12-14 02:35:50,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:50,429][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 1.9915764331817627, acc: 0.4773413836956024)
                     [2024-12-14 02:35:50,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:50,744][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 2.1072652339935303, acc: 0.4495677351951599)
                                                                                [2024-12-14 02:35:50,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:51,220][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 2.129807710647583, acc: 0.44062501192092896)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:35:51,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:51,747][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 2.0379934310913086, acc: 0.4465290904045105)
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:35:51,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:52,145][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 1.9317655563354492, acc: 0.47686833143234253)
                                                                                                                                                                                                                       [2024-12-14 02:35:52,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:52,455][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.9069267511367798, acc: 0.7599999904632568)
                                                                                                                                                                                                                      [2024-12-14 02:35:52,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:53,001][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 1.8561699390411377, acc: 0.4883720874786377)
                                                                                                                                                                                                                                                                                         [2024-12-14 02:35:53,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:53,797][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.7732009887695312, acc: 0.5158730149269104)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:35:54,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:54,713][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 1.7743940353393555, acc: 0.5)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:35:54,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:55,456][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 1.3396285772323608, acc: 0.6000000238418579)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:35:55,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:56,533][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 1.4744820594787598, acc: 0.6111111044883728)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:35:56,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:57,487][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 1.0939229726791382, acc: 0.6774193644523621)
                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:35:57,553][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:35:57,776][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.335130900144577, acc: 0.8928571343421936)
                                                                                                                                                                [2024-12-14 02:35:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:58,085][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.7886802554130554, acc: 0.7749999761581421)
                                                        [2024-12-14 02:35:58,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:58,492][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 1.2024859189987183, acc: 0.7058823704719543)
                                                                                                                                                                                                                                                                                      [2024-12-14 02:35:58,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:58,906][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 1.5940781831741333, acc: 0.595588207244873)
                                                                                                                                                                                                                                                                                         [2024-12-14 02:35:59,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:59,301][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 1.7494151592254639, acc: 0.5423728823661804)
                                                                                                                                                                                                                       [2024-12-14 02:35:59,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:35:59,654][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 1.8285481929779053, acc: 0.5)
                                                                                                                                                                                                                                       [2024-12-14 02:35:59,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:00,007][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 1.677103042602539, acc: 0.5145630836486816)
                                                                                                                                         [2024-12-14 02:36:00,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:00,309][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 1.2341351509094238, acc: 0.6507936716079712)
                                                                                                                                                                                                        [2024-12-14 02:36:00,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:00,669][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 1.3729021549224854, acc: 0.6153846383094788)
                                                                                                                                                                                                                      [2024-12-14 02:36:00,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:01,041][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 1.8031623363494873, acc: 0.5112107396125793)
                                                                              [2024-12-14 02:36:01,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:01,443][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 1.8481520414352417, acc: 0.5236220359802246)
                                                                                                                                     [2024-12-14 02:36:01,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:01,838][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 1.7699801921844482, acc: 0.4913793206214905)
                                                                                                                                                                                                                      [2024-12-14 02:36:01,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:02,238][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 1.7986253499984741, acc: 0.5289855003356934)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:36:02,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:02,599][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 1.9190638065338135, acc: 0.4747081696987152)
                                                                                                                                          [2024-12-14 02:36:02,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:02,947][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 1.6898202896118164, acc: 0.554347813129425)
 02:36:02,761][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.4651447832584381, acc: 0.875)
[2024-12-14 02:36:02,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:03,169][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.955280065536499, acc: 0.7222222089767456)
[2024-12-14 02:36:03,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:03,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:03,508][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 0.37808161973953247, acc: 0.7894737124443054)
[2024-12-14 02:36:03,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:03,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:03,889][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 0.9388138055801392, acc: 0.692307710647583)
[2024-12-14 02:36:03,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:04,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:04,249][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.5513017773628235, acc: 0.7931034564971924)
[2024-12-14 02:36:04,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:04,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:04,611][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.7143611907958984, acc: 0.7200000286102295)
[2024-12-14 02:36:04,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:04,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:04,981][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.3669890761375427, acc: 0.9047619104385376)
[2024-12-14 02:36:05,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:05,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:05,365][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 0.20539912581443787, acc: 0.9375)
[2024-12-14 02:36:05,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:05,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:05,752][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 1.3780522346496582, acc: 0.5849056839942932)
[2024-12-14 02:36:05,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:05,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:06,115][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 1.514235496520996, acc: 0.5616438388824463)
[2024-12-14 02:36:06,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:06,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:06,807][slam_llm.models.slam_model][INFO] - modality encoder
                                                            [2024-12-14 02:36:07,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:07,364][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 2.1179957389831543, acc: 0.4387351870536804)
[2024-12-14 02:36:07,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:07,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:07,637][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 1.1217538118362427, acc: 0.6279069781303406)
[2024-12-14 02:36:07,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:07,902][slam_llm.models.slam_model][INFO[2024-12-14 02:36:08,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:08,654][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 1.2119216918945312, acc: 0.6304348111152649)
 - modality encoder
[2024-12-14 02:36:08,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:08,330][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 1.4890841245651245, acc: 0.5432098507881165)
[2024-12-14 02:36:08,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:08,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:08,624][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 0.5333755612373352, acc: 0.8928571343421936)
[2024-12-14 02:36:08,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:08,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:08,932][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 0.5825091004371643, acc: 0.8148148059844971)
[2024-12-14 02:36:09,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:09,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:09,322][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.4231635332107544, acc: 0.8260869383811951)
[2024-12-14 02:36:09,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:09,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:09,714][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 1.8329321146011353, acc: 0.5042017102241516)
[2024-12-14 02:36:09,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:09,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:10,054][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 1.2135274410247803, acc: 0.6557376980781555)
[2024-12-14 02:36:10,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:10,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:10,462][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 1.5194731950759888, acc: 0.5396825671195984)
[2024-12-14 02:36:10,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:10,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:10,846][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 1.5797545909881592, acc: 0.5423728823661804)
[2024-12-14 02:36:10,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:10,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:11,256][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 1.17680025100708, acc: 0.6321839094161987)
[2024-12-14 02:36:11,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:11,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:11,592][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.6748553514480591, acc: 0.8095238208770752)
[2024-12-14 02:36:11,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:11,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:11,938][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.9264875054359436, acc: 0.692307710647583)
[2024-12-14 02:36:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:12,337][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 1.86849045753479, acc: 0.4864864945411682)
[2024-12-14 02:36:12,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:12,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:12,748][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 1.6268337965011597, acc: 0.5538461804389954)
[2024-12-14 02:36:12,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:12,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:13,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:13,214][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 1.7114135026931763, acc: 0.5454545617103577)
[2024-12-14 02:36:13,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:13,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:13,648][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 1.4418083429336548, acc: 0.6185566782951355)
[2[2024-12-14 02:36:13,867][slam_llm.mels.slam_model][INFO] - modality encoder
[2024-12-14 02:36:13,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:14,034][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 1.8103500604629517, acc: 0.529411792755127)
[2024-12-14 02:36:14,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:14,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:14,411][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.3701888918876648, acc: 0.9615384340286255)
[2024-12-14 02:36:14,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:14,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:14,802][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.24427548050880432, acc: 0.9259259104728699)
[2024-12-14 02:36:14,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:14,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:15,144][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.818301260471344, acc: 0.6785714030265808)
[2024-12-14 02:36:15,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:15,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:15,495][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.496930330991745, acc: 0.8611111044883728)
[2024-12-14 02:36:15,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:15,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:15,860][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 1.0040643215179443, acc: 0.719298243522644)
[2024-12-14 02:36:15,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:16,248][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 1.115307331085205, acc: 0.682539701461792)
[2024-12-14 02:36:16,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:16,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:16,599][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 1.5308244228363037, acc: 0.5492957830429077)
[2024-12-14 02:36:16,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:16,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:17,053][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.9551491737365723, acc: 0.5133333206176758)
[2024-12-14 02:36:17,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:17,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:17,435][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.7275444865226746, acc: 0.7297297120094299)
[2024-12-14 02:36:17,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:17,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:17,756][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.17431184649467468, acc: 0.9615384340286255)
[2024-12-14 02:36:17,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:18,196][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:36:18,502][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:36:18,822][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:36:19,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:19,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:1987612533569, acc: 0.8108108043670654)
[2024-12-14 02:36:19,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:19,771][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 1.2048286199569702, acc: 0.6617646813392639)
[2024-12-14 02:36:19,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:20,155][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.3642164170742035, acc: 0.8536585569381714)
[2024-12-14 02:36:20,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:20,514][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.05608386918902397, acc: 0.9599999785423279)
[2024-12-14 02:36:20,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:20,779][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.07868105918169022, acc: 1.0)
             [2024-12-14 02:36:20,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:21,117][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.21217596530914307, acc: 0.9354838728904724)
[2024-12-14 02:36:21,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:21,474][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.8838199377059937, acc: 0.6842105388641357)
[2024-12-14 02:36:21,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:21,826][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 1.0546395778656006, acc: 0.699999988079071)
[2024-12-14 02:36:21,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:22,136][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 1.049810767173767, acc: 0.7105262875556946)
[2024-12-14 02:36:22,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:22,720][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 1.2528845071792603, acc: 0.6226415038108826)
                                                                              [2024-12-14 02:36:22,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:23,301][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 1.5041489601135254, acc: 0.5833333134651184)
[2024-12-14 02:36:23,380][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:36:23,572][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.6607000827789307, acc: 0.7777777910232544)
[2024-12-14 02:36:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:23,943][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.6891647577285767, acc: 0.7419354915618896)
                                                                               [2024-12-14 02:36:24,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:24,309][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 2.125913143157959, acc: 0.47999998927116394)
[2024-12-14 02:36:24,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:24,708][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 1.4338936805725098, acc: 0.5833333134651184)
[2024-12-14 02:36:24,944][slam_llm.models.slam_model][INFO] - modality encoder
                                                                            [2024-12-14 02:36:25,563][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 2.1668834686279297, acc: 0.4560000002384186)
                                                                                                                                                                                                                                           [2024-12-14 02:36:25,659][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                              [2024-12-14 02:36:25,897][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 1.8923547267913818, acc: 0.449438214302063)
                                                                                                                                                              [2024-12-14 02:36:25,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:26,231][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 1.6782934665679932, acc: 0.5810810923576355)
                                                                              [2024-12-14 02:36:26,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:26,684][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 1.0939996242523193, acc: 0.7068965435028076)
                                                                                                                                                             [2024-12-14 02:36:26,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:27,047][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.20419970154762268, acc: 0.9090909361839294)
                                                                              [2024-12-14 02:36:27,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:27,439][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.4719899892807007, acc: 0.7727272510528564)
                                                                            [2024-12-14 02:36:27,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:27,837][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.33526134490966797, acc: 0.875)
                                                                                          [2024-12-14 02:36:27,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:28,227][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.5350444912910461, acc: 0.8999999761581421)
                                                                              [2024-12-14 02:36:28,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:28,614][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 1.1008565425872803, acc: 0.5833333134651184)
                                                                              [2024-12-14 02:36:28,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:28,957][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.555902361869812, acc: 0.8125)
                                                                                            [2024-12-14 02:36:29,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:29,309][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.3250846862792969, acc: 0.8999999761581421)
                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:36:29,991][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:36:30,330][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:36:30,600][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:36:30,984][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:36:31,373][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:36:31,640][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:36:31,901][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:36:32,242][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:36:32,714][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:36:33,105][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:36:33,458][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:36:33,815][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:36:34,193][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:36:34,564][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:36:34,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:34,895][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.8162730932235718, acc: 0.7428571581840515)
[2024-12-14 02:36:34,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:35,202][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.3782096207141876, acc: 0.8846153616905212)
[2024-12-14 02:36:35,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:35,406][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 1.7208569049835205, acc: 0.5679611563682556)
[2024-12-14 02:36:35,563][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 1.0274646282196045, acc: 0.5952380895614624)
[2024-12-14 02:36:35,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:35,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:35,895][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 0.8390055298805237, acc: 0.7333333492279053)
[2024-12-14 02:36:35,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:36,229][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.7849525213241577, acc: 0.5107526779174805)
[2024-12-14 02:36:36,261][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.5805255174636841, acc: 0.8260869383811951)
[2024-12-14 02:36:36,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:36,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:36,611][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 1.0669517517089844, acc: 0.7142857313156128)
[2024-12-14 02:36:36,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:36,937][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 1.1573814153671265, acc: 0.692307710647583)
[2024-12-14 02:36:37,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:37,034][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 1.6855134963989258, acc: 0.5818965435028076)
[2024-12-14 02:36:37,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:37,246][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 1.3185323476791382, acc: 0.5806451439857483)
[2024-12-14 02:36:37,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:37,560][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 1.5141100883483887, acc: 0.5405405163764954)
[2024-12-14 02:36:37,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:37,781][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 1.2270666360855103, acc: 0.6947368383407593)
[2024-12-14 02:36:38,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:38,096][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 1.6438474655151367, acc: 0.4912280738353729)
[2024-12-14 02:36:38,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:38,526][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 1.4771137237548828, acc: 0.5970149040222168)
[2024-12-14 02:36:38,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:38,773][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 1.8155804872512817, acc: 0.4752475321292877)
[2024-12-14 02:36:38,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:38,930][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 1.7836521863937378, acc: 0.43877550959587097)
[2024-12-14 02:36:39,034][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 1.7426528930664062, acc: 0.5806451439857483)
[2024-12-14 02:36:39,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:39,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:39,383][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 1.9319417476654053, acc: 0.43617022037506104)
[2024-12-14 02:36:39,627][slam_llm.models.slam_model][INFO] - modality encoder
eted (loss: 1.6846553087234497, acc: 0.5072463750839233)
[2024-12-14 02:36:39,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:39,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:39,762][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 1.50068199634552, acc: 0.5714285969734192)
[2024-12-14 02:36:39,859][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 1.9250364303588867, acc: 0.4285714328289032)
[2024-12-14 02:36:39,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:39,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:40,150][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 1.420081377029419, acc: 0.5357142686843872)
[2024-12-14 02:36:40,244][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 1.8583080768585205, acc: 0.42307692766189575)
[2024-12-14 02:36:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:40,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:40,529][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.7060900926589966, acc: 0.782608687877655)
[2024-12-14 02:36:40,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:40,641][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 1.9929940700531006, acc: 0.45255473256111145)
[2024-12-14 02:36:40,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:40,896][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.832800030708313, acc: 0.6551724076271057)
[2024-12-14 02:36:40,994][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 1.6914514303207397, acc: 0.5373134613037109)
[2024-12-14 02:36:41,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:41,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:41,320][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 1.3721988201141357, acc: 0.6521739363670349)
[2024-12-14 02:36:41,320][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.4158688187599182, acc: 0.8999999761581421)
[2024-12-14 02:36:41,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:41,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:41,703][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.2870526611804962, acc: 0.9545454382896423)
[2024-12-14 02:36:41,714][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 1.4857145547866821, acc: 0.5932203531265259)
[2024-12-14 02:36:41,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:41,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:42,036][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.38658902049064636, acc: 0.8695651888847351)
[2024-12-14 02:36:42,112][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 1.5431561470031738, acc: 0.6315789222717285)
[2024-12-14 02:36:42,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:42,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:42,400][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.747371256351471, acc: 0.7954545617103577)
[2024-12-14 02:36:42,460][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 1.6724613904953003, acc: 0.5540540814399719)
[2024-12-14 02:36:42,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:42,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:42,809][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 1.4405717849731445, acc: 0.568965494632721)
[2024-12-14 02:36:42,811][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.9483128786087036, acc: 0.75)
[2024-12-14 02:36:42,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:42,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:43,286][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:36:43,686][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:36:44,071][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                           [2024-12-14 02:36:44,328][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                          [2024-12-14 02:36:44,658][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:36:45,069][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:36:45,509][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                   [2024-12-14 02:36:45,917][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:36:46,360][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:36:46,718][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:36:47,067][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:36:47,418][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.8861185312271118, acc: 0.7727272510528564)
[2024-12-14 02:36:47,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:47,469][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 1.2585723400115967, acc: 0.6666666865348816)
[2024-12-14 02:36:47,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:47,726][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.6017811298370361, acc: 0.8095238208770752)
[2024-12-14 02:36:47,847][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 1.5450369119644165, acc: 0.577235758304596)
[2024-12-14 02:36:47,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:47,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:48,137][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 0.9688829183578491, acc: 0.7586206793785095)
[2024-12-14 02:36:48,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:48,269][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 1.1145575046539307, acc: 0.6774193644523621)
[2024-12-14 02:36:48,527][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.6404535174369812, acc: 0.8163265585899353)
[2024-12-14 02:36:48,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:48,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:48,909][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 0.9541105628013611, acc: 0.7200000286102295)
[2024-12-14 02:36:49,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:49,169][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 1.8315222263336182, acc: 0.48288974165916443)
[2024-12-14 02:36:49,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:49,288][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 1.0916552543640137, acc: 0.7361111044883728)
[2024-12-14 02:36:49,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:49,513][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 1.1180399656295776, acc: 0.6666666865348816)
[2024-12-14 02:36:49,629][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.6061784029006958, acc: 0.5490196347236633)
[2024-12-14 02:36:49,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:49,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:49,934][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 0.9201639890670776, acc: 0.7307692170143127)
[2024-12-14 02:36:50,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:50,327][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.2723661959171295, acc: 0.9166666865348816)
[2024-12-14 02:36:50,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:50,661][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 1.9919852018356323, acc: 0.5)
[2024-12-14 02:36:50,741][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.4952622354030609, acc: 0.8421052694320679)
[2024-12-14 02:36:50,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:50,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:50,976][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.3423028290271759, acc: 0.9166666865348816)
[2024-12-14 02:36:51,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:51,126][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 1.7764437198638916, acc: 0.47852760553359985)
[2024-12-14 02:36:51,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:51,376][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.5391725897789001, acc: 0.8148148059844971)
[2024-12-14 02:36:51,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:51,522][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.5608972311019897, acc: 0.5763888955116272)
[2024-12-14 02:36:51,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:51,714][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.2807316184043884, acc: 0.9642857313156128)
[2024-12-14 02:36:51,848][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 1.6604211330413818, acc: 0.5249999761581421)
[2024-12-14 02:36:51,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:51,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:52,179][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 1.7072595357894897, acc: 0.4821428656578064)
[2024-12-14 02:36:52,254][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.211676836013794, acc: 0.7079645991325378)
[2024-12-14 02:36:52,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:52,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:52,520][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 1.7026337385177612, acc: 0.5435897707939148)
[2024-12-14 02:36:52,548][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 1.3900306224822998, acc: 0.6521739363670349)
[2024-12-14 02:36:52,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:52,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:52,879][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 1.5445903539657593, acc: 0.5681818127632141)
[2024-12-14 02:36:52,927][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 1.4152289628982544, acc: 0.6470588445663452)
[2024-12-14 02:36:53,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:53,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:53,244][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.5600588917732239, acc: 0.8461538553237915)
[2024-12-14 02:36:53,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:53,580][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.19638298451900482, acc: 0.9130434989929199)
[2024-12-14 02:36:53,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:53,789][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 2.151968002319336, acc: 0.4198473393917084)
[2024-12-14 02:36:53,949][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.4614153802394867, acc: 0.84375)
[2024-12-14 02:36:53,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:54,460][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 1.9198640584945679, acc: 0.4740740656852722)
[2024-12-14 02:36:54,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:54,767][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 1.127553105354309, acc: 0.6721311211585999)
[2024-12-14 02:36:54,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:54,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:55,114][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.21879248321056366, acc: 0.9166666865348816)
[2024-12-14 02:36:55,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:55,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:55,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:55,459][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.5809274315834045, acc: 0.8399999737739563)
[2024-12-14 02:36:55,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:55,808][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.4051492214202881, acc: 0.8928571343421936)
[2024-12-14 02:36:55,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:55,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:56,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:56,173][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 1.494775414466858, acc: 0.5975610017776489)
[2024-12-14 02:36:56,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:56,504][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 1.8994780778884888, acc: 0.48942598700523376)
[2024-12-14 02:36:56,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:56,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:56,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:56,830][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 2.0523033142089844, acc: 0.4380403459072113)
[2024-12-14 02:36:56,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:57,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:57,305][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 2.082761526107788, acc: 0.46562498807907104)
[2024-12-14 02:36:57,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:57,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:57,832][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 1.9811015129089355, acc: 0.45778611302375793)
[2024-12-14 02:36:57,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:57,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:58,238][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 1.8695313930511475, acc: 0.5053380727767944)
[2024-12-14 02:36:58,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:58,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:58,536][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.6493117809295654, acc: 0.8399999737739563)
[2024-12-14 02:36:58,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:58,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:59,084][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 1.8664469718933105, acc: 0.5348837375640869)
[2024-12-14 02:36:59,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:59,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:59,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:36:59,886][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.6721162796020508, acc: 0.5873016119003296)
[2024-12-14 02:37:00,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:00,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:00,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:00,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:00,802][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 1.7071003913879395, acc: 0.5303030014038086)
[2024-12-14 02:37:01,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:01,091][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:37:01,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:01,543][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 1.4227664470672607, acc: 0.6117647290229797)
[2024-12-14 02:37:01,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:01,890][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:37:02,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:02,310][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 1.1790711879730225, acc: 0.6170212626457214)
[2024-12-14 02:37:02,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:02,632][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 1.1122703552246094, acc: 0.6666666865348816)
[2024-12-14 02:37:02,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:03,037][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.8008666634559631, acc: 0.7954545617103577)
[2024-12-14 02:37:03,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:03,449][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 1.839543342590332, acc: 0.5662650465965271)
[2024-12-14 02:37:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:03,816][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 1.6711076498031616, acc: 0.5555555820465088)
[2024-12-14 02:37:03,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:04,157][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.6971155405044556, acc: 0.7368420958518982)
                                                                              [2024-12-14 02:37:04,244][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:37:04,480][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 1.0578943490982056, acc: 0.6764705777168274)
[2024-12-14 02:37:04,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:04,841][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.5740461349487305, acc: 0.75)
                                   [2024-12-14 02:37:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:05,194][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 1.8222576379776, acc: 0.453125)
                                                                                           [2024-12-14 02:37:05,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:05,536][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 2.0200929641723633, acc: 0.4399999976158142)
                                                                               [2024-12-14 02:37:05,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:05,871][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 1.5010391473770142, acc: 0.6153846383094788)
                                                                              [2024-12-14 02:37:05,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:06,231][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 2.046774387359619, acc: 0.4285714328289032)
                                                                                [2024-12-14 02:37:06,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:06,584][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 2.108900785446167, acc: 0.40721648931503296)
                                                                               [2024-12-14 02:37:06,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:06,878][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.35406577587127686, acc: 0.8636363744735718)
                                                                              [2024-12-14 02:37:06,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:07,245][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 1.3507287502288818, acc: 0.6190476417541504)
                                                                               [2024-12-14 02:37:07,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:07,612][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 1.0869208574295044, acc: 0.6724137663841248)
                                                                               [2024-12-14 02:37:07,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:08,084][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.9934226274490356, acc: 0.6545454263687134)
                                                                               [2024-12-14 02:37:08,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:08,633][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 1.577904462814331, acc: 0.561855673789978)
                                                                                                                                                                                                                                                                                                    [2024-12-14 02:37:08,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:08,950][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 1.446747899055481, acc: 0.568965494632721)
[2024-12-14 02:37:09,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:09,306][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.693660318851471, acc: 0.8148148059844971)
[2024-12-14 02:37:09,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:09,622][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.877336323261261, acc: 0.7631579041481018)
                                                                                                        [2024-12-14 02:37:09,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:09,995][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.5926843285560608, acc: 0.8928571343421936)
[2024-12-14 02:37:10,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:10,345][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.6390663981437683, acc: 0.84375)
                                                                                                                                                                         [2024-12-14 02:37:10,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:10,706][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.9514927268028259, acc: 0.7735849022865295)
[2024-12-14 02:37:10,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:11,078][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.5658175349235535, acc: 0.849056601524353)
[2024-12-14 02:37:11,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:11,428][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.5053818225860596, acc: 0.7647058963775635)
[2024-12-14 02:37:11,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:11,779][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.5666942596435547, acc: 0.78125)
                                                                                                               [2024-12-14 02:37:11,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:12,184][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.8731801509857178, acc: 0.7704917788505554)
[2024-12-14 02:37:12,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:12,528][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.2918621003627777, acc: 0.8999999761581421)
                                                                               [2024-12-14 02:37:12,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:12,888][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.0762534812092781, acc: 1.0)
                                                                                                                                                                             [2024-12-14 02:37:12,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:13,195][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.24728763103485107, acc: 0.9259259104728699)
[2024-12-14 02:37:13,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:13,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:13,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:13,532][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.3168855607509613, acc: 0.8399999737739563)
[2024-12-14 02:37:13,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:13,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:13,917][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 1.1502522230148315, acc: 0.5961538553237915)
[2024-12-14 02:37:14,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:14,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:14,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:14,703][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 1.2101651430130005, acc: 0.64673912525177)
[2024-12-14 02:37:14,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:14,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:15,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:15,244][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 1.5473705530166626, acc: 0.5340909361839294)
[2024-12-14 02:37:15,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:15,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:15,669][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 1.5421994924545288, acc: 0.5106382966041565)
[2024-12-14 02:37:15,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:16,034][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.8633715510368347, acc: 0.7169811129570007)
[2024-12-14 02:37:16,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:16,384][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 1.1226928234100342, acc: 0.6499999761581421)
[2024-12-14 02:37:16,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:16,679][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.5344242453575134, acc: 0.8372092843055725)
[2024-12-14 02:37:16,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:16,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:17,046][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.5461946725845337, acc: 0.800000011920929)
[2024-12-14 02:37:17,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:17,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:17,481][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 1.7955601215362549, acc: 0.5052631497383118)
[2024-12-14 02:37:17,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:17,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:17,826][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 1.1704847812652588, acc: 0.699999988079071)
[2024-12-14 02:37:17,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:17,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:18,258][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 1.1693835258483887, acc: 0.6666666865348816)
[2024-12-14 02:37:18,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:18,665][slam_llm.modelTraining Epoch: 6/10, step 323/574 completed (loss: 0.8632170557975769, acc: 0.7428571581840515)
[2024-12-14 02:37:18,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:19,054][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.7677598595619202, acc: 0.7435897588729858)
[2024-12-14 02:37:19,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:19,426][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.155576467514038, acc: 0.6829268336296082)
                   [2024-12-14 02:37:19,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:19,802][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.9739817380905151, acc: 0.7105262875556946)
 [2024-12-14 02:37:19,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:20,186][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.14915533363819122, acc: 1.0)
                                                                                 [2024-12-14 02:37:20,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:20,534][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.142973855137825, acc: 0.9642857313156128)
                                                                                                                                                               [2024-12-14 02:37:20,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:20,912][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.5352247953414917, acc: 0.7407407164573669)
                                                                               [2024-12-14 02:37:21,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:21,265][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.29406964778900146, acc: 0.90625)
                                                                                        [2024-12-14 02:37:21,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:21,625][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.9907626509666443, acc: 0.6935483813285828)
                                                                               [2024-12-14 02:37:21,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:22,038][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.9945581555366516, acc: 0.6842105388641357)
                                                                               [2024-12-14 02:37:22,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:22,423][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 1.1225625276565552, acc: 0.6875)
            [2024-12-14 02:37:22,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:22,817][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.6518999934196472, acc: 0.8666666746139526)
                                                                                                                                                              [2024-12-14 02:37:22,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:23,194][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.4368721842765808, acc: 0.8421052694320679)
                                                                                [2024-12-14 02:37:23,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:23,553][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 1.323795199394226, acc: 0.6200000047683716)
                                                                                [2024-12-14 02:37:23,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:23,940][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 1.7886263132095337, acc: 0.5057471394538879)
                                                                               [2024-12-14 02:37:24,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:24,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:24,255][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.22098204493522644, acc: 0.949999988079071)
[2024-12-14 02:37:24,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:24,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:24,649][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.7203632593154907, acc: 0.7837837934494019)
[2024-12-14 02:37:24,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:24,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:25,007][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.5034684538841248, acc: 0.837837815284729)
[2024-12-14 02:37:25,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:25,373][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.5290405750274658, acc: 0.837837815284729)
 [2024-12-14 02:37:25,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:25,510][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.7780, device='cuda:0') eval_epoch_loss=tensor(1.7541, device='cuda:0') eval_epoch_acc=tensor(0.5833, device='cuda:0')
[2024-12-14 02:37:25,512][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:37:25,512][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:37:25,746][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 1.1020509004592896, acc: 0.6764705777168274)
[2024-12-14 02:37:25,756][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_6_step_133_loss_1.7540651559829712/model.pt
[2024-12-14 02:37:25,760][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:37:25,761][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.5832992196083069
[2024-12-14 02:37:25,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:25,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:26,078][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.3214128911495209, acc: 0.8048780560493469)
[2024-12-14 02:37:26,162][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.711190938949585, acc: 0.782608687877655)
[2024-12-14 02:37:26,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:26,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:26,461][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.051668182015419006, acc: 1.0)
[2024-12-14 02:37:26,517][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.6172620058059692, acc: 0.8285714387893677)
[2024-12-14 02:37:26,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:26,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:26,835][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.06330733001232147, acc: 1.0)
[2024-12-14 02:37:26,873][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.35295456647872925, acc: 0.8846153616905212)
[2024-12-14 02:37:26,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:26,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:27,160][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.20442453026771545, acc: 0.9354838728904724)
[2024-12-14 02:37:27,211][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 1.0010089874267578, acc: 0.6190476417541504)
[2024-12-14 02:37:27,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:27,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:27,743][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.48805156350135803, acc: 0.8399999737739563)
                                                                                                                                       [2024-12-14 02:37:27,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:28,152][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 1.075078010559082, acc: 0.6666666865348816)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:37:28,264][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:37:28,507][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 1.3071998357772827, acc: 0.6279069781303406)
                                                                                                                                                              [2024-12-14 02:37:28,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:28,883][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.9246229529380798, acc: 0.7435897588729858)
                                                                                                                                         [2024-12-14 02:37:29,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:29,293][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 1.3994215726852417, acc: 0.5777778029441833)
                                                                                                                                                                                                                       [2024-12-14 02:37:29,393][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:37:29,662][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.3725361227989197, acc: 0.8260869383811951)
                     [2024-12-14 02:37:29,760][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:37:30,002][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.5598903298377991, acc: 0.7692307829856873)
                                                                                                                                                              [2024-12-14 02:37:30,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:30,346][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 1.9840703010559082, acc: 0.4065934121608734)
                                                                                                                                         [2024-12-14 02:37:30,493][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:37:30,843][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 1.6501115560531616, acc: 0.539130449295044)
                                                                                [2024-12-14 02:37:30,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:31,179][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 1.5239211320877075, acc: 0.554347813129425)
[2024-12-14 02:37:31,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:31,551][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 1.3488458395004272, acc: 0.6122449040412903)
                                                                                [2024-12-14 02:37:31,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:31,908][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.10976383835077286, acc: 1.0)
                                                                                                                                         [2024-12-14 02:37:32,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:32,279][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.421135276556015, acc: 0.8846153616905212)
                                                                                                                                                                                                                        [2024-12-14 02:37:32,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:32,646][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.731042742729187, acc: 0.7560975551605225)
                                                                                                                                                                                                                         [2024-12-14 02:37:32,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:32,991][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 1.0553838014602661, acc: 0.6666666865348816)
                                                                                                                                                                                                                       [2024-12-14 02:37:33,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:33,322][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 1.1106964349746704, acc: 0.7236841917037964)
                                                                                                                                                                                                                        [2024-12-14 02:37:33,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:33,664][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 1.0842105150222778, acc: 0.6829268336296082)
                                                                                                                                                                                                                        [2024-12-14 02:37:33,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:34,025][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.8919383883476257, acc: 0.6969696879386902)
                                                                                                                                                                                                             [2024-12-14 02:37:34,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:34,384][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.10792382806539536, acc: 0.9583333134651184)
                                                                                                                                        [2024-12-14 02:37:34,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:34,722][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.09554330259561539, acc: 1.0)
                                                                                             [2024-12-14 02:37:34,810][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:37:35,038][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.46680155396461487, acc: 0.8571428656578064)
                                                                              [2024-12-14 02:37:35,118][slam_llm.models.slam_model][INFO] - modality encoder
                                              [2024-12-14 02:37:35,378][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.6007940769195557, acc: 0.875)
[2024-12-14 02:37:35,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:35,989][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 1.5383785963058472, acc: 0.5939394235610962)
[2024-12-14 02:37:36,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:36,873][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 1.07412588596344, acc: 0.6886792182922363)
                                                                                                                  [2024-12-14 02:37:36,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:37,258][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 1.1305079460144043, acc: 0.7111111283302307)
                                                                               [2024-12-14 02:37:37,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:37,612][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.8061202764511108, acc: 0.7142857313156128)
[2024-12-14 02:37:37,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:37,991][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.513954222202301, acc: 0.8285714387893677)
[2024-12-14 02:37:38,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:38,350][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.2103913128376007, acc: 0.9599999785423279)
[2024-12-14 02:37:38,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:38,660][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.07243543863296509, acc: 1.0)
                                   [2024-12-14 02:37:38,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:39,015][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.8583865761756897, acc: 0.7083333134651184)
                                                                               [2024-12-14 02:37:39,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:39,385][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 1.1975637674331665, acc: 0.6842105388641357)
                                                                                                                                                              [2024-12-14 02:37:39,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:39,988][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 1.355639934539795, acc: 0.6347305178642273)
                                                                                                                                                                                                                        [2024-12-14 02:37:40,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:40,401][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 1.1894465684890747, acc: 0.6390977501869202)
                                                                               [2024-12-14 02:37:40,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:41,679][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 1.4546788930892944, acc: 0.625668466091156)
/10, step 168/574 completed (loss: 1.06673264503479, acc: 0.7083333134651184)
[2024-12-14 02:37:40,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:40,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:41,103][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.5267491340637207, acc: 0.5588235259056091)
[2024-12-14 02:37:41,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:41,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:41,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:41,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:42,130][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 2.046312093734741, acc: 0.48630136251449585)
[2024-12-14 02:37:42,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:42,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:42,432][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.4493963420391083, acc: 0.875)
[2024-12-14 02:37:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:42,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:42,733][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.6492725014686584, acc: 0.8518518805503845)
[2024-12-14 02:37:42,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:42,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:43,036][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.6047849655151367, acc: 0.8571428656578064)
[2024-12-14 02:37:43,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:43,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:43,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:43,574][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.3415476083755493, acc: 0.6371681690216064)
[2024-12-14 02:37:43,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:43,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:43,876][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 1.2723593711853027, acc: 0.6376811861991882)
[2024-12-14 02:37:43,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:44,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:44,213][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 1.3032881021499634, acc: 0.6477272510528564)
[2024-12-14 02:37:44,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:44,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:44,812][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:37:45,122][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 2.050936222076416, acc: 0.442748099565506)
   [2024-12-14 02:37:45,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:45,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:45,519][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:37:45,825][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 1.8468297719955444, acc: 0.48148149251937866)
[2024-12-14 02:37:45,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:45,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:46,197][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 1.190036654472351, acc: 0.6393442749977112)
[2024-12-14 02:37:46,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:46,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:46,562][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.3285107910633087, acc: 0.875)
[2024-12-14 02:37:46,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:46,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:47,051][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 1.8907865285873413, acc: 0.4930555522441864)
10, step 181/574 completed (loss: 0.5337864756584167, acc: 0.800000011920929)
[2024-12-14 02:37:47,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:47,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:47,344][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.516230583190918, acc: 0.8928571343421936)
[2024-12-14 02:37:47,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:47,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:47,671][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 1.5094767808914185, acc: 0.5853658318519592)
[2024-12-14 02:37:47,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:47,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:47,995][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 1.9615633487701416, acc: 0.4743202328681946)
[2024-12-14 02:37:48,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:48,308][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 2.068881034851074, acc: 0.455331414937973)
[2024-12-14 02:37:48,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:48,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:48,786][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 2.1117849349975586, acc: 0.421875)
[2024-12-14 02:37:48,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:49,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:49,311][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 2.0123302936553955, acc: 0.4652908146381378)
[2024-12-14 02:37:49,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:49,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:49,725][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 1.8994325399398804, acc: 0.4661921560764313)
[2024-12-14 02:37:49,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:49,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:50,046][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.4051946997642517, acc: 0.9599999785423279)
[2024-12-14 02:37:50,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:50,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:50,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:50,602][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 1.8528940677642822, acc: 0.4651162922382355)
[2024-12-14 02:37:50,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:50,929][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:37:51,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:51,402][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.5939853191375732, acc: 0.5634920597076416)
 [2024-12-14 02:37:51,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:51,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:51,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:52,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:52,322][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 1.6764317750930786, acc: 0.5530303120613098)
[2024-12-14 02:37:52,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:52,526][slam_llm.models.slam_model][INFO] - modality encoder
                                      [2024-12-14 02:37:52,862][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:37:52,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:53,237][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.6006481051445007, acc: 0.800000011920929)
 [2024-12-14 02:37:53,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:53,622][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.5801955461502075, acc: 0.8484848737716675)
[2024-12-14 02:37:53,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:53,967][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.20547519624233246, acc: 0.9545454382896423)
[2024-12-14 02:37:54,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:54,314][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 1.2642735242843628, acc: 0.6078431606292725)
[2024-12-14 02:37:54,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:54,687][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 1.0831234455108643, acc: 0.6153846383094788)
[2024-12-14 02:37:54,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:55,047][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.7075329422950745, acc: 0.7777777910232544)
[2024-12-14 02:37:55,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:55,421][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 1.0087897777557373, acc: 0.625)
                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:37:56,121][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:37:56,524][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:37:56,772][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:37:57,165][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:37:57,554][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:37:57,981][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:37:58,386][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:37:58,636][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.8014477491378784, acc: 0.5067264437675476)
[2024-12-14 02:37:58,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:58,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:59,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:59,189][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 1.868139386177063, acc: 0.5)
[2024-12-14 02:37:59,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:59,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:59,635][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 1.7340890169143677, acc: 0.5301724076271057)
[2024-12-14 02:37:59,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:37:59,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:00,029][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 1.7287334203720093, acc: 0.54347825050354)
[2024-12-14 02:38:00,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:00,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:00,403][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 1.9273115396499634, acc: 0.4591439664363861)
[2024-12-14 02:38:00,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:00,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:00,744][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 1.6512848138809204, acc: 0.6195651888847351)
[2024-12-14 02:38:00,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:01,081][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.29965370893478394, acc: 0.8695651888847351)
[2024-12-14 02:38:01,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:01,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:01,397][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.5748757719993591, acc: 0.8214285969734192)
[2024-12-14 02:38:01,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:01,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:01,716][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.5875626802444458, acc: 0.8297872543334961)
[2024-12-14 02:38:01,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:01,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:02,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:02,394][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 1.3174232244491577, acc: 0.6615384817123413)
[2024-12-14 02:38:02,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:02,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:02,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:02,733][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 1.0602830648422241, acc: 0.6756756901741028)
[2024-12-14 02:38:02,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:02,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:03,097][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 1.0808022022247314, acc: 0.6976743936538696)
[2024-12-14 02:38:03,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:03,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:03,647][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 1.1679564714431763, acc: 0.6666666865348816)
[2024-12-14 02:38:03,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:04,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:03,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:04,019][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 1.141489028930664, acc: 0.6555555462837219)
[2024-12-14 02:38:04,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:04,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:04,379][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.4717567563056946, acc: 0.8484848737716675)
[2024-12-14 02:38:04,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:04,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:04,705][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.43660613894462585, acc: 0.8888888955116272)
[2024-12-14 02:38:04,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:05,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:05,039][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.35252776741981506, acc: 0.9200000166893005)
[2024-12-14 02:38:05,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:05,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:05,409][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 1.1285494565963745, acc: 0.7115384340286255)
[2024-12-14 02:38:05,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:05,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:06,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:06,175][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 1.2675693035125732, acc: 0.6304348111152649)
[2024-12-14 02:38:06,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:06,719][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 1.6262377500534058, acc: 0.5397727489471436)
[2024-12-14 02:38:06,753][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.5074, device='cuda:0') eval_epoch_loss=tensor(1.8729, device='cuda:0') eval_epoch_acc=tensor(0.5697, device='cuda:0')
[2024-12-14 02:38:06,754][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:38:06,754][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:38:06,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:06,951][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_6_step_276_loss_1.8729439973831177/model.pt
[2024-12-14 02:38:06,954][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:38:07,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:07,150][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 1.5132876634597778, acc: 0.542553186416626)
[2024-12-14 02:38:07,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:07,338][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 0.8760465383529663, acc: 0.8275862336158752)
[2024-12-14 02:38:07,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:07,503][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.876362144947052, acc: 0.698113203048706)
[2024-12-14 02:38:07,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:07,708][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.46197783946990967, acc: 0.8399999737739563)
[2024-12-14 02:38:07,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:07,896][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 1.0083547830581665, acc: 0.6499999761581421)
[2024-12-14 02:38:08,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:08,116][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 1.250023365020752, acc: 0.5957446694374084)
[2024-12-14 02:38:08,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:08,285][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.580564022064209, acc: 0.7906976938247681)
[2024-12-14 02:38:08,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:08,451][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 1.063449740409851, acc: 0.6458333134651184)
[2024-12-14 02:38:08,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:08,670][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.544818639755249, acc: 0.7666666507720947)
[2024-12-14 02:38:08,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:08,803][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.8174137473106384, acc: 0.7272727489471436)
[2024-12-14 02:38:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:09,103][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 1.6958727836608887, acc: 0.5368421077728271)
[2024-12-14 02:38:09,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:09,225][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 1.9035695791244507, acc: 0.46987950801849365)
[2024-12-14 02:38:09,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:09,456][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 1.226956844329834, acc: 0.644444465637207)
[2024-12-14 02:38:09,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:09,653][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 1.6178221702575684, acc: 0.5555555820465088)
[2024-12-14 02:38:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:09,901][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 1.1717945337295532, acc: 0.6833333373069763)
[2024-12-14 02:38:10,028][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.8481696248054504, acc: 0.7368420958518982)
[2024-12-14 02:38:10,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:10,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:10,390][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 0.704239010810852, acc: 0.7941176295280457)
[2024-12-14 02:38:10,400][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 1.5755925178527832, acc: 0.6009174585342407)
[2024-12-14 02:38:10,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:10,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:10,731][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.6623632907867432, acc: 0.75)
[2024-12-14 02:38:10,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:10,878][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 1.229479193687439, acc: 0.6846153736114502)
[2024-12-14 02:38:10,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:11,097][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 1.7105070352554321, acc: 0.53125)
[2024-12-14 02:38:11,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:11,231][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.3942888081073761, acc: 0.8421052694320679)
[2024-12-14 02:38:11,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:11,445][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 1.844273328781128, acc: 0.5040000081062317)
[2024-12-14 02:38:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:11,610][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.36495181918144226, acc: 0.9166666865348816)
[2024-12-14 02:38:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:11,801][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 1.3272935152053833, acc: 0.6483516693115234)
[2024-12-14 02:38:12,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:11,992][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 0.8794236779212952, acc: 0.7727272510528564)
[2024-12-14 02:38:12,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:12,127][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 2.0053062438964844, acc: 0.4906832277774811)
[2024-12-14 02:38:12,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:12,307][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.9974773526191711, acc: 0.7037037014961243)
[2024-12-14 02:38:12,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:12,482][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 2.1098039150238037, acc: 0.4020618498325348)
[2024-12-14 02:38:12,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:12,659][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.5834562182426453, acc: 0.800000011920929)
[2024-12-14 02:38:12,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:12,866][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.2531895935535431, acc: 0.8636363744735718)
[2024-12-14 02:38:12,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:13,098][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.8629934787750244, acc: 0.7045454382896423)
[2024-12-14 02:38:13,194][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 1.1519972085952759, acc: 0.5952380895614624)
[2024-12-14 02:38:13,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:13,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:13,443][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.6479501724243164, acc: 0.7954545617103577)
[2024-12-14 02:38:13,510][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 1.0470513105392456, acc: 0.7068965435028076)
[2024-12-14 02:38:13,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:13,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:13,969][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.8973999619483948, acc: 0.7636363506317139)
[2024-12-14 02:38:14,024][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 1.2392557859420776, acc: 0.6129032373428345)
[2024-12-14 02:38:14,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:14,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:14,519][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 1.6514626741409302, acc: 0.561855673789978)
[2024-12-14 02:38:14,559][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 0.7598525881767273, acc: 0.7727272510528564)
[2024-12-14 02:38:14,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:14,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:14,792][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 1.425745964050293, acc: 0.5344827771186829)
[2024-12-14 02:38:14,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:14,910][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.03383982181549072, acc: 1.0)
[2024-12-14 02:38:15,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:15,142][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.7271247506141663, acc: 0.8148148059844971)
[2024-12-14 02:38:15,254][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.189494788646698, acc: 0.9615384340286255)
[2024-12-14 02:38:15,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:15,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:15,484][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.9317660927772522, acc: 0.7105262875556946)
[2024-12-14 02:38:15,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:15,621][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.2956620752811432, acc: 0.9354838728904724)
[2024-12-14 02:38:15,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:15,889][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.6128333210945129, acc: 0.8571428656578064)
[2024-12-14 02:38:15,935][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.3378560543060303, acc: 0.8999999761581421)
[2024-12-14 02:38:15,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:16,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:16,275][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.367348849773407, acc: 0.90625)
[2024-12-14 02:38:16,361][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.36596983671188354, acc: 0.8918918967247009)
[2024-12-14 02:38:16,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:16,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:16,685][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.8741055727005005, acc: 0.698113203048706)
[2024-12-14 02:38:16,777][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.6518949270248413, acc: 0.7837837934494019)
[2024-12-14 02:38:16,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:16,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:17,038][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.441060870885849, acc: 0.849056601524353)
[2024-12-14 02:38:17,126][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.4889858365058899, acc: 0.837837815284729)
[2024-12-14 02:38:17,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:17,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:17,431][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.3843044638633728, acc: 0.9117646813392639)
[2024-12-14 02:38:17,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:17,542][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 1.3169727325439453, acc: 0.6029411554336548)
[2024-12-14 02:38:17,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:17,771][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.5220708250999451, acc: 0.90625)
[2024-12-14 02:38:17,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:17,913][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.4390173554420471, acc: 0.8292682766914368)
[2024-12-14 02:38:18,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:18,155][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.8948684930801392, acc: 0.7213114500045776)
[2024-12-14 02:38:18,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:18,299][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.016092920675873756, acc: 1.0)
[2024-12-14 02:38:18,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:18,457][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.3776806592941284, acc: 0.8333333134651184)
[2024-12-14 02:38:18,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:18,685][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.09000859409570694, acc: 0.9599999785423279)
[2024-12-14 02:38:18,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:18,796][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.05774679780006409, acc: 1.0)
[2024-12-14 02:38:19,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:19,053][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.21003343164920807, acc: 0.9354838728904724)
[2024-12-14 02:38:19,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:19,159][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 1.3387298583984375, acc: 0.5652173757553101)
[2024-12-14 02:38:19,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:19,370][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.8213077187538147, acc: 0.7719298005104065)
[2024-12-14 02:38:19,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:19,593][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 1.3083491325378418, acc: 0.5833333134651184)
[2024-12-14 02:38:19,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:19,701][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 1.0075984001159668, acc: 0.7428571581840515)
[2024-12-14 02:38:19,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:19,901][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 1.1257948875427246, acc: 0.6265060305595398)
[2024-12-14 02:38:19,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:20,052][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 0.914825439453125, acc: 0.6973684430122375)
[2024-12-14 02:38:20,186][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 1.5377336740493774, acc: 0.5641025900840759)
[2024-12-14 02:38:20,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:20,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:20,533][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 1.633298397064209, acc: 0.5714285969734192)
[2024-12-14 02:38:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:20,627][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 1.2241231203079224, acc: 0.6226415038108826)
[2024-12-14 02:38:20,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:20,833][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.020917309448122978, acc: 1.0)
[2024-12-14 02:38:20,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:21,161][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.2469497174024582, acc: 0.875)
[2024-12-14 02:38:21,237][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 1.5394209623336792, acc: 0.550000011920929)
[2024-12-14 02:38:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:21,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:21,502][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.38887378573417664, acc: 0.9032257795333862)
[2024-12-14 02:38:21,545][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.6432895660400391, acc: 0.7777777910232544)
[2024-12-14 02:38:21,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:21,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:21,819][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 0.5501367449760437, acc: 0.8709677457809448)
[2024-12-14 02:38:21,861][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.43137094378471375, acc: 0.9032257795333862)
[2024-12-14 02:38:21,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:21,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:22,148][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 0.9166992902755737, acc: 0.7761194109916687)
[2024-12-14 02:38:22,184][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 2.1121914386749268, acc: 0.4399999976158142)
[2024-12-14 02:38:22,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:22,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:22,496][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 1.16451895236969, acc: 0.625)
[2024-12-14 02:38:22,506][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 1.0856430530548096, acc: 0.7115384340286255)
[2024-12-14 02:38:22,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:22,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:22,896][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 0.9244441390037537, acc: 0.644444465637207)
[2024-12-14 02:38:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:23,242][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 0.982314944267273, acc: 0.6774193644523621)
[2024-12-14 02:38:23,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:23,321][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 2.080324649810791, acc: 0.46399998664855957)
[2024-12-14 02:38:23,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:23,541][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.5713882446289062, acc: 0.800000011920929)
[2024-12-14 02:38:23,616][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 1.7527787685394287, acc: 0.4157303273677826)
[2024-12-14 02:38:23,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:23,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:23,909][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 1.0205026865005493, acc: 0.6666666865348816)
[2024-12-14 02:38:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:24,054][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 1.7297025918960571, acc: 0.5270270109176636)
[2024-12-14 02:38:24,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:24,280][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 1.062499761581421, acc: 0.6857143044471741)
[2024-12-14 02:38:24,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:24,521][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 1.0211355686187744, acc: 0.6724137663841248)
[2024-12-14 02:38:24,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:24,666][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.8930859565734863, acc: 0.7179487347602844)
[2024-12-14 02:38:24,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:24,824][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.18278507888317108, acc: 0.9545454382896423)
[2024-12-14 02:38:24,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:24,974][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.481650710105896, acc: 0.6341463327407837)
[2024-12-14 02:38:25,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:25,085][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.3527228832244873, acc: 0.8636363744735718)
[2024-12-14 02:38:25,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:25,299][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 1.2273212671279907, acc: 0.6842105388641357)
[2024-12-14 02:38:25,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:25,488][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.42211824655532837, acc: 0.875)
[2024-12-14 02:38:25,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:25,622][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.2742648720741272, acc: 0.9473684430122375)
[2024-12-14 02:38:25,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:25,799][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.43012434244155884, acc: 0.8666666746139526)
[2024-12-14 02:38:25,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:25,949][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.18846546113491058, acc: 0.8571428656578064)
[2024-12-14 02:38:26,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:26,245][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 1.080049991607666, acc: 0.6666666865348816)
[2024-12-14 02:38:26,632][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.8439, device='cuda:0') eval_epoch_loss=tensor(1.7654, device='cuda:0') eval_epoch_acc=tensor(0.5736, device='cuda:0')
[2024-12-14 02:38:26,633][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:38:26,634][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:38:26,855][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_6_step_419_loss_1.7653952836990356/model.pt
[2024-12-14 02:38:26,858][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:38:26,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:27,268][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.6978024244308472, acc: 0.800000011920929)
[2024-12-14 02:38:27,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:27,658][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.08381100744009018, acc: 1.0)
              [2024-12-14 02:38:27,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:27,978][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.6079323887825012, acc: 0.800000011920929)
                                                                    [2024-12-14 02:38:28,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:28,322][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.4849579930305481, acc: 0.875)
                                                                                             [2024-12-14 02:38:28,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:28,759][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.4426196217536926, acc: 0.8611111044883728)
                                                                                                                                                                                                                        [2024-12-14 02:38:28,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:29,109][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.40313854813575745, acc: 0.8518518805503845)
                                                                                                                                                             [2024-12-14 02:38:29,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:29,463][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.540492594242096, acc: 0.8484848737716675)
[2024-12-14 02:38:29,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:29,843][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.3121180236339569, acc: 0.8695651888847351)
                                                                                                                                                                [2024-12-14 02:38:29,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:30,207][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.5617865324020386, acc: 0.8648648858070374)
                                                                                                                                                             [2024-12-14 02:38:30,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:30,548][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.26282480359077454, acc: 0.9629629850387573)
[2024-12-14 02:38:30,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:30,928][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.11560681462287903, acc: 1.0)
77226924896)
[2024-12-14 02:38:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:30,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:31,117][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 1.1453262567520142, acc: 0.6792452931404114)
[2024-12-14 02:38:31,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:31,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:31,458][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 1.3140883445739746, acc: 0.6455696225166321)
[2024-12-14 02:38:31,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:31,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:31,823][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 1.0594638586044312, acc: 0.6666666865348816)
[2024-12-14 02:38:31,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:31,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:32,209][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 1.762878179550171, acc: 0.5074626803398132)
[2024-12-14 02:38:32,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:32,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:32,520][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.2638072967529297, acc: 0.949999988079071)
[2024-12-14 02:38:32,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:32,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:32,827][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.37135809659957886, acc: 0.8799999952316284)
[2024-12-14 02:38:32,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:33,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:33,208][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 0.9254915714263916, acc: 0.8055555820465088)
[2024-12-14 02:38:33,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:33,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:33,571][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 1.442460536956787, acc: 0.5116279125213623)
[2024-12-14 02:38:33,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:33,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:33,923][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 1.0371973514556885, acc: 0.7948718070983887)
[2024-12-14 02:38:33,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:34,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:34,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:34,320][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 1.5463919639587402, acc: 0.5333333611488342)
[2024-12-14 02:38:34,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:34,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:34,685][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.34384971857070923, acc: 0.9130434989929199)
[2024-12-14 02:38:34,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:35,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:35,059][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.7268049716949463, acc: 0.7692307829856873)
[2024-12-14 02:38:35,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:35,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:35,458][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 1.8584086894989014, acc: 0.48351648449897766)
[2024-12-14 02:38:35,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:35,749][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:38:36,062][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 1.6689366102218628, acc: 0.582608699798584)
[2024-12-14 02:38:36,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:36,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:36,374][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 1.4765548706054688, acc: 0.5978260636329651)
[2024-12-14 02:38:36,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:36,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:36,719][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 1.304374098777771, acc: 0.6938775777816772)
[2024-12-14 02:38:36,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:36,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:37,057][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.10582507401704788, acc: 0.9583333134651184)
[2024-12-14 02:38:37,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:37,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:37,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:37,425][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.3518434762954712, acc: 0.8846153616905212)
[2024-12-14 02:38:37,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:37,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:37,804][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.7066567540168762, acc: 0.7317073345184326)
[2024-12-14 02:38:37,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:38,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:38,203][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 1.0367039442062378, acc: 0.644444465637207)
[2024-12-14 02:38:38,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:38,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:38,561][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 1.3051484823226929, acc: 0.6447368264198303)
[2024-12-14 02:38:38,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:38,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:38,899][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 0.9859117865562439, acc: 0.7560975551605225)
[2024-12-14 02:38:38,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:39,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:39,220][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.9457627534866333, acc: 0.6666666865348816)
[2024-12-14 02:38:39,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:39,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:39,564][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.17272056639194489, acc: 0.9583333134651184)
[2024-12-14 02:38:39,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:39,878][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.08381380140781403, acc: 1.0)
[2024-12-14 02:38:39,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:39,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:40,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:40,197][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.18548919260501862, acc: 1.0)
[2024-12-14 02:38:40,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:40,458][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.4886455237865448, acc: 0.875)
[2024-12-14 02:38:40,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:40,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:40,936][slam_, acc: 0.8484848737716675)
[2024-12-14 02:38:41,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:41,234][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 1.7696712017059326, acc: 0.47422680258750916)
[2024-12-14 02:38:41,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:41,523][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 1.0334821939468384, acc: 0.6428571343421936)
[2024-12-14 02:38:41,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:41,881][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 1.7700285911560059, acc: 0.4883720874786377)
[2024-12-14 02:38:41,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:42,235][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 1.276330828666687, acc: 0.5535714030265808)
                                                                               [2024-12-14 02:38:42,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:42,614][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 1.5653666257858276, acc: 0.5802469253540039)
                                                                               [2024-12-14 02:38:42,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:42,934][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.9123111367225647, acc: 0.7777777910232544)
                                                                               [2024-12-14 02:38:43,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:43,294][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.3809855878353119, acc: 0.875)
[2024-12-14 02:38:43,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:43,659][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.549835205078125, acc: 0.8461538553237915)
                                                                                                                                                                          [2024-12-14 02:38:43,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:44,039][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.6737609505653381, acc: 0.8260869383811951)
                                                                 [2024-12-14 02:38:44,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:44,390][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 1.14657723903656, acc: 0.6190476417541504)
                                                                                [2024-12-14 02:38:44,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:44,774][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 1.3547407388687134, acc: 0.6626505851745605)
[2024-12-14 02:38:44,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:45,137][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 1.1313821077346802, acc: 0.630630612373352)
                      [2024-12-14 02:38:45,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:45,470][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 1.4060612916946411, acc: 0.6213592290878296)
[2024-12-14 02:38:45,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:45,803][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 1.1386313438415527, acc: 0.6991869807243347)
[2024-12-14 02:38:45,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:46,219][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.4904632568359375, acc: 0.875)
[2024-12-14 02:38:46,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:46,584][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.6459155082702637, acc: 0.8214285969734192)
[2024-12-14 02:38:46,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:46,979][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 1.6875605583190918, acc: 0.5392156839370728)
[2024-12-14 02:38:47,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:47,356][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 1.9345332384109497, acc: 0.4628821015357971)
[2024-12-14 02:38:47,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:47,675][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 1.603193759918213, acc: 0.5625)
              [2024-12-14 02:38:47,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:47,994][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 1.8080551624298096, acc: 0.5214723944664001)
                                                                               [2024-12-14 02:38:48,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:48,368][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 1.7054634094238281, acc: 0.5395683646202087)
                                                                                                                                                   [2024-12-14 02:38:48,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:48,735][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 1.9740403890609741, acc: 0.45728641748428345)
                                                                              [2024-12-14 02:38:48,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:49,044][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.6006712317466736, acc: 0.7777777910232544)
[2024-12-14 02:38:49,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:49,366][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.6291489005088806, acc: 0.7878788113594055)
                                                                [2024-12-14 02:38:49,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:49,667][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.4942625164985657, acc: 0.8518518805503845)
[2024-12-14 02:38:49,752][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:38:50,004][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.6788135766983032, acc: 0.75)
[2024-12-14 02:38:50,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:50,321][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.38927915692329407, acc: 0.8999999761581421)
                                                                                                                  [2024-12-14 02:38:50,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:50,709][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 0.8299504518508911, acc: 0.7241379022598267)
                                                                               [2024-12-14 02:38:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:51,081][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.3617165982723236, acc: 0.9354838728904724)
                                                                                [2024-12-14 02:38:51,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:51,473][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.23443272709846497, acc: 0.8947368264198303)
[2024-12-14 02:38:51,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:51,827][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 0.818213939666748, acc: 0.7037037014961243)
[2024-12-14 02:38:51,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:52,234][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.8113749623298645, acc: 0.761904776096344)
O] - modality encoder
[2024-12-14 02:38:52,214][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 2.001830577850342, acc: 0.4930555522441864)
[2024-12-14 02:38:52,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:52,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:52,566][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.9409590363502502, acc: 0.6976743936538696)
[2024-12-14 02:38:52,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:52,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:52,940][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.4431978762149811, acc: 0.9166666865348816)
[2024-12-14 02:38:53,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:53,284][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.7075496315956116, acc: 0.8139534592628479)
[2024-12-14 02:38:53,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:53,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:53,625][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.4880813956260681, acc: 0.8399999737739563)
[2024-12-14 02:38:53,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:53,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:54,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:54,159][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 1.3340712785720825, acc: 0.5882353186607361)
[2024-12-14 02:38:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:54,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:54,512][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 1.4087393283843994, acc: 0.5600000023841858)
[2024-12-14 02:38:54,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:54,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:54,861][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.6473256349563599, acc: 0.8181818127632141)
[2024-12-14 02:38:54,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:55,184][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.7677786350250244, acc: 0.9090909361839294)
[2024-12-14 02:38:55,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:55,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:55,559][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.16473443806171417, acc: 0.9354838728904724)
[2024-12-14 02:38:55,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:55,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:55,951][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.3508135974407196, acc: 0.8518518805503845)
[2024-12-14 02:38:56,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:56,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:56,293][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.15758100152015686, acc: 0.9599999785423279)
[2024-12-14 02:38:56,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:56,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:56,624][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.4550861716270447, acc: 0.8333333134651184)
[2024-12-14 02:38:56,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:56,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:56,955][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.36823388934135437, acc: 0.8888888955116272)
[2024-12-14 02:38:57,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:57,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:57,358][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.564445436000824, acc: 0.8799999952316284)
  [2024-12-14 02:38:57,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:57,704][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.22807273268699646, acc: 0.9230769276618958)
                                                                              [2024-12-14 02:38:57,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:58,069][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.42627644538879395, acc: 0.8518518805503845)
                                                                               [2024-12-14 02:38:58,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:58,420][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.597043514251709, acc: 0.8148148059844971)
                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:38:58,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:58,774][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.9198415279388428, acc: 0.6603773832321167)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:38:58,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:59,125][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.4889805316925049, acc: 0.8965517282485962)
                                                                                                                                          [2024-12-14 02:38:59,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:38:59,720][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.5618025064468384, acc: 0.5405405163764954)
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:38:59,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:00,172][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 1.3661736249923706, acc: 0.6760563254356384)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:39:00,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:00,483][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.12213772535324097, acc: 0.949999988079071)
[2024-12-14 02:39:00,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:00,837][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.2394172102212906, acc: 0.9333333373069763)
                                                                               [2024-12-14 02:39:00,931][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:39:01,173][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.392642617225647, acc: 0.8846153616905212)
[2024-12-14 02:39:02,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:03,851][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 1.6854445934295654, acc: 0.5642856955528259)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:39:04,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:04,619][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 1.4871845245361328, acc: 0.6111111044883728)
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:39:04,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:05,011][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.44634103775024414, acc: 0.8571428656578064)
                                                                              [2024-12-14 02:39:05,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:05,387][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 1.0062429904937744, acc: 0.7333333492279053)
                                                                               [2024-12-14 02:39:05,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:06,087][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 1.1167948246002197, acc: 0.6944444179534912)
[2024-12-14 02:39:05,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:05,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:06,079][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 1.638742446899414, acc: 0.5412371158599854)
[2024-12-14 02:39:06,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:06,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:06,401][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 1.3646130561828613, acc: 0.6206896305084229)
[2024-12-14 02:39:06,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:06,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:06,844][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.7672982215881348, acc: 0.7777777910232544)
[2024-12-14 02:39:06,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:06,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:07,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:07,230][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.9265297055244446, acc: 0.7631579041481018)
[2024-12-14 02:39:07,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:07,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:07,602][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.6335382461547852, acc: 0.8035714030265808)
[2024-12-14 02:39:07,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:07,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:07,957][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.6548076272010803, acc: 0.78125)
[2024-12-14 02:39:08,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:08,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:08,312][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.9738249778747559, acc: 0.7169811129570007)
[2024-12-14 02:39:08,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:08,640][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.4132460057735443, acc: 0.8679245114326477)
[2024-12-14 02:39:08,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:08,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:08,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:09,048][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.46196526288986206, acc: 0.8823529481887817)
[2024-12-14 02:39:09,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:09,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:09,398][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.6839182376861572, acc: 0.875)
[2024-12-14 02:39:09,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:09,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:09,756][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.9326778650283813, acc: 0.7377049326896667)
[2024-12-14 02:39:09,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:09,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:10,066][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.2904756963253021, acc: 0.9333333373069763)
[2024-12-14 02:39:10,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:10,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:10,439][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.3305940330028534, acc: 0.8947368264198303)
[2024-12-14 02:39:10,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:10,678][slam_llm.models.slam_model][INFO[2024-12-14 02:39:10,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:11,081][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 1.6249911785125732, acc: 0.49180328845977783)
[2024-12-14 02:39:11,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:11,447][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 1.0527822971343994, acc: 0.7457627058029175)
                                                                                                 [2024-12-14 02:39:11,579][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:39:11,830][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 1.3820819854736328, acc: 0.604651153087616)
[2024-12-14 02:39:11,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:12,179][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 1.107680320739746, acc: 0.75)
                                                                                                                   [2024-12-14 02:39:12,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:12,514][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 1.106041431427002, acc: 0.6603773832321167)
 [2024-12-14 02:39:12,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:12,882][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.759164571762085, acc: 0.7727272510528564)
                                                                                                                                                 [2024-12-14 02:39:12,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:13,223][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.4733583331108093, acc: 0.8799999952316284)
[2024-12-14 02:39:13,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:13,619][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.5126088261604309, acc: 0.800000011920929)
                                                                                                                                                  [2024-12-14 02:39:13,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:13,960][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.38950327038764954, acc: 0.8636363744735718)
[2024-12-14 02:39:14,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:14,383][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 1.0193872451782227, acc: 0.7230769395828247)
                                                                                                                                                              [2024-12-14 02:39:14,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:14,719][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 0.9751772880554199, acc: 0.734375)
                                                                                         [2024-12-14 02:39:14,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:15,104][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.5600535869598389, acc: 0.90625)
                                                                                          [2024-12-14 02:39:15,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:15,455][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.64544677734375, acc: 0.8181818127632141)
[2024-12-14 02:39:15,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:15,828][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.2538701295852661, acc: 0.875)
                                                                                              [2024-12-14 02:39:15,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:16,195][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 0.9630661606788635, acc: 0.7037037014961243)
[2024-12-14 02:39:15,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:16,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:16,207][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 0.789770781993866, acc: 0.7714285850524902)
[2024-12-14 02:39:16,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:16,542][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.80050128698349, acc: 0.692307710647583)
[2024-12-14 02:39:16,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:16,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:16,918][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.2389235496520996, acc: 0.6341463327407837)
[2024-12-14 02:39:16,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:17,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:17,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:17,312][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.9133872985839844, acc: 0.7894737124443054)
[2024-12-14 02:39:17,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:17,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:17,692][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.1359214335680008, acc: 0.9473684430122375)
[2024-12-14 02:39:17,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:17,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:18,049][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.13072499632835388, acc: 0.9285714030265808)
[2024-12-14 02:39:18,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:18,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:18,404][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.5051898956298828, acc: 0.8148148059844971)
[2024-12-14 02:39:18,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:18,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:18,759][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.3021438717842102, acc: 0.90625)
[2024-12-14 02:39:18,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:19,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:19,137][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.9432032108306885, acc: 0.7096773982048035)
[2024-12-14 02:39:19,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:19,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:19,511][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.9493046998977661, acc: 0.719298243522644)
[2024-12-14 02:39:19,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:19,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:19,898][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 0.8539891242980957, acc: 0.75)
[2024-12-14 02:39:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:20,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:20,253][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.37251633405685425, acc: 0.8666666746139526)
[2024-12-14 02:39:20,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:20,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:20,586][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.3058478832244873, acc: 0.8947368264198303)
[2024-12-14 02:39:20,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:20,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:21,001][slam_llm.models.slam_modelch: 6/10, step 555/574 completed (loss: 1.8880773782730103, acc: 0.4714285731315613)
[2024-12-14 02:39:21,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:21,327][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 1.6914058923721313, acc: 0.503311276435852)
[2024-12-14 02:39:21,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:21,649][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 1.2684820890426636, acc: 0.6410256624221802)
                      [2024-12-14 02:39:21,736][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:39:21,991][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.09231182187795639, acc: 0.9599999785423279)
[2024-12-14 02:39:22,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:22,325][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.28591597080230713, acc: 0.9230769276618958)
[2024-12-14 02:39:22,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:22,689][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.267524778842926, acc: 0.9230769276618958)
                      [2024-12-14 02:39:22,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:23,031][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.7024585604667664, acc: 0.8205128312110901)
                                                                                                                                                                                                                       [2024-12-14 02:39:23,725][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:39:24,048][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:39:24,392][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:39:24,734][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:39:25,114][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:39:25,506][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:39:25,861][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:39:26,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:26,206][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 1.446288824081421, acc: 0.6279069781303406)
[2024-12-14 02:39:26,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:26,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:26,597][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.9330226182937622, acc: 0.7179487347602844)
[2024-12-14 02:39:26,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:26,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:26,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:26,998][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 1.2998119592666626, acc: 0.644444465637207)
[2024-12-14 02:39:27,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:27,311][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.46047309041023254, acc: 0.8260869383811951)
[2024-12-14 02:39:27,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:27,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:27,682][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.5786417722702026, acc: 0.807692289352417)
[2024-12-14 02:39:27,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:27,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:28,072][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 1.9059076309204102, acc: 0.450549453496933)
[2024-12-14 02:39:28,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:28,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:28,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:28,590][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 1.640602469444275, acc: 0.5652173757553101)
[2024-12-14 02:39:28,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:28,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:28,936][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 1.395022988319397, acc: 0.6195651888847351)
[2024-12-14 02:39:29,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:29,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:29,271][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 1.2877097129821777, acc: 0.6734693646430969)
[2024-12-14 02:39:29,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:29,584][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.06038912758231163, acc: 1.0)
[2024-12-14 02:39:29,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:29,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:29,981][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.26985684037208557, acc: 0.9230769276618958)
[2024-12-14 02:39:30,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:30,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:30,341][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.7761890888214111, acc: 0.7560975551605225)
[2024-12-14 02:39:30,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:30,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:30,678][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 1.0090550184249878, acc: 0.7111111283302307)
[2024-12-14 02:39:30,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:30,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:31,040][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 1.2600481510162354, acc: 0.7105262875556946)
[2024-12-14 02:39:31,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:31,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:31,427][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 1.003393530845642, acc: 0.6585366129875183)
[2024-12-14 02:39:31,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:31,805][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.7826675176620483, acc: 0.7878788113594055)
[2024-12-14 02:39:31,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:32,017][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.8295, device='cuda:0') eval_epoch_loss=tensor(1.7629, device='cuda:0') eval_epoch_acc=tensor(0.5871, device='cuda:0')
[2024-12-14 02:39:32,019][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:39:32,019][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:39:32,183][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.0698753222823143, acc: 0.9583333134651184)
[2024-12-14 02:39:32,228][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_6_step_419_loss_1.762932538986206/model.pt
[2024-12-14 02:39:32,231][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:39:32,232][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.5871275067329407
[2024-12-14 02:39:32,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:32,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:32,569][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.3326379358768463, acc: 0.800000011920929)
[2024-12-14 02:39:32,572][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.08702611923217773, acc: 0.95652174949646)
[2024-12-14 02:39:32,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:32,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:32,958][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.22133196890354156, acc: 0.8928571343421936)
[2024-12-14 02:39:32,958][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.11007209867238998, acc: 1.0)
[2024-12-14 02:39:33,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:33,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:33,298][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.5350167751312256, acc: 0.875)
[2024-12-14 02:39:33,339][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.7250611782073975, acc: 0.800000011920929)
[2024-12-14 02:39:33,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:33,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:33,682][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.31846824288368225, acc: 0.875)
[2024-12-14 02:39:33,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:33,900][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 1.6183491945266724, acc: 0.5636363625526428)
[2024-12-14 02:39:34,022][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.5100528597831726, acc: 0.8611111044883728)
[2024-12-14 02:39:34,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:34,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:34,394][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.21229188144207, acc: 0.8888888955116272)
[2024-12-14 02:39:34,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:34,742][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 1.1079702377319336, acc: 0.6886792182922363)
[2024-12-14 02:39:34,756][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.3490782082080841, acc: 0.939393937587738)
[2024-12-14 02:39:34,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:34,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:35,083][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 1.1604998111724854, acc: 0.6666666865348816)
[2024-12-14 02:39:35,137][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.09340731054544449, acc: 1.0)
[2024-12-14 02:39:35,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:35,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:35,403][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.8770424723625183, acc: 0.7142857313156128)
[2024-12-14 02:39:35,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:35,501][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.5644102096557617, acc: 0.8648648858070374)
[2024-12-14 02:39:35,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:35,734][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.44911497831344604, acc: 0.8857142925262451)
[2024-12-14 02:39:35,818][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.33708158135414124, acc: 0.8888888955116272)
[2024-12-14 02:39:35,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:35,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:36,077][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.0814368948340416, acc: 1.0)
[2024-12-14 02:39:36,128][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.525285542011261, acc: 0.8695651888847351)
[2024-12-14 02:39:36,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:36,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:36,465][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.029292955994606018, acc: 1.0)
[2024-12-14 02:39:36,500][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.09487870335578918, acc: 0.95652174949646)
[2024-12-14 02:39:36,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:36,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:36,843][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.10933799296617508, acc: 0.9259259104728699)
[2024-12-14 02:39:36,890][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.6526477336883545, acc: 0.7916666865348816)
[2024-12-14 02:39:36,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:37,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:37,214][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.42086583375930786, acc: 0.8695651888847351)
[2024-12-14 02:39:37,272][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 1.2193151712417603, acc: 0.6526315808296204)
[2024-12-14 02:39:37,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:37,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:37,593][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.7994140982627869, acc: 0.7777777910232544)
[2024-12-14 02:39:37,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:37,849][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 1.3994991779327393, acc: 0.6107784509658813)
[2024-12-14 02:39:37,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:37,987][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.44985848665237427, acc: 0.9200000166893005)
[2024-12-14 02:39:38,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:38,255][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 1.2127951383590698, acc: 0.6390977501869202)
[2024-12-14 02:39:38,380][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.7194589972496033, acc: 0.7878788113594055)
[2024-12-14 02:39:38,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:38,716][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 0.8349641561508179, acc: 0.7777777910232544)
[2024-12-14 02:39:38,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:38,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:39,083][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.971860945224762, acc: 0.75)
[2024-12-14 02:39:39,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:39,425][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.21491536498069763, acc: 0.9523809552192688)
[2024-12-14 02:39:39,501][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 1.4347838163375854, acc: 0.5935828685760498)
[2024-12-14 02:39:39,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:39,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:39,777][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 1.2813546657562256, acc: 0.6666666865348816)
[2024-12-14 02:39:39,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:40,064][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 1.0134481191635132, acc: 0.7567567825317383)
[2024-12-14 02:39:40,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:40,221][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 1.6274524927139282, acc: 0.6060606241226196)
[2024-12-14 02:39:40,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:40,478][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.4481220543384552, acc: 0.8928571343421936)
[2024-12-14 02:39:40,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:40,799][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.1828400194644928, acc: 0.9285714030265808)
[2024-12-14 02:39:40,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:40,913][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 2.253488779067993, acc: 0.4000000059604645)
[2024-12-14 02:39:41,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:41,063][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.8987593650817871, acc: 0.78125)
[2024-12-14 02:39:41,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:41,323][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 1.9838258028030396, acc: 0.47580644488334656)
[2024-12-14 02:39:41,326][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.3502824902534485, acc: 0.8888888955116272)
[2024-12-14 02:39:41,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:41,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:41,602][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.3425584137439728, acc: 0.8947368264198303)
[2024-12-14 02:39:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:41,971][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.02208315022289753, acc: 1.0)
[2024-12-14 02:39:41,975][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 1.843991994857788, acc: 0.4875621795654297)
[2024-12-14 02:39:42,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:42,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:42,343][root][INFO] - Training Epoch: 6/10, step 444/574 comp[2024-12-14 02:39:42,609][slam_llm.models.slam_model][INFO] - modality encoder
355][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.39662522077560425, acc: 0.8500000238418579)
[2024-12-14 02:39:42,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:42,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:42,728][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.43927279114723206, acc: 0.9047619104385376)
[2024-12-14 02:39:42,774][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.6852483153343201, acc: 0.8181818127632141)
[2024-12-14 02:39:42,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:42,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:43,116][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 1.40805184841156, acc: 0.6111111044883728)
[2024-12-14 02:39:43,166][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.32128411531448364, acc: 0.9130434989929199)
[2024-12-14 02:39:43,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:43,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:43,491][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 1.9291857481002808, acc: 0.5048543810844421)
[2024-12-14 02:39:43,531][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.5955568552017212, acc: 0.807692289352417)
[2024-12-14 02:39:43,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:43,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:43,900][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.4336269199848175, acc: 0.8571428656578064)
[2024-12-14 02:39:44,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:44,009][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 1.6889899969100952, acc: 0.5661764740943909)
[2024-12-14 02:39:44,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:44,272][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 1.3386744260787964, acc: 0.641791045665741)
[2024-12-14 02:39:44,354][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 1.9617834091186523, acc: 0.46666666865348816)
[2024-12-14 02:39:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:44,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:44,661][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 1.1477264165878296, acc: 0.6111111044883728)
[2024-12-14 02:39:44,724][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 1.9212021827697754, acc: 0.4930555522441864)
[2024-12-14 02:39:44,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:44,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:45,018][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 1.2302989959716797, acc: 0.6739130616188049)
[2024-12-14 02:39:45,048][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.9654721021652222, acc: 0.7906976938247681)
[2024-12-14 02:39:45,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:45,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:45,348][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 1.3020951747894287, acc: 0.6153846383094788)
[2024-12-14 02:39:45,372][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.33158794045448303, acc: 0.9583333134651184)
[2024-12-14 02:39:45,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:45,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:45,708][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 1.322833776473999, acc: 0.5789473652839661)
[2024-12-14 02:39:45,788][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.7943801283836365, acc: 0.8139534592628479)
[2024-12-14 02:39:45,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:46,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:46,090][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 1.0121949911117554, acc: 0.6734693646430969)
[2024-12-14 02:39:46,169][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.4772645831108093, acc: 0.8399999737739563)
[2024-12-14 02:39:46,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:46,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:46,429][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.5982733964920044, acc: 0.7575757503509521)
[2024-12-14 02:39:46,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:46,738][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 1.3209056854248047, acc: 0.6176470518112183)
[2024-12-14 02:39:46,762][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 1.6583856344223022, acc: 0.5670102834701538)
[2024-12-14 02:39:46,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:46,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:47,098][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 1.0047301054000854, acc: 0.6857143044471741)
[2024-12-14 02:39:47,142][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 1.2915880680084229, acc: 0.6133333444595337)
[2024-12-14 02:39:47,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:47,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:47,485][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 1.606633186340332, acc: 0.5639534592628479)
[2024-12-14 02:39:47,493][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.7289334535598755, acc: 0.7575757503509521)
[2024-12-14 02:39:47,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:47,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:47,827][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 1.27615487575531, acc: 0.5535714030265808)
[2024-12-14 02:39:47,833][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.444855660200119, acc: 0.8787878751754761)
[2024-12-14 02:39:47,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:47,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:48,182][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 1.4723373651504517, acc: 0.5802469253540039)
[2024-12-14 02:39:48,197][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.14259356260299683, acc: 0.9354838728904724)
[2024-12-14 02:39:48,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:48,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:48,552][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.7810113430023193, acc: 0.7777777910232544)
[2024-12-14 02:39:48,589][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.35329529643058777, acc: 0.8888888955116272)
[2024-12-14 02:39:48,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:48,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:48,933][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.5709335803985596, acc: 0.875)
[2024-12-14 02:39:48,933][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.18578670918941498, acc: 0.9599999785423279)
[2024-12-14 02:39:49,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:49,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:49,267][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.29118242859840393, acc: 0.9230769276618958)
[2024-12-14 02:39:49,287][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.42747819423675537, acc: 0.9166666865348816)
[2024-12-14 02:39:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:49,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:49,640][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.499685674905777, acc: 0.8148148059844971)
[2024-12-14 02:39:49,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:49,675][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.7343644499778748, acc: 0.804347813129425)
[2024-12-14 02:39:49,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:49,896][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.19882512092590332, acc: 0.9615384340286255)
[2024-12-14 02:39:49,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:50,065][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 1.0432049036026, acc: 0.6785714030265808)
[2024-12-14 02:39:50,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:50,254][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.890932023525238, acc: 0.6896551847457886)
[2024-12-14 02:39:50,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:50,404][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 1.3608789443969727, acc: 0.6385542154312134)
[2024-12-14 02:39:50,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:50,590][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.34789589047431946, acc: 0.9285714030265808)
[2024-12-14 02:39:50,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:50,774][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 1.1628962755203247, acc: 0.6126126050949097)
[2024-12-14 02:39:50,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:50,976][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.3344445526599884, acc: 0.8666666746139526)
[2024-12-14 02:39:51,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:51,150][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 1.317025899887085, acc: 0.6310679316520691)
[2024-12-14 02:39:51,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:51,282][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.1780899614095688, acc: 0.9696969985961914)
[2024-12-14 02:39:51,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:51,543][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 1.1610435247421265, acc: 0.6666666865348816)
[2024-12-14 02:39:51,604][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.25198647379875183, acc: 0.9090909361839294)
[2024-12-14 02:39:51,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:51,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:51,899][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.4553094804286957, acc: 0.7916666865348816)
[2024-12-14 02:39:51,982][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 1.1481770277023315, acc: 0.6470588445663452)
[2024-12-14 02:39:51,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:52,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:52,209][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.7262545228004456, acc: 0.8571428656578064)
[2024-12-14 02:39:52,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:52,365][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 0.6497009992599487, acc: 0.807692289352417)
[2024-12-14 02:39:52,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:52,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:53,282][slam_llm.models.slam_model][INFO] - modality encoder
701][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.37232184410095215, acc: 0.9444444179534912)
[2024-12-14 02:39:52,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:52,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:53,068][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 1.9442405700683594, acc: 0.47598254680633545)
[2024-12-14 02:39:53,088][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.93305903673172, acc: 0.6499999761581421)
[2024-12-14 02:39:53,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:53,475][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 1.5529576539993286, acc: 0.5520833134651184)
[2024-12-14 02:39:53,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:53,828][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 1.7995891571044922, acc: 0.4907975494861603)
[2024-12-14 02:39:53,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:53,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:54,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:54,202][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 1.7813172340393066, acc: 0.5107913613319397)
                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:39:54,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:54,619][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 2.0387699604034424, acc: 0.4522612988948822)
[2024-12-14 02:39:54,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:54,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:54,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:55,021][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.5307140350341797, acc: 0.8333333134651184)
[2024-12-14 02:39:55,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:55,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:55,429][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.6555566787719727, acc: 0.8181818127632141)
[2024-12-14 02:39:55,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:55,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:55,797][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.49698007106781006, acc: 0.9259259104728699)
[2024-12-14 02:39:55,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:56,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:56,149][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.6724368333816528, acc: 0.699999988079071)
[2024-12-14 02:39:56,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:56,471][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.39395639300346375, acc: 0.8500000238418579)
[2024-12-14 02:39:56,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:56,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:56,848][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 0.7770904898643494, acc: 0.7413793206214905)
[2024-12-14 02:39:56,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:56,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:57,124][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.39657968282699585, acc: 0.8709677457809448)
[2024-12-14 02:39:57,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:57,275][slam_llm.models.slam_model][INFO[2024-12-14 02:39:57,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:57,815][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 1.0119295120239258, acc: 0.7008547186851501)
[2024-12-14 02:39:57,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:58,152][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 1.8580795526504517, acc: 0.4897959232330322)
[2024-12-14 02:39:58,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12lity encoder
[2024-12-14 02:39:58,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:58,251][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.5673466920852661, acc: 0.9047619104385376)
[2024-12-14 02:39:58,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:58,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:58,619][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 0.383510947227478, acc: 0.9090909361839294)
[2024-12-14 02:39:58,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:58,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:58,995][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 1.3682094812393188, acc: 0.5538461804389954)
[2024-12-14 02:39:59,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:59,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:59,382][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.763146698474884, acc: 0.800000011920929)
                                                                [2024-12-14 02:39:59,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:59,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:59,765][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 0.6181498765945435, acc: 0.7931034564971924)
[2024-12-14 02:39:59,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:39:59,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:00,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:00,148][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 1.3759119510650635, acc: 0.5686274766921997)
[2024-12-14 02:40:00,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:00,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:00,521][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 0.8306224942207336, acc: 0.7241379022598267)
[2024-12-14 02:40:00,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:00,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:00,933][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.28166189789772034, acc: 0.9473684430122375)
[2024-12-14 02:40:01,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:01,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:01,324][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.6864604353904724, acc: 0.7368420958518982)
[2024-12-14 02:40:01,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:01,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:01,684][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 1.4954633712768555, acc: 0.5535714030265808)
[2024-12-14 02:40:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:02,068][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 1.4292500019073486, acc: 0.5955055952072144)
[2024-12-14 02:40:02,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:02,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:02,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:02,431][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 1.6163127422332764, acc: 0.5617977380752563)
[2024-12-14 02:40:02,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:02,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:02,760][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 1.935563325881958, acc: 0.42553192377090454)
[2024-12-14 02:40:02,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:03,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:03,154][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 1.6824145317077637, acc: 0.52173912525177)
[2024-12-14 02:40:03,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:03,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:03,537][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.22872354090213776, acc: 0.8799999952316284)
[2024-12-14 02:40:03,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:03,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:03,879][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.2834216356277466, acc: 0.8846153616905212)
[2024-12-14 02:40:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:04,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:04,228][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.3417445421218872, acc: 0.9629629850387573)
[2024-12-14 02:40:04,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:04,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:04,579][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.6355780959129333, acc: 0.7777777910232544)
[2024-12-14 02:40:04,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:04,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:04,912][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.9890876412391663, acc: 0.6415094137191772)
[2024-12-14 02:40:05,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:05,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:05,264][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.5304135680198669, acc: 0.7586206793785095)
[2024-12-14 02:40:05,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:05,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:05,849][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.582057237625122, acc: 0.5405405163764954)
[2024-12-14 02:40:05,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:06,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:06,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:06,299][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 1.3852039575576782, acc: 0.6478873491287231)
[2024-12-14 02:40:06,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:06,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:06,612][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.11142556369304657, acc: 0.949999988079071)
[2024-12-14 02:40:06,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:06,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:06,906][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.23307417333126068, acc: 0.8999999761581421)
[2024-12-14 02:40:06,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:07,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:07,205][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.34666532278060913, acc: 0.9230769276618958)
[2024-12-14 02:40:07,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:07,860][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:40:08,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:08,309][slam_llm.models.slam_model][INFO] - modality encoder
                                                        [2024-12-14 02:40:08,440][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:40:08,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:08,764][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.4696117639541626, acc: 0.875)
[2024-12-14 02:40:08,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:09,180][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 1.2437299489974976, acc: 0.6415094137191772)
[2024-12-14 02:40:09,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:09,588][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 1.5482134819030762, acc: 0.6027397513389587)
[2024-12-14 02:40:10,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:10,844][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 2.103437662124634, acc: 0.4545454680919647)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:40:10,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:11,136][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.7867251634597778, acc: 0.7209302186965942)
                                                                                [2024-12-14 02:40:11,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:11,519][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 1.3508323431015015, acc: 0.650602400302887)
[2024-12-14 02:40:11,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:11,894][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 1.353689193725586, acc: 0.5925925970077515)
[2024-12-14 02:40:12,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:12,261][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.41747069358825684, acc: 0.8214285969734192)
                                                                                 [2024-12-14 02:40:12,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:12,636][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.4084378778934479, acc: 0.8888888955116272)
                                                                               [2024-12-14 02:40:12,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:13,024][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.2563161551952362, acc: 0.95652174949646)
                                                                                  [2024-12-14 02:40:13,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:13,420][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 1.535354495048523, acc: 0.5966386795043945)
                                                                                                                                                                [2024-12-14 02:40:13,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:13,810][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.8225624561309814, acc: 0.7540983557701111)
[2024-12-14 02:40:13,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:14,161][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 1.1066303253173828, acc: 0.6666666865348816)
[2024-12-14 02:40:14,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:14,459][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 1.2220458984375, acc: 0.6101694703102112)
    [2024-12-14 02:40:14,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:14,804][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 1.0597257614135742, acc: 0.7126436829566956)
[2024-12-14 02:40:14,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:15,165][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.30201536417007446, acc: 0.9047619104385376)
                    [2024-12-14 02:40:15,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:15,530][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.4030502438545227, acc: 0.8846153616905212)
[2024-12-14 02:40:15,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:15,913][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 1.4147224426269531, acc: 0.5675675868988037)
                                                                                [2024-12-14 02:40:16,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:16,325][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 1.3580008745193481, acc: 0.6307692527770996)
                                                                                                                                                               [2024-12-14 02:40:16,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:16,813][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 1.4240134954452515, acc: 0.6262626051902771)
                                                                                                                                                              [2024-12-14 02:40:16,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:17,229][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 1.2568107843399048, acc: 0.6494845151901245)
                                                                                                                                         [2024-12-14 02:40:17,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:17,633][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 1.5744054317474365, acc: 0.5661764740943909)
                                                                                [2024-12-14 02:40:17,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:17,945][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.35608312487602234, acc: 0.9615384340286255)
[2024-12-14 02:40:18,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:18,317][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.09157716482877731, acc: 0.9629629850387573)
                                                                                                                                                             [2024-12-14 02:40:18,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:18,665][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.5271220207214355, acc: 0.8214285969734192)
                                                                                [2024-12-14 02:40:18,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:19,046][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.36907967925071716, acc: 0.9444444179534912)
                                                                               [2024-12-14 02:40:19,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:19,461][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.9866522550582886, acc: 0.6666666865348816)
                                                                               [2024-12-14 02:40:19,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:19,807][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.8889893889427185, acc: 0.7301587462425232)
                                                                                [2024-12-14 02:40:19,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:20,158][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 1.2095320224761963, acc: 0.6619718074798584)
                                                                                [2024-12-14 02:40:20,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:20,609][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.828039526939392, acc: 0.5266666412353516)
                                                                                                                                                   [2024-12-14 02:40:20,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:20,939][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.5761131048202515, acc: 0.837837815284729)
[2024-12-14 02:40:21,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:21,316][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.22203446924686432, acc: 0.9230769276618958)
                                                                     [2024-12-14 02:40:22,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:24,268][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 1.6541674137115479, acc: 0.5870307087898254)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:40:24,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:25,561][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 2.2137038707733154, acc: 0.4117647111415863)
evice='cuda:0') eval_epoch_acc=tensor(0.5878, device='cuda:0')
[2024-12-14 02:40:24,305][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:40:24,305][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:40:24,535][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.2529408633708954, acc: 0.9200000166893005)
[2024-12-14 02:40:24,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:24,688][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_6_step_419_loss_1.8294697999954224/model.pt
[2024-12-14 02:40:24,694][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:40:24,695][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.5878177881240845
[2024-12-14 02:40:24,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:24,872][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.26636460423469543, acc: 0.9696969985961914)
[2024-12-14 02:40:24,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:25,128][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.3110423684120178, acc: 0.8999999761581421)
[2024-12-14 02:40:25,199][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.3048972189426422, acc: 0.8999999761581421)
[2024-12-14 02:40:25,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:25,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:25,516][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.04223749041557312, acc: 1.0)
[2024-12-14 02:40:25,567][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.5345691442489624, acc: 0.8714285492897034)
[2024-12-14 02:40:25,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:25,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:25,879][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.4300316870212555, acc: 0.8666666746139526)
[2024-12-14 02:40:25,936][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 1.8003599643707275, acc: 0.49635037779808044)
[2024-12-14 02:40:25,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:26,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:26,284][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 1.3441996574401855, acc: 0.6068965792655945)
[2024-12-14 02:40:26,290][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.2735627591609955, acc: 0.90625)
[2024-12-14 02:40:26,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:26,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:26,640][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.49034371972084045, acc: 0.8055555820465088)
[2024-12-14 02:40:26,654][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 1.937680721282959, acc: 0.5142857432365417)
[2024-12-14 02:40:26,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:26,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:26,956][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.4643316864967346, acc: 0.7777777910232544)
[2024-12-14 02:40:27,017][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 1.7313456535339355, acc: 0.4900662302970886)
[2024-12-14 02:40:27,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:27,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:27,271][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.4317114055156708, acc: 0.9090909361839294)
[2024-12-14 02:40:27,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:27,409][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 1.2173455953598022, acc: 0.632478654384613)
[2024-12-14 02:40:27,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:27,649][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.25960397720336914, acc: 0.95652174949646)
[2024-12-14 02:40:27,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:28,133][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.3123962879180908, acc: 0.9117646813392639)
                                                                                                                                                                                                                        [2024-12-14 02:40:28,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:28,564][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 0.7176547646522522, acc: 0.7777777910232544)
                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:40:28,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:28,984][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.7454457879066467, acc: 0.78125)
                                                                                          [2024-12-14 02:40:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:29,346][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.21140065789222717, acc: 0.931034505367279)
                                                                                                                                                                                                                                                                       [2024-12-14 02:40:29,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:29,710][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 1.1725599765777588, acc: 0.6785714030265808)
                                                                               [2024-12-14 02:40:29,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:30,109][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 1.3318554162979126, acc: 0.6333333253860474)
                                                                                [2024-12-14 02:40:30,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:30,497][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.262708842754364, acc: 0.9200000166893005)
                                                                                                                                                                 [2024-12-14 02:40:30,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:30,842][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.4660528898239136, acc: 0.8055555820465088)
 [2024-12-14 02:40:30,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:31,228][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.5142297744750977, acc: 0.7575757503509521)
                                                                                [2024-12-14 02:40:31,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:31,641][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 1.5657447576522827, acc: 0.5661764740943909)
                                                                                                                                                               [2024-12-14 02:40:31,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:32,040][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 1.5769261121749878, acc: 0.579365074634552)
                                                                                                                                                                 [2024-12-14 02:40:32,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:32,387][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 1.865776777267456, acc: 0.4871794879436493)
 [2024-12-14 02:40:32,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:32,706][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 1.2010964155197144, acc: 0.6428571343421936)
[2024-12-14 02:40:32,835][slam_llm.models.slam_model][INFO] - modality encoder
 [2024-12-14 02:40:33,080][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 1.9254910945892334, acc: 0.4253731369972229)
[2024-12-14 02:40:33,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:33,472][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 2.0318329334259033, acc: 0.47445255517959595)
[2024-12-14 02:40:33,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:33,847][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.08451443165540695, acc: 1.0)
[2024-12-14 02:40:33,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:34,187][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.2013375163078308, acc: 0.9166666865348816)
[2024-12-14 02:40:34,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:34,543][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.35897666215896606, acc: 0.8787878751754761)
[2024-12-14 02:40:34,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:34,922][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.24389778077602386, acc: 0.9230769276618958)
[2024-12-14 02:40:35,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:35,286][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.9958308339118958, acc: 0.6730769276618958)
                      [2024-12-14 02:40:35,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:35,613][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 0.9819008111953735, acc: 0.692307710647583)
                                                                 [2024-12-14 02:40:35,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:35,991][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.2696884274482727, acc: 0.90625)
                                                                                                                                                                       [2024-12-14 02:40:36,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:36,376][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 1.1924859285354614, acc: 0.6666666865348816)
                                                                                [2024-12-14 02:40:36,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:36,768][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.7397595047950745, acc: 0.800000011920929)
                                                                                  [2024-12-14 02:40:36,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:37,169][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.25896158814430237, acc: 0.8695651888847351)
                                                                              [2024-12-14 02:40:37,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:37,653][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 1.1765522956848145, acc: 0.6600000262260437)
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:40:37,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:38,071][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 1.2290669679641724, acc: 0.6407766938209534)
                                                                                [2024-12-14 02:40:38,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:39,214][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 1.5965653657913208, acc: 0.582524299621582)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:40:39,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:40,036][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.72048020362854, acc: 0.5161290168762207)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:40:40,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:40,841][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 1.5923060178756714, acc: 0.5991379022598267)
                                                                                                                                                                                                                                                                                           [2024-12-14 02:40:41,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:41,590][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 1.0338324308395386, acc: 0.7052631378173828)
                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:40:41,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:42,583][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 1.7190113067626953, acc: 0.5247524976730347)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:40:42,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:42,866][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 1.5027439594268799, acc: 0.5806451439857483)
                                                                                [2024-12-14 02:40:42,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:43,267][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 1.1806243658065796, acc: 0.6666666865348816)
                                                                                [2024-12-14 02:40:43,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:43,646][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 1.8243093490600586, acc: 0.48739495873451233)
[2024-12-14 02:40:43,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:44,050][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 1.7645407915115356, acc: 0.4326923191547394)
                                                                                                                                                               [2024-12-14 02:40:44,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:44,447][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 1.80936598777771, acc: 0.48905110359191895)
                                                                                                                                                                 [2024-12-14 02:40:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:44,817][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 1.3321537971496582, acc: 0.5223880410194397)
  [2024-12-14 02:40:44,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:45,201][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.178483247756958, acc: 0.949999988079071)
                                                                                                                                                               [2024-12-14 02:40:45,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:45,556][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.1331605315208435, acc: 0.9545454382896423)
[2024-12-14 02:40:45,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:45,921][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.2494277060031891, acc: 0.95652174949646)
                                                                               [2024-12-14 02:40:46,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:46,281][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.6186220645904541, acc: 0.8636363744735718)
                                                                               [2024-12-14 02:40:46,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:46,657][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 1.1607184410095215, acc: 0.5862069129943848)
                                                                                [2024-12-14 02:40:46,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:47,038][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.6720014810562134, acc: 0.8604651093482971)
                                                                              [2024-12-14 02:40:47,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:47,396][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.46969345211982727, acc: 0.8799999952316284)
                                                                             [2024-12-14 02:40:47,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:47,803][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.07191671431064606, acc: 1.0)
                                                                                             [2024-12-14 02:40:47,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:48,156][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.05714046210050583, acc: 1.0)
                                                                                                                                                                            [2024-12-14 02:40:48,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:48,473][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.5409083366394043, acc: 0.8333333134651184)
                                                                              [2024-12-14 02:40:48,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:48,891][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 1.156455636024475, acc: 0.6615384817123413)
 [2024-12-14 02:40:49,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:49,308][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 1.0688472986221313, acc: 0.7543859481811523)
                                                                                                                                                                                                                                             [2024-12-14 02:40:49,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:49,706][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.9168919920921326, acc: 0.719298243522644)
                                                                                 [2024-12-14 02:40:49,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:50,092][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.8782179355621338, acc: 0.7435897588729858)
                                                                               [2024-12-14 02:40:50,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:50,467][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.7962572574615479, acc: 0.7755101919174194)
                                                                               [2024-12-14 02:40:50,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:50,760][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.07426147907972336, acc: 0.9545454382896423)
                                                                              [2024-12-14 02:40:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:51,157][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 1.1681816577911377, acc: 0.6666666865348816)
[2024-12-14 02:40:51,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:51,526][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 1.4114335775375366, acc: 0.6341463327407837)
                                                                               [2024-12-14 02:40:51,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:51,873][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 1.044711947441101, acc: 0.6935483813285828)
                                                                               [2024-12-14 02:40:52,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:52,776][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 1.847017526626587, acc: 0.4942965805530548)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:40:52,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:52,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:53,127][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.46179646253585815, acc: 0.8421052694320679)
[2024-12-14 02:40:53,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:53,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:53,477][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.8518786430358887, acc: 0.7368420958518982)
[2024-12-14 02:40:53,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:53,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:53,907][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 1.4212206602096558, acc: 0.6696428656578064)
[2024-12-14 02:40:54,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:54,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:54,306][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 1.3389027118682861, acc: 0.6404494643211365)
[2024-12-14 02:40:54,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:54,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:54,659][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 1.6108262538909912, acc: 0.5617977380752563)
[2024-12-14 02:40:54,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:54,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:55,001][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 1.942135214805603, acc: 0.4609929025173187)
[2024-12-14 02:40:55,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:55,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:55,352][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 1.6475600004196167, acc: 0.52173912525177)
[2024-12-14 02:40:55,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:55,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:55,632][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.3329124450683594, acc: 0.8399999737739563)
[2024-12-14 02:40:55,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:55,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:55,929][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.35991477966308594, acc: 0.9230769276618958)
[2024-12-14 02:40:56,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:56,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:56,285][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.37146297097206116, acc: 0.9259259104728699)
[2024-12-14 02:40:56,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:56,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:56,637][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.5976271033287048, acc: 0.8518518805503845)
[2024-12-14 02:40:56,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:56,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:57,006][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 1.021071195602417, acc: 0.7169811129570007)
[2024-12-14 02:40:57,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:57,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:57,355][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.5011894106864929, acc: 0.8965517282485962)
[2024-12-14 02:40:57,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:57,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:57,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:57,940][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.5413519144058228, acc: 0.5495495200157166)
[2024-12-14 02:40:58,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:58,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:58,372][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 1.1574952602386475, acc: 0.7183098793029785)
[2024-12-14 02:40:58,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:58,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:58,682][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.1653798520565033, acc: 0.8999999761581421)
[2024-12-14 02:40:58,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:58,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:58,992][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.30264124274253845, acc: 0.8666666746139526)
[2024-12-14 02:40:59,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:59,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:40:59,380][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.42911332845687866, acc: 0.807692289352417)
[2024-12-14 02:40:59,648][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.3667, device='cuda:0') eval_epoch_loss=tensor(1.8511, device='cuda:0') eval_epoch_acc=tensor(0.5679, device='cuda:0')
[2024-12-14 02:40:59,649][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:40:59,649][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:40:59,872][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_6_step_562_loss_1.8510814905166626/model.pt
[2024-12-14 02:40:59,875][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:40:59,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:00,246][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 1.2194831371307373, acc: 0.6777777671813965)
[2024-12-14 02:41:00,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:00,630][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.8326015472412109, acc: 0.7272727489471436)
[2024-12-14 02:41:00,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:01,026][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.4283179044723511, acc: 0.8958333134651184)
[2024-12-14 02:41:01,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:01,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:01,427][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.5003176331520081, acc: 0.8620689511299133)
[2024-12-14 02:41:01,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:01,782][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 1.3804783821105957, acc: 0.6071428656578064)
[2024-12-14 02:41:01,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:02,103][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.46715033054351807, acc: 0.8421052694320679)
[2024-12-14 02:41:02,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:02,373][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 1.7050997018814087, acc: 0.5071428418159485)
[2024-12-14 02:41:02,451][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.22320601344108582, acc: 0.8888888955116272)
[2024-12-14 02:41:03,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:02,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:02,875][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 1.5867578983306885, acc: 0.5561497211456299)
[2024-12-14 02:41:02,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:03,151][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 1.450378179550171, acc: 0.5634920597076416)
[2024-12-14 02:41:03,212][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.8346458077430725, acc: 0.725806474685669)
[2024-12-14 02:41:03,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:03,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:03,452][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.4574367105960846, acc: 0.9285714030265808)
[2024-12-14 02:41:03,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:03,634][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 1.1330618858337402, acc: 0.692307710647583)
[2024-12-14 02:41:03,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:03,831][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 1.043555498123169, acc: 0.7333333492279053)
[2024-12-14 02:41:03,966][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 1.806732177734375, acc: 0.48469388484954834)
[2024-12-14 02:41:04,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:04,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:04,308][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 1.7652254104614258, acc: 0.49685534834861755)
[2024-12-14 02:41:04,547][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 0.9885161519050598, acc: 0.7361111044883728)
[2024-12-14 02:41:04,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:04,784][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=2.6976, train_epoch_loss=0.9924, epoch time 360.43913146853447s
[2024-12-14 02:41:04,784][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:41:04,784][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-14 02:41:04,784][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:41:04,785][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 18
[2024-12-14 02:41:04,785][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 02:41:04,912][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.15423472225666046, acc: 1.0)
[2024-12-14 02:41:05,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:05,268][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.5986544489860535, acc: 0.8709677457809448)
[2024-12-14 02:41:05,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:05,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:05,617][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.5396062731742859, acc: 0.800000011920929)
[2024-12-14 02:41:05,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:05,787][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.5291879177093506, acc: 0.8518518805503845)
[2024-12-14 02:41:05,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:06,012][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.5056971907615662, acc: 0.7777777910232544)
[2024-12-14 02:41:06,168][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.4529092013835907, acc: 0.8399999737739563)
[2024-12-14 02:41:06,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:06,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:06,522][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 0.8503888845443726, acc: 0.7297297120094299)
[2024-12-14 02:41:06,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:06,899][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 0.6969808340072632, acc: 0.8157894611358643)
[2024-12-14 02:41:07,003][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 1.878719449043274, acc: 0.5042372941970825)
[2024-12-14 02:41:07,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:07,258][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.8058878183364868, acc: 0.7027027010917664)
[2024-12-14 02:41:07,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:07,398][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 1.5558313131332397, acc: 0.5223880410194397)
[2024-12-14 02:41:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:07,644][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.7439347505569458, acc: 0.7142857313156128)
[2024-12-14 02:41:07,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:07,791][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 1.7078988552093506, acc: 0.5328466892242432)
[2024-12-14 02:41:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:07,999][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 0.8352952003479004, acc: 0.7346938848495483)
[2024-12-14 02:41:08,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:08,361][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 1.6361404657363892, acc: 0.550000011920929)
[2024-12-14 02:41:08,380][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.3869909644126892, acc: 0.8666666746139526)
[2024-12-14 02:41:08,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:08,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:08,767][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 1.0590602159500122, acc: 0.6851851940155029)
[2024-12-14 02:41:08,799][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.03689837083220482, acc: 1.0)
[2024-12-14 02:41:08,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:09,149][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 0.9263597726821899, acc: 0.7115384340286255)
[2024-12-14 02:41:09,169][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.025736723095178604, acc: 1.0)
[2024-12-14 02:41:09,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:09,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:09,474][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.5608618855476379, acc: 0.8095238208770752)
[2024-12-14 02:41:09,515][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.3332630395889282, acc: 0.8888888955116272)
[2024-12-14 02:41:09,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:09,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:09,825][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 1.6620794534683228, acc: 0.5245901346206665)
[2024-12-14 02:41:09,884][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.6889260411262512, acc: 0.7692307829856873)
[2024-12-14 02:41:09,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:09,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:10,208][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 1.0386542081832886, acc: 0.7118644118309021)
[2024-12-14 02:41:10,495][slam_llm.models.slam_model][INFO] - modality encoder
eted (loss: 0.5305871963500977, acc: 0.7878788113594055)
[2024-12-14 02:41:10,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:10,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:10,583][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 1.249281883239746, acc: 0.6976743936538696)
[2024-12-14 02:41:10,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:10,708][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.6936702132225037, acc: 0.804347813129425)
[2024-12-14 02:41:10,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:10,955][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 0.9456104636192322, acc: 0.8181818127632141)
[2024-12-14 02:41:11,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:11,085][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 1.0451364517211914, acc: 0.7254902124404907)
[2024-12-14 02:41:11,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:11,311][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 1.1664425134658813, acc: 0.6415094137191772)
[2024-12-14 02:41:11,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:11,470][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.7627537250518799, acc: 0.795918345451355)
[2024-12-14 02:41:11,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:11,694][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.6891893744468689, acc: 0.8409090638160706)
[2024-12-14 02:41:11,791][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.347586989402771, acc: 0.8947368264198303)
[2024-12-14 02:41:11,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:11,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:12,038][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.4575135111808777, acc: 0.8799999952316284)
[2024-12-14 02:41:12,105][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.2652777433395386, acc: 0.9583333134651184)
[2024-12-14 02:41:12,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:12,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:12,326][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.21630966663360596, acc: 1.0)
[2024-12-14 02:41:12,405][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 0.6162790656089783, acc: 0.8055555820465088)
[2024-12-14 02:41:12,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:12,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:12,708][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.26038146018981934, acc: 0.9545454382896423)
[2024-12-14 02:41:12,709][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.25015580654144287, acc: 0.8421052694320679)
[2024-12-14 02:41:12,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:12,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:13,099][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.3087463676929474, acc: 0.9230769276618958)
[2024-12-14 02:41:13,136][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 1.0525614023208618, acc: 0.6769230961799622)
[2024-12-14 02:41:13,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:13,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:13,444][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.3356952965259552, acc: 0.8620689511299133)
[2024-12-14 02:41:13,515][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 1.016392707824707, acc: 0.703125)
[2024-12-14 02:41:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:13,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:13,832][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.28594067692756653, acc: 0.8799999952316284)
[2024-12-14 02:41:14,077][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.5009409785270691, acc: 0.84375)
[2024-12-14 02:41:13,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:14,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:14,191][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.3381093144416809, acc: 0.8571428656578064)
[2024-12-14 02:41:14,245][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.5511305332183838, acc: 0.7878788113594055)
[2024-12-14 02:41:14,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:14,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:14,582][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.14182886481285095, acc: 0.9375)
[2024-12-14 02:41:14,598][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.2854413688182831, acc: 0.875)
[2024-12-14 02:41:14,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:14,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:14,986][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.4151720106601715, acc: 0.9032257795333862)
[2024-12-14 02:41:14,997][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 1.2193293571472168, acc: 0.6603773832321167)
[2024-12-14 02:41:15,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:15,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:15,327][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.1545346975326538, acc: 0.95652174949646)
[2024-12-14 02:41:15,370][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 1.4402590990066528, acc: 0.6164383292198181)
[2024-12-14 02:41:15,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:15,688][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.7840461134910583, acc: 0.800000011920929)
[2024-12-14 02:41:15,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:15,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:16,046][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 0.5677691102027893, acc: 0.8292682766914368)
[2024-12-14 02:41:16,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:16,393][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.2256549447774887, acc: 0.9428571462631226)
[2024-12-14 02:41:16,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:16,604][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 2.1589553356170654, acc: 0.4545454680919647)
[2024-12-14 02:41:16,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:16,721][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.5312747955322266, acc: 0.8157894611358643)
[2024-12-14 02:41:16,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:16,953][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.872348427772522, acc: 0.7441860437393188)
[2024-12-14 02:41:17,037][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.4834897816181183, acc: 0.9032257795333862)
[2024-12-14 02:41:17,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:17,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:17,371][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 1.4573160409927368, acc: 0.6024096608161926)
[2024-12-14 02:41:17,380][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.14138023555278778, acc: 0.8799999952316284)
[2024-12-14 02:41:17,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:17,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:17,741][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 1.303019404411316, acc: 0.5802469253540039)
[2024-12-14 02:41:17,786][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.27319714426994324, acc: 0.8787878751754761)
[2024-12-14 02:41:18,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:17,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:18,115][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.4956975281238556, acc: 0.8571428656578064)
[2024-12-14 02:41:18,119][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.2629053592681885, acc: 0.949999988079071)
[2024-12-14 02:41:18,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:18,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:18,461][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.9438291192054749, acc: 0.7285714149475098)
[2024-12-14 02:41:18,507][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.41815364360809326, acc: 0.8518518805503845)
[2024-12-14 02:41:18,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:18,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:18,853][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 1.9265702962875366, acc: 0.5036496520042419)
[2024-12-14 02:41:18,914][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.15988440811634064, acc: 1.0)
[2024-12-14 02:41:18,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:19,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:19,205][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 1.449397325515747, acc: 0.6137930750846863)
[2024-12-14 02:41:19,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:19,332][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 1.580949068069458, acc: 0.5798319578170776)
[2024-12-14 02:41:19,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:19,500][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 2.2310025691986084, acc: 0.4000000059604645)
[2024-12-14 02:41:19,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:19,677][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.9268002510070801, acc: 0.6393442749977112)
[2024-12-14 02:41:19,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:19,872][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 1.8970450162887573, acc: 0.46357616782188416)
[2024-12-14 02:41:19,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:20,079][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 1.1481537818908691, acc: 0.6507936716079712)
[2024-12-14 02:41:20,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:20,247][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 1.3782509565353394, acc: 0.5811966061592102)
[2024-12-14 02:41:20,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:20,447][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 1.3333319425582886, acc: 0.5593220591545105)
[2024-12-14 02:41:20,571][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.13575252890586853, acc: 0.9200000166893005)
[2024-12-14 02:41:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:20,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:20,858][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.28477582335472107, acc: 0.9615384340286255)
[2024-12-14 02:41:20,883][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 0.982134997844696, acc: 0.7701149582862854)
[2024-12-14 02:41:20,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:20,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:21,157][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.09176723659038544, acc: 1.0)
[2024-12-14 02:41:21,248][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.4160313010215759, acc: 0.9047619104385376)
[2024-12-14 02:41:21,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:21,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:21,479][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 1.010495662689209, acc: 0.7179487347602844)
[2024-12-14 02:41:21,559][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.7538570761680603, acc: 0.7692307829856873)
[2024-12-14 02:41:21,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:21,932][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 1.3525028228759766, acc: 0.6486486196517944)
[2024-12-14 02:41:22,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:22,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:22,349][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 1.500583529472351, acc: 0.5846154093742371)
[2024-12-14 02:41:22,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:22,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:22,771][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 1.5571085214614868, acc: 0.6060606241226196)
[2024-12-14 02:41:22,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:23,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:23,155][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 1.2068588733673096, acc: 0.7113401889801025)
[2024-12-14 02:41:23,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:23,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:23,588][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 1.6962112188339233, acc: 0.5367646813392639)
[2024-12-14 02:41:23,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:23,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:23,926][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.3433167040348053, acc: 0.9230769276618958)
[2024-12-14 02:41:24,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:24,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:24,248][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.07410826534032822, acc: 1.0)
[2024-12-14 02:41:24,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:24,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:24,511][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.6403898000717163, acc: 0.8214285969734192)
[2024-12-14 02:41:24,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:24,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:24,864][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.32870522141456604, acc: 0.8888888955116272)
[2024-12-14 02:41:25,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:25,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:25,262][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.947990357875824, acc: 0.6666666865348816)
[2024-12-14 02:41:25,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:25,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:25,681][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 1.0099016427993774, acc: 0.761904776096344)
[2024-12-14 02:41:25,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:25,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:26,077][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 1.191855788230896, acc: 0.6197183132171631)
[2024-12-14 02:41:26,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:26,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:26,550][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.8129483461380005, acc: 0.5133333206176758)
[2024-12-14 02:41:26,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:26,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:26,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:27,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:27,508][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:41:28,058][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.8634, device='cuda:0') eval_epoch_loss=tensor(1.7687, device='cuda:0') eval_epoch_acc=tensor(0.5821, device='cuda:0')
[2024-12-14 02:41:28,059][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:41:28,060][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:41:28,250][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_7_step_131_loss_1.768723964691162/model.pt
[2024-12-14 02:41:28,256][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:41:28,257][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.5821221470832825
[2024-12-14 02:41:28,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:28,637][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.20903973281383514, acc: 0.9130434989929199)
[2024-12-14 02:41:28,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:28,986][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.5197344422340393, acc: 0.84375)
[2024-12-14 02:41:29,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:29,286][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.6197311878204346, acc: 0.8260869383811951)
[2024-12-14 02:41:29,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:29,618][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.6109318733215332, acc: 0.800000011920929)
[2024-12-14 02:41:29,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:29,909][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.31464260816574097, acc: 0.9230769276618958)
[2024-12-14 02:41:29,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:30,216][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.706445038318634, acc: 0.761904776096344)
[2024-12-14 02:41:30,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:30,532][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.5546733140945435, acc: 0.7666666507720947)
[2024-12-14 02:41:30,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:30,891][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.32608771324157715, acc: 0.8260869383811951)
[2024-12-14 02:41:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:31,248][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.5556760430335999, acc: 0.8571428656578064)
[2024-12-14 02:41:31,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:31,590][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.6718329191207886, acc: 0.807692289352417)
 [2024-12-14 02:41:31,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:31,878][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.9266741275787354, acc: 0.6774193644523621)
[2024-12-14 02:41:31,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:32,263][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.9341163635253906, acc: 0.7567567825317383)
[2024-12-14 02:41:32,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:32,790][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 1.4282814264297485, acc: 0.5614035129547119)
                   [2024-12-14 02:41:32,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:33,184][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 1.350246787071228, acc: 0.5895522236824036)
[2024-12-14 02:41:33,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:33,569][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 1.7121812105178833, acc: 0.4897959232330322)
[2024-12-14 02:41:33,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:34,013][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 1.62871515750885, acc: 0.5531914830207825)
                                                                                         [2024-12-14 02:41:34,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:34,378][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 1.1704835891723633, acc: 0.6571428775787354)
                                                                              [2024-12-14 02:41:34,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:34,751][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.44359809160232544, acc: 0.8214285969734192)
                                                                             [2024-12-14 02:41:34,846][slam_llm.models.slam_model][INFO] - modality encoder
                                               [2024-12-14 02:41:35,113][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.580716073513031, acc: 0.782608687877655)
                                                                                                                                                               [2024-12-14 02:41:35,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:35,508][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.4213595986366272, acc: 0.8965517282485962)
                                                                              [2024-12-14 02:41:35,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:35,905][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 1.0780023336410522, acc: 0.739130437374115)
                                                                               [2024-12-14 02:41:36,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:36,307][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 1.3734157085418701, acc: 0.5762711763381958)
                                                                                                                                                                                                                              [2024-12-14 02:41:36,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:36,685][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 1.4438128471374512, acc: 0.5964912176132202)
                                                                              [2024-12-14 02:41:36,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:37,079][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 1.4775052070617676, acc: 0.5945945978164673)
[2024-12-14 02:41:37,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:37,442][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.8163985013961792, acc: 0.8214285969734192)
                                                                                                                                                           [2024-12-14 02:41:37,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:37,829][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.4908665418624878, acc: 0.782608687877655)
[2024-12-14 02:41:37,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:38,54][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 2.021702289581299, acc: 0.46666666865348816)
[2024-12-14 02:41:38,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:38,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:38,438][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 1.4160927534103394, acc: 0.581632673740387)
[2024-12-14 02:41:38,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:38,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:38,797][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 2.0215885639190674, acc: 0.41791045665740967)
[2024-12-14 02:41:38,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:38,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:39,189][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 2.0210800170898438, acc: 0.46715328097343445)
[2024-12-14 02:41:39,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:39,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:39,570][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.19660641252994537, acc: 0.9523809552192688)
[2024-12-14 02:41:39,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:39,950][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.2335951179265976, acc: 0.9166666865348816)
[2024-12-14 02:41:39,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:40,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:40,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:40,336][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.523771345615387, acc: 0.8484848737716675)
[2024-12-14 02:41:40,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:40,686][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.20058926939964294, acc: 0.9230769276618958)
[2024-12-14 02:41:40,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:40,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:41,011][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 1.1015686988830566, acc: 0.7115384340286255)
[2024-12-14 02:41:41,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:41,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:41,353][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 1.1571040153503418, acc: 0.6730769276618958)
[2024-12-14 02:41:41,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:41,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:41,703][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.4871380627155304, acc: 0.8125)
[2024-12-14 02:41:41,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:41,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:42,076][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 1.144567608833313, acc: 0.6811594367027283)
[2024-12-14 02:41:42,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:42,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:42,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:42,504][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.8707653880119324, acc: 0.7400000095367432)
[2024-12-14 02:41:42,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:42,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:42,912][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.6776708960533142, acc: 0.695652186870575)
[2024-12-14 02:41:43,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:43,295][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.7330214977264404, acc: 0.7755101919174194)
[2024-12-14 02:41:43,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:43,648][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.8482810258865356, acc: 0.7200000286102295)
[2024-12-14 02:41:43,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:44,050][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 1.097009539604187, acc: 0.75)
[2024-12-14 02:41:44,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:44,379][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 1.1604480743408203, acc: 0.656862735748291)
[2024-12-14 02:41:44,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:45,414][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 1.9861353635787964, acc: 0.4383561611175537)
                                                                                                                                                             [2024-12-14 02:41:45,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:45,742][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.3672659695148468, acc: 0.8333333134651184)
[2024-12-14 02:41:45,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:46,053][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 1.0033698081970215, acc: 0.7037037014961243)
[2024-12-14 02:41:46,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:46,421][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.5973696112632751, acc: 0.75)
[2024-12-14 02:41:46,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:46,959][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 1.494781494140625, acc: 0.6283186078071594)
[2024-12-14 02:41:47,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:47,331][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 1.0648726224899292, acc: 0.695652186870575)
[2024-12-14 02:41:47,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:47,692][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 1.1712442636489868, acc: 0.6704545617103577)
[2024-12-14 02:41:47,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:48,608][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 2.0156185626983643, acc: 0.42748090624809265)
                                                                                                                                                                                                                                                                                                   [2024-12-14 02:41:48,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:49,287][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 1.713575839996338, acc: 0.4592592716217041)
                                                                                                                                                                                                                                             [2024-12-14 02:41:49,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:49,635][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.9314126968383789, acc: 0.7213114500045776)
                                                                                                                                                                                                                        [2024-12-14 02:41:49,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:50,005][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.24916963279247284, acc: 0.9583333134651184)
[2024-12-14 02:41:50,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:50,386][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.654916524887085, acc: 0.8399999737739563)
                                                                                                                                                           [2024-12-14 02:41:50,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:50,721][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.5193147659301758, acc: 0.8214285969734192)
                                                                               [2024-12-14 02:41:50,813][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:41:51,078][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 1.2469267845153809, acc: 0.6341463327407837)
[2024-12-14 02:41:51,186][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:41:51,448][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 1.8965518474578857, acc: 0.4924471378326416)
                                                                              [2024-12-14 02:41:51,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:51,757][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 2.049654960632324, acc: 0.46109509468078613)
[2024-12-14 02:41:51,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:52,235][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 2.0673670768737793, acc: 0.4375)
                                                                                                                                                                          [2024-12-14 02:41:52,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:52,768][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 1.9915457963943481, acc: 0.452157586812973)
                                                                                                                                                               [2024-12-14 02:41:52,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:53,197][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 1.8751863241195679, acc: 0.46975088119506836)
                                                                               [2024-12-14 02:41:53,282][slam_llm.models.slam_model][INFO] - modality encoder
                                            [2024-12-14 02:41:53,520][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.5595612525939941, acc: 0.8799999952316284)
[2024-12-14 02:41:53,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:54,068][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 1.7918635606765747, acc: 0.5)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:41:54,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:54,865][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.705701470375061, acc: 0.5634920597076416)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:41:55,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:55,780][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 1.6785664558410645, acc: 0.5681818127632141)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:41:55,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:56,521][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 1.2930724620819092, acc: 0.6235294342041016)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:41:56,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:57,602][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 1.5012789964675903, acc: 0.604938268661499)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:41:57,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:58,556][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 0.9536112546920776, acc: 0.7419354915618896)
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:41:58,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:58,899][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.27609267830848694, acc: 0.9285714030265808)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:41:59,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:59,244][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.7377730011940002, acc: 0.800000011920929)
 [2024-12-14 02:41:59,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:41:59,537][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 1.1569963693618774, acc: 0.6764705777168274)
                                                                             [2024-12-14 02:41:59,635][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:41:59,915][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 1.6177568435668945, acc: 0.5514705777168274)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:42:00,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:00,289][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 1.651324987411499, acc: 0.5508474707603455)
[2024-12-14 02:42:00,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:00,687][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 1.680310606956482, acc: 0.5522388219833374)
                                                                                                                                                                                                                                                                                                     [2024-12-14 02:42:00,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:01,093][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 1.4971094131469727, acc: 0.5631067752838135)
                                                                                                                                       [2024-12-14 02:42:01,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:01,437][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 0.9976752400398254, acc: 0.6984127163887024)
                                                                                                                                                                                                                      [2024-12-14 02:42:01,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:01,497][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 1.6522912979125977, acc: 0.5416666865348816)
[2024-12-14 02:42:01,602][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 0.8534948229789734, acc: 0.7551020383834839)
[2024-12-14 02:42:01,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:01,874][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 1.598495602607727, acc: 0.5538461804389954)
[2024-12-14 02:42:01,947][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.3979116976261139, acc: 0.8999999761581421)
[2024-12-14 02:42:01,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:02,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:02,282][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 1.473223328590393, acc: 0.5808823704719543)
[2024-12-14 02:42:02,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:02,376][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.14585894346237183, acc: 0.9545454382896423)
[2024-12-14 02:42:02,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:02,610][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.3210696578025818, acc: 0.8846153616905212)
[2024-12-14 02:42:02,737][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.2679808437824249, acc: 0.9615384340286255)
[2024-12-14 02:42:02,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:03,154][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.4096103012561798, acc: 0.8148148059844971)
[2024-12-14 02:42:03,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:03,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:03,509][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.9587209820747375, acc: 0.692307710647583)
[2024-12-14 02:42:03,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:03,820][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.4972257912158966, acc: 0.8181818127632141)
[2024-12-14 02:42:03,842][slam_llm.models.slam_model][INFO] - modality encoder
 [2024-12-14 02:42:03,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:04,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:04,228][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.7776010632514954, acc: 0.760869562625885)
[2024-12-14 02:42:04,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:04,563][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 0.8307409286499023, acc: 0.7254902124404907)
[2024-12-14 02:42:04,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:04,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:04,939][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.7722474932670593, acc: 0.7142857313156128)
[2024-12-14 02:42:04,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:05,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:05,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:05,342][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.3107292354106903, acc: 0.8947368264198303)
[2024-12-14 02:42:05,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:05,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:05,668][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.6178001761436462, acc: 0.7916666865348816)
[2024-12-14 02:42:05,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:06,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:06,242][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 0.8103113174438477, acc: 0.7972972989082336)
2024-12-14 02:42:06,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:06,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:06,401][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.38147085905075073, acc: 0.8947368264198303)
[2024-12-14 02:42:06,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:06,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:06,783][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.5116075873374939, acc: 0.8461538553237915)
[2024-12-14 02:42:06,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:07,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:07,151][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.5652375817298889, acc: 0.8275862336158752)
[2024-12-14 02:42:07,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:07,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:07,527][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.4366719126701355, acc: 0.9200000166893005)
[2024-12-14 02:42:07,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:07,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:07,901][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.15446262061595917, acc: 0.9523809552192688)
[2024-12-14 02:42:08,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:08,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:08,244][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 1.1167066097259521, acc: 0.8125)
[2024-12-14 02:42:08,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:08,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:08,645][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 1.1065988540649414, acc: 0.6037735939025879)
[2024-12-14 02:42:08,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:08,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:09,076][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 1.3284142017364502, acc: 0.6301369667053223)
[2024-12-14 02:42:09,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:09,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:09,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:09,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:10,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:10,467][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 2.000258207321167, acc: 0.47035571932792664)
[2024-12-14 02:42:10,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:10,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:10,749][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.7934877276420593, acc: 0.7441860437393188)
[2024-12-14 02:42:10,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:11,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:11,090][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 1.1059720516204834, acc: 0.650602400302887)
[2024-12-14 02:42:11,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:11,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:11,460][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 1.157620906829834, acc: 0.6172839403152466)
[2024-12-14 02:42:11,579][slam_llm.models.slam_model][INFO] - modality encoder
[2[2024-12-14 02:42:11,965][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.39580029249191284, acc: 0.8837209343910217)
 step 31/574 completed (loss: 0.5816496014595032, acc: 0.8214285969734192)
[2024-12-14 02:42:11,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:11,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:12,178][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.37990763783454895, acc: 0.8888888955116272)
[2024-12-14 02:42:12,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:12,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:12,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:12,597][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.1649760752916336, acc: 0.9130434989929199)
[2024-12-14 02:42:12,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:12,955][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 1.6008880138397217, acc: 0.5630252361297607)
[2024-12-14 02:42:12,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:13,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:13,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:13,329][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 1.0856926441192627, acc: 0.7049180269241333)
[2024-12-14 02:42:13,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:13,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:13,692][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 1.233332633972168, acc: 0.6349206566810608)
[2024-12-14 02:42:13,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:13,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:14,087][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 1.295201301574707, acc: 0.5423728823661804)
[2024-12-14 02:42:14,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:14,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:14,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:14,500][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 1.1694881916046143, acc: 0.6551724076271057)
[2024-12-14 02:42:14,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:14,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:14,835][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.22012320160865784, acc: 0.9523809552192688)
[2024-12-14 02:42:14,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:15,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:15,211][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.6714796423912048, acc: 0.807692289352417)
[2024-12-14 02:42:15,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:15,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:15,628][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 1.456650972366333, acc: 0.6216216087341309)
[2024-12-14 02:42:15,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:15,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:15,982][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 1.4146803617477417, acc: 0.6461538672447205)
[2024-12-14 02:42:16,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:16,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:16,457][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 1.5557905435562134, acc: 0.6363636255264282)
[2024-12-14 02:42:16,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:16,896][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 1.3599845170974731, acc: 0.6494845151901245)
[2024-12-14 02:42:17,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:17,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:17,325][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 1.5895249843597412, acc: 0.6029411554336548)
[2024-12-14 02:42:17,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:17,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:17,697][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.3342779576778412, acc: 0.9230769276618958)
[2024-12-14 02:42:17,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:17,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:18,040][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.18469257652759552, acc: 0.9629629850387573)
[2024-12-14 02:42:18,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:18,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:18,415][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.5560766458511353, acc: 0.7857142686843872)
[2024-12-14 02:42:18,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:18,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:18,799][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.39725416898727417, acc: 0.8333333134651184)
[2024-12-14 02:42:18,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:19,220][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.8714186549186707, acc: 0.719298243522644)
[2024-12-14 02:42:19,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:19,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:19,541][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.9798671007156372, acc: 0.7301587462425232)
[2024-12-14 02:42:19,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:19,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:19,942][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 1.231719970703125, acc: 0.6619718074798584)
[2024-12-14 02:42:19,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:20,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:20,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:20,430][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.7898368835449219, acc: 0.5)
[2024-12-14 02:42:20,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:20,847][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.43508797883987427, acc: 0.8918918967247009)
[2024-12-14 02:42:20,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:20,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:21,220][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.12595003843307495, acc: 0.9615384340286255)
[2024-12-14 02:42:21,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:21,652][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                           [2024-12-14 02:42:22,069][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:42:22,539][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                          [2024-12-14 02:42:22,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:22,866][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.6430346369743347, acc: 0.7894737124443054)
[2024-12-14 02:42:22,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:23,185][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 1.0240216255187988, acc: 0.7428571581840515)
[2024-12-14 02:42:23,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:23,535][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.8295294046401978, acc: 0.7763158082962036)
[2024-12-14 02:42:23,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:24,099][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 1.28750741481781, acc: 0.5849056839942932)
[2024-12-14 02:42:24,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:24,679][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 1.4130090475082397, acc: 0.625)
            [2024-12-14 02:42:24,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:25,024][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.5254045128822327, acc: 0.8055555820465088)
[2024-12-14 02:42:25,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:25,381][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.5803148150444031, acc: 0.8387096524238586)
[2024-12-14 02:42:25,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:25,758][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 1.8558095693588257, acc: 0.4933333396911621)
[2024-12-14 02:42:25,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:26,145][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 1.2264618873596191, acc: 0.625)
[2024-12-14 02:42:26,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:26,977][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 2.126394748687744, acc: 0.4560000002384186)
                                                                                                              [2024-12-14 02:42:27,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:27,292][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 1.6190392971038818, acc: 0.516853928565979)
[2024-12-14 02:42:27,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:27,625][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 1.4222232103347778, acc: 0.6081081032752991)
[2024-12-14 02:42:27,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:28,079][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.9663028120994568, acc: 0.7241379022598267)
                                                                                                  [2024-12-14 02:42:28,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:28,434][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.3909679651260376, acc: 0.9090909361839294)
                                                                               [2024-12-14 02:42:28,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:28,786][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.3026110827922821, acc: 0.9545454382896423)
                                                                              [2024-12-14 02:42:28,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:29,089][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.26969993114471436, acc: 0.90625)
[2024-12-14 02:42:29,210][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 02:42:29,459][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.25376778841018677, acc: 0.9666666388511658)
                                                                             [2024-12-14 02:42:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:29,821][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.9683749079704285, acc: 0.7166666388511658)
                                                                                                                                                             [2024-12-14 02:42:30,555][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:42:30,892][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:42:31,284][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:42:31,689][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:42:32,145][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                        [2024-12-14 02:42:32,500][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:42:32,874][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                      [2024-12-14 02:42:33,214][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:42:33,611][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:42:33,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:33,862][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.05580125376582146, acc: 1.0)
[2024-12-14 02:42:33,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:34,156][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.18671323359012604, acc: 0.95652174949646)
[2024-12-14 02:42:34,214][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.2222936600446701, acc: 0.9583333134651184)
[2024-12-14 02:42:34,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:34,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:34,502][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.48988232016563416, acc: 0.8125)
[2024-12-14 02:42:34,546][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.5381860733032227, acc: 0.7878788113594055)
[2024-12-14 02:42:34,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:34,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:34,884][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.35985267162323, acc: 0.9130434989929199)
[2024-12-14 02:42:34,897][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.2735131084918976, acc: 0.9615384340286255)
[2024-12-14 02:42:34,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:34,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:35,221][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.9632853865623474, acc: 0.6730769276618958)
[2024-12-14 02:42:35,231][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.6466109156608582, acc: 0.800000011920929)
[2024-12-14 02:42:35,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:35,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:35,497][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 1.138885259628296, acc: 0.6730769276618958)
[2024-12-14 02:42:35,561][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.3024720847606659, acc: 0.8846153616905212)
[2024-12-14 02:42:35,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:35,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:35,861][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.403712660074234, acc: 0.84375)
[2024-12-14 02:42:35,915][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.6789859533309937, acc: 0.761904776096344)
[2024-12-14 02:42:35,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:36,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:36,244][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 1.0866448879241943, acc: 0.6666666865348816)
[2024-12-14 02:42:36,272][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.8481485843658447, acc: 0.7666666507720947)
[2024-12-14 02:42:36,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:36,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:36,607][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.39898568391799927, acc: 0.8695651888847351)
[2024-12-14 02:42:36,620][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.8615060448646545, acc: 0.7400000095367432)
[2024-12-14 02:42:36,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:36,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:36,936][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.5425026416778564, acc: 0.782608687877655)
[2024-12-14 02:42:36,941][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.5517821311950684, acc: 0.8095238208770752)
[2024-12-14 02:42:37,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:37,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:37,267][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.7771718502044678, acc: 0.7692307829856873)
[2024-12-14 02:42:37,397][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 0.7777320146560669, acc: 0.699999988079071)
[2024-12-14 02:42:37,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:37,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:37,709][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.8483194708824158, acc: 0.6451612710952759)
[2024-12-14 02:42:37,819][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 1.314008355140686, acc: 0.6504854559898376)
[2024-12-14 02:42:37,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:38,116][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.8203235268592834, acc: 0.7567567825317383)
[2024-12-14 02:42:38,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:38,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:38,656][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 1.4738456010818481, acc: 0.5438596606254578)
[2024-12-14 02:42:38,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:38,951][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 1.6127338409423828, acc: 0.5873786211013794)
[2024-12-14 02:42:39,007][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 1.3615590333938599, acc: 0.60447758436203)
[2024-12-14 02:42:39,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:39,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:39,427][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 1.6688497066497803, acc: 0.4693877696990967)
[2024-12-14 02:42:39,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:39,770][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.7254700660705566, acc: 0.5322580933570862)
[2024-12-14 02:42:39,868][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 1.5267680883407593, acc: 0.563829779624939)
[2024-12-14 02:42:39,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:39,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:40,221][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 1.193251132965088, acc: 0.6857143044471741)
[2024-12-14 02:42:40,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:40,577][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 1.6482439041137695, acc: 0.5862069129943848)
[2024-12-14 02:42:40,581][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.7076905369758606, acc: 0.75)
[2024-12-14 02:42:40,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:40,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:40,949][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.5399916768074036, acc: 0.739130437374115)
[2024-12-14 02:42:41,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:41,286][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.46609827876091003, acc: 0.7931034564971924)
[2024-12-14 02:42:41,326][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 1.002549171447754, acc: 0.75789475440979)
[2024-12-14 02:42:41,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:41,622][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 1.1980518102645874, acc: 0.695652186870575)
[2024-12-14 02:42:41,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:41,963][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 1.1368924379348755, acc: 0.694915235042572)
[2024-12-14 02:42:42,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:42,302][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 1.2473976612091064, acc: 0.6842105388641357)
[2024-12-14 02:42:42,317][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 1.558003544807434, acc: 0.5049505233764648)
[2024-12-14 02:42:42,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:42,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:42,630][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 1.5394912958145142, acc: 0.5945945978164673)
[2024-12-14 02:42:42,672][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 1.3313913345336914, acc: 0.6451612710952759)
[2024-12-14 02:42:42,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:42,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:43,027][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.7984414100646973, acc: 0.7142857313156128)
[2024-12-14 02:42:43,073][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 1.2811015844345093, acc: 0.6086956262588501)
[2024-12-14 02:42:43,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:43,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:43,400][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.6472970247268677, acc: 0.695652186870575)
[2024-12-14 02:42:43,441][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 1.7623217105865479, acc: 0.47058823704719543)
[2024-12-14 02:42:43,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:43,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:43,749][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.599343478679657, acc: 0.7894737124443054)
[2024-12-14 02:42:43,833][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 1.6878259181976318, acc: 0.4615384638309479)
[2024-12-14 02:42:43,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:44,224][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 1.8412169218063354, acc: 0.510948896408081)
[2024-12-14 02:42:44,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:44,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:44,608][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 1.33763587474823, acc: 0.5373134613037109)
[2024-12-14 02:42:44,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:45,002][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.17053727805614471, acc: 0.949999988079071)
[2024-12-14 02:42:45,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:45,349][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.37872031331062317, acc: 0.9090909361839294)
[2024-12-14 02:42:45,374][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 1.216955542564392, acc: 0.6756756901741028)
[2024-12-14 02:42:45,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:45,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:45,678][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.2803741991519928, acc: 0.9130434989929199)
[2024-12-14 02:42:45,685][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 1.713604211807251, acc: 0.5740740895271301)
[2024-12-14 02:42:45,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:45,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:46,000][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.6046897768974304, acc: 0.7954545617103577)
[2024-12-14 02:42:46,097][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 1.1013826131820679, acc: 0.6860465407371521)
[2024-12-14 02:42:46,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:46,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:46,364][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 1.0751303434371948, acc: 0.6379310488700867)
[2024-12-14 02:42:46,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:46,686][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 0.9263905882835388, acc: 0.7058823704719543)
[2024-12-14 02:42:46,686][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.44530948996543884, acc: 0.8837209343910217)
[2024-12-14 02:42:46,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:46,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:47,051][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.4270598590373993, acc: 0.8399999737739563)
[2024-12-14 02:42:47,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:47,240][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 1.499143123626709, acc: 0.550561785697937)
[2024-12-14 02:42:47,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:47,388][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.06753143668174744, acc: 1.0)
[2024-12-14 02:42:47,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:47,598][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.6544476747512817, acc: 0.8863636255264282)
[2024-12-14 02:42:47,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:47,782][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.029245348647236824, acc: 1.0)
[2024-12-14 02:42:47,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:47,946][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.4125129282474518, acc: 0.8571428656578064)
[2024-12-14 02:42:48,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:48,136][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.41623884439468384, acc: 0.8809523582458496)
[2024-12-14 02:42:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:48,312][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 0.709729790687561, acc: 0.7586206793785095)
[2024-12-14 02:42:48,450][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 1.2058067321777344, acc: 0.6461538672447205)
[2024-12-14 02:42:48,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:48,741][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.447156697511673, acc: 0.8367347121238708)
[2024-12-14 02:42:48,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:48,849][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 1.1511255502700806, acc: 0.6491228342056274)
[2024-12-14 02:42:48,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:49,087][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.6060829758644104, acc: 0.8199999928474426)
[2024-12-14 02:42:49,207][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.967714786529541, acc: 0.6666666865348816)
[2024-12-14 02:42:49,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:49,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:49,514][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 0.9901917576789856, acc: 0.7361111044883728)
[2024-12-14 02:42:49,555][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.8359575271606445, acc: 0.7948718070983887)
[2024-12-14 02:42:49,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:49,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:49,857][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 1.2343167066574097, acc: 0.6078431606292725)
[2024-12-14 02:42:49,942][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.6495059132575989, acc: 0.7755101919174194)
[2024-12-14 02:42:50,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:50,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:50,311][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.04571603238582611, acc: 1.0)
[2024-12-14 02:42:50,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:50,670][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 1.1308975219726562, acc: 0.6666666865348816)
[2024-12-14 02:42:50,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:50,883][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 1.8613312244415283, acc: 0.5136986374855042)
[2024-12-14 02:42:50,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:51,011][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 1.5798351764678955, acc: 0.577235758304596)
[2024-12-14 02:42:51,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:51,236][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.2429218888282776, acc: 0.9166666865348816)
[2024-12-14 02:42:51,347][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.9556760191917419, acc: 0.6935483813285828)
[2024-12-14 02:42:51,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:51,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:51,617][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.6826801896095276, acc: 0.7777777910232544)
[2024-12-14 02:42:51,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:51,951][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.3511311709880829, acc: 0.8214285969734192)
[2024-12-14 02:42:52,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:52,228][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 1.8807711601257324, acc: 0.48669201135635376)
[2024-12-14 02:42:52,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:52,498][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 1.2529062032699585, acc: 0.6637167930603027)
[2024-12-14 02:42:52,583][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 1.028456211090088, acc: 0.6800000071525574)
[2024-12-14 02:42:52,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:52,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:52,875][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 0.9663161039352417, acc: 0.695652186870575)
[2024-12-14 02:42:52,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:52,995][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.9664674401283264, acc: 0.7115384340286255)
[2024-12-14 02:42:53,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:53,279][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 1.0543735027313232, acc: 0.7045454382896423)
[2024-12-14 02:42:53,284][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.2518666088581085, acc: 0.9166666865348816)
[2024-12-14 02:42:53,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:53,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:53,614][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.31888261437416077, acc: 0.8421052694320679)
[2024-12-14 02:42:53,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:54,008][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 1.5232467651367188, acc: 0.558282196521759)
[2024-12-14 02:42:54,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:54,189][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 1.8469369411468506, acc: 0.5267175436019897)
[2024-12-14 02:42:54,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:54,393][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 1.508668065071106, acc: 0.5833333134651184)
[2024-12-14 02:42:54,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:54,697][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 1.5415682792663574, acc: 0.5333333611488342)
[2024-12-14 02:42:54,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:54,859][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 1.6929411888122559, acc: 0.5481481552124023)
[2024-12-14 02:42:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:55,094][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 1.5400304794311523, acc: 0.5297619104385376)
[2024-12-14 02:42:55,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:55,231][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.7942343950271606, acc: 0.7213114500045776)
[2024-12-14 02:42:55,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:55,456][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 1.5628471374511719, acc: 0.5487179756164551)
[2024-12-14 02:42:55,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:55,582][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.18221431970596313, acc: 0.9583333134651184)
[2024-12-14 02:42:55,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:55,857][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 1.418913722038269, acc: 0.654411792755127)
[2024-12-14 02:42:55,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:55,946][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.4235994815826416, acc: 0.8799999952316284)
[2024-12-14 02:42:56,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:56,149][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.3362305760383606, acc: 0.8846153616905212)
[2024-12-14 02:42:56,363][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.29316049814224243, acc: 0.8928571343421936)
[2024-12-14 02:42:56,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:56,743][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 1.232149600982666, acc: 0.5853658318519592)
[2024-12-14 02:42:56,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:56,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:57,153][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 1.8857766389846802, acc: 0.4773413836956024)
[2024-12-14 02:42:57,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:57,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:57,537][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 2.0523335933685303, acc: 0.47262248396873474)
[2024-12-14 02:42:57,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:57,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:57,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:58,016][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 2.0695924758911133, acc: 0.44999998807907104)
[2024-12-14 02:42:58,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:58,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:58,550][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 2.0342979431152344, acc: 0.4390243887901306)
[2024-12-14 02:42:58,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:58,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:58,961][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 1.8728936910629272, acc: 0.49822065234184265)
[2024-12-14 02:42:58,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:59,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:59,329][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.2976526618003845, acc: 0.9599999785423279)
[2024-12-14 02:42:59,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:59,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:59,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:42:59,840][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 1.8507366180419922, acc: 0.43023255467414856)
[2024-12-14 02:43:00,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:00,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:00,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:00,640][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.600328803062439, acc: 0.579365074634552)
[2024-12-14 02:43:00,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:00,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:01,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:01,556][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 1.6728721857070923, acc: 0.5530303120613098)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:43:01,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:01,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:01,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:02,297][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 1.3481959104537964, acc: 0.6470588445663452)
[2024-12-14 02:43:02,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:02,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:02,647][slam_llm.models.slam_model][INFO] - modality encoder
                           [2024-12-14 02:43:02,960][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:43:03,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:03,372][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 1.3399690389633179, acc: 0.6358024477958679)
[2024-12-14 02:43:03,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:03,640][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:43:03,943][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:43:04,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:04,323][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 0.9377890825271606, acc: 0.7419354915618896)
[2024-12-14 02:43:04,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:04,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:04,628][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.5156547427177429, acc: 0.8571428656578064)
[2024-12-14 02:43:04,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:05,024][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.5644701719284058, acc: 0.824999988079071)
[2024-12-14 02:43:05,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:05,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:05,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:05,575][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.6620806455612183, acc: 0.7352941036224365)
                                                                [2024-12-14 02:43:05,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:05,963][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.5631740689277649, acc: 0.800000011920929)
                                                                               [2024-12-14 02:43:06,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:06,364][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 1.5622119903564453, acc: 0.53125)
                                                                                          [2024-12-14 02:43:06,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:06,767][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 1.7667299509048462, acc: 0.47999998927116394)
                                                             [2024-12-14 02:43:06,866][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:43:07,129][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 1.3351331949234009, acc: 0.6153846383094788)
                                                                                                                                                             [2024-12-14 02:43:07,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:07,544][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 1.8482643365859985, acc: 0.5093167424201965)
                                                                               [2024-12-14 02:43:07,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:07,936][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 2.031062126159668, acc: 0.44329896569252014)
                                                                                [2024-12-14 02:43:08,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:08,274][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.18966378271579742, acc: 0.9545454382896423)
                                                                              [2024-12-14 02:43:08,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:08,614][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.8597105741500854, acc: 0.7857142686843872)
[2024-12-14 02:43:08,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:08,963][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.8706580996513367, acc: 0.7068965435028076)
[2024-12-14 02:43:09,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:09,424][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.6463879942893982, acc: 0.8181818127632141)
                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:43:09,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:09,975][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 1.5503064393997192, acc: 0.6134020686149597)
                                                                                                                                                              [2024-12-14 02:43:10,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:10,341][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 1.2454895973205566, acc: 0.6206896305084229)
                                                                               [2024-12-14 02:43:10,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:10,728][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.9052115082740784, acc: 0.7407407164573669)
                                                                               [2024-12-14 02:43:10,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:11,097][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.5869672298431396, acc: 0.8684210777282715)
                                                                               [2024-12-14 02:43:11,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:11,479][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.4120330810546875, acc: 0.8571428656578064)
[2024-12-14 02:43:11,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:11,835][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.7418808341026306, acc: 0.84375)
[2024-12-14 02:43:11,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:12,216][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.8813320398330688, acc: 0.7169811129570007)
                                [2024-12-14 02:43:12,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:12,585][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.47768259048461914, acc: 0.8679245114326477)
                                                                             [2024-12-14 02:43:12,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:12,984][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.28576192259788513, acc: 0.9411764740943909)
                                                                              [2024-12-14 02:43:13,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:13,324][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.40540263056755066, acc: 0.84375)
          [2024-12-14 02:43:13,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:13,684][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.7806071043014526, acc: 0.7540983557701111)
                                                                               [2024-12-14 02:43:13,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:14,065][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.2711349129676819, acc: 0.8666666746139526)
                                                                                                                                                               [2024-12-14 02:43:14,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:14,380][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.2885405123233795, acc: 0.8947368264198303)
 [2024-12-14 02:43:14,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:14,791][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 1.1424607038497925, acc: 0.6666666865348816)
                                                                               [2024-12-14 02:43:14,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:15,209][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 1.072864294052124, acc: 0.6805555820465088)
[2024-12-14 02:43:15,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:15,590][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.9111949801445007, acc: 0.6987951993942261)
                    [2024-12-14 02:43:15,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:15,990][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 1.1978588104248047, acc: 0.6282051205635071)
                                                                   [2024-12-14 02:43:16,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:16,398][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 1.3957223892211914, acc: 0.6428571343421936)
                                                                                                                                                              [2024-12-14 02:43:16,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:16,744][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.031840670853853226, acc: 1.0)
                                                                                            [2024-12-14 02:43:16,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:17,057][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.3489999771118164, acc: 0.9166666865348816)
[2024-12-14 02:43:17,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:17,435][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.1866144984960556, acc: 0.9677419066429138)
                                                                              [2024-12-14 02:43:17,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:17,773][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.30049559473991394, acc: 0.9354838728904724)
[2024-12-14 02:43:17,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:18,078][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.8297920227050781, acc: 0.7910447716712952)
                   [2024-12-14 02:43:18,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:18,444][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.9535152912139893, acc: 0.7211538553237915)
                                                                               [2024-12-14 02:43:18,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:18,805][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.6290444135665894, acc: 0.800000011920929)
[2024-12-14 02:43:18,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:19,184][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.8575813174247742, acc: 0.7419354915618896)
                                                                               [2024-12-14 02:43:19,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:19,544][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.39070630073547363, acc: 0.8600000143051147)
                                                                              [2024-12-14 02:43:19,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:19,862][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.6563388705253601, acc: 0.7037037014961243)
[2024-12-14 02:43:19,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:20,159][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 0.7345158457756042, acc: 0.7428571581840515)
[2024-12-14 02:43:20,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:20,465][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.8432952761650085, acc: 0.7435897588729858)
[2024-12-14 02:43:20,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:20,814][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 0.814260721206665, acc: 0.8048780560493469)
                                                                                          [2024-12-14 02:43:20,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:21,195][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.9517719745635986, acc: 0.6842105388641357)
[2024-12-14 02:43:21,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:21,566][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.16011816263198853, acc: 0.9473684430122375)
2024-12-14 02:43:21,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:21,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:21,700][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.37659886479377747, acc: 0.8571428656578064)
[2024-12-14 02:43:21,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:21,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:22,072][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.5794327855110168, acc: 0.9090909361839294)
[2024-12-14 02:43:22,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:22,388][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.7140040993690491, acc: 0.7727272510528564)
[2024-12-14 02:43:22,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:22,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:22,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:22,968][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 1.1822715997695923, acc: 0.6290322542190552)
[2024-12-14 02:43:23,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:23,265][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:43:23,498][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.7523841857910156, acc: 0.75)
[2024-12-14 02:43:23,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:23,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:23,847][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.5061600804328918, acc: 0.9047619104385376)
[2024-12-14 02:43:23,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:23,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:24,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:24,241][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.2767081558704376, acc: 0.9230769276618958)
[2024-12-14 02:43:24,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:24,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:24,594][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.16380555927753448, acc: 0.9354838728904724)
[2024-12-14 02:43:24,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:24,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:24,941][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.1511419713497162, acc: 1.0)
[2024-12-14 02:43:25,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:25,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:25,319][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.4700643718242645, acc: 0.8108108043670654)
[2024-12-14 02:43:25,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:25,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:25,702][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.5678662657737732, acc: 0.8108108043670654)
[2024-12-14 02:43:25,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:25,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:26,109][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.43883833289146423, acc: 0.8648648858070374)
[2024-12-14 02:43:26,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:26,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:26,457][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 1.1399776935577393, acc: 0.6764705777168274)
[2024-12-14 02:43:26,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:26,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:27,092][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 1.71613609790802, acc: 0.5180723071098328)
                                                                                 [2024-12-14 02:43:27,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:27,419][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.9936653971672058, acc: 0.698113203048706)
                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:43:27,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:27,774][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 1.071311354637146, acc: 0.7088607549667358)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:43:27,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:28,151][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.8174973130226135, acc: 0.7843137383460999)
                                                                                                                                                                                                                        [2024-12-14 02:43:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:28,490][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 1.4604575634002686, acc: 0.447761207818985)
                                                                                                                                                                                                              [2024-12-14 02:43:28,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:28,853][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.21053001284599304, acc: 0.949999988079071)
                                                                                                                                                                                                                        [2024-12-14 02:43:28,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:29,252][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.22755743563175201, acc: 0.9599999785423279)
                                                                                                                                                                                                        [2024-12-14 02:43:29,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:29,656][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.7433872222900391, acc: 0.8333333134651184)
                                                                                                                                                                                                                       [2024-12-14 02:43:29,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:29,964][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 1.2503865957260132, acc: 0.6279069781303406)
[2024-12-14 02:43:30,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:30,283][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.7322867512702942, acc: 0.8205128312110901)
2024-12-14 02:43:30,167][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.5040085911750793, acc: 0.8666666746139526)
[2024-12-14 02:43:30,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:30,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:30,445][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.44627368450164795, acc: 0.8333333134651184)
[2024-12-14 02:43:30,514][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.5364733338356018, acc: 0.9130434989929199)
[2024-12-14 02:43:30,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:30,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:30,822][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.3861279785633087, acc: 0.9032257795333862)
[2024-12-14 02:43:30,873][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.43796616792678833, acc: 0.8571428656578064)
[2024-12-14 02:43:30,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:30,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:31,175][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.5885502099990845, acc: 0.7692307829856873)
[2024-12-14 02:43:31,217][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 1.7142311334609985, acc: 0.5199999809265137)
[2024-12-14 02:43:31,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:31,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:31,503][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.7552456855773926, acc: 0.6774193644523621)
[2024-12-14 02:43:31,593][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 1.0338462591171265, acc: 0.6875)
[2024-12-14 02:43:31,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:31,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:31,857][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.810078501701355, acc: 0.7567567825317383)
[2024-12-14 02:43:31,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:32,380][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 1.547735333442688, acc: 0.5438596606254578)
[2024-12-14 02:43:32,448][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 1.9423725605010986, acc: 0.4959999918937683)
[2024-12-14 02:43:32,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:32,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:32,817][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 1.3018109798431396, acc: 0.6641790866851807)
[2024-12-14 02:43:32,856][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 1.5995229482650757, acc: 0.483146071434021)
[2024-12-14 02:43:32,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:33,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:33,226][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 1.6537182331085205, acc: 0.4897959232330322)
[2024-12-14 02:43:33,248][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 1.36611008644104, acc: 0.6351351141929626)
[2024-12-14 02:43:33,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:33,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:33,680][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 1.6535454988479614, acc: 0.5531914830207825)
[2024-12-14 02:43:33,715][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.9207088351249695, acc: 0.7413793206214905)
[2024-12-14 02:43:33,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:34,109][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.9032379984855652, acc: 0.6585366129875183)
10, step 269/574 completed (loss: 0.18338681757450104, acc: 0.9545454382896423)
[2024-12-14 02:43:34,076][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 1.156088948249817, acc: 0.6571428775787354)
[2024-12-14 02:43:34,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:34,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:34,361][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.29868200421333313, acc: 0.8636363744735718)
[2024-12-14 02:43:34,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:34,444][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.7337043881416321, acc: 0.75)
[2024-12-14 02:43:34,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:34,690][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.4190681576728821, acc: 0.875)
[2024-12-14 02:43:34,791][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.546779215335846, acc: 0.8695651888847351)
[2024-12-14 02:43:34,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:34,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:35,045][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.2233801782131195, acc: 0.9333333373069763)
[2024-12-14 02:43:35,140][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.43620818853378296, acc: 0.8275862336158752)
[2024-12-14 02:43:35,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:35,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:35,495][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.8199323415756226, acc: 0.6666666865348816)
[2024-12-14 02:43:35,527][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 0.8612651228904724, acc: 0.717391312122345)
[2024-12-14 02:43:35,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:35,941][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 1.1138255596160889, acc: 0.6610169410705566)
[2024-12-14 02:43:36,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:36,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:36,322][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 1.2132046222686768, acc: 0.6666666865348816)
[2024-12-14 02:43:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:36,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:36,735][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 1.321545124053955, acc: 0.6081081032752991)
[2024-12-14 02:43:36,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:37,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:37,081][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.4118378460407257, acc: 0.7857142686843872)
[2024-12-14 02:43:37,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:37,408][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.35421401262283325, acc: 0.8695651888847351)
[2024-12-14 02:43:37,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:37,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:37,755][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.6993119120597839, acc: 0.8421052694320679)
[2024-12-14 02:43:37,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:38,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:38,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:38,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:38,791][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:43:39,151][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:43:39,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:39,619][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.4169468581676483, acc: 0.8857142925262451)
                                                                               [2024-12-14 02:43:39,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:39,910][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.07733410596847534, acc: 0.9599999785423279)
                                                                              [2024-12-14 02:43:39,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:40,201][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.2262665331363678, acc: 0.95652174949646)
 [2024-12-14 02:43:40,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:40,500][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.6032553315162659, acc: 0.7916666865348816)
[2024-12-14 02:43:40,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:40,896][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 0.988101601600647, acc: 0.75789475440979)
  [2024-12-14 02:43:41,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:41,480][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 1.250929355621338, acc: 0.658682644367218)
                                                                                                                                                                [2024-12-14 02:43:41,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:41,911][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 1.015192985534668, acc: 0.6917293071746826)
 [2024-12-14 02:43:42,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:43,009][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 1.2146633863449097, acc: 0.6684492230415344)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:43:43,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:43,584][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.8138784170150757, acc: 0.7657657861709595)
                                                                               [2024-12-14 02:43:43,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:43,950][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.3792247474193573, acc: 0.8928571343421936)
[2024-12-14 02:43:44,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:44,344][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.28842443227767944, acc: 0.9285714030265808)
                                                                            [2024-12-14 02:43:44,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:44,715][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.4796162545681, acc: 0.75)
[2024-12-14 02:43:44,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:45,069][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.15235558152198792, acc: 0.9444444179534912)
                                   [2024-12-14 02:43:45,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:45,424][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.1931343525648117, acc: 0.9736841917037964)
                                                                               [2024-12-14 02:43:45,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:45,761][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.029013069346547127, acc: 1.0)
                                                                                                                                                                           [2024-12-14 02:43:45,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:46,062][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.03223646059632301, acc: 1.0)
              [2024-12-14 02:43:46,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:46,397][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.42825430631637573, acc: 0.9047619104385376)
[2024-12-14 02:43:46,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:46,713][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.8509376049041748, acc: 0.7407407164573669)
                                                                               [2024-12-14 02:43:46,807][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:43:47,005][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 1.5343587398529053, acc: 0.5631067752838135)
[2024-12-14 02:43:47,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:47,523][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 1.577541708946228, acc: 0.5588235259056091)
[2024-12-14 02:43:47,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:47,936][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 1.913061261177063, acc: 0.5199999809265137)
[2024-12-14 02:43:48,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:48,349][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 1.8306715488433838, acc: 0.4861111044883728)
                                          [2024-12-14 02:43:48,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:48,714][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.584293782711029, acc: 0.8139534592628479)
[2024-12-14 02:43:48,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:49,038][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.1507430523633957, acc: 0.9583333134651184)
[2024-12-14 02:43:49,139][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:43:49,405][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.7334800362586975, acc: 0.8372092843055725)
                                                                   [2024-12-14 02:43:49,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:49,805][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.2709118723869324, acc: 0.8799999952316284)
                                                                              [2024-12-14 02:43:49,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:50,347][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 1.0530335903167725, acc: 0.6617646813392639)
                                                                                                                                                                                                                                             [2024-12-14 02:43:50,454][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.343644618988037, acc: 0.6219512224197388)
[2024-12-14 02:43:50,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:50,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:50,827][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 1.9005130529403687, acc: 0.4833836853504181)
[2024-12-14 02:43:50,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:50,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:51,166][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 2.118206739425659, acc: 0.45821326971054077)
[2024-12-14 02:43:51,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:51,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:51,641][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 2.077726364135742, acc: 0.4375)
[2024-12-14 02:43:51,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:51,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:52,011][slam_llm.models.slam_model][INFO] - modality encoder
                                                                        [2024-12-14 02:43:52,182][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 2.0155303478240967, acc: 0.46904316544532776)
[2024-12-14 02:43:52,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:52,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:52,630][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 1.8858436346054077, acc: 0.5195729732513428)
[2024-12-14 02:43:52,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:52,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:52,991][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.6629704236984253, acc: 0.800000011920929)
[2024-12-14 02:43:53,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:53,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:53,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:53,547][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 1.7447341680526733, acc: 0.5348837375640869)
[2024-12-14 02:43:53,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:53,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:53,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:54,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:54,344][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.6572867631912231, acc: 0.5873016119003296)
[2024-12-14 02:43:54,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:54,604][slam_llm.models.slam_model][INFO] - modality encoder
                                      [2024-12-14 02:43:54,883][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:43:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:55,264][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 1.6429195404052734, acc: 0.5454545617103577)
[2024-12-14 02:43:55,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:55,484][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:43:55,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:56,011][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 1.2602847814559937, acc: 0.658823549747467)
[2024-12-14 02:43:56,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:56,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:56,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:57,071][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:43:57,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:57,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:43:58,035][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:43:58,368][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:43:58,803][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:43:59,215][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:43:59,531][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:43:59,864][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:44:00,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:00,586][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:44:00,871][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:44:01,277][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:44:01,569][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:44:01,975][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:44:02,277][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                         [2024-12-14 02:44:02,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:02,792][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:44:03,159][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:44:03,445][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:44:03,765][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:44:04,074][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:44:04,362][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:44:04,690][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:44:05,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:05,403][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:44:05,786][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:44:06,113][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:44:06,449][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:44:06,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:06,765][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 1.0491420030593872, acc: 0.684684693813324)
[2024-12-14 02:44:06,825][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.7286916971206665, acc: 0.7586206793785095)
[2024-12-14 02:44:06,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:06,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:07,169][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 0.9478681683540344, acc: 0.6666666865348816)
[2024-12-14 02:44:07,186][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.35659459233283997, acc: 0.8799999952316284)
[2024-12-14 02:44:07,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:07,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:07,503][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.8635607957839966, acc: 0.7021276354789734)
[2024-12-14 02:44:07,540][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.3456779420375824, acc: 0.939393937587738)
[2024-12-14 02:44:07,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:07,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:07,832][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.5592231750488281, acc: 0.7916666865348816)
[2024-12-14 02:44:07,856][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.2293170988559723, acc: 0.9259259104728699)
[2024-12-14 02:44:07,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:07,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:08,189][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.22599095106124878, acc: 0.9200000166893005)
[2024-12-14 02:44:08,207][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.5253728032112122, acc: 0.8636363744735718)
[2024-12-14 02:44:08,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:08,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:08,594][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 0.7340434193611145, acc: 0.7884615659713745)
[2024-12-14 02:44:08,637][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 1.270647406578064, acc: 0.6385542154312134)
[2024-12-14 02:44:08,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:08,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:09,000][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 1.4074667692184448, acc: 0.5925925970077515)
[2024-12-14 02:44:09,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:09,362][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 1.1809086799621582, acc: 0.66847825050354)
[2024-12-14 02:44:09,379][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.510349452495575, acc: 0.8157894611358643)
[2024-12-14 02:44:09,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:09,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:09,754][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.31095415353775024, acc: 0.9411764740943909)
[2024-12-14 02:44:09,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:09,903][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 1.518784999847412, acc: 0.5681818127632141)
[2024-12-14 02:44:10,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:10,170][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.6030905246734619, acc: 0.824999988079071)
[2024-12-14 02:44:10,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:10,339][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 1.357395052909851, acc: 0.585106372833252)
[2024-12-14 02:44:10,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:10,566][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 1.6312389373779297, acc: 0.484375)
[2024-12-14 02:44:10,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:10,690][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.6397275924682617, acc: 0.8301886916160583)
[2024-12-14 02:44:10,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:10,887][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 1.672446370124817, acc: 0.5759999752044678)
[2024-12-14 02:44:10,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:11,037][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.7882770299911499, acc: 0.7666666507720947)
[2024-12-14 02:44:11,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:11,240][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 1.2814412117004395, acc: 0.6813187003135681)
[2024-12-14 02:44:11,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:11,451][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.36852794885635376, acc: 0.8837209343910217)
[2024-12-14 02:44:11,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:11,599][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 1.947872519493103, acc: 0.4968944191932678)
[2024-12-14 02:44:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:11,838][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 0.2935652732849121, acc: 0.8666666746139526)
[2024-12-14 02:44:11,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:12,016][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 2.013404130935669, acc: 0.44329896569252014)
[2024-12-14 02:44:12,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:12,259][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 1.6091866493225098, acc: 0.5473684072494507)
[2024-12-14 02:44:12,343][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.33426007628440857, acc: 0.9545454382896423)
[2024-12-14 02:44:12,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:12,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:12,637][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 1.1924132108688354, acc: 0.6555555462837219)
[2024-12-14 02:44:12,713][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.764258086681366, acc: 0.6904761791229248)
[2024-12-14 02:44:12,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:12,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:13,061][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 1.0352452993392944, acc: 0.7055555582046509)
[2024-12-14 02:44:13,080][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.9375239610671997, acc: 0.7068965435028076)
[2024-12-14 02:44:13,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:13,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:13,551][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.7771140336990356, acc: 0.7818182110786438)
[2024-12-14 02:44:13,553][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 1.595253586769104, acc: 0.6192660331726074)
[2024-12-14 02:44:13,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:13,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:14,023][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 1.0747321844100952, acc: 0.7307692170143127)
[2024-12-14 02:44:14,106][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 1.5484524965286255, acc: 0.5670102834701538)
[2024-12-14 02:44:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:14,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:14,366][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.238688662648201, acc: 0.9473684430122375)
[2024-12-14 02:44:14,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:14,478][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 1.0521767139434814, acc: 0.7241379022598267)
[2024-12-14 02:44:14,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:14,684][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.30329790711402893, acc: 0.875)
[2024-12-14 02:44:14,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:14,835][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.5357729196548462, acc: 0.8888888955116272)
[2024-12-14 02:44:14,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:15,065][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.772164523601532, acc: 0.7272727489471436)
[2024-12-14 02:44:15,158][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.7829452753067017, acc: 0.7631579041481018)
[2024-12-14 02:44:15,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:15,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:15,475][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.39601799845695496, acc: 0.8888888955116272)
[2024-12-14 02:44:15,498][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.5522826910018921, acc: 0.8571428656578064)
[2024-12-14 02:44:15,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:15,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:15,818][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.1789015233516693, acc: 0.9714285731315613)
[2024-12-14 02:44:15,874][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.421399861574173, acc: 0.875)
[2024-12-14 02:44:15,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:16,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:16,167][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.7044755220413208, acc: 0.8409090638160706)
[2024-12-14 02:44:16,247][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.8931589126586914, acc: 0.698113203048706)
[2024-12-14 02:44:16,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:16,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:16,548][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.6079989075660706, acc: 0.7954545617103577)
[2024-12-14 02:44:16,641][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.3960850238800049, acc: 0.8867924809455872)
[2024-12-14 02:44:16,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:16,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:16,980][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.3830394148826599, acc: 0.8529411554336548)
[2024-12-14 02:44:17,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:17,127][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 1.0729591846466064, acc: 0.6774193644523621)
[2024-12-14 02:44:17,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:17,304][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.38854408264160156, acc: 0.875)
[2024-12-14 02:44:17,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:17,659][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.584033191204071, acc: 0.8863636255264282)
[2024-12-14 02:44:17,690][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.8083717226982117, acc: 0.7868852615356445)
[2024-12-14 02:44:17,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:17,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:17,964][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.024175817146897316, acc: 1.0)
[2024-12-14 02:44:18,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:18,084][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.3291398882865906, acc: 0.8666666746139526)
[2024-12-14 02:44:18,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:18,272][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.1475096195936203, acc: 0.9615384340286255)
[2024-12-14 02:44:18,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:18,418][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.20047833025455475, acc: 0.8947368264198303)
[2024-12-14 02:44:18,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:18,591][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.3552190959453583, acc: 0.9354838728904724)
[2024-12-14 02:44:18,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:18,712][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 1.2031333446502686, acc: 0.5797101259231567)
[2024-12-14 02:44:18,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:18,957][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.1573997437953949, acc: 1.0)
[2024-12-14 02:44:19,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:19,169][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 1.0095829963684082, acc: 0.7222222089767456)
[2024-12-14 02:44:19,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:19,327][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.4856348931789398, acc: 0.8648648858070374)
[2024-12-14 02:44:19,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:19,570][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.9944875240325928, acc: 0.6987951993942261)
[2024-12-14 02:44:19,646][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.35343703627586365, acc: 0.8918918967247009)
[2024-12-14 02:44:19,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:19,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:19,955][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 1.4144943952560425, acc: 0.5384615659713745)
[2024-12-14 02:44:19,962][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.44408437609672546, acc: 0.7837837934494019)
[2024-12-14 02:44:20,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:20,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:20,279][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 0.8928865790367126, acc: 0.7352941036224365)
[2024-12-14 02:44:20,321][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 1.4213194847106934, acc: 0.6224489808082581)
[2024-12-14 02:44:20,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:20,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:20,620][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.2191798985004425, acc: 0.9024389982223511)
[2024-12-14 02:44:20,673][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.08137453347444534, acc: 0.9583333134651184)
[2024-12-14 02:44:20,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:20,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:20,996][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.25187256932258606, acc: 0.9200000166893005)
[2024-12-14 02:44:21,008][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.38165438175201416, acc: 0.9166666865348816)
[2024-12-14 02:44:21,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:21,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:21,354][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.39534270763397217, acc: 0.9032257795333862)
[2024-12-14 02:44:21,374][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.021465733647346497, acc: 1.0)
[2024-12-14 02:44:21,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:21,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:21,704][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.09810623526573181, acc: 1.0)
[2024-12-14 02:44:21,731][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.40960150957107544, acc: 0.9032257795333862)
[2024-12-14 02:44:21,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:21,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:22,084][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.5571998953819275, acc: 0.8245614171028137)
[2024-12-14 02:44:22,133][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.8730950355529785, acc: 0.7313432693481445)
[2024-12-14 02:44:22,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:22,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:22,479][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.740272581577301, acc: 0.7857142686843872)
[2024-12-14 02:44:22,511][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.965694010257721, acc: 0.6730769276618958)
[2024-12-14 02:44:22,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:22,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:22,824][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.6716145873069763, acc: 0.8026315569877625)
[2024-12-14 02:44:22,892][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.38866543769836426, acc: 0.8888888955116272)
[2024-12-14 02:44:22,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:22,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:23,212][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.811064600944519, acc: 0.774193525314331)
[2024-12-14 02:44:23,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:23,387][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 1.201666235923767, acc: 0.6792452931404114)
[2024-12-14 02:44:23,520][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.42898690700531006, acc: 0.8799999952316284)
[2024-12-14 02:44:23,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:23,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:23,800][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 1.0000163316726685, acc: 0.7037037014961243)
[2024-12-14 02:44:23,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:23,966][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 1.3961308002471924, acc: 0.6083333492279053)
[2024-12-14 02:44:24,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:24,156][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 0.7509375214576721, acc: 0.8285714387893677)
[2024-12-14 02:44:24,244][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.45533955097198486, acc: 0.8888888955116272)
[2024-12-14 02:44:24,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:24,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:24,498][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 1.0360164642333984, acc: 0.6410256624221802)
[2024-12-14 02:44:24,608][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.4867495000362396, acc: 0.8387096524238586)
[2024-12-14 02:44:24,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:24,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:25,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:25,514][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:44:26,257][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.7450, device='cuda:0') eval_epoch_loss=tensor(1.7483, device='cuda:0') eval_epoch_acc=tensor(0.5849, device='cuda:0')
[2024-12-14 02:44:26,258][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:44:26,258][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:44:26,448][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_7_step_417_loss_1.7483309507369995/model.pt
[2024-12-14 02:44:26,451][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:44:26,452][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.5849462151527405
[2024-12-14 02:44:26,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:26,863][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.33881938457489014, acc: 0.8888888955116272)
[2024-12-14 02:44:26,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:27,255][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.769219696521759, acc: 0.7250000238418579)
                                                                                                                                                                                                              [2024-12-14 02:44:27,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:27,650][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.2763741910457611, acc: 0.8999999761581421)
                                                                                                                                                                                                                       [2024-12-14 02:44:27,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:28,019][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.3117613196372986, acc: 0.9047619104385376)
                                                                                                                                                                                                          [2024-12-14 02:44:28,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:28,344][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.5355450510978699, acc: 0.8333333134651184)
                                                                                                                                                                                                                        [2024-12-14 02:44:28,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:28,726][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.3152056038379669, acc: 0.90625)
[2024-12-14 02:44:28,658][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.309337854385376, acc: 0.8947368264198303)
[2024-12-14 02:44:28,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:28,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:28,972][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.2680250108242035, acc: 0.8999999761581421)
[2024-12-14 02:44:29,055][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 1.0065054893493652, acc: 0.7200000286102295)
[2024-12-14 02:44:29,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:29,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:29,362][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.9197224378585815, acc: 0.7333333492279053)
[2024-12-14 02:44:29,466][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 1.6692065000534058, acc: 0.540229856967926)
[2024-12-14 02:44:29,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:29,866][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 1.5428063869476318, acc: 0.5744680762290955)
[2024-12-14 02:44:29,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:30,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:30,206][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 1.7280917167663574, acc: 0.46987950801849365)
[2024-12-14 02:44:30,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:30,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:30,585][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.16372013092041016, acc: 0.95652174949646)
[2024-12-14 02:44:30,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:30,913][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.6909818053245544, acc: 0.7692307829856873)
[2024-12-14 02:44:30,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:31,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:31,263][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 1.3234435319900513, acc: 0.6265060305595398)
[2024-12-14 02:44:31,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:31,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:31,640][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.8318243026733398, acc: 0.7547169923782349)
[2024-12-14 02:44:31,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:31,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:32,050][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 1.0281341075897217, acc: 0.6962025165557861)
[2024-12-14 02:44:32,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:32,186][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:44:32,437][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.9291951656341553, acc: 0.7254902124404907)
[2024-12-14 02:44:32,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:32,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:32,802][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 1.5276451110839844, acc: 0.5373134613037109)
[2024-12-14 02:44:32,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:33,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:33,202][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.18817496299743652, acc: 0.949999988079071)
[2024-12-14 02:44:33,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:33,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:33,740][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.5184148550033569, acc: 0.8333333134651184)

[2024-12-14 02:44:33,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:33,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:33,993][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.8315518498420715, acc: 0.7777777910232544)
[2024-12-14 02:44:34,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:34,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:34,312][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 1.1078304052352905, acc: 0.6279069781303406)
[2024-12-14 02:44:34,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:34,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:34,639][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.928265392780304, acc: 0.7435897588729858)
[2024-12-14 02:44:34,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:34,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:35,042][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 1.0077260732650757, acc: 0.6888889074325562)
[2024-12-14 02:44:35,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:35,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:35,413][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.35723981261253357, acc: 0.9130434989929199)
[2024-12-14 02:44:35,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:35,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:35,791][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.4224222004413605, acc: 0.8461538553237915)
[2024-12-14 02:44:35,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:36,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:36,214][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 1.6969164609909058, acc: 0.5054945349693298)
[2024-12-14 02:44:36,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:36,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:36,718][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 1.5597100257873535, acc: 0.5565217137336731)
[2024-12-14 02:44:36,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:36,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:37,058][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 1.4245271682739258, acc: 0.5869565010070801)
[2024-12-14 02:44:37,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:37,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:37,418][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 1.0300840139389038, acc: 0.7142857313156128)
[2024-12-14 02:44:37,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:37,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:37,792][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.12039149552583694, acc: 0.9583333134651184)
[2024-12-14 02:44:37,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:37,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:38,169][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.21619075536727905, acc: 0.9230769276618958)
[2024-12-14 02:44:38,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:38,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:38,508][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.48215749859809875, acc: 0.8048780560493469)
[2024-12-14 02:44:38,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:39,000][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.1640065461397171, acc: 0.9642857313156128)
10, step 362/574 completed (loss: 0.8080788254737854, acc: 0.7111111283302307)
[2024-12-14 02:44:38,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:39,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:39,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:39,288][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 0.9995930194854736, acc: 0.7105262875556946)
[2024-12-14 02:44:39,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:39,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:39,692][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.9240753650665283, acc: 0.7560975551605225)
[2024-12-14 02:44:39,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:40,011][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.5445153117179871, acc: 0.7878788113594055)
[2024-12-14 02:44:40,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:40,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:40,365][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.09207399934530258, acc: 1.0)
[2024-12-14 02:44:40,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:40,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:40,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:40,749][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.05903853476047516, acc: 1.0)
[2024-12-14 02:44:40,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:41,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:41,142][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.26667019724845886, acc: 0.9642857313156128)
[2024-12-14 02:44:41,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:41,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:41,523][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.4280909597873688, acc: 0.875)
[2024-12-14 02:44:41,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:41,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:41,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:42,126][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 1.57229483127594, acc: 0.5757575631141663)
[2024-12-14 02:44:42,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:42,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:42,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:42,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:42,971][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 1.192854642868042, acc: 0.6792452931404114)
[2024-12-14 02:44:43,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:43,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:43,310][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 1.0479774475097656, acc: 0.7444444298744202)
[2024-12-14 02:44:43,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:43,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:43,650][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.753603458404541, acc: 0.75)
[2024-12-14 02:44:43,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:43,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:44,025][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.46213003993034363, acc: 0.9428571462631226)
[2024-12-14 02:44:44,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:44,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:44,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:44,721][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.6033084988594055, acc: 0.8260869383811951)
                                                                                                                                                                                                           [2024-12-14 02:44:44,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:45,117][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.9612440466880798, acc: 0.7023809552192688)
                                                                               [2024-12-14 02:44:45,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:45,457][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 1.2888576984405518, acc: 0.6746987700462341)
                                                                               [2024-12-14 02:44:45,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:45,827][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 0.9952247142791748, acc: 0.6936936974525452)
[2024-12-14 02:44:45,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:46,181][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 1.1998931169509888, acc: 0.6893203854560852)
                    [2024-12-14 02:44:46,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:46,578][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 1.0077744722366333, acc: 0.6991869807243347)
[2024-12-14 02:44:46,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:46,957][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.20955003798007965, acc: 0.9166666865348816)
[2024-12-14 02:44:47,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:47,296][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.5418173670768738, acc: 0.8214285969734192)
[2024-12-14 02:44:47,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:47,720][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 1.5442100763320923, acc: 0.5686274766921997)
[2024-12-14 02:44:47,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:48,127][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 1.7895172834396362, acc: 0.5196506381034851)
                                                                              [2024-12-14 02:44:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:48,474][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 1.2951258420944214, acc: 0.6770833134651184)
                                                                               [2024-12-14 02:44:48,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:48,842][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 1.5636656284332275, acc: 0.5644171833992004)
                                                                                                                                                               [2024-12-14 02:44:48,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:49,155][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 1.4265553951263428, acc: 0.6187050342559814)
[2024-12-14 02:44:49,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:49,537][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 1.8602038621902466, acc: 0.5025125741958618)
[2024-12-14 02:44:49,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:49,908][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.48484575748443604, acc: 0.8333333134651184)
                                                                                                                                                                                                                                 [2024-12-14 02:44:50,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:50,254][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.42820048332214355, acc: 0.8484848737716675)
                                                                 [2024-12-14 02:44:50,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:50,571][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.3124258816242218, acc: 0.8888888955116272)
                                                                               [2024-12-14 02:44:50,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:50,965][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.3414481282234192, acc: 0.8999999761581421)
                                                                               [2024-12-14 02:44:51,095][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:44:51,336][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.30358752608299255, acc: 0.8500000238418579)
[2024-12-14 02:44:51,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:51,702][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.7623947262763977, acc: 0.7413793206214905)
[2024-12-14 02:44:51,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:52,062][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.2583067715167999, acc: 0.9032257795333862)
[2024-12-14 02:44:52,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:52,404][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.29710716009140015, acc: 0.7894737124443054)
[2024-12-14 02:44:52,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:52,756][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.38541996479034424, acc: 0.8518518805503845)
[2024-12-14 02:44:52,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:53,138][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.35136231780052185, acc: 0.8571428656578064)
                                                                                                 [2024-12-14 02:44:53,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:53,500][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.33066338300704956, acc: 0.8636363744735718)
[2024-12-14 02:44:53,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:53,849][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 1.1837579011917114, acc: 0.6615384817123413)
                                                                                                                                                            [2024-12-14 02:44:53,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:54,213][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.5306645631790161, acc: 0.8666666746139526)
[2024-12-14 02:44:54,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:54,585][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.3057272136211395, acc: 0.8620689511299133)
                                                                 [2024-12-14 02:44:54,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:54,955][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.961657702922821, acc: 0.7450980544090271)
[2024-12-14 02:44:55,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:55,296][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.5325114130973816, acc: 0.7931034564971924)
[2024-12-14 02:44:55,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:55,643][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.40458953380584717, acc: 0.9473684430122375)
- modality encoder
[2024-12-14 02:44:55,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:55,784][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.7300090193748474, acc: 0.7878788113594055)
[2024-12-14 02:44:55,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:55,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:56,166][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.4934642016887665, acc: 0.8484848737716675)
[2024-12-14 02:44:56,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:56,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:56,529][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.22669273614883423, acc: 0.9032257795333862)
[2024-12-14 02:44:56,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:56,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:56,863][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.2654227316379547, acc: 0.8888888955116272)
[2024-12-14 02:44:56,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:56,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:57,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:57,222][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.1864442229270935, acc: 0.9599999785423279)
[2024-12-14 02:44:57,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:57,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:57,605][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.2699531018733978, acc: 0.9444444179534912)
[2024-12-14 02:44:57,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:57,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:57,984][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.2275606393814087, acc: 0.9259259104728699)
[2024-12-14 02:44:58,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:58,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:58,345][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.101943239569664, acc: 0.9615384340286255)
[2024-12-14 02:44:58,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:58,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:58,721][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.579338550567627, acc: 0.8793103694915771)
[2024-12-14 02:44:58,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:59,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:59,096][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.2574599087238312, acc: 0.8928571343421936)
[2024-12-14 02:44:59,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:59,447][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.26490917801856995, acc: 0.8999999761581421)
[2024-12-14 02:44:59,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:59,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:59,824][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.3395460546016693, acc: 0.9090909361839294)
[2024-12-14 02:44:59,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:44:59,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:00,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:00,188][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.19343768060207367, acc: 0.9090909361839294)
[2024-12-14 02:45:00,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:00,890][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 1.3398197889328003, acc: 0.6619718074798584)
[2024-12-14 02:45:00,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:00,813][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.7333, device='cuda:0') eval_epoch_loss=tensor(1.7463, device='cuda:0') eval_epoch_acc=tensor(0.5829, device='cuda:0')
[2024-12-14 02:45:00,814][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:45:00,815][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:45:00,863][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 0.38318315148353577, acc: 0.9230769276618958)
[2024-12-14 02:45:01,100][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_7_step_274_loss_1.7462944984436035/model.pt
[2024-12-14 02:45:01,107][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:45:01,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:01,544][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.26584261655807495, acc: 0.9375)
           [2024-12-14 02:45:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:01,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:01,935][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.32688841223716736, acc: 0.8333333134651184)
[2024-12-14 02:45:01,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:02,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:02,308][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.727159321308136, acc: 0.8275862336158752)
[2024-12-14 02:45:02,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:02,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:02,710][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.5208326578140259, acc: 0.8399999737739563)
[2024-12-14 02:45:02,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:02,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:03,076][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.9624572396278381, acc: 0.6808510422706604)
[2024-12-14 02:45:03,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:03,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:03,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:03,499][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.9648457169532776, acc: 0.7291666865348816)
[2024-12-14 02:45:03,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:03,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:03,859][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.6652044057846069, acc: 0.8409090638160706)
[2024-12-14 02:45:03,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:04,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:04,306][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 1.3690563440322876, acc: 0.6385542154312134)
[2024-12-14 02:45:04,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:04,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:04,686][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 1.3935273885726929, acc: 0.6296296119689941)
[2024-12-14 02:45:04,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:05,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:05,051][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.42297202348709106, acc: 0.8947368264198303)
[2024-12-14 02:45:05,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:05,398][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.4523070752620697, acc: 0.8529411554336548)
[2024-12-14 02:45:05,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:05,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:05,759][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.4408031404018402, acc: 0.824999988079071)
[2024-12-14 02:45:05,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:05,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:06,101][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 1.5681406259536743, acc: 0.46875)
[2024-12-14 02:45:06,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:06,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:06,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:06,552][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 1.7302887439727783, acc: 0.5519999861717224)
[2024-12-14 02:45:06,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:06,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:06,923][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 1.060597538948059, acc: 0.7142857313156128)
[2024-12-14 02:45:07,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:07,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:07,273][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 1.843682885169983, acc: 0.5031055808067322)
[2024-12-14 02:45:07,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:07,454][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:45:07,619][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 1.818899393081665, acc: 0.5)
[2024-12-14 02:45:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:07,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:08,035][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.11367964744567871, acc: 0.9545454382896423)
[2024-12-14 02:45:08,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:08,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:08,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:08,412][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.9607174396514893, acc: 0.7857142686843872)
[2024-12-14 02:45:08,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:08,817][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.8389955163002014, acc: 0.7241379022598267)
[2024-12-14 02:45:09,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:09,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:09,325][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.7737981081008911, acc: 0.7818182110786438)
[2024-12-14 02:45:09,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:09,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:09,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:09,886][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 1.4614943265914917, acc: 0.5824742317199707)
[2024-12-14 02:45:09,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:10,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:10,254][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 1.1062548160552979, acc: 0.6724137663841248)
[2024-12-14 02:45:10,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:10,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:7841362357139587, acc: 0.7592592835426331)
[2024-12-14 02:45:10,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:10,994][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.7715688943862915, acc: 0.7115384340286255)
[2024-12-14 02:45:11,073][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:45:11,341][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.4107506573200226, acc: 0.8571428656578064)
[2024-12-14 02:45:11,457][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                               [2024-12-14 02:45:11,700][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 1.072338581085205, acc: 0.6557376980781555)
[2024-12-14 02:45:11,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:12,001][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 1.1194742918014526, acc: 0.7118644118309021)
           [2024-12-14 02:45:12,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:12,389][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 0.9849871397018433, acc: 0.7906976938247681)
                                                                               [2024-12-14 02:45:12,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:12,772][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.6296602487564087, acc: 0.8636363744735718)
                                                                               [2024-12-14 02:45:12,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:13,105][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.7990782856941223, acc: 0.7169811129570007)
                                                                                [2024-12-14 02:45:13,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:13,450][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.6473605036735535, acc: 0.8409090638160706)
                                                                   [2024-12-14 02:45:13,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:13,824][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.20538263022899628, acc: 0.8799999952316284)
                                                                                                                                                                                                                      [2024-12-14 02:45:13,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:14,174][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.3172297775745392, acc: 0.8500000238418579)
                                                                  [2024-12-14 02:45:14,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:14,473][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.22500038146972656, acc: 1.0)
                                                                                             [2024-12-14 02:45:14,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:14,891][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.7380790114402771, acc: 0.8307692408561707)
                                                                 [2024-12-14 02:45:14,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:15,277][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.7330029010772705, acc: 0.859375)
                                                                                         [2024-12-14 02:45:15,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:15,674][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.35063114762306213, acc: 0.9375)
                                                                                          [2024-12-14 02:45:15,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:16,004][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.677062451839447, acc: 0.8181818127632141)
[2024-12-14 02:45:16,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:16,358][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.22309724986553192, acc: 0.9375)
                                                                                                                                                            [2024-12-14 02:45:16,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:16,683][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.21360163390636444, acc: 0.9354838728904724)
                                                                                                                                                              [2024-12-14 02:45:16,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:17,055][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.06303905695676804, acc: 0.95652174949646)
                                                                                 [2024-12-14 02:45:17,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:17,423][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.6632719039916992, acc: 0.800000011920929)
 [2024-12-14 02:45:17,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:17,808][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.5257129073143005, acc: 0.8048780560493469)
                                                                               [2024-12-14 02:45:17,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:18,182][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.24710869789123535, acc: 0.9142857193946838)
                                                                              [2024-12-14 02:45:18,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:18,555][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.3258718252182007, acc: 0.9473684430122375)
                                                                               [2024-12-14 02:45:18,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:18,873][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.23705287277698517, acc: 0.9354838728904724)
                                                                              [2024-12-14 02:45:18,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:19,192][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.16394470632076263, acc: 0.9599999785423279)
[2024-12-14 02:45:19,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:19,543][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.32679951190948486, acc: 0.9090909361839294)
                    [2024-12-14 02:45:19,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:19,925][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.47764644026756287, acc: 0.875)
                                                                                           [2024-12-14 02:45:20,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:20,273][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.63437819480896, acc: 0.8285714387893677)
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:45:20,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:20,693][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 1.6595147848129272, acc: 0.5328466892242432)
                                                                               [2024-12-14 02:45:20,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:21,075][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 1.3168976306915283, acc: 0.6137930750846863)
                                                                                                                                                              [2024-12-14 02:45:21,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:21,465][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 1.8409934043884277, acc: 0.5071428418159485)
                                                                                [2024-12-14 02:45:21,596][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                          [2024-12-14 02:45:21,835][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 1.5874402523040771, acc: 0.49668875336647034)
[2024-12-14 02:45:21,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:22,199][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 1.0863434076309204, acc: 0.6837607026100159)
                                                                               [2024-12-14 02:45:22,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:22,541][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.19579562544822693, acc: 0.9599999785423279)
[2024-12-14 02:45:22,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:22,943][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.2692931592464447, acc: 0.9230769276618958)
                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:45:23,664][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:45:24,087][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:45:24,420][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:45:24,799][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:45:25,220][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:45:25,610][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:45:25,905][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:45:26,342][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:45:26,780][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:45:27,066][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:45:27,404][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:45:27,736][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:45:28,218][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:45:28,569][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:45:28,970][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:45:29,409][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:45:29,733][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:45:30,055][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:45:30,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:30,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:30,542][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.25041621923446655, acc: 0.9130434989929199)
[2024-12-14 02:45:30,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:30,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:30,946][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.19638392329216003, acc: 1.0)
[2024-12-14 02:45:31,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:31,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:31,357][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 1.6361685991287231, acc: 0.5054945349693298)
[2024-12-14 02:45:31,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:31,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:31,876][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 1.5482017993927002, acc: 0.626086950302124)
[2024-12-14 02:45:31,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:32,055][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.7714, device='cuda:0') eval_epoch_loss=tensor(1.7529, device='cuda:0') eval_epoch_acc=tensor(0.5947, device='cuda:0')
[2024-12-14 02:45:32,056][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:45:32,056][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:45:32,215][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 1.2630560398101807, acc: 0.6086956262588501)
[2024-12-14 02:45:32,272][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_7_step_417_loss_1.752912163734436/model.pt
[2024-12-14 02:45:32,275][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:45:32,276][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.594660222530365
[2024-12-14 02:45:32,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:32,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:32,620][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.22956688702106476, acc: 0.9444444179534912)
[2024-12-14 02:45:32,642][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 1.1142404079437256, acc: 0.6530612111091614)
[2024-12-14 02:45:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:32,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:32,946][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.5930450558662415, acc: 0.824999988079071)
[2024-12-14 02:45:32,970][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.05498404800891876, acc: 1.0)
[2024-12-14 02:45:33,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:33,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:33,283][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.22880582511425018, acc: 0.8999999761581421)
[2024-12-14 02:45:33,284][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.2110036313533783, acc: 0.9230769276618958)
[2024-12-14 02:45:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:33,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:33,619][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.5373273491859436, acc: 0.8292682766914368)
[2024-12-14 02:45:33,642][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.053792987018823624, acc: 1.0)
[2024-12-14 02:45:33,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:34,094][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:45:34,428][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:45:34,811][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:45:35,221][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:45:35,665][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:45:36,039][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:45:36,486][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                       [2024-12-14 02:45:36,833][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:45:37,230][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:45:37,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:37,473][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.03354980796575546, acc: 1.0)
[2024-12-14 02:45:37,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:37,836][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.08402387797832489, acc: 1.0)
[2024-12-14 02:45:37,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:37,972][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 1.1894302368164062, acc: 0.6603773832321167)
[2024-12-14 02:45:38,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:38,249][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.4925384521484375, acc: 0.8611111044883728)
[2024-12-14 02:45:38,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:38,376][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 0.9859293699264526, acc: 0.7444444298744202)
[2024-12-14 02:45:38,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:38,612][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.0688413605093956, acc: 1.0)
[2024-12-14 02:45:38,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:38,717][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.8156284689903259, acc: 0.75)
[2024-12-14 02:45:38,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:38,957][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.402770072221756, acc: 0.8787878751754761)
[2024-12-14 02:45:39,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:39,099][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.4891732931137085, acc: 0.8857142925262451)
[2024-12-14 02:45:39,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:39,302][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.38405004143714905, acc: 0.9166666865348816)
[2024-12-14 02:45:39,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:39,495][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.14936429262161255, acc: 0.9599999785423279)
[2024-12-14 02:45:39,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:39,688][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.733722448348999, acc: 0.8181818127632141)
[2024-12-14 02:45:39,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:39,876][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.17929977178573608, acc: 0.95652174949646)
[2024-12-14 02:45:39,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:40,033][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.08782334625720978, acc: 0.9523809552192688)
[2024-12-14 02:45:40,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:40,220][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.6965956091880798, acc: 0.7916666865348816)
[2024-12-14 02:45:40,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:40,407][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.5280534029006958, acc: 0.8461538553237915)
[2024-12-14 02:45:40,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:40,633][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 1.0117961168289185, acc: 0.7157894968986511)
[2024-12-14 02:45:40,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:40,872][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 1.3250726461410522, acc: 0.6666666865348816)
[2024-12-14 02:45:41,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:41,209][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 1.2825613021850586, acc: 0.6706587076187134)
[2024-12-14 02:45:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:41,550][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 1.9615641832351685, acc: 0.46399998664855957)
[2024-12-14 02:45:41,632][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 1.0613551139831543, acc: 0.7142857313156128)
[2024-12-14 02:45:41,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:41,972][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 1.7486735582351685, acc: 0.5483871102333069)
[2024-12-14 02:45:42,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:42,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:42,633][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 1.7382832765579224, acc: 0.5323383212089539)
[2024-12-14 02:45:42,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:42,765][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 1.2847834825515747, acc: 0.6470588445663452)
[2024-12-14 02:45:42,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:42,956][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 1.171495795249939, acc: 0.7169811129570007)
[2024-12-14 02:45:43,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:43,333][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.8082566857337952, acc: 0.792792797088623)
[2024-12-14 02:45:43,378][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.5400878190994263, acc: 0.8181818127632141)
[2024-12-14 02:45:43,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:43,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:43,674][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.41833359003067017, acc: 0.8571428656578064)
[2024-12-14 02:45:43,782][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.265481561422348, acc: 0.9130434989929199)
[2024-12-14 02:45:43,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:43,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:44,033][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.30031758546829224, acc: 0.8928571343421936)
[2024-12-14 02:45:44,124][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.5554484128952026, acc: 0.7307692170143127)
[2024-12-14 02:45:44,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:44,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:44,419][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.47642821073532104, acc: 0.8125)
[2024-12-14 02:45:44,524][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.2823323607444763, acc: 0.8571428656578064)
[2024-12-14 02:45:44,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:44,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:44,780][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.44020897150039673, acc: 0.8611111044883728)
[2024-12-14 02:45:44,901][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 1.0582636594772339, acc: 0.7611940503120422)
[2024-12-14 02:45:44,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:45,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:45,157][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.44159331917762756, acc: 0.8421052694320679)
[2024-12-14 02:45:45,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:45,295][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 1.1507099866867065, acc: 0.6805555820465088)
[2024-12-14 02:45:45,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:45,481][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.03883099555969238, acc: 1.0)
[2024-12-14 02:45:45,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:45,649][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 1.0022612810134888, acc: 0.739130437374115)
[2024-12-14 02:45:45,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:45,827][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.1488056480884552, acc: 0.949999988079071)
[2024-12-14 02:45:45,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:46,005][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 1.0032000541687012, acc: 0.6794871687889099)
[2024-12-14 02:45:46,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:46,174][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.10581157356500626, acc: 1.0)
[2024-12-14 02:45:46,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:46,321][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.9692631959915161, acc: 0.7105262875556946)
[2024-12-14 02:45:46,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:46,540][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.9564095139503479, acc: 0.7407407164573669)
[2024-12-14 02:45:46,614][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.745543897151947, acc: 0.7755101919174194)
[2024-12-14 02:45:46,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:46,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:46,945][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 1.6163502931594849, acc: 0.5339806079864502)
[2024-12-14 02:45:46,991][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.28282031416893005, acc: 0.9090909361839294)
[2024-12-14 02:45:47,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:47,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:47,390][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 1.4589935541152954, acc: 0.5876288414001465)
[2024-12-14 02:45:47,505][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 1.6669691801071167, acc: 0.5441176295280457)
[2024-12-14 02:45:47,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:47,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:47,777][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 0.8939197659492493, acc: 0.7571428418159485)
[2024-12-14 02:45:47,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:47,936][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 1.7206231355667114, acc: 0.5199999809265137)
[2024-12-14 02:45:48,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:48,205][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 1.5222872495651245, acc: 0.5639534592628479)
[2024-12-14 02:45:48,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:48,311][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 1.8775092363357544, acc: 0.4861111044883728)
[2024-12-14 02:45:48,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:48,533][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.9580987691879272, acc: 0.7321428656578064)
[2024-12-14 02:45:48,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:48,695][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.711173951625824, acc: 0.7906976938247681)
[2024-12-14 02:45:48,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:48,857][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 1.2566584348678589, acc: 0.6790123581886292)
[2024-12-14 02:45:48,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:48,995][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.49637842178344727, acc: 0.875)
[2024-12-14 02:45:49,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:49,182][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.5356576442718506, acc: 0.7777777910232544)
[2024-12-14 02:45:49,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:49,331][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.6096016764640808, acc: 0.8139534592628479)
[2024-12-14 02:45:49,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:49,518][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.17574730515480042, acc: 0.96875)
[2024-12-14 02:45:49,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:49,706][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.26711225509643555, acc: 0.9599999785423279)
[2024-12-14 02:45:49,834][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.540672242641449, acc: 0.807692289352417)
[2024-12-14 02:45:49,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:49,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:50,169][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.4679306745529175, acc: 0.9130434989929199)
[2024-12-14 02:45:50,242][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 1.1087932586669922, acc: 0.6764705777168274)
[2024-12-14 02:45:50,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:50,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:50,552][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.8159124255180359, acc: 0.738095223903656)
[2024-12-14 02:45:50,625][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 1.0499659776687622, acc: 0.7333333492279053)
[2024-12-14 02:45:50,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:50,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:50,869][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 1.0176938772201538, acc: 0.6867470145225525)
[2024-12-14 02:45:50,967][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.46536898612976074, acc: 0.8787878751754761)
[2024-12-14 02:45:50,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:51,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:51,239][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 0.94109046459198, acc: 0.6936936974525452)
[2024-12-14 02:45:51,328][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.4402276873588562, acc: 0.8787878751754761)
[2024-12-14 02:45:51,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:51,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:51,633][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 1.0485025644302368, acc: 0.6990291476249695)
[2024-12-14 02:45:51,723][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.18306219577789307, acc: 0.9677419066429138)
[2024-12-14 02:45:51,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:51,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:51,970][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 1.1071183681488037, acc: 0.7154471278190613)
[2024-12-14 02:45:52,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:52,066][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.24835741519927979, acc: 0.9259259104728699)
[2024-12-14 02:45:52,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:52,308][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.22880659997463226, acc: 0.9166666865348816)
[2024-12-14 02:45:52,375][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.0856916531920433, acc: 0.9599999785423279)
[2024-12-14 02:45:52,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:52,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:52,763][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.4202651381492615, acc: 0.8928571343421936)
[2024-12-14 02:45:52,699][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.3153967559337616, acc: 0.9166666865348816)
[2024-12-14 02:45:52,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:52,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:53,099][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.18332546949386597, acc: 0.9259259104728699)
[2024-12-14 02:45:53,105][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 1.4588853120803833, acc: 0.5686274766921997)
[2024-12-14 02:45:53,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:53,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:53,491][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.09048338234424591, acc: 1.0)
[2024-12-14 02:45:53,504][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 1.8466987609863281, acc: 0.49344977736473083)
[2024-12-14 02:45:53,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:53,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:53,823][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 1.1661909818649292, acc: 0.7291666865348816)
[2024-12-14 02:45:53,908][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.8490196466445923, acc: 0.7758620977401733)
[2024-12-14 02:45:53,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:54,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:54,186][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 1.6109179258346558, acc: 0.5644171833992004)
[2024-12-14 02:45:54,276][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.41481325030326843, acc: 0.7857142686843872)
[2024-12-14 02:45:54,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:54,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:54,558][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 1.522559642791748, acc: 0.6043165326118469)
[2024-12-14 02:45:54,634][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.25497785210609436, acc: 0.9333333373069763)
[2024-12-14 02:45:54,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:54,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:54,913][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 1.7441127300262451, acc: 0.4974874258041382)
[2024-12-14 02:45:54,933][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.37832579016685486, acc: 0.9090909361839294)
[2024-12-14 02:45:55,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:55,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:55,228][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.35659465193748474, acc: 0.8888888955116272)
[2024-12-14 02:45:55,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:55,318][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.1836100071668625, acc: 0.9545454382896423)
[2024-12-14 02:45:55,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:55,561][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.3460270166397095, acc: 0.9090909361839294)
[2024-12-14 02:45:55,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:55,705][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 1.0057255029678345, acc: 0.7450980544090271)
[2024-12-14 02:45:55,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:55,906][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.45844534039497375, acc: 0.9259259104728699)
[2024-12-14 02:45:56,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:56,326][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 1.1966768503189087, acc: 0.6555555462837219)
                                                                                                                                         [2024-12-14 02:45:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:56,715][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.8638216257095337, acc: 0.6883116960525513)
[2024-12-14 02:45:56,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:57,044][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.47528955340385437, acc: 0.875)
[2024-12-14 02:45:57,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:57,388][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.5079299211502075, acc: 0.8275862336158752)
[2024-12-14 02:45:57,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:57,709][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 1.0337074995040894, acc: 0.6547619104385376)
[2024-12-14 02:45:57,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:58,070][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.367530882358551, acc: 0.8684210777282715)
                                 [2024-12-14 02:45:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:58,430][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.3059259057044983, acc: 0.8888888955116272)
                                                                               [2024-12-14 02:45:58,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:58,823][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 1.5025829076766968, acc: 0.5882353186607361)
                                                                                                                                                               [2024-12-14 02:45:58,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:59,212][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.8759442567825317, acc: 0.725806474685669)
                                                                                [2024-12-14 02:45:59,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:59,598][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 0.9627208709716797, acc: 0.7094017267227173)
[2024-12-14 02:45:59,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:45:59,933][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 1.8252360820770264, acc: 0.4693877696990967)
[2024-12-14 02:46:00,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:00,281][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 1.7305084466934204, acc: 0.5094339847564697)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:46:00,675][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=2.3475, train_epoch_loss=0.8534, epoch time 361.76009817793965s
[2024-12-14 02:46:00,675][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:46:00,676][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-12-14 02:46:00,676][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:46:00,676][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 20
[2024-12-14 02:46:00,676][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:46:01,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:01,137][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.1473214328289032, acc: 0.9473684430122375)
[2024-12-14 02:46:01,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:01,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:01,515][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.32469964027404785, acc: 0.9473684430122375)
[2024-12-14 02:46:01,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:01,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:01,898][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 1.4523905515670776, acc: 0.5982142686843872)
[2024-12-14 02:46:02,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:02,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:02,276][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 1.1517395973205566, acc: 0.6516854166984558)
[2024-12-14 02:46:02,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:02,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:02,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:02,604][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 1.4496080875396729, acc: 0.5955055952072144)
[2024-12-14 02:46:02,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:02,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:02,964][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.944840431213379, acc: 0.39007091522216797)
[2024-12-14 02:46:03,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:03,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:03,369][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 1.6531444787979126, acc: 0.510869562625885)
[2024-12-14 02:46:03,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:03,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:03,699][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.30981236696243286, acc: 0.9200000166893005)
[2024-12-14 02:46:03,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:04,044][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.1669711172580719, acc: 0.9230769276618958)
[2024-12-14 02:46:04,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:04,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:04,427][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.6835575103759766, acc: 0.8518518805503845)
[2024-12-14 02:46:04,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:04,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:04,800][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.6760014295578003, acc: 0.8148148059844971)
[2024-12-14 02:46:04,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:04,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:05,173][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.5818735361099243, acc: 0.8113207817077637)
[2024-12-14 02:46:05,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:05,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:05,545][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.42299166321754456, acc: 0.931034505367279)
[2024-12-14 02:46:05,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:05,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:05,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:06,151][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 1.535683274269104, acc: 0.5585585832595825)
[2024-12-14 02:46:06,206][slam_llm.models.slam_model][INFO] - modality encoder
[[2024-12-14 02:46:06,587][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.46974873542785645, acc: 0.8478260636329651)
[2024-12-14 02:46:06,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:06,983][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.6697535514831543, acc: 0.8039215803146362)
                     [2024-12-14 02:46:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:07,303][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.4638345539569855, acc: 0.8367347121238708)
                                                                   [2024-12-14 02:46:07,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:07,642][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.2028675079345703, acc: 0.8947368264198303)
                                                                                 [2024-12-14 02:46:07,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:07,990][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.15906701982021332, acc: 1.0)
               [2024-12-14 02:46:08,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:08,341][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.49486786127090454, acc: 0.8611111044883728)
[2024-12-14 02:46:08,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:08,700][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.10694976896047592, acc: 1.0)
[2024-12-14 02:46:08,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:09,032][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.5841513276100159, acc: 0.807692289352417)
[2024-12-14 02:46:09,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:09,352][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.29878243803977966, acc: 0.8965517282485962)
[2024-12-14 02:46:09,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:09,681][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.3267441689968109, acc: 0.9200000166893005)
[2024-12-14 02:46:09,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:10,064][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.30464375019073486, acc: 0.8571428656578064)
[2024-12-14 02:46:10,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:10,406][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.5896037817001343, acc: 0.8125)
             [2024-12-14 02:46:10,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:10,762][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 1.2733540534973145, acc: 0.6792452931404114)
[2024-12-14 02:46:10,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:11,139][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 1.4942784309387207, acc: 0.534246563911438)
                                                                               [2024-12-14 02:46:11,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:12,389][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 1.8677549362182617, acc: 0.5138339996337891)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:46:12,457][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:46:12,695][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.6027937531471252, acc: 0.8139534592628479)
[2024-12-14 02:46:12,777][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                 [2024-12-14 02:46:13,033][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 1.035849928855896, acc: 0.6987951993942261)
                                                                                                                                                               [2024-12-14 02:46:13,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:13,416][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 1.1337264776229858, acc: 0.604938268661499)
                                                                                 [2024-12-14 02:46:13,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:13,761][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.4508066773414612, acc: 0.8928571343421936)
                                                                                 [2024-12-14 02:46:13,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:14,106][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.6466925144195557, acc: 0.8148148059844971)
[2024-12-14 02:46:14,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:14,429][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.06593475490808487, acc: 0.95652174949646)
[2024-12-14 02:46:14,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:14,824][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 1.410861849784851, acc: 0.605042040348053)
[2024-12-14 02:46:14,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:15,165][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.8063675761222839, acc: 0.7213114500045776)
[2024-12-14 02:46:15,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:15,531][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 1.0972262620925903, acc: 0.6507936716079712)
                           [2024-12-14 02:46:15,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:15,905][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 1.3466284275054932, acc: 0.6440678238868713)
[2024-12-14 02:46:16,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:16,286][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.9583889245986938, acc: 0.6896551847457886)
[2024-12-14 02:46:16,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:16,587][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.2488546073436737, acc: 0.9523809552192688)
                        [2024-12-14 02:46:16,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:16,974][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.40867680311203003, acc: 0.8846153616905212)
                                                                 [2024-12-14 02:46:17,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:17,355][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 1.0212740898132324, acc: 0.7162162065505981)
                                                                                [2024-12-14 02:46:17,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:17,774][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 1.0644317865371704, acc: 0.7076923251152039)
                                                                                                                                                               [2024-12-14 02:46:17,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:18,161][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 1.2818067073822021, acc: 0.6969696879386902)
                                                                                [2024-12-14 02:46:18,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:18,567][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 1.134238839149475, acc: 0.7113401889801025)
                                                                                [2024-12-14 02:46:18,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:18,964][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 1.4198832511901855, acc: 0.5808823704719543)
 [2024-12-14 02:46:19,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:19,287][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.5808402299880981, acc: 0.8461538553237915)
                                                                                [2024-12-14 02:46:19,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:19,671][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.03902466967701912, acc: 1.0)
                                                                                              [2024-12-14 02:46:19,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:20,055][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.5019571185112, acc: 0.8571428656578064)
                                                                                                                                                                  [2024-12-14 02:46:20,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:20,410][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.13926270604133606, acc: 0.9722222089767456)
                                                                               [2024-12-14 02:46:20,488][slam_llm.models.slam_model][INFO] - modality encoder
                                            [2024-12-14 02:46:20,775][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.6007243394851685, acc: 0.7894737124443054)
[2024-12-14 02:46:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:21,230][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.8858160376548767, acc: 0.7301587462425232)
                                                                                                     [2024-12-14 02:46:21,327][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                               [2024-12-14 02:46:21,564][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.8473778367042542, acc: 0.7183098793029785)
[2024-12-14 02:46:21,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:22,011][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 1.6697951555252075, acc: 0.5933333039283752)
             [2024-12-14 02:46:22,114][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:46:22,391][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.26817989349365234, acc: 0.9459459185600281)
[2024-12-14 02:46:22,497][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                   [2024-12-14 02:46:22,753][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.15480099618434906, acc: 0.9230769276618958)
                                                                              [2024-12-14 02:46:24,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:25,691][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.6577513217926025, acc: 0.5563139915466309)
/10, step 543/574 completed (loss: 0.04972011595964432, acc: 1.0)
[2024-12-14 02:46:23,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:23,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:23,436][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.6021511554718018, acc: 0.8333333134651184)
[2024-12-14 02:46:23,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:23,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:23,789][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.40653181076049805, acc: 0.9024389982223511)
[2024-12-14 02:46:23,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:23,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:24,136][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.24439959228038788, acc: 0.9428571462631226)
[2024-12-14 02:46:24,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:24,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:24,479][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.2914430499076843, acc: 0.9210526347160339)
[2024-12-14 02:46:24,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:24,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:24,827][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.4406207501888275, acc: 0.8709677457809448)
[2024-12-14 02:46:24,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:24,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:25,164][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.037466634064912796, acc: 1.0)
[2024-12-14 02:46:25,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:25,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:25,475][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.19138593971729279, acc: 0.9696969985961914)
[2024-12-14 02:46:25,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:25,757][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.2800537943840027, acc: 0.949999988079071)
[2024-12-14 02:46:25,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:26,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:26,099][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.3212594985961914, acc: 0.9142857193946838)
[2024-12-14 02:46:26,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:26,470][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 1.4825783967971802, acc: 0.5912408828735352)
[2024-12-14 02:46:26,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:26,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:26,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:26,819][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 1.1687772274017334, acc: 0.634482741355896)
[2024-12-14 02:46:26,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:27,192][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 1.7105449438095093, acc: 0.5357142686843872)
[2024-12-14 02:46:27,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:27,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:27,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:27,500][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 1.4873601198196411, acc: 0.5165562629699707)
[2024-12-14 02:46:27,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:27,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:27,811][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 1.0545567274093628, acc: 0.6752136945724487)
[2024-12-14 02:46:27,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:28,186][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.03321853280067444, acc: 1.0)
[2024-12-14 02:46:28,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:28,402][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7039, device='cuda:0') eval_epoch_loss=tensor(1.9027, device='cuda:0') eval_epoch_acc=tensor(0.5604, device='cuda:0')
[2024-12-14 02:46:28,403][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:46:28,403][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:46:28,572][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.1414947509765625, acc: 0.9615384340286255)
[2024-12-14 02:46:28,642][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_7_step_417_loss_1.9026861190795898/model.pt
[2024-12-14 02:46:28,654][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:46:28,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:29,081][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.5411553978919983, acc: 0.7777777910232544)
[2024-12-14 02:46:29,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:29,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:29,461][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.7838166356086731, acc: 0.699999988079071)
[2024-12-14 02:46:29,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:29,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:29,853][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.5210448503494263, acc: 0.8500000238418579)
[2024-12-14 02:46:29,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:30,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:30,163][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.4523616433143616, acc: 0.9047619104385376)
[2024-12-14 02:46:30,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:30,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:30,546][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.25304898619651794, acc: 0.8999999761581421)
[2024-12-14 02:46:30,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:30,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:30,894][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.19759342074394226, acc: 0.96875)
[2024-12-14 02:46:31,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:31,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:31,276][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.7125453352928162, acc: 0.8611111044883728)
[2024-12-14 02:46:31,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:31,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:31,655][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.38712432980537415, acc: 0.9259259104728699)
[2024-12-14 02:46:31,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:31,883][slam_llm.models.slam_model][INFO] - modality encoder
                                                       [2024-12-14 02:46:32,065][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.2434626817703247, acc: 0.9696969985961914)
[2024-12-14 02:46:32,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:32,436][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.7294498682022095, acc: 0.8695651888847351)
[2024-12-14 02:46:32,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:32,652][slam_llmc: 0.6102941036224365)
[2024-12-14 02:46:32,882][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                [2024-12-14 02:46:33,182][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 1.468024492263794, acc: 0.5873016119003296)
[2024-12-14 02:46:33,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:33,546][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 1.8357958793640137, acc: 0.49743589758872986)
[2024-12-14 02:46:33,628][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                  [2024-12-14 02:46:33,905][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 1.2270989418029785, acc: 0.6326530575752258)
[2024-12-14 02:46:34,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:34,295][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 1.7782227993011475, acc: 0.4776119291782379)
[2024-12-14 02:46:34,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:34,699][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.9318257570266724, acc: 0.485401451587677)
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:46:34,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:35,073][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.03974061831831932, acc: 1.0)
                                                                                              [2024-12-14 02:46:35,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:35,437][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.12364184111356735, acc: 0.9583333134651184)
[2024-12-14 02:46:35,529][slam_llm.models.slam_model][INFO] - modality encoder
                                                                             [2024-12-14 02:46:35,812][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.24474270641803741, acc: 0.939393937587738)
                                                                                [2024-12-14 02:46:35,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:36,168][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.06388753652572632, acc: 1.0)
                                                                                                                                                                              [2024-12-14 02:46:36,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:36,540][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.8614663481712341, acc: 0.75)
[2024-12-14 02:46:36,647][slam_llm.models.slam_model][INFO] - modality encoder
               [2024-12-14 02:46:36,911][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 0.8134645819664001, acc: 0.7307692170143127)
                                                                   [2024-12-14 02:46:37,015][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:46:37,260][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.2560512125492096, acc: 0.90625)
[2024-12-14 02:46:37,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:37,632][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 1.0318833589553833, acc: 0.695652186870575)
[2024-12-14 02:46:37,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:38,020][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.6581017971038818, acc: 0.8399999737739563)
[2024-12-14 02:46:38,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:38,338][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.16970640420913696, acc: 0.95652174949646)
[2024-12-14 02:46:38,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:38,797][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 1.0316959619522095, acc: 0.6800000071525574)
[2024-12-14 02:46:38,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:39,136][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 0.8981311917304993, acc: 0.7864077687263489)
[2024-12-14 02:46:39,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:40,200][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 1.4906940460205078, acc: 0.5970873832702637)
                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:46:40,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:41,023][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 1.597097396850586, acc: 0.5053763389587402)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:46:41,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:41,825][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 1.561525583267212, acc: 0.5991379022598267)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:46:42,012][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:46:42,568][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 0.9016172885894775, acc: 0.7263157963752747)
                                                                                                                                                             [2024-12-14 02:46:42,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:43,561][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 1.5642706155776978, acc: 0.5346534848213196)

[2024-12-14 02:46:42,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:43,086][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.9970851540565491, acc: 0.6842105388641357)
[2024-12-14 02:46:43,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:43,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:43,452][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.7852542400360107, acc: 0.7551020383834839)
[2024-12-14 02:46:43,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:43,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:43,782][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.2271888256072998, acc: 0.9696969985961914)
[2024-12-14 02:46:43,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:43,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:44,180][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 1.5517864227294922, acc: 0.5773195624351501)
[2024-12-14 02:46:44,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:44,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:44,575][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 1.0257877111434937, acc: 0.7285714149475098)
[2024-12-14 02:46:44,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:44,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:44,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:44,964][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 1.53886079788208, acc: 0.5988371968269348)
[2024-12-14 02:46:45,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:45,294][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.9373123049736023, acc: 0.7321428656578064)
[2024-12-14 02:46:45,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:45,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:45,620][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 1.2968875169754028, acc: 0.6172839403152466)
[2024-12-14 02:46:45,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:45,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:45,958][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.7142432332038879, acc: 0.7222222089767456)
[2024-12-14 02:46:46,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:46,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:46,286][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.33460599184036255, acc: 0.9375)
[2024-12-14 02:46:46,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:46,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:46,588][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.29704293608665466, acc: 0.9230769276618958)
[2024-12-14 02:46:46,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:46,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:46,952][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.5311301946640015, acc: 0.804347813129425)
[2024-12-14 02:46:47,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:47,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:47,302][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 1.072121262550354, acc: 0.6309523582458496)
[2024-12-14 02:46:47,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:47,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:47,625][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 1.3488198518753052, acc: 0.5903614163398743)
[2024-12-14 02:46:47,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:47,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:48,053][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 1.030386209487915, acc: 0.7207207083702087)
[2024-12-14 02:46:48,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:48,617][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.012305117212235928, acc: 1.0)
                                                                                            [2024-12-14 02:46:48,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:48,980][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.01930627040565014, acc: 1.0)
                                                                                                                                                                           [2024-12-14 02:46:49,103][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                             [2024-12-14 02:46:49,389][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.370423823595047, acc: 0.9047619104385376)
[2024-12-14 02:46:49,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:49,813][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.9115339517593384, acc: 0.7692307829856873)
                                                                                                                                                                                                                                              [2024-12-14 02:46:49,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:50,233][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.9361280202865601, acc: 0.7543859481811523)
                                                                               [2024-12-14 02:46:50,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:50,597][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.7431325912475586, acc: 0.8070175647735596)
[2024-12-14 02:46:50,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:50,975][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.704210638999939, acc: 0.7692307829856873)
                                                                                                                                                   [2024-12-14 02:46:51,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:51,357][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.6826494932174683, acc: 0.7551020383834839)
                                                                               [2024-12-14 02:46:51,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:51,717][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.015136167407035828, acc: 1.0)
                                                                                           [2024-12-14 02:46:51,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:52,106][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.9189500212669373, acc: 0.7777777910232544)
                                                                                [2024-12-14 02:46:52,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:52,491][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 1.2503432035446167, acc: 0.642276406288147)
                                                                                 [2024-12-14 02:46:52,596][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:46:52,866][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.7850639820098877, acc: 0.6935483813285828)
                                                                                                                                                               [2024-12-14 02:46:53,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:53,704][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 1.9201745986938477, acc: 0.49809885025024414)
                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:46:53,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:54,081][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.9926433563232422, acc: 0.6800000071525574)
                                                                               [2024-12-14 02:46:54,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:54,508][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.739040732383728, acc: 0.807692289352417)
                                                                                                                                                                                                            [2024-12-14 02:46:54,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:54,905][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.20078592002391815, acc: 0.9166666865348816)
                                                                              [2024-12-14 02:46:55,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:55,248][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.16692014038562775, acc: 0.9473684430122375)
                                                                                                                                                             [2024-12-14 02:46:55,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:55,603][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.6226534843444824, acc: 0.4907975494861603)
                                                                                [2024-12-14 02:46:55,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:56,041][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 1.44511878490448, acc: 0.625)
                                                                                                                                                                             [2024-12-14 02:46:56,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:56,445][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 1.4125328063964844, acc: 0.550000011920929)
                                                                                [2024-12-14 02:46:56,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:56,840][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.5856916904449463, acc: 0.5059523582458496)
                                                                              [2024-12-14 02:46:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:57,188][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 1.5071134567260742, acc: 0.5538461804389954)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:46:57,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:57,863][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.7246460914611816, acc: 0.7894737124443054)
[2024-12-14 02:46:57,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:57,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:58,292][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 1.4651433229446411, acc: 0.5892857313156128)
[2024-12-14 02:46:58,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:58,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:58,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:58,689][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 1.2568213939666748, acc: 0.617977499961853)
[2024-12-14 02:46:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:58,996][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 1.6996475458145142, acc: 0.584269642829895)
[2024-12-14 02:46:59,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:59,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:59,394][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.9449571371078491, acc: 0.4751773178577423)
[2024-12-14 02:46:59,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:59,733][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7693, device='cuda:0') eval_epoch_loss=tensor(1.9124, device='cuda:0') eval_epoch_acc=tensor(0.5836, device='cuda:0')
[2024-12-14 02:46:59,735][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:46:59,735][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:46:59,792][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 1.5240983963012695, acc: 0.5652173757553101)
[2024-12-14 02:46:59,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:46:59,945][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_7_step_560_loss_1.9123985767364502/model.pt
[2024-12-14 02:46:59,948][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:47:00,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:00,161][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.2161404937505722, acc: 0.8799999952316284)
[2024-12-14 02:47:00,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:00,336][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.1567966639995575, acc: 0.9615384340286255)
[2024-12-14 02:47:00,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:00,516][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.2290126234292984, acc: 0.9230769276618958)
[2024-12-14 02:47:00,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:00,673][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.46816176176071167, acc: 0.8717948794364929)
[2024-12-14 02:47:00,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:00,853][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.25644880533218384, acc: 0.9629629850387573)
[2024-12-14 02:47:00,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:01,046][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 0.9514926671981812, acc: 0.7222222089767456)
[2024-12-14 02:47:01,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:01,262][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.41329288482666016, acc: 0.8518518805503845)
[2024-12-14 02:47:01,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:01,443][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.6082592606544495, acc: 0.8311688303947449)
[2024-12-14 02:47:01,705][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:02,139][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 02:47:02,498][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:47:02,904][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:47:03,248][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                    [2024-12-14 02:47:03,599][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:47:03,870][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:04,259][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:04,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:04,977][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                   [2024-12-14 02:47:05,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:05,607][slam_llm.models.slam_model][INFO] - modality encoder
12-14 02:47:05,269][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:47:05,269][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-12-14 02:47:05,269][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:47:05,269][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 20
[2024-12-14 02:47:05,269][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 02:47:05,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:06,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:06,194][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.3240991532802582, acc: 0.9259259104728699)
[2024-12-14 02:47:06,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:06,593][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.3790352940559387, acc: 0.8399999737739563)
[2024-12-14 02:47:06,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:06,971][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.8887583017349243, acc: 0.7567567825317383)
[2024-12-14 02:47:07,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:07,371][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 1.6234612464904785, acc: 0.5428571701049805)
[2024-12-14 02:47:07,422][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.45328566431999207, acc: 0.8421052694320679)
[2024-12-14 02:47:07,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:07,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:07,784][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.5349855422973633, acc: 0.8648648858070374)
[2024-12-14 02:47:07,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:08,154][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 1.4112187623977661, acc: 0.579365074634552)
[2024-12-14 02:47:08,177][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.41894108057022095, acc: 0.8571428656578064)
[2024-12-14 02:47:08,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:08,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:08,454][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.26854515075683594, acc: 0.9642857313156128)
[2024-12-14 02:47:08,562][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.6229205131530762, acc: 0.795918345451355)
[2024-12-14 02:47:08,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:08,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:08,847][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.8101838827133179, acc: 0.7666666507720947)
[2024-12-14 02:47:08,964][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.17925319075584412, acc: 1.0)
[2024-12-14 02:47:09,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:09,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:09,356][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.009933913126587868, acc: 1.0)
[2024-12-14 02:47:09,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:09,560][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.9675666093826294, acc: 0.7361111044883728)
[2024-12-14 02:47:09,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:09,726][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.0341687947511673, acc: 1.0)
[2024-12-14 02:47:09,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:09,920][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.11221425235271454, acc: 0.9615384340286255)
[2024-12-14 02:47:10,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:10,135][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.21165265142917633, acc: 0.9629629850387573)
[2024-12-14 02:47:10,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:10,286][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.4336836338043213, acc: 0.8064516186714172)
[2024-12-14 02:47:10,624][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:47:11,027][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:47:11,369][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:47:11,681][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:47:12,039][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:47:12,385][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:12,633][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:47:12,967][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:47:13,346][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:13,678][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:47:14,061][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:47:14,376][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:14,732][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:47:15,017][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                   [2024-12-14 02:47:15,364][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:47:15,724][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:16,111][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:47:16,485][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:47:16,831][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:47:17,192][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:47:17,548][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:47:17,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:18,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:18,032][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.687819242477417, acc: 0.7384615540504456)
[2024-12-14 02:47:18,038][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 1.0922800302505493, acc: 0.6172839403152466)
[2024-12-14 02:47:18,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:18,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:18,404][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.4185996651649475, acc: 0.8928571343421936)
[2024-12-14 02:47:18,420][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.674588680267334, acc: 0.828125)
[2024-12-14 02:47:18,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:18,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:18,794][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.50104820728302, acc: 0.8518518805503845)
[2024-12-14 02:47:18,836][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.3086681663990021, acc: 0.96875)
[2024-12-14 02:47:18,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:18,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:19,146][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.17003466188907623, acc: 0.95652174949646)
[2024-12-14 02:47:19,191][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.47011128067970276, acc: 0.8181818127632141)
[2024-12-14 02:47:19,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:19,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:19,502][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 1.358210802078247, acc: 0.6302521228790283)
[2024-12-14 02:47:19,535][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.1756049245595932, acc: 0.9375)
[2024-12-14 02:47:19,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:19,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:19,842][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.19630305469036102, acc: 0.9354838728904724)
[2024-12-14 02:47:19,894][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.665632963180542, acc: 0.8032786846160889)
[2024-12-14 02:47:19,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:20,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:20,196][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.028696350753307343, acc: 1.0)
[2024-12-14 02:47:20,293][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.9149953722953796, acc: 0.682539701461792)
[2024-12-14 02:47:20,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:20,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:20,564][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.4466576874256134, acc: 0.8666666746139526)
[2024-12-14 02:47:20,621][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 1.0046406984329224, acc: 0.6271186470985413)
[2024-12-14 02:47:20,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:20,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:20,902][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.5268328785896301, acc: 0.8048780560493469)
[2024-12-14 02:47:20,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:20,989][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.8553619980812073, acc: 0.7586206793785095)
[2024-12-14 02:47:21,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:21,215][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.23566614091396332, acc: 0.8857142925262451)
[2024-12-14 02:47:21,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:21,352][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.12374500185251236, acc: 0.9523809552192688)
[2024-12-14 02:47:21,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:21,555][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.3000558912754059, acc: 0.9473684430122375)
[2024-12-14 02:47:21,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:21,779][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.3444214463233948, acc: 0.8461538553237915)
[2024-12-14 02:47:21,874][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.2793775498867035, acc: 0.9354838728904724)
[2024-12-14 02:47:21,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:21,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:22,130][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 1.1057772636413574, acc: 0.7027027010917664)
[2024-12-14 02:47:22,178][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.051107607781887054, acc: 1.0)
[2024-12-14 02:47:22,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:22,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:22,461][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 0.9869200587272644, acc: 0.7230769395828247)
[2024-12-14 02:47:22,530][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.19062454998493195, acc: 0.9090909361839294)
[2024-12-14 02:47:22,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:22,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:22,868][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.33118492364883423, acc: 0.8999999761581421)
[2024-12-14 02:47:22,875][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 1.2474796772003174, acc: 0.6969696879386902)
[2024-12-14 02:47:22,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:23,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:23,181][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.39078637957572937, acc: 0.8571428656578064)
[2024-12-14 02:47:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:23,291][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 1.0447821617126465, acc: 0.7010309100151062)
[2024-12-14 02:47:23,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:23,559][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 1.5757849216461182, acc: 0.55474454164505)
[2024-12-14 02:47:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:23,709][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 1.4807003736495972, acc: 0.5808823704719543)
[2024-12-14 02:47:23,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:23,953][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 1.2393630743026733, acc: 0.634482741355896)
[2024-12-14 02:47:24,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:24,080][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.26587727665901184, acc: 0.9615384340286255)
[2024-12-14 02:47:24,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:24,349][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 1.882772445678711, acc: 0.4714285731315613)
[2024-12-14 02:47:24,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:24,476][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.02622947469353676, acc: 1.0)
[2024-12-14 02:47:24,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:24,691][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 1.5710668563842773, acc: 0.5496688485145569)
[2024-12-14 02:47:24,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:24,881][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.3430493474006653, acc: 0.8571428656578064)
[2024-12-14 02:47:25,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:25,025][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 1.1287963390350342, acc: 0.6495726704597473)
[2024-12-14 02:47:25,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:25,234][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.34652113914489746, acc: 0.9166666865348816)
[2024-12-14 02:47:25,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:25,380][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.1269543319940567, acc: 0.9599999785423279)
[2024-12-14 02:47:25,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:25,602][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.6871159076690674, acc: 0.8070175647735596)
[2024-12-14 02:47:25,683][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.13344749808311462, acc: 0.9615384340286255)
[2024-12-14 02:47:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:25,943][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.8967066407203674, acc: 0.7301587462425232)
[2024-12-14 02:47:26,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:26,252][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.8931456208229065, acc: 0.7464788556098938)
[2024-12-14 02:47:26,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:26,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:26,711][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 1.6098670959472656, acc: 0.5733333230018616)
[2024-12-14 02:47:26,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:26,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:27,025][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.414257287979126, acc: 0.8648648858070374)
[2024-12-14 02:47:27,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:27,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:27,360][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.16073039174079895, acc: 0.9615384340286255)
[2024-12-14 02:47:27,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:27,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:28,380][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:47:28,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:28,895][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:47:29,227][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:47:29,607][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:47:29,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:30,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:30,386][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.5841350555419922, acc: 0.5733oder
[2024-12-14 02:47:30,163][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.9147830605506897, acc: 0.8695651888847351)
[2024-12-14 02:47:30,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:30,481][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.5147143006324768, acc: 0.800000011920929)
[2024-12-14 02:47:30,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:30,823][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.2978495955467224, acc: 0.8846153616905212)
[2024-12-14 02:47:30,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:31,159][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.5533056259155273, acc: 0.8333333134651184)
[2024-12-14 02:47:31,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:31,516][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.450313001871109, acc: 0.8999999761581421)
[2024-12-14 02:47:31,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:31,883][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.17369656264781952, acc: 0.95652174949646)
[2024-12-14 02:47:32,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:32,252][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.5241044759750366, acc: 0.9047619104385376)
[2024-12-14 02:47:32,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:32,604][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.8196163773536682, acc: 0.807692289352417)
[2024-12-14 02:47:32,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:32,912][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.49867087602615356, acc: 0.8064516186714172)
[2024-12-14 02:47:33,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:33,256][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.5148309469223022, acc: 0.8648648858070374)
[2024-12-14 02:47:33,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:33,779][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 1.3898138999938965, acc: 0.5438596606254578)
                                                                                                                                                 [2024-12-14 02:47:33,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:34,124][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 1.1965687274932861, acc: 0.6492537260055542)
[2024-12-14 02:47:34,213][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:47:34,500][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 1.3472692966461182, acc: 0.581632673740387)
[2024-12-14 02:47:34,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:34,944][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 1.4093399047851562, acc: 0.542553186416626)
                                                                                                                                                    [2024-12-14 02:47:35,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:35,311][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.983536958694458, acc: 0.7142857313156128)
                                                                                [2024-12-14 02:47:35,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:35,625][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.6113327741622925, acc: 0.75)
                                                                                            [2024-12-14 02:47:35,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:35,968][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.6359399557113647, acc: 0.739130437374115)
[2024-12-14 02:47:36,050][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:47:36,277][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.5767198801040649, acc: 0.8620689511299133)
[2024-12-14 02:47:36,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:36,623][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.8922062516212463, acc: 0.739130437374115)
                                                                [2024-12-14 02:47:36,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:37,029][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 1.1194391250610352, acc: 0.6610169410705566)
                                                                              [2024-12-14 02:47:37,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:37,371][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 1.1602948904037476, acc: 0.6315789222717285)
                                                                              [2024-12-14 02:47:37,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:37,763][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 1.322758674621582, acc: 0.6486486196517944)
                                                                                                                                                              [2024-12-14 02:47:37,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:38,130][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.41996946930885315, acc: 0.8928571343421936)
                                                                             [2024-12-14 02:47:38,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:38,491][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.5358054041862488, acc: 0.782608687877655)
                                                                               [2024-12-14 02:47:38,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:38,827][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.8183720707893372, acc: 0.6842105388641357)
                                                                               [2024-12-14 02:47:39,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:40,563][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 0.8975202441215515, acc: 0.7027027010917664)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:47:40,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:40,961][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 1.063829779624939, acc: 0.6666666865348816)
                                                                                [2024-12-14 02:47:41,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:41,365][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 0.8960739970207214, acc: 0.8023256063461304)
                                                                                                                                                             [2024-12-14 02:47:41,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:41,960][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 0.8732321262359619, acc: 0.729411780834198)
                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:47:42,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:42,524][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 1.2245463132858276, acc: 0.6741573214530945)
                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:47:42,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:42,912][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.6483281254768372, acc: 0.8409090638160706)
                                                                              [2024-12-14 02:47:43,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:43,276][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.546589732170105, acc: 0.8571428656578064)
[2024-12-14 02:47:43,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:43,651][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.3699358105659485, acc: 0.8620689511299133)
                                                                              [2024-12-14 02:47:43,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:44,049][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.5337485074996948, acc: 0.8571428656578064)
[2024-12-14 02:47:44,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:44,442][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.5958340764045715, acc: 0.8199999928474426)
[2024-12-14 02:47:44,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:44,841][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.9254873991012573, acc: 0.7361111044883728)
[2024-12-14 02:47:44,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:45,213][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.0984071493148804, acc: 0.656862735748291)
[2024-12-14 02:47:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:46,243][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.89083731174469, acc: 0.48630136251449585)
                                                                                                                                                              [2024-12-14 02:47:46,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:46,604][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.3155088722705841, acc: 0.9166666865348816)
                                                                              [2024-12-14 02:47:46,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:46,991][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.4872497022151947, acc: 0.7777777910232544)
[2024-12-14 02:47:47,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:47,385][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.37405332922935486, acc: 0.8571428656578064)
[2024-12-14 02:47:47,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:47,923][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 1.2844855785369873, acc: 0.6548672318458557)
[2024-12-14 02:47:47,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:48,214][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 1.0084456205368042, acc: 0.739130437374115)
                                                                               [2024-12-14 02:47:48,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:48,509][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 1.1560559272766113, acc: 0.6704545617103577)
[2024-12-14 02:47:48,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:49,417][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 1.8755238056182861, acc: 0.47328245639801025)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:47:49,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:50,088][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 1.6555534601211548, acc: 0.4962962865829468)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:47:50,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:50,396][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.7458682656288147, acc: 0.7377049326896667)
[2024-12-14 02:47:50,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:50,797][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.2102222442626953, acc: 0.875)
                                                                              [2024-12-14 02:47:50,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:51,140][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.5206671357154846, acc: 0.800000011920929)
                                                                   [2024-12-14 02:47:51,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:51,428][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.39454028010368347, acc: 0.9285714030265808)
[2024-12-14 02:47:51,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:51,766][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 1.1759634017944336, acc: 0.6463414430618286)
                     [2024-12-14 02:47:51,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:52,126][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 1.9055233001708984, acc: 0.4773413836956024)
                                                                                [2024-12-14 02:47:52,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:52,435][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 2.0917084217071533, acc: 0.4524495601654053)
                                                                               [2024-12-14 02:47:52,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:52,917][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 1.9948896169662476, acc: 0.46875)
                                                                                          [2024-12-14 02:47:53,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:53,443][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 2.0180184841156006, acc: 0.44840526580810547)
                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:47:53,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:53,872][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 1.9178305864334106, acc: 0.4661921560764313)
                                                                                [2024-12-14 02:47:53,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:54,200][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.3266884684562683, acc: 0.8799999952316284)
                                                                               [2024-12-14 02:47:54,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:54,783][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 1.6197383403778076, acc: 0.4883720874786377)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:47:55,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:55,596][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 1.5778615474700928, acc: 0.579365074634552)
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:47:55,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:56,523][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 1.605751395225525, acc: 0.5530303120613098)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:47:56,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:57,265][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 1.202467441558838, acc: 0.6823529601097107)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:47:57,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:57,290][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_7_step_560_loss_1.9262580871582031/model.pt
[2024-12-14 02:47:57,296][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:47:57,356][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.7303265929222107, acc: 0.725806474685669)
[2024-12-14 02:47:57,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:57,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:57,667][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.185801163315773, acc: 0.9615384340286255)
[2024-12-14 02:47:57,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:57,966][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.7076176404953003, acc: 0.7692307829856873)
[2024-12-14 02:47:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:58,237][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 1.7190954685211182, acc: 0.4904943108558655)
[2024-12-14 02:47:58,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:58,349][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 1.0846341848373413, acc: 0.6666666865348816)
[2024-12-14 02:47:58,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:58,584][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.731020987033844, acc: 0.7599999904632568)
[2024-12-14 02:47:58,694][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.8158736228942871, acc: 0.7532467246055603)
[2024-12-14 02:47:58,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:58,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:58,999][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.5303295254707336, acc: 0.8653846383094788)
[2024-12-14 02:47:59,046][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.5075321793556213, acc: 0.875)
[2024-12-14 02:47:59,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:59,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:59,375][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.13996942341327667, acc: 0.9166666865348816)
[2024-12-14 02:47:59,414][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.4862086772918701, acc: 0.8448275923728943)
[2024-12-14 02:47:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:59,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:59,722][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 1.17063307762146, acc: 0.5714285969734192)
[2024-12-14 02:47:59,770][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.17087431252002716, acc: 0.9473684430122375)
[2024-12-14 02:47:59,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:47:59,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:00,021][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.33648714423179626, acc: 0.8947368264198303)
[2024-12-14 02:48:00,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:00,190][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.5587762594223022, acc: 0.5521472096443176)
[2024-12-14 02:48:00,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:00,395][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.0911145880818367, acc: 1.0)
[2024-12-14 02:48:00,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:00,634][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 1.455315113067627, acc: 0.6388888955116272)
[2024-12-14 02:48:00,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:00,772][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 1.651901364326477, acc: 0.5508021116256714)
[2024-12-14 02:48:00,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:01,047][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 1.3687070608139038, acc: 0.5833333134651184)
[2024-12-14 02:48:01,099][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.9881716370582581, acc: 0.7096773982048035)
[2024-12-14 02:48:01,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:01,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:01,447][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 1.1185128688812256, acc: 0.692307710647583)
[2024-12-14 02:48:01,458][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.485323190689087, acc: 0.5535714030265808)
[2024-12-14 02:48:01,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:01,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:01,787][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 1.729500412940979, acc: 0.5153061151504517)
[2024-12-14 02:48:01,875][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 1.469178318977356, acc: 0.5897436141967773)
[2024-12-14 02:48:01,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:02,129][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 1.778813362121582, acc: 0.5031446814537048)
[2024-12-14 02:48:02,588][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=2.2958, train_epoch_loss=0.8311, epoch time 364.02177058905363s
[2024-12-14 02:48:02,588][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:48:02,588][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-12-14 02:48:02,588][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:48:02,588][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 20
[2024-12-14 02:48:02,588][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:48:02,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:03,013][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:48:03,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:03,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:03,488][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.271643728017807, acc: 0.8888888955116272)
   [2024-12-14 02:48:03,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:03,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:03,889][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.45465630292892456, acc: 0.800000011920929)
[2024-12-14 02:48:03,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:04,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:04,232][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.5732816457748413, acc: 0.837837815284729)
[2024-12-14 02:48:04,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:04,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:04,596][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.5164594054222107, acc: 0.8684210777282715)
[2024-12-14 02:48:04,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:04,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:04,932][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.7143089771270752, acc: 0.7837837934494019)
[2024-12-14 02:48:05,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:05,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:05,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:05,600][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.2774631083011627, acc: 0.8928571343421936)
                                                                              [2024-12-14 02:48:05,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:05,925][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.4957074522972107, acc: 0.8936170339584351)
                                                                            [2024-12-14 02:48:06,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:06,599][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 1.1365718841552734, acc: 0.6769230961799622)
                                                                                                                                                                                                     [2024-12-14 02:48:06,691][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:48:06,963][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.6613630056381226, acc: 0.8108108043670654)
                                                                              [2024-12-14 02:48:07,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:07,367][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.9234699010848999, acc: 0.7325581312179565)
                                                                                                                                                             [2024-12-14 02:48:07,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:07,901][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 1.0453462600708008, acc: 0.6756756901741028)
                                                                              [2024-12-14 02:48:08,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:08,294][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.9634753465652466, acc: 0.7111111283302307)
                                                                               [2024-12-14 02:48:08,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:08,648][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.3510478138923645, acc: 0.9090909361839294)
                                                                              [2024-12-14 02:48:08,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:09,036][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.09044504910707474, acc: 0.9629629850387573)
                                                                             [2024-12-14 02:48:09,135][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:48:09,368][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.14039848744869232, acc: 0.9200000166893005)
[2024-12-14 02:48:09,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:09,767][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.627467691898346, acc: 0.807692289352417)
                                                                                                                                                                                                                                            [2024-12-14 02:48:09,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:10,528][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 1.1584100723266602, acc: 0.679347813129425)
/10, step 18/574 completed (loss: 0.7107958793640137, acc: 0.8611111044883728)
[2024-12-14 02:48:10,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:10,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:10,518][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.17354102432727814, acc: 0.8947368264198303)
[2024-12-14 02:48:10,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:10,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:10,852][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.2762298882007599, acc: 0.8846153616905212)
[2024-12-14 02:48:10,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:11,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:11,214][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.45460253953933716, acc: 0.8620689511299133)
[2024-12-14 02:48:11,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:11,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:11,556][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.43735426664352417, acc: 0.8399999737739563)
[2024-12-14 02:48:11,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:11,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:11,921][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.4189019799232483, acc: 0.9047619104385376)
[2024-12-14 02:48:12,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:12,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:12,291][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.4844275116920471, acc: 0.875)
[2024-12-14 02:48:12,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:12,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:12,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:12,658][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 1.0694377422332764, acc: 0.6415094137191772)
[2024-12-14 02:48:12,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:12,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:12,995][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 1.345080852508545, acc: 0.6301369667053223)
[2024-12-14 02:48:13,257][slam_llm.models.slam_model][INFO] - modality encoder
 [2024-12-14 02:48:13,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:13,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:13,894][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                    [2024-12-14 02:48:14,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:14,425][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 2.231818199157715, acc: 0.4466403126716614)
[2024-12-14 02:48:14,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:14,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:14,839][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.6809351444244385, acc: 0.7441860437393188)
[2024-12-14 02:48:14,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:14,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:15,214][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 1.0313175916671753, acc: 0.7108433842658997)
[2024-12-14 02:48:15,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:15,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:15,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:15,625][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 0.9484862089157104, acc: 0.6913580298423767)
[2024-12-14 02:48:15,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:16,111][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.40684783458709717, acc: 0.8636363744735718)
0, step 31/574 completed (loss: 0.5060982704162598, acc: 0.8928571343421936)
[2024-12-14 02:48:16,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:16,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:16,363][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.3538869321346283, acc: 0.8518518805503845)
[2024-12-14 02:48:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:16,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:16,762][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.13858839869499207, acc: 0.95652174949646)
[2024-12-14 02:48:16,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:16,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:17,135][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 1.3444981575012207, acc: 0.605042040348053)
[2024-12-14 02:48:17,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:17,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:17,507][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.6919572353363037, acc: 0.8032786846160889)
[2024-12-14 02:48:17,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:17,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:17,853][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.9420629143714905, acc: 0.7142857313156128)
[2024-12-14 02:48:17,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:18,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:18,199][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 0.8332675099372864, acc: 0.694915235042572)
[2024-12-14 02:48:18,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:18,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:18,623][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.8786121010780334, acc: 0.7471264600753784)
[2024-12-14 02:48:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:18,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:19,018][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.22220733761787415, acc: 0.9047619104385376)
[2024-12-14 02:48:19,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:19,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:19,393][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.15450014173984528, acc: 1.0)
[2024-12-14 02:48:19,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:19,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:19,781][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 1.3860340118408203, acc: 0.6351351141929626)
[2024-12-14 02:48:19,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:19,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:20,190][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 1.0802998542785645, acc: 0.692307710647583)
[2024-12-14 02:48:20,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:20,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:20,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:20,620][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 1.342153549194336, acc: 0.6363636255264282)
[2024-12-14 02:48:20,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:20,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:21,031][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 1.240937352180481, acc: 0.6804123520851135)
[2024-12-14 02:48:21,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:21,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:21,621][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 1.489249348640442, acc: 0.5735294222831726)
[2024-12-14 02:48:21,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:21,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:21,825][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.2483104020357132, acc: 0.9230769276618958)
[2024-12-14 02:48:21,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:22,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:22,180][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.03565572574734688, acc: 1.0)
[2024-12-14 02:48:22,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:22,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:22,486][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.39949965476989746, acc: 0.7857142686843872)
[2024-12-14 02:48:22,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:22,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:22,881][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.28986382484436035, acc: 0.9166666865348816)
[2024-12-14 02:48:22,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:23,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:23,247][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.7554216384887695, acc: 0.7017543911933899)
[2024-12-14 02:48:23,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:23,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:23,531][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.9641383290290833, acc: 0.7460317611694336)
[2024-12-14 02:48:23,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:23,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:23,909][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.9719074964523315, acc: 0.7605633735656738)
[2024-12-14 02:48:24,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:24,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:24,364][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 1.7840760946273804, acc: 0.5400000214576721)
[2024-12-14 02:48:24,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:24,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:24,694][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.47638610005378723, acc: 0.8648648858070374)
[2024-12-14 02:48:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:24,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:25,005][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.18617917597293854, acc: 0.9230769276618958)
[2024-12-14 02:48:25,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:25,685][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:48:26,120][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:48:26,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:26,615][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:48:26,947][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:48:27,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:27,625][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:48:27,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:28,037][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 1.3557960987091064, acc: 0.550561785697937)
[2024-12-14 02:48:28,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:28,378][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 1.3122975826263428, acc: 0.6756756901741028)
[2024-12-14 02:48:28,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:28,840][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.8964763283729553, acc: 0.7586206793785095)
[2024-12-14 02:48:28,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:29,214][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.09329204261302948, acc: 1.0)
[2024-12-14 02:48:29,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:29,568][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.22130435705184937, acc: 0.9545454382896423)
[2024-12-14 02:48:29,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:29,913][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.28530019521713257, acc: 0.9375)
                                                                                         [2024-12-14 02:48:30,617][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:48:30,952][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:48:31,350][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:48:31,719][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:48:32,109][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:48:32,414][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:48:32,677][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                              [2024-12-14 02:48:32,974][slam_llm.models.slam_model][INFO] - modality encoder
6.2221, device='cuda:0') eval_epoch_loss=tensor(1.8281, device='cuda:0') eval_epoch_acc=tensor(0.5950, device='cuda:0')
[2024-12-14 02:48:32,905][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:48:32,905][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:48:32,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:33,173][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_8_step_129_loss_1.828108549118042/model.pt
[2024-12-14 02:48:33,178][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:48:33,178][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.5950257778167725
[2024-12-14 02:48:33,237][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.16871489584445953, acc: 0.931034505367279)
[2024-12-14 02:48:33,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:33,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:33,631][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.8812897801399231, acc: 0.6785714030265808)
[2024-12-14 02:48:33,648][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 1.2420600652694702, acc: 0.6397058963775635)
[2024-12-14 02:48:33,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:33,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:33,984][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 1.1360400915145874, acc: 0.699999988079071)
[2024-12-14 02:48:34,057][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.39782583713531494, acc: 0.8846153616905212)
[2024-12-14 02:48:34,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:34,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:34,385][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.10481197386980057, acc: 0.9599999785423279)
[2024-12-14 02:48:34,411][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.19673624634742737, acc: 0.95652174949646)
[2024-12-14 02:48:34,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:34,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:34,749][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.3901723027229309, acc: 0.84375)
[2024-12-14 02:48:34,769][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.45682764053344727, acc: 0.8611111044883728)
[2024-12-14 02:48:34,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:34,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:35,089][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.4006367623806, acc: 0.8695651888847351)
[2024-12-14 02:48:35,131][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.46477454900741577, acc: 0.8787878751754761)
[2024-12-14 02:48:35,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:35,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:35,452][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.5165084004402161, acc: 0.8285714387893677)
[2024-12-14 02:48:35,524][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 1.5416135787963867, acc: 0.5735294222831726)
[2024-12-14 02:48:35,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:35,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:35,826][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.1529824435710907, acc: 0.9615384340286255)
[2024-12-14 02:48:35,912][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 1.51810884475708, acc: 0.5317460298538208)
[2024-12-14 02:48:35,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:36,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:36,192][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.35039809346199036, acc: 0.9047619104385376)
[2024-12-14 02:48:36,273][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 1.7640265226364136, acc: 0.5487179756164551)
[2024-12-14 02:48:36,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:36,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:36,555][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.5637089610099792, acc: 0.8999999761581421)
[2024-12-14 02:48:36,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:36,699][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 1.25214421749115, acc: 0.6734693646430969)
[2024-12-14 02:48:36,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:36,927][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.23788130283355713, acc: 0.95652174949646)
[2024-12-14 02:48:37,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:37,116][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 1.873061180114746, acc: 0.5074626803398132)
[2024-12-14 02:48:37,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:37,298][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.2802254557609558, acc: 0.8571428656578064)
[2024-12-14 02:48:37,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:37,517][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.933028221130371, acc: 0.4927007257938385)
[2024-12-14 02:48:37,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:37,665][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.6616665124893188, acc: 0.807692289352417)
[2024-12-14 02:48:37,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:37,895][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.032641079276800156, acc: 1.0)
[2024-12-14 02:48:38,018][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.5149530172348022, acc: 0.8064516186714172)
[2024-12-14 02:48:38,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:38,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:38,274][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.12613552808761597, acc: 0.9583333134651184)
[2024-12-14 02:48:38,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:38,381][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.7243779301643372, acc: 0.7567567825317383)
[2024-12-14 02:48:38,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:38,632][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.2584235668182373, acc: 0.939393937587738)
[2024-12-14 02:48:38,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:38,911][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 1.3726991415023804, acc: 0.5526315569877625)
[2024-12-14 02:48:38,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:39,017][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.13522908091545105, acc: 0.9615384340286255)
[2024-12-14 02:48:39,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:39,269][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 1.1318525075912476, acc: 0.6567164063453674)
[2024-12-14 02:48:39,367][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.7813959121704102, acc: 0.8461538553237915)
[2024-12-14 02:48:39,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:39,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:39,675][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 1.086519718170166, acc: 0.6538461446762085)
[2024-12-14 02:48:39,695][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 1.531495213508606, acc: 0.5714285969734192)
[2024-12-14 02:48:39,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:39,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:40,031][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.42277008295059204, acc: 0.84375)
[2024-12-14 02:48:40,138][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 1.3102781772613525, acc: 0.5531914830207825)
[2024-12-14 02:48:40,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:40,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:40,386][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 0.834253191947937, acc: 0.739130437374115)
[2024-12-14 02:48:40,452][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.9121309518814087, acc: 0.7571428418159485)
[2024-12-14 02:48:40,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:40,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:40,732][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.6453257203102112, acc: 0.8399999737739563)
[2024-12-14 02:48:40,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:40,852][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.7793680429458618, acc: 0.7142857313156128)
[2024-12-14 02:48:40,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:41,062][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.35289230942726135, acc: 0.9130434989929199)
[2024-12-14 02:48:41,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:41,248][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.615576446056366, acc: 0.8260869383811951)
[2024-12-14 02:48:41,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:41,542][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 0.8000216484069824, acc: 0.7799999713897705)
[2024-12-14 02:48:41,631][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.29571080207824707, acc: 0.8620689511299133)
[2024-12-14 02:48:41,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:41,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:41,978][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 1.157505989074707, acc: 0.6407766938209534)
[2024-12-14 02:48:42,034][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.9142786264419556, acc: 0.739130437374115)
[2024-12-14 02:48:42,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:42,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:42,394][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.8966806530952454, acc: 0.7796609997749329)
[2024-12-14 02:48:42,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:42,725][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.8232846856117249, acc: 0.7368420958518982)
[2024-12-14 02:48:42,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:43,078][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 1.147371530532837, acc: 0.6891891956329346)
[2024-12-14 02:48:43,102][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 1.690479040145874, acc: 0.5728155374526978)
[2024-12-14 02:48:43,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:43,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:43,459][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.4044976532459259, acc: 0.8571428656578064)
[2024-12-14 02:48:43,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:43,767][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.44995760917663574, acc: 0.8695651888847351)
[2024-12-14 02:48:43,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:43,923][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 1.8022098541259766, acc: 0.5053763389587402)
[2024-12-14 02:48:44,094][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.8091105222702026, acc: 0.8421052694320679)
[2024-12-14 02:48:44,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:44,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:44,755][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 1.7125753164291382, acc: 0.5646551847457886)
[2024-12-14 02:48:44,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:45,498][root][INFO] - Training Epoch: 8/10, steality encoder
[2024-12-14 02:48:45,670][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:48:45,934][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:48:46,307][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:48:46,689][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:48:46,969][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:48:47,357][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:48:47,709][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:48:48,024][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                  [2024-12-14 02:48:48,387][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:48:48,708][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 02:48:49,055][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:48:49,376][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.19238433241844177, acc: 0.9545454382896423)
[2024-12-14 02:48:49,273][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.6224308609962463, acc: 0.8600000143051147)
[2024-12-14 02:48:49,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:49,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:49,570][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.13893890380859375, acc: 0.95652174949646)
[2024-12-14 02:48:49,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:49,709][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.9645017981529236, acc: 0.7361111044883728)
[2024-12-14 02:48:49,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:49,919][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.3721332848072052, acc: 0.8863636255264282)
[2024-12-14 02:48:50,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:50,103][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.0806759595870972, acc: 0.6764705777168274)
[2024-12-14 02:48:50,280][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.9498176574707031, acc: 0.7413793206214905)
[2024-12-14 02:48:50,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:50,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:50,666][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.3889002799987793, acc: 0.8139534592628479)
[2024-12-14 02:48:50,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:51,042][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.34665775299072266, acc: 0.8399999737739563)
[2024-12-14 02:48:51,130][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.794073224067688, acc: 0.5410959124565125)
[2024-12-14 02:48:51,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:51,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:51,441][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.02716241590678692, acc: 1.0)
[2024-12-14 02:48:51,489][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.1608317643404007, acc: 0.9583333134651184)
[2024-12-14 02:48:51,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:51,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:51,822][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.01232155505567789, acc: 1.0)
[2024-12-14 02:48:51,824][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.2969733476638794, acc: 0.8888888955116272)
[2024-12-14 02:48:51,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:51,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:52,173][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.3717254102230072, acc: 0.9285714030265808)
[2024-12-14 02:48:52,203][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.37262892723083496, acc: 0.8571428656578064)
[2024-12-14 02:48:52,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:52,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:52,592][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.8297858834266663, acc: 0.7846153974533081)
[2024-12-14 02:48:52,743][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 1.0959196090698242, acc: 0.6725663542747498)
[2024-12-14 02:48:52,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:52,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:53,026][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.9523174166679382, acc: 0.7894737124443054)
[2024-12-14 02:48:53,052][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 0.8893935680389404, acc: 0.739130437374115)
[2024-12-14 02:48:53,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:53,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:53,600][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.685370922088623, acc: 0.8070175647735596)
[2024-12-14 02:48:53,460][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 1.0145589113235474, acc: 0.7045454382896423)
[2024-12-14 02:48:53,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:53,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:53,763][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.49556228518486023, acc: 0.8974359035491943)
[2024-12-14 02:48:53,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:54,099][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.5490103960037231, acc: 0.795918345451355)
[2024-12-14 02:48:54,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:54,370][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 1.777287244796753, acc: 0.5419847369194031)
[2024-12-14 02:48:54,494][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.03173108398914337, acc: 1.0)
[2024-12-14 02:48:54,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:54,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:54,904][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 1.0327988862991333, acc: 0.682539701461792)
[2024-12-14 02:48:55,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:55,048][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 1.667710781097412, acc: 0.5259259343147278)
[2024-12-14 02:48:55,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:55,314][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 1.1616218090057373, acc: 0.6341463327407837)
[2024-12-14 02:48:55,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:55,437][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.6118341684341431, acc: 0.8360655903816223)
[2024-12-14 02:48:55,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:55,724][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.7300069332122803, acc: 0.725806474685669)
[2024-12-14 02:48:55,816][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.14349393546581268, acc: 0.9583333134651184)
[2024-12-14 02:48:55,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:55,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:56,167][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.3906223177909851, acc: 0.8799999952316284)
[2024-12-14 02:48:56,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:56,455][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.23443517088890076, acc: 0.8928571343421936)
[2024-12-14 02:48:56,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:56,591][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 1.717799186706543, acc: 0.5323193669319153)
[2024-12-14 02:48:56,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:56,774][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 0.9660466909408569, acc: 0.7195122241973877)
[2024-12-14 02:48:56,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:56,924][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.8516969680786133, acc: 0.7333333492279053)
[2024-12-14 02:48:57,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:57,188][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 1.802846074104309, acc: 0.5196374654769897)
[2024-12-14 02:48:57,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:57,331][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.6375446319580078, acc: 0.807692289352417)
[2024-12-14 02:48:57,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:57,569][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 1.977718472480774, acc: 0.47838616371154785)
[2024-12-14 02:48:57,715][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.18292666971683502, acc: 0.9166666865348816)
[2024-12-14 02:48:57,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:57,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:58,049][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 2.0207273960113525, acc: 0.4625000059604645)
[2024-12-14 02:48:58,072][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.13694529235363007, acc: 1.0)
[2024-12-14 02:48:58,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:58,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:58,420][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.6885329484939575, acc: 0.5276073813438416)
[2024-12-14 02:48:58,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:58,577][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 2.0273525714874268, acc: 0.4465290904045105)
[2024-12-14 02:48:58,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:58,839][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 1.5835577249526978, acc: 0.5833333134651184)
[2024-12-14 02:48:58,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:58,994][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 1.8396199941635132, acc: 0.5053380727767944)
[2024-12-14 02:48:59,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:59,220][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 1.5515294075012207, acc: 0.6000000238418579)
[2024-12-14 02:48:59,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:59,380][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.4980981945991516, acc: 0.8799999952316284)
[2024-12-14 02:48:59,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:59,622][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.5344383716583252, acc: 0.5595238208770752)
[2024-12-14 02:48:59,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:48:59,926][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 1.592288851737976, acc: 0.5348837375640869)
[2024-12-14 02:49:00,040][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 1.6170037984848022, acc: 0.5128205418586731)
[2024-12-14 02:49:00,167][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:49:00,723][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 1.5310295820236206, acc: 0.5714285969734192)
[2024-12-14 02:49:00,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:00,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:01,336][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                            [2024-12-14 02:49:01,644][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 1.6205857992172241, acc: 0.5303030014038086)
[2024-12-14 02:49:01,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:01,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:01,972][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                       [2024-12-14 02:49:02,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:02,517][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.2843622863292694, acc: 0.9200000166893005)
[2024-12-14 02:49:02,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:02,851][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.9552927017211914, acc: 0.7446808218955994)
[2024-12-14 02:49:02,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:03,235][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.8008810877799988, acc: 0.7291666865348816)
[2024-12-14 02:49:03,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:03,572][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.5812456607818604, acc: 0.8636363744735718)
[2024-12-14 02:49:03,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:03,996][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 1.2058351039886475, acc: 0.7228915691375732)
[2024-12-14 02:49:04,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:04,354][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 1.4255589246749878, acc: 0.6111111044883728)
[2024-12-14 02:49:04,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:04,721][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.33325400948524475, acc: 0.8947368264198303)
                                                                               [2024-12-14 02:49:04,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:05,124][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.3377719819545746, acc: 0.9117646813392639)
                                                                                [2024-12-14 02:49:05,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:05,473][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.6413655877113342, acc: 0.7749999761581421)
                                                                               [2024-12-14 02:49:05,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:05,781][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 1.4832696914672852, acc: 0.5390625)
[2024-12-14 02:49:05,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:06,109][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 1.5474590063095093, acc: 0.5440000295639038)
[2024-12-14 02:49:06,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:06,451][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 1.1878552436828613, acc: 0.6593406796455383)
                 [2024-12-14 02:49:06,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:06,830][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 1.838586688041687, acc: 0.5093167424201965)
                                                                                [2024-12-14 02:49:06,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:07,191][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 1.9628390073776245, acc: 0.48969072103500366)
                                                                              [2024-12-14 02:49:07,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:07,551][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.07131404429674149, acc: 1.0)
                                                                                                                                                                            [2024-12-14 02:49:07,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:07,884][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.8368000984191895, acc: 0.761904776096344)

[2024-12-14 02:49:07,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:08,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:08,249][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.8651224970817566, acc: 0.7758620977401733)
                                                                               [2024-12-14 02:49:08,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:08,719][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.7658129334449768, acc: 0.7636363506317139)
                                                                                                                                                              [2024-12-14 02:49:08,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:09,268][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 1.3830963373184204, acc: 0.6288659572601318)
                                                                               [2024-12-14 02:49:09,344][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:49:09,603][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.9884687662124634, acc: 0.7241379022598267)
[2024-12-14 02:49:09,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:09,955][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.21685200929641724, acc: 0.9629629850387573)
                   [2024-12-14 02:49:10,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:10,292][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.4494559168815613, acc: 0.9473684430122375)
                                                                               [2024-12-14 02:49:10,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:10,665][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.2480512410402298, acc: 0.9642857313156128)
 [2024-12-14 02:49:10,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:11,025][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.35976704955101013, acc: 0.9375)
                                                                                                                                                                          [2024-12-14 02:49:11,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:11,363][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.5061438679695129, acc: 0.8113207817077637)
[2024-12-14 02:49:11,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:11,742][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.4515804648399353, acc: 0.849056601524353)
[2024-12-14 02:49:11,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:12,116][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.33711397647857666, acc: 0.8823529481887817)
[2024-12-14 02:49:12,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:12,457][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.3745259642601013, acc: 0.875)
                                  [2024-12-14 02:49:12,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:12,843][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.7218279242515564, acc: 0.7213114500045776)
                                                                               [2024-12-14 02:49:12,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:13,229][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.35642531514167786, acc: 0.8666666746139526)
                                                                              [2024-12-14 02:49:13,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:13,608][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.23483537137508392, acc: 0.9473684430122375)
                                                                              [2024-12-14 02:49:13,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:13,913][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 1.0628025531768799, acc: 0.695652186870575)
                                                                                 [2024-12-14 02:49:14,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:14,348][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 0.9629614353179932, acc: 0.7361111044883728)
                                                                                                                                                               [2024-12-14 02:49:14,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:14,728][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.8087540864944458, acc: 0.759036123752594)
                                                                                 [2024-12-14 02:49:14,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:15,100][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 1.121471881866455, acc: 0.6538461446762085)
 [2024-12-14 02:49:15,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:15,430][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 1.2784234285354614, acc: 0.6428571343421936)
[2024-12-14 02:49:15,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:15,772][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.03865428641438484, acc: 1.0)
             [2024-12-14 02:49:15,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:16,145][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.053032949566841125, acc: 1.0)
[2024-12-14 02:49:16,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:16,526][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.1582593023777008, acc: 0.9677419066429138)
[2024-12-14 02:49:16,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:16,902][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.10067687928676605, acc: 1.0)
[2024-12-14 02:49:17,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:17,285][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.7499599456787109, acc: 0.7910447716712952)
                                               [2024-12-14 02:49:17,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:17,624][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.8976485729217529, acc: 0.7211538553237915)
                                                                                                                                                [2024-12-14 02:49:17,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:17,973][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.4126628339290619, acc: 0.8666666746139526)
                                                                                                                                                              [2024-12-14 02:49:18,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:18,312][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.56549471616745, acc: 0.7903226017951965)
[2024-12-14 02:49:18,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:18,649][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.3816925287246704, acc: 0.8799999952316284)
 [2024-12-14 02:49:18,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:18,966][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.8886452317237854, acc: 0.7407407164573669)
10, step 231/574 completed (loss: 0.7979133725166321, acc: 0.800000011920929)
[2024-12-14 02:49:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:19,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:19,355][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 0.9316916465759277, acc: 0.75)
             [2024-12-14 02:49:19,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:19,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:19,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:19,845][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.4458786249160767, acc: 0.6376146674156189)
[2024-12-14 02:49:19,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:19,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:20,322][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 0.9713777899742126, acc: 0.7076923251152039)
[2024-12-14 02:49:20,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:20,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:20,645][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.3107200562953949, acc: 0.8421052694320679)
[2024-12-14 02:49:20,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:20,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:21,005][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.1666199117898941, acc: 0.9583333134651184)
[2024-12-14 02:49:21,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:21,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:21,379][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.4822101891040802, acc: 0.8181818127632141)
[2024-12-14 02:49:21,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:21,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:21,723][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.3405744433403015, acc: 0.9259259104728699)
[2024-12-14 02:49:21,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:21,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:22,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:22,103][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.14615195989608765, acc: 0.9714285731315613)
[2024-12-14 02:49:22,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:22,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:22,507][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.6984158158302307, acc: 0.7727272510528564)
[2024-12-14 02:49:22,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:22,885][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.42939817905426025, acc: 0.8863636255264282)
[2024-12-14 02:49:23,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:23,221][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:49:23,466][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.9703625440597534, acc: 0.6935483813285828)
[2024-12-14 02:49:23,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:23,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:23,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:24,000][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.5003645420074463, acc: 0.8409090638160706)
[2024-12-14 02:49:24,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:24,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:24,561][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 1.4826332330703735, acc: 0.5632184147834778)
                                                                               [2024-12-14 02:49:24,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:24,918][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 1.3568055629730225, acc: 0.542553186416626)
                                                                                [2024-12-14 02:49:25,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:25,292][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 1.485826849937439, acc: 0.5542168617248535)
                                                                                 [2024-12-14 02:49:25,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:25,658][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.08741603046655655, acc: 1.0)
                                                                               [2024-12-14 02:49:25,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:25,973][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.345838338136673, acc: 0.8717948794364929)
                                                                                [2024-12-14 02:49:26,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:26,355][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 1.3110450506210327, acc: 0.650602400302887)
                                                                                 [2024-12-14 02:49:26,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:26,730][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.8550970554351807, acc: 0.7735849022865295)
                                                                               [2024-12-14 02:49:26,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:27,132][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.8733651041984558, acc: 0.746835470199585)
                                                                                [2024-12-14 02:49:27,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:27,505][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.5941673517227173, acc: 0.8039215803146362)
                                                                                [2024-12-14 02:49:27,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:27,868][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 1.1105214357376099, acc: 0.641791045665741)
                                                                                                                                                                [2024-12-14 02:49:27,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:28,248][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.06664861738681793, acc: 1.0)
                                                                                [2024-12-14 02:49:28,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:28,616][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.144606813788414, acc: 0.9599999785423279)
                                                                   [2024-12-14 02:49:28,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:29,053][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.44702401757240295, acc: 0.7777777910232544)
                                                                               [2024-12-14 02:49:29,166][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:49:29,402][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.9424313306808472, acc: 0.6744186282157898)
                     [2024-12-14 02:49:29,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:29,766][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.6257339715957642, acc: 0.8974359035491943)
                                                                               [2024-12-14 02:49:29,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:30,128][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.8729988932609558, acc: 0.7333333492279053)
[2024-12-14 02:49:30,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:30,485][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.20042462646961212, acc: 0.9130434989929199)
[2024-12-14 02:49:30,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:30,864][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.3409084975719452, acc: 0.9230769276618958)
                     [2024-12-14 02:49:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:31,248][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 1.4188299179077148, acc: 0.5714285969734192)
[2024-12-14 02:49:31,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:31,788][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 1.37314772605896, acc: 0.6000000238418579)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:49:31,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:32,172][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 1.264102578163147, acc: 0.6739130616188049)
                                                          [2024-12-14 02:49:32,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:32,578][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.8631796836853027, acc: 0.7755101919174194)
                                                                               [2024-12-14 02:49:32,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:32,937][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.05076507851481438, acc: 1.0)
                                                                                                                                                                                                                                       [2024-12-14 02:49:33,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:33,277][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.04201122373342514, acc: 1.0)
                                                                                                                                          [2024-12-14 02:49:33,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:33,664][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.332120805978775, acc: 0.9268292784690857)
/10, step 133/574 completed (loss: 0.39319920539855957, acc: 0.8695651888847351)
[2024-12-14 02:49:33,609][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 1.13185453414917, acc: 0.7162162065505981)
[2024-12-14 02:49:33,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:33,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:33,899][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.32734885811805725, acc: 0.8857142925262451)
[2024-12-14 02:49:33,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:34,071][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.7200519442558289, acc: 0.7758620977401733)
[2024-12-14 02:49:34,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:34,215][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.1506900191307068, acc: 1.0)
[2024-12-14 02:49:34,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:34,378][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.4174562394618988, acc: 0.9090909361839294)
[2024-12-14 02:49:34,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:34,533][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.5844284892082214, acc: 0.8333333134651184)
[2024-12-14 02:49:34,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:34,730][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.15497832000255585, acc: 0.9545454382896423)
[2024-12-14 02:49:34,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:34,890][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.3659702241420746, acc: 0.8999999761581421)
[2024-12-14 02:49:34,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:35,105][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.11523021757602692, acc: 1.0)
[2024-12-14 02:49:35,196][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.423663467168808, acc: 0.8260869383811951)
[2024-12-14 02:49:35,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:35,535][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.38742968440055847, acc: 0.9047619104385376)
[2024-12-14 02:49:35,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:35,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:35,888][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.48652923107147217, acc: 0.8846153616905212)
[2024-12-14 02:49:36,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:36,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:36,271][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.3852848708629608, acc: 0.9032257795333862)
[2024-12-14 02:49:36,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:36,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:36,665][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.6434502005577087, acc: 0.7567567825317383)
[2024-12-14 02:49:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:36,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:37,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:38,045][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 0.8785415291786194, acc: 0.7641509175300598)
2024-12-14 02:49:37,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:37,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:37,609][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 1.1248635053634644, acc: 0.6567164063453674)
[2024-12-14 02:49:37,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:37,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:37,979][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 1.3403183221817017, acc: 0.581632673740387)
[2024-12-14 02:49:38,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:38,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:38,436][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 1.4937776327133179, acc: 0.5957446694374084)
[2024-12-14 02:49:38,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:38,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:38,801][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.946286141872406, acc: 0.6857143044471741)
[2024-12-14 02:49:38,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:38,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:39,136][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.6780694127082825, acc: 0.8214285969734192)
[2024-12-14 02:49:39,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:39,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:39,482][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.4010579586029053, acc: 0.8260869383811951)
[2024-12-14 02:49:39,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:39,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:39,850][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.5725764632225037, acc: 0.7931034564971924)
[2024-12-14 02:49:39,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:39,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:40,212][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.9629852175712585, acc: 0.6739130616188049)
[2024-12-14 02:49:40,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:40,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:40,561][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.755021870136261, acc: 0.7457627058029175)
[2024-12-14 02:49:40,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:40,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:40,933][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.7779693603515625, acc: 0.7894737124443054)
[2024-12-14 02:49:41,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:41,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:41,280][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 1.258059024810791, acc: 0.6216216087341309)
[2024-12-14 02:49:41,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:41,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:41,598][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.3810051381587982, acc: 0.8928571343421936)
[2024-12-14 02:49:41,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:41,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:41,970][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.6611120700836182, acc: 0.782608687877655)
[2024-12-14 02:49:42,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:42,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:42,331][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.14036062359809875, acc: 1.0)
[2024-12-14 02:49:42,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:42,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:43,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:43,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:43,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:43,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:44,043][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 1.1338626146316528, acc: 0.7162162065505981)
[2024-12-14 02:49:44,132][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:49:44,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:44,363][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 1.3527311086654663, acc: 0.5740740895271301)
[2024-12-14 02:49:44,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:44,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:44,761][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 1.041165828704834, acc: 0.6860465407371521)
[2024-12-14 02:49:44,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:44,998][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:49:45,360][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 0.8507518172264099, acc: 0.7647058963775635)
[2024-12-14 02:49:45,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:45,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:45,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:45,925][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 1.263777256011963, acc: 0.6966292262077332)
[2024-12-14 02:49:46,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:46,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:46,288][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.3932974934577942, acc: 0.8636363744735718)
[2024-12-14 02:49:46,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:46,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:46,665][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.7655062675476074, acc: 0.761904776096344)
[2024-12-14 02:49:46,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:46,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:47,051][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.795029878616333, acc: 0.7586206793785095)
[2024-12-14 02:49:47,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:47,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:47,357][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.6253905296325684, acc: 0.7755101919174194)
[2024-12-14 02:49:47,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:47,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:47,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:47,750][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.8320323824882507, acc: 0.7200000286102295)
[2024-12-14 02:49:47,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:48,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:48,161][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 1.0078481435775757, acc: 0.75)
[2024-12-14 02:49:48,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:48,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:48,553][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.1451936960220337, acc: 0.6372548937797546)
[2024-12-14 02:49:48,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:48,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:49,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:49,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:49,585][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.8652809858322144, acc: 0.4931506812572479)
[2024-12-14 02:49:49,688][slam_llm.models.sldality encoder
[2024-12-14 02:49:49,866][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.08092033118009567, acc: 1.0)
[2024-12-14 02:49:50,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:50,406][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.879317045211792, acc: 0.75)
                                                                                                                                                                                                                                                                                              [2024-12-14 02:49:50,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:50,811][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.8671603202819824, acc: 0.7200000286102295)
[2024-12-14 02:49:50,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:51,200][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.4781387150287628, acc: 0.8484848737716675)
                                                                                                                                                              [2024-12-14 02:49:51,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:51,578][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.2680028975009918, acc: 0.939393937587738)
 [2024-12-14 02:49:51,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:51,909][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.047181855887174606, acc: 1.0)
                                                                                            [2024-12-14 02:49:52,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:52,272][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.3321057856082916, acc: 0.9259259104728699)
[2024-12-14 02:49:52,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:52,638][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.06679031252861023, acc: 1.0)
[2024-12-14 02:49:52,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:52,980][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.15877482295036316, acc: 0.9722222089767456)
[2024-12-14 02:49:53,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:53,326][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.08610714972019196, acc: 1.0)
[2024-12-14 02:49:53,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:53,637][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.10590198636054993, acc: 0.9615384340286255)
[2024-12-14 02:49:53,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:53,998][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.6042861342430115, acc: 0.8103448152542114)
                                [2024-12-14 02:49:54,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:54,365][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.5828325152397156, acc: 0.8571428656578064)
                                                                                [2024-12-14 02:49:54,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:54,741][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.1994645744562149, acc: 0.8999999761581421)
                                                                              [2024-12-14 02:49:54,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:55,111][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.21273033320903778, acc: 0.939393937587738)
                                                                               [2024-12-14 02:49:55,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:55,477][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.14848779141902924, acc: 0.9090909361839294)
                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:49:56,258][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:49:56,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:56,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:57,208][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:49:57,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:57,848][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                       [2024-12-14 02:49:58,265][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:49:58,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:58,993][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:49:59,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:49:59,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:00,074][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:50:00,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:00,795][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:50:01,123][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:50:01,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:01,849][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:50:02,168][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:50:02,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:02,908][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:50:03,231][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:50:03,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:03,915][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                         [2024-12-14 02:50:04,281][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:50:04,712][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:50:05,019][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:50:05,384][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:50:05,798][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:50:06,136][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:50:06,430][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:50:06,808][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:50:07,165][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:50:07,542][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:50:07,975][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:50:08,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:08,596][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:50:08,945][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:50:09,298][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:50:09,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:09,960][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:50:10,398][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.3250716924667358, acc: 0.5925925970077515)
[2024-12-14 02:50:10,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:10,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:10,589][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.6456609964370728, acc: 0.837837815284729)
[2024-12-14 02:50:10,612][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.3829862177371979, acc: 0.8157894611358643)
[2024-12-14 02:50:10,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:10,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:10,927][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.5888373255729675, acc: 0.8235294222831726)
[2024-12-14 02:50:11,008][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.8313032388687134, acc: 0.7674418687820435)
[2024-12-14 02:50:11,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:11,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:11,229][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.48321494460105896, acc: 0.875)
[2024-12-14 02:50:11,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:11,542][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 0.9754252433776855, acc: 0.7207207083702087)
[2024-12-14 02:50:11,542][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 1.3858628273010254, acc: 0.6015625)
[2024-12-14 02:50:11,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:11,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:11,940][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.7750815749168396, acc: 0.800000011920929)
[2024-12-14 02:50:11,964][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 1.4167951345443726, acc: 0.6000000238418579)
[2024-12-14 02:50:12,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:12,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:12,305][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 1.0375293493270874, acc: 0.7142857313156128)
[2024-12-14 02:50:12,348][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.2725624740123749, acc: 0.939393937587738)
[2024-12-14 02:50:12,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:12,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:12,657][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 1.7486190795898438, acc: 0.5155279636383057)
[2024-12-14 02:50:12,696][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.08951514214277267, acc: 0.9259259104728699)
[2024-12-14 02:50:12,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:12,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:12,976][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.2764202654361725, acc: 0.9599999785423279)
[2024-12-14 02:50:13,056][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 1.7823044061660767, acc: 0.5206185579299927)
[2024-12-14 02:50:13,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:13,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:13,297][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.6250365972518921, acc: 0.8461538553237915)
[2024-12-14 02:50:13,425][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.09491775184869766, acc: 1.0)
[2024-12-14 02:50:13,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:13,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:13,783][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.5774274468421936, acc: 0.8571428656578064)
[2024-12-14 02:50:13,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:14,293][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.0267482995986938, acc: 0.679347813129425)
[2024-12-14 02:50:14,151][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.8567349910736084, acc: 0.7586206793785095)
[2024-12-14 02:50:14,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:14,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:14,630][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 1.3940463066101074, acc: 0.5738636255264282)
[2024-12-14 02:50:14,677][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.6016523838043213, acc: 0.8181818127632141)
[2024-12-14 02:50:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:14,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:15,064][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 1.1140722036361694, acc: 0.6382978558540344)
[2024-12-14 02:50:15,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:15,226][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 1.46547532081604, acc: 0.6030927896499634)
[2024-12-14 02:50:15,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:15,416][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.57889324426651, acc: 0.849056601524353)
[2024-12-14 02:50:15,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:15,565][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.9579482078552246, acc: 0.6551724076271057)
[2024-12-14 02:50:15,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:15,766][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.6069861650466919, acc: 0.8166666626930237)
[2024-12-14 02:50:15,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:15,938][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.3432779312133789, acc: 0.9259259104728699)
[2024-12-14 02:50:16,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:16,109][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.2533501088619232, acc: 0.9069767594337463)
[2024-12-14 02:50:16,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:16,272][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.5414760708808899, acc: 0.8421052694320679)
[2024-12-14 02:50:16,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:16,415][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 0.47064870595932007, acc: 0.8666666746139526)
[2024-12-14 02:50:16,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:16,629][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.2994671165943146, acc: 0.8928571343421936)
[2024-12-14 02:50:16,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:16,830][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 1.1679295301437378, acc: 0.6736842393875122)
[2024-12-14 02:50:16,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:16,988][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.4155021011829376, acc: 0.90625)
[2024-12-14 02:50:17,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:17,183][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 1.1346040964126587, acc: 0.6666666865348816)
[2024-12-14 02:50:17,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:17,391][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.726295530796051, acc: 0.8301886916160583)
[2024-12-14 02:50:17,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:17,604][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 0.9709211587905884, acc: 0.7166666388511658)
[2024-12-14 02:50:17,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:17,777][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.49111923575401306, acc: 0.849056601524353)
[2024-12-14 02:50:17,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:18,102][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.5761890411376953, acc: 0.5963302850723267)
[2024-12-14 02:50:18,154][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.18826356530189514, acc: 0.970588207244873)
[2024-12-14 02:50:18,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:18,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:18,526][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.1261707842350006, acc: 1.0)
[2024-12-14 02:50:18,582][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 0.9385830163955688, acc: 0.7230769395828247)
[2024-12-14 02:50:18,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:18,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:18,873][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.6341191530227661, acc: 0.8196721076965332)
[2024-12-14 02:50:18,925][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.07709082961082458, acc: 1.0)
[2024-12-14 02:50:18,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:19,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:19,234][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.25814807415008545, acc: 0.9166666865348816)
[2024-12-14 02:50:19,268][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.1398228108882904, acc: 0.9333333373069763)
[2024-12-14 02:50:19,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:19,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:19,553][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.6336768269538879, acc: 0.7272727489471436)
[2024-12-14 02:50:19,640][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.09881904721260071, acc: 1.0)
[2024-12-14 02:50:19,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:19,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:19,877][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.589924693107605, acc: 0.8148148059844971)
[2024-12-14 02:50:19,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:19,981][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.9573037028312683, acc: 0.695652186870575)
[2024-12-14 02:50:20,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:20,185][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.18163923919200897, acc: 0.9714285731315613)
[2024-12-14 02:50:20,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:20,432][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 0.9377536773681641, acc: 0.7916666865348816)
[2024-12-14 02:50:20,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:20,546][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.42515242099761963, acc: 0.8863636255264282)
[2024-12-14 02:50:20,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:20,810][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.8378927111625671, acc: 0.7349397540092468)
[2024-12-14 02:50:20,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:20,936][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.5248702764511108, acc: 0.8409090638160706)
[2024-12-14 02:50:21,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:21,169][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 1.1665232181549072, acc: 0.6025640964508057)
[2024-12-14 02:50:21,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:21,515][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.9618760347366333, acc: 0.6935483813285828)
[2024-12-14 02:50:21,527][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 1.1894779205322266, acc: 0.6734693646430969)
[2024-12-14 02:50:21,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:21,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:21,887][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.09209868311882019, acc: 1.0)
[2024-12-14 02:50:21,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:22,053][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.5117380619049072, acc: 0.8181818127632141)
[2024-12-14 02:50:22,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:22,179][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.17029809951782227, acc: 0.9583333134651184)
[2024-12-14 02:50:22,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:22,399][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.2577733099460602, acc: 0.9047619104385376)
[2024-12-14 02:50:22,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:22,519][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.09590493142604828, acc: 1.0)
[2024-12-14 02:50:22,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:22,773][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.2699654996395111, acc: 0.9230769276618958)
[2024-12-14 02:50:22,854][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.18714666366577148, acc: 0.9677419066429138)
[2024-12-14 02:50:22,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:22,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:23,178][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.10944221168756485, acc: 1.0)
[2024-12-14 02:50:23,256][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.7396804094314575, acc: 0.7910447716712952)
[2024-12-14 02:50:23,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:23,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:23,512][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.2563105523586273, acc: 0.8999999761581421)
[2024-12-14 02:50:23,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:23,628][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.8665931224822998, acc: 0.7307692170143127)
[2024-12-14 02:50:23,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:23,849][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.3844819664955139, acc: 0.9459459185600281)
[2024-12-14 02:50:23,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:23,964][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.4269770383834839, acc: 0.8222222328186035)
[2024-12-14 02:50:24,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:24,159][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.42342495918273926, acc: 0.8648648858070374)
[2024-12-14 02:50:24,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:24,276][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.610170841217041, acc: 0.8225806355476379)
[2024-12-14 02:50:24,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:24,489][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.3842334449291229, acc: 0.8918918967247009)
[2024-12-14 02:50:24,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:24,654][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.39507007598876953, acc: 0.8600000143051147)
[2024-12-14 02:50:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:24,810][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.7823243141174316, acc: 0.8088235259056091)
[2024-12-14 02:50:25,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:25,046][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.48173144459724426, acc: 0.8148148059844971)
[2024-12-14 02:50:25,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:25,216][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.13666336238384247, acc: 0.9512194991111755)
[2024-12-14 02:50:25,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:25,439][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 0.4205855429172516, acc: 0.8857142925262451)
[2024-12-14 02:50:25,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:25,569][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.0272250697016716, acc: 1.0)
[2024-12-14 02:50:25,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:25,815][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.578689455986023, acc: 0.8205128312110901)
[2024-12-14 02:50:25,894][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.031140809878706932, acc: 1.0)
[2024-12-14 02:50:25,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:25,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:26,194][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 0.6161061525344849, acc: 0.7560975551605225)
[2024-12-14 02:50:26,222][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.1665879338979721, acc: 0.9677419066429138)
[2024-12-14 02:50:26,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:26,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:26,567][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.4111507833003998, acc: 0.8771929740905762)
[2024-12-14 02:50:26,585][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.8385280966758728, acc: 0.8157894611358643)
[2024-12-14 02:50:26,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:26,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:26,954][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.7132896184921265, acc: 0.7571428418159485)
[2024-12-14 02:50:26,957][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.20073343813419342, acc: 0.8947368264198303)
[2024-12-14 02:50:27,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:27,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:27,287][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.4615391790866852, acc: 0.8684210777282715)
[2024-12-14 02:50:27,356][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.10160195082426071, acc: 0.9285714030265808)
[2024-12-14 02:50:27,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:27,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:27,752][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.4739077389240265, acc: 0.8148148059844971)
[2024-12-14 02:50:27,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:27,860][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 1.0998966693878174, acc: 0.6698113083839417)
[2024-12-14 02:50:28,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:28,127][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.2540373206138611, acc: 0.90625)
[2024-12-14 02:50:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:28,442][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 1.1442103385925293, acc: 0.6416666507720947)
[[2024-12-14 02:50:28,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:28,803][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.5623115301132202, acc: 0.8500000238418579)
2024-12-14 02:50:28,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:28,800][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.37733733654022217, acc: 0.9444444179534912)
[2024-12-14 02:50:28,841][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.7107446193695068, acc: 0.7543859481811523)
[2024-12-14 02:50:28,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:28,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:29,173][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.19138872623443604, acc: 0.9354838728904724)
[2024-12-14 02:50:29,239][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.5920323133468628, acc: 0.75)
[2024-12-14 02:50:29,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:29,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:29,508][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 1.3221243619918823, acc: 0.5866666436195374)
[2024-12-14 02:50:29,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:29,636][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.1701839417219162, acc: 0.9333333373069763)
[2024-12-14 02:50:29,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:29,894][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.6896119713783264, acc: 0.875)
[2024-12-14 02:50:30,011][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.29622676968574524, acc: 0.9473684430122375)
[2024-12-14 02:50:30,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:30,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:30,403][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.7631465792655945, acc: 0.800000011920929)
[2024-12-14 02:50:30,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:30,711][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 1.717483401298523, acc: 0.5360000133514404)
[2024-12-14 02:50:30,753][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 1.5603309869766235, acc: 0.5977011322975159)
[2024-12-14 02:50:30,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:30,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:31,069][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 1.0640580654144287, acc: 0.6629213690757751)
[2024-12-14 02:50:31,126][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 1.5312957763671875, acc: 0.542553186416626)
[2024-12-14 02:50:31,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:31,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:31,447][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 0.999138593673706, acc: 0.6891891956329346)
[2024-12-14 02:50:31,512][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 1.4759958982467651, acc: 0.5060241222381592)
[2024-12-14 02:50:31,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:31,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:31,820][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.0830577164888382, acc: 1.0)
[2024-12-14 02:50:31,901][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.7751248478889465, acc: 0.7758620977401733)
[2024-12-14 02:50:31,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:31,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:32,184][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.39603254199028015, acc: 0.8461538553237915)
[2024-12-14 02:50:32,243][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.4158013164997101, acc: 0.8636363744735718)
[2024-12-14 02:50:32,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:32,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:32,730][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.13502654433250427, acc: 0.95652174949646)
                                                                                                                                                                                                                          [2024-12-14 02:50:32,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:33,046][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.09470893442630768, acc: 0.9629629850387573)
                                                                                                                             [2024-12-14 02:50:33,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:33,414][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.04855683818459511, acc: 1.0)
              [2024-12-14 02:50:33,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:33,775][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.14145590364933014, acc: 0.9130434989929199)
[2024-12-14 02:50:33,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:34,132][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.440885454416275, acc: 0.8888888955116272)
                                                                                                                                                              [2024-12-14 02:50:34,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:34,472][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.05558796972036362, acc: 1.0)
                                                                               [2024-12-14 02:50:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:34,858][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.4121089279651642, acc: 0.8787878751754761)
                                                                               [2024-12-14 02:50:34,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:35,220][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.22290712594985962, acc: 0.9166666865348816)
                                                                              [2024-12-14 02:50:35,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:35,605][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.3590724468231201, acc: 0.8863636255264282)
                                                                               [2024-12-14 02:50:35,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:35,986][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.171995148062706, acc: 0.9523809552192688)
                                                                                [2024-12-14 02:50:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:36,347][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.3921383321285248, acc: 0.8717948794364929)
                                                                              [2024-12-14 02:50:36,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:36,827][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 1.1319706439971924, acc: 0.6818181872367859)
                                                                               [2024-12-14 02:50:37,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:37,517][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 1.7860000133514404, acc: 0.5120000243186951)
                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:50:37,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:37,944][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 1.5917986631393433, acc: 0.5645161271095276)
[2024-12-14 02:50:38,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:38,602][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 1.7676522731781006, acc: 0.482587069272995)
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:50:38,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:38,919][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.6152114868164062, acc: 0.7735849022865295)
                                                                 [2024-12-14 02:50:39,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:39,339][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.4387890100479126, acc: 0.8181818127632141)
                                                                                                                                                             [2024-12-14 02:50:39,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:39,685][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.26720815896987915, acc: 0.95652174949646)
  [2024-12-14 02:50:39,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:40,045][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.28703945875167847, acc: 0.8846153616905212)
                                                                              [2024-12-14 02:50:40,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:40,391][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.4243625998497009, acc: 0.8571428656578064)
                                                                                                                                               [2024-12-14 02:50:40,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:40,736][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.7666765451431274, acc: 0.746268630027771)
                                                                                [2024-12-14 02:50:40,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:41,095][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.851729691028595, acc: 0.7916666865348816)
                                                                                [2024-12-14 02:50:41,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:41,481][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.8982297778129578, acc: 0.717391312122345)
                                                                                 [2024-12-14 02:50:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:41,855][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.8767538070678711, acc: 0.692307710647583)
                                                                  [2024-12-14 02:50:41,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:42,204][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.8088706731796265, acc: 0.7631579041481018)
                                                                                [2024-12-14 02:50:42,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:42,569][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.593977153301239, acc: 0.8367347121238708)
                                                                   [2024-12-14 02:50:42,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:42,922][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.1759425848722458, acc: 0.9696969985961914)
[2024-12-14 02:50:43,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:43,264][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 1.3621952533721924, acc: 0.5773195624351501)
[2024-12-14 02:50:43,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:43,676][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.8135635256767273, acc: 0.7428571581840515)
[2024-12-14 02:50:43,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:44,095][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 1.4392552375793457, acc: 0.5988371968269348)
[2024-12-14 02:50:44,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:44,456][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.6556330919265747, acc: 0.8214285969734192)
[2024-12-14 02:50:44,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:44,827][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 1.0743372440338135, acc: 0.6666666865348816)
                                                                              [2024-12-14 02:50:44,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:45,173][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.5852770209312439, acc: 0.8611111044883728)
                                                                               [2024-12-14 02:50:45,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:45,545][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.07289525866508484, acc: 0.96875)
                                                                                          [2024-12-14 02:50:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:45,908][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.104315385222435, acc: 1.0)
                                                                                  [2024-12-14 02:50:46,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:46,291][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.39335206151008606, acc: 0.8913043737411499)
[2024-12-14 02:50:46,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:46,617][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.7030974626541138, acc: 0.773809552192688)
                     [2024-12-14 02:50:46,700][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:50:46,921][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.9652806520462036, acc: 0.7108433842658997)
[2024-12-14 02:50:47,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:47,227][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.787906289100647, acc: 0.7477477192878723)
[2024-12-14 02:50:47,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:47,555][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 1.0409166812896729, acc: 0.7281553149223328)
[2024-12-14 02:50:47,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:47,904][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.888357937335968, acc: 0.7560975551605225)
[2024-12-14 02:50:48,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:48,277][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.13886456191539764, acc: 1.0)
[2024-12-14 02:50:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:48,651][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.2181732952594757, acc: 0.9642857313156128)
[2024-12-14 02:50:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:49,055][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 1.4738322496414185, acc: 0.5882353186607361)
[2024-12-14 02:50:49,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:49,454][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 1.6861567497253418, acc: 0.5764192342758179)
[2024-12-14 02:50:49,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:49,850][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 0.9764368534088135, acc: 0.75)
                                  [2024-12-14 02:50:49,955][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:50:50,194][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 1.4470019340515137, acc: 0.6257668733596802)
[2024-12-14 02:50:50,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:50,543][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 1.4194668531417847, acc: 0.6187050342559814)
[2024-12-14 02:50:50,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:50,927][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 1.6561098098754883, acc: 0.5477386713027954)
                                                                                                                                                                         [2024-12-14 02:50:51,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:51,271][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.15462952852249146, acc: 0.9722222089767456)
[2024-12-14 02:50:51,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:51,617][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.2452607899904251, acc: 0.939393937587738)
                                                                                                                                                                                                                                                                            [2024-12-14 02:50:51,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:51,958][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.5494198203086853, acc: 0.8148148059844971)
                                                                                                                                                              [2024-12-14 02:50:52,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:52,286][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.33897775411605835, acc: 0.8999999761581421)
[2024-12-14 02:50:52,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:52,636][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.28324323892593384, acc: 0.8500000238418579)
[2024-12-14 02:50:52,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:53,004][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.6367564797401428, acc: 0.7758620977401733)
                                                                                                                                             [2024-12-14 02:50:53,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:53,355][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.2828308939933777, acc: 0.9677419066429138)
[2024-12-14 02:50:53,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:53,702][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.06935877352952957, acc: 1.0)
[2024-12-14 02:50:53,816][slam_llm.models.slam_model][INFO] - modality encoder
m_model][INFO] - modality encoder
[2024-12-14 02:50:53,901][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 1.687239646911621, acc: 0.5933333039283752)
[2024-12-14 02:50:53,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:54,038][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:50:54,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:54,318][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 1.6417158842086792, acc: 0.5486111044883728)
[2024-12-14 02:50:54,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:54,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:54,727][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.3098791539669037, acc: 0.9069767594337463)
[2024-12-14 02:50:54,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:55,072][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.26856669783592224, acc: 0.9583333134651184)
[2024-12-14 02:50:55,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:55,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:55,438][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.3227578401565552, acc: 0.9069767594337463)
[2024-12-14 02:50:55,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:55,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:55,822][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.0507068857550621, acc: 1.0)
[2024-12-14 02:50:55,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:56,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:56,356][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.7145076394081116, acc: 0.75)
[2024-12-14 02:50:56,448][slam_llm.models.slam_model][INFO] - modality encoder
        [2024-12-14 02:50:56,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:56,709][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.9945703148841858, acc: 0.746666669845581)
[2024-12-14 02:50:56,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:56,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:57,046][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.5428405404090881, acc: 0.8181818127632141)
[2024-12-14 02:50:57,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:57,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:57,392][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.34008461236953735, acc: 0.939393937587738)
[2024-12-14 02:50:57,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:57,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:57,775][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.4479738771915436, acc: 0.8709677457809448)
[2024-12-14 02:50:57,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:57,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:58,088][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.3158119320869446, acc: 0.8518518805503845)
[2024-12-14 02:50:58,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:58,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:58,411][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.06519965827465057, acc: 1.0)
[2024-12-14 02:50:58,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:58,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:58,761][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.28444015979766846, acc: 0.9166666865348816)
[2024-12-14 02:50:59,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:59,334][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.2599771022796631, acc: 0.8799999952316284)
10, step 408/574 completed (loss: 0.26816704869270325, acc: 0.8888888955116272)
[2024-12-14 02:50:59,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:59,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:59,502][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.14390277862548828, acc: 0.9615384340286255)
[2024-12-14 02:50:59,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:59,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:59,819][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.6316717863082886, acc: 0.8620689511299133)
[2024-12-14 02:50:59,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:50:59,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:00,200][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.2994171977043152, acc: 0.8928571343421936)
[2024-12-14 02:51:00,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:00,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:00,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:00,590][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.34363552927970886, acc: 0.9333333373069763)
[2024-12-14 02:51:00,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:00,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:00,990][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.24211283028125763, acc: 0.939393937587738)
[2024-12-14 02:51:01,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:01,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:01,337][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.24892467260360718, acc: 0.8636363744735718)
[2024-12-14 02:51:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:02,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:02,069][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:51:02,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:02,504][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                           [2024-12-14 02:51:02,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:02,882][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:51:03,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:03,263][slam_llm.models.slam_model][INFO[2024-12-14 02:51:04,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:05,752][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 1.5818392038345337, acc: 0.5642856955528259)
dels.slam_model][INFO] - modality encoder
[2024-12-14 02:51:04,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:04,313][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.8771, device='cuda:0') eval_epoch_loss=tensor(1.9282, device='cuda:0') eval_epoch_acc=tensor(0.5636, device='cuda:0')
[2024-12-14 02:51:04,315][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:51:04,315][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:51:04,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:04,664][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_8_step_272_loss_1.9281917810440063/model.pt
[2024-12-14 02:51:04,668][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:51:04,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:04,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:05,076][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.22926966845989227, acc: 0.9333333373069763)
[2024-12-14 02:51:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:05,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:05,447][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.8131411075592041, acc: 0.7833333611488342)
[2024-12-14 02:51:05,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:05,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:05,806][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.38241681456565857, acc: 0.875)
[2024-12-14 02:51:05,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:06,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:06,200][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.1905023157596588, acc: 0.9333333373069763)
[2024-12-14 02:51:06,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:06,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:06,591][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.45125120878219604, acc: 0.8620689511299133)
[2024-12-14 02:51:06,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:06,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:06,999][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.5912408232688904, acc: 0.8399999737739563)
[2024-12-14 02:51:07,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:07,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:07,300][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 1.1646144390106201, acc: 0.7234042286872864)
[2024-12-14 02:51:07,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:07,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:07,639][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.9304265379905701, acc: 0.7291666865348816)
[2024-12-14 02:51:07,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:07,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:08,036][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.6121734380722046, acc: 0.8409090638160706)
[2024-12-14 02:51:08,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:08,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:08,473][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 1.099900245666504, acc: 0.6987951993942261)
[2024-12-14 02:51:08,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:08,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:08,835][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 1.2186086177825928, acc: 0.6574074029922485)
[2024-12-14 02:51:08,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:08,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:09,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:09,216][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.5256913900375366, acc: 0.8947368264198303)
[2024-12-14 02:51:09,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:10,282][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 1.7089014053344727, acc: 0.5211864113807678)
2024-12-14 02:51:09,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:09,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:09,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:09,906][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.2436484545469284, acc: 0.925000011920929)
[2024-12-14 02:51:10,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:10,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:10,292][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 1.371252417564392, acc: 0.59375)
[2024-12-14 02:51:10,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:10,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:10,691][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 1.5323580503463745, acc: 0.5360000133514404)
[2024-12-14 02:51:10,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:10,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:11,051][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 0.9995405673980713, acc: 0.6703296899795532)
[2024-12-14 02:51:11,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:11,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:11,405][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 1.7628899812698364, acc: 0.5155279636383057)
[2024-12-14 02:51:11,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:11,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:11,755][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 1.7777659893035889, acc: 0.48969072103500366)
[2024-12-14 02:51:11,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:12,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:12,082][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.12434077262878418, acc: 0.9545454382896423)
[2024-12-14 02:51:12,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:12,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:12,398][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.8236512541770935, acc: 0.8333333134651184)
[2024-12-14 02:51:12,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:12,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:12,724][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.7691851258277893, acc: 0.7931034564971924)
[2024-12-14 02:51:12,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:13,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:13,181][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.6133065819740295, acc: 0.8181818127632141)
[2024-12-14 02:51:13,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:13,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:13,738][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 1.4110772609710693, acc: 0.6340206265449524)
[2024-12-14 02:51:13,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:13,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:14,088][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.754170298576355, acc: 0.7586206793785095)
[2024-12-14 02:51:14,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:14,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:14,465][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.26657673716545105, acc: 0.9259259104728699)
[2024-12-14 02:51:14,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:14,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:14,805][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.5363892912864685, acc: 0.8947368264198303)
[2024-12-14 02:51:14,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:14,939][slam_llm.models.slam_model][INFO] - modality encoder
[[2024-12-14 02:51:15,385][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.16680540144443512, acc: 0.949999988079071)
                                                                                                                                                              [2024-12-14 02:51:15,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:15,767][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.2696724832057953, acc: 0.9090909361839294)
                                                                     [2024-12-14 02:51:15,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:16,186][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.6013518571853638, acc: 0.8461538553237915)
                                                                              [2024-12-14 02:51:16,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:16,574][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.711264431476593, acc: 0.8125)
                                                                                                                                                                           [2024-12-14 02:51:16,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:16,966][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.4763956367969513, acc: 0.8125)
                                                                                            [2024-12-14 02:51:17,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:17,280][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.4901059567928314, acc: 0.8787878751754761)
                                                                   [2024-12-14 02:51:17,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:17,603][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.10423468798398972, acc: 1.0)
                                                                                             [2024-12-14 02:51:17,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:17,968][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.14317989349365234, acc: 0.9677419066429138)
                                                                               [2024-12-14 02:51:18,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:18,338][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.023410452529788017, acc: 1.0)
              [2024-12-14 02:51:18,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:18,698][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.3383594751358032, acc: 0.8999999761581421)
                                                                              [2024-12-14 02:51:18,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:19,074][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.31861692667007446, acc: 0.8536585569381714)
                                                                              [2024-12-14 02:51:19,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:19,429][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.18269158899784088, acc: 0.9714285731315613)
                                                                                                                                                             [2024-12-14 02:51:19,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:19,805][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.3055649995803833, acc: 0.9210526347160339)
                                                                               [2024-12-14 02:51:19,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:20,172][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.23084217309951782, acc: 0.8709677457809448)
[2024-12-14 02:51:20,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:20,507][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.02584371156990528, acc: 1.0)
                                                                              [2024-12-14 02:51:20,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:20,831][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.09872815757989883, acc: 0.939393937587738)
                                                                                                                                                                                                                                             [2024-12-14 02:51:20,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:21,184][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.47212544083595276, acc: 0.8999999761581421)
[2024-12-14 02:51:21,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:21,542][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.39089542627334595, acc: 0.8714285492897034)
                                                                               [2024-12-14 02:51:21,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:21,953][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 1.453708529472351, acc: 0.5474452376365662)
                                                                                [2024-12-14 02:51:22,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:22,339][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 1.1275542974472046, acc: 0.682758629322052)
                                                                                [2024-12-14 02:51:22,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:22,700][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 1.6141595840454102, acc: 0.6071428656578064)
                                                                                                                                                               [2024-12-14 02:51:22,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:23,020][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 1.4258359670639038, acc: 0.5761589407920837)
 [2024-12-14 02:51:23,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:23,334][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.9771708846092224, acc: 0.6837607026100159)
                                                                                [2024-12-14 02:51:24,068][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:51:24,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:24,629][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:51:25,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:24,885][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 0.5022449493408203, acc: 0.8292682766914368)
[2024-12-14 02:51:24,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:25,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:25,255][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.7589427828788757, acc: 0.8157894611358643)
[2024-12-14 02:51:25,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:25,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:25,627][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.03480764850974083, acc: 1.0)
[2024-12-14 02:51:25,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:25,981][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.06752936542034149, acc: 0.9642857313156128)
[2024-12-14 02:51:26,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:26,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:26,309][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.20696227252483368, acc: 0.9629629850387573)
[2024-12-14 02:51:26,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:26,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:26,645][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.21797430515289307, acc: 0.9375)
[2024-12-14 02:51:26,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:26,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:27,028][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.6209651231765747, acc: 0.8548387289047241)
[2024-12-14 02:51:27,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:27,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:27,466][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.8149394392967224, acc: 0.7894737124443054)
[2024-12-14 02:51:27,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:27,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:27,843][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.7005852460861206, acc: 0.90625)
[2024-12-14 02:51:27,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:27,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:28,276][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.4175105690956116, acc: 0.8666666746139526)
[2024-12-14 02:51:28,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:28,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:28,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:28,716][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.07367369532585144, acc: 1.0)
[2024-12-14 02:51:28,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:28,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:29,052][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.7292417287826538, acc: 0.800000011920929)
[2024-12-14 02:51:29,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:29,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:29,377][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 1.443484902381897, acc: 0.6321839094161987)
[2024-12-14 02:51:29,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:29,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:29,745][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 1.33518385887146, acc: 0.6276595592498779)
[2024-12-14 02:51:29,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:29,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:30,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:30,135][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 1.4636017084121704, acc: 0.5662650465965271)
[2024-12-14 02:51:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:30,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:30,532][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.10152694582939148, acc: 0.95652174949646)
[2024-12-14 02:51:30,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:30,884][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.2604594826698303, acc: 0.9230769276618958)
[2024-12-14 02:51:30,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:30,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:31,240][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 0.985241174697876, acc: 0.6987951993942261)
[2024-12-14 02:51:31,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:31,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:31,594][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.5541720986366272, acc: 0.849056601524353)
[2024-12-14 02:51:31,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:31,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:31,961][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.7626226544380188, acc: 0.797468364238739)
[2024-12-14 02:51:32,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:32,236][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.7150, device='cuda:0') eval_epoch_loss=tensor(1.7431, device='cuda:0') eval_epoch_acc=tensor(0.5936, device='cuda:0')
[2024-12-14 02:51:32,238][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:51:32,238][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:51:32,360][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.3881148397922516, acc: 0.9019607901573181)
[2024-12-14 02:51:32,441][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_8_step_415_loss_1.7430880069732666/model.pt
[2024-12-14 02:51:32,445][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:51:32,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:32,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:32,711][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 1.1444697380065918, acc: 0.611940324306488)
[2024-12-14 02:51:32,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:32,826][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.7486332654953003, acc: 0.7254902124404907)
[2024-12-14 02:51:32,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:33,069][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.1419738531112671, acc: 0.949999988079071)
[2024-12-14 02:51:33,122][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.6280769109725952, acc: 0.8846153616905212)
[2024-12-14 02:51:33,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:33,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:33,441][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.4339991509914398, acc: 0.8799999952316284)
[2024-12-14 02:51:33,494][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.3106752634048462, acc: 0.8888888955116272)
[2024-12-14 02:51:33,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:33,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:33,826][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.2563318610191345, acc: 0.9444444179534912)
[2024-12-14 02:51:33,874][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.47885769605636597, acc: 0.875)
[2024-12-14 02:51:34,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:34,406][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                    [2024-12-14 02:51:34,717][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:51:35,099][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 02:51:35,449][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:51:35,865][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 02:51:36,327][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:51:36,666][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:51:36,987][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:51:37,391][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:51:37,796][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:51:38,199][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:51:38,589][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:51:38,944][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                    [2024-12-14 02:51:39,322][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:51:39,668][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:51:40,121][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                    [2024-12-14 02:51:40,512][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:51:40,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:40,733][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.12714479863643646, acc: 0.9642857313156128)
[2024-12-14 02:51:40,794][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.3817720115184784, acc: 0.8863636255264282)
[2024-12-14 02:51:40,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:40,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:41,027][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.3250364065170288, acc: 0.9375)
[2024-12-14 02:51:41,170][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.020537277683615685, acc: 1.0)
[2024-12-14 02:51:41,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:41,526][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.5707085728645325, acc: 0.8717948794364929)
[2024-12-14 02:51:41,646][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 1.4818005561828613, acc: 0.6000000238418579)
[2024-12-14 02:51:41,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:41,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:42,004][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 1.0021017789840698, acc: 0.7121211886405945)
[2024-12-14 02:51:42,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:42,513][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 1.0197614431381226, acc: 0.7547169923782349)
[2024-12-14 02:51:42,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:42,698][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 1.7034674882888794, acc: 0.5360000133514404)
[2024-12-14 02:51:42,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:42,864][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.7676559686660767, acc: 0.7888888716697693)
[2024-12-14 02:51:43,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:43,123][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 1.5371626615524292, acc: 0.524193525314331)
[2024-12-14 02:51:43,269][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.5954171419143677, acc: 0.8035714030265808)
[2024-12-14 02:51:43,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:43,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:43,640][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.444243460893631, acc: 0.8571428656578064)
[2024-12-14 02:51:43,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:43,776][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 1.5687395334243774, acc: 0.5572139024734497)
[2024-12-14 02:51:43,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:43,932][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.04432053491473198, acc: 1.0)
[2024-12-14 02:51:44,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:44,157][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.6911090016365051, acc: 0.8113207817077637)
[2024-12-14 02:51:44,233][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.020835379138588905, acc: 1.0)
[2024-12-14 02:51:44,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:44,588][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.5496605038642883, acc: 0.8125)
[2024-12-14 02:51:44,598][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.39927902817726135, acc: 0.8863636255264282)
[2024-12-14 02:51:44,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:44,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:44,954][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 1.0125683546066284, acc: 0.7157894968986511)
[2024-12-14 02:51:44,981][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.05568515136837959, acc: 0.95652174949646)
[2024-12-14 02:51:45,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:45,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:45,370][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.18211601674556732, acc: 0.8846153616905212)
[2024-12-14 02:51:45,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:45,525][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 1.2456300258636475, acc: 0.6407185792922974)
[2024-12-14 02:51:45,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:45,751][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.2026420682668686, acc: 0.9642857313156128)
[2024-12-14 02:51:45,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:45,965][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.9322749972343445, acc: 0.7293233275413513)
[2024-12-14 02:51:46,095][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.7243480086326599, acc: 0.8208954930305481)
[2024-12-14 02:51:46,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:46,475][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.7047255039215088, acc: 0.7916666865348816)
[2024-12-14 02:51:46,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:46,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:46,842][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.7936649322509766, acc: 0.72826087474823)
[2024-12-14 02:51:46,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:47,201][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.7619256973266602, acc: 0.7307692170143127)
[2024-12-14 02:51:47,271][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 1.2017611265182495, acc: 0.6470588445663452)
[2024-12-14 02:51:47,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:47,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:47,577][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.7688996195793152, acc: 0.7105262875556946)
[2024-12-14 02:51:47,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:47,872][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.7238363027572632, acc: 0.8108108043670654)
[2024-12-14 02:51:47,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:48,000][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.5547002553939819, acc: 0.8367347121238708)
[2024-12-14 02:51:48,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:48,275][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.15865814685821533, acc: 0.9642857313156128)
[2024-12-14 02:51:48,342][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.1958218216896057, acc: 0.9090909361839294)
[2024-12-14 02:51:48,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:48,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:48,618][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.059729255735874176, acc: 1.0)
[2024-12-14 02:51:48,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:48,735][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 1.365325927734375, acc: 0.5979381203651428)
[2024-12-14 02:51:48,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:48,984][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.16082966327667236, acc: 0.9375)
[2024-12-14 02:51:49,111][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.675229012966156, acc: 0.8142856955528259)
[2024-12-14 02:51:49,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:49,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:49,369][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.07050647586584091, acc: 1.0)
[2024-12-14 02:51:49,490][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 1.3888236284255981, acc: 0.6569767594337463)
[2024-12-14 02:51:49,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:49,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:49,745][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.21407054364681244, acc: 0.9210526347160339)
[2024-12-14 02:51:49,822][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.6482280492782593, acc: 0.8035714030265808)
[2024-12-14 02:51:49,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:49,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:50,095][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.012476381845772266, acc: 1.0)
[2024-12-14 02:51:50,138][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 1.106522798538208, acc: 0.6790123581886292)
[2024-12-14 02:51:50,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:50,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:50,441][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.057646654546260834, acc: 0.949999988079071)
[2024-12-14 02:51:50,503][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.25037336349487305, acc: 0.9722222089767456)
[2024-12-14 02:51:50,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:50,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:50,789][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.10874021798372269, acc: 0.9523809552192688)
[2024-12-14 02:51:50,843][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.108120396733284, acc: 0.96875)
[2024-12-14 02:51:50,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:50,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:51,083][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.805831253528595, acc: 0.7592592835426331)
[2024-12-14 02:51:51,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:51,201][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.08658719807863235, acc: 1.0)
[2024-12-14 02:51:51,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:51,421][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 1.4943981170654297, acc: 0.582524299621582)
[2024-12-14 02:51:51,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:51,598][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.3276618421077728, acc: 0.9347826242446899)
[2024-12-14 02:51:51,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:51,949][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 1.4821397066116333, acc: 0.6176470518112183)
[2024-12-14 02:51:51,991][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.7618548274040222, acc: 0.7142857313156128)
[2024-12-14 02:51:52,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:52,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:52,330][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 1.6491107940673828, acc: 0.5266666412353516)
[2024-12-14 02:51:52,392][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.8541162610054016, acc: 0.7951807379722595)
[2024-12-14 02:51:52,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:52,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:52,748][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 1.5954910516738892, acc: 0.5347222089767456)
[2024-12-14 02:51:52,795][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.7686861753463745, acc: 0.7657657861709595)
[2024-12-14 02:51:52,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:53,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:53,098][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.3452151417732239, acc: 0.930232584476471)
[2024-12-14 02:51:53,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:53,214][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 0.8785728812217712, acc: 0.7475728392601013)
[2024-12-14 02:51:53,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:53,483][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.3042651116847992, acc: 0.9166666865348816)
[2024-12-14 02:51:53,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:53,601][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.8833169937133789, acc: 0.7317073345184326)
[2024-12-14 02:51:53,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:53,830][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.47912663221359253, acc: 0.9069767594337463)
[2024-12-14 02:51:53,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:54,002][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.21976058185100555, acc: 0.9166666865348816)
[2024-12-14 02:51:54,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:54,121][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.12527689337730408, acc: 0.9599999785423279)
[2024-12-14 02:51:54,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:54,371][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.28989729285240173, acc: 0.9285714030265808)
[2024-12-14 02:51:54,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:54,665][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.7677223682403564, acc: 0.7647058963775635)
[2024-12-14 02:51:54,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:54,802][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 1.2436586618423462, acc: 0.6274510025978088)
[2024-12-14 02:51:54,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:55,065][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.8226004242897034, acc: 0.7333333492279053)
[2024-12-14 02:51:55,210][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 1.7015856504440308, acc: 0.5633187890052795)
[2024-12-14 02:51:55,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:55,314][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:51:55,466][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.42635810375213623, acc: 0.939393937587738)
[2024-12-14 02:51:55,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:55,604][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 0.8926272988319397, acc: 0.75)
[2024-12-14 02:51:55,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:55,868][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.3676152229309082, acc: 0.9090909361839294)
[2024-12-14 02:51:55,994][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 1.2877895832061768, acc: 0.6134969592094421)
[2024-12-14 02:51:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:56,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:56,253][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.027819309383630753, acc: 1.0)
[2024-12-14 02:51:56,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:56,687][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.3211384415626526, acc: 0.8717948794364929)
2024-12-14 02:51:56,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:56,603][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.22673660516738892, acc: 0.9259259104728699)
[2024-12-14 02:51:56,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:56,733][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 1.7253285646438599, acc: 0.5276381969451904)
[2024-12-14 02:51:56,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:56,926][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.11735031008720398, acc: 0.9200000166893005)
[2024-12-14 02:51:57,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:57,107][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.16711370646953583, acc: 0.9444444179534912)
[2024-12-14 02:51:57,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:57,286][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.3178032636642456, acc: 0.9166666865348816)
[2024-12-14 02:51:57,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:57,500][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.3613077402114868, acc: 0.8181818127632141)
[2024-12-14 02:51:57,621][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.2713695764541626, acc: 0.8888888955116272)
[2024-12-14 02:51:57,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:57,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:57,833][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.3191582262516022, acc: 0.9259259104728699)
[2024-12-14 02:51:57,972][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.14412972331047058, acc: 0.9615384340286255)
[2024-12-14 02:51:57,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:58,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:58,242][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.04069153964519501, acc: 1.0)
[2024-12-14 02:51:58,345][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.6175623536109924, acc: 0.8793103694915771)
[2024-12-14 02:51:58,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:58,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:58,586][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.12186626344919205, acc: 0.949999988079071)
[2024-12-14 02:51:58,697][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.2379704713821411, acc: 0.8571428656578064)
[2024-12-14 02:51:58,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:58,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:58,996][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.5287761688232422, acc: 0.8103448152542114)
[2024-12-14 02:51:59,068][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.10582266747951508, acc: 0.9333333373069763)
[2024-12-14 02:51:59,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:59,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:59,379][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.12626111507415771, acc: 0.9677419066429138)
[2024-12-14 02:51:59,436][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.17146413028240204, acc: 0.9696969985961914)
[2024-12-14 02:51:59,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:59,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:51:59,728][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.16457851231098175, acc: 0.9473684430122375)
[2024-12-14 02:51:59,820][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.25742262601852417, acc: 0.9090909361839294)
[2024-12-14 02:52:00,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:00,376][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.9155778884887695, acc: 0.7179487347602844)
[2024-12-14 02:52:00,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:00,708][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 1.7235910892486572, acc: 0.5)
[2024-12-14 02:52:00,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:01,042][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 1.6795302629470825, acc: 0.48427674174308777)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:52:01,438][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=2.0642, train_epoch_loss=0.7247, epoch time 360.76128966733813s
[2024-12-14 02:52:01,439][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:52:01,439][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:52:01,439][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:52:01,439][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 23
[2024-12-14 02:52:01,439][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 02:52:01,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:02,289][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.21807177364826202, acc: 0.9629629850387573)
                                                                                [2024-12-14 02:52:02,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:02,639][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.7437713742256165, acc: 0.7599999904632568)
                                                                               [2024-12-14 02:52:02,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:02,991][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.6005931496620178, acc: 0.8108108043670654)
                                                                                 [2024-12-14 02:52:03,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:03,342][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.3175668716430664, acc: 0.8684210777282715)
                                                                                 [2024-12-14 02:52:03,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:03,711][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.6726781725883484, acc: 0.7837837934494019)
[2024-12-14 02:52:03,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:04,061][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.48070797324180603, acc: 0.8214285969734192)
                       [2024-12-14 02:52:04,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:04,397][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.6411012411117554, acc: 0.795918345451355)
                                                                                  [2024-12-14 02:52:04,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:04,705][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.33902671933174133, acc: 0.9333333373069763)
 [2024-12-14 02:52:04,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:05,074][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.011608383618295193, acc: 1.0)
                                                                                              [2024-12-14 02:52:05,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:05,211][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 1.1782846450805664, acc: 0.6195651888847351)
[2024-12-14 02:52:05,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:05,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:05,551][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.042535457760095596, acc: 1.0)
[2024-12-14 02:52:05,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:05,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:05,914][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.23261664807796478, acc: 0.8461538553237915)
[2024-12-14 02:52:06,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:06,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:06,271][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.14361746609210968, acc: 0.9259259104728699)
[2024-12-14 02:52:06,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:06,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:06,646][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.28017139434814453, acc: 0.8518518805503845)
[2024-12-14 02:52:06,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:06,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:07,065][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.6191298365592957, acc: 0.8679245114326477)
[2024-12-14 02:52:07,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:07,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:07,471][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.4432699978351593, acc: 0.8275862336158752)
[2024-12-14 02:52:07,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:07,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:08,057][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 1.3697365522384644, acc: 0.6036036014556885)
[2024-12-14 02:52:08,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:08,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:08,500][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 1.006009578704834, acc: 0.7042253613471985)
[2024-12-14 02:52:08,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:08,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:08,809][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.188981831073761, acc: 0.8999999761581421)
[2024-12-14 02:52:08,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:09,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:09,175][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.2835262417793274, acc: 0.8999999761581421)
[2024-12-14 02:52:09,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:09,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:09,554][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.2251610904932022, acc: 0.9230769276618958)
[2024-12-14 02:52:09,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:10,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:10,468][slam_llm.models.slam_model][INFO] - modality encoder
                                    [2024-12-14 02:52:10,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:10,811][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:52:11,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:11,010][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.39569878578186035, acc: 0.875)
[2024-12-14 02:52:11,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:11,377][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.5329240560531616, acc: 0.849056601524353)
[2024-12-14 02:52:11,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:11,750][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 1.2156301736831665, acc: 0.6575342416763306)
[2024-12-14 02:52:12,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:13,026][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 1.8190218210220337, acc: 0.5256916880607605)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:52:13,096][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:52:13,335][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.4038273096084595, acc: 0.8604651093482971)
                      [2024-12-14 02:52:13,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:13,678][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.8972905278205872, acc: 0.7349397540092468)
                                                                                [2024-12-14 02:52:13,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:14,078][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 1.0949087142944336, acc: 0.6296296119689941)
[2024-12-14 02:52:14,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:14,436][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.16594184935092926, acc: 0.9285714030265808)
[2024-12-14 02:52:14,557][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                 [2024-12-14 02:52:14,830][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.278881698846817, acc: 0.8888888955116272)
                       [2024-12-14 02:52:14,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:15,229][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.029927877709269524, acc: 1.0)
                                                                               [2024-12-14 02:52:15,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:15,639][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 1.4513437747955322, acc: 0.5798319578170776)
                                                                  [2024-12-14 02:52:15,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:15,960][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.6314857006072998, acc: 0.8196721076965332)
                                                                                [2024-12-14 02:52:16,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:16,293][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.7367056012153625, acc: 0.7777777910232544)
[2024-12-14 02:52:16,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:16,666][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.7352151274681091, acc: 0.7118644118309021)
[2024-12-14 02:52:16,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:17,090][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.8147966861724854, acc: 0.7356321811676025)
[2024-12-14 02:52:17,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:17,451][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.267816960811615, acc: 0.9047619104385376)
                                                                                [2024-12-14 02:52:17,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:17,759][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.2263554483652115, acc: 0.9230769276618958)
[2024-12-14 02:52:17,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:18,136][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 0.7229795455932617, acc: 0.7567567825317383)
                     [2024-12-14 02:52:18,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:18,495][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.9314645528793335, acc: 0.7230769395828247)
 [2024-12-14 02:52:18,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:18,921][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 1.0843549966812134, acc: 0.6464646458625793)
                                                                                                                                                               [2024-12-14 02:52:19,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:19,350][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 1.0464661121368408, acc: 0.6701030731201172)
 [2024-12-14 02:52:19,479][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:52:19,765][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 1.2165285348892212, acc: 0.6397058963775635)
[2024-12-14 02:52:19,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:20,080][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.3870154619216919, acc: 0.8846153616905212)
                       [2024-12-14 02:52:20,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:20,386][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.028124414384365082, acc: 1.0)
                                                                                             [2024-12-14 02:52:20,470][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:52:20,697][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.3286793529987335, acc: 0.8928571343421936)
[2024-12-14 02:52:20,798][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:52:21,088][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.2586424946784973, acc: 0.9166666865348816)
[2024-12-14 02:52:21,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:21,488][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.6393694281578064, acc: 0.859649121761322)
                                                                                                                                                                                                                                 [2024-12-14 02:52:21,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:21,804][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.7148792147636414, acc: 0.8095238208770752)
[2024-12-14 02:52:21,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:22,139][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.6945863962173462, acc: 0.7183098793029785)
[2024-12-14 02:52:22,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:22,581][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 1.5909217596054077, acc: 0.5400000214576721)
           [2024-12-14 02:52:22,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:22,947][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.3545333743095398, acc: 0.8648648858070374)
                                                                               [2024-12-14 02:52:23,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:23,356][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.10543958097696304, acc: 1.0)
                                                                                                                                                                 [2024-12-14 02:52:24,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:26,344][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.6130295991897583, acc: 0.6040955781936646)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:52:26,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:27,619][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 2.203448534011841, acc: 0.4596949815750122)
8/10, step 548/574 completed (loss: 0.1480071246623993, acc: 0.9354838728904724)
[2024-12-14 02:52:26,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:26,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:26,993][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.04904864355921745, acc: 0.9599999785423279)
[2024-12-14 02:52:27,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:27,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:27,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:27,347][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.15490220487117767, acc: 0.939393937587738)
[2024-12-14 02:52:27,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:27,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:27,741][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.18931347131729126, acc: 0.949999988079071)
[2024-12-14 02:52:27,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:27,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:28,117][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.3811793327331543, acc: 0.8714285492897034)
[2024-12-14 02:52:28,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:28,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:28,487][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 1.2441368103027344, acc: 0.6423357725143433)
[2024-12-14 02:52:28,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:28,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:28,883][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 1.0489674806594849, acc: 0.6620689630508423)
[2024-12-14 02:52:28,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:28,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:29,254][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 1.4455331563949585, acc: 0.6285714507102966)
[2024-12-14 02:52:29,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:29,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:29,600][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 1.3029223680496216, acc: 0.5827814340591431)
[2024-12-14 02:52:29,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:29,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:29,917][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.8001921772956848, acc: 0.7777777910232544)
[2024-12-14 02:52:29,963][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                      [2024-12-14 02:52:30,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:30,588][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7632, device='cuda:0') eval_epoch_loss=tensor(1.9115, device='cuda:0') eval_epoch_acc=tensor(0.5820, device='cuda:0')
[2024-12-14 02:52:30,589][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:52:30,590][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:52:30,793][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_8_step_415_loss_1.911501169204712/model.pt
[2024-12-14 02:52:30,803][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:52:30,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:30,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:31,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:31,328][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.6754813194274902, acc: 0.8235294222831726)
[2024-12-14 02:52:31,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:31,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:31,670][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.1434626281261444, acc: 0.9230769276618958)
[2024-12-14 02:52:31,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:31,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:32,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:32,414][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.07508251070976257, acc: 1.0)
[2024-12-14 02:52:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:32,802][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.24565458297729492, acc: 0.9166666865348816)
                                                                                                                                                                                                                                                                                         [2024-12-14 02:52:32,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:33,185][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.24624058604240417, acc: 0.9090909361839294)
                                                                                [2024-12-14 02:52:33,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:33,571][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 1.2810635566711426, acc: 0.6176470518112183)
                                                                               [2024-12-14 02:52:33,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:33,936][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 1.3873125314712524, acc: 0.5873016119003296)
                                                                                                                                                    [2024-12-14 02:52:34,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:34,318][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 1.7188156843185425, acc: 0.5384615659713745)
                                                                                 [2024-12-14 02:52:34,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:34,704][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 0.9581009149551392, acc: 0.7142857313156128)
                                                                                 [2024-12-14 02:52:34,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:35,087][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 1.6778297424316406, acc: 0.5074626803398132)
                                                                               [2024-12-14 02:52:35,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:35,488][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 1.9150390625, acc: 0.4781021773815155)
                                                                                                                                                                    [2024-12-14 02:52:35,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:35,856][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.029776666313409805, acc: 1.0)
                                                                                             [2024-12-14 02:52:35,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:36,202][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.1302778422832489, acc: 0.9583333134651184)
                                                                                                                                                                                                                        [2024-12-14 02:52:36,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:36,564][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.1453627198934555, acc: 0.9696969985961914)
                                                                  [2024-12-14 02:52:36,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:36,918][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.06960971653461456, acc: 1.0)
ining Epoch: 8/10, step 431/574 completed (loss: 0.02444065921008587, acc: 1.0)
[2024-12-14 02:52:36,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:37,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:37,244][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.17179282009601593, acc: 0.9130434989929199)
[2024-12-14 02:52:37,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:37,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:37,670][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.32665902376174927, acc: 0.8888888955116272)
[2024-12-14 02:52:37,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:37,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:38,008][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.21042437851428986, acc: 0.9200000166893005)
[2024-12-14 02:52:38,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:38,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:38,329][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.321168452501297, acc: 0.8484848737716675)
[2024-12-14 02:52:38,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:38,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:38,687][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.4707031846046448, acc: 0.8888888955116272)
[2024-12-14 02:52:38,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:38,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:39,046][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.43037983775138855, acc: 0.8863636255264282)
[2024-12-14 02:52:39,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:39,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:39,445][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.07210184633731842, acc: 0.9523809552192688)
[2024-12-14 02:52:39,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:39,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:39,822][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.615778386592865, acc: 0.8461538553237915)
[2024-12-14 02:52:39,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:39,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:40,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:40,284][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 0.9823057055473328, acc: 0.7878788113594055)
[2024-12-14 02:52:40,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:40,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:40,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:40,964][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 1.7600913047790527, acc: 0.4880000054836273)
[2024-12-14 02:52:41,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:41,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:41,388][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 1.4674068689346313, acc: 0.5725806355476379)
[2024-12-14 02:52:41,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:41,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:42,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:42,684][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 1.465505838394165, acc: 0.6293103694915771)
)
[2024-12-14 02:52:42,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:42,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:42,407][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.5626612901687622, acc: 0.7924528121948242)
[2024-12-14 02:52:42,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:42,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:42,822][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.3168226480484009, acc: 0.9090909361839294)
[2024-12-14 02:52:42,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:42,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:43,162][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.17992450296878815, acc: 0.95652174949646)
[2024-12-14 02:52:43,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:43,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:43,501][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.4085225760936737, acc: 0.807692289352417)
[2024-12-14 02:52:43,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:43,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:43,862][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.22611916065216064, acc: 0.9642857313156128)
[2024-12-14 02:52:43,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:43,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:44,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:44,250][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.6159192323684692, acc: 0.8059701323509216)
[2024-12-14 02:52:44,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:44,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:44,657][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.6268513202667236, acc: 0.8055555820465088)
[2024-12-14 02:52:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:44,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:45,040][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.6935590505599976, acc: 0.79347825050354)
[2024-12-14 02:52:45,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:45,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:45,432][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.8139712810516357, acc: 0.7564102411270142)
[2024-12-14 02:52:45,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:45,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:45,742][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.5904120206832886, acc: 0.7894737124443054)
[2024-12-14 02:52:45,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:45,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:46,115][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.5070720314979553, acc: 0.8571428656578064)
[2024-12-14 02:52:46,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:46,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:46,485][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.1132187470793724, acc: 0.9696969985961914)
[2024-12-14 02:52:46,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:46,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:46,847][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 1.2876826524734497, acc: 0.6494845151901245)
[2024-12-14 02:52:47,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:47,285][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.04753899201750755, acc: 1.0)
ning Epoch: 8/10, step 457/574 completed (loss: 0.6005221605300903, acc: 0.8142856955528259)
[2024-12-14 02:52:47,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:47,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:47,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:47,529][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 1.3952211141586304, acc: 0.6337209343910217)
[2024-12-14 02:52:47,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:47,823][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.6196622252464294, acc: 0.7857142686843872)
[2024-12-14 02:52:47,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:47,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:48,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:48,134][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 1.1047381162643433, acc: 0.6913580298423767)
[2024-12-14 02:52:48,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:48,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:48,472][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.30714675784111023, acc: 0.8888888955116272)
[2024-12-14 02:52:48,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:48,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:48,794][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.12691350281238556, acc: 1.0)
[2024-12-14 02:52:48,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:49,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:49,162][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.20349082350730896, acc: 0.9615384340286255)
[2024-12-14 02:52:49,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:49,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:49,544][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.32762202620506287, acc: 0.8913043737411499)
[2024-12-14 02:52:49,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:49,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:49,977][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.8167187571525574, acc: 0.7142857313156128)
[2024-12-14 02:52:50,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:50,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:50,391][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 1.0004186630249023, acc: 0.7469879388809204)
[2024-12-14 02:52:50,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:50,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:50,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:50,796][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.9581860899925232, acc: 0.7387387156486511)
[2024-12-14 02:52:50,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:51,135][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 0.9847111105918884, acc: 0.737864077091217)
[2024-12-14 02:52:51,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:51,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:51,511][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.9678017497062683, acc: 0.7154471278190613)
[2024-12-14 02:52:51,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:51,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:51,856][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.09858465194702148, acc: 1.0)
[2024-12-14 02:52:51,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:52,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:52,567][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.028729891404509544, acc: 1.0)
714030265808)
[2024-12-14 02:52:52,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:52,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:52,632][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 1.3721843957901, acc: 0.6176470518112183)
[2024-12-14 02:52:52,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:52,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:53,020][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 1.7408616542816162, acc: 0.4803493320941925)
[2024-12-14 02:52:53,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:53,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:53,408][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 1.099009394645691, acc: 0.6770833134651184)
[2024-12-14 02:52:53,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:53,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:53,826][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 1.373386263847351, acc: 0.6012269854545593)
[2024-12-14 02:52:53,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:53,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:54,166][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 1.357587456703186, acc: 0.633093535900116)
[2024-12-14 02:52:54,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:54,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:54,541][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 1.6533154249191284, acc: 0.5226130485534668)
[2024-12-14 02:52:54,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:54,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:54,891][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.3665449023246765, acc: 0.9166666865348816)
[2024-12-14 02:52:54,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:54,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:55,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:55,219][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.19577765464782715, acc: 0.939393937587738)
[2024-12-14 02:52:55,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:55,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:55,577][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.5998238325119019, acc: 0.8518518805503845)
[2024-12-14 02:52:55,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:55,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:55,927][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.3006058633327484, acc: 0.8500000238418579)
[2024-12-14 02:52:56,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:56,284][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.15438959002494812, acc: 0.949999988079071)
[2024-12-14 02:52:56,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:56,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:56,673][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.44301286339759827, acc: 0.8793103694915771)
[2024-12-14 02:52:56,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:56,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:57,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:57,417][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 1.157607913017273, acc: 0.6666666865348816)
)
[2024-12-14 02:52:57,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:57,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:57,383][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.2377985417842865, acc: 0.8947368264198303)
[2024-12-14 02:52:57,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:57,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:57,708][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.4707326889038086, acc: 0.8518518805503845)
[2024-12-14 02:52:57,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:57,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:58,076][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.7134885787963867, acc: 0.8571428656578064)
[2024-12-14 02:52:58,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:58,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:58,447][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.5406082272529602, acc: 0.8181818127632141)
[2024-12-14 02:52:58,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:58,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:58,802][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.7006239295005798, acc: 0.8153846263885498)
[2024-12-14 02:52:58,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:59,155][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.33121469616889954, acc: 0.9333333373069763)
[2024-12-14 02:52:59,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:59,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:59,507][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.15670764446258545, acc: 0.9655172228813171)
[2024-12-14 02:52:59,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:52:59,819][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.9147, device='cuda:0') eval_epoch_loss=tensor(1.9337, device='cuda:0') eval_epoch_acc=tensor(0.5934, device='cuda:0')
[2024-12-14 02:52:59,820][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:52:59,820][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:52:59,838][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.631048321723938, acc: 0.843137264251709)
[2024-12-14 02:52:59,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:00,030][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_8_step_558_loss_1.9336504936218262/model.pt
[2024-12-14 02:53:00,033][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:53:00,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:00,167][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.29806652665138245, acc: 0.931034505367279)
[2024-12-14 02:53:00,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:00,421][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.10214313864707947, acc: 0.9599999785423279)
[2024-12-14 02:53:00,512][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.11984199285507202, acc: 0.9473684430122375)
[2024-12-14 02:53:00,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:00,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:00,770][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.09308676421642303, acc: 0.9615384340286255)
[2024-12-14 02:53:00,862][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.26426684856414795, acc: 0.8947368264198303)
[2024-12-14 02:53:00,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:01,298][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:53:01,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:02,013][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:53:02,472][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:53:02,951][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:53:03,335][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:53:03,690][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:53:04,137][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:53:04,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:04,360][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 1.3702950477600098, acc: 0.6363636255264282)
[2024-12-14 02:53:04,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:04,578][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.5062822103500366, acc: 0.8301886916160583)
[2024-12-14 02:53:04,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:04,710][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.4474455416202545, acc: 0.8709677457809448)
[2024-12-14 02:53:04,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:04,960][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.32631605863571167, acc: 0.8275862336158752)
[2024-12-14 02:53:05,093][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.7708139419555664, acc: 0.7777777910232544)
[2024-12-14 02:53:05,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:05,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:05,428][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 1.5551460981369019, acc: 0.581632673740387)
[2024-12-14 02:53:05,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:05,599][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 1.1798804998397827, acc: 0.6036036014556885)
[2024-12-14 02:53:05,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:05,765][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 1.5205354690551758, acc: 0.5786163806915283)
[2024-12-14 02:53:06,043][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 0.8461011648178101, acc: 0.7746478915214539)
[2024-12-14 02:53:06,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:06,229][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=1.9806, train_epoch_loss=0.6834, epoch time 360.95882473513484s
[2024-12-14 02:53:06,229][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:53:06,229][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 02:53:06,229][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:53:06,230][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 23
[2024-12-14 02:53:06,230][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 02:53:06,403][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.05138571187853813, acc: 1.0)
[2024-12-14 02:53:06,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:06,782][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.3671254515647888, acc: 0.9333333373069763)
[2024-12-14 02:53:06,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:07,113][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.22176861763000488, acc: 0.9615384340286255)
[2024-12-14 02:53:07,162][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.11102310568094254, acc: 0.9259259104728699)
[2024-12-14 02:53:07,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:07,526][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.08638396114110947, acc: 0.9599999785423279)
[2024-12-14 02:53:07,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:07,851][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.506140947341919, acc: 0.837837815284729)
[2024-12-14 02:53:07,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:08,234][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.572558581829071, acc: 0.8421052694320679)
[2024-12-14 02:53:08,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:08,589][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.3479224741458893, acc: 0.9189189076423645)
[2024-12-14 02:53:08,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:09,182][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:53:09,516][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:53:09,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:10,127][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                  [2024-12-14 02:53:10,576][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                       [2024-12-14 02:53:10,886][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:53:11,168][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:53:11,536][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                 [2024-12-14 02:53:11,957][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:53:12,295][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:53:12,651][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:53:12,980][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:53:13,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:13,280][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.18800954520702362, acc: 0.9583333134651184)
[2024-12-14 02:53:13,309][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.07978251576423645, acc: 1.0)
[2024-12-14 02:53:13,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:13,570][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.2873665690422058, acc: 0.8888888955116272)
[2024-12-14 02:53:13,637][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.5956189632415771, acc: 0.8611111044883728)
[2024-12-14 02:53:13,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:14,006][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.031123105436563492, acc: 1.0)
[2024-12-14 02:53:14,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:14,366][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.12661637365818024, acc: 0.9615384340286255)
[2024-12-14 02:53:14,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:14,564][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 1.8045634031295776, acc: 0.5381355881690979)
[2024-12-14 02:53:14,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:14,732][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.4307754635810852, acc: 0.8620689511299133)
[2024-12-14 02:53:14,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:14,972][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 1.1662602424621582, acc: 0.6641790866851807)
[2024-12-14 02:53:15,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:15,087][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.17111316323280334, acc: 0.9200000166893005)
[2024-12-14 02:53:15,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:15,350][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 1.3687949180603027, acc: 0.5985401272773743)
[2024-12-14 02:53:15,410][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.05382990837097168, acc: 1.0)
[2024-12-14 02:53:15,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:15,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:15,706][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.1128397136926651, acc: 1.0)
[2024-12-14 02:53:15,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:15,917][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 1.5253509283065796, acc: 0.5950000286102295)
[2024-12-14 02:53:16,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:16,107][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.6136884689331055, acc: 0.8113207817077637)
[2024-12-14 02:53:16,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:16,287][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.7654158473014832, acc: 0.7777777910232544)
[2024-12-14 02:53:16,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:16,514][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.8346526026725769, acc: 0.7534246444702148)
[2024-12-14 02:53:16,630][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.429512083530426, acc: 0.8461538553237915)
[2024-12-14 02:53:17,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:16,964][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.4596060812473297, acc: 0.8571428656578064)
[2024-12-14 02:53:17,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:17,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:17,291][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 0.8361513614654541, acc: 0.7540983557701111)
[2024-12-14 02:53:17,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:17,583][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.3726344108581543, acc: 0.9152542352676392)
[2024-12-14 02:53:17,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:17,751][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 1.900726079940796, acc: 0.47035571932792664)
[2024-12-14 02:53:17,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:17,893][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 0.7077193260192871, acc: 0.7674418687820435)
[2024-12-14 02:53:18,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:18,100][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.47731417417526245, acc: 0.8837209343910217)
[2024-12-14 02:53:18,232][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.5973499417304993, acc: 0.8409090638160706)
[2024-12-14 02:53:18,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:18,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:18,518][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.7909988760948181, acc: 0.7951807379722595)
[2024-12-14 02:53:18,552][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.6124915480613708, acc: 0.7547169923782349)
[2024-12-14 02:53:18,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:18,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:18,908][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.45804110169410706, acc: 0.8636363744735718)
[2024-12-14 02:53:18,920][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.8735543489456177, acc: 0.7530864477157593)
[2024-12-14 02:53:19,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:19,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:19,189][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.2764958441257477, acc: 0.8799999952316284)
[2024-12-14 02:53:19,264][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.2461121529340744, acc: 0.9285714030265808)
[2024-12-14 02:53:19,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:19,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:19,540][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.11365680396556854, acc: 0.949999988079071)
[2024-12-14 02:53:19,627][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.39047694206237793, acc: 0.8518518805503845)
[2024-12-14 02:53:19,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:19,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:19,822][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.08127482235431671, acc: 1.0)
[2024-12-14 02:53:19,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:20,033][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.04960843175649643, acc: 1.0)
[2024-12-14 02:53:20,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:20,191][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.7092480659484863, acc: 0.7538461685180664)
[2024-12-14 02:53:20,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:20,400][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 1.2205113172531128, acc: 0.6470588445663452)
[2024-12-14 02:53:20,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:20,498][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.7756546139717102, acc: 0.796875)
[2024-12-14 02:53:20,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:20,720][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.4790157973766327, acc: 0.8360655903816223)
[2024-12-14 02:53:20,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:20,867][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.3731648921966553, acc: 0.84375)
[2024-12-14 02:53:20,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:21,066][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.6463733911514282, acc: 0.8095238208770752)
[2024-12-14 02:53:21,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:21,222][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.6885530352592468, acc: 0.7878788113594055)
[2024-12-14 02:53:21,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:21,397][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.590595543384552, acc: 0.7457627058029175)
[2024-12-14 02:53:21,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:21,592][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.06477272510528564, acc: 1.0)
[2024-12-14 02:53:21,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:21,771][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.789817750453949, acc: 0.7816091775894165)
[2024-12-14 02:53:21,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:21,959][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.1261293888092041, acc: 1.0)
[2024-12-14 02:53:22,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:22,172][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.060935359448194504, acc: 1.0)
[2024-12-14 02:53:22,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:22,299][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.07620720565319061, acc: 0.95652174949646)
[2024-12-14 02:53:22,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:22,558][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.1691109836101532, acc: 0.9615384340286255)
[2024-12-14 02:53:22,638][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.272605299949646, acc: 0.8999999761581421)
[2024-12-14 02:53:22,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:22,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:22,964][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 0.8043525815010071, acc: 0.7972972989082336)
[2024-12-14 02:53:23,017][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.4159303605556488, acc: 0.8780487775802612)
[2024-12-14 02:53:23,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:23,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:23,319][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.6598936319351196, acc: 0.8461538553237915)
[2024-12-14 02:53:23,405][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.15201528370380402, acc: 0.9428571462631226)
[2024-12-14 02:53:23,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:23,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:23,731][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 1.0401514768600464, acc: 0.7070707082748413)
[2024-12-14 02:53:23,779][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.3280785083770752, acc: 0.9210526347160339)
[2024-12-14 02:53:23,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:23,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:24,134][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.15015210211277008, acc: 0.9677419066429138)
[2024-12-14 02:53:24,157][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 0.7522655129432678, acc: 0.7731958627700806)
[2024-12-14 02:53:24,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:24,593][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:53:24,995][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:53:25,272][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:53:25,610][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:53:25,889][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:53:26,142][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:53:26,465][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:53:26,792][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 02:53:27,218][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:53:27,501][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                [2024-12-14 02:53:27,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:28,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:28,687][slam_llm.models.slam_model][INFO] - modality encoder
090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:28,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:28,380][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.09632889181375504, acc: 0.9615384340286255)
[2024-12-14 02:53:28,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:28,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:29,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:29,472][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 02:53:29,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:29,947][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:53:30,372][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:53:30,723][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:53:31,133][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:53:31,436][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.587340235710144, acc: 0.5699658989906311)
                                                                              [2024-12-14 02:53:31,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:31,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:31,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:32,184][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                          [2024-12-14 02:53:32,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:32,607][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 2.173834800720215, acc: 0.43790850043296814)
 [2024-12-14 02:53:32,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:32,860][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:53:33,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:33,243][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 1.4627918004989624, acc: 0.6022727489471436)
[2024-12-14 02:53:33,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:33,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:33,817][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 1.2744147777557373, acc: 0.6323529481887817)
[2024-12-14 02:53:33,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:34,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:34,376][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 1.4690124988555908, acc: 0.5579710006713867)
leted (loss: 0.3944064676761627, acc: 0.9047619104385376)
[2024-12-14 02:53:34,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:34,577][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.35108059644699097, acc: 0.8846153616905212)
                    [2024-12-14 02:53:34,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:34,890][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.36861905455589294, acc: 0.8709677457809448)
[2024-12-14 02:53:34,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:35,225][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.48766109347343445, acc: 0.8648648858070374)
                                                                           [2024-12-14 02:53:35,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:35,761][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 1.248557209968567, acc: 0.6228070259094238)
                                                                                                                                                               [2024-12-14 02:53:35,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:36,158][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 1.104364275932312, acc: 0.6791045069694519)
                                                                    [2024-12-14 02:53:36,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:36,579][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 1.2385272979736328, acc: 0.6020408272743225)
                                                                              [2024-12-14 02:53:36,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:37,018][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 1.2512112855911255, acc: 0.563829779624939)
                                                                                                                                                [2024-12-14 02:53:37,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:37,329][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.7842470407485962, acc: 0.8142856955528259)
[2024-12-14 02:53:37,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:37,685][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.5892601013183594, acc: 0.7857142686843872)
                                                                                                                                                                                                                                                                                       [2024-12-14 02:53:37,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:38,051][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.39004021883010864, acc: 0.9130434989929199)
[2024-12-14 02:53:38,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:38,418][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.07861785590648651, acc: 0.9655172228813171)
                   [2024-12-14 02:53:38,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:38,806][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.3932008445262909, acc: 0.8695651888847351)
                                                                              [2024-12-14 02:53:38,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:39,171][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 0.6007680892944336, acc: 0.8135592937469482)
                                                                                                                                                                                                                      [2024-12-14 02:53:39,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:39,533][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.6822560429573059, acc: 0.7719298005104065)
                                                                             [2024-12-14 02:53:39,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:39,887][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.9841700196266174, acc: 0.6216216087341309)
                                                                                                                                                             [2024-12-14 02:53:40,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:40,253][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.35005125403404236, acc: 0.8571428656578064)
                                                              [2024-12-14 02:53:40,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:40,608][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.7236177325248718, acc: 0.8695651888847351)
                                                                [2024-12-14 02:53:40,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:41,026][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.35458722710609436, acc: 0.8947368264198303)
                                                               [2024-12-14 02:53:41,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:42,742][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.6787011027336121, acc: 0.7837837934494019)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:53:42,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:43,040][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 0.7902072072029114, acc: 0.7037037014961243)
[2024-12-14 02:53:43,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:43,440][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 0.6863078474998474, acc: 0.8139534592628479)
                                                                                                                                                             [2024-12-14 02:53:43,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:44,044][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.5819728970527649, acc: 0.8117647171020508)
                                                                                                                                               [2024-12-14 02:53:44,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:44,599][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 1.2371528148651123, acc: 0.6404494643211365)
024-12-14 02:53:44,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:44,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:44,492][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.9449530839920044, acc: 0.6699029207229614)
[2024-12-14 02:53:44,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:44,863][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:53:45,150][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:53:45,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:45,593][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 1.4434926509857178, acc: 0.6310679316520691)
[2024-12-14 02:53:45,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:45,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:46,121][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:53:46,421][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 1.4543284177780151, acc: 0.5806451439857483)
[2024-12-14 02:53:46,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:46,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:46,854][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:53:47,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:47,231][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 1.5039342641830444, acc: 0.5991379022598267)
 [2024-12-14 02:53:47,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:47,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:47,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:47,974][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.7531206011772156, acc: 0.7368420958518982)
[2024-12-14 02:53:48,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:48,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:48,504][slam_llm.models.slam_model][INFO] - modality encoder
                                              [2024-12-14 02:53:48,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:48,968][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 1.1329654455184937, acc: 0.6435643434524536)
 [2024-12-14 02:53:49,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:49,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:49,328][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.8438369035720825, acc: 0.774193525314331)
[2024-12-14 02:53:49,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:49,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:49,701][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.8118487000465393, acc: 0.739130437374115)
[2024-12-14 02:53:49,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:50,050][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 1.330918312072754, acc: 0.5966386795043945)
[2024-12-14 02:53:50,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:50,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:50,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:50,411][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 1.1095974445343018, acc: 0.6634615659713745)
[2024-12-14 02:53:50,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:50,763][slam_llm.models.slam_model][INFO[2024-12-14 02:53:50,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:51,512][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 1.6540274620056m_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:51,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:51,141][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.5815034508705139, acc: 0.8507462739944458)
[2024-12-14 02:53:51,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:51,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:51,500][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.06020183488726616, acc: 1.0)
[2024-12-14 02:53:51,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:51,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:51,853][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.14407116174697876, acc: 0.9545454382896423)
[2024-12-14 02:53:51,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:52,189][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.017913734540343285, acc: 1.0)
[2024-12-14 02:53:52,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:52,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:52,578][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.1442723423242569, acc: 0.9545454382896423)
[2024-12-14 02:53:52,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:52,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:52,934][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.640083909034729, acc: 0.8103448152542114)
[2024-12-14 02:53:53,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:53,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:53,307][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.18818189203739166, acc: 0.9534883499145508)
[2024-12-14 02:53:53,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:53,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:53,651][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.10497565567493439, acc: 0.9599999785423279)
[2024-12-14 02:53:53,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:53,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:53,996][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.00809329655021429, acc: 1.0)
[2024-12-14 02:53:54,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:54,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:54,369][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.004415083210915327, acc: 1.0)
[2024-12-14 02:53:54,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:54,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:54,772][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.19692330062389374, acc: 0.9523809552192688)
[2024-12-14 02:53:54,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:54,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:55,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:55,151][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.5411766767501831, acc: 0.8615384697914124)
[2024-12-14 02:53:55,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:55,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:55,571][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.6738986372947693, acc: 0.7719298005104065)
[2024-12-14 02:53:55,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:55,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:55,924][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.5508710145950317, acc: 0.7719298005104065)
[2024-12-14 02:53:56,032][slam_llm.models.slam_g Epoch: 9/10, step 188/574 completed (loss: 1.8742834329605103, acc: 0.49822065234184265)
[2024-12-14 02:53:56,305][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:53:56,579][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.4463568925857544, acc: 0.8399999737739563)
                     [2024-12-14 02:53:56,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:57,133][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 1.3943122625350952, acc: 0.5813953280448914)
                                                                                                                                                                                                                                                                                          [2024-12-14 02:53:57,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:57,931][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 1.2540634870529175, acc: 0.6507936716079712)
                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:53:58,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:58,879][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 1.4828637838363647, acc: 0.5833333134651184)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:53:59,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:59,623][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 1.0657693147659302, acc: 0.6823529601097107)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:53:59,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:59,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:59,861][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.06071106344461441, acc: 1.0)
[2024-12-14 02:53:59,916][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.4172609746456146, acc: 0.9038461446762085)
[2024-12-14 02:53:59,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:53:59,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:00,188][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.6543393731117249, acc: 0.7435897588729858)
[2024-12-14 02:54:00,212][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.4814716875553131, acc: 0.9583333134651184)
[2024-12-14 02:54:00,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:00,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:00,535][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.923545241355896, acc: 0.7333333492279053)
[2024-12-14 02:54:00,568][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.12373524904251099, acc: 0.9473684430122375)
[2024-12-14 02:54:00,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:00,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:00,857][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.5183268189430237, acc: 0.8051947951316833)
[2024-12-14 02:54:00,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:00,978][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 1.3929980993270874, acc: 0.5828220844268799)
[2024-12-14 02:54:01,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:01,232][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.2859679162502289, acc: 0.9583333134651184)
[2024-12-14 02:54:01,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:01,366][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 1.2783150672912598, acc: 0.625)
[2024-12-14 02:54:01,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:01,612][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.3799477219581604, acc: 0.8448275923728943)
[2024-12-14 02:54:01,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:01,769][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 1.1924359798431396, acc: 0.6583333611488342)
[2024-12-14 02:54:01,999][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 1.0118305683135986, acc: 0.738095223903656)
[2024-12-14 02:54:02,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:02,376][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.14950628578662872, acc: 1.0)
              [2024-12-14 02:54:02,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:02,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:02,709][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.09728521853685379, acc: 0.9629629850387573)
[2024-12-14 02:54:02,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:03,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:03,105][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 1.4443081617355347, acc: 0.5989304780960083)
[2024-12-14 02:54:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:03,410][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.722892165184021, acc: 0.8387096524238586)
[2024-12-14 02:54:03,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:03,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:03,830][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 1.062113881111145, acc: 0.6581196784973145)
[2024-12-14 02:54:03,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:03,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:04,169][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 1.6292901039123535, acc: 0.5663265585899353)
[2024-12-14 02:54:04,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:04,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:04,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:04,964][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.7667871117591858, acc: 0.8131868243217468)
[2024-12-14 02:54:05,073][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:54:05,333][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 1.6218955516815186, acc: 0.5695067048072815)
[2024-12-14 02:54:05,494][slam_llm.models.slam_model][INFO] - modality encoder
                     [2024-12-14 02:54:05,775][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 1.686591625213623, acc: 0.5590550899505615)
[2024-12-14 02:54:05,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:06,146][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 1.6079550981521606, acc: 0.5215517282485962)
[2024-12-14 02:54:06,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:06,523][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 1.5266910791397095, acc: 0.5688405632972717)
                    [2024-12-14 02:54:06,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:06,921][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 1.658007025718689, acc: 0.5175096988677979)
                                                                             [2024-12-14 02:54:07,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:07,307][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 1.2807093858718872, acc: 0.6304348111152649)
                                                                              [2024-12-14 02:54:07,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:07,665][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.14586496353149414, acc: 0.95652174949646)
                                                                             [2024-12-14 02:54:07,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:07,981][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.5786072611808777, acc: 0.9285714030265808)
                                                                             [2024-12-14 02:54:08,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:08,340][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.4324822425842285, acc: 0.914893627166748)
                                                                              [2024-12-14 02:54:08,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:09,022][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 1.0596027374267578, acc: 0.692307710647583)
                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:54:09,131][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                         [2024-12-14 02:54:09,423][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.5280205011367798, acc: 0.8648648858070374)
] - modality encoder
[2024-12-14 02:54:09,406][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.17417968809604645, acc: 0.9259259104728699)
[2024-12-14 02:54:09,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:09,713][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.6033504009246826, acc: 0.7948718070983887)
[2024-12-14 02:54:09,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:09,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:10,022][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.3197598457336426, acc: 0.939393937587738)
[2024-12-14 02:54:10,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:10,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:10,410][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.46357354521751404, acc: 0.8695651888847351)
[2024-12-14 02:54:10,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:10,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:10,741][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.6229659914970398, acc: 0.843137264251709)
[2024-12-14 02:54:10,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:10,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:11,083][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.7425205707550049, acc: 0.8367347121238708)
[2024-12-14 02:54:11,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:11,466][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.12912248075008392, acc: 0.9473684430122375)
[2024-12-14 02:54:11,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:11,579][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:54:11,827][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.15577460825443268, acc: 0.9583333134651184)
[2024-12-14 02:54:11,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:11,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:12,170][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.5635501742362976, acc: 0.8611111044883728)
[2024-12-14 02:54:12,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:12,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:12,515][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.12496847659349442, acc: 0.9473684430122375)
[2024-12-14 02:54:12,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:12,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:12,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:12,908][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.38142478466033936, acc: 0.807692289352417)
[2024-12-14 02:54:13,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:13,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:13,252][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.23671914637088776, acc: 0.8965517282485962)
[2024-12-14 02:54:13,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:13,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:13,578][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.08696771413087845, acc: 0.9599999785423279)
[2024-12-14 02:54:13,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:13,979][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.27849775552749634, acc: 0.9523809552192688)
[[2024-12-14 02:54:14,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:14,556][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.676345705986023, acc: 0.7666666507720947)
                                                                                                                                                                                                                               [2024-12-14 02:54:14,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:14,959][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.2692524194717407, acc: 0.930232584476471)
                                                                               [2024-12-14 02:54:15,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:15,340][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.27838268876075745, acc: 0.8666666746139526)
[2024-12-14 02:54:15,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:15,735][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 1.076305627822876, acc: 0.6947368383407593)
[2024-12-14 02:54:15,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:16,088][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 0.8745688796043396, acc: 0.7777777910232544)
[2024-12-14 02:54:16,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:16,553][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 0.9594190120697021, acc: 0.699999988079071)
[2024-12-14 02:54:16,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:17,048][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 1.537612795829773, acc: 0.60550457239151)
                                                                                                                                                                [2024-12-14 02:54:17,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:17,525][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 0.8691203594207764, acc: 0.7615384459495544)
                                                                              [2024-12-14 02:54:17,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:17,882][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.11100628226995468, acc: 1.0)
                                                                                            [2024-12-14 02:54:17,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:18,240][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.09840726852416992, acc: 0.9583333134651184)
[2024-12-14 02:54:18,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:18,542][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.22772039473056793, acc: 0.9090909361839294)
                                                                                                                                                           [2024-12-14 02:54:18,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:18,897][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.21778544783592224, acc: 0.9259259104728699)
                                                                                                                                              [2024-12-14 02:54:19,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:19,286][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.16832691431045532, acc: 1.0)
                                                                                           [2024-12-14 02:54:19,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:19,703][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.7935783863067627, acc: 0.7954545617103577)
                                                                              [2024-12-14 02:54:19,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:20,063][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.36984312534332275, acc: 0.8863636255264282)
[2024-12-14 02:54:20,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:20,645][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 1.1328856945037842, acc: 0.6290322542190552)
                                                                                                                                                                                                                                          [2024-12-14 02:54:20,805][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:54:21,178][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.5151283740997314, acc: 0.7727272510528564)
[2024-12-14 02:54:21,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:21,551][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.011064993217587471, acc: 1.0)
             [2024-12-14 02:54:21,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:21,903][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.33622223138809204, acc: 0.9615384340286255)
                                                                            [2024-12-14 02:54:22,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:22,259][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.03954556584358215, acc: 1.0)
                                                                                           [2024-12-14 02:54:22,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:22,586][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.09388259053230286, acc: 1.0)
[2024-12-14 02:54:22,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:22,921][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.23792524635791779, acc: 0.9459459185600281)
                                [2024-12-14 02:54:23,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:23,240][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.368880033493042, acc: 0.9189189076423645)
[2024-12-14 02:54:23,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:23,621][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.2525971531867981, acc: 0.9189189076423645)
                                                                            [2024-12-14 02:54:23,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:24,017][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.5283147096633911, acc: 0.8529411554336548)
                                                                              [2024-12-14 02:54:24,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:24,408][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.08519637584686279, acc: 0.9512194991111755)
                                                              [2024-12-14 02:54:24,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:24,744][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.009401747956871986, acc: 1.0)
[2024-12-14 02:54:24,838][slam_llm.models.slam_model][INFO] - modality encoder
            [2024-12-14 02:54:25,100][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.1180746778845787, acc: 0.9599999785423279)
                     [2024-12-14 02:54:25,174][slam_llm.models.slam_model][INFO] - modality encoder
eted (loss: 0.1560216248035431, acc: 0.9722222089767456)
[2024-12-14 02:54:25,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:25,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:25,502][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.7959177494049072, acc: 0.7368420958518982)
[2024-12-14 02:54:25,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:25,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:25,917][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.6824406385421753, acc: 0.8095238208770752)
[2024-12-14 02:54:26,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:26,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:26,272][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.6463487148284912, acc: 0.8450704216957092)
[2024-12-14 02:54:26,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:26,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:26,732][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 1.6449209451675415, acc: 0.5600000023841858)
[2024-12-14 02:54:26,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:26,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:27,067][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.3853055536746979, acc: 0.837837815284729)
[2024-12-14 02:54:27,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:27,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:27,444][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.09655097872018814, acc: 0.9230769276618958)
[2024-12-14 02:54:27,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:27,832][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:54:28,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:28,480][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:54:28,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:28,998][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:54:29,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:29,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:29,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:30,075][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                    [2024-12-14 02:54:30,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:30,487][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.696805715560913, acc: 0.5426621437072754)
[2024-12-14 02:54:30,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:30,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:31,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:31,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:31,776][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 2.2835586071014404, acc: 0.4095860421657562)
[2024-12-14 02:54:32,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:32,033][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.0486, device='cuda:0') eval_epoch_loss=tensor(1.7998, device='cuda:0') eval_epoch_acc=tensor(0.6098, device='cuda:0')
[2024-12-14 02:54:32,034][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:54:32,034][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:54:32,245][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_9_step_127_loss_1.799823522567749/model.pt
[2024-12-14 02:54:32,248][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:54:32,248][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 9 is 0.6098343729972839
[2024-12-14 02:54:32,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:32,402][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 1.4933040142059326, acc: 0.5909090638160706)
[2024-12-14 02:54:32,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:32,718][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 1.4635858535766602, acc: 0.5654761791229248)
[2024-12-14 02:54:32,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:32,977][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 1.4131983518600464, acc: 0.6102941036224365)
[2024-12-14 02:54:33,105][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 1.3810195922851562, acc: 0.6153846383094788)
[2024-12-14 02:54:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:33,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:33,515][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 0.9995014071464539, acc: 0.7132353186607361)
[2024-12-14 02:54:33,538][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 1.6323888301849365, acc: 0.5362318754196167)
[2024-12-14 02:54:33,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:33,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:33,889][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.3948022723197937, acc: 0.8461538553237915)
[2024-12-14 02:54:33,953][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 1.1879408359527588, acc: 0.6875)
[2024-12-14 02:54:33,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:34,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:34,259][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.26848891377449036, acc: 0.9130434989929199)
[2024-12-14 02:54:34,282][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.1345304697751999, acc: 0.970588207244873)
[2024-12-14 02:54:34,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:34,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:34,608][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.2132372409105301, acc: 0.96875)
[2024-12-14 02:54:34,661][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.3641429841518402, acc: 0.8611111044883728)
[2024-12-14 02:54:34,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:35,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:34,973][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.28746968507766724, acc: 0.9130434989929199)
[2024-12-14 02:54:35,026][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.562846302986145, acc: 0.859375)
[2024-12-14 02:54:35,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:35,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:35,281][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.3673313558101654, acc: 0.9142857193946838)
[2024-12-14 02:54:35,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:35,400][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.22748211026191711, acc: 0.8965517282485962)
[2024-12-14 02:54:35,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:35,591][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.08987472951412201, acc: 1.0)
[2024-12-14 02:54:35,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:35,759][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.6477730870246887, acc: 0.8035714030265808)
[2024-12-14 02:54:35,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:35,891][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.3674025237560272, acc: 0.9047619104385376)
[2024-12-14 02:54:35,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:36,090][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.8612577319145203, acc: 0.6833333373069763)
[2024-12-14 02:54:36,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:36,245][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.3376602232456207, acc: 0.8666666746139526)
[2024-12-14 02:54:36,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:36,443][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.03695092350244522, acc: 1.0)
[2024-12-14 02:54:36,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:36,610][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.07285122573375702, acc: 1.0)
[2024-12-14 02:54:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:36,810][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.3363976776599884, acc: 0.9166666865348816)
[2024-12-14 02:54:36,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:36,952][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.2592606842517853, acc: 0.9047619104385376)
[2024-12-14 02:54:37,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:37,216][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.269597589969635, acc: 0.939393937587738)
[2024-12-14 02:54:37,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:37,321][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.5488345623016357, acc: 0.8846153616905212)
[2024-12-14 02:54:37,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:37,553][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 1.3702577352523804, acc: 0.654411792755127)
[2024-12-14 02:54:37,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:37,704][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.1530667543411255, acc: 1.0)
[2024-12-14 02:54:37,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:37,880][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 1.2901265621185303, acc: 0.6111111044883728)
[2024-12-14 02:54:37,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:38,042][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.5555492043495178, acc: 0.8108108043670654)
[2024-12-14 02:54:38,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:38,214][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 1.6788278818130493, acc: 0.5384615659713745)
[2024-12-14 02:54:38,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:38,574][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 1.1519842147827148, acc: 0.6052631735801697)
[2024-12-14 02:54:38,584][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 1.0099457502365112, acc: 0.7244898080825806)
[2024-12-14 02:54:38,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:38,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:38,890][root][INFO] - Training Epoch: 9/10, step 75/574 compl[2024-12-14 02:54:39,208][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:54:39,609][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                          [2024-12-14 02:54:39,912][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:54:40,214][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:54:40,595][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:54:40,989][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:54:41,355][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:54:41,648][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:54:41,961][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:54:42,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:42,299][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.6006762385368347, acc: 0.8070175647735596)
[2024-12-14 02:54:42,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:42,501][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.6295758485794067, acc: 0.8600000143051147)
[2024-12-14 02:54:42,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:42,672][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.9062604308128357, acc: 0.7162162065505981)
[2024-12-14 02:54:42,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:42,868][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.20662853121757507, acc: 0.9130434989929199)
[2024-12-14 02:54:43,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:43,045][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.1424543559551239, acc: 0.9642857313156128)
[2024-12-14 02:54:43,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:43,353][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.7132611870765686, acc: 0.7400000095367432)
[2024-12-14 02:54:43,443][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.2624961733818054, acc: 0.95652174949646)
[2024-12-14 02:54:43,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:43,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:43,699][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.8189456462860107, acc: 0.7766990065574646)
[2024-12-14 02:54:43,814][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.14059863984584808, acc: 1.0)
[2024-12-14 02:54:44,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:44,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:44,804][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 1.525953769683838, acc: 0.6116504669189453)
[2024-12-14 02:54:45,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:45,445][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.5878751873970032, acc: 0.7972972989082336)
[2024-12-14 02:54:45,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:45,624][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 1.6090245246887207, acc: 0.5752688050270081)
[2024-12-14 02:54:45,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:45,844][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 0.6004285216331482, acc: 0.7592592835426331)
[2024-12-14 02:54:45,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:46,267][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 0.9005815982818604, acc: 0.7674418687820435)
[2024-12-14 02:54:46,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:46,426][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 1.4832974672317505, acc: 0.6293103694915771)
[2024-12-14 02:54:46,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:46,855][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.4282245337963104, acc: 0.8588235378265381)
[2024-12-14 02:54:46,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:47,172][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.7198694944381714, acc: 0.7789473533630371)
[2024-12-14 02:54:47,407][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 0.9693769812583923, acc: 0.7191011309623718)
[2024-12-14 02:54:47,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:47,724][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.2742072343826294, acc: 0.9318181872367859)
[2024-12-14 02:54:48,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:48,101][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.3034294545650482, acc: 0.9047619104385376)
[2024-12-14 02:54:48,174][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 1.234846830368042, acc: 0.6633663177490234)
[2024-12-14 02:54:48,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:48,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:48,485][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.39145657420158386, acc: 0.8620689511299133)
[2024-12-14 02:54:48,516][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.8137239217758179, acc: 0.774193525314331)
[2024-12-14 02:54:48,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:48,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:48,880][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.4189468324184418, acc: 0.8571428656578064)
[2024-12-14 02:54:48,918][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.8579676151275635, acc: 0.739130437374115)
[2024-12-14 02:54:49,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:49,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:49,277][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 1.4126652479171753, acc: 0.5630252361297607)
[2024-12-14 02:54:49,294][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.472977876663208, acc: 0.8199999928474426)
[2024-12-14 02:54:49,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:49,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:49,644][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 1.2208174467086792, acc: 0.625)
[2024-12-14 02:54:49,731][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.7670325636863708, acc: 0.7638888955116272)
[2024-12-14 02:54:49,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:49,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:50,056][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 1.6276469230651855, acc: 0.5474452376365662)
[2024-12-14 02:54:50,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:50,150][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 1.049699306488037, acc: 0.6666666865348816)
[2024-12-14 02:54:50,341][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.739503800868988, acc: 0.746268630027771)
[2024-12-14 02:54:50,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:50,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:50,588][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.1500413715839386, acc: 0.949999988079071)
[2024-12-14 02:54:50,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:50,903][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.041758231818675995, acc: 1.0)
[2024-12-14 02:54:51,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:51,191][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 1.7209888696670532, acc: 0.5205479264259338)
[2024-12-14 02:54:51,288][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.10048392415046692, acc: 0.95652174949646)
[2024-12-14 02:54:51,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:51,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:51,563][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.11854469031095505, acc: 0.9583333134651184)
[2024-12-14 02:54:51,637][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.2442459613084793, acc: 0.9318181872367859)
[2024-12-14 02:54:51,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:51,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:51,951][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.33182293176651, acc: 0.8518518805503845)
[2024-12-14 02:54:51,960][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.5563539862632751, acc: 0.8448275923728943)
[2024-12-14 02:54:52,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:52,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:52,292][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.1531456857919693, acc: 0.9285714030265808)
[2024-12-14 02:54:52,311][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.37914782762527466, acc: 0.9069767594337463)
[2024-12-14 02:54:52,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:52,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:52,712][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.11725980043411255, acc: 0.9599999785423279)
[2024-12-14 02:54:52,829][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 0.9702620506286621, acc: 0.6814159154891968)
[2024-12-14 02:54:52,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:52,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:53,100][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.010957760736346245, acc: 1.0)
[2024-12-14 02:54:53,143][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.6684938073158264, acc: 0.7971014380455017)
[2024-12-14 02:54:53,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:53,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:53,452][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 0.9830575585365295, acc: 0.7159090638160706)
[2024-12-14 02:54:53,457][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.017555279657244682, acc: 1.0)
[2024-12-14 02:54:53,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:53,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:53,818][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.24408124387264252, acc: 0.9523809552192688)
[2024-12-14 02:54:53,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:54,229][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.6434550881385803, acc: 0.8153846263885498)
[2024-12-14 02:54:54,359][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 1.7283666133880615, acc: 0.5419847369194031)
[2024-12-14 02:54:54,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:54,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:54,658][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.8255907893180847, acc: 0.7894737124443054)
[2024-12-14 02:54:54,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:55,027][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 1.4692682027816772, acc: 0.5333333611488342)
[2024-12-14 02:54:55,068][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.6378611326217651, acc: 0.8070175647735596)
[2024-12-14 02:54:55,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:55,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:55,390][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.49275654554367065, acc: 0.8196721076965332)
[2024-12-14 02:54:55,459][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.5725017189979553, acc: 0.8461538553237915)
[2024-12-14 02:54:55,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:55,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:55,750][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.13951900601387024, acc: 0.9166666865348816)
[2024-12-14 02:54:55,845][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.5121139287948608, acc: 0.8367347121238708)
[2024-12-14 02:54:55,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:55,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:56,246][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:54:56,624][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:54:57,015][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:54:57,501][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:54:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:54:58,143][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                   [2024-12-14 02:54:58,463][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:54:58,890][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:54:59,238][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:54:59,580][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                    [2024-12-14 02:54:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:00,155][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 1.272280216217041, acc: 0.5889570713043213)
[2024-12-14 02:55:00,037][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 1.3809882402420044, acc: 0.6395348906517029)
[2024-12-14 02:55:00,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:00,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:00,418][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 1.1796718835830688, acc: 0.6875)
[2024-12-14 02:55:00,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:00,832][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 1.44694983959198, acc: 0.6190476417541504)
[2024-12-14 02:55:00,845][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 1.1687705516815186, acc: 0.6499999761581421)
[2024-12-14 02:55:01,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:01,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:01,747][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 1.4242877960205078, acc: 0.5984848737716675)
[2024-12-14 02:55:01,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:01,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:02,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:02,488][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 1.1007213592529297, acc: 0.6941176652908325)
[2024-12-14 02:55:02,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:02,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:03,192][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:55:03,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:03,563][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 1.1873687505722046, acc: 0.6419752836227417)
[2024-12-14 02:55:03,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:03,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:04,263][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                        [2024-12-14 02:55:04,516][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.731741189956665, acc: 0.7580645084381104)
[2024-12-14 02:55:04,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:04,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:04,807][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.11886303126811981, acc: 0.9285714030265808)
[2024-12-14 02:55:04,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:04,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:05,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:05,157][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.2226870357990265, acc: 0.925000011920929)
[2024-12-14 02:55:05,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:05,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:05,501][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.6472466588020325, acc: 0.779411792755127)
[2024-12-14 02:55:05,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:05,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:06,020][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.1773035079240799, acc: 0.9200000166893005)
                                                                               [2024-12-14 02:55:06,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:06,415][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.5080461502075195, acc: 0.8085106611251831)
                                                                               [2024-12-14 02:55:06,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:06,794][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.6953742504119873, acc: 0.75)
                                                                                             [2024-12-14 02:55:06,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:07,149][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.3873481750488281, acc: 0.8863636255264282)
[2024-12-14 02:55:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:07,567][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.891714870929718, acc: 0.7349397540092468)
                                                                                                                                                             [2024-12-14 02:55:07,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:07,928][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 1.1067334413528442, acc: 0.6944444179534912)
                                                                               [2024-12-14 02:55:07,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:08,219][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.40810519456863403, acc: 0.8421052694320679)
[2024-12-14 02:55:08,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:08,530][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.309129923582077, acc: 0.970588207244873)
                                                                                [2024-12-14 02:55:08,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:08,860][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.28600990772247314, acc: 0.8999999761581421)
                                                                              [2024-12-14 02:55:08,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:09,171][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 1.2527109384536743, acc: 0.59375)
[2024-12-14 02:55:09,257][slam_llm.models.slam_model][INFO] - modality encoder
           [2024-12-14 02:55:09,491][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 1.470960259437561, acc: 0.6240000128746033)
                      [2024-12-14 02:55:09,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:09,804][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 1.0166445970535278, acc: 0.7252747416496277)
                                                                               [2024-12-14 02:55:09,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:10,111][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 1.6467766761779785, acc: 0.52173912525177)
  [2024-12-14 02:55:10,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:10,445][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 1.796114444732666, acc: 0.5154638886451721)
                                                                                [2024-12-14 02:55:10,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:10,796][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.08422782272100449, acc: 0.9545454382896423)
                                                                              [2024-12-14 02:55:10,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:11,175][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.4247564673423767, acc: 0.9047619104385376)
                                                                               [2024-12-14 02:55:11,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:11,602][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.6296788454055786, acc: 0.7758620977401733)
[2024-12-14 02:55:11,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:12,074][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.5751422047615051, acc: 0.8181818127632141)
                                                                                                                                                               [2024-12-14 02:55:12,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:12,632][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 1.4463560581207275, acc: 0.623711347579956)
                                                                                [2024-12-14 02:55:12,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:13,013][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.8499401807785034, acc: 0.7068965435028076)
                                                                                                                                                              [2024-12-14 02:55:13,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:13,392][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.23535899817943573, acc: 0.9629629850387573)
                                                                              [2024-12-14 02:55:13,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:13,770][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.5746045112609863, acc: 0.8421052694320679)
                                                                                                                                                [2024-12-14 02:55:13,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:14,159][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.29610443115234375, acc: 0.9464285969734192)
                                                                [2024-12-14 02:55:14,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:14,508][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.732158362865448, acc: 0.8125)
                                                                                             [2024-12-14 02:55:14,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:14,889][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.38699445128440857, acc: 0.9245283007621765)
[2024-12-14 02:55:15,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:15,277][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.31020182371139526, acc: 0.8867924809455872)
                 [2024-12-14 02:55:15,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:15,665][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.21773362159729004, acc: 0.8823529481887817)
[2024-12-14 02:55:15,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:16,038][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.31741058826446533, acc: 0.90625)
                                                                                       [2024-12-14 02:55:16,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:16,401][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.45994699001312256, acc: 0.8360655903816223)
                                                                              [2024-12-14 02:55:16,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:16,756][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.09188604354858398, acc: 1.0)
                                                                                            [2024-12-14 02:55:16,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:17,137][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.013640689663589, acc: 1.0)
                                                                                                                                                                              [2024-12-14 02:55:17,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:17,505][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.8144672513008118, acc: 0.782608687877655)
                                                                                [2024-12-14 02:55:17,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:17,936][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.8701351881027222, acc: 0.7638888955116272)
[2024-12-14 02:55:18,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:18,315][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.68572998046875, acc: 0.8072289228439331)
                                                                                                                                                               [2024-12-14 02:55:18,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:18,702][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.8140259981155396, acc: 0.7435897588729858)
                                                                               [2024-12-14 02:55:18,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:19,064][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 0.8492308855056763, acc: 0.6836734414100647)
                                                                               [2024-12-14 02:55:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:19,370][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.02671848051249981, acc: 1.0)
              [2024-12-14 02:55:19,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:19,676][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.1506136804819107, acc: 0.9166666865348816)
[2024-12-14 02:55:19,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:20,031][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.28140491247177124, acc: 0.9032257795333862)
                    [2024-12-14 02:55:20,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:20,406][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.15341714024543762, acc: 0.9677419066429138)
                                                                              [2024-12-14 02:55:20,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:20,759][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.44563060998916626, acc: 0.8656716346740723)
                                                                              [2024-12-14 02:55:20,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:21,111][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.8488330245018005, acc: 0.7596153616905212)
                                                                               [2024-12-14 02:55:21,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:21,481][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.2516447901725769, acc: 0.9111111164093018)
                                                                               [2024-12-14 02:55:21,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:21,816][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.5140871405601501, acc: 0.7903226017951965)

[2024-12-14 02:55:21,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:21,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:21,906][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.3378438949584961, acc: 0.8863636255264282)
[2024-12-14 02:55:22,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:22,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:22,282][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.36134982109069824, acc: 0.9090909361839294)
[2024-12-14 02:55:22,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:22,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:22,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:22,886][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.8186413049697876, acc: 0.725806474685669)
[2024-12-14 02:55:23,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:23,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:23,428][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.4145263731479645, acc: 0.8636363744735718)
[2024-12-14 02:55:23,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:23,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:23,812][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.20359723269939423, acc: 0.9523809552192688)
[2024-12-14 02:55:23,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:23,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:24,125][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.31200525164604187, acc: 0.9230769276618958)
[2024-12-14 02:55:24,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:24,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:24,466][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.07975353300571442, acc: 1.0)
[2024-12-14 02:55:24,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:24,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:24,795][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.2961617112159729, acc: 0.8500000238418579)
[2024-12-14 02:55:24,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:25,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:25,184][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.31713274121284485, acc: 0.9189189076423645)
[2024-12-14 02:55:25,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:25,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:25,537][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.2722260355949402, acc: 0.8918918967247009)
[2024-12-14 02:55:25,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:25,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:25,924][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.1326325535774231, acc: 0.9729729890823364)
[2024-12-14 02:55:26,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:26,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:26,239][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.637974202632904, acc: 0.7941176295280457)
[2024-12-14 02:55:26,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:26,584][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.064733125269413, acc: 1.0)
[2024-12-14 02:55:26,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:26,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:26,969][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.06803596019744873, acc: 1.0)

[2024-12-14 02:55:26,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:27,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:27,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:27,288][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.06497497856616974, acc: 0.9599999785423279)
[2024-12-14 02:55:27,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:27,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:27,626][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.23796115815639496, acc: 0.9032257795333862)
[2024-12-14 02:55:27,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:27,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:27,981][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.276477187871933, acc: 0.8947368264198303)
[2024-12-14 02:55:28,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:28,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:28,317][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.6121342778205872, acc: 0.8142856955528259)
[2024-12-14 02:55:28,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:28,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:28,706][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.5085040926933289, acc: 0.8421052694320679)
[2024-12-14 02:55:28,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:29,040][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:55:29,277][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 0.7361180782318115, acc: 0.7924528121948242)
[2024-12-14 02:55:29,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:29,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:29,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:29,871][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 0.9765100479125977, acc: 0.7083333134651184)
[2024-12-14 02:55:29,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:29,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:30,236][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.19047988951206207, acc: 0.9166666865348816)
[2024-12-14 02:55:30,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:30,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:30,565][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.2948994040489197, acc: 0.9032257795333862)
[2024-12-14 02:55:30,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:30,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:30,964][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 0.8964906930923462, acc: 0.6800000071525574)
[2024-12-14 02:55:31,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:31,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:31,329][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.8856356143951416, acc: 0.6666666865348816)
[2024-12-14 02:55:31,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:31,707][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7218, device='cuda:0') eval_epoch_loss=tensor(1.9054, dev[2024-12-14 02:55:31,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:32,229][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.41619759798049927, acc: 0.8055555820465088)
ler][INFO] - --> saving model ...
[2024-12-14 02:55:31,955][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_9_step_127_loss_1.9053503274917603/model.pt
[2024-12-14 02:55:31,959][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:55:31,960][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 9 is 0.6000970602035522
[2024-12-14 02:55:32,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:32,191][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 1.4098742008209229, acc: 0.5759999752044678)
[2024-12-14 02:55:32,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:32,408][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 1.3487859964370728, acc: 0.601190447807312)
[2024-12-14 02:55:32,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:32,578][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 0.9608086347579956, acc: 0.6404494643211365)
[2024-12-14 02:55:32,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:32,798][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 1.4140653610229492, acc: 0.6000000238418579)
[2024-12-14 02:55:32,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:32,949][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.908477783203125, acc: 0.7837837934494019)
[2024-12-14 02:55:33,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:33,186][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 1.1560688018798828, acc: 0.6691176295280457)
[2024-12-14 02:55:33,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:33,408][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.3856143653392792, acc: 0.8448275923728943)
[2024-12-14 02:55:33,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:33,568][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.2410784512758255, acc: 0.9230769276618958)
[2024-12-14 02:55:33,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:33,762][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.011722550727427006, acc: 1.0)
[2024-12-14 02:55:33,951][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.28552141785621643, acc: 0.95652174949646)
[2024-12-14 02:55:34,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:34,344][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.1871410459280014, acc: 0.9375)
[2024-12-14 02:55:34,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:34,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:34,685][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.39380812644958496, acc: 0.9130434989929199)
[2024-12-14 02:55:34,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:34,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:35,023][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.4632703363895416, acc: 0.8857142925262451)
[2024-12-14 02:55:35,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:35,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:35,387][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.10591424256563187, acc: 0.9615384340286255)
[2024-12-14 02:55:35,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:35,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:35,750][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.3400627374649048, acc: 0.9523809552192688)
[[2024-12-14 02:55:36,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:36,270][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.05907895416021347, acc: 1.0)
ing Epoch: 9/10, step 137/574 completed (loss: 0.5290852785110474, acc: 0.8333333134651184)
[2024-12-14 02:55:36,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:36,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:36,484][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.24407613277435303, acc: 0.95652174949646)
[2024-12-14 02:55:36,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:36,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:36,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:36,869][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.2151728868484497, acc: 0.9047619104385376)
[2024-12-14 02:55:36,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:37,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:37,216][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.6917584538459778, acc: 0.7692307829856873)
[2024-12-14 02:55:37,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:37,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:37,599][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.31370237469673157, acc: 0.9354838728904724)
[2024-12-14 02:55:37,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:37,946][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.4579090476036072, acc: 0.8918918967247009)
[2024-12-14 02:55:38,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:38,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:38,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:38,492][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 1.2637931108474731, acc: 0.5964912176132202)
[2024-12-14 02:55:38,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:38,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:38,869][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 1.0356619358062744, acc: 0.6567164063453674)
[2024-12-14 02:55:38,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:39,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:39,219][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 1.0635607242584229, acc: 0.6734693646430969)
[2024-12-14 02:55:39,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:39,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:39,659][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 1.0638103485107422, acc: 0.6170212626457214)
[2024-12-14 02:55:39,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:39,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:39,972][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.5484578013420105, acc: 0.800000011920929)
[2024-12-14 02:55:40,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:40,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:40,329][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.3583119511604309, acc: 0.8571428656578064)
[2024-12-14 02:55:40,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:40,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:40,655][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.470999151468277, acc: 0.782608687877655)
[2024-12-14 02:55:40,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:40,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:40,972][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.2508763372898102, acc: 0.8965517282485962)
[2024-12-14 02:55:41,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:41,606][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.5264807939529419, acc: 0.8214285969734192)
                                                                             [2024-12-14 02:55:41,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:41,969][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.197892963886261, acc: 0.9428571462631226)
                                                                                [2024-12-14 02:55:42,052][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:55:42,282][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.11311351507902145, acc: 0.9599999785423279)
[2024-12-14 02:55:42,386][slam_llm.models.slam_model][INFO] - modality encoder
                                                                             [2024-12-14 02:55:42,647][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.021722447127103806, acc: 1.0)
[2024-12-14 02:55:42,755][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                             [2024-12-14 02:55:42,985][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.33877280354499817, acc: 0.8958333134651184)
[2024-12-14 02:55:43,080][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:55:43,323][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.6825318932533264, acc: 0.800000011920929)
[2024-12-14 02:55:43,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:43,897][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 1.0144259929656982, acc: 0.7245509028434753)
                       [2024-12-14 02:55:44,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:44,314][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.7566424608230591, acc: 0.7518796920776367)
[2024-12-14 02:55:44,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:45,597][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 0.9789134860038757, acc: 0.6951871514320374)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:55:45,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:46,160][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.5397899150848389, acc: 0.8558558821678162)
                                                                               [2024-12-14 02:55:46,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:46,502][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.3176998496055603, acc: 0.8928571343421936)
                                                                               [2024-12-14 02:55:46,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:46,858][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.02443327009677887, acc: 1.0)
[2024-12-14 02:55:46,978][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                             [2024-12-14 02:55:47,229][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.06328786164522171, acc: 1.0)
[2024-12-14 02:55:47,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:47,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:47,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:47,590][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 1.0941948890686035, acc: 0.7142857313156128)
[2024-12-14 02:55:47,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:47,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:47,930][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.41735610365867615, acc: 0.8620689511299133)
[2024-12-14 02:55:48,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:48,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:48,355][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.41572484374046326, acc: 0.8163265585899353)
[2024-12-14 02:55:48,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:48,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:48,702][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.5345431566238403, acc: 0.800000011920929)
[2024-12-14 02:55:48,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:49,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:49,103][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.9332979917526245, acc: 0.6666666865348816)
[2024-12-14 02:55:49,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:49,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:49,509][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 1.152122974395752, acc: 0.686274528503418)
[2024-12-14 02:55:49,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:49,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:50,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:50,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:50,546][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 1.7170850038528442, acc: 0.5205479264259338)
[2024-12-14 02:55:50,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:50,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:50,913][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.0920504704117775, acc: 0.9583333134651184)
[2024-12-14 02:55:51,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:51,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:51,301][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.5410313010215759, acc: 0.7407407164573669)
[2024-12-14 02:55:51,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:51,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:51,686][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.2780575752258301, acc: 0.9285714030265808)
[2024-12-14 02:55:51,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:51,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:52,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:52,241][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 1.1380454301834106, acc: 0.6991150379180908)
[2024-12-14 02:55:52,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:52,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:52,620][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.8097161054611206, acc: 0.7681159377098083)
[2024-12-14 02:55:52,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:52,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:52,987][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 1.0324015617370605, acc: 0.6818181872367859)
[2024-12-14 02:55:53,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:53,391][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.8691321015357971, acc: 0.7333333492279053)
[2024-12-14 02:55:53,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:53,761][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.41535091400146484, acc: 0.8484848737716675)
[2024-12-14 02:55:53,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:54,096][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.2738008499145508, acc: 0.9090909361839294)
[2024-12-14 02:55:54,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:54,445][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.10024279356002808, acc: 0.9677419066429138)
[2024-12-14 02:55:54,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:54,795][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.2637442946434021, acc: 0.8888888955116272)
[2024-12-14 02:55:54,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:55,117][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.029839441180229187, acc: 1.0)
                                                                                           [2024-12-14 02:55:55,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:55,505][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.19449473917484283, acc: 0.9722222089767456)
[2024-12-14 02:55:55,613][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:55:55,886][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.18633390963077545, acc: 0.9629629850387573)
                                                                                                                                                              [2024-12-14 02:55:56,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:56,247][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.015737859532237053, acc: 1.0)
             [2024-12-14 02:55:56,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:56,618][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.40619370341300964, acc: 0.8965517282485962)
                                                                              [2024-12-14 02:55:56,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:57,012][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.22128881514072418, acc: 0.8928571343421936)
[2024-12-14 02:55:57,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:57,404][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.09210079163312912, acc: 0.9666666388511658)
                                                                                                                                                                                                                                           [2024-12-14 02:55:58,084][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:55:58,388][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:55:58,730][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:55:59,085][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:55:59,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:55:59,781][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:56:00,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:00,494][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                      [2024-12-14 02:56:00,861][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:56:01,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:01,604][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:56:02,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:02,388][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:56:02,726][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:56:03,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:03,463][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:56:03,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:04,417][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:56:04,833][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:56:05,130][slam_llm.models.slam_model][INFO] - modality encoder
7.5548, device='cuda:0') eval_epoch_loss=tensor(2.0222, device='cuda:0') eval_epoch_acc=tensor(0.5798, device='cuda:0')
[2024-12-14 02:56:04,969][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:56:04,969][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:56:05,196][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.8375913500785828, acc: 0.75)
[2024-12-14 02:56:05,213][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_9_step_270_loss_2.0221896171569824/model.pt
[2024-12-14 02:56:05,217][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:56:05,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:05,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:05,503][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 1.4519081115722656, acc: 0.5735294222831726)
[2024-12-14 02:56:05,557][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.1310471147298813, acc: 1.0)
[2024-12-14 02:56:05,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:05,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:05,846][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 1.4594415426254272, acc: 0.5593220591545105)
[2024-12-14 02:56:05,893][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.04715355113148689, acc: 1.0)
[2024-12-14 02:56:05,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:06,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:06,193][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 1.3625274896621704, acc: 0.6343283653259277)
[2024-12-14 02:56:06,247][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.2070620208978653, acc: 0.8666666746139526)
[2024-12-14 02:56:06,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:06,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:06,558][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 1.2785987854003906, acc: 0.5728155374526978)
[2024-12-14 02:56:06,651][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.39638474583625793, acc: 0.8666666746139526)
[2024-12-14 02:56:06,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:06,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:06,937][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.7775673270225525, acc: 0.7460317611694336)
[2024-12-14 02:56:07,024][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.06647739559412003, acc: 1.0)
[2024-12-14 02:56:07,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:07,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:07,294][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.8897579908370972, acc: 0.7362637519836426)
[2024-12-14 02:56:07,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:07,423][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.12164198607206345, acc: 0.9666666388511658)
[2024-12-14 02:56:07,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:07,688][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 1.6224154233932495, acc: 0.5291479825973511)
[2024-12-14 02:56:07,792][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.30791065096855164, acc: 0.8620689511299133)
[2024-12-14 02:56:07,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:07,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:08,105][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 1.7808492183685303, acc: 0.5196850299835205)
[2024-12-14 02:56:08,163][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.12779970467090607, acc: 0.9200000166893005)
[2024-12-14 02:56:08,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:08,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:08,461][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 1.5695466995239258, acc: 0.5517241358757019)
[2024-12-14 02:56:08,548][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.3293267786502838, acc: 0.936170220375061)
[2024-12-14 02:56:08,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:08,856][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 1.532994270324707, acc: 0.6014492511749268)
[2024-12-14 02:56:08,911][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.4451572597026825, acc: 0.8541666865348816)
[2024-12-14 02:56:08,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:08,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:09,230][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 1.6412018537521362, acc: 0.5408560037612915)
[2024-12-14 02:56:09,230][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.13356465101242065, acc: 1.0)
[2024-12-14 02:56:09,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:09,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:09,574][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 1.2038049697875977, acc: 0.6304348111152649)
[2024-12-14 02:56:09,645][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 1.154946208000183, acc: 0.6867470145225525)
[2024-12-14 02:56:09,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:09,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:09,929][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.28254076838493347, acc: 0.8695651888847351)
[2024-12-14 02:56:10,007][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 0.9907892942428589, acc: 0.6851851940155029)
[2024-12-14 02:56:10,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:10,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:10,230][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.10817646980285645, acc: 1.0)
[2024-12-14 02:56:10,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:10,378][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.36814767122268677, acc: 0.8947368264198303)
[2024-12-14 02:56:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:10,565][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.3049158751964569, acc: 0.914893627166748)
[2024-12-14 02:56:10,703][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.25240883231163025, acc: 0.9411764740943909)
[2024-12-14 02:56:10,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:10,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:11,094][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.15114040672779083, acc: 0.925000011920929)
[2024-12-14 02:56:11,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:11,295][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 0.9698684215545654, acc: 0.7076923251152039)
[2024-12-14 02:56:11,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:11,462][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 1.3875205516815186, acc: 0.5859375)
[2024-12-14 02:56:11,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:11,660][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.5113340616226196, acc: 0.8648648858070374)
[2024-12-14 02:56:11,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:11,847][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 1.7403080463409424, acc: 0.5440000295639038)
[2024-12-14 02:56:11,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:12,036][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.6564623713493347, acc: 0.8372092843055725)
[2024-12-14 02:56:12,213][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.8265950083732605, acc: 0.7582417726516724)
[2024-12-14 02:56:12,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:12,596][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:56:12,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:13,202][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:56:13,583][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:56:13,894][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:56:14,255][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 02:56:14,621][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:56:14,981][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:56:15,420][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:56:15,773][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:56:16,112][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:56:16,521][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:56:16,883][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:56:17,264][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:56:17,659][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:56:18,021][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:56:18,365][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                  [2024-12-14 02:56:18,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:19,050][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:56:19,543][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:56:19,813][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:56:20,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:20,010][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.8283348083496094, acc: 0.7638888955116272)
[2024-12-14 02:56:20,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:20,176][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.3271277844905853, acc: 0.9473684430122375)
[2024-12-14 02:56:20,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:20,386][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.7545009255409241, acc: 0.7951807379722595)
[2024-12-14 02:56:20,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:20,562][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.15592797100543976, acc: 0.9166666865348816)
[2024-12-14 02:56:20,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:20,710][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.9314025640487671, acc: 0.7179487347602844)
[2024-12-14 02:56:20,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:20,927][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.4378167390823364, acc: 0.8636363744735718)
[2024-12-14 02:56:21,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:21,099][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 0.9995315074920654, acc: 0.7244898080825806)
[2024-12-14 02:56:21,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:21,299][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.4268793761730194, acc: 0.8888888955116272)
[2024-12-14 02:56:21,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:21,419][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.05128351226449013, acc: 1.0)
[2024-12-14 02:56:21,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:21,675][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.474059134721756, acc: 0.800000011920929)
[2024-12-14 02:56:21,774][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.056663628667593, acc: 1.0)
[2024-12-14 02:56:21,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:21,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:22,049][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.38428211212158203, acc: 0.8636363744735718)
[2024-12-14 02:56:22,138][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.2922373116016388, acc: 0.8709677457809448)
[2024-12-14 02:56:22,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:22,418][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.525958240032196, acc: 0.8409090638160706)
[2024-12-14 02:56:22,501][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.23275242745876312, acc: 0.8709677457809448)
[2024-12-14 02:56:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:22,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:22,887][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.49314743280410767, acc: 0.7910447716712952)
[2024-12-14 02:56:23,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:23,004][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.6888530850410461, acc: 0.7903226017951965)
[2024-12-14 02:56:23,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:23,240][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.9254884719848633, acc: 0.7211538553237915)
[2024-12-14 02:56:23,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:23,548][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.27375543117523193, acc: 0.9090909361839294)
[2024-12-14 02:56:23,588][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.12764962017536163, acc: 0.9777777791023254)
[2024-12-14 02:56:23,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:23,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:23,926][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.030895976349711418, acc: 1.0)
[2024-12-14 02:56:23,940][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.3732101023197174, acc: 0.8709677457809448)
[2024-12-14 02:56:24,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:24,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:24,290][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.24698592722415924, acc: 0.9615384340286255)
[2024-12-14 02:56:24,316][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.19533394277095795, acc: 0.9399999976158142)
[2024-12-14 02:56:24,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:24,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:24,663][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.4936937391757965, acc: 0.8518518805503845)
[2024-12-14 02:56:24,673][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.18094506859779358, acc: 0.9677419066429138)
[2024-12-14 02:56:24,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:24,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:25,016][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.22077488899230957, acc: 0.949999988079071)
[2024-12-14 02:56:25,053][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.3686061203479767, acc: 0.9714285731315613)
[2024-12-14 02:56:25,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:25,392][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.3834827244281769, acc: 0.8648648858070374)
[2024-12-14 02:56:25,434][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.22929534316062927, acc: 0.9230769276618958)
[2024-12-14 02:56:25,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:25,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:25,783][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.2281225621700287, acc: 0.9189189076423645)
[2024-12-14 02:56:25,803][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 0.3164319694042206, acc: 0.9268292784690857)
[2024-12-14 02:56:25,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:25,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:26,088][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.43943873047828674, acc: 0.8648648858070374)
[2024-12-14 02:56:26,176][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.5535111427307129, acc: 0.8421052694320679)
[2024-12-14 02:56:26,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:26,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:26,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:27,291][slam_llm.models.slam_model][INFO] - modality encoder
515][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.25640201568603516, acc: 0.9473684430122375)
[2024-12-14 02:56:26,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:26,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:26,767][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.2664417028427124, acc: 0.9268292784690857)
[2024-12-14 02:56:26,842][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.028457816690206528, acc: 1.0)
[2024-12-14 02:56:26,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:26,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:27,023][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.05656634271144867, acc: 1.0)
[2024-12-14 02:56:27,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:27,250][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.12165998667478561, acc: 0.9629629850387573)
[2024-12-14 02:56:27,309][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.09096799045801163, acc: 0.9599999785423279)
[2024-12-14 02:56:27,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:27,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:27,624][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.18922004103660583, acc: 0.96875)
[2024-12-14 02:56:27,637][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.05667572095990181, acc: 1.0)
[2024-12-14 02:56:27,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:27,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:27,955][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.2563958168029785, acc: 0.8947368264198303)
[2024-12-14 02:56:27,956][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.5703809857368469, acc: 0.7903226017951965)
[2024-12-14 02:56:28,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:28,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:28,289][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.36532655358314514, acc: 0.8714285492897034)
[2024-12-14 02:56:28,362][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.5545977354049683, acc: 0.8245614171028137)
[2024-12-14 02:56:28,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:28,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:28,625][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.5674851536750793, acc: 0.8026315569877625)
[2024-12-14 02:56:28,740][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.5258539915084839, acc: 0.8125)
[2024-12-14 02:56:28,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:28,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:29,144][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.3187040090560913, acc: 0.8666666746139526)
[2024-12-14 02:56:29,205][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 1.0309849977493286, acc: 0.6792452931404114)
[2024-12-14 02:56:29,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:29,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:29,487][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.19368746876716614, acc: 0.9473684430122375)
[2024-12-14 02:56:29,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:29,796][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.6671196818351746, acc: 0.7599999904632568)
[2024-12-14 02:56:29,824][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 1.0967782735824585, acc: 0.675000011920929)
[2024-12-14 02:56:29,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:29,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:30,090][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 1.07758367061615, acc: 0.6436781883239746)
[2024-12-14 02:56:30,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:30,217][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.3245302736759186, acc: 0.9166666865348816)
[2024-12-14 02:56:30,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:30,654][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.10256733745336533, acc: 1.0)
744490623474)
[2024-12-14 02:56:30,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:30,593][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.1525922417640686, acc: 0.9032257795333862)
[2024-12-14 02:56:30,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:30,751][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 1.374071717262268, acc: 0.5903614163398743)
[2024-12-14 02:56:30,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:30,937][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 1.044217586517334, acc: 0.6800000071525574)
[2024-12-14 02:56:31,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:31,146][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.09716084599494934, acc: 1.0)
[2024-12-14 02:56:31,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:31,293][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.6618979573249817, acc: 0.8125)
[2024-12-14 02:56:31,481][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.277670294046402, acc: 0.9230769276618958)
[2024-12-14 02:56:31,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:31,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:31,838][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 1.6078271865844727, acc: 0.6024096608161926)
[2024-12-14 02:56:31,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:32,135][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 1.472496509552002, acc: 0.5759999752044678)
[2024-12-14 02:56:32,215][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.6605964303016663, acc: 0.8113207817077637)
[2024-12-14 02:56:32,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:32,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:32,471][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 1.101694107055664, acc: 0.6516854166984558)
[2024-12-14 02:56:32,566][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.8030458092689514, acc: 0.7848101258277893)
[2024-12-14 02:56:32,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:32,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:32,866][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.8849950432777405, acc: 0.7432432174682617)
[2024-12-14 02:56:32,913][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.4689512550830841, acc: 0.8235294222831726)
[2024-12-14 02:56:32,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:33,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:33,263][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.6579633951187134, acc: 0.746268630027771)
[2024-12-14 02:56:33,312][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.6395443677902222, acc: 0.7931034564971924)
[2024-12-14 02:56:33,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:33,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:33,546][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.034098245203495026, acc: 1.0)
[2024-12-14 02:56:33,667][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.06289675831794739, acc: 1.0)
[2024-12-14 02:56:33,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:33,960][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.14085008203983307, acc: 0.9599999785423279)
[2024-12-14 02:56:34,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:34,381][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.28322741389274597, acc: 0.9166666865348816)
[2024-12-14 02:56:34,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:34,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:34,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:34,871][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.17079485952854156, acc: 0.9259259104728699)
[2024-12-14 02:56:34,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:35,179][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.06212076544761658, acc: 0.95652174949646)
[2024-12-14 02:56:35,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:35,571][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.5480270385742188, acc: 0.8055555820465088)
[2024-12-14 02:56:35,675][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:56:35,909][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.21685969829559326, acc: 0.9599999785423279)
[2024-12-14 02:56:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:36,239][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.24322602152824402, acc: 0.939393937587738)
                   [2024-12-14 02:56:36,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:36,568][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.3087540566921234, acc: 0.9166666865348816)
[2024-12-14 02:56:36,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:36,967][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.2377425730228424, acc: 0.9318181872367859)
                                                                                                                                                                                                                             [2024-12-14 02:56:37,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:37,320][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.0956166684627533, acc: 0.9523809552192688)
[2024-12-14 02:56:37,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:37,664][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.3047868609428406, acc: 0.9230769276618958)
                                                                              [2024-12-14 02:56:37,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:38,108][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.7402714490890503, acc: 0.7878788113594055)
                                                                               [2024-12-14 02:56:38,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:38,787][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 1.696698784828186, acc: 0.5199999809265137)
                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 02:56:38,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:39,191][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 1.3891633749008179, acc: 0.6532257795333862)
                                                                               [2024-12-14 02:56:39,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:39,843][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 1.55990731716156, acc: 0.572139322757721)
                                                                                                                                                                                                                                                [2024-12-14 02:56:39,931][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:56:40,194][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.5021889805793762, acc: 0.8301886916160583)
] - modality encoder
[2024-12-14 02:56:40,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:40,244][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.28416183590888977, acc: 0.9512194991111755)
[2024-12-14 02:56:40,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:40,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:40,607][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.24561716616153717, acc: 0.9696969985961914)
[2024-12-14 02:56:40,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:40,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:40,974][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.028122378513216972, acc: 1.0)
[2024-12-14 02:56:41,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:41,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:41,340][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.04733763635158539, acc: 1.0)
[2024-12-14 02:56:41,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:41,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:41,682][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.18524590134620667, acc: 0.8928571343421936)
[2024-12-14 02:56:41,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:41,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:42,006][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.09558927267789841, acc: 1.0)
[2024-12-14 02:56:42,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:42,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:42,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:42,606][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 1.3544082641601562, acc: 0.6303030252456665)
[2024-12-14 02:56:42,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:42,960][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:56:43,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:43,487][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 0.9003998637199402, acc: 0.7264150977134705)
[2024-12-14 02:56:43,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:43,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:43,823][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.7085188031196594, acc: 0.8111110925674438)
[2024-12-14 02:56:43,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:44,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:44,189][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.5349105596542358, acc: 0.8571428656578064)
[2024-12-14 02:56:44,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:44,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:44,523][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.35790354013442993, acc: 0.8857142925262451)
[2024-12-14 02:56:44,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:44,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:44,862][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.02107006311416626, acc: 1.0)
[2024-12-14 02:56:44,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:44,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:45,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:45,546][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.4476589262485504, acc: 0.8214285969734192)
2024-12-14 02:56:45,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:45,659][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.31522566080093384, acc: 0.8541666865348816)
[2024-12-14 02:56:45,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:45,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:45,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:46,055][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.7020719051361084, acc: 0.7789473533630371)
[2024-12-14 02:56:46,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:46,326][slam_llm.models.slam_model][INFO] - modality encoder
                                                [2024-12-14 02:56:46,647][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 1.1700589656829834, acc: 0.6946107745170593)
[2024-12-14 02:56:46,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:46,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:47,052][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.8046900629997253, acc: 0.7593985199928284)
[2024-12-14 02:56:47,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:47,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:47,578][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:56:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:48,044][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 02:56:48,354][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 1.046712040901184, acc: 0.7058823704719543)
                                                                                [2024-12-14 02:56:48,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:48,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:48,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:48,917][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.5580762028694153, acc: 0.8468468189239502)
[2024-12-14 02:56:49,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:49,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:49,306][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.1473734825849533, acc: 0.9642857313156128)
[2024-12-14 02:56:49,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:49,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:49,654][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.05625895783305168, acc: 0.9642857313156128)
[2024-12-14 02:56:49,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:49,978][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.23483926057815552, acc: 0.96875)
[2024-12-14 02:56:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:50,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:50,301][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.09104977548122406, acc: 0.9722222089767456)
[2024-12-14 02:56:50,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:50,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:50,662][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.18872423470020294, acc: 0.9210526347160339)
[2024-12-14 02:56:50,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:50,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:51,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:51,037][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.005029621999710798, acc: 1.0)
[2024-12-14 02:56:51,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:51,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:51,564][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 1.174241065979004, acc: 0.6762589812278748)
                                                                                [2024-12-14 02:56:51,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:51,905][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 1.6150842905044556, acc: 0.5628140568733215)
[2024-12-14 02:56:52,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:52,263][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.18280009925365448, acc: 0.9722222089767456)
                                                                                                                                                             [2024-12-14 02:56:52,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:52,631][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.2613585591316223, acc: 0.939393937587738)
                                                                                [2024-12-14 02:56:52,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:52,990][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.6170045137405396, acc: 0.8888888955116272)
[2024-12-14 02:56:53,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:53,366][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.11203622817993164, acc: 0.949999988079071)
                                                                               [2024-12-14 02:56:53,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:53,710][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.22111301124095917, acc: 0.949999988079071)
                                                                              [2024-12-14 02:56:53,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:54,125][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.3799287974834442, acc: 0.8793103694915771)
                                                                               [2024-12-14 02:56:54,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:54,473][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.17805516719818115, acc: 0.9354838728904724)
                                                                              [2024-12-14 02:56:54,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:54,790][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.0589347779750824, acc: 1.0)
                                                                                               [2024-12-14 02:56:54,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:55,144][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.5337416529655457, acc: 0.8888888955116272)
                                                                                [2024-12-14 02:56:55,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:55,522][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.21689635515213013, acc: 0.9047619104385376)
[2024-12-14 02:56:55,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:55,895][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.17617632448673248, acc: 0.9090909361839294)
                                                                              [2024-12-14 02:56:56,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:56,253][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.6806414127349854, acc: 0.8769230842590332)
                                                                                                                                                              [2024-12-14 02:56:56,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:56,430][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.272137850522995, acc: 0.939393937587738)
[2024-12-14 02:56:56,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:56,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:56,776][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.17184585332870483, acc: 0.939393937587738)
[2024-12-14 02:56:56,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:57,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:57,139][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.11242778599262238, acc: 0.9677419066429138)
[2024-12-14 02:56:57,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:57,483][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.29269346594810486, acc: 0.8888888955116272)
[2024-12-14 02:56:57,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:57,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:57,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:57,850][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.08487647026777267, acc: 0.9599999785423279)
[2024-12-14 02:56:57,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:58,184][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.11982875317335129, acc: 0.9722222089767456)
[2024-12-14 02:56:58,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:58,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:58,501][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.0826496034860611, acc: 0.9629629850387573)
[2024-12-14 02:56:58,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:58,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:58,867][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.1032293364405632, acc: 0.9615384340286255)
[2024-12-14 02:56:58,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:58,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:59,208][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.5035706162452698, acc: 0.8793103694915771)
[2024-12-14 02:56:59,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:59,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:59,572][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.3460620939731598, acc: 0.9642857313156128)
[2024-12-14 02:56:59,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:59,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:56:59,951][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.170625239610672, acc: 0.9333333373069763)
[2024-12-14 02:57:00,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:00,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:00,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:00,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:00,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:01,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:01,283][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                   [2024-12-14 02:57:01,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:01,570][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:57:01,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:01,961][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.5325152277946472, acc: 0.8301886916160583)
[2024-12-14 02:57:02,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:02,290][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.33328694105148315, acc: 0.931034505367279)
[2024-12-14 02:57:02,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:02,871][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 1.1170454025268555, acc: 0.6576576828956604)
[2024-12-14 02:57:03,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:03,321][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.7485069036483765, acc: 0.8169013857841492)
[2024-12-14 02:57:03,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:03,637][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.1579214185476303, acc: 0.949999988079071)
[2024-12-14 02:57:03,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:03,964][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.6011195778846741, acc: 0.9333333373069763)
[2024-12-14 02:57:04,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:04,242][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.14188984036445618, acc: 0.9230769276618958)
                                                                                                                  [2024-12-14 02:57:05,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:06,964][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 1.4472039937973022, acc: 0.5857142806053162)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:57:07,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:07,726][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 1.0258734226226807, acc: 0.6746031641960144)
[2024-12-14 02:57:07,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:07,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:07,391][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.2633614242076874, acc: 0.8799999952316284)
[2024-12-14 02:57:07,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:07,733][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.38473960757255554, acc: 0.8936170339584351)
[2024-12-14 02:57:07,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:08,104][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.6103797554969788, acc: 0.7916666865348816)
[2024-12-14 02:57:08,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:08,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:08,430][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.4711703062057495, acc: 0.8863636255264282)
[2024-12-14 02:57:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:08,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:08,839][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 1.053084135055542, acc: 0.6987951993942261)
[2024-12-14 02:57:08,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:09,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:09,166][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 1.115212082862854, acc: 0.7222222089767456)
[2024-12-14 02:57:09,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:09,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:09,537][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.3055962324142456, acc: 0.9210526347160339)
[2024-12-14 02:57:09,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:09,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:09,875][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.4521521329879761, acc: 0.970588207244873)
[2024-12-14 02:57:09,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:10,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:10,199][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.2124032974243164, acc: 0.925000011920929)
[2024-12-14 02:57:10,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:10,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:10,462][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 1.2940243482589722, acc: 0.6171875)
[2024-12-14 02:57:10,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:10,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:10,796][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 1.3560463190078735, acc: 0.6079999804496765)
[2024-12-14 02:57:10,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:11,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:11,135][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 1.0904814004898071, acc: 0.6813187003135681)
[2024-12-14 02:57:11,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:11,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:11,474][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 1.5896868705749512, acc: 0.5776397585868835)
[2024-12-14 02:57:11,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:11,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:11,935][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 1.0587328672409058, acc: 0.6641790866851807)
                                                                              [2024-12-14 02:57:12,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:12,302][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 1.3544931411743164, acc: 0.6131386756896973)
 [2024-12-14 02:57:12,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:12,863][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 1.456466555595398, acc: 0.5899999737739563)
                                                                                                                                                                                                                                                                                                        [2024-12-14 02:57:12,977][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 02:57:13,208][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.42335498332977295, acc: 0.8518518805503845)
                                                                              [2024-12-14 02:57:13,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:13,568][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.5126693248748779, acc: 0.8461538553237915)
[2024-12-14 02:57:13,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:13,903][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.39356178045272827, acc: 0.8571428656578064)
[2024-12-14 02:57:13,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:14,216][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.49722057580947876, acc: 0.8196721076965332)
[2024-12-14 02:57:14,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:14,579][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.4012828767299652, acc: 0.8813559412956238)
                                                                              [2024-12-14 02:57:14,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:14,921][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.5931540131568909, acc: 0.8139534592628479)
                                                                               [2024-12-14 02:57:15,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:15,290][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.3530489206314087, acc: 0.9318181872367859)
                                                                                [2024-12-14 02:57:15,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:15,666][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.5064035654067993, acc: 0.9056603908538818)
                                                                  [2024-12-14 02:57:15,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:15,996][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.23493395745754242, acc: 0.9318181872367859)
                                                                               [2024-12-14 02:57:16,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:16,329][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.11116384714841843, acc: 0.9599999785423279)
                                                                               [2024-12-14 02:57:16,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:16,723][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.3884410262107849, acc: 0.8500000238418579)
                                                                               [2024-12-14 02:57:16,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:17,053][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.1758166402578354, acc: 0.9090909361839294)
                                                                    [2024-12-14 02:57:17,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:17,446][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.3859565854072571, acc: 0.8769230842590332)
                                                                                                                                                              [2024-12-14 02:57:17,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:17,845][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.6860732436180115, acc: 0.8125)
                                                                                                                                                                           [2024-12-14 02:57:17,973][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                          [2024-12-14 02:57:18,245][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.1801706999540329, acc: 0.9375)
[2024-12-14 02:57:18,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:18,586][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.36506789922714233, acc: 0.8787878751754761)
[2024-12-14 02:57:18,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:18,902][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.04899032041430473, acc: 1.0)
[2024-12-14 02:57:18,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:19,190][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.22201186418533325, acc: 0.9354838728904724)
[2024-12-14 02:57:19,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:19,491][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.3059498071670532, acc: 0.95652174949646)
[2024-12-14 02:57:19,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:19,772][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.5278685092926025, acc: 0.8666666746139526)
  [2024-12-14 02:57:19,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:20,142][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.21296504139900208, acc: 0.9024389982223511)
                                                                              [2024-12-14 02:57:20,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:20,469][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.08113159239292145, acc: 1.0)
                                                                                                                                                                             [2024-12-14 02:57:20,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:20,835][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.2509671151638031, acc: 0.9210526347160339)
                                                                  [2024-12-14 02:57:20,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:21,182][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.04497748985886574, acc: 1.0)
               [2024-12-14 02:57:21,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:21,515][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.057402241975069046, acc: 1.0)
                                                                                                                                                                            [2024-12-14 02:57:21,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:21,874][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.25396010279655457, acc: 0.9696969985961914)
2024-12-14 02:57:21,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:21,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:22,039][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.654149055480957, acc: 0.7788461446762085)
[2024-12-14 02:57:22,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:22,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:22,414][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.1984807699918747, acc: 0.9555555582046509)
[2024-12-14 02:57:22,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:22,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:22,756][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.318446546792984, acc: 0.8870967626571655)
[2024-12-14 02:57:22,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:22,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:23,101][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.2152976095676422, acc: 0.9200000166893005)
[2024-12-14 02:57:23,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:23,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:23,437][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.525537371635437, acc: 0.8518518805503845)
[2024-12-14 02:57:23,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:23,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:23,811][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.5653790235519409, acc: 0.800000011920929)
[2024-12-14 02:57:23,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:23,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:24,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:24,200][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.6305042505264282, acc: 0.8205128312110901)
[2024-12-14 02:57:24,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:24,550][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 0.5258779525756836, acc: 0.8292682766914368)
[2024-12-14 02:57:24,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:24,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:24,879][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.35654187202453613, acc: 0.8947368264198303)
[2024-12-14 02:57:24,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:25,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:25,167][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.1881471574306488, acc: 0.9473684430122375)
[2024-12-14 02:57:25,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:25,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:25,477][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.024944914504885674, acc: 1.0)
[2024-12-14 02:57:25,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:25,781][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.17232273519039154, acc: 0.9259259104728699)
[2024-12-14 02:57:25,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:25,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:26,168][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.2452743500471115, acc: 0.90625)
[2024-12-14 02:57:26,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:26,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:26,630][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.46899956464767456, acc: 0.8387096524238586)
[2024-12-14 02:57:26,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:26,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:26,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:26,922][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.5307466387748718, acc: 0.859649121761322)
[2024-12-14 02:57:27,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:27,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:27,279][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.4382854402065277, acc: 0.90625)
[2024-12-14 02:57:27,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:27,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:27,615][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.40637004375457764, acc: 0.8999999761581421)
[2024-12-14 02:57:27,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:27,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:27,902][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.2176647186279297, acc: 0.9473684430122375)
[2024-12-14 02:57:28,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:28,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:28,283][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.5764502882957458, acc: 0.8600000143051147)
[2024-12-14 02:57:28,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:28,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:28,693][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 1.2304919958114624, acc: 0.5977011322975159)
[2024-12-14 02:57:28,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:28,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:29,061][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 0.975716233253479, acc: 0.7553191781044006)
[2024-12-14 02:57:29,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:29,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:29,388][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 1.1818411350250244, acc: 0.6144578456878662)
[2024-12-14 02:57:29,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:29,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:29,693][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.1565878540277481, acc: 0.95652174949646)
[2024-12-14 02:57:29,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:29,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:30,062][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.24468547105789185, acc: 0.9487179517745972)
[2024-12-14 02:57:30,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:30,462][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.5967413783073425, acc: 0.7951807379722595)
[2024-12-14 02:57:30,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:30,646][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.1519, device='cuda:0') eval_epoch_loss=tensor(2.0982, device='cuda:0') eval_epoch_acc=tensor(0.5653, device='cuda:0')
[2024-12-14 02:57:30,647][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:57:30,647][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:57:30,819][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.3980104923248291, acc: 0.8867924809455872)
[2024-12-14 02:57:30,873][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_9_step_413_loss_2.098245143890381/model.pt
[2024-12-14 02:57:30,876][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:57:30,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:30,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:31,155][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.48373809456825256, acc: 0.8607594966888428)
[2024-12-14 02:57:31,218][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.10791274160146713, acc: 0.9696969985961914)
[2024-12-14 02:57:31,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:31,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:31,505][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.1411595493555069, acc: 0.9545454382896423)
[2024-12-14 02:57:31,524][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.2938190996646881, acc: 0.9411764740943909)
[2024-12-14 02:57:31,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:31,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:31,868][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.609698474407196, acc: 0.8235294222831726)
[2024-12-14 02:57:31,897][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.5579687356948853, acc: 0.8358209133148193)
[2024-12-14 02:57:31,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:31,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:32,197][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.4719424545764923, acc: 0.7692307829856873)
[2024-12-14 02:57:32,268][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.07430599629878998, acc: 1.0)
[2024-12-14 02:57:32,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:32,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:32,510][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.3240911364555359, acc: 0.8888888955116272)
[2024-12-14 02:57:32,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:32,611][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.10562082380056381, acc: 0.9599999785423279)
[2024-12-14 02:57:32,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:32,849][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.21534974873065948, acc: 0.9750000238418579)
[2024-12-14 02:57:32,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:33,025][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.3918550908565521, acc: 0.8333333134651184)
[2024-12-14 02:57:33,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:33,147][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.044105928391218185, acc: 1.0)
[2024-12-14 02:57:33,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:33,386][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.906123161315918, acc: 0.6744186282157898)
[2024-12-14 02:57:33,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:33,496][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.019162418320775032, acc: 1.0)
[2024-12-14 02:57:33,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:33,737][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.4537045359611511, acc: 0.8717948794364929)
[2024-12-14 02:57:33,876][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.1465386003255844, acc: 0.9333333373069763)
[2024-12-14 02:57:33,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:34,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:34,186][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.6144195199012756, acc: 0.800000011920929)
[2024-12-14 02:57:34,217][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.20966167747974396, acc: 0.90625)
[2024-12-14 02:57:34,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:34,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:34,559][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.05907439813017845, acc: 1.0)
[2024-12-14 02:57:34,592][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.442715048789978, acc: 0.9722222089767456)
[2024-12-14 02:57:34,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:34,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:34,853][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.21090181171894073, acc: 0.9230769276618958)
[2024-12-14 02:57:34,954][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.03376777097582817, acc: 1.0)
[2024-12-14 02:57:34,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:35,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:35,217][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 1.1360955238342285, acc: 0.6593406796455383)
[2024-12-14 02:57:35,327][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.23324976861476898, acc: 0.9696969985961914)
[2024-12-14 02:57:35,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:35,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:35,630][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.4465326964855194, acc: 0.8695651888847351)
[2024-12-14 02:57:35,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:35,785][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 1.2292814254760742, acc: 0.7217391133308411)
[2024-12-14 02:57:35,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:35,956][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.21235837042331696, acc: 0.9729729890823364)
[2024-12-14 02:57:36,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:36,165][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 1.076491355895996, acc: 0.70652174949646)
[2024-12-14 02:57:36,189][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.08195605874061584, acc: 1.0)
[2024-12-14 02:57:36,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:36,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:36,484][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.616920530796051, acc: 0.8571428656578064)
[2024-12-14 02:57:36,534][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.10989051312208176, acc: 0.95652174949646)
[2024-12-14 02:57:36,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:36,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:36,844][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.01374597568064928, acc: 1.0)
[2024-12-14 02:57:36,864][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.004151743836700916, acc: 1.0)
[2024-12-14 02:57:36,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:36,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:37,137][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.1481504589319229, acc: 0.9230769276618958)
[2024-12-14 02:57:37,147][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.020929722115397453, acc: 1.0)
[2024-12-14 02:57:37,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:37,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:37,457][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.13614055514335632, acc: 0.95652174949646)
[2024-12-14 02:57:37,482][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.3970109522342682, acc: 0.9024389982223511)
[2024-12-14 02:57:37,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:37,997][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:57:38,365][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:57:38,778][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2024-12-14 02:57:39,181][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:57:39,544][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:57:39,924][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 02:57:40,303][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                    [2024-12-14 02:57:40,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:41,047][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:57:41,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:41,474][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 1.421079397201538, acc: 0.5806451439857483)
[2024-12-14 02:57:41,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:41,701][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 1.046331524848938, acc: 0.6886792182922363)
[2024-12-14 02:57:41,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:42,060][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.7232189774513245, acc: 0.7777777910232544)
[2024-12-14 02:57:42,122][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 1.4445817470550537, acc: 0.6019900441169739)
[2024-12-14 02:57:42,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:42,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:42,412][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.6547456979751587, acc: 0.7678571343421936)
[2024-12-14 02:57:42,453][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.42842286825180054, acc: 0.8867924809455872)
[2024-12-14 02:57:42,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:42,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:42,800][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.2727423906326294, acc: 0.9428571462631226)
[2024-12-14 02:57:42,862][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.30422091484069824, acc: 0.9090909361839294)
[2024-12-14 02:57:42,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:42,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:43,128][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.01427267212420702, acc: 1.0)
[2024-12-14 02:57:43,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:43,236][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.05573432892560959, acc: 1.0)
[2024-12-14 02:57:43,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:43,472][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.031991664320230484, acc: 1.0)
[2024-12-14 02:57:43,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:43,607][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.20068120956420898, acc: 0.9230769276618958)
[2024-12-14 02:57:43,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:43,871][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.3829474151134491, acc: 0.9166666865348816)
[2024-12-14 02:57:43,908][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.05809777230024338, acc: 1.0)
[2024-12-14 02:57:43,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:43,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:44,270][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.5366681218147278, acc: 0.8507462739944458)
[2024-12-14 02:57:44,292][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.6865883469581604, acc: 0.7894737124443054)
[2024-12-14 02:57:44,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:44,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:44,677][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.5018793344497681, acc: 0.8611111044883728)
[2024-12-14 02:57:44,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:44,869][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 1.0982320308685303, acc: 0.688622772693634)
[2024-12-14 02:57:44,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:45,018][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.5667311549186707, acc: 0.8152173757553101)
[2024-12-14 02:57:45,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:45,280][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.8162582516670227, acc: 0.7744361162185669)
[2024-12-14 02:57:45,485][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 02:57:45,757][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                       [2024-12-14 02:57:46,080][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:57:46,523][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 02:57:47,048][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 02:57:47,395][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:57:47,838][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:57:48,290][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:57:48,607][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:57:49,083][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.23377808928489685, acc: 0.9375)
[2024-12-14 02:57:48,905][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.21066272258758545, acc: 0.9210526347160339)
[2024-12-14 02:57:48,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:48,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:49,172][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.2042720466852188, acc: 0.9230769276618958)
[2024-12-14 02:57:49,255][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.011381187476217747, acc: 1.0)
[2024-12-14 02:57:49,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:49,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:49,549][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.1541251540184021, acc: 0.97826087474823)
[2024-12-14 02:57:49,602][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.012203561142086983, acc: 1.0)
[2024-12-14 02:57:49,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:49,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:49,843][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.5002598166465759, acc: 0.8571428656578064)
[2024-12-14 02:57:49,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:50,004][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.047008465975522995, acc: 1.0)
[2024-12-14 02:57:50,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:50,144][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.5857074856758118, acc: 0.7710843086242676)
[2024-12-14 02:57:50,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:50,351][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.6369067430496216, acc: 0.8148148059844971)
[2024-12-14 02:57:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:50,531][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.6441627740859985, acc: 0.8108108043670654)
[2024-12-14 02:57:50,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:50,754][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 1.3874175548553467, acc: 0.5922330021858215)
[2024-12-14 02:57:50,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:50,925][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 0.6922243237495422, acc: 0.7961165308952332)
[2024-12-14 02:57:51,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:51,276][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 1.3842099905014038, acc: 0.625)
[2024-12-14 02:57:51,308][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.7934839725494385, acc: 0.8048780560493469)
[2024-12-14 02:57:51,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:51,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:51,628][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.08141052722930908, acc: 0.9583333134651184)
[2024-12-14 02:57:51,656][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 1.4759000539779663, acc: 0.6000000238418579)
[2024-12-14 02:57:51,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:51,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:52,011][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.14551924169063568, acc: 0.9285714030265808)
[2024-12-14 02:57:52,029][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 1.313968539237976, acc: 0.6041666865348816)
[2024-12-14 02:57:52,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:52,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:52,364][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.5509542226791382, acc: 0.8604651093482971)
[2024-12-14 02:57:52,421][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 0.9935968518257141, acc: 0.6960784196853638)
[2024-12-14 02:57:52,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:52,717][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.21859805285930634, acc: 0.9166666865348816)
[2024-12-14 02:57:52,772][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 1.5428733825683594, acc: 0.5458515286445618)
[2024-12-14 02:57:52,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:52,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:53,077][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 0.7277841567993164, acc: 0.7708333134651184)
[2024-12-14 02:57:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:53,169][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.3254891633987427, acc: 0.9069767594337463)
[2024-12-14 02:57:53,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:53,413][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 1.140753149986267, acc: 0.6319018602371216)
[2024-12-14 02:57:53,519][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.13614410161972046, acc: 0.9599999785423279)
[2024-12-14 02:57:53,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:53,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:53,793][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 1.1533331871032715, acc: 0.6546762585639954)
[2024-12-14 02:57:53,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:54,055][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.5834855437278748, acc: 0.8529411554336548)
[2024-12-14 02:57:54,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:54,195][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 1.4896864891052246, acc: 0.572864294052124)
[2024-12-14 02:57:54,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:54,390][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.8446165919303894, acc: 0.7599999904632568)
[2024-12-14 02:57:54,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:54,575][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.20119664072990417, acc: 0.9444444179534912)
[2024-12-14 02:57:54,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:54,715][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.2995862364768982, acc: 0.8484848737716675)
[2024-12-14 02:57:54,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:54,945][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.23414750397205353, acc: 0.8787878751754761)
[2024-12-14 02:57:55,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:55,096][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.22240206599235535, acc: 0.939393937587738)
[2024-12-14 02:57:55,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:55,287][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.15609540045261383, acc: 0.9259259104728699)
[2024-12-14 02:57:55,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:55,468][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.022961677983403206, acc: 1.0)
[2024-12-14 02:57:55,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:55,659][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.4361744523048401, acc: 0.8999999761581421)
[2024-12-14 02:57:55,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:55,794][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.15985500812530518, acc: 0.9259259104728699)
    [2024-12-14 02:57:55,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:55,965][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.12755510210990906, acc: 0.949999988079071)
[2024-12-14 02:57:56,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:56,428][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.8216919302940369, acc: 0.752136766910553)
02:57:56,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:56,354][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.3512682318687439, acc: 0.8965517282485962)
[2024-12-14 02:57:56,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:56,459][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.10366348922252655, acc: 1.0)
[2024-12-14 02:57:56,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:56,699][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.09070246666669846, acc: 0.9677419066429138)
[2024-12-14 02:57:56,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:56,811][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.24428297579288483, acc: 0.8888888955116272)
[2024-12-14 02:57:56,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:57,023][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.10516531020402908, acc: 0.9473684430122375)
[2024-12-14 02:57:57,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:57,177][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.043283503502607346, acc: 1.0)
[2024-12-14 02:57:57,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:57,299][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.2751246690750122, acc: 0.9259259104728699)
[2024-12-14 02:57:57,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:57,541][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.3571826219558716, acc: 0.9137930870056152)
[2024-12-14 02:57:57,566][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.6988972425460815, acc: 0.761904776096344)
[2024-12-14 02:57:57,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:57,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:57,868][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.14852318167686462, acc: 0.9285714030265808)
[2024-12-14 02:57:57,919][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.14575093984603882, acc: 0.9545454382896423)
[2024-12-14 02:57:57,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:58,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:58,219][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.3281315267086029, acc: 0.8999999761581421)
[2024-12-14 02:57:58,252][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.5314444303512573, acc: 0.8615384697914124)
[2024-12-14 02:57:58,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:58,533][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.3642466962337494, acc: 0.8999999761581421)
[2024-12-14 02:57:58,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:58,915][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.15743252635002136, acc: 0.931034505367279)
[2024-12-14 02:57:58,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:59,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:59,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:59,275][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.43349796533584595, acc: 0.843137264251709)
[2024-12-14 02:57:59,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:59,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:59,616][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.3881577253341675, acc: 0.8965517282485962)
[2024-12-14 02:57:59,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:59,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:57:59,997][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.14186082780361176, acc: 0.9473684430122375)
[2024-12-14 02:58:00,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:00,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:00,334][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.3666757643222809, acc: 0.8421052694320679)
[2024-12-14 02:58:00,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:00,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:00,709][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.9462342262268066, acc: 0.7232142686843872)
[2024-12-14 02:58:00,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:00,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:01,142][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.7430015206336975, acc: 0.7640449404716492)
[2024-12-14 02:58:01,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:01,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:01,504][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 0.9616903066635132, acc: 0.7415730357170105)
[2024-12-14 02:58:01,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:01,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:01,883][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 1.3949437141418457, acc: 0.5815602540969849)
[2024-12-14 02:58:01,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:02,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:02,232][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.8909010887145996, acc: 0.717391312122345)
[2024-12-14 02:58:02,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:02,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:02,594][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.1883818656206131, acc: 0.9599999785423279)
[2024-12-14 02:58:02,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:02,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:02,994][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.0465923473238945, acc: 0.9615384340286255)
[2024-12-14 02:58:03,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:03,103][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                      [2024-12-14 02:58:03,355][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.4150767922401428, acc: 0.9259259104728699)
[2024-12-14 02:58:03,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:03,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:03,698][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.14618436992168427, acc: 0.9629629850387573)
[2024-12-14 02:58:03,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:04,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:04,053][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.5372567772865295, acc: 0.849056601524353)
[2024-12-14 02:58:04,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:04,425][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.4385558068752289, acc: 0.8965517282485962)
[2024-12-14 02:58:04,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:04,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:04,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:05,015][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 1.0463824272155762, acc: 0.684684693813324)
[2024-12-14 02:58:05,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:05,241][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.14671635627746582, acc: 0.9642857313156128)
[2024-12-14 02:58:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:05,788][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.5121452808380127, acc: 0.8367347121238708)
                                                                                                                                                                                                           [2024-12-14 02:58:05,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:06,172][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.4373685419559479, acc: 0.9333333373069763)
                                                                  [2024-12-14 02:58:06,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:06,555][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.029089324176311493, acc: 1.0)
                                                                                              [2024-12-14 02:58:06,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:06,918][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.04685930162668228, acc: 0.9615384340286255)
[2024-12-14 02:58:07,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:07,257][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.24584199488162994, acc: 0.9259259104728699)
[2024-12-14 02:58:07,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:07,614][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.2925901710987091, acc: 0.9487179517745972)
[2024-12-14 02:58:07,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:07,989][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.1562115103006363, acc: 0.9696969985961914)
[2024-12-14 02:58:08,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:08,368][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.40870463848114014, acc: 0.760869562625885)
[2024-12-14 02:58:08,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:08,750][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.45371055603027344, acc: 0.843137264251709)
[2024-12-14 02:58:08,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:09,147][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.5648031234741211, acc: 0.8571428656578064)
[2024-12-14 02:58:09,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:09,522][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.16817951202392578, acc: 0.8947368264198303)
[2024-12-14 02:58:09,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:09,868][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.09581037610769272, acc: 1.0)
[2024-12-14 02:58:09,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:10,177][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.2965294122695923, acc: 0.8333333134651184)
[2024-12-14 02:58:10,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:10,534][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.05675668641924858, acc: 0.9473684430122375)
[2024-12-14 02:58:10,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:10,866][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.3319796025753021, acc: 0.8846153616905212)
[2024-12-14 02:58:10,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:11,171][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.08105489611625671, acc: 1.0)
[2024-12-14 02:58:11,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:11,469][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.07079596817493439, acc: 1.0)
[2024-12-14 02:58:11,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:11,843][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.1898230016231537, acc: 0.9523809552192688)
[2024-12-14 02:58:11,945][slam_llm.models.slam_model][INFO] - modality encoder
                           [2024-12-14 02:58:12,201][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.11403559148311615, acc: 1.0)
                                   [2024-12-14 02:58:12,309][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 02:58:12,591][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.6336581110954285, acc: 0.7735849022865295)
[2024-12-14 02:58:12,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:12,932][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 1.0513708591461182, acc: 0.7123287916183472)
                     [2024-12-14 02:58:13,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:14,182][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 1.7663030624389648, acc: 0.5177865624427795)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:58:14,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:14,477][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.3119165301322937, acc: 0.9069767594337463)
[2024-12-14 02:58:14,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:14,808][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.9170622229576111, acc: 0.7228915691375732)
[2024-12-14 02:58:14,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:15,151][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.7580462098121643, acc: 0.7777777910232544)
[2024-12-14 02:58:15,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:15,468][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.12340755015611649, acc: 0.9642857313156128)
[2024-12-14 02:58:15,548][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                       [2024-12-14 02:58:15,768][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.3129040002822876, acc: 0.9259259104728699)
[2024-12-14 02:58:15,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:16,134][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.053314872086048126, acc: 1.0)
              [2024-12-14 02:58:16,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:16,522][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 1.1914950609207153, acc: 0.6554622054100037)
                                                                               [2024-12-14 02:58:16,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:16,875][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.5118377208709717, acc: 0.8196721076965332)
                                                                                                                                                               [2024-12-14 02:58:16,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:16,969][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.4891422688961029, acc: 0.8372092843055725)
[2024-12-14 02:58:17,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:17,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:17,323][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.42484357953071594, acc: 0.9090909361839294)
[2024-12-14 02:58:17,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:17,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:17,665][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.7309175133705139, acc: 0.849056601524353)
[2024-12-14 02:58:17,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:17,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:18,011][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.12274324148893356, acc: 1.0)
[2024-12-14 02:58:18,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:18,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:18,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:18,339][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.17048482596874237, acc: 0.9599999785423279)
[2024-12-14 02:58:18,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:18,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:18,742][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.09354670345783234, acc: 1.0)
[2024-12-14 02:58:18,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:19,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:19,049][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.1468971073627472, acc: 0.9545454382896423)
[2024-12-14 02:58:19,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:19,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:19,466][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.5608028769493103, acc: 0.7846153974533081)
[2024-12-14 02:58:19,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:19,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:19,856][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.5781160593032837, acc: 0.796875)
[2024-12-14 02:58:20,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:20,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:20,269][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.2023543119430542, acc: 1.0)
[2024-12-14 02:58:20,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:20,641][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.34798383712768555, acc: 0.8787878751754761)
[2024-12-14 02:58:20,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:20,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:21,007][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.0833163782954216, acc: 1.0)
[2024-12-14 02:58:21,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:21,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:21,380][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.2797911465167999, acc: 0.9354838728904724)
[2024-12-14 02:58:21,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:21,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:21,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:21,714][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.025171060115098953, acc: 1.0)
[2024-12-14 02:58:21,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:22,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:22,369][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.0696147158741951, acc: 0.9722222089767456)
                                                                                                                                                              [2024-12-14 02:58:22,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:22,757][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.38909295201301575, acc: 0.8245614171028137)
                                                                                                                                                                                                                         [2024-12-14 02:58:22,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:23,152][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.5639054179191589, acc: 0.8095238208770752)
                                                                                [2024-12-14 02:58:23,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:23,544][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.6770012378692627, acc: 0.8028169274330139)
[2024-12-14 02:58:23,710][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:58:24,013][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.341158390045166, acc: 0.6133333444595337)
                      [2024-12-14 02:58:24,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:24,396][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.3176693916320801, acc: 0.8648648858070374)
                                                                              [2024-12-14 02:58:24,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:24,818][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.052992306649684906, acc: 0.9615384340286255)
                                                                             [2024-12-14 02:58:26,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:27,807][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.5926951169967651, acc: 0.5904436707496643)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2024-12-14 02:58:28,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:28,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:28,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:28,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:28,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:28,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:28,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:28,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:29,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:29,446][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.3815, device='cuda:0') eval_epoch_loss=tensor(1.9990, device='cuda:0') eval_epoch_acc=tensor(0.5697, device='cuda:0')
[2024-12-14 02:58:29,447][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:58:29,447][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:58:29,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:29,771][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_9_step_413_loss_1.9989771842956543/model.pt
[2024-12-14 02:58:29,778][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:58:29,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:29,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:30,287][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.26571911573410034, acc: 0.8787878751754761)
[2024-12-14 02:58:30,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:30,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:30,627][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.027343906462192535, acc: 1.0)
[2024-12-14 02:58:30,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:30,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:30,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:31,039][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.48653444647789, acc: 0.843137264251709)
[2024-12-14 02:58:31,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:31,441][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.09843965619802475, acc: 1.0)
[2024-12-14 02:58:31,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:31,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:31,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:31,825][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.1675843745470047, acc: 0.9444444179534912)
[2024-12-14 02:58:31,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:32,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:32,195][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.24814128875732422, acc: 0.875)
[2024-12-14 02:58:32,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:32,510][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.10794514417648315, acc: 0.949999988079071)
[2024-12-14 02:58:32,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:32,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:32,821][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.015703808516263962, acc: 1.0)
[2024-12-14 02:58:32,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:33,213][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.362718790769577, acc: 0.8571428656578064)
/10, step 421/574 completed (loss: 0.18480239808559418, acc: 0.9666666388511658)
[2024-12-14 02:58:33,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:33,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:33,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:33,482][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.09505409747362137, acc: 0.96875)
[2024-12-14 02:58:33,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:33,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:33,859][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.21434134244918823, acc: 0.9444444179534912)
[2024-12-14 02:58:33,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:34,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:34,263][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.1365644484758377, acc: 0.9259259104728699)
[2024-12-14 02:58:34,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:34,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:34,630][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.3917357325553894, acc: 0.939393937587738)
[2024-12-14 02:58:34,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:34,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:35,018][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.0716841071844101, acc: 1.0)
[2024-12-14 02:58:35,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:35,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:35,379][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.1857193559408188, acc: 0.9459459185600281)
[2024-12-14 02:58:35,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:35,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:35,696][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.1151270717382431, acc: 0.9629629850387573)
[2024-12-14 02:58:35,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:35,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:36,004][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.3503422439098358, acc: 0.9130434989929199)
[2024-12-14 02:58:36,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:36,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:36,309][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.00742750708013773, acc: 1.0)
[2024-12-14 02:58:36,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:36,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:36,639][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.08912455290555954, acc: 0.9629629850387573)
[2024-12-14 02:58:36,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:36,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:36,910][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.13146579265594482, acc: 0.95652174949646)
[2024-12-14 02:58:37,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:37,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:37,340][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.38151562213897705, acc: 0.8333333134651184)
[2024-12-14 02:58:37,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:37,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:37,699][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.058629099279642105, acc: 0.9599999785423279)
[2024-12-14 02:58:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:37,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:38,219][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.1904790699481964, acc: 0.8787878751754761)
                                                                                                                                                            [2024-12-14 02:58:38,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:38,600][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.06179400905966759, acc: 0.9615384340286255)
                                                                               [2024-12-14 02:58:38,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:38,991][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.4384697377681732, acc: 0.8461538553237915)
[2024-12-14 02:58:39,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:39,389][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.7808306813240051, acc: 0.7692307829856873)
                                                                  [2024-12-14 02:58:39,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:39,743][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.30655136704444885, acc: 0.90625)
           [2024-12-14 02:58:39,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:40,083][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.5144482254981995, acc: 0.8550724387168884)
                                                                                                                                                              [2024-12-14 02:58:40,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:40,375][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.32348597049713135, acc: 0.9399999976158142)
[2024-12-14 02:58:40,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:40,765][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.15318365395069122, acc: 0.9130434989929199)
[2024-12-14 02:58:40,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:41,227][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.5164378881454468, acc: 0.8600000143051147)
[2024-12-14 02:58:41,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:41,589][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.46591028571128845, acc: 0.8058252334594727)
[2024-12-14 02:58:41,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:42,712][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 1.3499774932861328, acc: 0.6456310749053955)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:58:42,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:43,541][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 1.4133670330047607, acc: 0.6075268983840942)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 02:58:43,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:43,791][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.167130246758461, acc: 0.9285714030265808)
[2024-12-14 02:58:43,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:43,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:44,107][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.515194833278656, acc: 0.8656716346740723)
[2024-12-14 02:58:44,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:44,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:44,428][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.4026859998703003, acc: 0.8888888955116272)
[2024-12-14 02:58:44,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:44,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:44,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:44,798][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.6236562132835388, acc: 0.804347813129425)
[2024-12-14 02:58:44,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:45,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:45,161][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.6510207056999207, acc: 0.7692307829856873)
[2024-12-14 02:58:45,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:45,480][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.4674319624900818, acc: 0.8552631735801697)
[2024-12-14 02:58:45,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:45,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:45,859][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.3499416708946228, acc: 0.8979591727256775)
[2024-12-14 02:58:45,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:45,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:46,252][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.13656404614448547, acc: 0.939393937587738)
[2024-12-14 02:58:46,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:46,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:46,563][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 0.9752187728881836, acc: 0.7216494679450989)
[2024-12-14 02:58:46,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:46,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:46,885][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.49771571159362793, acc: 0.8142856955528259)
[2024-12-14 02:58:46,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:47,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:47,263][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 1.2199574708938599, acc: 0.6686046719551086)
[2024-12-14 02:58:47,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:47,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:47,595][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.6103297472000122, acc: 0.8035714030265808)
[2024-12-14 02:58:47,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:47,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:47,989][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 0.8438084125518799, acc: 0.7530864477157593)
[2024-12-14 02:58:48,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:48,383][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.26474881172180176, acc: 0.8888888955116272)
[2024-12-14 02:58:48,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:48,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:48,709][root][INFO] - Training Epoch: 9/1[2024-12-14 02:58:48,982][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.02671661786735058, acc: 1.0)
                       [2024-12-14 02:58:49,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:49,379][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.023608041927218437, acc: 1.0)
                                                                                            [2024-12-14 02:58:49,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:49,770][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.16901849210262299, acc: 0.9545454382896423)
                                                                                                                                                          [2024-12-14 02:58:49,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:50,127][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.47176042199134827, acc: 0.8103448152542114)
                                                                            [2024-12-14 02:58:50,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:50,482][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.40416133403778076, acc: 0.9069767594337463)
                                                                             [2024-12-14 02:58:50,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:50,858][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.22640106081962585, acc: 0.9200000166893005)
                                                                             [2024-12-14 02:58:50,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:51,247][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.00934881716966629, acc: 1.0)
                                                                                                                                                                           [2024-12-14 02:58:51,356][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 02:58:51,644][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.007577344309538603, acc: 1.0)
[2024-12-14 02:58:51,741][slam_llm.models.slam_model][INFO] - modality encoder
            [2024-12-14 02:58:51,991][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.11415371298789978, acc: 0.976190447807312)
[2024-12-14 02:58:52,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:52,403][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.5896202325820923, acc: 0.8307692408561707)
                    [2024-12-14 02:58:52,528][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 02:58:52,821][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.4950823485851288, acc: 0.859649121761322)
                                                                               [2024-12-14 02:58:52,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:53,175][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.46129700541496277, acc: 0.9298245906829834)
[2024-12-14 02:58:53,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:53,539][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.4089903235435486, acc: 0.8974359035491943)
       [2024-12-14 02:58:53,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:53,923][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.2667897045612335, acc: 0.9591836929321289)
024-12-14 02:58:53,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:53,907][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 1.2183198928833008, acc: 0.6402877569198608)
[2024-12-14 02:58:54,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:54,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:54,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:54,311][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 1.453985571861267, acc: 0.5577889680862427)
[2024-12-14 02:58:54,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:54,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:54,693][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.12960116565227509, acc: 1.0)
[2024-12-14 02:58:54,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:55,037][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.3293299376964569, acc: 0.939393937587738)
[2024-12-14 02:58:55,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:55,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:55,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:55,422][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.096662238240242, acc: 1.0)
[2024-12-14 02:58:55,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:55,815][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.07444702088832855, acc: 1.0)
[2024-12-14 02:58:55,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:55,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:56,170][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.20964393019676208, acc: 0.949999988079071)
[2024-12-14 02:58:56,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:56,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:56,583][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.3607952296733856, acc: 0.931034505367279)
[2024-12-14 02:58:56,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:56,917][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.09321227669715881, acc: 0.9677419066429138)
[2024-12-14 02:58:56,926][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.0643, device='cuda:0') eval_epoch_loss=tensor(1.9551, device='cuda:0') eval_epoch_acc=tensor(0.6053, device='cuda:0')
[2024-12-14 02:58:56,930][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:58:56,931][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:58:57,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:57,230][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_9_step_556_loss_1.9550602436065674/model.pt
[2024-12-14 02:58:57,236][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:58:57,257][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.09223423153162003, acc: 0.9473684430122375)
[2024-12-14 02:58:57,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:57,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:57,558][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.6163351535797119, acc: 0.8148148059844971)
[2024-12-14 02:58:57,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:57,697][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 1.174696922302246, acc: 0.6423841118812561)
[2024-12-14 02:58:57,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:57,857][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.16570690274238586, acc: 0.9523809552192688)
[2024-12-14 02:58:57,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:58,050][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.6666444540023804, acc: 0.7863247990608215)
[2024-12-14 02:58:58,136][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.11664766818284988, acc: 0.9545454382896423)
[2024-12-14 02:58:58,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:58,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:58,418][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.23642875254154205, acc: 0.9200000166893005)
[2024-12-14 02:58:58,473][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.5339125394821167, acc: 0.8461538553237915)
[2024-12-14 02:58:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:58,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:58,791][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.4517596960067749, acc: 0.8666666746139526)
[2024-12-14 02:58:58,795][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.12224081158638, acc: 1.0)
[2024-12-14 02:58:58,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:59,125][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.12525303661823273, acc: 0.931034505367279)
[2024-12-14 02:58:59,175][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.17133662104606628, acc: 0.9615384340286255)
[2024-12-14 02:58:59,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:59,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:59,489][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.4550512731075287, acc: 0.8823529481887817)
[2024-12-14 02:58:59,549][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.17435798048973083, acc: 0.9743589758872986)
[2024-12-14 02:58:59,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:59,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:58:59,860][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.11395235359668732, acc: 1.0)
[2024-12-14 02:58:59,928][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.5194196105003357, acc: 0.8111110925674438)
[2024-12-14 02:58:59,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:00,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:00,270][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.07391675561666489, acc: 0.9473684430122375)
[2024-12-14 02:59:00,306][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.3409361243247986, acc: 0.9350649118423462)
[2024-12-14 02:59:00,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:00,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:00,631][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.35644206404685974, acc: 0.8421052694320679)
[2024-12-14 02:59:00,695][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.18593108654022217, acc: 0.9583333134651184)
[2024-12-14 02:59:00,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:00,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:01,039][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.9047834277153015, acc: 0.7142857313156128)
[2024-12-14 02:59:01,067][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.2746029794216156, acc: 0.9137930870056152)
[2024-12-14 02:59:01,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:01,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:01,414][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.6692734360694885, acc: 0.773809552192688)
[2024-12-14 02:59:01,460][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.7853401899337769, acc: 0.7640449404716492)
[2024-12-14 02:59:01,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:01,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:01,790][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.33220532536506653, acc: 0.8684210777282715)
[2024-12-14 02:59:01,801][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 0.9513229131698608, acc: 0.7752808928489685)
[2024-12-14 02:59:01,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:01,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:02,126][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.1164700984954834, acc: 0.9259259104728699)
[2024-12-14 02:59:02,196][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 1.33195960521698, acc: 0.609929084777832)
[2024-12-14 02:59:02,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:02,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:02,535][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 1.3087273836135864, acc: 0.6577540040016174)
[2024-12-14 02:59:02,580][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.8277861475944519, acc: 0.79347825050354)
[2024-12-14 02:59:02,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:02,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:02,892][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.4008873403072357, acc: 0.9354838728904724)
[2024-12-14 02:59:02,898][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.04919486492872238, acc: 0.9599999785423279)
[2024-12-14 02:59:02,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:03,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:03,233][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.21980704367160797, acc: 0.8846153616905212)
[2024-12-14 02:59:03,242][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.6967251896858215, acc: 0.8290598392486572)
[2024-12-14 02:59:03,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:03,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:03,546][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.10120498389005661, acc: 0.9629629850387573)
[2024-12-14 02:59:03,550][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 1.3951444625854492, acc: 0.6173469424247742)
[2024-12-14 02:59:03,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:03,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:03,884][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 1.302459955215454, acc: 0.6226415038108826)
[2024-12-14 02:59:03,894][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.18205395340919495, acc: 0.9629629850387573)
[2024-12-14 02:59:03,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:04,393][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.48226529359817505, acc: 0.849056601524353)
[2024-12-14 02:59:04,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:04,338][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.7539, train_epoch_loss=0.5619, epoch time 358.1075793877244s
[2024-12-14 02:59:04,339][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 02:59:04,339][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 13 GB
[2024-12-14 02:59:04,339][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 02:59:04,339][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 26
[2024-12-14 02:59:04,339][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 02:59:04,572][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.4091130495071411, acc: 0.8965517282485962)
[2024-12-14 02:59:04,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:05,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:05,181][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 1.1404030323028564, acc: 0.6486486196517944)
[2024-12-14 02:59:05,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:05,351][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.11356145888566971, acc: 0.9629629850387573)
[2024-12-14 02:59:05,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:05,621][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.9331595301628113, acc: 0.7323943376541138)
[2024-12-14 02:59:05,661][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.1600082516670227, acc: 0.9599999785423279)
[2024-12-14 02:59:05,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:05,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:05,948][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.42500314116477966, acc: 0.837837815284729)
[2024-12-14 02:59:05,992][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.042929306626319885, acc: 1.0)
[2024-12-14 02:59:06,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:06,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:06,358][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.22189107537269592, acc: 0.9736841917037964)
[2024-12-14 02:59:06,380][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.08450114727020264, acc: 0.9666666388511658)
[2024-12-14 02:59:06,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:06,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:06,704][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.0864257961511612, acc: 0.9615384340286255)
[2024-12-14 02:59:06,731][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.2886284291744232, acc: 0.8918918967247009)
[2024-12-14 02:59:06,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:07,091][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.09158404916524887, acc: 1.0)
[2024-12-14 02:59:07,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:07,473][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.4530743658542633, acc: 0.8163265585899353)
[2024-12-14 02:59:07,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:07,758][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.10721025615930557, acc: 0.9666666388511658)
[2024-12-14 02:59:07,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:08,080][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.013783960603177547, acc: 1.0)
[2024-12-14 02:59:08,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:08,383][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.015415580943226814, acc: 1.0)
[2024-12-14 02:59:08,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:08,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:08,753][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.17540065944194794, acc: 0.9259259104728699)
[2024-12-14 02:59:08,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:09,159][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.21778416633605957, acc: 0.9743589758872986)
[2024-12-14 02:59:09,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:09,656][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.09315783530473709, acc: 1.0)
[2024-12-14 02:59:09,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:09,741][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 1.4625701904296875, acc: 0.5642856955528259)
[2024-12-14 02:59:09,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:09,968][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.2002599686384201, acc: 0.95652174949646)
[2024-12-14 02:59:10,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:10,374][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.2679203152656555, acc: 0.9215686321258545)
[2024-12-14 02:59:10,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:10,519][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 1.1780346632003784, acc: 0.682539701461792)
[2024-12-14 02:59:10,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:10,781][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.34547871351242065, acc: 0.8979591727256775)
[2024-12-14 02:59:10,846][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.14143672585487366, acc: 0.9642857313156128)
[2024-12-14 02:59:10,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:10,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:11,076][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.37681150436401367, acc: 0.9473684430122375)
[2024-12-14 02:59:11,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:11,248][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.32640865445137024, acc: 0.9333333373069763)
[2024-12-14 02:59:11,369][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.1345377117395401, acc: 0.9166666865348816)
[2024-12-14 02:59:11,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:11,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:11,647][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.3133641481399536, acc: 0.8611111044883728)
[2024-12-14 02:59:11,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:11,950][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.6020181179046631, acc: 0.8055555820465088)
[2024-12-14 02:59:11,954][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.04533900320529938, acc: 1.0)
[2024-12-14 02:59:12,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:12,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:12,269][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.030226776376366615, acc: 1.0)
[2024-12-14 02:59:12,286][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.32551729679107666, acc: 0.9230769276618958)
[2024-12-14 02:59:12,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:12,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:12,609][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.19854247570037842, acc: 0.931034505367279)
[2024-12-14 02:59:12,629][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.22333870828151703, acc: 0.9032257795333862)
[2024-12-14 02:59:12,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:12,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:12,967][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.09823931008577347, acc: 1.0)
[2024-12-14 02:59:12,982][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.11887987703084946, acc: 1.0)
[2024-12-14 02:59:13,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:13,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:13,317][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.10308922082185745, acc: 0.9523809552192688)
[2024-12-14 02:59:13,325][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.34759166836738586, acc: 0.9629629850387573)
[2024-12-14 02:59:13,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:13,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:13,688][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.22903576493263245, acc: 0.875)
[2024-12-14 02:59:13,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:14,073][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.44394558668136597, acc: 0.8679245114326477)
[2024-12-14 02:59:14,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:14,311][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 1.5981258153915405, acc: 0.5508474707603455)
[2024-12-14 02:59:14,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:14,460][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.6993171572685242, acc: 0.7808219194412231)
[2024-12-14 02:59:14,695][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 0.9045913219451904, acc: 0.7164179086685181)
[2024-12-14 02:59:14,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:14,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:15,059][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 1.0864394903182983, acc: 0.7080292105674744)
[2024-12-14 02:59:15,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:15,619][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 1.3950423002243042, acc: 0.6150000095367432)
[2024-12-14 02:59:15,675][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 1.7890172004699707, acc: 0.5098814368247986)
[2024-12-14 02:59:15,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:15,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:15,939][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.35454049706459045, acc: 0.9074074029922485)
[2024-12-14 02:59:15,967][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.4048100411891937, acc: 0.8837209343910217)
[2024-12-14 02:59:16,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:16,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:16,304][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.32103732228279114, acc: 0.9038461446762085)
[2024-12-14 02:59:16,349][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.6199221611022949, acc: 0.7831325531005859)
[2024-12-14 02:59:16,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:16,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:16,630][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.07532726228237152, acc: 1.0)
[2024-12-14 02:59:16,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:16,722][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.7182232737541199, acc: 0.7283950448036194)
[2024-12-14 02:59:16,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:16,967][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.5120564699172974, acc: 0.8360655903816223)
[2024-12-14 02:59:17,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:17,113][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.0570676326751709, acc: 0.9642857313156128)
[2024-12-14 02:59:17,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:17,303][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.4255408048629761, acc: 0.9152542352676392)
[2024-12-14 02:59:17,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:17,496][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.24811400473117828, acc: 0.9259259104728699)
[2024-12-14 02:59:17,754][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:59:18,129][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 02:59:18,484][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 02:59:18,745][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:59:19,058][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:59:19,423][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 02:59:19,779][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 02:59:20,150][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 02:59:20,471][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:59:20,855][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 02:59:21,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:21,259][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.6641582250595093, acc: 0.8307692408561707)
[2024-12-14 02:59:21,364][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.20193834602832794, acc: 0.939393937587738)
[2024-12-14 02:59:21,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:21,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:21,717][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.739318311214447, acc: 0.747474730014801)
[2024-12-14 02:59:21,743][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.012055905535817146, acc: 1.0)
[2024-12-14 02:59:21,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:21,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:22,067][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.09708274900913239, acc: 0.9354838728904724)
[2024-12-14 02:59:22,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:22,165][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.6520054936408997, acc: 0.7938144207000732)
[2024-12-14 02:59:22,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:22,398][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.008936921134591103, acc: 1.0)
[2024-12-14 02:59:22,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:22,577][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 1.0049816370010376, acc: 0.6691176295280457)
[2024-12-14 02:59:22,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:22,712][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.1876319944858551, acc: 0.9333333373069763)
[2024-12-14 02:59:22,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:22,925][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.10520687699317932, acc: 0.9615384340286255)
[2024-12-14 02:59:23,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:23,131][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.3699672818183899, acc: 0.8780487775802612)
[2024-12-14 02:59:23,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:23,257][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.03806672245264053, acc: 1.0)
[2024-12-14 02:59:23,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:23,503][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.10724891722202301, acc: 0.9714285731315613)
[2024-12-14 02:59:23,627][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.16356663405895233, acc: 0.9285714030265808)
[2024-12-14 02:59:23,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:23,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:23,910][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.3501070439815521, acc: 0.9473684430122375)
[2024-12-14 02:59:23,962][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.15572065114974976, acc: 0.9444444179534912)
[2024-12-14 02:59:24,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:24,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:24,278][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.3285770118236542, acc: 0.9122806787490845)
[2024-12-14 02:59:24,291][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.11509985476732254, acc: 0.9677419066429138)
[2024-12-14 02:59:24,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:24,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:24,728][slam_llm.models.slam_model][INFO] - modality encoder
leted (loss: 0.009332519955933094, acc: 1.0)
[2024-12-14 02:59:24,673][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.39077359437942505, acc: 0.8730158805847168)
[2024-12-14 02:59:24,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:24,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:25,047][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.24028030037879944, acc: 0.939393937587738)
[2024-12-14 02:59:25,080][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.5823404788970947, acc: 0.8309859037399292)
[2024-12-14 02:59:25,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:25,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:25,380][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.30678802728652954, acc: 0.925000011920929)
[2024-12-14 02:59:25,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:25,546][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.1743522882461548, acc: 0.6600000262260437)
[2024-12-14 02:59:25,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:25,702][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.2800291180610657, acc: 0.9285714030265808)
[2024-12-14 02:59:25,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:25,887][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.28242599964141846, acc: 0.8918918967247009)
[2024-12-14 02:59:25,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:26,037][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 1.1429643630981445, acc: 0.6861313581466675)
[2024-12-14 02:59:26,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:26,238][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.09923163056373596, acc: 0.9615384340286255)
[2024-12-14 02:59:26,440][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 0.8794713020324707, acc: 0.7103448510169983)
[2024-12-14 02:59:26,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:26,781][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 1.3395153284072876, acc: 0.6428571343421936)
[2024-12-14 02:59:27,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:27,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:27,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:28,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:28,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:28,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:29,283][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.4899280071258545, acc: 0.5836177468299866)
[2024-12-14 02:59:29,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:29,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:29,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:29,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:30,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:30,457][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 2.0995450019836426, acc: 0.4596949815750122)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 02:59:30,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:30,803][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:59:31,100][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 1.3103373050689697, acc: 0.6647727489471436)
[2024-12-14 02:59:31,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:31,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:31,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:31,672][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 1.0594990253448486, acc: 0.6911764740943909)
[2024-12-14 02:59:31,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:31,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:32,231][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 1.3049403429031372, acc: 0.5869565010070801)
[2024-12-14 02:59:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:32,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:32,644][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.8668710589408875, acc: 0.75)
[2024-12-14 02:59:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:32,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:33,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:33,051][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.03488754853606224, acc: 1.0)
[2024-12-14 02:59:33,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:33,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:33,457][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.26617762446403503, acc: 0.8888888955116272)
[2024-12-14 02:59:33,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:33,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:33,848][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.36129724979400635, acc: 0.890625)
[2024-12-14 02:59:33,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:33,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:34,209][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.17337174713611603, acc: 0.931034505367279)
[2024-12-14 02:59:34,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:34,584][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.47754716873168945, acc: 0.7857142686843872)
[2024-12-14 02:59:34,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:34,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:34,927][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.47525325417518616, acc: 0.8500000238418579)
[2024-12-14 02:59:35,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:35,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:35,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:35,325][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.06585154682397842, acc: 0.9599999785423279)
[2024-12-14 02:59:35,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:35,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:35,646][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.17255884408950806, acc: 0.9444444179534912)
[2024-12-14 02:59:35,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:35,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:36,039][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.2746458947658539, acc: 0.939393937587738)
[2024-12-14 02:59:36,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:36,376][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.2803311049938202, acc: 0.9032257795333862)
[2024-12-14 02:59:36,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:36,822][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.41795411705970764, acc: 0.8108108043670654)
[2024-12-14 02:59:36,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:37,352][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 1.0261441469192505, acc: 0.6842105388641357)
                                                                                                                                                                                                                                       [2024-12-14 02:59:37,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:37,728][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.9502832293510437, acc: 0.7164179086685181)
[2024-12-14 02:59:37,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:38,075][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 1.1163142919540405, acc: 0.6326530575752258)
                   [2024-12-14 02:59:38,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:38,577][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 1.0948542356491089, acc: 0.6595744490623474)
                                                                                                                                                                                                                                                                                                      [2024-12-14 02:59:38,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:38,937][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.5257036089897156, acc: 0.8428571224212646)
                                                                [2024-12-14 02:59:39,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:39,323][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.23629650473594666, acc: 0.8571428656578064)
                                                               [2024-12-14 02:59:39,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:39,688][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.13004519045352936, acc: 0.95652174949646)
[2024-12-14 02:59:39,779][slam_llm.models.slam_model][INFO] - modality encoder
 [2024-12-14 02:59:40,052][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.12742765247821808, acc: 0.9655172228813171)
[2024-12-14 02:59:40,162][slam_llm.models.slam_model][INFO] - modality encoder
                                                               [2024-12-14 02:59:40,404][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.31049662828445435, acc: 0.9347826242446899)
[2024-12-14 02:59:40,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:40,803][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.47958144545555115, acc: 0.8813559412956238)
                                                                                                [2024-12-14 02:59:40,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:41,187][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.4398578405380249, acc: 0.859649121761322)
                                                                                                                                                                                                             [2024-12-14 02:59:41,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:41,543][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.6591075658798218, acc: 0.7837837934494019)
[2024-12-14 02:59:41,615][slam_llm.models.slam_model][INFO] - modality encoder
2024-12-14 02:59:41,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:41,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:41,890][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.3974546492099762, acc: 0.8799999952316284)
[2024-12-14 02:59:41,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:41,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:42,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:42,268][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.23241005837917328, acc: 0.95652174949646)
[2024-12-14 02:59:42,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:42,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:42,743][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.4895201027393341, acc: 0.8199999928474426)
[2024-12-14 02:59:42,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:42,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:43,110][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.729730486869812, acc: 0.7475728392601013)
[2024-12-14 02:59:43,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:43,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:43,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:43,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:44,215][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 1.3547859191894531, acc: 0.6310679316520691)
[2024-12-14 02:59:44,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:44,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:44,545][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 02:59:44,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:45,033][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 1.4175965785980225, acc: 0.6182795763015747)
[2024-12-14 02:59:45,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:45,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:45,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:45,833][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 1.402215600013733, acc: 0.6465517282485962)
[2024-12-14 02:59:45,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:46,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:46,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:46,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:46,577][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.6659992337226868, acc: 0.7789473533630371)
[2024-12-14 02:59:46,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:46,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:47,325][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                        [2024-12-14 02:59:47,566][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 1.0769437551498413, acc: 0.6237623691558838)
 [2024-12-14 02:59:47,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:47,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:47,887][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.6277531385421753, acc: 0.7419354915618896)
[2024-12-14 02:59:47,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:48,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:48,257][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.6157048344612122, acc: 0.7681159377098083)
[[2024-12-14 02:59:48,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:48,615][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 0.7164982557296753, acc: 0.7941176295280457)
[2024-12-14 02:59:48,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:49,647][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 1.6399283409118652, acc: 0.534246563911438)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 02:59:49,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:49,940][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.23630648851394653, acc: 0.875)
                                                                                           [2024-12-14 02:59:50,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:50,246][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.4504812955856323, acc: 0.8518518805503845)
                                                                               [2024-12-14 02:59:50,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:50,521][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.5030513405799866, acc: 0.8214285969734192)
  [2024-12-14 02:59:50,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:51,063][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 0.8879445791244507, acc: 0.76106196641922)
                                                                                                                                                   [2024-12-14 02:59:51,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:51,409][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.6460264921188354, acc: 0.8405796885490417)
[2024-12-14 02:59:51,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:51,833][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.6322347521781921, acc: 0.8409090638160706)
                                                                                                                                                              [2024-12-14 02:59:52,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:52,742][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 1.3835965394973755, acc: 0.5572519302368164)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 02:59:52,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:53,412][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 1.1569503545761108, acc: 0.6074073910713196)
                                                                                                                                                                                                                                [2024-12-14 02:59:53,484][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.10563544183969498, acc: 0.976190447807312)
[2024-12-14 02:59:53,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:53,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:53,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:53,870][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.3826063573360443, acc: 0.9230769276618958)
[2024-12-14 02:59:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:54,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:54,282][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.43479809165000916, acc: 0.8771929740905762)
[2024-12-14 02:59:54,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:54,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:54,630][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.3110308051109314, acc: 0.9122806787490845)
[2024-12-14 02:59:54,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:54,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:55,035][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.1560649573802948, acc: 0.9743589758872986)
[2024-12-14 02:59:55,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:55,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:55,471][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.2535901963710785, acc: 0.9591836929321289)
[2024-12-14 02:59:55,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:55,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:55,863][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.006260999012738466, acc: 1.0)
[2024-12-14 02:59:55,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:56,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:56,235][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.5968342423439026, acc: 0.8095238208770752)
[2024-12-14 02:59:56,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:56,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:56,570][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.5954026579856873, acc: 0.8292682766914368)
[2024-12-14 02:59:56,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:56,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:56,973][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.3057797849178314, acc: 0.9032257795333862)
[2024-12-14 02:59:57,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:57,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:57,749][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.0836, device='cuda:0') eval_epoch_loss=tensor(1.9578, device='cuda:0') eval_epoch_acc=tensor(0.5984, device='cuda:0')
[2024-12-14 02:59:57,750][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 02:59:57,751][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 02:59:57,853][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 1.666513442993164, acc: 0.5589353442192078)
[2024-12-14 02:59:58,274][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 1.0517048835754395, acc: 0.6976743936538696)
][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_9_step_556_loss_1.957783818244934/model.pt
[2024-12-14 02:59:58,037][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 02:59:58,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:58,253][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.4131506681442261, acc: 0.8533333539962769)
[2024-12-14 02:59:58,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:58,449][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 1.2726449966430664, acc: 0.6158940196037292)
[2024-12-14 02:59:58,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:58,630][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.34730085730552673, acc: 0.9230769276618958)
[2024-12-14 02:59:58,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:58,839][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.7464191913604736, acc: 0.752136766910553)
[2024-12-14 02:59:58,923][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.07435689121484756, acc: 0.9583333134651184)
[2024-12-14 02:59:58,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:59,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:59,238][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.05947665870189667, acc: 0.9599999785423279)
[2024-12-14 02:59:59,255][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.24935822188854218, acc: 0.9473684430122375)
[2024-12-14 02:59:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:59,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:59,569][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.14122284948825836, acc: 0.9615384340286255)
[2024-12-14 02:59:59,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 02:59:59,667][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 1.2039698362350464, acc: 0.6134969592094421)
[2024-12-14 02:59:59,875][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.21037325263023376, acc: 0.9230769276618958)
[2024-12-14 02:59:59,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:00,213][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.38705360889434814, acc: 0.8461538553237915)
[2024-12-14 03:00:00,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:00,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:00,570][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.6096109747886658, acc: 0.8111110925674438)
[2024-12-14 03:00:00,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:00,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:00,917][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.42631980776786804, acc: 0.8831169009208679)
[2024-12-14 03:00:01,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:01,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:01,299][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.32762786746025085, acc: 0.9166666865348816)
[2024-12-14 03:00:01,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:01,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:01,661][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.26240894198417664, acc: 0.9137930870056152)
[2024-12-14 03:00:01,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:01,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:02,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:02,759][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.6523138880729675, acc: 0.8387096524238586)
2024-12-14 03:00:02,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:02,360][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.20162132382392883, acc: 0.9210526347160339)
[2024-12-14 03:00:02,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:02,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:02,714][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.0715833529829979, acc: 1.0)
[2024-12-14 03:00:02,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:02,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:03,149][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 1.2698585987091064, acc: 0.6791443824768066)
[2024-12-14 03:00:03,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:03,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:03,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:03,579][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.5001213550567627, acc: 0.8225806355476379)
[2024-12-14 03:00:03,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:03,958][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.7342143058776855, acc: 0.7863247990608215)
[2024-12-14 03:00:03,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:04,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:04,278][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 1.454702377319336, acc: 0.6275510191917419)
[2024-12-14 03:00:04,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:04,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:04,658][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 1.4050289392471313, acc: 0.5723270177841187)
[2024-12-14 03:00:04,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:05,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:05,075][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.7810, train_epoch_loss=0.5772, epoch time 360.1201820522547s
[2024-12-14 03:00:05,076][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 03:00:05,076][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 13 GB
[2024-12-14 03:00:05,076][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 03:00:05,076][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 26
[2024-12-14 03:00:05,076][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 03:00:05,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:05,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:05,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:06,032][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.04681382328271866, acc: 1.0)
                                                                          [2024-12-14 03:00:06,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:06,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:06,357][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.29996079206466675, acc: 0.8799999952316284)
[2024-12-14 03:00:06,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:06,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:06,733][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.48601213097572327, acc: 0.8108108043670654)
[2024-12-14 03:00:06,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:06,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:07,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:07,138][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.28151050209999084, acc: 0.8684210777282715)
[2024-12-14 03:00:07,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:07,586][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 1.4836434125900269, acc: 0.5905796885490417)
10, step 4/574 completed (loss: 0.22975197434425354, acc: 0.9189189076423645)
[2024-12-14 03:00:07,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:07,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:07,840][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.16352646052837372, acc: 0.9642857313156128)
[2024-12-14 03:00:07,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:08,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:08,235][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.6450848579406738, acc: 0.7755101919174194)
[2024-12-14 03:00:08,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:08,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:08,580][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.07350052148103714, acc: 1.0)
[2024-12-14 03:00:08,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:08,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:08,918][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.035815704613924026, acc: 1.0)
[2024-12-14 03:00:08,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:09,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:09,191][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.4528449773788452, acc: 0.8846153616905212)
[2024-12-14 03:00:09,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:09,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:09,504][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.2261854112148285, acc: 0.8888888955116272)
[2024-12-14 03:00:09,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:09,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:09,888][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.5593668818473816, acc: 0.8205128312110901)
[2024-12-14 03:00:09,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:10,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:10,275][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.4952572286128998, acc: 0.8181818127632141)
[2024-12-14 03:00:10,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:10,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:10,636][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.5707399249076843, acc: 0.8478260636329651)
[2024-12-14 03:00:10,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:10,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:10,987][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.33246877789497375, acc: 0.8823529481887817)
[2024-12-14 03:00:11,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:11,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:11,371][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.3667348623275757, acc: 0.8571428656578064)
[2024-12-14 03:00:11,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:11,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:11,747][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.014693427830934525, acc: 1.0)
[2024-12-14 03:00:11,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:11,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:12,139][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.22164945304393768, acc: 0.9166666865348816)
[2024-12-14 03:00:12,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:12,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:12,585][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.11390611529350281, acc: 0.9629629850387573)
[2024-12-14 03:00:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:12,993][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.16994239389896393, acc: 0.9599999785423279)
                                                                            [2024-12-14 03:00:13,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:13,381][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.2838227152824402, acc: 0.9615384340286255)
                                                                                                                                                              [2024-12-14 03:00:13,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:14,150][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.9062997698783875, acc: 0.739130437374115)
                                                                                                                                                                                                                                                                                                                                                                                      [2024-12-14 03:00:14,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:14,690][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 1.1790720224380493, acc: 0.6193181872367859)
                                                                                                                                                                                             [2024-12-14 03:00:14,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:15,123][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.8631436228752136, acc: 0.7127659320831299)
                                                                                                                                                             [2024-12-14 03:00:15,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:15,483][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.3281695544719696, acc: 0.9056603908538818)
                                                                              [2024-12-14 03:00:15,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:15,893][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.4758327603340149, acc: 0.8666666746139526)
[2024-12-14 03:00:16,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:16,309][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.2240346372127533, acc: 0.9534883499145508)
[2024-12-14 03:00:16,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:16,623][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.22245948016643524, acc: 0.8999999761581421)
[2024-12-14 03:00:16,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:17,002][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 0.9083605408668518, acc: 0.800000011920929)
                                                                               [2024-12-14 03:00:17,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:17,305][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.7948222756385803, acc: 0.7666666507720947)
[2024-12-14 03:00:17,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:17,754][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 0.7189401388168335, acc: 0.8055555820465088)
                                                                                                                                                           [2024-12-14 03:00:17,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:18,245][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 1.2930179834365845, acc: 0.6559633016586304)
2024-12-14 03:00:17,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:18,131][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.15242385864257812, acc: 0.9642857313156128)
[2024-12-14 03:00:18,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:18,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:18,423][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.15139137208461761, acc: 0.9259259104728699)
[2024-12-14 03:00:18,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:18,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:18,816][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.02778494544327259, acc: 1.0)
[2024-12-14 03:00:18,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:18,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:19,191][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 1.000025749206543, acc: 0.6554622054100037)
[2024-12-14 03:00:19,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:19,317][slam_llm.models.slam_model][INFO] - modality encoder
   [2024-12-14 03:00:19,601][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.3457713723182678, acc: 0.8852459192276001)
[2024-12-14 03:00:19,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:19,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:20,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:20,024][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.4735417068004608, acc: 0.8571428656578064)
[2024-12-14 03:00:20,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:20,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:20,390][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.3633693754673004, acc: 0.9152542352676392)
[2024-12-14 03:00:20,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:20,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:20,800][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.42765146493911743, acc: 0.8505747318267822)
[2024-12-14 03:00:20,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:21,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:21,127][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.05118270218372345, acc: 1.0)
[2024-12-14 03:00:21,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:21,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:21,510][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.6178330779075623, acc: 0.8846153616905212)
[2024-12-14 03:00:21,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:21,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:21,896][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.6095159649848938, acc: 0.8513513803482056)
[2024-12-14 03:00:21,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:22,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:22,269][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.696114182472229, acc: 0.7692307829856873)
[2024-12-14 03:00:22,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:22,702][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.9039192795753479, acc: 0.7373737096786499)
[2024-12-14 03:00:22,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:22,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:23,239][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.16772684454917908, acc: 0.96774190650623)
[2024-12-14 03:00:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:23,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:23,547][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 0.8588908910751343, acc: 0.7426470518112183)
[2024-12-14 03:00:23,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:23,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:23,838][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.15082839131355286, acc: 0.9615384340286255)
[2024-12-14 03:00:23,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:23,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:24,194][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.022901037707924843, acc: 1.0)
[2024-12-14 03:00:24,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:24,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:24,571][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.45351463556289673, acc: 0.8571428656578064)
[2024-12-14 03:00:24,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:24,965][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.14952053129673004, acc: 0.9722222089767456)
[2024-12-14 03:00:25,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:25,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:25,369][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.4836367666721344, acc: 0.8421052694320679)
[2024-12-14 03:00:25,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:25,701][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.6118729114532471, acc: 0.7777777910232544)
[2024-12-14 03:00:25,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:25,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:26,048][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.8871553540229797, acc: 0.7323943376541138)
[2024-12-14 03:00:26,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:26,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:26,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:26,505][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.3847464323043823, acc: 0.5866666436195374)
[2024-12-14 03:00:26,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:26,825][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.2736842930316925, acc: 0.9189189076423645)
[2024-12-14 03:00:26,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:26,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:27,166][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.08155035972595215, acc: 1.0)
[2024-12-14 03:00:27,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:27,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:27,924][slam_llm.models.slam_model][INFO] - modality encoder
                                                                         [2024-12-14 03:00:28,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:28,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:28,724][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 03:00:28,888][slam_llm.models.slam_model][INFO] - modality encoder
                                                            [2024-12-14 03:00:29,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:29,216][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.2642377018928528, acc: 0.9354838728904724)
[2024-12-14 03:00:29,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:29,547][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.7012022137641907, acc: 0.7866666913032532)
[2024-12-14 03:00:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:29,915][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.39606335759162903, acc: 0.8541666865348816)
[2024-12-14 03:00:30,134][slam_llm.models.slam_model][INFO] - modality encoder
                                                                             [2024-12-14 03:00:30,744][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 1.3691630363464355, acc: 0.656000018119812)
                     [2024-12-14 03:00:30,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:31,051][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.6897101402282715, acc: 0.7752808928489685)
[2024-12-14 03:00:31,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:31,423][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.850882351398468, acc: 0.662162184715271)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 03:00:32,254][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 03:00:32,630][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 03:00:33,051][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 03:00:33,389][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                 [2024-12-14 03:00:33,767][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.27519798278808594, acc: 0.8846153616905212)
[2024-12-14 03:00:33,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:33,784][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.8981706500053406, acc: 0.737500011920929)
[2024-12-14 03:00:33,842][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.1906706988811493, acc: 0.9130434989929199)
[2024-12-14 03:00:33,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:33,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:34,166][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.19286935031414032, acc: 0.96875)
[2024-12-14 03:00:34,178][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.16722756624221802, acc: 0.970588207244873)
[2024-12-14 03:00:34,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:34,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:34,504][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.09301169961690903, acc: 0.95652174949646)
[2024-12-14 03:00:34,604][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.3364645838737488, acc: 0.8888888955116272)
[2024-12-14 03:00:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:34,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:34,841][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.31497758626937866, acc: 0.8857142925262451)
[2024-12-14 03:00:34,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:34,980][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.31459516286849976, acc: 0.890625)
[2024-12-14 03:00:35,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:35,151][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.11752515286207199, acc: 0.9615384340286255)
[2024-12-14 03:00:35,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:35,325][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.03429673612117767, acc: 1.0)
[2024-12-14 03:00:35,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:35,507][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.21235907077789307, acc: 0.9285714030265808)
[2024-12-14 03:00:35,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:35,717][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.4007400572299957, acc: 0.8928571343421936)
[2024-12-14 03:00:35,850][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.44482123851776123, acc: 0.8333333134651184)
[2024-12-14 03:00:35,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:35,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:36,122][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.4157564640045166, acc: 0.8260869383811951)
[2024-12-14 03:00:36,124][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.5095463991165161, acc: 0.8500000238418579)
[2024-12-14 03:00:36,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:36,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:36,478][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.08797425776720047, acc: 1.0)
[2024-12-14 03:00:36,492][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.03630995750427246, acc: 1.0)
[2024-12-14 03:00:36,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:36,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:36,809][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.30320945382118225, acc: 0.9166666865348816)
[2024-12-14 03:00:37,050][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.1882091462612152, acc: 0.9615384340286255)
[2024-12-14 03:00:36,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:36,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:37,174][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.17438249289989471, acc: 0.9696969985961914)
[2024-12-14 03:00:37,203][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.4540269672870636, acc: 0.8387096524238586)
[2024-12-14 03:00:37,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:37,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:37,526][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.35314035415649414, acc: 0.8918918967247009)
[2024-12-14 03:00:37,586][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 1.1923372745513916, acc: 0.6838235259056091)
[2024-12-14 03:00:37,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:37,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:37,930][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 1.1743935346603394, acc: 0.6904761791229248)
[2024-12-14 03:00:38,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:38,047][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 1.0115281343460083, acc: 0.6140350699424744)
[2024-12-14 03:00:38,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:38,247][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 1.6632925271987915, acc: 0.5743589997291565)
[2024-12-14 03:00:38,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:38,456][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.8332240581512451, acc: 0.7238805890083313)
[2024-12-14 03:00:38,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:38,607][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.7633872628211975, acc: 0.7755101919174194)
[2024-12-14 03:00:38,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:38,832][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 0.9341583251953125, acc: 0.6938775777816772)
[2024-12-14 03:00:38,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:39,024][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 1.414534091949463, acc: 0.60447758436203)
[2024-12-14 03:00:39,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:39,267][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 0.7500774264335632, acc: 0.7127659320831299)
[2024-12-14 03:00:39,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:39,422][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 1.7666250467300415, acc: 0.5218977928161621)
[2024-12-14 03:00:39,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:39,636][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.46065500378608704, acc: 0.8428571224212646)
[2024-12-14 03:00:39,719][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.018195033073425293, acc: 1.0)
[2024-12-14 03:00:39,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:39,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:39,978][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.42559003829956055, acc: 0.8571428656578064)
[2024-12-14 03:00:40,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:40,092][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.05133703723549843, acc: 1.0)
[2024-12-14 03:00:40,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:40,272][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.4117271602153778, acc: 0.782608687877655)
[2024-12-14 03:00:40,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:40,428][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.15326276421546936, acc: 0.939393937587738)
[2024-12-14 03:00:40,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:40,615][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.16125309467315674, acc: 0.931034505367279)
[2024-12-14 03:00:40,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:40,825][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.06522359699010849, acc: 0.9615384340286255)
[2024-12-14 03:00:40,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:41,012][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.6134046316146851, acc: 0.8478260636329651)
[2024-12-14 03:00:41,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:41,222][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.2531897723674774, acc: 0.942307710647583)
[2024-12-14 03:00:41,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:41,327][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.23264874517917633, acc: 0.9661017060279846)
[2024-12-14 03:00:41,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:41,566][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.32389628887176514, acc: 0.9038461446762085)
[2024-12-14 03:00:41,642][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.4216196537017822, acc: 0.8771929740905762)
[2024-12-14 03:00:41,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:41,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:41,945][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.10420497506856918, acc: 0.96875)
[2024-12-14 03:00:42,023][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.644291877746582, acc: 0.8243243098258972)
[2024-12-14 03:00:42,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:42,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:42,300][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.4550188481807709, acc: 0.8405796885490417)
[2024-12-14 03:00:42,342][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.10024537891149521, acc: 1.0)
[2024-12-14 03:00:42,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:42,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:42,684][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.19926419854164124, acc: 0.8695651888847351)
[2024-12-14 03:00:42,688][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.3493928015232086, acc: 0.8999999761581421)
[2024-12-14 03:00:42,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:42,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:43,035][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.10814084857702255, acc: 1.0)
[2024-12-14 03:00:43,071][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.26153528690338135, acc: 0.9473684430122375)
[2024-12-14 03:00:43,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:43,518][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.49687090516090393, acc: 0.8600000143051147)
[2024-12-14 03:00:43,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:43,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:43,920][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.6542261838912964, acc: 0.7864077687263489)
[2024-12-14 03:00:44,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:44,718][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 0.5310284495353699, acc: 0.8783783912658691)
[2024-12-14 03:00:44,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:45,035][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 1.336763858795166, acc: 0.6359223127365112)
[2024-12-14 03:00:45,049][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.709881067276001, acc: 0.8148148059844971)
[2024-12-14 03:00:45,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:45,351][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 03:00:45,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:46,134][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                    [2024-12-14 03:00:46,545][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 03:00:46,865][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                           [2024-12-14 03:00:47,229][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:00:47,570][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                               [2024-12-14 03:00:47,949][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                           [2024-12-14 03:00:48,311][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                     [2024-12-14 03:00:48,644][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:00:48,885][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 03:00:49,197][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 03:00:49,490][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 03:00:49,922][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                        [2024-12-14 03:00:50,236][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 1.69534432888031, acc: 0.5)
[2024-12-14 03:00:50,294][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 1.276120662689209, acc: 0.6642335653305054)
[2024-12-14 03:00:50,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:50,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:50,584][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.08579527586698532, acc: 0.9583333134651184)
[2024-12-14 03:00:50,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:50,684][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.5827773213386536, acc: 0.8507462739944458)
[2024-12-14 03:00:50,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:50,925][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.34545475244522095, acc: 0.9259259104728699)
[2024-12-14 03:00:51,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:51,059][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.22925607860088348, acc: 0.949999988079071)
[2024-12-14 03:00:51,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:51,267][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.21807105839252472, acc: 0.9285714030265808)
[2024-12-14 03:00:51,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:51,430][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.054089296609163284, acc: 1.0)
[2024-12-14 03:00:51,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:51,804][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 0.9091376066207886, acc: 0.7256637215614319)
[2024-12-14 03:00:51,818][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.027440404519438744, acc: 1.0)
[2024-12-14 03:00:51,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:51,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:52,125][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.580922544002533, acc: 0.8115941882133484)
[2024-12-14 03:00:52,145][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.16118751466274261, acc: 0.9318181872367859)
[2024-12-14 03:00:52,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:52,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:52,488][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.38635215163230896, acc: 0.8620689511299133)
[2024-12-14 03:00:52,556][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.6250271201133728, acc: 0.7840909361839294)
[2024-12-14 03:00:52,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:52,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:52,889][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.14335185289382935, acc: 0.930232584476471)
[2024-12-14 03:00:53,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:53,304][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.14412592351436615, acc: 1.0)
[2024-12-14 03:00:53,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:53,461][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 1.457404613494873, acc: 0.5496183037757874)
[2024-12-14 03:00:53,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:53,651][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.006451681721955538, acc: 1.0)
[2024-12-14 03:00:53,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:54,130][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.002983452519401908, acc: 1.0)
[2024-12-14 03:00:54,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:54,129][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 1.3390065431594849, acc: 0.614814817905426)
[2024-12-14 03:00:54,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:54,301][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.0898846760392189, acc: 0.976190447807312)
[2024-12-14 03:00:54,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:54,502][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.37900787591934204, acc: 0.8524590134620667)
[2024-12-14 03:00:54,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:54,711][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.8101727366447449, acc: 0.7538461685180664)
[2024-12-14 03:00:54,818][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.10786426067352295, acc: 0.9583333134651184)
[2024-12-14 03:00:54,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:54,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:55,120][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.3173734247684479, acc: 0.9200000166893005)
[2024-12-14 03:00:55,145][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.5898566246032715, acc: 0.7894737124443054)
[2024-12-14 03:00:55,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:55,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:55,459][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.13442790508270264, acc: 0.9285714030265808)
[2024-12-14 03:00:55,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:55,545][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.4486066699028015, acc: 0.8245614171028137)
[2024-12-14 03:00:55,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:55,762][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.7664169073104858, acc: 0.707317054271698)
[2024-12-14 03:00:55,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:55,941][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.345303475856781, acc: 0.8205128312110901)
[2024-12-14 03:00:56,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:56,105][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 1.6746681928634644, acc: 0.5317220687866211)
[2024-12-14 03:00:56,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:56,317][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.33829766511917114, acc: 0.8775510191917419)
[2024-12-14 03:00:56,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:56,531][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 1.89468514919281, acc: 0.4870316982269287)
[2024-12-14 03:00:56,633][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.0069939494132995605, acc: 1.0)
[2024-12-14 03:00:56,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:56,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:57,002][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.6002291440963745, acc: 0.841269850730896)
[2024-12-14 03:00:57,011][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 1.9522521495819092, acc: 0.45625001192092896)
[2024-12-14 03:00:57,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:57,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:57,324][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.8383944034576416, acc: 0.7560975551605225)
[2024-12-14 03:00:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:57,546][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 1.9416496753692627, acc: 0.48968106508255005)
[2024-12-14 03:00:57,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:57,731][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.42273029685020447, acc: 0.8709677457809448)
[2024-12-14 03:00:58,102][slam_llm.models.slam_model][INFO] - modality encodcompleted (loss: 1.738938808441162, acc: 0.5444839596748352)
[2024-12-14 03:00:58,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:58,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:58,253][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.2851342260837555, acc: 0.8799999952316284)
[2024-12-14 03:00:58,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:58,648][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 1.5134507417678833, acc: 0.5703421831130981)
[2024-12-14 03:00:58,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:58,796][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 1.037148356437683, acc: 0.7093023061752319)
[2024-12-14 03:00:59,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:59,022][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.361941933631897, acc: 0.8666666746139526)
[2024-12-14 03:00:59,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:59,456][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.4119822084903717, acc: 0.8653846383094788)
[2024-12-14 03:00:59,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:59,587][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 1.2882933616638184, acc: 0.60317462682724)
[2024-12-14 03:00:59,813][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.02755160443484783, acc: 1.0)
[2024-12-14 03:00:59,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:00:59,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:00,153][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.022699669003486633, acc: 1.0)
[2024-12-14 03:01:00,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:00,468][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 1.0621352195739746, acc: 0.7055214643478394)
[2024-12-14 03:01:00,499][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 1.2532014846801758, acc: 0.6363636255264282)
[2024-12-14 03:01:00,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:01,239][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 1.018367886543274, acc: 0.7176470756530762)
[2024-12-14 03:01:01,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:01,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:01,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:01,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:02,310][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 1.1723252534866333, acc: 0.654321014881134)
[2024-12-14 03:01:02,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:02,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:02,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:03,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:03,260][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.5779669284820557, acc: 0.8225806355476379)
[2024-12-14 03:01:03,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:03,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:03,627][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.21913354098796844, acc: 0.9285714030265808)
[2024-12-14 03:01:03,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:03,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:04,001][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.2595592141151428, acc: 0.9750000238418579)
me_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 03:01:03,718][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 10 is 0.6034912467002869
[2024-12-14 03:01:03,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:04,225][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.4628264307975769, acc: 0.8275862336158752)
                    [2024-12-14 03:01:04,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:04,607][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.3320886492729187, acc: 0.8636363744735718)
                                                                               [2024-12-14 03:01:04,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:04,956][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.1642635464668274, acc: 0.9545454382896423)
                                                                              [2024-12-14 03:01:05,071][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 03:01:05,370][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.05078957974910736, acc: 1.0)
                                                                                                                                                                            [2024-12-14 03:01:05,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:05,741][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.22613784670829773, acc: 0.9333333373069763)
[2024-12-14 03:01:05,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:06,156][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.5653284192085266, acc: 0.7666666507720947)
                  [2024-12-14 03:01:06,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:06,533][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.0907091498374939, acc: 1.0)
                                                                                             [2024-12-14 03:01:06,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:06,903][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.14352639019489288, acc: 0.9333333373069763)
                                                                              [2024-12-14 03:01:07,003][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 03:01:07,295][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.2771872580051422, acc: 0.8965517282485962)
                    [2024-12-14 03:01:07,405][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:01:07,704][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.1764116883277893, acc: 0.8799999952316284)
[2024-12-14 03:01:07,806][slam_llm.models.slam_model][INFO] - modality encoder
                                                                  [2024-12-14 03:01:08,080][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.44141554832458496, acc: 0.8510638475418091)
[2024-12-14 03:01:08,193][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 03:01:08,464][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.48595675826072693, acc: 0.8125)
[2024-12-14 03:01:08,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:08,818][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.16453047096729279, acc: 0.9318181872367859)
                              [2024-12-14 03:01:08,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:09,244][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.647852897644043, acc: 0.8072289228439331)
                                                                               [2024-12-14 03:01:09,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:09,308][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.13206101953983307, acc: 0.95652174949646)
[2024-12-14 03:01:09,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:09,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:09,615][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.1833944022655487, acc: 0.8928571343421936)
[2024-12-14 03:01:09,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:09,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:10,014][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.3170800805091858, acc: 0.8936170339584351)
[2024-12-14 03:01:10,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:10,277][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 03:01:10,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:10,694][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.8308379054069519, acc: 0.7615384459495544)
[2024-12-14 03:01:10,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:11,052][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.23956835269927979, acc: 0.9864864945411682)
[2024-12-14 03:01:11,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:11,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:11,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:11,448][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.47335031628608704, acc: 0.8488371968269348)
[2024-12-14 03:01:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:11,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:11,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:11,980][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.656647264957428, acc: 0.7837837934494019)
[2024-12-14 03:01:12,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:12,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:12,363][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.4170933663845062, acc: 0.8666666746139526)
[2024-12-14 03:01:12,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:12,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:12,632][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.23603081703186035, acc: 0.9696969985961914)
[2024-12-14 03:01:12,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:12,906][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.026930665597319603, acc: 1.0)
[2024-12-14 03:01:13,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:13,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:13,301][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.36934003233909607, acc: 0.9200000166893005)
[2024-12-14 03:01:13,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:13,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:13,651][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.3123030662536621, acc: 0.8846153616905212)
[2024-12-14 03:01:13,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:13,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:14,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:14,408][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.9184937477111816, acc: 0.7336956262588501)
[2024-12-14 03:01:14,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:14,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:14,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:14,939][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.556201696395874, acc: 0.8275862336158752)
[2024-12-14 03:01:15,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:15,256][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.3205420970916748, acc: 0.8888888955116272)
[2024-12-14 03:01:15,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:15,616][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.34311240911483765, acc: 0.8947368264198303)
[2024-12-14 03:01:15,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:16,029][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.43734925985336304, acc: 0.8928571343421936)
                                                                                                  [2024-12-14 03:01:16,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:16,410][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.4633401930332184, acc: 0.90625)
                                                                                           [2024-12-14 03:01:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:16,803][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.2792237401008606, acc: 0.9056603908538818)
                                                                                [2024-12-14 03:01:16,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:17,167][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.38830170035362244, acc: 0.8113207817077637)
                                                                [2024-12-14 03:01:17,246][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 03:01:17,481][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.1576475352048874, acc: 0.970588207244873)
                     [2024-12-14 03:01:17,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:17,883][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.06741054356098175, acc: 1.0)
                                                                                            [2024-12-14 03:01:18,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:18,312][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.5376209020614624, acc: 0.7704917788505554)
                                                                                                                                                              [2024-12-14 03:01:18,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:18,696][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.150151789188385, acc: 0.9666666388511658)
 [2024-12-14 03:01:18,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:19,014][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.08194569498300552, acc: 0.9473684430122375)
[2024-12-14 03:01:19,098][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 03:01:19,384][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.6772110462188721, acc: 0.782608687877655)
[2024-12-14 03:01:19,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:19,834][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.7834060192108154, acc: 0.7916666865348816)
                                                                                                                                                                                                                  [2024-12-14 03:01:19,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:20,244][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.6390340328216553, acc: 0.7831325531005859)
                                                                                [2024-12-14 03:01:20,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:20,583][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.72347491979599, acc: 0.7692307829856873)
[2024-12-14 03:01:20,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:20,958][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.7928233742713928, acc: 0.7448979616165161)
[2024-12-14 03:01:21,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:21,332][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.015176136046648026, acc: 1.0)
                                   [2024-12-14 03:01:21,442][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:01:21,705][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.0992189273238182, acc: 0.9583333134651184)
[2024-12-14 03:01:21,820][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 03:01:22,104][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.1447429656982422, acc: 0.9354838728904724)
[2024-12-14 03:01:22,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:22,456][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.25765594840049744, acc: 0.9032257795333862)
                 [2024-12-14 03:01:22,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:22,851][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.38507482409477234, acc: 0.8656716346740723)
[2024-12-14 03:01:22,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:23,234][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.677351713180542, acc: 0.8269230723381042)
                                                                    [2024-12-14 03:01:23,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:23,565][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.3892267942428589, acc: 0.8666666746139526)
[2024-12-14 03:01:23,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:23,958][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.1486663669347763, acc: 0.9677419066429138)
                                                                                                                                                 [2024-12-14 03:01:24,060][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:01:24,335][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.20913167297840118, acc: 0.9599999785423279)
[2024-12-14 03:01:24,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:24,717][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.28142422437667847, acc: 0.8518518805503845)
                                                                                                                                               [2024-12-14 03:01:24,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:25,043][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.38293471932411194, acc: 0.9142857193946838)
[2024-12-14 03:01:25,149][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:01:25,389][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.223786860704422, acc: 0.9487179517745972)
  [2024-12-14 03:01:25,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:25,762][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.46071353554725647, acc: 0.7804877758026123)
                                                                              [2024-12-14 03:01:25,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:26,066][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.6641885638237, acc: 0.8684210777282715)
[2024-12-14 03:01:26,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:26,439][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.038724351674318314, acc: 1.0)
                                                                                             [2024-12-14 03:01:26,533][slam_llm.models.slam_model][INFO] - modality encoder
                                              [2024-12-14 03:01:26,743][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.14377057552337646, acc: 0.9285714030265808)
[2024-12-14 03:01:26,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:27,054][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.13218481838703156, acc: 0.9259259104728699)
                                                                                                  [2024-12-14 03:01:27,162][slam_llm.models.slam_model][INFO] - modality encoder
                                                            [2024-12-14 03:01:27,390][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.16384509205818176, acc: 0.9375)
[2024-12-14 03:01:27,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:27,687][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.4681462347507477, acc: 0.8709677457809448)
                                                                                                              [2024-12-14 03:01:27,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:28,048][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.42686665058135986, acc: 0.8421052694320679)
                                                                               [2024-12-14 03:01:28,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:28,440][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.31883692741394043, acc: 0.84375)
[2024-12-14 03:01:28,553][slam_llm.models.slam_model][INFO] - modality encoder
          [2024-12-14 03:01:28,753][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.31496289372444153, acc: 0.8999999761581421)
[2024-12-14 03:01:28,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:29,055][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.9076917767524719, acc: 0.8421052694320679)
                  [2024-12-14 03:01:29,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:29,411][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.3044496178627014, acc: 0.8999999761581421)
[2024-12-14 03:01:29,507][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:01:29,790][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.8801026344299316, acc: 0.7011494040489197)
                                                                               [2024-12-14 03:01:29,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:30,194][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.7048110961914062, acc: 0.7553191781044006)
                                                                               [2024-12-14 03:01:30,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:30,579][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 0.6753523349761963, acc: 0.7349397540092468)
                                                                               [2024-12-14 03:01:30,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:30,994][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.008637800812721252, acc: 1.0)
                                                                                [2024-12-14 03:01:31,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:31,374][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.22564095258712769, acc: 0.9230769276618958)
[2024-12-14 03:01:31,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:31,736][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.4732021987438202, acc: 0.8674699068069458)
                                                                                                                                                                                                                                                                                                                     [2024-12-14 03:01:31,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:32,096][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.3080974519252777, acc: 0.9433962106704712)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 03:01:32,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:32,493][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.4327702522277832, acc: 0.8354430198669434)
                                                                                                                                          [2024-12-14 03:01:32,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:32,890][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.27604857087135315, acc: 0.9019607901573181)
                                                                              [2024-12-14 03:01:32,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:33,254][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.4826353192329407, acc: 0.89552241563797)
                                                                                [2024-12-14 03:01:33,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:33,624][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.05357024073600769, acc: 1.0)
[2024-12-14 03:01:33,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:34,034][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.11599387228488922, acc: 0.9599999785423279)
                                                                                                                                                                           [2024-12-14 03:01:34,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:34,461][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.09090439975261688, acc: 1.0)
                                                                                              [2024-12-14 03:01:34,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:34,808][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.5521877408027649, acc: 0.7674418687820435)
                                                                               [2024-12-14 03:01:34,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:35,176][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.5879448056221008, acc: 0.8974359035491943)
[2024-12-14 03:01:35,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:35,531][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.539583683013916, acc: 0.8888888955116272)
                                                                                                                                                    [2024-12-14 03:01:35,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:35,914][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.12080613523721695, acc: 0.95652174949646)
                                                                                 [2024-12-14 03:01:36,015][slam_llm.models.slam_model][INFO] - modality encoder
                                             [2024-12-14 03:01:36,250][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.5441323518753052, acc: 0.807692289352417)
                     [2024-12-14 03:01:36,353][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:01:36,591][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 1.0227752923965454, acc: 0.6703296899795532)
[2024-12-14 03:01:36,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:37,090][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 0.9428533315658569, acc: 0.7130434513092041)
                                                                                                                                                              [2024-12-14 03:01:37,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:37,425][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.7822074294090271, acc: 0.760869562625885)
                                                                                 [2024-12-14 03:01:37,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:37,801][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.5278987884521484, acc: 0.8571428656578064)
[2024-12-14 03:01:37,928][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                             [2024-12-14 03:01:38,184][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.01315805409103632, acc: 1.0)
                                                                                            [2024-12-14 03:01:38,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:38,564][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.22761081159114838, acc: 0.9615384340286255)
[2024-12-14 03:01:38,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:38,987][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.3368177115917206, acc: 0.9024389982223511)
                   [2024-12-14 03:01:39,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:39,341][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.27684590220451355, acc: 0.9111111164093018)
                                                                              [2024-12-14 03:01:39,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:39,743][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.5418332815170288, acc: 0.8815789222717285)
                                                                               [2024-12-14 03:01:39,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:40,138][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.3489026725292206, acc: 0.9024389982223511)
                                                                              [2024-12-14 03:01:40,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:40,398][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 0.8613640069961548, acc: 0.6914893388748169)
[2024-12-14 03:01:40,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:40,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:40,705][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.33529728651046753, acc: 0.8999999761581421)
[2024-12-14 03:01:40,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:40,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:41,044][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.19748996198177338, acc: 0.9285714030265808)
[2024-12-14 03:01:41,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:41,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:41,424][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.4190184473991394, acc: 0.8695651888847351)
[2024-12-14 03:01:41,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:41,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:41,715][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.1702825278043747, acc: 0.931034505367279)
[2024-12-14 03:01:41,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:41,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:42,085][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.3879089653491974, acc: 0.9130434989929199)
[2024-12-14 03:01:42,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:42,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:42,467][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.41545721888542175, acc: 0.8474576473236084)
[2024-12-14 03:01:42,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:42,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:42,785][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.4494374394416809, acc: 0.8245614171028137)
[2024-12-14 03:01:42,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:43,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:43,138][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.8322569131851196, acc: 0.7432432174682617)
[2024-12-14 03:01:43,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:43,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:43,485][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.07463546097278595, acc: 1.0)
[2024-12-14 03:01:43,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:43,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:43,857][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.21047988533973694, acc: 0.95652174949646)
[2024-12-14 03:01:43,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:44,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:44,252][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.4502406418323517, acc: 0.9473684430122375)
[2024-12-14 03:01:44,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:44,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:44,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:45,060][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                          [2024-12-14 03:01:45,428][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 03:01:45,719][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                           [2024-12-14 03:01:45,962][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 0.44501927495002747, acc: 0.8783783912658691)
[2024-12-14 03:01:46,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:46,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:46,286][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.4661819040775299, acc: 0.9074074029922485)
[2024-12-14 03:01:46,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:46,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:46,694][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 0.5062537789344788, acc: 0.8604651093482971)
[2024-12-14 03:01:46,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:46,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:47,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:47,280][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 0.4783742427825928, acc: 0.8588235378265381)
[2024-12-14 03:01:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:47,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:47,832][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 0.7609724998474121, acc: 0.7752808928489685)
[2024-12-14 03:01:47,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:47,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:48,126][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.3107428252696991, acc: 0.9090909361839294)
[2024-12-14 03:01:48,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:48,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:48,518][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.2078518122434616, acc: 0.9047619104385376)
[2024-12-14 03:01:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:48,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:48,881][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 0.8454674482345581, acc: 0.6896551847457886)
[2024-12-14 03:01:48,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:48,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:49,216][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.2990093529224396, acc: 0.8979591727256775)
[2024-12-14 03:01:49,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:49,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:49,527][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.37994346022605896, acc: 0.800000011920929)
[2024-12-14 03:01:49,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:49,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:49,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:49,964][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.525111734867096, acc: 0.8611111044883728)
[2024-12-14 03:01:50,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:50,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:50,370][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 0.9171838164329529, acc: 0.7352941036224365)
[2024-12-14 03:01:50,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:50,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:50,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:51,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:51,333][slam_llm.models.slam_model][INFO] - modality 02127075, acc: 0.949999988079071)
[2024-12-14 03:01:51,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:51,553][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.1661442220211029, acc: 0.9047619104385376)
[2024-12-14 03:01:51,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:51,888][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.5274765491485596, acc: 0.8518518805503845)
                                                      [2024-12-14 03:01:52,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:52,249][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 1.0423232316970825, acc: 0.6504854559898376)
                                                                               [2024-12-14 03:01:52,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:52,775][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 1.0196162462234497, acc: 0.6985294222831726)
                                                                                                                                                              [2024-12-14 03:01:52,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:53,154][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 1.1287734508514404, acc: 0.6333333253860474)
                                                                               [2024-12-14 03:01:53,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:53,567][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 1.1030634641647339, acc: 0.6458333134651184)
                                                                              [2024-12-14 03:01:53,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:53,981][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.3209564685821533, acc: 0.8837209343910217)
[2024-12-14 03:01:54,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:54,359][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.18833090364933014, acc: 0.9583333134651184)
[2024-12-14 03:01:54,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:54,766][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.2975505292415619, acc: 0.9069767594337463)
[2024-12-14 03:01:54,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:55,070][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.09154121577739716, acc: 1.0)
[2024-12-14 03:01:55,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:55,611][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.4074569642543793, acc: 0.9117646813392639)
                                                                                                                 [2024-12-14 03:01:55,705][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                           [2024-12-14 03:01:56,003][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.4569011926651001, acc: 0.8666666746139526)
                                                                                 [2024-12-14 03:01:56,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:56,358][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.5458147525787354, acc: 0.8787878751754761)
                                                                                [2024-12-14 03:01:56,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:56,675][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.2623526453971863, acc: 0.8787878751754761)
[2024-12-14 03:01:56,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:57,042][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.07960332185029984, acc: 0.9677419066429138)
                    [2024-12-14 03:01:57,144][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 03:01:57,374][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.07755511999130249, acc: 0.9629629850387573)
                   [2024-12-14 03:01:57,475][slam_llm.models.slam_model][INFO] - modality encoder
                                                           [2024-12-14 03:01:57,714][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.016099749132990837, acc: 1.0)
                                 [2024-12-14 03:01:57,799][slam_llm.models.slam_model][INFO] - modality encoder
                                                         [2024-12-14 03:01:58,026][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.07039862126111984, acc: 0.9722222089767456)
[2024-12-14 03:01:58,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:58,423][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.10457754880189896, acc: 0.9629629850387573)
       [2024-12-14 03:01:58,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:58,808][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.08084038645029068, acc: 1.0)
                                                                                             [2024-12-14 03:01:58,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:01:59,106][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.5378942489624023, acc: 0.8448275923728943)
                                                                                                                                                                                                                                                                                                                                                                                        [2024-12-14 03:01:59,947][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                        [2024-12-14 03:02:00,242][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:02:00,657][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                         [2024-12-14 03:02:01,090][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:02:01,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:01,752][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 03:02:02,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:02,450][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:02:02,943][slam_llm.models.slam_model][INFO] - modality encoder
7.4655, device='cuda:0') eval_epoch_loss=tensor(2.0103, device='cuda:0') eval_epoch_acc=tensor(0.5978, device='cuda:0')
[2024-12-14 03:02:02,738][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 03:02:02,738][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 03:02:02,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:03,025][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_10_step_268_loss_2.0102953910827637/model.pt
[2024-12-14 03:02:03,029][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 03:02:03,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:03,536][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 1.2904099225997925, acc: 0.6419752836227417)
[2024-12-14 03:02:03,539][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.3493764102458954, acc: 0.8793103694915771)
[2024-12-14 03:02:03,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:03,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:03,846][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.05456347391009331, acc: 1.0)
[2024-12-14 03:02:03,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:04,154][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.10139444470405579, acc: 0.9545454382896423)
[2024-12-14 03:02:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:04,487][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.6668338775634766, acc: 0.8548387289047241)
[2024-12-14 03:02:04,509][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.10644950717687607, acc: 0.96875)
[2024-12-14 03:02:04,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:04,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:04,818][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.10860218107700348, acc: 0.9642857313156128)
[2024-12-14 03:02:04,866][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.02804110199213028, acc: 1.0)
[2024-12-14 03:02:04,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:05,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:05,163][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.3497384190559387, acc: 0.8500000238418579)
[2024-12-14 03:02:05,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:05,284][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.5036690831184387, acc: 0.8333333134651184)
[2024-12-14 03:02:05,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:05,496][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.6220682859420776, acc: 0.8235294222831726)
[2024-12-14 03:02:05,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:05,676][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.05027534440159798, acc: 1.0)
[2024-12-14 03:02:05,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:05,809][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 1.1321269273757935, acc: 0.6397058963775635)
[2024-12-14 03:02:05,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:06,064][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.07098747044801712, acc: 0.9666666388511658)
[2024-12-14 03:02:06,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:06,223][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 1.1971054077148438, acc: 0.6271186470985413)
[2024-12-14 03:02:06,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:06,399][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.1700746715068817, acc: 0.9655172228813171)
[2024-12-14 03:02:06,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:06,559][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 1.2150683403015137, acc: 0.6492537260055542)
[2024-12-14 03:02:06,683][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                            [2024-12-14 03:02:06,996][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:02:07,332][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:02:07,673][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                   [2024-12-14 03:02:08,011][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:02:08,357][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:02:08,702][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2024-12-14 03:02:09,070][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:02:09,377][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                          [2024-12-14 03:02:09,673][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 03:02:10,009][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 1.0504372119903564, acc: 0.6521739363670349)
[2024-12-14 03:02:09,967][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 0.8969078063964844, acc: 0.6875)
[2024-12-14 03:02:09,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:10,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:10,284][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.14935444295406342, acc: 0.9130434989929199)
[2024-12-14 03:02:10,362][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 1.0823472738265991, acc: 0.7360000014305115)
[2024-12-14 03:02:10,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:10,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:10,628][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.07464196532964706, acc: 1.0)
[2024-12-14 03:02:10,703][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.5229759216308594, acc: 0.901098906993866)
[2024-12-14 03:02:10,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:10,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:11,041][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.22115913033485413, acc: 0.914893627166748)
[2024-12-14 03:02:11,054][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 1.4614245891571045, acc: 0.5714285969734192)
[2024-12-14 03:02:11,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:11,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:11,420][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 1.5803571939468384, acc: 0.592783510684967)
[2024-12-14 03:02:11,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:11,691][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.13661448657512665, acc: 0.9545454382896423)
[2024-12-14 03:02:11,717][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.825252890586853, acc: 0.7615384459495544)
[2024-12-14 03:02:11,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:11,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:11,991][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.2969752848148346, acc: 0.8809523582458496)
[2024-12-14 03:02:12,076][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.3866821229457855, acc: 0.8783783912658691)
[2024-12-14 03:02:12,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:12,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:12,310][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.3344317078590393, acc: 0.8793103694915771)
[2024-12-14 03:02:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:12,517][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.5778467655181885, acc: 0.8139534592628479)
[2024-12-14 03:02:12,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:12,768][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.3721046447753906, acc: 0.8363636136054993)
[2024-12-14 03:02:12,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:13,059][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.7095608115196228, acc: 0.7747747898101807)
[2024-12-14 03:02:13,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:13,312][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 1.515223741531372, acc: 0.5824742317199707)
[2024-12-14 03:02:13,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:13,447][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.5340297818183899, acc: 0.8333333134651184)
[2024-12-14 03:02:13,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:13,573][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.5482149720191956, acc: 0.8103448152542114)
[2024-12-14 03:02:13,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:13,888][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.14698809385299683, acc: 0.939393937587738)
[2024-12-14 03:02:13,914][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.24817998707294464, acc: 0.9259259104728699)
[2024-12-14 03:02:13,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:14,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:14,186][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.016177264973521233, acc: 1.0)
[2024-12-14 03:02:14,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:14,314][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.4179655611515045, acc: 0.8421052694320679)
[2024-12-14 03:02:14,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:14,531][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.40454909205436707, acc: 0.9599999785423279)
[2024-12-14 03:02:14,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:14,668][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.2178950309753418, acc: 0.9464285969734192)
[2024-12-14 03:02:14,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:14,936][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.44544166326522827, acc: 0.8653846383094788)
[2024-12-14 03:02:15,020][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.2760423719882965, acc: 0.90625)
[2024-12-14 03:02:15,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:15,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:15,412][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.36018112301826477, acc: 0.8867924809455872)
[2024-12-14 03:02:15,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:15,692][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.882297933101654, acc: 0.739130437374115)
[2024-12-14 03:02:15,815][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.19699913263320923, acc: 0.9245283007621765)
[2024-12-14 03:02:15,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:15,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:16,194][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.15862983465194702, acc: 0.9117646813392639)
[2024-12-14 03:02:16,228][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 1.0832933187484741, acc: 0.6590909361839294)
[2024-12-14 03:02:16,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:16,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:16,527][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.32847732305526733, acc: 0.875)
[2024-12-14 03:02:16,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:16,658][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.7369653582572937, acc: 0.7446808218955994)
[2024-12-14 03:02:16,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:16,921][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.48656633496284485, acc: 0.8524590134620667)
[2024-12-14 03:02:17,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:17,043][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.24314604699611664, acc: 0.9433962106704712)
[2024-12-14 03:02:17,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:17,273][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.3637385368347168, acc: 0.9333333373069763)
[2024-12-14 03:02:17,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:17,738][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.3836968243122101, acc: 0.9166666865348816)
[2024-12-14 03:02:17,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:17,654][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.04013103246688843, acc: 1.0)
[2024-12-14 03:02:17,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:17,869][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.13259470462799072, acc: 0.9534883499145508)
[2024-12-14 03:02:17,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:18,073][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.6356701254844666, acc: 0.8260869383811951)
[2024-12-14 03:02:18,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:18,239][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.33338436484336853, acc: 0.8333333134651184)
[2024-12-14 03:02:18,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:18,491][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.8507465124130249, acc: 0.7916666865348816)
[2024-12-14 03:02:18,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:18,612][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 0.7586044073104858, acc: 0.7052631378173828)
[2024-12-14 03:02:18,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:18,860][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.5826840400695801, acc: 0.8192771077156067)
[2024-12-14 03:02:18,943][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.6768488883972168, acc: 0.800000011920929)
[2024-12-14 03:02:18,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:19,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:19,251][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.7497570514678955, acc: 0.7692307829856873)
[2024-12-14 03:02:19,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:19,407][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 0.7308417558670044, acc: 0.7888888716697693)
[2024-12-14 03:02:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:19,655][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.8429404497146606, acc: 0.6938775777816772)
[2024-12-14 03:02:19,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:19,893][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 1.186582088470459, acc: 0.7018348574638367)
[2024-12-14 03:02:20,000][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.02228657342493534, acc: 1.0)
[2024-12-14 03:02:20,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:20,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:20,361][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.05984017625451088, acc: 1.0)
[2024-12-14 03:02:20,366][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 0.6522335410118103, acc: 0.807692289352417)
[2024-12-14 03:02:20,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:20,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:20,622][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.17023277282714844, acc: 0.9473684430122375)
[2024-12-14 03:02:20,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:20,723][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.3846571445465088, acc: 0.9677419066429138)
[2024-12-14 03:02:20,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:20,928][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.05997626855969429, acc: 0.9583333134651184)
[2024-12-14 03:02:21,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:21,094][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.18909935653209686, acc: 0.9354838728904724)
[2024-12-14 03:02:21,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:21,337][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.1974158138036728, acc: 0.9090909361839294)
[2024-12-14 03:02:21,690][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 03:02:22,281][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 03:02:22,653][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 03:02:22,984][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                          [2024-12-14 03:02:23,307][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                    [2024-12-14 03:02:23,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:23,961][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 03:02:24,449][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                     [2024-12-14 03:02:24,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:24,815][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.27244386076927185, acc: 0.8947368264198303)
[2024-12-14 03:02:24,901][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.11774881184101105, acc: 0.9677419066429138)
[2024-12-14 03:02:24,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:24,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:25,159][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.03382677957415581, acc: 1.0)
[2024-12-14 03:02:25,170][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.021086562424898148, acc: 1.0)
[2024-12-14 03:02:25,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:25,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:25,514][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.1951526254415512, acc: 0.9189189076423645)
[2024-12-14 03:02:25,537][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.012365360744297504, acc: 1.0)
[2024-12-14 03:02:25,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:25,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:25,877][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.3326922357082367, acc: 0.9189189076423645)
[2024-12-14 03:02:25,926][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.05404999479651451, acc: 1.0)
[2024-12-14 03:02:25,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:26,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:26,195][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.18747666478157043, acc: 0.9729729890823364)
[2024-12-14 03:02:26,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:26,339][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.03532588109374046, acc: 1.0)
[2024-12-14 03:02:26,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:26,585][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.3175959885120392, acc: 0.8676470518112183)
[2024-12-14 03:02:26,689][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.45342275500297546, acc: 0.8709677457809448)
[2024-12-14 03:02:26,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:26,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:26,993][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.03371163457632065, acc: 1.0)
[2024-12-14 03:02:27,093][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.5942050814628601, acc: 0.7894737124443054)
[2024-12-14 03:02:27,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:27,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:27,364][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.01207934133708477, acc: 1.0)
[2024-12-14 03:02:27,466][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.23130054771900177, acc: 0.9375)
[2024-12-14 03:02:27,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:27,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:27,752][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.053835831582546234, acc: 1.0)
[2024-12-14 03:02:27,794][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.11181628704071045, acc: 0.9666666388511658)
[2024-12-14 03:02:27,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:27,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:28,079][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.1596228927373886, acc: 0.9473684430122375)
[2024-12-14 03:02:28,082][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.07125392556190491, acc: 1.0)
[2024-12-14 03:02:28,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:28,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:28,620][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.212522953748703, acc: 0.8947368264198303)
[2024-12-14 03:02:28,405][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.7911428213119507, acc: 0.8199999928474426)
[2024-12-14 03:02:28,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:28,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:28,753][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.33094775676727295, acc: 0.9142857193946838)
[2024-12-14 03:02:28,825][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.7816681265830994, acc: 0.7586206793785095)
[2024-12-14 03:02:28,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:28,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:29,061][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.35285067558288574, acc: 0.8947368264198303)
[2024-12-14 03:02:29,188][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.8414624929428101, acc: 0.7553191781044006)
[2024-12-14 03:02:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:29,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:29,544][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 0.8409552574157715, acc: 0.7228915691375732)
[2024-12-14 03:02:29,638][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.759258508682251, acc: 0.7735849022865295)
[2024-12-14 03:02:29,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:29,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:29,887][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.04824880510568619, acc: 1.0)
[2024-12-14 03:02:29,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:30,155][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.10115209966897964, acc: 0.9743589758872986)
[2024-12-14 03:02:30,223][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 0.8407215476036072, acc: 0.7666666507720947)
[2024-12-14 03:02:30,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:30,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:30,529][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.7052817940711975, acc: 0.759036123752594)
[2024-12-14 03:02:30,580][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.17904064059257507, acc: 0.9722222089767456)
[2024-12-14 03:02:30,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:30,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:30,929][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.4918961822986603, acc: 0.8867924809455872)
                                                                                                                                                                                                              [2024-12-14 03:02:30,966][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.3472345471382141, acc: 0.9032257795333862)
[2024-12-14 03:02:31,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:31,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:31,283][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.41571393609046936, acc: 0.8734177350997925)
[2024-12-14 03:02:31,326][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.7311593294143677, acc: 0.7866666913032532)
[2024-12-14 03:02:31,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:31,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:31,627][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.19783666729927063, acc: 0.9411764740943909)
[2024-12-14 03:02:31,682][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.37648022174835205, acc: 0.875)
[2024-12-14 03:02:31,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:31,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:32,010][root][INFO] - Training Epoch: 10/1[2024-12-14 03:02:32,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:32,310][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.09259354323148727, acc: 0.9545454382896423)
[2024-12-14 03:02:32,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:32,640][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.5058913230895996, acc: 0.843137264251709)
                                                                 [2024-12-14 03:02:32,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:32,961][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.11805813759565353, acc: 0.9615384340286255)
                                                                                                                                                                                                                         [2024-12-14 03:02:33,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:33,318][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.11113548278808594, acc: 0.9444444179534912)
                                                                                                                                                                                                                        [2024-12-14 03:02:33,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:33,727][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.21379204094409943, acc: 0.949999988079071)
 [2024-12-14 03:02:33,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:34,111][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.13341864943504333, acc: 0.8999999761581421)
[2024-12-14 03:02:34,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:34,419][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.013281671330332756, acc: 1.0)
                                                                                          [2024-12-14 03:02:34,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:34,761][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.1484275758266449, acc: 0.8999999761581421)
                                                                                                                                                 [2024-12-14 03:02:34,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:35,121][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.150765523314476, acc: 0.96875)
             [2024-12-14 03:02:35,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:35,479][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.29382506012916565, acc: 0.9444444179534912)
                                                                             [2024-12-14 03:02:35,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:35,850][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.13136321306228638, acc: 0.9629629850387573)
[2024-12-14 03:02:35,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:36,194][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.12355499714612961, acc: 0.9696969985961914)
[2024-12-14 03:02:36,294][slam_llm.models.slam_model][INFO] - modality encoder
                                                                            [2024-12-14 03:02:36,542][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.08510120213031769, acc: 0.95652174949646)
[2024-12-14 03:02:36,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:36,927][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.10578753799200058, acc: 0.9459459185600281)
                     [2024-12-14 03:02:37,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:37,265][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.06429307907819748, acc: 0.9629629850387573)
                                                                                                                                                                                                                                                                             [2024-12-14 03:02:37,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:37,578][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.19816800951957703, acc: 0.9130434989929199)
[2024-12-14 03:02:37,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:37,879][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.020132170990109444, acc: 1.0)
[2024-12-14 03:02:37,968][slam_llm.models.slam_model][INFO] - modality encoder
              [2024-12-14 03:02:38,264][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.12301424145698547, acc: 0.9629629850387573)
                   [2024-12-14 03:02:38,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:38,616][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.13900449872016907, acc: 0.95652174949646)
                                                                                 [2024-12-14 03:02:38,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:39,031][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.20811013877391815, acc: 0.9444444179534912)
                                                                               [2024-12-14 03:02:39,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:39,415][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.08732131123542786, acc: 0.9599999785423279)
                                                                               [2024-12-14 03:02:39,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:39,824][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.085044264793396, acc: 0.9696969985961914)
                                                                                                                                                                                                                                                                              [2024-12-14 03:02:39,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:40,191][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.2362401783466339, acc: 0.9166666865348816)
                                                               [2024-12-14 03:02:40,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:40,560][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.2774522304534912, acc: 0.9318181872367859)
                                                                    [2024-12-14 03:02:40,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:40,923][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.06636247038841248, acc: 0.9523809552192688)
[2024-12-14 03:02:41,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:41,337][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.31330862641334534, acc: 0.9230769276618958)
                  [2024-12-14 03:02:41,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:41,809][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.6023769974708557, acc: 0.8181818127632141)
[2024-12-14 03:02:41,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:42,490][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 1.494085431098938, acc: 0.5759999752044678)
                                                                                                                                                                                                                                              [2024-12-14 03:02:42,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:42,924][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 1.3435319662094116, acc: 0.6048387289047241)
[2024-12-14 03:02:43,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:43,582][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 1.5660451650619507, acc: 0.5870646834373474)
                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 03:02:43,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:43,903][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.2718175947666168, acc: 0.9056603908538818)
                                                                 [2024-12-14 03:02:44,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:44,332][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.27232763171195984, acc: 0.9090909361839294)
                                                                              [2024-12-14 03:02:44,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:44,711][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.17755384743213654, acc: 0.9130434989929199)
                                                                              [2024-12-14 03:02:44,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:45,087][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.28217822313308716, acc: 0.8846153616905212)
                                                                              [2024-12-14 03:02:45,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:45,438][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.2611866593360901, acc: 0.9285714030265808)
[2024-12-14 03:02:45,546][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:02:45,792][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.3998657464981079, acc: 0.89552241563797)
[2024-12-14 03:02:45,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:46,110][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.5735649466514587, acc: 0.8194444179534912)
[2024-12-14 03:02:46,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:46,474][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.44458845257759094, acc: 0.8804348111152649)
[2024-12-14 03:02:46,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:46,854][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.5083869099617004, acc: 0.8205128312110901)
[2024-12-14 03:02:46,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:47,221][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.3603285253047943, acc: 0.9078947305679321)
[2024-12-14 03:02:47,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:47,612][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.17211587727069855, acc: 0.9387755393981934)
[2024-12-14 03:02:47,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:47,993][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.14786846935749054, acc: 0.9696969985961914)
                                                                                                                                                                                                                [2024-12-14 03:02:48,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:48,399][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.9500551223754883, acc: 0.7010309100151062)
                                                                                                                                                    [2024-12-14 03:02:48,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:48,745][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.30254942178726196, acc: 0.8999999761581421)
                                                                                [2024-12-14 03:02:48,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:49,121][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 1.0069984197616577, acc: 0.7267441749572754)
                                                                               [2024-12-14 03:02:49,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:49,446][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.19700820744037628, acc: 0.9642857313156128)
                                                                  [2024-12-14 03:02:49,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:49,758][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.5623264908790588, acc: 0.8518518805503845)
                                                                 [2024-12-14 03:02:49,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:50,115][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.07034095376729965, acc: 1.0)
                                                                                              [2024-12-14 03:02:50,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:50,484][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.19314946234226227, acc: 0.90625)
                                                                                         [2024-12-14 03:02:50,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:50,794][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.09787271916866302, acc: 0.9230769276618958)
[2024-12-14 03:02:50,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:51,101][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.14163996279239655, acc: 0.9347826242446899)
[2024-12-14 03:02:51,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:51,408][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.43743228912353516, acc: 0.8452380895614624)
[2024-12-14 03:02:51,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:51,762][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.405286580324173, acc: 0.891566276550293)
  [2024-12-14 03:02:51,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:52,169][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.5779902935028076, acc: 0.8108108043670654)
                                                                                                                                                              [2024-12-14 03:02:52,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:52,545][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.5980145931243896, acc: 0.8252426981925964)
                                                                               [2024-12-14 03:02:52,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:52,930][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.5376972556114197, acc: 0.8211382031440735)
                                                                                                                                                              [2024-12-14 03:02:53,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:53,286][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.27807846665382385, acc: 0.930232584476471)
[2024-12-14 03:02:53,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:53,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:53,527][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.10494834929704666, acc: 1.0)
[2024-12-14 03:02:53,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:53,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:53,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:54,063][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.5259848833084106, acc: 0.8823529481887817)
[2024-12-14 03:02:54,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:54,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:54,392][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.43254515528678894, acc: 0.8933333158493042)
[2024-12-14 03:02:54,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:54,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:54,723][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.14096403121948242, acc: 0.939393937587738)
[2024-12-14 03:02:54,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:55,088][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.1880003809928894, acc: 0.939393937587738)
[2024-12-14 03:02:55,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:55,401][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.034992340952157974, acc: 1.0)
[2024-12-14 03:02:55,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:55,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:55,762][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.12474299967288971, acc: 0.9629629850387573)
[2024-12-14 03:02:55,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:56,132][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.01407700777053833, acc: 1.0)
[2024-12-14 03:02:56,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:56,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:56,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:56,502][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.024877481162548065, acc: 1.0)
[2024-12-14 03:02:56,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:56,845][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.22045612335205078, acc: 0.8888888955116272)
[2024-12-14 03:02:56,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:56,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:57,154][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.050828732550144196, acc: 0.9615384340286255)
[2024-12-14 03:02:57,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:57,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:57,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:57,519][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.3673771917819977, acc: 0.8965517282485962)
[2024-12-14 03:02:57,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:58,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:58,401][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                         [2024-12-14 03:02:58,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:58,770][slam_llm.models.slam_model][INFO] - modality encoder
pleted (loss: 0.07225745916366577, acc: 1.0)
[2024-12-14 03:02:58,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:59,007][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.4457394778728485, acc: 0.8518518805503845)
[2024-12-14 03:02:59,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:59,345][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.31002169847488403, acc: 0.8571428656578064)
[2024-12-14 03:02:59,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:02:59,711][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.18807083368301392, acc: 0.9090909361839294)
[2024-12-14 03:02:59,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:00,097][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.47391653060913086, acc: 0.8615384697914124)
[2024-12-14 03:03:00,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:00,430][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.28272971510887146, acc: 0.8999999761581421)
[2024-12-14 03:03:00,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:00,758][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.20944727957248688, acc: 0.8965517282485962)
[2024-12-14 03:03:00,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:01,100][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.36230912804603577, acc: 0.8627451062202454)
[2024-12-14 03:03:01,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:01,425][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.21971474587917328, acc: 0.931034505367279)
[2024-12-14 03:03:01,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:01,725][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.055360984057188034, acc: 1.0)
[2024-12-14 03:03:01,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:02,104][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.2598496079444885, acc: 0.8947368264198303)
[2024-12-14 03:03:02,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:02,470][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.8347935080528259, acc: 0.7321428656578064)
[2024-12-14 03:03:02,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:02,902][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.6992101669311523, acc: 0.7977527976036072)
[2024-12-14 03:03:03,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:03,231][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.7316020131111145, acc: 0.8202247023582458)
[2024-12-14 03:03:03,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:03,616][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 1.1661264896392822, acc: 0.6170212626457214)
[2024-12-14 03:03:03,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:04,017][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.7526139616966248, acc: 0.77173912525177)
[2024-12-14 03:03:04,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:04,375][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.014908564276993275, acc: 1.0)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 03:03:04,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:04,753][root][INFO] - Training Epoch: 10/10, step 502/574 com[2024-12-14 03:.27496811747550964, acc: 0.9615384340286255)
[2024-12-14 03:03:04,858][slam_llm.models.slam_model][INFO] - modality encoder
                                                                              [2024-12-14 03:03:05,107][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.1892341673374176, acc: 0.9259259104728699)
[2024-12-14 03:03:05,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:05,490][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.14288434386253357, acc: 0.9629629850387573)
      [2024-12-14 03:03:05,588][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                           [2024-12-14 03:03:05,817][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.3664108216762543, acc: 0.9245283007621765)
[2024-12-14 03:03:05,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:06,176][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.2827790677547455, acc: 0.931034505367279)
           [2024-12-14 03:03:06,343][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 03:03:06,787][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.9585903286933899, acc: 0.6936936974525452)
                                                                                                                                                              [2024-12-14 03:03:06,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:07,210][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.5733805894851685, acc: 0.8028169274330139)
                                                                     [2024-12-14 03:03:07,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:07,511][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.011222170665860176, acc: 1.0)
              [2024-12-14 03:03:07,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:07,821][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.03462039306759834, acc: 1.0)
                                                                                              [2024-12-14 03:03:07,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:08,121][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.13052663207054138, acc: 0.9230769276618958)
                                                                               [2024-12-14 03:03:09,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:10,768][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 1.3290393352508545, acc: 0.6214285492897034)
10, step 278/574 completed (loss: 0.2808399200439453, acc: 0.8723404407501221)
[2024-12-14 03:03:08,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:08,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:08,869][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.46671542525291443, acc: 0.8541666865348816)
[2024-12-14 03:03:08,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:09,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:09,237][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.25693291425704956, acc: 0.9318181872367859)
[2024-12-14 03:03:09,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:09,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:09,668][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.7057937383651733, acc: 0.759036123752594)
[2024-12-14 03:03:09,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:09,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:10,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:10,052][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 0.7522552013397217, acc: 0.7870370149612427)
[2024-12-14 03:03:10,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:10,422][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.686104953289032, acc: 0.8157894611358643)
[2024-12-14 03:03:10,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:10,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:10,748][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.4285963475704193, acc: 0.8823529481887817)
[2024-12-14 03:03:10,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:10,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:11,150][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.202724888920784, acc: 0.9750000238418579)
[2024-12-14 03:03:11,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:11,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:11,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:11,557][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 1.0805275440216064, acc: 0.6796875)
[2024-12-14 03:03:11,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:11,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:11,958][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 0.9495313167572021, acc: 0.7039999961853027)
[2024-12-14 03:03:12,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:12,282][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.6782751679420471, acc: 0.7802197933197021)
[2024-12-14 03:03:12,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:12,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:12,603][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 1.4472249746322632, acc: 0.5776397585868835)
[2024-12-14 03:03:12,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:12,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:12,942][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 1.5086088180541992, acc: 0.5463917255401611)
[2024-12-14 03:03:13,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:13,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:13,247][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.02262137643992901, acc: 1.0)
[2024-12-14 03:03:13,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:13,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:13,578][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.39105677604675293, acc: 0.9285714030265808)
[2024-12-14 03:03:13,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:13,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:13,918][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.4398980438709259, acc: 0.8793103694915771)
[2024-12-14 03:03:14,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:14,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:14,393][root][INFO] - Traini[2024-12-14 03:03:14,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:15,359][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 1.5688323974609375, acc: 0.5677965879440308)
_model][INFO] - modality encoder
[2024-12-14 03:03:14,950][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 1.2880668640136719, acc: 0.6340206265449524)
[2024-12-14 03:03:14,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:15,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:15,341][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.6484013795852661, acc: 0.8275862336158752)
[2024-12-14 03:03:15,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:15,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:15,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:15,691][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.2804799973964691, acc: 0.8888888955116272)
[2024-12-14 03:03:15,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:15,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:16,051][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.3071571886539459, acc: 0.8684210777282715)
[2024-12-14 03:03:16,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:16,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:16,432][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.2940891683101654, acc: 0.9285714030265808)
[2024-12-14 03:03:16,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:16,775][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.2674364149570465, acc: 0.96875)
[2024-12-14 03:03:16,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:16,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:17,160][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.22414855659008026, acc: 0.9433962106704712)
[2024-12-14 03:03:17,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:17,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:17,515][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.2037200927734375, acc: 0.9622641801834106)
[2024-12-14 03:03:17,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:17,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:17,829][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.2858225703239441, acc: 0.9117646813392639)
[2024-12-14 03:03:17,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:17,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:18,135][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.22633227705955505, acc: 0.9375)
[2024-12-14 03:03:18,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:18,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:18,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:18,499][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.37779754400253296, acc: 0.8852459192276001)
[2024-12-14 03:03:18,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:18,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:18,848][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.1189371794462204, acc: 0.9666666388511658)
[2024-12-14 03:03:18,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:19,172][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.18240447342395782, acc: 0.8947368264198303)
[2024-12-14 03:03:19,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:19,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:19,496][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.4898040294647217, acc: 0.8550724387168884)
[2024-12-14 03:03:19,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:19,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:19,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:20,026][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.15377959609031677, acc: 0.9772727489471436)
[2024-12-14 03:03:20,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:20,339][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.053302276879549026, acc: 1.0)
             [2024-12-14 03:03:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:20,651][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.07386014610528946, acc: 1.0)
                                                                                             [2024-12-14 03:03:20,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:21,008][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.033200155943632126, acc: 1.0)
[2024-12-14 03:03:21,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:21,403][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.27433016896247864, acc: 0.892307698726654)
                                                                                                                                                              [2024-12-14 03:03:21,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:21,774][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.36292046308517456, acc: 0.875)
                                                                              [2024-12-14 03:03:21,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:22,177][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.1334707885980606, acc: 0.96875)
                                                                                                                                                                          [2024-12-14 03:03:22,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:22,509][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.23467928171157837, acc: 0.9090909361839294)
[2024-12-14 03:03:22,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:22,840][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.04110807925462723, acc: 1.0)
                                                                                          [2024-12-14 03:03:22,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:23,204][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.07379835098981857, acc: 1.0)
                                                                                             [2024-12-14 03:03:23,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:23,565][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.005846863146871328, acc: 1.0)
                                                                                                                                                                           [2024-12-14 03:03:23,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:23,915][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.2949661314487457, acc: 0.8999999761581421)
 [2024-12-14 03:03:24,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:24,303][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.296139657497406, acc: 0.9024389982223511)
                                                                                                                                                                [2024-12-14 03:03:24,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:24,653][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.15823693573474884, acc: 0.9714285731315613)
                                                                              [2024-12-14 03:03:24,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:24,993][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.09860548377037048, acc: 0.9736841917037964)
[2024-12-14 03:03:25,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:25,337][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.06685293465852737, acc: 0.9677419066429138)
                  [2024-12-14 03:03:25,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:25,659][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.007159256376326084, acc: 1.0)
                                                                                            [2024-12-14 03:03:25,738][slam_llm.models.slam_model][INFO] - modality encoder
                                                            [2024-12-14 03:03:25,999][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.11017631739377975, acc: 0.9696969985961914)
                   [2024-12-14 03:03:26,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:26,346][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.14139670133590698, acc: 0.949999988079071)
                                                                               [2024-12-14 03:03:26,427][slam_llm.models.slam_model][INFO] - modality encoder
                                                            [2024-12-14 03:03:26,628][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.2263399362564087, acc: 0.9142857193946838)
                    [2024-12-14 03:03:26,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:26,953][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 1.0125031471252441, acc: 0.7153284549713135)
                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 03:03:27,677][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                              [2024-12-14 03:03:27,986][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:03:28,299][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                          [2024-12-14 03:03:28,614][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 03:03:28,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:28,788][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_10_step_411_loss_2.1523141860961914/model.pt
[2024-12-14 03:03:28,794][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 03:03:28,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:28,990][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.1491294950246811, acc: 0.9666666388511658)
[2024-12-14 03:03:29,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:29,180][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.23246951401233673, acc: 0.8928571343421936)
[2024-12-14 03:03:29,273][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.23712599277496338, acc: 0.9473684430122375)
[2024-12-14 03:03:29,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:29,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:29,562][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.2291572391986847, acc: 0.8999999761581421)
[2024-12-14 03:03:29,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:29,661][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.26684513688087463, acc: 0.9200000166893005)
[2024-12-14 03:03:29,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:29,946][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.11255975812673569, acc: 0.9696969985961914)
[2024-12-14 03:03:30,010][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.8288273215293884, acc: 0.7011494040489197)
[2024-12-14 03:03:30,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:30,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:30,326][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.1032809242606163, acc: 0.9545454382896423)
[2024-12-14 03:03:30,422][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.7425597310066223, acc: 0.7765957713127136)
[2024-12-14 03:03:30,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:30,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:30,708][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.4441417157649994, acc: 0.8627451062202454)
[2024-12-14 03:03:30,776][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 1.0263792276382446, acc: 0.650602400302887)
[2024-12-14 03:03:30,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:30,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:31,097][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.23152920603752136, acc: 0.9615384340286255)
[2024-12-14 03:03:31,175][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.07770676165819168, acc: 0.95652174949646)
[2024-12-14 03:03:31,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:31,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:31,448][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.3200676143169403, acc: 0.8888888955116272)
[2024-12-14 03:03:31,491][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.042772382497787476, acc: 1.0)
[2024-12-14 03:03:31,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:31,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:31,814][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.49546316266059875, acc: 0.8072289228439331)
[2024-12-14 03:03:31,839][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.34552350640296936, acc: 0.875)
[2024-12-14 03:03:31,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:31,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:32,190][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.22669902443885803, acc: 0.9622641801834106)
[2024-12-14 03:03:32,201][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.1326320767402649, acc: 0.949999988079071)
[2024-12-14 03:03:32,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:32,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:32,572][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.3239568769931793, acc: 0.8987341523170471)
[2024-12-14 03:03:32,574][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.03298642113804817, acc: 1.0)
[2024-12-14 03:03:32,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:32,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:32,911][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.13608695566654205, acc: 0.9666666388511658)
[2024-12-14 03:03:32,923][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.09808386862277985, acc: 0.9803921580314636)
[2024-12-14 03:03:32,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:33,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:33,247][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.23029248416423798, acc: 0.90625)
[2024-12-14 03:03:33,298][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.4506126344203949, acc: 0.8507462739944458)
[2024-12-14 03:03:33,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:33,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:33,611][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.43059343099594116, acc: 0.8611111044883728)
[2024-12-14 03:03:33,618][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.0257017370313406, acc: 1.0)
[2024-12-14 03:03:33,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:33,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:33,908][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.14145325124263763, acc: 0.9200000166893005)
[2024-12-14 03:03:33,956][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.25686195492744446, acc: 0.9629629850387573)
[2024-12-14 03:03:34,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:34,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:34,295][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.11623747646808624, acc: 0.9696969985961914)
[2024-12-14 03:03:34,298][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.3238900899887085, acc: 0.8888888955116272)
[2024-12-14 03:03:34,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:34,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:34,597][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.014953183941543102, acc: 1.0)
[2024-12-14 03:03:34,648][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.44620469212532043, acc: 0.8372092843055725)
[2024-12-14 03:03:34,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:34,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:34,919][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.09444517642259598, acc: 0.9729729890823364)
[2024-12-14 03:03:35,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:35,058][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.28288817405700684, acc: 0.8717948794364929)
[2024-12-14 03:03:35,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:35,302][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.08930189162492752, acc: 0.9629629850387573)
[2024-12-14 03:03:35,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:35,475][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.4371233284473419, acc: 0.8444444537162781)
[2024-12-14 03:03:35,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:35,671][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.10435917228460312, acc: 0.95652174949646)
[2024-12-14 03:03:35,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:35,865][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.04003509134054184, acc: 1.0)
[2024-12-14 03:03:35,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:36,000][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.00607635360211134, acc: 1.0)
[2024-12-14 03:03:36,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:36,186][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.25202953815460205, acc: 0.9230769276618958)
[2024-12-14 03:03:36,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:36,370][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.04045423865318298, acc: 0.9629629850387573)
[2024-12-14 03:03:36,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:36,533][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 1.1689059734344482, acc: 0.6483516693115234)
[2024-12-14 03:03:36,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:36,748][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.38835155963897705, acc: 0.9130434989929199)
[2024-12-14 03:03:36,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:37,080][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 1.154913306236267, acc: 0.686956524848938)
[2024-12-14 03:03:37,163][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.2619672417640686, acc: 0.9166666865348816)
[2024-12-14 03:03:37,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:37,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:37,448][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 1.0337376594543457, acc: 0.739130437374115)
[2024-12-14 03:03:37,546][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.03206239640712738, acc: 1.0)
[2024-12-14 03:03:37,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:37,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:37,810][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.4580334722995758, acc: 0.8775510191917419)
[2024-12-14 03:03:37,889][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.15783539414405823, acc: 0.9696969985961914)
[2024-12-14 03:03:37,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:37,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:38,195][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.0033883012365549803, acc: 1.0)
[2024-12-14 03:03:38,252][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.29259660840034485, acc: 0.9166666865348816)
[2024-12-14 03:03:38,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:38,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:38,597][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.015375452116131783, acc: 1.0)
[2024-12-14 03:03:38,653][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.27816832065582275, acc: 0.9090909361839294)
[2024-12-14 03:03:38,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:38,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:39,000][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.19235672056674957, acc: 0.9756097793579102)
[2024-12-14 03:03:39,011][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.04034719616174698, acc: 1.0)
[2024-12-14 03:03:39,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:39,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:39,327][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.30687791109085083, acc: 0.9111111164093018)
[2024-12-14 03:03:39,346][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.37361568212509155, acc: 0.9230769276618958)
[2024-12-14 03:03:39,613][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 03:03:40,000][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 03:03:40,346][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:03:40,703][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:03:41,092][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                            [2024-12-14 03:03:41,438][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                    [2024-12-14 03:03:41,795][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                      [2024-12-14 03:03:42,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:42,396][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                    [2024-12-14 03:03:42,800][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                         [2024-12-14 03:03:43,159][slam_llm.models.slam_model][INFO] - modality encoder
                                                            [2024-12-14 03:03:43,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:43,291][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.8453466296195984, acc: 0.7735849022865295)
[2024-12-14 03:03:43,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:43,445][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.4240596294403076, acc: 0.8928571343421936)
[2024-12-14 03:03:43,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:43,637][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.6362554430961609, acc: 0.8222222328186035)
[2024-12-14 03:03:43,692][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.34150585532188416, acc: 0.9104477763175964)
[2024-12-14 03:03:43,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:43,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:43,986][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.37769314646720886, acc: 0.9107142686843872)
[2024-12-14 03:03:44,041][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.3616016209125519, acc: 0.8611111044883728)
[2024-12-14 03:03:44,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:44,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:44,363][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.22293509542942047, acc: 0.9142857193946838)
[2024-12-14 03:03:44,424][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.4103153944015503, acc: 0.8804348111152649)
[2024-12-14 03:03:44,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:44,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:44,688][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.04411168396472931, acc: 1.0)
[2024-12-14 03:03:44,764][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.38150033354759216, acc: 0.8974359035491943)
[2024-12-14 03:03:44,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:44,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:44,987][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.004569225013256073, acc: 1.0)
[2024-12-14 03:03:45,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:45,134][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.33678269386291504, acc: 0.8947368264198303)
[2024-12-14 03:03:45,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:45,292][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.3332216739654541, acc: 0.8541666865348816)
[2024-12-14 03:03:45,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:45,485][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.2388249933719635, acc: 0.9387755393981934)
[2024-12-14 03:03:45,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:45,618][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.6347125172615051, acc: 0.8105263113975525)
[2024-12-14 03:03:45,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:45,831][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.18095727264881134, acc: 0.9696969985961914)
[2024-12-14 03:03:45,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:46,189][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 1.0707532167434692, acc: 0.71856290102005)
[2024-12-14 03:03:46,221][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.811869204044342, acc: 0.7628865838050842)
[2024-12-14 03:03:46,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:46,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:46,594][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.7271468639373779, acc: 0.7894737124443054)
[2024-12-14 03:03:46,598][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.36821138858795166, acc: 0.8571428656578064)
[2024-12-14 03:03:46,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:47,015][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 1.1152691841125488, acc: 0.6918604373931885)
[2024-12-14 03:03:47,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:47,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:47,354][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.214396670460701, acc: 0.9642857313156128)
[2024-12-14 03:03:47,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:47,683][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.5234881639480591, acc: 0.9012345671653748)
[2024-12-14 03:03:47,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:47,872][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 0.9121465682983398, acc: 0.6898396015167236)
[2024-12-14 03:03:48,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:48,051][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.10399812459945679, acc: 0.9722222089767456)
[2024-12-14 03:03:48,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:48,369][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.16859732568264008, acc: 0.9375)
[2024-12-14 03:03:48,434][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.4577273726463318, acc: 0.8468468189239502)
[2024-12-14 03:03:48,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:48,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:48,689][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.017352484166622162, acc: 1.0)
[2024-12-14 03:03:48,774][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.02962028980255127, acc: 1.0)
[2024-12-14 03:03:48,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:48,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:49,071][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.15861012041568756, acc: 0.97826087474823)
[2024-12-14 03:03:49,159][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.06462033092975616, acc: 1.0)
[2024-12-14 03:03:49,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:49,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:49,409][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.5374215245246887, acc: 0.8452380895614624)
[2024-12-14 03:03:49,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:49,496][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.03667484223842621, acc: 1.0)
[2024-12-14 03:03:49,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:49,727][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.7178380489349365, acc: 0.7710843086242676)
[2024-12-14 03:03:49,804][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.08083006739616394, acc: 1.0)
[2024-12-14 03:03:49,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:49,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:50,073][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.6788876056671143, acc: 0.7837837934494019)
[2024-12-14 03:03:50,160][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.12802304327487946, acc: 0.9473684430122375)
[2024-12-14 03:03:50,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:50,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:50,452][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.5358877182006836, acc: 0.8252426981925964)
[2024-12-14 03:03:50,473][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.011944356374442577, acc: 1.0)
[2024-12-14 03:03:50,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:50,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:50,824][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.634059727191925, acc: 0.8211382031440735)
[2024-12-14 03:03:50,830][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.020921234041452408, acc: 1.0)
[2024-12-14 03:03:50,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:50,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:51,165][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.13111180067062378, acc: 0.9047619104385376)
[2024-12-14 03:03:51,179][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.07613258808851242, acc: 1.0)
[2024-12-14 03:03:51,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:51,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:51,530][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.3350510895252228, acc: 0.9259259104728699)
[2024-12-14 03:03:51,600][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.2841092646121979, acc: 0.9285714030265808)
[2024-12-14 03:03:51,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:51,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:51,928][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 1.1274114847183228, acc: 0.6893203854560852)
[2024-12-14 03:03:51,999][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 0.8244271278381348, acc: 0.7745097875595093)
[2024-12-14 03:03:52,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:52,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:52,407][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 1.4606907367706299, acc: 0.5720524191856384)
[2024-12-14 03:03:52,450][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 1.177825927734375, acc: 0.6985294222831726)
[2024-12-14 03:03:52,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:52,756][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.6264415383338928, acc: 0.8333333134651184)
[2024-12-14 03:03:52,819][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 1.3778247833251953, acc: 0.6333333253860474)
[2024-12-14 03:03:52,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:52,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:53,140][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.9255902171134949, acc: 0.7055214643478394)
[2024-12-14 03:03:53,240][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 1.259009838104248, acc: 0.6388888955116272)
[2024-12-14 03:03:53,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:53,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:53,475][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.8726457953453064, acc: 0.7482014298439026)
[2024-12-14 03:03:53,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:53,597][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.36814507842063904, acc: 0.8837209343910217)
[2024-12-14 03:03:53,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:53,864][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 1.251196265220642, acc: 0.623115599155426)
[2024-12-14 03:03:53,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:53,992][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.23492871224880219, acc: 0.9583333134651184)
[2024-12-14 03:03:54,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:54,191][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.2904869318008423, acc: 0.8611111044883728)
[2024-12-14 03:03:54,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:54,418][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.31572458148002625, acc: 0.930232584476471)
[2024-12-14 03:03:54,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:54,549][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.1619330644607544, acc: 0.9696969985961914)
[2024-12-14 03:03:54,703][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                           [2024-12-14 03:03:55,083][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2024-12-14 03:03:55,546][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                           [2024-12-14 03:03:55,850][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:03:56,157][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                       [2024-12-14 03:03:56,565][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:03:56,993][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                  [2024-12-14 03:03:57,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:57,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:57,948][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2024-12-14 03:03:58,504][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.4881, device='cuda:0') eval_epoch_loss=tensor(2.1387, device='cuda:0') eval_epoch_acc=tensor(0.6002, device='cuda:0')
[2024-12-14 03:03:58,506][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 03:03:58,506][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 03:03:58,734][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_10_step_554_loss_2.138660192489624/model.pt
[2024-12-14 03:03:58,737][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 03:03:58,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:59,151][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.8232731223106384, acc: 0.7379310131072998)
                                                                                                                                                                                                                           [2024-12-14 03:03:59,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:59,496][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 1.1180996894836426, acc: 0.6928571462631226)
 [2024-12-14 03:03:59,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:03:59,877][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 0.953572154045105, acc: 0.7152317762374878)
                                                                                                                                                 [2024-12-14 03:03:59,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:00,250][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.6202027201652527, acc: 0.7692307829856873)
[2024-12-14 03:04:00,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:00,621][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.03824293240904808, acc: 1.0)
              [2024-12-14 03:04:00,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:00,973][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.02081827074289322, acc: 1.0)
                                                                                                                                                                             [2024-12-14 03:04:01,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:01,283][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.04437908157706261, acc: 1.0)
[2024-12-14 03:04:01,359][slam_llm.models.slam_model][INFO] - modality encoder
             [2024-12-14 03:04:01,583][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.27851593494415283, acc: 0.8717948794364929)
[2024-12-14 03:04:01,659][slam_llm.models.slam_model][INFO] - modality encoder
                                                          [2024-12-14 03:04:01,927][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.5658816695213318, acc: 0.8111110925674438)
                    [2024-12-14 03:04:02,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:02,252][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.3067093789577484, acc: 0.9090909361839294)
[2024-12-14 03:04:02,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:02,624][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.21917809545993805, acc: 0.9166666865348816)
[2024-12-14 03:04:02,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:02,986][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.33303630352020264, acc: 0.9137930870056152)
completed (loss: 0.014983056113123894, acc: 1.0)
[2024-12-14 03:04:02,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:02,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:03,004][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.18970909714698792, acc: 0.9259259104728699)
[2024-12-14 03:04:03,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:03,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:03,344][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.16996514797210693, acc: 0.9259259104728699)
[2024-12-14 03:04:03,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:03,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:03,659][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.3181985914707184, acc: 0.9056603908538818)
[2024-12-14 03:04:03,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:03,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:03,971][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.3053319752216339, acc: 0.8965517282485962)
[2024-12-14 03:04:04,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:04,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:04,552][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.8343161940574646, acc: 0.7567567825317383)
[2024-12-14 03:04:04,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:04,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:04,995][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.4791431128978729, acc: 0.8732394576072693)
[2024-12-14 03:04:05,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:05,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:05,340][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.007938675582408905, acc: 1.0)
[2024-12-14 03:04:05,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:05,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:05,692][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.11705811321735382, acc: 0.9333333373069763)
[2024-12-14 03:04:05,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:05,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:06,147][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.6342, train_epoch_loss=0.4911, epoch time 363.27794018387794s
[2024-12-14 03:04:06,147][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 03:04:06,147][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-12-14 03:04:06,147][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 03:04:06,148][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 29
[2024-12-14 03:04:06,148][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 03:04:06,152][root][INFO] - Key: avg_train_prep, Value: 4.700620651245117
[2024-12-14 03:04:06,153][root][INFO] - Key: avg_train_loss, Value: 1.2473043203353882
[2024-12-14 03:04:06,154][root][INFO] - Key: avg_train_acc, Value: 0.6678726077079773
[2024-12-14 03:04:06,154][root][INFO] - Key: avg_eval_prep, Value: 7.464081764221191
[2024-12-14 03:04:06,154][root][INFO] - Key: avg_eval_loss, Value: 1.9728691577911377
[2024-12-14 03:04:06,154][root][INFO] - Key: avg_eval_acc, Value: 0.5373177528381348
[2024-12-14 03:04:06,154][root][INFO] - Key: avg_epoch_time, Value: 363.21214829571545
[2024-12-14 03:04:06,154][root][INFO] - Key: avg_checkpoint_time, Value: 0.2289996923878789
dality encoder
[2024-12-14 03:04:09,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:09,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:09,598][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.3446553647518158, acc: 0.8214285969734192)
[2024-12-14 03:04:09,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:09,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:09,976][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.3484703302383423, acc: 0.8833333253860474)
[2024-12-14 03:04:10,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:10,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:10,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:10,670][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.4201265871524811, acc: 0.8611111044883728)
[2024-12-14 03:04:10,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:10,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:11,006][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.2102748304605484, acc: 0.9615384340286255)
[2024-12-14 03:04:11,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:11,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:11,298][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.39138874411582947, acc: 0.8709677457809448)
[2024-12-14 03:04:11,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:11,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:11,692][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.3649706542491913, acc: 0.8999999761581421)
[2024-12-14 03:04:11,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:11,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:12,098][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.11165276169776917, acc: 0.9629629850387573)
[2024-12-14 03:04:12,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:12,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:12,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:12,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:13,083][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 1.7057955265045166, acc: 0.5296609997749329)
[2024-12-14 03:04:13,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:13,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:13,434][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 1.0283979177474976, acc: 0.6716417670249939)
[2024-12-14 03:04:13,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:13,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:13,842][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 1.0309792757034302, acc: 0.6715328693389893)
[2024-12-14 03:04:13,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:14,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:14,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:14,399][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 1.3913145065307617, acc: 0.5849999785423279)
[2024-12-14 03:04:14,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:14,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:14,769][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.397143691778183, acc: 0.8703703880310059)
[2024-12-14 03:04:14,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:14,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:15,117][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.5526437163352966, acc: 0.807692289352417)
[2024-12-14 03:04:15,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:15,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:15,464][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.13770750164985657, acc: 0.9523809552192688)
[2024-12-14 03:04:15,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:15,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:15,793][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.4860319495201111, acc: 0.868852436542511)
[2024-12-14 03:04:15,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:16,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:16,163][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.4137890636920929, acc: 0.8644067645072937)
[2024-12-14 03:04:16,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:16,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:16,549][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.6401627063751221, acc: 0.7674418687820435)
[2024-12-14 03:04:16,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:16,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:16,944][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.414983868598938, acc: 0.9090909361839294)
[2024-12-14 03:04:17,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:17,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:17,315][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.4123270511627197, acc: 0.8679245114326477)
[2024-12-14 03:04:17,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:17,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:17,636][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.15857051312923431, acc: 1.0)
[2024-12-14 03:04:17,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:17,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:17,996][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.27178406715393066, acc: 0.9599999785423279)
[2024-12-14 03:04:18,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:18,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:18,333][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.0424642488360405, acc: 1.0)
[2024-12-14 03:04:18,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:18,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:18,649][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.12289488315582275, acc: 0.9545454382896423)
[2024-12-14 03:04:18,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:18,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:19,083][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.3515494465827942, acc: 0.892307698726654)
[2024-12-14 03:04:19,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:19,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:19,486][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.3411560654640198, acc: 0.890625)
[2024-12-14 03:04:19,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:19,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:19,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:19,878][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.12238621711730957, acc: 1.0)
[2024-12-14 03:04:19,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:20,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:20,226][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.22747202217578888, acc: 0.9090909361839294)
[2024-12-14 03:04:20,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:20,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:20,601][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.025560341775417328, acc: 1.0)
[2024-12-14 03:04:20,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:20,970][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.2092154324054718, acc: 0.9354838728904724)
[2024-12-14 03:04:21,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:21,339][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.016597632318735123, acc: 1.0)
[2024-12-14 03:04:21,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:21,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:21,702][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.1524990350008011, acc: 0.9666666388511658)
[2024-12-14 03:04:21,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:21,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:22,094][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.2703729569911957, acc: 0.8780487775802612)
[2024-12-14 03:04:22,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:22,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:22,433][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.1422233134508133, acc: 0.9142857193946838)
[2024-12-14 03:04:22,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:22,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:22,800][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.24296621978282928, acc: 0.8947368264198303)
[2024-12-14 03:04:22,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:22,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:23,169][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.04907406121492386, acc: 1.0)
[2024-12-14 03:04:23,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:23,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:23,534][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.01551370695233345, acc: 1.0)
[2024-12-14 03:04:23,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:23,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:23,903][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.18075017631053925, acc: 0.9090909361839294)
[2024-12-14 03:04:23,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:24,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:24,231][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.2305862456560135, acc: 0.9750000238418579)
[2024-12-14 03:04:24,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:24,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:24,535][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.23916438221931458, acc: 0.9285714030265808)
[2024-12-14 03:04:24,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:24,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:24,873][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 1.2336302995681763, acc: 0.6350364685058594)
[2024-12-14 03:04:25,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:25,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:25,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:25,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:26,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:26,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:26,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:26,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:26,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:26,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:27,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:27,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:27,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:27,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:28,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:28,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:28,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:28,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:28,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:29,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:29,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:29,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:29,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:29,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:30,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:30,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:30,547][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.5837, device='cuda:0') eval_epoch_loss=tensor(2.0260, device='cuda:0') eval_epoch_acc=tensor(0.5963, device='cuda:0')
[2024-12-14 03:04:30,548][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 03:04:30,548][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 03:04:30,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:30,808][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_10_step_411_loss_2.0259957313537598/model.pt
[2024-12-14 03:04:30,812][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 03:04:30,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:31,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:31,163][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.19355705380439758, acc: 0.9642857313156128)
[2024-12-14 03:04:31,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:31,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:31,486][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.08849440515041351, acc: 0.9666666388511658)
[2024-12-14 03:04:31,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:31,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:31,794][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.20303398370742798, acc: 0.939393937587738)
[2024-12-14 03:04:31,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:32,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:32,146][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.04959660768508911, acc: 1.0)
[2024-12-14 03:04:32,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:32,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:32,522][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.5001475214958191, acc: 0.8235294222831726)
[2024-12-14 03:04:32,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:32,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:32,881][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.3908124566078186, acc: 0.9230769276618958)
[2024-12-14 03:04:32,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:33,233][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.16965404152870178, acc: 0.9444444179534912)
[2024-12-14 03:04:33,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:33,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:33,581][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.19311204552650452, acc: 0.9750000238418579)
[2024-12-14 03:04:33,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:33,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:33,911][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.11454914510250092, acc: 0.949999988079071)
[2024-12-14 03:04:34,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:34,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:34,231][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.04128764197230339, acc: 1.0)
[2024-12-14 03:04:34,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:34,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:34,529][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.13934414088726044, acc: 0.9333333373069763)
[2024-12-14 03:04:34,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:34,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:34,877][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.11492165923118591, acc: 1.0)
[2024-12-14 03:04:34,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:35,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:35,249][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.3298763930797577, acc: 0.9444444179534912)
[2024-12-14 03:04:35,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:35,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:35,632][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.2840675711631775, acc: 0.9629629850387573)
[2024-12-14 03:04:35,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:35,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:35,970][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.2853686809539795, acc: 0.939393937587738)
[2024-12-14 03:04:36,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:36,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:36,283][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.03438926860690117, acc: 1.0)
[2024-12-14 03:04:36,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:36,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:36,620][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.08248622715473175, acc: 0.9729729890823364)
[2024-12-14 03:04:36,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:36,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:36,977][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.058899685740470886, acc: 0.9629629850387573)
[2024-12-14 03:04:37,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:37,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:37,352][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.05327029153704643, acc: 1.0)
[2024-12-14 03:04:37,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:37,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:37,749][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.03872920572757721, acc: 0.9629629850387573)
[2024-12-14 03:04:37,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:37,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:38,102][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.0682872012257576, acc: 0.9629629850387573)
[2024-12-14 03:04:38,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:38,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:38,452][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.23279382288455963, acc: 0.9130434989929199)
[2024-12-14 03:04:38,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:38,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:38,829][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.1295972764492035, acc: 0.9722222089767456)
[2024-12-14 03:04:38,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:38,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:39,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:39,181][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.1316763162612915, acc: 0.9599999785423279)
[2024-12-14 03:04:39,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:39,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:39,593][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.1658875048160553, acc: 0.9090909361839294)
[2024-12-14 03:04:39,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:39,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:39,979][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.22637015581130981, acc: 0.9166666865348816)
[2024-12-14 03:04:40,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:40,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:40,377][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.2084338665008545, acc: 0.9090909361839294)
[2024-12-14 03:04:40,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:40,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:40,761][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.004917549435049295, acc: 1.0)
[2024-12-14 03:04:40,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:40,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:41,158][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.20277462899684906, acc: 0.9487179517745972)
[2024-12-14 03:04:41,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:41,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:41,662][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.6053445339202881, acc: 0.8333333134651184)
[2024-12-14 03:04:41,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:41,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:41,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:42,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:42,383][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 1.2003557682037354, acc: 0.6399999856948853)
[2024-12-14 03:04:42,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:42,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:42,784][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 1.0105832815170288, acc: 0.7096773982048035)
[2024-12-14 03:04:42,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:42,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:43,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:43,446][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 1.3345403671264648, acc: 0.6218905448913574)
[2024-12-14 03:04:43,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:43,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:43,850][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.1979333460330963, acc: 0.9622641801834106)
[2024-12-14 03:04:44,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:44,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:44,279][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.23615407943725586, acc: 0.9545454382896423)
[2024-12-14 03:04:44,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:44,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:44,672][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.13960839807987213, acc: 0.95652174949646)
[2024-12-14 03:04:44,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:44,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:44,997][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.5015162825584412, acc: 0.8846153616905212)
[2024-12-14 03:04:45,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:45,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:45,289][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.07863052934408188, acc: 0.9642857313156128)
[2024-12-14 03:04:45,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:45,598][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.3296740651130676, acc: 0.9104477763175964)
[2024-12-14 03:04:45,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:45,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:45,946][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.348100483417511, acc: 0.8472222089767456)
[2024-12-14 03:04:46,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:46,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:46,332][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.3314869701862335, acc: 0.9239130616188049)
[2024-12-14 03:04:46,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:46,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:46,726][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.39279207587242126, acc: 0.8717948794364929)
[2024-12-14 03:04:46,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:46,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:47,110][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.2936501204967499, acc: 0.9342105388641357)
[2024-12-14 03:04:47,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:47,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:47,462][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.19641681015491486, acc: 0.9591836929321289)
[2024-12-14 03:04:47,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:47,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:47,810][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.024893272668123245, acc: 1.0)
[2024-12-14 03:04:47,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:48,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:48,172][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.7472677826881409, acc: 0.7422680258750916)
[2024-12-14 03:04:48,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:48,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:48,560][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.22506189346313477, acc: 0.9428571462631226)
[2024-12-14 03:04:48,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:48,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:48,972][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 1.0469635725021362, acc: 0.7093023061752319)
[2024-12-14 03:04:49,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:49,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:49,343][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.22305355966091156, acc: 0.9642857313156128)
[2024-12-14 03:04:49,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:49,680][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.5875927805900574, acc: 0.8148148059844971)
[2024-12-14 03:04:49,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:49,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:49,974][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.13266992568969727, acc: 1.0)
[2024-12-14 03:04:50,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:50,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:50,368][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.05033918097615242, acc: 1.0)
[2024-12-14 03:04:50,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:50,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:50,740][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.12276297062635422, acc: 0.9615384340286255)
[2024-12-14 03:04:50,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:50,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:51,037][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.1412808746099472, acc: 0.95652174949646)
[2024-12-14 03:04:51,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:51,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:51,327][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.5406940579414368, acc: 0.8095238208770752)
[2024-12-14 03:04:51,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:51,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:51,664][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.6074912548065186, acc: 0.8313252925872803)
[2024-12-14 03:04:51,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:51,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:51,998][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.7330634593963623, acc: 0.7747747898101807)
[2024-12-14 03:04:52,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:52,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:52,326][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.7776243090629578, acc: 0.7766990065574646)
[2024-12-14 03:04:52,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:52,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:52,648][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.6556983590126038, acc: 0.8048780560493469)
[2024-12-14 03:04:52,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:52,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:52,945][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.0918314978480339, acc: 0.9583333134651184)
[2024-12-14 03:04:53,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:53,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:53,268][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.17610394954681396, acc: 0.9642857313156128)
[2024-12-14 03:04:53,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:53,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:53,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:53,686][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 0.8571817278862, acc: 0.7254902124404907)
[2024-12-14 03:04:53,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:53,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:54,053][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 1.543430209159851, acc: 0.567685604095459)
[2024-12-14 03:04:54,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:54,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:54,424][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.5529481172561646, acc: 0.8541666865348816)
[2024-12-14 03:04:54,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:54,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:54,779][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.9547437429428101, acc: 0.7361963391304016)
[2024-12-14 03:04:54,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:55,170][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.9223217964172363, acc: 0.7194244861602783)
[2024-12-14 03:04:55,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:55,322][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.2099, device='cuda:0') eval_epoch_loss=tensor(1.9754, device='cuda:0') eval_epoch_acc=tensor(0.6031, device='cuda:0')
[2024-12-14 03:04:55,323][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 03:04:55,324][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 03:04:55,506][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 1.3069474697113037, acc: 0.6281406879425049)
[2024-12-14 03:04:55,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:55,645][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_10_step_554_loss_1.9754492044448853/model.pt
[2024-12-14 03:04:55,650][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 03:04:55,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:55,916][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.3936155140399933, acc: 0.8611111044883728)
[2024-12-14 03:04:56,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:56,086][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.805357038974762, acc: 0.7379310131072998)
[2024-12-14 03:04:56,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:56,245][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.23000988364219666, acc: 0.9090909361839294)
[2024-12-14 03:04:56,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:56,442][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 1.3262890577316284, acc: 0.6000000238418579)
[2024-12-14 03:04:56,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:56,604][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.2852924168109894, acc: 0.9259259104728699)
[2024-12-14 03:04:56,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:56,785][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 1.2204984426498413, acc: 0.6291390657424927)
[2024-12-14 03:04:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:56,936][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.3006981909275055, acc: 0.8500000238418579)
[2024-12-14 03:04:57,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:57,202][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.6406707763671875, acc: 0.8205128312110901)
[2024-12-14 03:04:57,307][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.33719268441200256, acc: 0.8500000238418579)
[2024-12-14 03:04:57,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:57,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:57,577][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.02822044864296913, acc: 1.0)
[2024-12-14 03:04:57,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:57,706][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.2766413986682892, acc: 0.8793103694915771)
[2024-12-14 03:04:57,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:57,919][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.04545559734106064, acc: 1.0)
[2024-12-14 03:04:58,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:58,081][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.06485480070114136, acc: 0.9677419066429138)
[2024-12-14 03:04:58,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:58,299][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.012773820199072361, acc: 1.0)
[2024-12-14 03:04:58,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:58,426][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.029749898239970207, acc: 1.0)
[2024-12-14 03:04:58,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:58,654][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.2109149545431137, acc: 0.9743589758872986)
[2024-12-14 03:04:58,735][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.36728766560554504, acc: 0.8888888955116272)
[2024-12-14 03:04:58,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:58,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:59,037][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.7111880779266357, acc: 0.7666666507720947)
[2024-12-14 03:04:59,082][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.5755236744880676, acc: 0.8095238208770752)
[2024-12-14 03:04:59,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:59,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:59,393][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.38464629650115967, acc: 0.8571428656578064)
[2024-12-14 03:04:59,424][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.16253168880939484, acc: 0.9545454382896423)
[2024-12-14 03:04:59,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:59,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:59,768][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.49576932191848755, acc: 0.8769230842590332)
[2024-12-14 03:04:59,778][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.15882796049118042, acc: 0.9166666865348816)
[2024-12-14 03:04:59,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:59,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:00,113][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.2195957750082016, acc: 0.9482758641242981)
[2024-12-14 03:05:00,135][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.32590293884277344, acc: 0.8999999761581421)
[2024-12-14 03:05:00,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:00,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:00,449][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.5119233131408691, acc: 0.8214285969734192)
[2024-12-14 03:05:00,468][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.18002644181251526, acc: 0.9655172228813171)
[2024-12-14 03:05:00,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:00,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:00,790][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.13783633708953857, acc: 0.9210526347160339)
[2024-12-14 03:05:00,841][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.26770150661468506, acc: 0.9411764740943909)
[2024-12-14 03:05:00,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:00,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:01,151][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.25412848591804504, acc: 0.8518518805503845)
[2024-12-14 03:05:01,217][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.27933749556541443, acc: 0.8965517282485962)
[2024-12-14 03:05:01,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:01,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:01,549][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 1.1966885328292847, acc: 0.6737967729568481)
[2024-12-14 03:05:01,593][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.13785718381404877, acc: 0.9473684430122375)
[2024-12-14 03:05:01,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:01,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:01,946][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.34102749824523926, acc: 0.7894737124443054)
[2024-12-14 03:05:01,954][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.25996652245521545, acc: 0.9193548560142517)
[2024-12-14 03:05:02,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:02,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:02,337][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.5890286564826965, acc: 0.8290598392486572)
[2024-12-14 03:05:02,345][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.6282297372817993, acc: 0.8125)
[2024-12-14 03:05:02,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:02,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:02,674][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 1.3644649982452393, acc: 0.6326530575752258)
[2024-12-14 03:05:02,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:02,805][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.48926886916160583, acc: 0.8539325594902039)
[2024-12-14 03:05:02,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:03,020][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 1.2246456146240234, acc: 0.6603773832321167)
[2024-12-14 03:05:03,229][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.6634668707847595, acc: 0.7528089880943298)
[2024-12-14 03:05:03,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:03,468][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.6013, train_epoch_loss=0.4708, epoch time 359.1273030601442s
[2024-12-14 03:05:03,468][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 03:05:03,468][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-12-14 03:05:03,468][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 03:05:03,468][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 29
[2024-12-14 03:05:03,468][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-12-14 03:05:03,473][root][INFO] - Key: avg_train_prep, Value: 4.658959865570068
[2024-12-14 03:05:03,474][root][INFO] - Key: avg_train_loss, Value: 1.2316491603851318
[2024-12-14 03:05:03,474][root][INFO] - Key: avg_train_acc, Value: 0.6730785369873047
[2024-12-14 03:05:03,474][root][INFO] - Key: avg_eval_prep, Value: 7.420613765716553
[2024-12-14 03:05:03,475][root][INFO] - Key: avg_eval_loss, Value: 1.960720419883728
[2024-12-14 03:05:03,475][root][INFO] - Key: avg_eval_acc, Value: 0.5406965613365173
[2024-12-14 03:05:03,475][root][INFO] - Key: avg_epoch_time, Value: 362.0695080313832
[2024-12-14 03:05:03,475][root][INFO] - Key: avg_checkpoint_time, Value: 0.2525958280079067
[2024-12-14 03:05:03,628][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 1.048539638519287, acc: 0.6808510422706604)
[2024-12-14 03:05:03,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:04,002][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.6678603887557983, acc: 0.8260869383811951)
[2024-12-14 03:05:04,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:04,348][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.07377137988805771, acc: 0.9599999785423279)
[2024-12-14 03:05:04,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:04,676][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.03099162131547928, acc: 1.0)
[2024-12-14 03:05:04,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:04,978][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.04431665688753128, acc: 0.9629629850387573)
[2024-12-14 03:05:05,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:05,342][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.2113591432571411, acc: 0.9259259104728699)
[2024-12-14 03:05:05,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:05,642][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.22640681266784668, acc: 0.9245283007621765)
[2024-12-14 03:05:05,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:05,957][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.297323614358902, acc: 0.8965517282485962)
[2024-12-14 03:05:06,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:06,597][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 1.1176927089691162, acc: 0.684684693813324)
[2024-12-14 03:05:06,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:07,050][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.5013243556022644, acc: 0.8309859037399292)
[2024-12-14 03:05:07,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:07,397][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.04335348680615425, acc: 1.0)
[2024-12-14 03:05:07,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:07,733][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.07895980030298233, acc: 0.9666666388511658)
[2024-12-14 03:05:07,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:08,077][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.214816153049469, acc: 0.8846153616905212)
[2024-12-14 03:05:09,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:11,162][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 1.1275784969329834, acc: 0.6857143044471741)
[2024-12-14 03:05:11,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:11,931][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.939349889755249, acc: 0.7539682388305664)
[2024-12-14 03:05:12,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:12,259][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.08724067360162735, acc: 1.0)
[2024-12-14 03:05:12,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:12,632][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.3563445806503296, acc: 0.8666666746139526)
[2024-12-14 03:05:12,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:13,332][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.3471323549747467, acc: 0.9027777910232544)
[2024-12-14 03:05:13,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:13,653][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.04908043518662453, acc: 0.9615384340286255)
[2024-12-14 03:05:13,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:14,000][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.0750950276851654, acc: 1.0)
[2024-12-14 03:05:14,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:14,313][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.160225510597229, acc: 0.8999999761581421)
[2024-12-14 03:05:14,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:14,686][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.38477790355682373, acc: 0.8518518805503845)
[2024-12-14 03:05:14,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:15,693][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 1.6361485719680786, acc: 0.555084764957428)
[2024-12-14 03:05:15,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:16,000][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 0.8788934350013733, acc: 0.753731369972229)
[2024-12-14 03:05:16,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:16,412][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 1.0389988422393799, acc: 0.7080292105674744)
[2024-12-14 03:05:16,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:16,977][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 1.2804967164993286, acc: 0.6449999809265137)
[2024-12-14 03:05:17,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:17,316][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.3506489396095276, acc: 0.8888888955116272)
[2024-12-14 03:05:17,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:17,635][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.28156664967536926, acc: 0.9230769276618958)
[2024-12-14 03:05:17,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:17,961][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.17506593465805054, acc: 0.9523809552192688)
[2024-12-14 03:05:18,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:18,336][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.3681596517562866, acc: 0.9180327653884888)
[2024-12-14 03:05:18,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:18,673][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.1644364893436432, acc: 0.9491525292396545)
[2024-12-14 03:05:18,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:19,047][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.6174144148826599, acc: 0.8372092843055725)
[2024-12-14 03:05:19,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:19,403][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.2663722038269043, acc: 0.9090909361839294)
[2024-12-14 03:05:19,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:19,818][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.25880730152130127, acc: 0.9245283007621765)
[2024-12-14 03:05:19,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:20,167][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.0952477678656578, acc: 0.9772727489471436)
[2024-12-14 03:05:20,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:20,534][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.09400833398103714, acc: 0.9599999785423279)
[2024-12-14 03:05:20,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:20,861][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.04635918140411377, acc: 1.0)
[2024-12-14 03:05:20,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:21,154][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.13394294679164886, acc: 0.9545454382896423)
[2024-12-14 03:05:21,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:21,571][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.32633259892463684, acc: 0.8461538553237915)
[2024-12-14 03:05:21,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:21,973][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.38456010818481445, acc: 0.90625)
[2024-12-14 03:05:22,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:22,368][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.17187203466892242, acc: 0.96875)
[2024-12-14 03:05:22,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:22,688][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.12235124409198761, acc: 0.939393937587738)
[2024-12-14 03:05:22,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:23,036][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.07613131403923035, acc: 1.0)
[2024-12-14 03:05:23,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:23,365][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.021614985540509224, acc: 1.0)
[2024-12-14 03:05:23,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:23,682][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.020640239119529724, acc: 1.0)
[2024-12-14 03:05:23,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:24,103][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.18819104135036469, acc: 0.8999999761581421)
[2024-12-14 03:05:24,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:24,470][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.06550400704145432, acc: 1.0)
[2024-12-14 03:05:24,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:24,791][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.0791606456041336, acc: 0.9714285731315613)
[2024-12-14 03:05:24,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:25,116][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.11719459295272827, acc: 0.9473684430122375)
[2024-12-14 03:05:25,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:25,490][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.06083925440907478, acc: 0.9677419066429138)
[2024-12-14 03:05:25,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:25,830][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.02365398406982422, acc: 1.0)
[2024-12-14 03:05:25,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:26,184][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.10470841825008392, acc: 0.939393937587738)
[2024-12-14 03:05:26,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:26,575][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.06575577706098557, acc: 0.9750000238418579)
[2024-12-14 03:05:26,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:26,928][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.21738620102405548, acc: 0.8857142925262451)
[2024-12-14 03:05:27,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:27,237][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 1.1076313257217407, acc: 0.6496350169181824)
[2024-12-14 03:05:28,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:28,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:28,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:29,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:29,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:29,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:30,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:30,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:31,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:31,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:31,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:32,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:32,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:33,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:33,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:33,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:34,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:34,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:34,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:35,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:35,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:35,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:36,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:36,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:36,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:37,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:37,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:37,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:38,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:38,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:38,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:39,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:39,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:39,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:40,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:40,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:40,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:41,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:41,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:41,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:42,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:42,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:42,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:43,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:43,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:43,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:43,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:44,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:44,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:44,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:45,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:45,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:45,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:46,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:46,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:47,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:47,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:48,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:48,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:48,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:49,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:49,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:50,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:50,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:50,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:51,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:51,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:51,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:52,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:52,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:53,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:53,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:53,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:54,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:54,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:54,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:55,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:55,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:55,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:56,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:56,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:56,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:57,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:57,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:58,018][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.2609, device='cuda:0') eval_epoch_loss=tensor(2.1115, device='cuda:0') eval_epoch_acc=tensor(0.5965, device='cuda:0')
[2024-12-14 03:05:58,019][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 03:05:58,019][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 03:05:58,236][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_10_step_554_loss_2.1115317344665527/model.pt
[2024-12-14 03:05:58,239][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft directory
[2024-12-14 03:05:58,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:58,686][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.7156310081481934, acc: 0.800000011920929)
[2024-12-14 03:05:58,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:59,059][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 0.9915627837181091, acc: 0.7357142567634583)
[2024-12-14 03:05:59,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:59,435][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 1.0189143419265747, acc: 0.6490066051483154)
[2024-12-14 03:05:59,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:59,816][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.5653838515281677, acc: 0.8205128312110901)
[2024-12-14 03:05:59,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:00,201][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.03351391851902008, acc: 1.0)
[2024-12-14 03:06:00,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:00,566][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.0643058568239212, acc: 1.0)
[2024-12-14 03:06:00,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:00,949][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.03580480068922043, acc: 1.0)
[2024-12-14 03:06:01,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:01,341][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.13491667807102203, acc: 0.9743589758872986)
[2024-12-14 03:06:01,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:01,701][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.4328049421310425, acc: 0.855555534362793)
[2024-12-14 03:06:01,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:02,098][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.3625679910182953, acc: 0.8701298832893372)
[2024-12-14 03:06:02,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:02,467][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.28487762808799744, acc: 0.9375)
[2024-12-14 03:06:02,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:02,786][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.15902310609817505, acc: 0.9137930870056152)
[2024-12-14 03:06:02,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:03,098][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.4901917278766632, acc: 0.8333333134651184)
[2024-12-14 03:06:03,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:03,442][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.2806095480918884, acc: 0.8947368264198303)
[2024-12-14 03:06:03,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:03,763][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.02021215669810772, acc: 1.0)
[2024-12-14 03:06:03,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:04,152][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 1.148483395576477, acc: 0.6737967729568481)
[2024-12-14 03:06:04,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:04,531][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.23068659007549286, acc: 0.9193548560142517)
[2024-12-14 03:06:04,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:04,908][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.564935028553009, acc: 0.8205128312110901)
[2024-12-14 03:06:05,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:05,232][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 1.2415504455566406, acc: 0.6275510191917419)
[2024-12-14 03:06:05,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:05,584][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 1.1228034496307373, acc: 0.6477987170219421)
[2024-12-14 03:06:05,999][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.6063, train_epoch_loss=0.4739, epoch time 360.9215785264969s
[2024-12-14 03:06:05,999][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 03:06:05,999][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-12-14 03:06:05,999][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 03:06:05,999][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 29
[2024-12-14 03:06:05,999][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 03:06:06,004][root][INFO] - Key: avg_train_prep, Value: 4.664773464202881
[2024-12-14 03:06:06,006][root][INFO] - Key: avg_train_loss, Value: 1.2337653636932373
[2024-12-14 03:06:06,006][root][INFO] - Key: avg_train_acc, Value: 0.6727461218833923
[2024-12-14 03:06:06,006][root][INFO] - Key: avg_eval_prep, Value: 7.4279985427856445
[2024-12-14 03:06:06,006][root][INFO] - Key: avg_eval_loss, Value: 1.9625005722045898
[2024-12-14 03:06:06,006][root][INFO] - Key: avg_eval_acc, Value: 0.538783609867096
[2024-12-14 03:06:06,006][root][INFO] - Key: avg_epoch_time, Value: 364.5696372997016
[2024-12-14 03:06:06,006][root][INFO] - Key: avg_checkpoint_time, Value: 0.2899475244805217
