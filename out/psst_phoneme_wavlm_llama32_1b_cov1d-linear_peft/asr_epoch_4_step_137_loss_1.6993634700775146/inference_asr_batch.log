[2024-12-14 03:04:26,159][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-12-14 03:04:26,159][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 03:04:26,159][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'cov1d-linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 03:04:27,526][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 03:04:32,984][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 03:04:32,986][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 03:04:32,988][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 03:04:32,989][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 03:04:36,723][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 03:04:36,724][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 03:04:36,725][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 03:04:36,846][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 03:04:36,848][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 03:04:36,927][slam_llm.utils.train_utils][INFO] - --> Module cov1d-linear
[2024-12-14 03:04:36,927][slam_llm.utils.train_utils][INFO] - --> cov1d-linear has 11.539456 Million params

[2024-12-14 03:04:36,927][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_137_loss_1.6993634700775146/model.pt
[2024-12-14 03:04:37,012][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 03:04:37,015][slam_llm.utils.train_utils][INFO] - --> asr has 17.175552 Million params

[2024-12-14 03:04:38,876][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 03:04:39,559][root][INFO] - --> Training Set Length = 652
[2024-12-14 03:04:39,559][root][INFO] - =====================================
[2024-12-14 03:04:40,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:41,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:42,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:42,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:48,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:04:53,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:00,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:06,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:07,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:13,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:18,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:24,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:30,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:33,956][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-12-14 03:05:33,957][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 03:05:33,957][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'cov1d-linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 03:05:35,494][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 03:05:40,806][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 03:05:40,808][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 03:05:40,810][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 03:05:40,811][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 03:05:45,999][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 03:05:46,001][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 03:05:46,002][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 03:05:46,125][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 03:05:46,127][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 03:05:46,210][slam_llm.utils.train_utils][INFO] - --> Module cov1d-linear
[2024-12-14 03:05:46,210][slam_llm.utils.train_utils][INFO] - --> cov1d-linear has 11.539456 Million params

[2024-12-14 03:05:46,210][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_137_loss_1.6993634700775146/model.pt
[2024-12-14 03:05:46,371][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 03:05:46,375][slam_llm.utils.train_utils][INFO] - --> asr has 17.175552 Million params

[2024-12-14 03:05:48,226][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 03:05:49,585][root][INFO] - --> Training Set Length = 652
[2024-12-14 03:05:49,586][root][INFO] - =====================================
[2024-12-14 03:05:50,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:52,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:53,118][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:05:53,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:54,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:54,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:05:57,430][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:06:03,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:08,781][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:06:14,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:15,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:17,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:18,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:18,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:19,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:19,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:20,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:21,201][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:06:26,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:29,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:29,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:30,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:32,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:33,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:34,220][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:06:39,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:40,515][slam_llm.models.slam_model][INFO] - modality encoder
p': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-12-14 03:06:36,587][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 03:06:36,587][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'cov1d-linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 03:06:38,180][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 03:06:41,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:43,435][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 03:06:43,438][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 03:06:43,440][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 03:06:43,441][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 03:06:47,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:49,045][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 03:06:49,045][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 03:06:49,046][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 03:06:49,163][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 03:06:49,165][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 03:06:49,250][slam_llm.utils.train_utils][INFO] - --> Module cov1d-linear
[2024-12-14 03:06:49,250][slam_llm.utils.train_utils][INFO] - --> cov1d-linear has 11.539456 Million params

[2024-12-14 03:06:49,250][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_cov1d-linear_peft/asr_epoch_4_step_137_loss_1.6993634700775146/model.pt
[2024-12-14 03:06:49,334][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 03:06:49,339][slam_llm.utils.train_utils][INFO] - --> asr has 17.175552 Million params

[2024-12-14 03:06:50,893][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 03:06:51,873][root][INFO] - --> Training Set Length = 652
[2024-12-14 03:06:51,874][root][INFO] - =====================================
[2024-12-14 03:06:53,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:53,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:53,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:54,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:54,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:06:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:00,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:01,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:02,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:04,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:04,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:05,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:06,554][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:07:07,922][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:07:13,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:13,530][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:07:19,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:19,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:20,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:25,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:25,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:28,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:28,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:29,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:29,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:30,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:30,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:31,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:31,756][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:07:37,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:37,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:39,579][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:07:40,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:40,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:42,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:43,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:43,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:44,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:49,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:50,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:50,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:55,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:55,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:56,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:56,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:57,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:07:58,315][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:08:03,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:04,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:04,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:04,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:05,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:06,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:07,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:07,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:10,160][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:08:10,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:15,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:17,136][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:08:17,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:18,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:18,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:19,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:21,455][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:08:24,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:27,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:27,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:30,220][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:08:30,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:30,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:31,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:31,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:32,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:33,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:33,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:36,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:39,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:41,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:42,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:42,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:42,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:45,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:46,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:46,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:48,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:48,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:52,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:52,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:54,378][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:08:58,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:59,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:08:59,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:00,132][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:09:05,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:05,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:07,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:11,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:13,017][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2024-12-14 03:09:17,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:18,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:19,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:19,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:19,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:19,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:20,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:20,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:21,270][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:09:25,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:26,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:27,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:27,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:32,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:33,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:38,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:39,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:39,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:40,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:44,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:45,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:50,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:51,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:56,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:09:58,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:02,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:04,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:07,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:10,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:13,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:16,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:16,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:16,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:17,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:18,161][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 03:10:23,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:24,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:24,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:25,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:25,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:26,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:27,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:28,093][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:10:33,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:34,648][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:10:40,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:41,158][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:10:41,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:42,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:43,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:43,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:44,190][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:10:49,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:50,536][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:10:56,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:56,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:57,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:57,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:58,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:58,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:10:59,627][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:11:05,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:05,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:06,477][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                             [2024-12-14 03:11:12,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:13,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:13,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:15,205][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:11:20,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:21,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:22,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:22,518][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2024-12-14 03:11:28,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:28,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:29,363][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                            [2024-12-14 03:11:34,930][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                            [2024-12-14 03:11:40,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:41,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:41,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:42,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:43,832][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:11:45,506][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2024-12-14 03:11:52,977][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:11:58,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:11:59,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:01,643][slam_llm.models.slam_model][INFO] - modality encoder
                                                                                                                                                              [2024-12-14 03:12:05,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:05,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:06,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:06,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:07,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:07,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:08,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:08,754][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:12:12,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:13,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:14,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:14,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:15,564][slam_llm.models.slam_model][INFO] - modality encoder
                                                                               [2024-12-14 03:12:19,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:21,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:22,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:22,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:24,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:26,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:27,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:27,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:28,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:28,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:29,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:30,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:30,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:31,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:31,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:35,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:35,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:35,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:36,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:36,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:37,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:37,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:37,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:38,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:38,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:39,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:44,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:44,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:45,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:49,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:50,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:50,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:51,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:51,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:52,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:52,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:52,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:53,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:54,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:54,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:54,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:12:55,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:00,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:01,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:01,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:07,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:07,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:07,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:08,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:08,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:09,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:09,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:10,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:13,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:14,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:14,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:15,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:16,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:16,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:17,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:20,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:23,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:24,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:26,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:26,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:27,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:31,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:32,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:32,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:33,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:34,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:38,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:39,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:40,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:45,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:51,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:51,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:52,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:53,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:54,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:13:56,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:03,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:09,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:15,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:15,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:16,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:16,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:22,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:28,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 03:14:36,015][slam_llm.models.slam_model][INFO] - modality encoder
