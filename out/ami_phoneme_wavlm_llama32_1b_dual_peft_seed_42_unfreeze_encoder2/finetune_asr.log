[2025-02-17 17:35:38,046][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 2, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-17 17:35:38,047][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-17 17:35:38,047][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'ami_phoneme_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2'}
[2025-02-17 17:35:38,047][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_phoneme_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2025-02-17_17-35-37.txt', 'log_interval': 5}
[2025-02-17 17:35:58,176][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-17 17:36:03,085][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-17 17:36:03,087][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-17 17:36:03,089][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-17 17:36:03,090][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-17 17:36:03,545][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-17 17:36:03,546][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-17 17:36:03,547][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-17 17:36:03,548][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-17 17:36:06,502][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-17 17:36:06,504][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-17 17:36:06,504][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-17 17:36:06,628][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-17 17:36:06,630][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-17 17:36:06,777][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-02-17 17:36:06,777][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-02-17 17:36:06,778][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-17 17:36:06,783][slam_llm.utils.train_utils][INFO] - --> asr has 346.244736 Million params

[2025-02-17 17:36:09,137][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-17 17:36:10,748][root][INFO] - --> Training Set Length = 107898
[2025-02-17 17:36:10,800][root][INFO] - --> Validation Set Length = 8351
[2025-02-17 17:36:10,801][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-17 17:36:10,801][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-17 17:36:12,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:12,729][root][INFO] - Training Epoch: 1/2, step 0/53949 completed (loss: 5.245827674865723, acc: 0.06451612710952759)
[2025-02-17 17:36:12,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:13,153][root][INFO] - Training Epoch: 1/2, step 1/53949 completed (loss: 5.01934814453125, acc: 0.10447761416435242)
[2025-02-17 17:36:13,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:13,580][root][INFO] - Training Epoch: 1/2, step 2/53949 completed (loss: 11.448973655700684, acc: 0.0)
[2025-02-17 17:36:13,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:14,004][root][INFO] - Training Epoch: 1/2, step 3/53949 completed (loss: 5.299704551696777, acc: 0.06201550364494324)
[2025-02-17 17:36:14,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:14,473][root][INFO] - Training Epoch: 1/2, step 4/53949 completed (loss: 4.596729755401611, acc: 0.12980769574642181)
[2025-02-17 17:36:14,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:14,847][root][INFO] - Training Epoch: 1/2, step 5/53949 completed (loss: 5.075525760650635, acc: 0.031578946858644485)
[2025-02-17 17:36:15,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:15,247][root][INFO] - Training Epoch: 1/2, step 6/53949 completed (loss: 5.302279949188232, acc: 0.07777778059244156)
[2025-02-17 17:36:15,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:15,650][root][INFO] - Training Epoch: 1/2, step 7/53949 completed (loss: 5.090919494628906, acc: 0.05882352963089943)
[2025-02-17 17:36:15,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:16,062][root][INFO] - Training Epoch: 1/2, step 8/53949 completed (loss: 5.0956878662109375, acc: 0.07042253762483597)
[2025-02-17 17:36:16,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:16,439][root][INFO] - Training Epoch: 1/2, step 9/53949 completed (loss: 5.6446452140808105, acc: 0.0)
[2025-02-17 17:36:16,611][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:16,861][root][INFO] - Training Epoch: 1/2, step 10/53949 completed (loss: 5.5849385261535645, acc: 0.027027027681469917)
[2025-02-17 17:36:17,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:17,286][root][INFO] - Training Epoch: 1/2, step 11/53949 completed (loss: 5.127256870269775, acc: 0.0810810774564743)
[2025-02-17 17:36:17,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:17,662][root][INFO] - Training Epoch: 1/2, step 12/53949 completed (loss: 4.816184997558594, acc: 0.09574468433856964)
[2025-02-17 17:36:17,872][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:18,086][root][INFO] - Training Epoch: 1/2, step 13/53949 completed (loss: 10.693931579589844, acc: 0.0)
[2025-02-17 17:36:18,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:18,537][root][INFO] - Training Epoch: 1/2, step 14/53949 completed (loss: 4.67731237411499, acc: 0.15286624431610107)
[2025-02-17 17:36:18,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:18,917][root][INFO] - Training Epoch: 1/2, step 15/53949 completed (loss: 5.887977600097656, acc: 0.04545454680919647)
[2025-02-17 17:36:19,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:19,322][root][INFO] - Training Epoch: 1/2, step 16/53949 completed (loss: 4.823955059051514, acc: 0.1041666641831398)
[2025-02-17 17:36:19,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:19,739][root][INFO] - Training Epoch: 1/2, step 17/53949 completed (loss: 7.0197625160217285, acc: 0.0)
[2025-02-17 17:36:19,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:20,137][root][INFO] - Training Epoch: 1/2, step 18/53949 completed (loss: 6.329439640045166, acc: 0.05000000074505806)
[2025-02-17 17:36:20,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:20,535][root][INFO] - Training Epoch: 1/2, step 19/53949 completed (loss: 4.968749046325684, acc: 0.171875)
[2025-02-17 17:36:20,723][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:20,922][root][INFO] - Training Epoch: 1/2, step 20/53949 completed (loss: 7.872012615203857, acc: 0.0)
[2025-02-17 17:36:21,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:21,330][root][INFO] - Training Epoch: 1/2, step 21/53949 completed (loss: 5.337185382843018, acc: 0.08474576473236084)
[2025-02-17 17:36:21,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:21,714][root][INFO] - Training Epoch: 1/2, step 22/53949 completed (loss: 6.176344871520996, acc: 0.09302325546741486)
[2025-02-17 17:36:21,872][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:22,080][root][INFO] - Training Epoch: 1/2, step 23/53949 completed (loss: 6.272274494171143, acc: 0.02857142873108387)
[2025-02-17 17:36:22,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:22,432][root][INFO] - Training Epoch: 1/2, step 24/53949 completed (loss: 4.4080657958984375, acc: 0.16129031777381897)
[2025-02-17 17:36:22,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:22,822][root][INFO] - Training Epoch: 1/2, step 25/53949 completed (loss: 5.3926167488098145, acc: 0.1147540956735611)
[2025-02-17 17:36:22,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:23,202][root][INFO] - Training Epoch: 1/2, step 26/53949 completed (loss: 4.321290493011475, acc: 0.19402985274791718)
[2025-02-17 17:36:23,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:23,575][root][INFO] - Training Epoch: 1/2, step 27/53949 completed (loss: 5.228351593017578, acc: 0.0317460335791111)
[2025-02-17 17:36:23,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:23,952][root][INFO] - Training Epoch: 1/2, step 28/53949 completed (loss: 5.4302544593811035, acc: 0.12244898080825806)
[2025-02-17 17:36:24,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:24,434][root][INFO] - Training Epoch: 1/2, step 29/53949 completed (loss: 4.929736137390137, acc: 0.15789473056793213)
[2025-02-17 17:36:24,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:24,840][root][INFO] - Training Epoch: 1/2, step 30/53949 completed (loss: 4.906543254852295, acc: 0.11940298229455948)
[2025-02-17 17:36:25,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:25,231][root][INFO] - Training Epoch: 1/2, step 31/53949 completed (loss: 5.837177753448486, acc: 0.03030303120613098)
[2025-02-17 17:36:25,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:25,679][root][INFO] - Training Epoch: 1/2, step 32/53949 completed (loss: 4.752037525177002, acc: 0.09090909361839294)
[2025-02-17 17:36:25,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:26,121][root][INFO] - Training Epoch: 1/2, step 33/53949 completed (loss: 4.402943134307861, acc: 0.1339285671710968)
[2025-02-17 17:36:26,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:26,530][root][INFO] - Training Epoch: 1/2, step 34/53949 completed (loss: 4.060229301452637, acc: 0.2199999988079071)
[2025-02-17 17:36:26,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:26,946][root][INFO] - Training Epoch: 1/2, step 35/53949 completed (loss: 4.2367377281188965, acc: 0.17142857611179352)
[2025-02-17 17:36:27,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:27,386][root][INFO] - Training Epoch: 1/2, step 36/53949 completed (loss: 6.893245697021484, acc: 0.0)
[2025-02-17 17:36:27,611][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:27,829][root][INFO] - Training Epoch: 1/2, step 37/53949 completed (loss: 4.857034683227539, acc: 0.08527132123708725)
[2025-02-17 17:36:27,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:28,173][root][INFO] - Training Epoch: 1/2, step 38/53949 completed (loss: 6.639993190765381, acc: 0.0)
[2025-02-17 17:36:28,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:28,550][root][INFO] - Training Epoch: 1/2, step 39/53949 completed (loss: 7.629823684692383, acc: 0.0)
[2025-02-17 17:36:28,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:28,924][root][INFO] - Training Epoch: 1/2, step 40/53949 completed (loss: 5.509577751159668, acc: 0.054054055362939835)
[2025-02-17 17:36:29,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:29,300][root][INFO] - Training Epoch: 1/2, step 41/53949 completed (loss: 4.415666580200195, acc: 0.10606060922145844)
[2025-02-17 17:36:29,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:29,719][root][INFO] - Training Epoch: 1/2, step 42/53949 completed (loss: 4.171785354614258, acc: 0.16935484111309052)
[2025-02-17 17:36:29,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:30,091][root][INFO] - Training Epoch: 1/2, step 43/53949 completed (loss: 4.796970367431641, acc: 0.1111111119389534)
[2025-02-17 17:36:30,257][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:30,479][root][INFO] - Training Epoch: 1/2, step 44/53949 completed (loss: 4.552026271820068, acc: 0.1428571492433548)
[2025-02-17 17:36:30,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:30,878][root][INFO] - Training Epoch: 1/2, step 45/53949 completed (loss: 5.2831196784973145, acc: 0.08695652335882187)
[2025-02-17 17:36:31,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:31,295][root][INFO] - Training Epoch: 1/2, step 46/53949 completed (loss: 4.237267971038818, acc: 0.15555556118488312)
[2025-02-17 17:36:31,466][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:31,704][root][INFO] - Training Epoch: 1/2, step 47/53949 completed (loss: 8.033361434936523, acc: 0.0)
[2025-02-17 17:36:31,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:32,166][root][INFO] - Training Epoch: 1/2, step 48/53949 completed (loss: 4.879943370819092, acc: 0.050847455859184265)
[2025-02-17 17:36:32,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:32,643][root][INFO] - Training Epoch: 1/2, step 49/53949 completed (loss: 5.097633361816406, acc: 0.0476190485060215)
[2025-02-17 17:36:32,849][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:33,082][root][INFO] - Training Epoch: 1/2, step 50/53949 completed (loss: 9.237499237060547, acc: 0.0)
[2025-02-17 17:36:33,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:33,473][root][INFO] - Training Epoch: 1/2, step 51/53949 completed (loss: 5.505380153656006, acc: 0.04878048598766327)
[2025-02-17 17:36:33,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:33,909][root][INFO] - Training Epoch: 1/2, step 52/53949 completed (loss: 3.949697256088257, acc: 0.13934426009655)
[2025-02-17 17:36:34,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:34,325][root][INFO] - Training Epoch: 1/2, step 53/53949 completed (loss: 3.36356520652771, acc: 0.2884615361690521)
[2025-02-17 17:36:34,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:34,719][root][INFO] - Training Epoch: 1/2, step 54/53949 completed (loss: 4.6929240226745605, acc: 0.12962962687015533)
[2025-02-17 17:36:34,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:35,113][root][INFO] - Training Epoch: 1/2, step 55/53949 completed (loss: 5.065619468688965, acc: 0.042553190141916275)
[2025-02-17 17:36:35,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:35,451][root][INFO] - Training Epoch: 1/2, step 56/53949 completed (loss: 4.297629356384277, acc: 0.13432836532592773)
[2025-02-17 17:36:35,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:35,888][root][INFO] - Training Epoch: 1/2, step 57/53949 completed (loss: 6.1672749519348145, acc: 0.05882352963089943)
[2025-02-17 17:36:36,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:36,285][root][INFO] - Training Epoch: 1/2, step 58/53949 completed (loss: 3.805903196334839, acc: 0.25)
[2025-02-17 17:36:36,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:36,711][root][INFO] - Training Epoch: 1/2, step 59/53949 completed (loss: 4.507020473480225, acc: 0.16190476715564728)
[2025-02-17 17:36:36,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:37,165][root][INFO] - Training Epoch: 1/2, step 60/53949 completed (loss: 4.02537727355957, acc: 0.15333333611488342)
[2025-02-17 17:36:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:37,672][root][INFO] - Training Epoch: 1/2, step 61/53949 completed (loss: 3.944088935852051, acc: 0.16393442451953888)
[2025-02-17 17:36:37,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:38,107][root][INFO] - Training Epoch: 1/2, step 62/53949 completed (loss: 5.770287990570068, acc: 0.043478261679410934)
[2025-02-17 17:36:38,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:38,499][root][INFO] - Training Epoch: 1/2, step 63/53949 completed (loss: 5.268547058105469, acc: 0.125)
[2025-02-17 17:36:38,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:38,892][root][INFO] - Training Epoch: 1/2, step 64/53949 completed (loss: 3.948005437850952, acc: 0.13636364042758942)
[2025-02-17 17:36:39,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:39,269][root][INFO] - Training Epoch: 1/2, step 65/53949 completed (loss: 3.3451120853424072, acc: 0.29870128631591797)
[2025-02-17 17:36:39,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:39,640][root][INFO] - Training Epoch: 1/2, step 66/53949 completed (loss: 5.710621356964111, acc: 0.0714285746216774)
[2025-02-17 17:36:39,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:40,017][root][INFO] - Training Epoch: 1/2, step 67/53949 completed (loss: 4.447818279266357, acc: 0.10638298094272614)
[2025-02-17 17:36:40,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:40,437][root][INFO] - Training Epoch: 1/2, step 68/53949 completed (loss: 6.998917579650879, acc: 0.0)
[2025-02-17 17:36:40,619][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:40,845][root][INFO] - Training Epoch: 1/2, step 69/53949 completed (loss: 4.161030292510986, acc: 0.1041666641831398)
[2025-02-17 17:36:41,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:41,238][root][INFO] - Training Epoch: 1/2, step 70/53949 completed (loss: 4.131645679473877, acc: 0.12264151126146317)
[2025-02-17 17:36:41,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:41,602][root][INFO] - Training Epoch: 1/2, step 71/53949 completed (loss: 4.364490985870361, acc: 0.15909090638160706)
[2025-02-17 17:36:41,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:41,965][root][INFO] - Training Epoch: 1/2, step 72/53949 completed (loss: 4.634852409362793, acc: 0.05882352963089943)
[2025-02-17 17:36:42,124][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:42,335][root][INFO] - Training Epoch: 1/2, step 73/53949 completed (loss: 4.339898586273193, acc: 0.11764705926179886)
[2025-02-17 17:36:42,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:42,712][root][INFO] - Training Epoch: 1/2, step 74/53949 completed (loss: 3.7581355571746826, acc: 0.1794871836900711)
[2025-02-17 17:36:42,840][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:43,061][root][INFO] - Training Epoch: 1/2, step 75/53949 completed (loss: 6.088994979858398, acc: 0.0)
[2025-02-17 17:36:43,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:43,435][root][INFO] - Training Epoch: 1/2, step 76/53949 completed (loss: 4.025516510009766, acc: 0.12612612545490265)
[2025-02-17 17:36:43,594][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:43,802][root][INFO] - Training Epoch: 1/2, step 77/53949 completed (loss: 6.375708103179932, acc: 0.0)
[2025-02-17 17:36:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:44,190][root][INFO] - Training Epoch: 1/2, step 78/53949 completed (loss: 4.509653568267822, acc: 0.04651162773370743)
[2025-02-17 17:36:44,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:44,612][root][INFO] - Training Epoch: 1/2, step 79/53949 completed (loss: 4.041140556335449, acc: 0.14130434393882751)
[2025-02-17 17:36:44,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:44,972][root][INFO] - Training Epoch: 1/2, step 80/53949 completed (loss: 5.92232084274292, acc: 0.09090909361839294)
[2025-02-17 17:36:45,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:45,356][root][INFO] - Training Epoch: 1/2, step 81/53949 completed (loss: 4.209428787231445, acc: 0.16393442451953888)
[2025-02-17 17:36:45,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:45,709][root][INFO] - Training Epoch: 1/2, step 82/53949 completed (loss: 3.7442214488983154, acc: 0.25)
[2025-02-17 17:36:45,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:46,080][root][INFO] - Training Epoch: 1/2, step 83/53949 completed (loss: 3.9104666709899902, acc: 0.0845070406794548)
[2025-02-17 17:36:46,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:46,486][root][INFO] - Training Epoch: 1/2, step 84/53949 completed (loss: 4.320321559906006, acc: 0.06976744532585144)
[2025-02-17 17:36:46,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:46,909][root][INFO] - Training Epoch: 1/2, step 85/53949 completed (loss: 5.4079461097717285, acc: 0.0)
[2025-02-17 17:36:47,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:47,323][root][INFO] - Training Epoch: 1/2, step 86/53949 completed (loss: 4.14327335357666, acc: 0.11666666716337204)
[2025-02-17 17:36:47,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:47,748][root][INFO] - Training Epoch: 1/2, step 87/53949 completed (loss: 3.6122748851776123, acc: 0.2795698940753937)
[2025-02-17 17:36:47,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:48,120][root][INFO] - Training Epoch: 1/2, step 88/53949 completed (loss: 4.359947681427002, acc: 0.10000000149011612)
[2025-02-17 17:36:48,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:48,530][root][INFO] - Training Epoch: 1/2, step 89/53949 completed (loss: 3.777186393737793, acc: 0.10000000149011612)
[2025-02-17 17:36:48,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:48,959][root][INFO] - Training Epoch: 1/2, step 90/53949 completed (loss: 3.8690929412841797, acc: 0.11594203114509583)
[2025-02-17 17:36:49,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:49,404][root][INFO] - Training Epoch: 1/2, step 91/53949 completed (loss: 3.776362895965576, acc: 0.14942528307437897)
[2025-02-17 17:36:49,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:49,829][root][INFO] - Training Epoch: 1/2, step 92/53949 completed (loss: 3.546708583831787, acc: 0.19672131538391113)
[2025-02-17 17:36:50,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:50,237][root][INFO] - Training Epoch: 1/2, step 93/53949 completed (loss: 5.4428324699401855, acc: 0.125)
[2025-02-17 17:36:50,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:50,623][root][INFO] - Training Epoch: 1/2, step 94/53949 completed (loss: 3.974059581756592, acc: 0.1666666716337204)
[2025-02-17 17:36:50,814][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:51,035][root][INFO] - Training Epoch: 1/2, step 95/53949 completed (loss: 3.5789008140563965, acc: 0.12068965286016464)
[2025-02-17 17:36:51,209][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:51,427][root][INFO] - Training Epoch: 1/2, step 96/53949 completed (loss: 3.4323177337646484, acc: 0.214067280292511)
[2025-02-17 17:36:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:51,772][root][INFO] - Training Epoch: 1/2, step 97/53949 completed (loss: 3.602004051208496, acc: 0.1734693944454193)
[2025-02-17 17:36:51,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:52,154][root][INFO] - Training Epoch: 1/2, step 98/53949 completed (loss: 3.4763896465301514, acc: 0.16814158856868744)
[2025-02-17 17:36:52,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:52,577][root][INFO] - Training Epoch: 1/2, step 99/53949 completed (loss: 3.5924715995788574, acc: 0.10000000149011612)
[2025-02-17 17:36:52,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:52,985][root][INFO] - Training Epoch: 1/2, step 100/53949 completed (loss: 3.7510409355163574, acc: 0.1538461595773697)
[2025-02-17 17:36:53,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:53,338][root][INFO] - Training Epoch: 1/2, step 101/53949 completed (loss: 3.7403481006622314, acc: 0.1515151560306549)
[2025-02-17 17:36:53,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:53,688][root][INFO] - Training Epoch: 1/2, step 102/53949 completed (loss: 4.614480972290039, acc: 0.1111111119389534)
[2025-02-17 17:36:53,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:54,029][root][INFO] - Training Epoch: 1/2, step 103/53949 completed (loss: 3.5067901611328125, acc: 0.2112676054239273)
[2025-02-17 17:36:54,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:54,374][root][INFO] - Training Epoch: 1/2, step 104/53949 completed (loss: 3.7167675495147705, acc: 0.20512820780277252)
[2025-02-17 17:36:54,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:54,764][root][INFO] - Training Epoch: 1/2, step 105/53949 completed (loss: 3.358937978744507, acc: 0.2083333283662796)
[2025-02-17 17:36:54,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:55,170][root][INFO] - Training Epoch: 1/2, step 106/53949 completed (loss: 3.0705792903900146, acc: 0.32710281014442444)
[2025-02-17 17:36:55,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:55,621][root][INFO] - Training Epoch: 1/2, step 107/53949 completed (loss: 3.6725456714630127, acc: 0.14444445073604584)
[2025-02-17 17:36:55,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:56,020][root][INFO] - Training Epoch: 1/2, step 108/53949 completed (loss: 4.078157424926758, acc: 0.13333334028720856)
[2025-02-17 17:36:56,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:56,399][root][INFO] - Training Epoch: 1/2, step 109/53949 completed (loss: 3.513481855392456, acc: 0.24137930572032928)
[2025-02-17 17:36:56,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:56,842][root][INFO] - Training Epoch: 1/2, step 110/53949 completed (loss: 3.642831802368164, acc: 0.10869564861059189)
[2025-02-17 17:36:57,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:57,268][root][INFO] - Training Epoch: 1/2, step 111/53949 completed (loss: 3.3775784969329834, acc: 0.24137930572032928)
[2025-02-17 17:36:57,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:57,689][root][INFO] - Training Epoch: 1/2, step 112/53949 completed (loss: 3.092461585998535, acc: 0.19718310236930847)
[2025-02-17 17:36:57,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:58,056][root][INFO] - Training Epoch: 1/2, step 113/53949 completed (loss: 3.4471848011016846, acc: 0.23333333432674408)
[2025-02-17 17:36:58,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:58,436][root][INFO] - Training Epoch: 1/2, step 114/53949 completed (loss: 3.910175323486328, acc: 0.09090909361839294)
[2025-02-17 17:36:58,606][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:58,894][root][INFO] - Training Epoch: 1/2, step 115/53949 completed (loss: 3.359776735305786, acc: 0.2278480976819992)
[2025-02-17 17:36:59,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:59,340][root][INFO] - Training Epoch: 1/2, step 116/53949 completed (loss: 3.1629533767700195, acc: 0.23456789553165436)
[2025-02-17 17:36:59,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:36:59,813][root][INFO] - Training Epoch: 1/2, step 117/53949 completed (loss: 3.1703169345855713, acc: 0.25)
[2025-02-17 17:36:59,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:00,210][root][INFO] - Training Epoch: 1/2, step 118/53949 completed (loss: 2.959993600845337, acc: 0.2926829159259796)
[2025-02-17 17:37:00,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:00,614][root][INFO] - Training Epoch: 1/2, step 119/53949 completed (loss: 3.7758774757385254, acc: 0.25)
[2025-02-17 17:37:00,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:01,047][root][INFO] - Training Epoch: 1/2, step 120/53949 completed (loss: 3.7240684032440186, acc: 0.22727273404598236)
[2025-02-17 17:37:01,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:01,439][root][INFO] - Training Epoch: 1/2, step 121/53949 completed (loss: 3.1797406673431396, acc: 0.2292993664741516)
[2025-02-17 17:37:01,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:01,897][root][INFO] - Training Epoch: 1/2, step 122/53949 completed (loss: 3.1981186866760254, acc: 0.22439023852348328)
[2025-02-17 17:37:02,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:02,312][root][INFO] - Training Epoch: 1/2, step 123/53949 completed (loss: 3.3585877418518066, acc: 0.13924050331115723)
[2025-02-17 17:37:02,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:02,729][root][INFO] - Training Epoch: 1/2, step 124/53949 completed (loss: 3.555209159851074, acc: 0.12244898080825806)
[2025-02-17 17:37:02,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:03,099][root][INFO] - Training Epoch: 1/2, step 125/53949 completed (loss: 3.1179213523864746, acc: 0.2705882489681244)
[2025-02-17 17:37:03,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:03,456][root][INFO] - Training Epoch: 1/2, step 126/53949 completed (loss: 2.909449338912964, acc: 0.3333333432674408)
[2025-02-17 17:37:03,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:03,861][root][INFO] - Training Epoch: 1/2, step 127/53949 completed (loss: 3.201357841491699, acc: 0.17475728690624237)
[2025-02-17 17:37:04,032][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:04,305][root][INFO] - Training Epoch: 1/2, step 128/53949 completed (loss: 3.168694257736206, acc: 0.13636364042758942)
[2025-02-17 17:37:04,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:04,737][root][INFO] - Training Epoch: 1/2, step 129/53949 completed (loss: 3.2923789024353027, acc: 0.25)
[2025-02-17 17:37:04,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:05,168][root][INFO] - Training Epoch: 1/2, step 130/53949 completed (loss: 2.8897528648376465, acc: 0.24742268025875092)
[2025-02-17 17:37:05,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:05,568][root][INFO] - Training Epoch: 1/2, step 131/53949 completed (loss: 3.5502517223358154, acc: 0.21052631735801697)
[2025-02-17 17:37:05,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:06,023][root][INFO] - Training Epoch: 1/2, step 132/53949 completed (loss: 2.873971939086914, acc: 0.25999999046325684)
[2025-02-17 17:37:06,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:06,493][root][INFO] - Training Epoch: 1/2, step 133/53949 completed (loss: 3.2093875408172607, acc: 0.18539325892925262)
[2025-02-17 17:37:06,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:06,932][root][INFO] - Training Epoch: 1/2, step 134/53949 completed (loss: 3.0295591354370117, acc: 0.14000000059604645)
[2025-02-17 17:37:07,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:07,328][root][INFO] - Training Epoch: 1/2, step 135/53949 completed (loss: 1.1005520820617676, acc: 0.800000011920929)
[2025-02-17 17:37:07,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:07,728][root][INFO] - Training Epoch: 1/2, step 136/53949 completed (loss: 3.6361114978790283, acc: 0.10526315867900848)
[2025-02-17 17:37:07,904][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:08,126][root][INFO] - Training Epoch: 1/2, step 137/53949 completed (loss: 3.099199056625366, acc: 0.17241379618644714)
[2025-02-17 17:37:08,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:08,533][root][INFO] - Training Epoch: 1/2, step 138/53949 completed (loss: 2.953869104385376, acc: 0.19607843458652496)
[2025-02-17 17:37:08,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:08,934][root][INFO] - Training Epoch: 1/2, step 139/53949 completed (loss: 3.3542442321777344, acc: 0.15714286267757416)
[2025-02-17 17:37:09,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:09,340][root][INFO] - Training Epoch: 1/2, step 140/53949 completed (loss: 1.5138747692108154, acc: 0.5714285969734192)
[2025-02-17 17:37:09,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:09,724][root][INFO] - Training Epoch: 1/2, step 141/53949 completed (loss: 3.0263147354125977, acc: 0.23999999463558197)
[2025-02-17 17:37:09,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:10,104][root][INFO] - Training Epoch: 1/2, step 142/53949 completed (loss: 3.3004846572875977, acc: 0.18292683362960815)
[2025-02-17 17:37:10,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:10,509][root][INFO] - Training Epoch: 1/2, step 143/53949 completed (loss: 2.772895097732544, acc: 0.28378379344940186)
[2025-02-17 17:37:10,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:10,921][root][INFO] - Training Epoch: 1/2, step 144/53949 completed (loss: 2.2945876121520996, acc: 0.40740740299224854)
[2025-02-17 17:37:11,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:11,312][root][INFO] - Training Epoch: 1/2, step 145/53949 completed (loss: 3.1876304149627686, acc: 0.19090908765792847)
[2025-02-17 17:37:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:11,710][root][INFO] - Training Epoch: 1/2, step 146/53949 completed (loss: 3.320385217666626, acc: 0.2222222238779068)
[2025-02-17 17:37:11,896][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:12,110][root][INFO] - Training Epoch: 1/2, step 147/53949 completed (loss: 3.202516555786133, acc: 0.190476194024086)
[2025-02-17 17:37:12,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:12,592][root][INFO] - Training Epoch: 1/2, step 148/53949 completed (loss: 2.565281867980957, acc: 0.25)
[2025-02-17 17:37:12,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:13,021][root][INFO] - Training Epoch: 1/2, step 149/53949 completed (loss: 2.9730746746063232, acc: 0.25)
[2025-02-17 17:37:13,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:13,472][root][INFO] - Training Epoch: 1/2, step 150/53949 completed (loss: 2.8627893924713135, acc: 0.29629629850387573)
[2025-02-17 17:37:13,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:13,942][root][INFO] - Training Epoch: 1/2, step 151/53949 completed (loss: 2.786404609680176, acc: 0.2857142984867096)
[2025-02-17 17:37:14,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:14,344][root][INFO] - Training Epoch: 1/2, step 152/53949 completed (loss: 2.868631601333618, acc: 0.2368421107530594)
[2025-02-17 17:37:14,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:14,716][root][INFO] - Training Epoch: 1/2, step 153/53949 completed (loss: 3.0093019008636475, acc: 0.1538461595773697)
[2025-02-17 17:37:14,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:15,095][root][INFO] - Training Epoch: 1/2, step 154/53949 completed (loss: 1.4083271026611328, acc: 0.625)
[2025-02-17 17:37:15,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:15,547][root][INFO] - Training Epoch: 1/2, step 155/53949 completed (loss: 3.058706283569336, acc: 0.21290323138237)
[2025-02-17 17:37:15,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:15,954][root][INFO] - Training Epoch: 1/2, step 156/53949 completed (loss: 2.5733325481414795, acc: 0.5)
[2025-02-17 17:37:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:16,397][root][INFO] - Training Epoch: 1/2, step 157/53949 completed (loss: 2.922128438949585, acc: 0.21935483813285828)
[2025-02-17 17:37:16,545][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:16,762][root][INFO] - Training Epoch: 1/2, step 158/53949 completed (loss: 2.901703357696533, acc: 0.2857142984867096)
[2025-02-17 17:37:16,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:17,161][root][INFO] - Training Epoch: 1/2, step 159/53949 completed (loss: 2.520124673843384, acc: 0.3125)
[2025-02-17 17:37:17,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:17,530][root][INFO] - Training Epoch: 1/2, step 160/53949 completed (loss: 3.1586973667144775, acc: 0.1592920422554016)
[2025-02-17 17:37:17,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:17,933][root][INFO] - Training Epoch: 1/2, step 161/53949 completed (loss: 2.7313032150268555, acc: 0.34375)
[2025-02-17 17:37:18,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:18,333][root][INFO] - Training Epoch: 1/2, step 162/53949 completed (loss: 3.346862554550171, acc: 0.2183908075094223)
[2025-02-17 17:37:18,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:18,722][root][INFO] - Training Epoch: 1/2, step 163/53949 completed (loss: 2.7852089405059814, acc: 0.27184465527534485)
[2025-02-17 17:37:18,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:19,105][root][INFO] - Training Epoch: 1/2, step 164/53949 completed (loss: 2.6449737548828125, acc: 0.3802816867828369)
[2025-02-17 17:37:19,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:19,481][root][INFO] - Training Epoch: 1/2, step 165/53949 completed (loss: 0.7511700987815857, acc: 0.8333333134651184)
[2025-02-17 17:37:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:19,843][root][INFO] - Training Epoch: 1/2, step 166/53949 completed (loss: 2.9266390800476074, acc: 0.2209944725036621)
[2025-02-17 17:37:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:20,248][root][INFO] - Training Epoch: 1/2, step 167/53949 completed (loss: 3.011660575866699, acc: 0.2016129046678543)
[2025-02-17 17:37:20,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:20,682][root][INFO] - Training Epoch: 1/2, step 168/53949 completed (loss: 2.958850622177124, acc: 0.234375)
[2025-02-17 17:37:20,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:21,141][root][INFO] - Training Epoch: 1/2, step 169/53949 completed (loss: 3.2105774879455566, acc: 0.1599999964237213)
[2025-02-17 17:37:21,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:21,553][root][INFO] - Training Epoch: 1/2, step 170/53949 completed (loss: 3.037867784500122, acc: 0.1515151560306549)
[2025-02-17 17:37:21,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:21,941][root][INFO] - Training Epoch: 1/2, step 171/53949 completed (loss: 2.751723051071167, acc: 0.2680412232875824)
[2025-02-17 17:37:22,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:22,308][root][INFO] - Training Epoch: 1/2, step 172/53949 completed (loss: 3.1323254108428955, acc: 0.2266666740179062)
[2025-02-17 17:37:22,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:22,721][root][INFO] - Training Epoch: 1/2, step 173/53949 completed (loss: 2.856830358505249, acc: 0.23000000417232513)
[2025-02-17 17:37:22,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:23,109][root][INFO] - Training Epoch: 1/2, step 174/53949 completed (loss: 2.9268887042999268, acc: 0.2261904776096344)
[2025-02-17 17:37:23,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:23,566][root][INFO] - Training Epoch: 1/2, step 175/53949 completed (loss: 2.4953901767730713, acc: 0.35353535413742065)
[2025-02-17 17:37:23,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:23,927][root][INFO] - Training Epoch: 1/2, step 176/53949 completed (loss: 3.0217015743255615, acc: 0.1875)
[2025-02-17 17:37:24,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:24,312][root][INFO] - Training Epoch: 1/2, step 177/53949 completed (loss: 2.8005404472351074, acc: 0.3571428656578064)
[2025-02-17 17:37:24,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:24,710][root][INFO] - Training Epoch: 1/2, step 178/53949 completed (loss: 3.1056125164031982, acc: 0.18840579688549042)
[2025-02-17 17:37:24,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:25,113][root][INFO] - Training Epoch: 1/2, step 179/53949 completed (loss: 3.0210886001586914, acc: 0.20000000298023224)
[2025-02-17 17:37:25,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:25,546][root][INFO] - Training Epoch: 1/2, step 180/53949 completed (loss: 3.0941131114959717, acc: 0.22689075767993927)
[2025-02-17 17:37:25,693][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:25,912][root][INFO] - Training Epoch: 1/2, step 181/53949 completed (loss: 2.7914140224456787, acc: 0.2688172161579132)
[2025-02-17 17:37:26,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:26,344][root][INFO] - Training Epoch: 1/2, step 182/53949 completed (loss: 2.9858531951904297, acc: 0.21739129722118378)
[2025-02-17 17:37:26,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:26,748][root][INFO] - Training Epoch: 1/2, step 183/53949 completed (loss: 2.7499337196350098, acc: 0.260869562625885)
[2025-02-17 17:37:26,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:27,122][root][INFO] - Training Epoch: 1/2, step 184/53949 completed (loss: 2.6412899494171143, acc: 0.27358490228652954)
[2025-02-17 17:37:27,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:27,488][root][INFO] - Training Epoch: 1/2, step 185/53949 completed (loss: 2.622748374938965, acc: 0.37288135290145874)
[2025-02-17 17:37:27,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:27,868][root][INFO] - Training Epoch: 1/2, step 186/53949 completed (loss: 2.56278920173645, acc: 0.3888888955116272)
[2025-02-17 17:37:28,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:28,294][root][INFO] - Training Epoch: 1/2, step 187/53949 completed (loss: 2.832226037979126, acc: 0.1666666716337204)
[2025-02-17 17:37:28,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:28,703][root][INFO] - Training Epoch: 1/2, step 188/53949 completed (loss: 2.5223004817962646, acc: 0.40625)
[2025-02-17 17:37:28,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:29,100][root][INFO] - Training Epoch: 1/2, step 189/53949 completed (loss: 2.78581166267395, acc: 0.24550898373126984)
[2025-02-17 17:37:29,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:29,513][root][INFO] - Training Epoch: 1/2, step 190/53949 completed (loss: 2.507997751235962, acc: 0.3636363744735718)
[2025-02-17 17:37:29,659][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:29,873][root][INFO] - Training Epoch: 1/2, step 191/53949 completed (loss: 2.943615436553955, acc: 0.2641509473323822)
[2025-02-17 17:37:30,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:30,209][root][INFO] - Training Epoch: 1/2, step 192/53949 completed (loss: 2.9484589099884033, acc: 0.1910112351179123)
[2025-02-17 17:37:30,385][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:30,595][root][INFO] - Training Epoch: 1/2, step 193/53949 completed (loss: 2.841724395751953, acc: 0.30000001192092896)
[2025-02-17 17:37:30,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:30,978][root][INFO] - Training Epoch: 1/2, step 194/53949 completed (loss: 1.7174899578094482, acc: 0.625)
[2025-02-17 17:37:31,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:31,386][root][INFO] - Training Epoch: 1/2, step 195/53949 completed (loss: 2.7174434661865234, acc: 0.2702702581882477)
[2025-02-17 17:37:31,559][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:31,765][root][INFO] - Training Epoch: 1/2, step 196/53949 completed (loss: 2.1849799156188965, acc: 0.5)
[2025-02-17 17:37:31,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:32,163][root][INFO] - Training Epoch: 1/2, step 197/53949 completed (loss: 2.2620553970336914, acc: 0.4032258093357086)
[2025-02-17 17:37:32,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:32,573][root][INFO] - Training Epoch: 1/2, step 198/53949 completed (loss: 2.912585973739624, acc: 0.2822085916996002)
[2025-02-17 17:37:32,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:32,957][root][INFO] - Training Epoch: 1/2, step 199/53949 completed (loss: 2.598820209503174, acc: 0.3076923191547394)
[2025-02-17 17:37:33,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:33,332][root][INFO] - Training Epoch: 1/2, step 200/53949 completed (loss: 2.657843589782715, acc: 0.3333333432674408)
[2025-02-17 17:37:33,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:33,709][root][INFO] - Training Epoch: 1/2, step 201/53949 completed (loss: 2.8610150814056396, acc: 0.25)
[2025-02-17 17:37:33,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:34,058][root][INFO] - Training Epoch: 1/2, step 202/53949 completed (loss: 2.4404871463775635, acc: 0.3888888955116272)
[2025-02-17 17:37:34,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:34,428][root][INFO] - Training Epoch: 1/2, step 203/53949 completed (loss: 0.7778177261352539, acc: 0.6666666865348816)
[2025-02-17 17:37:34,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:34,797][root][INFO] - Training Epoch: 1/2, step 204/53949 completed (loss: 1.4284685850143433, acc: 0.7142857313156128)
[2025-02-17 17:37:34,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:35,185][root][INFO] - Training Epoch: 1/2, step 205/53949 completed (loss: 2.54247784614563, acc: 0.30136987566947937)
[2025-02-17 17:37:35,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:35,567][root][INFO] - Training Epoch: 1/2, step 206/53949 completed (loss: 2.649829864501953, acc: 0.28346458077430725)
[2025-02-17 17:37:35,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:35,987][root][INFO] - Training Epoch: 1/2, step 207/53949 completed (loss: 2.650444269180298, acc: 0.2584269642829895)
[2025-02-17 17:37:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:36,352][root][INFO] - Training Epoch: 1/2, step 208/53949 completed (loss: 2.502108335494995, acc: 0.1428571492433548)
[2025-02-17 17:37:36,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:36,785][root][INFO] - Training Epoch: 1/2, step 209/53949 completed (loss: 2.8112952709198, acc: 0.28155338764190674)
[2025-02-17 17:37:36,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:37,205][root][INFO] - Training Epoch: 1/2, step 210/53949 completed (loss: 2.5397109985351562, acc: 0.3086419701576233)
[2025-02-17 17:37:37,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:37,575][root][INFO] - Training Epoch: 1/2, step 211/53949 completed (loss: 2.9596290588378906, acc: 0.1666666716337204)
[2025-02-17 17:37:37,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:38,007][root][INFO] - Training Epoch: 1/2, step 212/53949 completed (loss: 2.6233115196228027, acc: 0.2881355881690979)
[2025-02-17 17:37:38,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:38,436][root][INFO] - Training Epoch: 1/2, step 213/53949 completed (loss: 2.7843329906463623, acc: 0.2715231776237488)
[2025-02-17 17:37:38,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:38,860][root][INFO] - Training Epoch: 1/2, step 214/53949 completed (loss: 2.7258400917053223, acc: 0.31578946113586426)
[2025-02-17 17:37:39,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:39,283][root][INFO] - Training Epoch: 1/2, step 215/53949 completed (loss: 3.0077269077301025, acc: 0.21686747670173645)
[2025-02-17 17:37:39,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:39,687][root][INFO] - Training Epoch: 1/2, step 216/53949 completed (loss: 1.6866626739501953, acc: 0.5)
[2025-02-17 17:37:39,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:40,084][root][INFO] - Training Epoch: 1/2, step 217/53949 completed (loss: 2.4032082557678223, acc: 0.3499999940395355)
[2025-02-17 17:37:40,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:40,423][root][INFO] - Training Epoch: 1/2, step 218/53949 completed (loss: 2.783453941345215, acc: 0.29032257199287415)
[2025-02-17 17:37:40,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:40,787][root][INFO] - Training Epoch: 1/2, step 219/53949 completed (loss: 2.248276948928833, acc: 0.3333333432674408)
[2025-02-17 17:37:40,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:41,208][root][INFO] - Training Epoch: 1/2, step 220/53949 completed (loss: 2.7766129970550537, acc: 0.2448979616165161)
[2025-02-17 17:37:41,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:41,622][root][INFO] - Training Epoch: 1/2, step 221/53949 completed (loss: 2.93664813041687, acc: 0.25362318754196167)
[2025-02-17 17:37:41,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:41,995][root][INFO] - Training Epoch: 1/2, step 222/53949 completed (loss: 2.738880157470703, acc: 0.27835050225257874)
[2025-02-17 17:37:42,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:42,340][root][INFO] - Training Epoch: 1/2, step 223/53949 completed (loss: 2.750075101852417, acc: 0.25882354378700256)
[2025-02-17 17:37:42,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:42,716][root][INFO] - Training Epoch: 1/2, step 224/53949 completed (loss: 2.9746408462524414, acc: 0.1894736886024475)
[2025-02-17 17:37:42,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:43,123][root][INFO] - Training Epoch: 1/2, step 225/53949 completed (loss: 2.843785524368286, acc: 0.25)
[2025-02-17 17:37:43,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:43,507][root][INFO] - Training Epoch: 1/2, step 226/53949 completed (loss: 0.811678946018219, acc: 0.6666666865348816)
[2025-02-17 17:37:43,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:43,917][root][INFO] - Training Epoch: 1/2, step 227/53949 completed (loss: 2.742570638656616, acc: 0.31147539615631104)
[2025-02-17 17:37:44,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:44,322][root][INFO] - Training Epoch: 1/2, step 228/53949 completed (loss: 2.5455355644226074, acc: 0.3606557250022888)
[2025-02-17 17:37:44,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:44,741][root][INFO] - Training Epoch: 1/2, step 229/53949 completed (loss: 0.5452286601066589, acc: 0.8333333134651184)
[2025-02-17 17:37:44,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:45,144][root][INFO] - Training Epoch: 1/2, step 230/53949 completed (loss: 2.4276628494262695, acc: 0.3571428656578064)
[2025-02-17 17:37:45,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:45,558][root][INFO] - Training Epoch: 1/2, step 231/53949 completed (loss: 2.7649848461151123, acc: 0.26436781883239746)
[2025-02-17 17:37:45,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:46,003][root][INFO] - Training Epoch: 1/2, step 232/53949 completed (loss: 2.7860829830169678, acc: 0.2539682686328888)
[2025-02-17 17:37:46,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:46,399][root][INFO] - Training Epoch: 1/2, step 233/53949 completed (loss: 2.891714096069336, acc: 0.27272728085517883)
[2025-02-17 17:37:46,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:46,829][root][INFO] - Training Epoch: 1/2, step 234/53949 completed (loss: 2.296849012374878, acc: 0.46666666865348816)
[2025-02-17 17:37:46,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:47,215][root][INFO] - Training Epoch: 1/2, step 235/53949 completed (loss: 2.472944736480713, acc: 0.3076923191547394)
[2025-02-17 17:37:47,383][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:47,603][root][INFO] - Training Epoch: 1/2, step 236/53949 completed (loss: 0.33611929416656494, acc: 0.8333333134651184)
[2025-02-17 17:37:47,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:47,980][root][INFO] - Training Epoch: 1/2, step 237/53949 completed (loss: 2.700800895690918, acc: 0.23529411852359772)
[2025-02-17 17:37:48,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:48,344][root][INFO] - Training Epoch: 1/2, step 238/53949 completed (loss: 2.7395806312561035, acc: 0.20000000298023224)
[2025-02-17 17:37:48,478][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:48,694][root][INFO] - Training Epoch: 1/2, step 239/53949 completed (loss: 2.3406624794006348, acc: 0.46666666865348816)
[2025-02-17 17:37:48,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:49,129][root][INFO] - Training Epoch: 1/2, step 240/53949 completed (loss: 2.255317211151123, acc: 0.4128440320491791)
[2025-02-17 17:37:49,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:49,507][root][INFO] - Training Epoch: 1/2, step 241/53949 completed (loss: 2.5899906158447266, acc: 0.23076923191547394)
[2025-02-17 17:37:49,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:49,924][root][INFO] - Training Epoch: 1/2, step 242/53949 completed (loss: 2.4559082984924316, acc: 0.3068181872367859)
[2025-02-17 17:37:50,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:50,316][root][INFO] - Training Epoch: 1/2, step 243/53949 completed (loss: 2.612978219985962, acc: 0.18333333730697632)
[2025-02-17 17:37:50,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:50,674][root][INFO] - Training Epoch: 1/2, step 244/53949 completed (loss: 2.5205492973327637, acc: 0.3333333432674408)
[2025-02-17 17:37:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:51,012][root][INFO] - Training Epoch: 1/2, step 245/53949 completed (loss: 2.8310017585754395, acc: 0.3283582031726837)
[2025-02-17 17:37:51,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:51,355][root][INFO] - Training Epoch: 1/2, step 246/53949 completed (loss: 2.506091833114624, acc: 0.3035714328289032)
[2025-02-17 17:37:51,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:51,716][root][INFO] - Training Epoch: 1/2, step 247/53949 completed (loss: 2.549947738647461, acc: 0.2818181812763214)
[2025-02-17 17:37:51,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:52,102][root][INFO] - Training Epoch: 1/2, step 248/53949 completed (loss: 2.6363344192504883, acc: 0.23469388484954834)
[2025-02-17 17:37:52,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:52,519][root][INFO] - Training Epoch: 1/2, step 249/53949 completed (loss: 2.5983030796051025, acc: 0.2857142984867096)
[2025-02-17 17:37:52,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:52,904][root][INFO] - Training Epoch: 1/2, step 250/53949 completed (loss: 2.41361403465271, acc: 0.30882352590560913)
[2025-02-17 17:37:53,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:53,293][root][INFO] - Training Epoch: 1/2, step 251/53949 completed (loss: 2.766467809677124, acc: 0.234375)
[2025-02-17 17:37:53,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:53,683][root][INFO] - Training Epoch: 1/2, step 252/53949 completed (loss: 2.581444025039673, acc: 0.28260868787765503)
[2025-02-17 17:37:53,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:54,084][root][INFO] - Training Epoch: 1/2, step 253/53949 completed (loss: 2.004098415374756, acc: 0.5)
[2025-02-17 17:37:54,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:54,514][root][INFO] - Training Epoch: 1/2, step 254/53949 completed (loss: 2.732015371322632, acc: 0.23000000417232513)
[2025-02-17 17:37:54,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:54,903][root][INFO] - Training Epoch: 1/2, step 255/53949 completed (loss: 2.6251187324523926, acc: 0.2612612545490265)
[2025-02-17 17:37:55,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:55,320][root][INFO] - Training Epoch: 1/2, step 256/53949 completed (loss: 2.209522008895874, acc: 0.4137931168079376)
[2025-02-17 17:37:55,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:55,715][root][INFO] - Training Epoch: 1/2, step 257/53949 completed (loss: 2.5323967933654785, acc: 0.3194444477558136)
[2025-02-17 17:37:55,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:56,089][root][INFO] - Training Epoch: 1/2, step 258/53949 completed (loss: 2.4781222343444824, acc: 0.3617021143436432)
[2025-02-17 17:37:56,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:56,455][root][INFO] - Training Epoch: 1/2, step 259/53949 completed (loss: 2.726710796356201, acc: 0.29347825050354004)
[2025-02-17 17:37:56,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:56,898][root][INFO] - Training Epoch: 1/2, step 260/53949 completed (loss: 1.8941078186035156, acc: 0.4166666567325592)
[2025-02-17 17:37:57,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:57,265][root][INFO] - Training Epoch: 1/2, step 261/53949 completed (loss: 2.741344928741455, acc: 0.25984251499176025)
[2025-02-17 17:37:57,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:57,728][root][INFO] - Training Epoch: 1/2, step 262/53949 completed (loss: 2.714170455932617, acc: 0.23999999463558197)
[2025-02-17 17:37:57,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:58,098][root][INFO] - Training Epoch: 1/2, step 263/53949 completed (loss: 1.143056869506836, acc: 0.7142857313156128)
[2025-02-17 17:37:58,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:58,460][root][INFO] - Training Epoch: 1/2, step 264/53949 completed (loss: 2.7374134063720703, acc: 0.3188405930995941)
[2025-02-17 17:37:58,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:58,808][root][INFO] - Training Epoch: 1/2, step 265/53949 completed (loss: 1.894843578338623, acc: 0.4444444477558136)
[2025-02-17 17:37:59,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:59,217][root][INFO] - Training Epoch: 1/2, step 266/53949 completed (loss: 0.3219161927700043, acc: 0.8333333134651184)
[2025-02-17 17:37:59,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:59,618][root][INFO] - Training Epoch: 1/2, step 267/53949 completed (loss: 2.9914145469665527, acc: 0.18333333730697632)
[2025-02-17 17:37:59,743][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:37:59,959][root][INFO] - Training Epoch: 1/2, step 268/53949 completed (loss: 2.8624513149261475, acc: 0.19672131538391113)
[2025-02-17 17:38:00,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:00,331][root][INFO] - Training Epoch: 1/2, step 269/53949 completed (loss: 2.613386631011963, acc: 0.2639999985694885)
[2025-02-17 17:38:00,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:00,745][root][INFO] - Training Epoch: 1/2, step 270/53949 completed (loss: 2.801891326904297, acc: 0.25)
[2025-02-17 17:38:00,957][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:01,184][root][INFO] - Training Epoch: 1/2, step 271/53949 completed (loss: 2.6626996994018555, acc: 0.2985074520111084)
[2025-02-17 17:38:01,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:01,550][root][INFO] - Training Epoch: 1/2, step 272/53949 completed (loss: 0.08835653215646744, acc: 1.0)
[2025-02-17 17:38:01,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:01,951][root][INFO] - Training Epoch: 1/2, step 273/53949 completed (loss: 2.645052909851074, acc: 0.23275862634181976)
[2025-02-17 17:38:02,104][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:02,316][root][INFO] - Training Epoch: 1/2, step 274/53949 completed (loss: 0.05693356692790985, acc: 1.0)
[2025-02-17 17:38:02,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:02,686][root][INFO] - Training Epoch: 1/2, step 275/53949 completed (loss: 2.287245273590088, acc: 0.4545454680919647)
[2025-02-17 17:38:02,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:03,087][root][INFO] - Training Epoch: 1/2, step 276/53949 completed (loss: 2.494647264480591, acc: 0.30882352590560913)
[2025-02-17 17:38:03,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:03,497][root][INFO] - Training Epoch: 1/2, step 277/53949 completed (loss: 2.701712131500244, acc: 0.28313252329826355)
[2025-02-17 17:38:03,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:03,908][root][INFO] - Training Epoch: 1/2, step 278/53949 completed (loss: 2.1746153831481934, acc: 0.38461539149284363)
[2025-02-17 17:38:04,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:04,271][root][INFO] - Training Epoch: 1/2, step 279/53949 completed (loss: 2.6726889610290527, acc: 0.2978723347187042)
[2025-02-17 17:38:04,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:04,629][root][INFO] - Training Epoch: 1/2, step 280/53949 completed (loss: 0.06925147026777267, acc: 1.0)
[2025-02-17 17:38:04,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:05,022][root][INFO] - Training Epoch: 1/2, step 281/53949 completed (loss: 0.32960057258605957, acc: 0.8333333134651184)
[2025-02-17 17:38:05,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:05,425][root][INFO] - Training Epoch: 1/2, step 282/53949 completed (loss: 3.0231947898864746, acc: 0.17391304671764374)
[2025-02-17 17:38:05,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:05,788][root][INFO] - Training Epoch: 1/2, step 283/53949 completed (loss: 2.3993289470672607, acc: 0.35384616255760193)
[2025-02-17 17:38:05,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:06,169][root][INFO] - Training Epoch: 1/2, step 284/53949 completed (loss: 2.453392505645752, acc: 0.3333333432674408)
[2025-02-17 17:38:06,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:06,543][root][INFO] - Training Epoch: 1/2, step 285/53949 completed (loss: 2.598947048187256, acc: 0.28947368264198303)
[2025-02-17 17:38:06,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:06,958][root][INFO] - Training Epoch: 1/2, step 286/53949 completed (loss: 2.3573532104492188, acc: 0.34285715222358704)
[2025-02-17 17:38:07,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:07,342][root][INFO] - Training Epoch: 1/2, step 287/53949 completed (loss: 2.635103225708008, acc: 0.2800000011920929)
[2025-02-17 17:38:07,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:07,754][root][INFO] - Training Epoch: 1/2, step 288/53949 completed (loss: 2.546675205230713, acc: 0.34210526943206787)
[2025-02-17 17:38:07,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:08,102][root][INFO] - Training Epoch: 1/2, step 289/53949 completed (loss: 2.2714991569519043, acc: 0.3670886158943176)
[2025-02-17 17:38:08,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:08,473][root][INFO] - Training Epoch: 1/2, step 290/53949 completed (loss: 2.4671459197998047, acc: 0.35766422748565674)
[2025-02-17 17:38:08,656][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:08,857][root][INFO] - Training Epoch: 1/2, step 291/53949 completed (loss: 2.4897639751434326, acc: 0.32499998807907104)
[2025-02-17 17:38:08,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:09,206][root][INFO] - Training Epoch: 1/2, step 292/53949 completed (loss: 2.978827953338623, acc: 0.31578946113586426)
[2025-02-17 17:38:09,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:09,586][root][INFO] - Training Epoch: 1/2, step 293/53949 completed (loss: 2.455514907836914, acc: 0.37837839126586914)
[2025-02-17 17:38:09,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:09,951][root][INFO] - Training Epoch: 1/2, step 294/53949 completed (loss: 2.087472915649414, acc: 0.5555555820465088)
[2025-02-17 17:38:10,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:10,331][root][INFO] - Training Epoch: 1/2, step 295/53949 completed (loss: 2.5126614570617676, acc: 0.38235294818878174)
[2025-02-17 17:38:10,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:10,806][root][INFO] - Training Epoch: 1/2, step 296/53949 completed (loss: 2.7852625846862793, acc: 0.25806450843811035)
[2025-02-17 17:38:11,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:11,197][root][INFO] - Training Epoch: 1/2, step 297/53949 completed (loss: 2.3421995639801025, acc: 0.38235294818878174)
[2025-02-17 17:38:11,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:11,581][root][INFO] - Training Epoch: 1/2, step 298/53949 completed (loss: 2.698060989379883, acc: 0.25925925374031067)
[2025-02-17 17:38:11,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:11,953][root][INFO] - Training Epoch: 1/2, step 299/53949 completed (loss: 1.282362461090088, acc: 0.5555555820465088)
[2025-02-17 17:38:12,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:12,344][root][INFO] - Training Epoch: 1/2, step 300/53949 completed (loss: 0.815263032913208, acc: 0.75)
[2025-02-17 17:38:12,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:12,744][root][INFO] - Training Epoch: 1/2, step 301/53949 completed (loss: 2.5044801235198975, acc: 0.3471074402332306)
[2025-02-17 17:38:12,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:13,117][root][INFO] - Training Epoch: 1/2, step 302/53949 completed (loss: 2.4538981914520264, acc: 0.3300970792770386)
[2025-02-17 17:38:13,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:13,464][root][INFO] - Training Epoch: 1/2, step 303/53949 completed (loss: 2.6088855266571045, acc: 0.26923078298568726)
[2025-02-17 17:38:13,627][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:13,845][root][INFO] - Training Epoch: 1/2, step 304/53949 completed (loss: 2.5154712200164795, acc: 0.2715231776237488)
[2025-02-17 17:38:13,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:14,200][root][INFO] - Training Epoch: 1/2, step 305/53949 completed (loss: 1.8612394332885742, acc: 0.5263158082962036)
[2025-02-17 17:38:14,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:14,638][root][INFO] - Training Epoch: 1/2, step 306/53949 completed (loss: 2.5043671131134033, acc: 0.29050278663635254)
[2025-02-17 17:38:14,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:15,047][root][INFO] - Training Epoch: 1/2, step 307/53949 completed (loss: 2.1773080825805664, acc: 0.43421053886413574)
[2025-02-17 17:38:15,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:15,379][root][INFO] - Training Epoch: 1/2, step 308/53949 completed (loss: 2.6363959312438965, acc: 0.2750000059604645)
[2025-02-17 17:38:15,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:15,715][root][INFO] - Training Epoch: 1/2, step 309/53949 completed (loss: 2.7317090034484863, acc: 0.2380952388048172)
[2025-02-17 17:38:15,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:16,069][root][INFO] - Training Epoch: 1/2, step 310/53949 completed (loss: 2.302513360977173, acc: 0.4528301954269409)
[2025-02-17 17:38:16,254][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:16,461][root][INFO] - Training Epoch: 1/2, step 311/53949 completed (loss: 2.1593401432037354, acc: 0.37931033968925476)
[2025-02-17 17:38:16,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:16,834][root][INFO] - Training Epoch: 1/2, step 312/53949 completed (loss: 2.3985602855682373, acc: 0.30882352590560913)
[2025-02-17 17:38:17,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:17,219][root][INFO] - Training Epoch: 1/2, step 313/53949 completed (loss: 2.3735597133636475, acc: 0.4262295067310333)
[2025-02-17 17:38:17,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:17,594][root][INFO] - Training Epoch: 1/2, step 314/53949 completed (loss: 2.5434787273406982, acc: 0.3125)
[2025-02-17 17:38:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:17,931][root][INFO] - Training Epoch: 1/2, step 315/53949 completed (loss: 2.353395938873291, acc: 0.30645161867141724)
[2025-02-17 17:38:18,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:18,338][root][INFO] - Training Epoch: 1/2, step 316/53949 completed (loss: 0.8209666013717651, acc: 0.8999999761581421)
[2025-02-17 17:38:18,499][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:18,707][root][INFO] - Training Epoch: 1/2, step 317/53949 completed (loss: 2.373337745666504, acc: 0.35227271914482117)
[2025-02-17 17:38:18,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:19,082][root][INFO] - Training Epoch: 1/2, step 318/53949 completed (loss: 2.66229510307312, acc: 0.30434781312942505)
[2025-02-17 17:38:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:19,493][root][INFO] - Training Epoch: 1/2, step 319/53949 completed (loss: 2.3445513248443604, acc: 0.36538460850715637)
[2025-02-17 17:38:19,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:19,880][root][INFO] - Training Epoch: 1/2, step 320/53949 completed (loss: 2.628683567047119, acc: 0.2750000059604645)
[2025-02-17 17:38:20,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:20,322][root][INFO] - Training Epoch: 1/2, step 321/53949 completed (loss: 2.457273483276367, acc: 0.28735631704330444)
[2025-02-17 17:38:20,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:20,767][root][INFO] - Training Epoch: 1/2, step 322/53949 completed (loss: 2.2898523807525635, acc: 0.34328359365463257)
[2025-02-17 17:38:20,965][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:21,172][root][INFO] - Training Epoch: 1/2, step 323/53949 completed (loss: 2.2808570861816406, acc: 0.35555556416511536)
[2025-02-17 17:38:21,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:21,575][root][INFO] - Training Epoch: 1/2, step 324/53949 completed (loss: 2.8591673374176025, acc: 0.2083333283662796)
[2025-02-17 17:38:21,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:22,016][root][INFO] - Training Epoch: 1/2, step 325/53949 completed (loss: 2.2714343070983887, acc: 0.3368421196937561)
[2025-02-17 17:38:22,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:22,438][root][INFO] - Training Epoch: 1/2, step 326/53949 completed (loss: 2.899158239364624, acc: 0.23404255509376526)
[2025-02-17 17:38:22,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:22,793][root][INFO] - Training Epoch: 1/2, step 327/53949 completed (loss: 2.4314897060394287, acc: 0.38235294818878174)
[2025-02-17 17:38:22,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:23,212][root][INFO] - Training Epoch: 1/2, step 328/53949 completed (loss: 2.7344918251037598, acc: 0.28333333134651184)
[2025-02-17 17:38:23,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:23,608][root][INFO] - Training Epoch: 1/2, step 329/53949 completed (loss: 2.6191582679748535, acc: 0.2702702581882477)
[2025-02-17 17:38:23,787][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:24,014][root][INFO] - Training Epoch: 1/2, step 330/53949 completed (loss: 2.474693536758423, acc: 0.28915661573410034)
[2025-02-17 17:38:24,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:24,397][root][INFO] - Training Epoch: 1/2, step 331/53949 completed (loss: 2.389352560043335, acc: 0.4000000059604645)
[2025-02-17 17:38:24,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:24,785][root][INFO] - Training Epoch: 1/2, step 332/53949 completed (loss: 2.275010585784912, acc: 0.3636363744735718)
[2025-02-17 17:38:24,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:25,183][root][INFO] - Training Epoch: 1/2, step 333/53949 completed (loss: 2.42326021194458, acc: 0.349056601524353)
[2025-02-17 17:38:25,414][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:25,627][root][INFO] - Training Epoch: 1/2, step 334/53949 completed (loss: 2.313775062561035, acc: 0.3661971688270569)
[2025-02-17 17:38:25,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:26,024][root][INFO] - Training Epoch: 1/2, step 335/53949 completed (loss: 2.4237987995147705, acc: 0.36666667461395264)
[2025-02-17 17:38:26,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:26,421][root][INFO] - Training Epoch: 1/2, step 336/53949 completed (loss: 2.2544374465942383, acc: 0.32258063554763794)
[2025-02-17 17:38:26,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:26,811][root][INFO] - Training Epoch: 1/2, step 337/53949 completed (loss: 2.5012266635894775, acc: 0.4021739065647125)
[2025-02-17 17:38:27,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:27,226][root][INFO] - Training Epoch: 1/2, step 338/53949 completed (loss: 2.7916152477264404, acc: 0.2586206793785095)
[2025-02-17 17:38:27,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:27,638][root][INFO] - Training Epoch: 1/2, step 339/53949 completed (loss: 2.4123079776763916, acc: 0.34246575832366943)
[2025-02-17 17:38:27,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:28,051][root][INFO] - Training Epoch: 1/2, step 340/53949 completed (loss: 2.4900569915771484, acc: 0.3606557250022888)
[2025-02-17 17:38:28,186][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:28,401][root][INFO] - Training Epoch: 1/2, step 341/53949 completed (loss: 2.294382095336914, acc: 0.3233082592487335)
[2025-02-17 17:38:28,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:28,855][root][INFO] - Training Epoch: 1/2, step 342/53949 completed (loss: 2.3342196941375732, acc: 0.4035087823867798)
[2025-02-17 17:38:29,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:29,274][root][INFO] - Training Epoch: 1/2, step 343/53949 completed (loss: 1.925593376159668, acc: 0.5)
[2025-02-17 17:38:29,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:29,650][root][INFO] - Training Epoch: 1/2, step 344/53949 completed (loss: 1.9889180660247803, acc: 0.41025641560554504)
[2025-02-17 17:38:29,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:29,982][root][INFO] - Training Epoch: 1/2, step 345/53949 completed (loss: 1.9604326486587524, acc: 0.4285714328289032)
[2025-02-17 17:38:30,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:30,376][root][INFO] - Training Epoch: 1/2, step 346/53949 completed (loss: 2.3657310009002686, acc: 0.3176470696926117)
[2025-02-17 17:38:30,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:30,836][root][INFO] - Training Epoch: 1/2, step 347/53949 completed (loss: 1.977766513824463, acc: 0.5)
[2025-02-17 17:38:31,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:31,248][root][INFO] - Training Epoch: 1/2, step 348/53949 completed (loss: 2.5102245807647705, acc: 0.26582279801368713)
[2025-02-17 17:38:31,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:31,617][root][INFO] - Training Epoch: 1/2, step 349/53949 completed (loss: 1.922519326210022, acc: 0.5)
[2025-02-17 17:38:31,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:31,981][root][INFO] - Training Epoch: 1/2, step 350/53949 completed (loss: 2.547398567199707, acc: 0.2638888955116272)
[2025-02-17 17:38:32,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:32,335][root][INFO] - Training Epoch: 1/2, step 351/53949 completed (loss: 3.0077285766601562, acc: 0.25)
[2025-02-17 17:38:32,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:32,706][root][INFO] - Training Epoch: 1/2, step 352/53949 completed (loss: 1.7396641969680786, acc: 0.5)
[2025-02-17 17:38:32,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:33,110][root][INFO] - Training Epoch: 1/2, step 353/53949 completed (loss: 2.8917829990386963, acc: 0.19230769574642181)
[2025-02-17 17:38:33,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:33,467][root][INFO] - Training Epoch: 1/2, step 354/53949 completed (loss: 1.9820811748504639, acc: 0.3636363744735718)
[2025-02-17 17:38:33,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:33,841][root][INFO] - Training Epoch: 1/2, step 355/53949 completed (loss: 2.5442922115325928, acc: 0.3103448152542114)
[2025-02-17 17:38:34,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:34,225][root][INFO] - Training Epoch: 1/2, step 356/53949 completed (loss: 2.579383134841919, acc: 0.25)
[2025-02-17 17:38:34,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:34,594][root][INFO] - Training Epoch: 1/2, step 357/53949 completed (loss: 2.5326154232025146, acc: 0.37142857909202576)
[2025-02-17 17:38:34,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:34,958][root][INFO] - Training Epoch: 1/2, step 358/53949 completed (loss: 2.413032293319702, acc: 0.2839506268501282)
[2025-02-17 17:38:35,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:35,347][root][INFO] - Training Epoch: 1/2, step 359/53949 completed (loss: 2.8365206718444824, acc: 0.20370370149612427)
[2025-02-17 17:38:35,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:35,712][root][INFO] - Training Epoch: 1/2, step 360/53949 completed (loss: 2.3469293117523193, acc: 0.4444444477558136)
[2025-02-17 17:38:35,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:36,053][root][INFO] - Training Epoch: 1/2, step 361/53949 completed (loss: 2.5922293663024902, acc: 0.27272728085517883)
[2025-02-17 17:38:36,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:36,435][root][INFO] - Training Epoch: 1/2, step 362/53949 completed (loss: 2.585897922515869, acc: 0.30909091234207153)
[2025-02-17 17:38:36,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:36,810][root][INFO] - Training Epoch: 1/2, step 363/53949 completed (loss: 0.773504376411438, acc: 0.7142857313156128)
[2025-02-17 17:38:37,005][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:37,216][root][INFO] - Training Epoch: 1/2, step 364/53949 completed (loss: 2.2497849464416504, acc: 0.2666666805744171)
[2025-02-17 17:38:37,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:37,590][root][INFO] - Training Epoch: 1/2, step 365/53949 completed (loss: 2.2265262603759766, acc: 0.3564356565475464)
[2025-02-17 17:38:37,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:37,972][root][INFO] - Training Epoch: 1/2, step 366/53949 completed (loss: 2.218632459640503, acc: 0.39523810148239136)
[2025-02-17 17:38:38,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:38,329][root][INFO] - Training Epoch: 1/2, step 367/53949 completed (loss: 0.13801710307598114, acc: 1.0)
[2025-02-17 17:38:38,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:38,683][root][INFO] - Training Epoch: 1/2, step 368/53949 completed (loss: 2.1616339683532715, acc: 0.38596490025520325)
[2025-02-17 17:38:38,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:39,034][root][INFO] - Training Epoch: 1/2, step 369/53949 completed (loss: 2.145127058029175, acc: 0.39047619700431824)
[2025-02-17 17:38:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:39,444][root][INFO] - Training Epoch: 1/2, step 370/53949 completed (loss: 1.6456944942474365, acc: 0.5384615659713745)
[2025-02-17 17:38:39,635][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:39,849][root][INFO] - Training Epoch: 1/2, step 371/53949 completed (loss: 2.729567766189575, acc: 0.5)
[2025-02-17 17:38:39,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:40,199][root][INFO] - Training Epoch: 1/2, step 372/53949 completed (loss: 2.732494831085205, acc: 0.23333333432674408)
[2025-02-17 17:38:40,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:40,554][root][INFO] - Training Epoch: 1/2, step 373/53949 completed (loss: 2.4850261211395264, acc: 0.3589743673801422)
[2025-02-17 17:38:40,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:40,963][root][INFO] - Training Epoch: 1/2, step 374/53949 completed (loss: 2.3924858570098877, acc: 0.35638296604156494)
[2025-02-17 17:38:41,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:41,358][root][INFO] - Training Epoch: 1/2, step 375/53949 completed (loss: 2.296081066131592, acc: 0.3684210479259491)
[2025-02-17 17:38:41,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:41,752][root][INFO] - Training Epoch: 1/2, step 376/53949 completed (loss: 2.4955251216888428, acc: 0.29629629850387573)
[2025-02-17 17:38:41,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:42,152][root][INFO] - Training Epoch: 1/2, step 377/53949 completed (loss: 2.24031662940979, acc: 0.41025641560554504)
[2025-02-17 17:38:42,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:42,544][root][INFO] - Training Epoch: 1/2, step 378/53949 completed (loss: 2.680049419403076, acc: 0.30612245202064514)
[2025-02-17 17:38:42,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:42,956][root][INFO] - Training Epoch: 1/2, step 379/53949 completed (loss: 2.4546568393707275, acc: 0.3112582862377167)
[2025-02-17 17:38:43,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:43,388][root][INFO] - Training Epoch: 1/2, step 380/53949 completed (loss: 2.616196393966675, acc: 0.28282827138900757)
[2025-02-17 17:38:43,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:43,770][root][INFO] - Training Epoch: 1/2, step 381/53949 completed (loss: 2.3920743465423584, acc: 0.3499999940395355)
[2025-02-17 17:38:43,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:44,165][root][INFO] - Training Epoch: 1/2, step 382/53949 completed (loss: 2.398475408554077, acc: 0.3186813294887543)
[2025-02-17 17:38:44,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:44,551][root][INFO] - Training Epoch: 1/2, step 383/53949 completed (loss: 2.6071114540100098, acc: 0.328125)
[2025-02-17 17:38:44,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:44,946][root][INFO] - Training Epoch: 1/2, step 384/53949 completed (loss: 2.384274959564209, acc: 0.3636363744735718)
[2025-02-17 17:38:45,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:45,364][root][INFO] - Training Epoch: 1/2, step 385/53949 completed (loss: 2.1953437328338623, acc: 0.4333333373069763)
[2025-02-17 17:38:45,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:45,731][root][INFO] - Training Epoch: 1/2, step 386/53949 completed (loss: 2.397982120513916, acc: 0.4285714328289032)
[2025-02-17 17:38:45,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:46,144][root][INFO] - Training Epoch: 1/2, step 387/53949 completed (loss: 2.309044599533081, acc: 0.3913043439388275)
[2025-02-17 17:38:46,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:46,506][root][INFO] - Training Epoch: 1/2, step 388/53949 completed (loss: 2.550528049468994, acc: 0.25925925374031067)
[2025-02-17 17:38:46,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:46,934][root][INFO] - Training Epoch: 1/2, step 389/53949 completed (loss: 2.5746235847473145, acc: 0.23376622796058655)
[2025-02-17 17:38:47,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:47,280][root][INFO] - Training Epoch: 1/2, step 390/53949 completed (loss: 2.328439474105835, acc: 0.3947368562221527)
[2025-02-17 17:38:47,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:47,623][root][INFO] - Training Epoch: 1/2, step 391/53949 completed (loss: 1.5676652193069458, acc: 0.6000000238418579)
[2025-02-17 17:38:47,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:47,980][root][INFO] - Training Epoch: 1/2, step 392/53949 completed (loss: 2.139878511428833, acc: 0.3986014127731323)
[2025-02-17 17:38:48,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:48,349][root][INFO] - Training Epoch: 1/2, step 393/53949 completed (loss: 2.117530345916748, acc: 0.43478259444236755)
[2025-02-17 17:38:48,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:48,726][root][INFO] - Training Epoch: 1/2, step 394/53949 completed (loss: 2.231593132019043, acc: 0.3984375)
[2025-02-17 17:38:48,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:49,145][root][INFO] - Training Epoch: 1/2, step 395/53949 completed (loss: 2.4512135982513428, acc: 0.32786884903907776)
[2025-02-17 17:38:49,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:49,586][root][INFO] - Training Epoch: 1/2, step 396/53949 completed (loss: 2.471771717071533, acc: 0.35321101546287537)
[2025-02-17 17:38:49,736][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:49,950][root][INFO] - Training Epoch: 1/2, step 397/53949 completed (loss: 1.8643248081207275, acc: 0.4000000059604645)
[2025-02-17 17:38:50,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:50,336][root][INFO] - Training Epoch: 1/2, step 398/53949 completed (loss: 2.2716355323791504, acc: 0.3720930218696594)
[2025-02-17 17:38:50,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:50,751][root][INFO] - Training Epoch: 1/2, step 399/53949 completed (loss: 2.6014814376831055, acc: 0.3100775182247162)
[2025-02-17 17:38:50,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:51,133][root][INFO] - Training Epoch: 1/2, step 400/53949 completed (loss: 2.428762912750244, acc: 0.30909091234207153)
[2025-02-17 17:38:51,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:51,555][root][INFO] - Training Epoch: 1/2, step 401/53949 completed (loss: 2.6457087993621826, acc: 0.18518517911434174)
[2025-02-17 17:38:51,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:51,986][root][INFO] - Training Epoch: 1/2, step 402/53949 completed (loss: 2.4190351963043213, acc: 0.3272727131843567)
[2025-02-17 17:38:52,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:52,378][root][INFO] - Training Epoch: 1/2, step 403/53949 completed (loss: 2.4842138290405273, acc: 0.3461538553237915)
[2025-02-17 17:38:52,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:52,819][root][INFO] - Training Epoch: 1/2, step 404/53949 completed (loss: 2.3131470680236816, acc: 0.3214285671710968)
[2025-02-17 17:38:52,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:53,209][root][INFO] - Training Epoch: 1/2, step 405/53949 completed (loss: 2.451000452041626, acc: 0.2835051417350769)
[2025-02-17 17:38:53,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:53,599][root][INFO] - Training Epoch: 1/2, step 406/53949 completed (loss: 0.2069403976202011, acc: 1.0)
[2025-02-17 17:38:53,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:53,983][root][INFO] - Training Epoch: 1/2, step 407/53949 completed (loss: 2.2189621925354004, acc: 0.3515625)
[2025-02-17 17:38:54,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:54,362][root][INFO] - Training Epoch: 1/2, step 408/53949 completed (loss: 0.12177129834890366, acc: 1.0)
[2025-02-17 17:38:54,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:54,777][root][INFO] - Training Epoch: 1/2, step 409/53949 completed (loss: 2.4968881607055664, acc: 0.3199999928474426)
[2025-02-17 17:38:54,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:55,148][root][INFO] - Training Epoch: 1/2, step 410/53949 completed (loss: 2.678048610687256, acc: 0.23076923191547394)
[2025-02-17 17:38:55,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:55,565][root][INFO] - Training Epoch: 1/2, step 411/53949 completed (loss: 1.9407553672790527, acc: 0.4117647111415863)
[2025-02-17 17:38:55,757][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:55,971][root][INFO] - Training Epoch: 1/2, step 412/53949 completed (loss: 2.403538942337036, acc: 0.323699414730072)
[2025-02-17 17:38:56,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:56,343][root][INFO] - Training Epoch: 1/2, step 413/53949 completed (loss: 2.3431942462921143, acc: 0.35862070322036743)
[2025-02-17 17:38:56,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:56,714][root][INFO] - Training Epoch: 1/2, step 414/53949 completed (loss: 2.5758235454559326, acc: 0.29914531111717224)
[2025-02-17 17:38:56,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:57,054][root][INFO] - Training Epoch: 1/2, step 415/53949 completed (loss: 2.346713066101074, acc: 0.3589743673801422)
[2025-02-17 17:38:57,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:57,418][root][INFO] - Training Epoch: 1/2, step 416/53949 completed (loss: 2.1743175983428955, acc: 0.4642857015132904)
[2025-02-17 17:38:57,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:57,772][root][INFO] - Training Epoch: 1/2, step 417/53949 completed (loss: 2.2383694648742676, acc: 0.4680851101875305)
[2025-02-17 17:38:57,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:58,139][root][INFO] - Training Epoch: 1/2, step 418/53949 completed (loss: 2.069392681121826, acc: 0.4375)
[2025-02-17 17:38:58,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:58,543][root][INFO] - Training Epoch: 1/2, step 419/53949 completed (loss: 2.357813596725464, acc: 0.37662336230278015)
[2025-02-17 17:38:58,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:58,930][root][INFO] - Training Epoch: 1/2, step 420/53949 completed (loss: 1.9897081851959229, acc: 0.48275861144065857)
[2025-02-17 17:38:59,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:59,273][root][INFO] - Training Epoch: 1/2, step 421/53949 completed (loss: 0.721262514591217, acc: 0.875)
[2025-02-17 17:38:59,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:59,640][root][INFO] - Training Epoch: 1/2, step 422/53949 completed (loss: 2.0544393062591553, acc: 0.38596490025520325)
[2025-02-17 17:38:59,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:00,078][root][INFO] - Training Epoch: 1/2, step 423/53949 completed (loss: 2.4079272747039795, acc: 0.3385826647281647)
[2025-02-17 17:39:00,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:00,434][root][INFO] - Training Epoch: 1/2, step 424/53949 completed (loss: 2.368856430053711, acc: 0.3333333432674408)
[2025-02-17 17:39:00,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:00,906][root][INFO] - Training Epoch: 1/2, step 425/53949 completed (loss: 2.237818956375122, acc: 0.3287671208381653)
[2025-02-17 17:39:01,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:01,305][root][INFO] - Training Epoch: 1/2, step 426/53949 completed (loss: 2.336747407913208, acc: 0.3229166567325592)
[2025-02-17 17:39:01,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:01,682][root][INFO] - Training Epoch: 1/2, step 427/53949 completed (loss: 2.5637621879577637, acc: 0.3125)
[2025-02-17 17:39:01,832][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:02,049][root][INFO] - Training Epoch: 1/2, step 428/53949 completed (loss: 2.323056697845459, acc: 0.2666666805744171)
[2025-02-17 17:39:02,204][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:02,415][root][INFO] - Training Epoch: 1/2, step 429/53949 completed (loss: 2.5003981590270996, acc: 0.2886597812175751)
[2025-02-17 17:39:02,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:02,782][root][INFO] - Training Epoch: 1/2, step 430/53949 completed (loss: 2.3417673110961914, acc: 0.4000000059604645)
[2025-02-17 17:39:02,905][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:03,111][root][INFO] - Training Epoch: 1/2, step 431/53949 completed (loss: 2.486503839492798, acc: 0.2181818187236786)
[2025-02-17 17:39:03,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:03,503][root][INFO] - Training Epoch: 1/2, step 432/53949 completed (loss: 2.451040506362915, acc: 0.36666667461395264)
[2025-02-17 17:39:03,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:03,859][root][INFO] - Training Epoch: 1/2, step 433/53949 completed (loss: 2.4343926906585693, acc: 0.32307693362236023)
[2025-02-17 17:39:04,032][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:04,260][root][INFO] - Training Epoch: 1/2, step 434/53949 completed (loss: 2.219064474105835, acc: 0.3918918967247009)
[2025-02-17 17:39:04,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:04,650][root][INFO] - Training Epoch: 1/2, step 435/53949 completed (loss: 2.301819324493408, acc: 0.3125)
[2025-02-17 17:39:04,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:05,041][root][INFO] - Training Epoch: 1/2, step 436/53949 completed (loss: 2.616251230239868, acc: 0.2921348214149475)
[2025-02-17 17:39:05,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:05,413][root][INFO] - Training Epoch: 1/2, step 437/53949 completed (loss: 2.0539300441741943, acc: 0.3448275923728943)
[2025-02-17 17:39:05,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:05,809][root][INFO] - Training Epoch: 1/2, step 438/53949 completed (loss: 2.416682243347168, acc: 0.34545454382896423)
[2025-02-17 17:39:05,998][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:06,216][root][INFO] - Training Epoch: 1/2, step 439/53949 completed (loss: 2.3570058345794678, acc: 0.37078651785850525)
[2025-02-17 17:39:06,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:06,580][root][INFO] - Training Epoch: 1/2, step 440/53949 completed (loss: 1.9989339113235474, acc: 0.43518519401550293)
[2025-02-17 17:39:06,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:06,943][root][INFO] - Training Epoch: 1/2, step 441/53949 completed (loss: 2.199922800064087, acc: 0.39175257086753845)
[2025-02-17 17:39:07,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:07,329][root][INFO] - Training Epoch: 1/2, step 442/53949 completed (loss: 2.5302352905273438, acc: 0.4027777910232544)
[2025-02-17 17:39:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:07,731][root][INFO] - Training Epoch: 1/2, step 443/53949 completed (loss: 2.346303701400757, acc: 0.373913049697876)
[2025-02-17 17:39:07,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:08,091][root][INFO] - Training Epoch: 1/2, step 444/53949 completed (loss: 2.5248048305511475, acc: 0.2957746386528015)
[2025-02-17 17:39:08,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:08,467][root][INFO] - Training Epoch: 1/2, step 445/53949 completed (loss: 2.361790895462036, acc: 0.38842976093292236)
[2025-02-17 17:39:08,637][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:08,861][root][INFO] - Training Epoch: 1/2, step 446/53949 completed (loss: 2.5750606060028076, acc: 0.297468364238739)
[2025-02-17 17:39:09,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:09,219][root][INFO] - Training Epoch: 1/2, step 447/53949 completed (loss: 2.2564191818237305, acc: 0.35185185074806213)
[2025-02-17 17:39:09,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:09,596][root][INFO] - Training Epoch: 1/2, step 448/53949 completed (loss: 2.069432020187378, acc: 0.4642857015132904)
[2025-02-17 17:39:09,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:10,008][root][INFO] - Training Epoch: 1/2, step 449/53949 completed (loss: 2.16538405418396, acc: 0.5454545617103577)
[2025-02-17 17:39:10,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:10,397][root][INFO] - Training Epoch: 1/2, step 450/53949 completed (loss: 2.1723220348358154, acc: 0.41025641560554504)
[2025-02-17 17:39:10,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:10,802][root][INFO] - Training Epoch: 1/2, step 451/53949 completed (loss: 2.1610231399536133, acc: 0.39024388790130615)
[2025-02-17 17:39:10,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:11,174][root][INFO] - Training Epoch: 1/2, step 452/53949 completed (loss: 2.399545431137085, acc: 0.3243243098258972)
[2025-02-17 17:39:11,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:11,539][root][INFO] - Training Epoch: 1/2, step 453/53949 completed (loss: 2.311769962310791, acc: 0.32926830649375916)
[2025-02-17 17:39:11,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:11,886][root][INFO] - Training Epoch: 1/2, step 454/53949 completed (loss: 2.0140628814697266, acc: 0.4109589159488678)
[2025-02-17 17:39:12,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:12,234][root][INFO] - Training Epoch: 1/2, step 455/53949 completed (loss: 1.798164963722229, acc: 0.550000011920929)
[2025-02-17 17:39:12,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:12,631][root][INFO] - Training Epoch: 1/2, step 456/53949 completed (loss: 2.382939577102661, acc: 0.39080458879470825)
[2025-02-17 17:39:12,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:13,063][root][INFO] - Training Epoch: 1/2, step 457/53949 completed (loss: 2.497062921524048, acc: 0.29139071702957153)
[2025-02-17 17:39:13,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:13,456][root][INFO] - Training Epoch: 1/2, step 458/53949 completed (loss: 2.090054750442505, acc: 0.4268292784690857)
[2025-02-17 17:39:13,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:13,838][root][INFO] - Training Epoch: 1/2, step 459/53949 completed (loss: 2.244964361190796, acc: 0.3787878751754761)
[2025-02-17 17:39:13,996][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:14,211][root][INFO] - Training Epoch: 1/2, step 460/53949 completed (loss: 2.164376974105835, acc: 0.3711340129375458)
[2025-02-17 17:39:14,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:14,618][root][INFO] - Training Epoch: 1/2, step 461/53949 completed (loss: 2.4660239219665527, acc: 0.2857142984867096)
[2025-02-17 17:39:14,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:15,024][root][INFO] - Training Epoch: 1/2, step 462/53949 completed (loss: 1.8547714948654175, acc: 0.5098039507865906)
[2025-02-17 17:39:15,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:15,399][root][INFO] - Training Epoch: 1/2, step 463/53949 completed (loss: 2.5473570823669434, acc: 0.3333333432674408)
[2025-02-17 17:39:15,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:15,756][root][INFO] - Training Epoch: 1/2, step 464/53949 completed (loss: 2.2939019203186035, acc: 0.3478260934352875)
[2025-02-17 17:39:15,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:16,154][root][INFO] - Training Epoch: 1/2, step 465/53949 completed (loss: 2.1995084285736084, acc: 0.3761467933654785)
[2025-02-17 17:39:16,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:16,540][root][INFO] - Training Epoch: 1/2, step 466/53949 completed (loss: 2.1252992153167725, acc: 0.4444444477558136)
[2025-02-17 17:39:16,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:16,903][root][INFO] - Training Epoch: 1/2, step 467/53949 completed (loss: 2.3047196865081787, acc: 0.4444444477558136)
[2025-02-17 17:39:17,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:17,292][root][INFO] - Training Epoch: 1/2, step 468/53949 completed (loss: 2.0577893257141113, acc: 0.45384615659713745)
[2025-02-17 17:39:17,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:17,665][root][INFO] - Training Epoch: 1/2, step 469/53949 completed (loss: 0.058751918375492096, acc: 1.0)
[2025-02-17 17:39:17,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:18,033][root][INFO] - Training Epoch: 1/2, step 470/53949 completed (loss: 3.088779926300049, acc: 0.25)
[2025-02-17 17:39:18,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:18,461][root][INFO] - Training Epoch: 1/2, step 471/53949 completed (loss: 2.324610471725464, acc: 0.353658527135849)
[2025-02-17 17:39:18,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:18,841][root][INFO] - Training Epoch: 1/2, step 472/53949 completed (loss: 2.4647247791290283, acc: 0.32740214467048645)
[2025-02-17 17:39:19,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:19,226][root][INFO] - Training Epoch: 1/2, step 473/53949 completed (loss: 2.0872721672058105, acc: 0.38181817531585693)
[2025-02-17 17:39:19,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:19,590][root][INFO] - Training Epoch: 1/2, step 474/53949 completed (loss: 1.8535789251327515, acc: 0.5862069129943848)
[2025-02-17 17:39:19,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:19,932][root][INFO] - Training Epoch: 1/2, step 475/53949 completed (loss: 2.357865333557129, acc: 0.37837839126586914)
[2025-02-17 17:39:20,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:20,344][root][INFO] - Training Epoch: 1/2, step 476/53949 completed (loss: 2.4515438079833984, acc: 0.35384616255760193)
[2025-02-17 17:39:20,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:20,737][root][INFO] - Training Epoch: 1/2, step 477/53949 completed (loss: 1.8795204162597656, acc: 0.49253731966018677)
[2025-02-17 17:39:20,912][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:21,125][root][INFO] - Training Epoch: 1/2, step 478/53949 completed (loss: 2.3230957984924316, acc: 0.3174603283405304)
[2025-02-17 17:39:21,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:21,527][root][INFO] - Training Epoch: 1/2, step 479/53949 completed (loss: 2.394775390625, acc: 0.3129771053791046)
[2025-02-17 17:39:21,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:21,900][root][INFO] - Training Epoch: 1/2, step 480/53949 completed (loss: 4.073988914489746, acc: 0.20000000298023224)
[2025-02-17 17:39:22,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:22,280][root][INFO] - Training Epoch: 1/2, step 481/53949 completed (loss: 2.2972633838653564, acc: 0.375)
[2025-02-17 17:39:22,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:22,637][root][INFO] - Training Epoch: 1/2, step 482/53949 completed (loss: 2.2580854892730713, acc: 0.4285714328289032)
[2025-02-17 17:39:22,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:22,967][root][INFO] - Training Epoch: 1/2, step 483/53949 completed (loss: 1.6955524682998657, acc: 0.4545454680919647)
[2025-02-17 17:39:23,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:23,329][root][INFO] - Training Epoch: 1/2, step 484/53949 completed (loss: 2.577855348587036, acc: 0.2888889014720917)
[2025-02-17 17:39:23,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:23,713][root][INFO] - Training Epoch: 1/2, step 485/53949 completed (loss: 1.783381700515747, acc: 0.4375)
[2025-02-17 17:39:23,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:24,073][root][INFO] - Training Epoch: 1/2, step 486/53949 completed (loss: 2.4759268760681152, acc: 0.23404255509376526)
[2025-02-17 17:39:24,254][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:24,469][root][INFO] - Training Epoch: 1/2, step 487/53949 completed (loss: 2.085171937942505, acc: 0.44859811663627625)
[2025-02-17 17:39:24,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:24,935][root][INFO] - Training Epoch: 1/2, step 488/53949 completed (loss: 1.7687206268310547, acc: 0.375)
[2025-02-17 17:39:25,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:25,364][root][INFO] - Training Epoch: 1/2, step 489/53949 completed (loss: 2.409287214279175, acc: 0.3384615480899811)
[2025-02-17 17:39:25,511][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:25,726][root][INFO] - Training Epoch: 1/2, step 490/53949 completed (loss: 2.3685381412506104, acc: 0.3076923191547394)
[2025-02-17 17:39:25,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:26,113][root][INFO] - Training Epoch: 1/2, step 491/53949 completed (loss: 2.2741293907165527, acc: 0.37037035822868347)
[2025-02-17 17:39:26,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:26,489][root][INFO] - Training Epoch: 1/2, step 492/53949 completed (loss: 2.0536580085754395, acc: 0.49504950642585754)
[2025-02-17 17:39:26,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:26,923][root][INFO] - Training Epoch: 1/2, step 493/53949 completed (loss: 2.26645827293396, acc: 0.3877550959587097)
[2025-02-17 17:39:27,086][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:27,310][root][INFO] - Training Epoch: 1/2, step 494/53949 completed (loss: 2.0423672199249268, acc: 0.375)
[2025-02-17 17:39:27,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:27,729][root][INFO] - Training Epoch: 1/2, step 495/53949 completed (loss: 2.504809856414795, acc: 0.29870128631591797)
[2025-02-17 17:39:27,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:28,130][root][INFO] - Training Epoch: 1/2, step 496/53949 completed (loss: 2.1561636924743652, acc: 0.4112149477005005)
[2025-02-17 17:39:28,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:28,557][root][INFO] - Training Epoch: 1/2, step 497/53949 completed (loss: 2.0650787353515625, acc: 0.3695652186870575)
[2025-02-17 17:39:28,759][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:28,971][root][INFO] - Training Epoch: 1/2, step 498/53949 completed (loss: 2.322645902633667, acc: 0.3333333432674408)
[2025-02-17 17:39:29,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:29,339][root][INFO] - Training Epoch: 1/2, step 499/53949 completed (loss: 2.374551773071289, acc: 0.3333333432674408)
[2025-02-17 17:39:29,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:29,730][root][INFO] - Training Epoch: 1/2, step 500/53949 completed (loss: 2.2454800605773926, acc: 0.3641025722026825)
[2025-02-17 17:39:29,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:30,079][root][INFO] - Training Epoch: 1/2, step 501/53949 completed (loss: 2.419600009918213, acc: 0.32692307233810425)
[2025-02-17 17:39:30,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:30,508][root][INFO] - Training Epoch: 1/2, step 502/53949 completed (loss: 1.9750033617019653, acc: 0.5)
[2025-02-17 17:39:30,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:30,993][root][INFO] - Training Epoch: 1/2, step 503/53949 completed (loss: 1.9540643692016602, acc: 0.2857142984867096)
[2025-02-17 17:39:31,206][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:31,440][root][INFO] - Training Epoch: 1/2, step 504/53949 completed (loss: 2.2034354209899902, acc: 0.42553192377090454)
[2025-02-17 17:39:31,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:31,864][root][INFO] - Training Epoch: 1/2, step 505/53949 completed (loss: 2.2871885299682617, acc: 0.4054054021835327)
[2025-02-17 17:39:32,046][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:32,268][root][INFO] - Training Epoch: 1/2, step 506/53949 completed (loss: 2.3352105617523193, acc: 0.3734939694404602)
[2025-02-17 17:39:32,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:32,642][root][INFO] - Training Epoch: 1/2, step 507/53949 completed (loss: 1.0304516553878784, acc: 0.8181818127632141)
[2025-02-17 17:39:32,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:33,046][root][INFO] - Training Epoch: 1/2, step 508/53949 completed (loss: 0.3531525433063507, acc: 0.800000011920929)
[2025-02-17 17:39:33,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:33,447][root][INFO] - Training Epoch: 1/2, step 509/53949 completed (loss: 2.517012357711792, acc: 0.30000001192092896)
[2025-02-17 17:39:33,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:33,862][root][INFO] - Training Epoch: 1/2, step 510/53949 completed (loss: 2.2777886390686035, acc: 0.38461539149284363)
[2025-02-17 17:39:34,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:34,227][root][INFO] - Training Epoch: 1/2, step 511/53949 completed (loss: 2.6457622051239014, acc: 0.26153847575187683)
[2025-02-17 17:39:34,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:34,629][root][INFO] - Training Epoch: 1/2, step 512/53949 completed (loss: 2.373769760131836, acc: 0.3827160596847534)
[2025-02-17 17:39:34,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:34,998][root][INFO] - Training Epoch: 1/2, step 513/53949 completed (loss: 2.221195697784424, acc: 0.3870967626571655)
[2025-02-17 17:39:35,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:35,421][root][INFO] - Training Epoch: 1/2, step 514/53949 completed (loss: 2.5490078926086426, acc: 0.36538460850715637)
[2025-02-17 17:39:35,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:35,933][root][INFO] - Training Epoch: 1/2, step 515/53949 completed (loss: 2.2740557193756104, acc: 0.3534482717514038)
[2025-02-17 17:39:36,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:36,377][root][INFO] - Training Epoch: 1/2, step 516/53949 completed (loss: 2.24096941947937, acc: 0.44117647409439087)
[2025-02-17 17:39:36,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:36,762][root][INFO] - Training Epoch: 1/2, step 517/53949 completed (loss: 2.136244535446167, acc: 0.4193548262119293)
[2025-02-17 17:39:36,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:37,120][root][INFO] - Training Epoch: 1/2, step 518/53949 completed (loss: 0.8921138048171997, acc: 0.75)
[2025-02-17 17:39:37,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:37,483][root][INFO] - Training Epoch: 1/2, step 519/53949 completed (loss: 2.163156747817993, acc: 0.41428571939468384)
[2025-02-17 17:39:37,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:37,822][root][INFO] - Training Epoch: 1/2, step 520/53949 completed (loss: 2.0984039306640625, acc: 0.4482758641242981)
[2025-02-17 17:39:37,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:38,158][root][INFO] - Training Epoch: 1/2, step 521/53949 completed (loss: 2.146374225616455, acc: 0.4025973975658417)
[2025-02-17 17:39:38,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:38,564][root][INFO] - Training Epoch: 1/2, step 522/53949 completed (loss: 2.2993154525756836, acc: 0.4166666567325592)
[2025-02-17 17:39:38,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:38,971][root][INFO] - Training Epoch: 1/2, step 523/53949 completed (loss: 1.7604175806045532, acc: 0.5454545617103577)
[2025-02-17 17:39:39,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:39,352][root][INFO] - Training Epoch: 1/2, step 524/53949 completed (loss: 1.5504112243652344, acc: 0.4399999976158142)
[2025-02-17 17:39:39,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:39,718][root][INFO] - Training Epoch: 1/2, step 525/53949 completed (loss: 2.557368516921997, acc: 0.31111112236976624)
[2025-02-17 17:39:39,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:40,121][root][INFO] - Training Epoch: 1/2, step 526/53949 completed (loss: 2.4391627311706543, acc: 0.3733333349227905)
[2025-02-17 17:39:40,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:40,522][root][INFO] - Training Epoch: 1/2, step 527/53949 completed (loss: 2.268394708633423, acc: 0.41860464215278625)
[2025-02-17 17:39:40,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:40,896][root][INFO] - Training Epoch: 1/2, step 528/53949 completed (loss: 2.5357778072357178, acc: 0.2772277295589447)
[2025-02-17 17:39:41,043][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:41,258][root][INFO] - Training Epoch: 1/2, step 529/53949 completed (loss: 1.497779369354248, acc: 0.59375)
[2025-02-17 17:39:41,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:41,674][root][INFO] - Training Epoch: 1/2, step 530/53949 completed (loss: 1.9126758575439453, acc: 0.41818180680274963)
[2025-02-17 17:39:41,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:42,036][root][INFO] - Training Epoch: 1/2, step 531/53949 completed (loss: 2.2911744117736816, acc: 0.33766233921051025)
[2025-02-17 17:39:42,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:42,444][root][INFO] - Training Epoch: 1/2, step 532/53949 completed (loss: 2.5426132678985596, acc: 0.29523810744285583)
[2025-02-17 17:39:42,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:42,861][root][INFO] - Training Epoch: 1/2, step 533/53949 completed (loss: 2.084505319595337, acc: 0.3684210479259491)
[2025-02-17 17:39:43,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:43,271][root][INFO] - Training Epoch: 1/2, step 534/53949 completed (loss: 2.5988426208496094, acc: 0.4285714328289032)
[2025-02-17 17:39:43,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:43,694][root][INFO] - Training Epoch: 1/2, step 535/53949 completed (loss: 2.315896511077881, acc: 0.36734694242477417)
[2025-02-17 17:39:43,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:44,071][root][INFO] - Training Epoch: 1/2, step 536/53949 completed (loss: 2.1804654598236084, acc: 0.4479166567325592)
[2025-02-17 17:39:44,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:44,458][root][INFO] - Training Epoch: 1/2, step 537/53949 completed (loss: 2.3372817039489746, acc: 0.3984375)
[2025-02-17 17:39:44,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:44,821][root][INFO] - Training Epoch: 1/2, step 538/53949 completed (loss: 2.267458915710449, acc: 0.41025641560554504)
[2025-02-17 17:39:45,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:45,243][root][INFO] - Training Epoch: 1/2, step 539/53949 completed (loss: 2.2870476245880127, acc: 0.3617021143436432)
[2025-02-17 17:39:45,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:45,612][root][INFO] - Training Epoch: 1/2, step 540/53949 completed (loss: 2.6302669048309326, acc: 0.3380281627178192)
[2025-02-17 17:39:45,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:45,969][root][INFO] - Training Epoch: 1/2, step 541/53949 completed (loss: 1.7054554224014282, acc: 0.5)
[2025-02-17 17:39:46,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:46,367][root][INFO] - Training Epoch: 1/2, step 542/53949 completed (loss: 2.253133535385132, acc: 0.3191489279270172)
[2025-02-17 17:39:46,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:46,788][root][INFO] - Training Epoch: 1/2, step 543/53949 completed (loss: 2.055483818054199, acc: 0.5)
[2025-02-17 17:39:46,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:47,204][root][INFO] - Training Epoch: 1/2, step 544/53949 completed (loss: 2.160794258117676, acc: 0.4394904375076294)
[2025-02-17 17:39:47,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:47,639][root][INFO] - Training Epoch: 1/2, step 545/53949 completed (loss: 3.0684568881988525, acc: 0.09090909361839294)
[2025-02-17 17:39:47,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:48,007][root][INFO] - Training Epoch: 1/2, step 546/53949 completed (loss: 2.2101917266845703, acc: 0.40425533056259155)
[2025-02-17 17:39:48,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:48,420][root][INFO] - Training Epoch: 1/2, step 547/53949 completed (loss: 2.294935941696167, acc: 0.37735849618911743)
[2025-02-17 17:39:48,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:48,825][root][INFO] - Training Epoch: 1/2, step 548/53949 completed (loss: 2.3059873580932617, acc: 0.3614457845687866)
[2025-02-17 17:39:48,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:49,179][root][INFO] - Training Epoch: 1/2, step 549/53949 completed (loss: 2.1393253803253174, acc: 0.42307692766189575)
[2025-02-17 17:39:49,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:49,552][root][INFO] - Training Epoch: 1/2, step 550/53949 completed (loss: 2.1035168170928955, acc: 0.41999998688697815)
[2025-02-17 17:39:49,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:49,914][root][INFO] - Training Epoch: 1/2, step 551/53949 completed (loss: 2.2237191200256348, acc: 0.34057971835136414)
[2025-02-17 17:39:50,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:50,311][root][INFO] - Training Epoch: 1/2, step 552/53949 completed (loss: 2.0055549144744873, acc: 0.460317462682724)
[2025-02-17 17:39:50,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:50,682][root][INFO] - Training Epoch: 1/2, step 553/53949 completed (loss: 2.1497344970703125, acc: 0.3888888955116272)
[2025-02-17 17:39:50,843][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:51,063][root][INFO] - Training Epoch: 1/2, step 554/53949 completed (loss: 2.1929335594177246, acc: 0.38461539149284363)
[2025-02-17 17:39:51,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:51,445][root][INFO] - Training Epoch: 1/2, step 555/53949 completed (loss: 1.7287095785140991, acc: 0.5)
[2025-02-17 17:39:51,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:51,865][root][INFO] - Training Epoch: 1/2, step 556/53949 completed (loss: 2.166257619857788, acc: 0.4099999964237213)
[2025-02-17 17:39:52,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:52,267][root][INFO] - Training Epoch: 1/2, step 557/53949 completed (loss: 1.9548325538635254, acc: 0.5)
[2025-02-17 17:39:52,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:52,673][root][INFO] - Training Epoch: 1/2, step 558/53949 completed (loss: 2.0236709117889404, acc: 0.4047619104385376)
[2025-02-17 17:39:52,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:53,029][root][INFO] - Training Epoch: 1/2, step 559/53949 completed (loss: 1.8020132780075073, acc: 0.4848484992980957)
[2025-02-17 17:39:53,186][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:53,403][root][INFO] - Training Epoch: 1/2, step 560/53949 completed (loss: 2.1157517433166504, acc: 0.4021739065647125)
[2025-02-17 17:39:53,577][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:53,778][root][INFO] - Training Epoch: 1/2, step 561/53949 completed (loss: 0.29752710461616516, acc: 1.0)
[2025-02-17 17:39:53,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:54,150][root][INFO] - Training Epoch: 1/2, step 562/53949 completed (loss: 1.9136017560958862, acc: 0.4333333373069763)
[2025-02-17 17:39:54,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:54,508][root][INFO] - Training Epoch: 1/2, step 563/53949 completed (loss: 2.0901172161102295, acc: 0.47058823704719543)
[2025-02-17 17:39:54,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:54,904][root][INFO] - Training Epoch: 1/2, step 564/53949 completed (loss: 2.254572868347168, acc: 0.3384615480899811)
[2025-02-17 17:39:55,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:55,306][root][INFO] - Training Epoch: 1/2, step 565/53949 completed (loss: 2.6177597045898438, acc: 0.2461538463830948)
[2025-02-17 17:39:55,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:55,664][root][INFO] - Training Epoch: 1/2, step 566/53949 completed (loss: 2.031038761138916, acc: 0.4893617033958435)
[2025-02-17 17:39:55,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:56,059][root][INFO] - Training Epoch: 1/2, step 567/53949 completed (loss: 1.4619420766830444, acc: 0.5625)
[2025-02-17 17:39:56,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:56,407][root][INFO] - Training Epoch: 1/2, step 568/53949 completed (loss: 2.4735336303710938, acc: 0.2876712381839752)
[2025-02-17 17:39:56,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:56,835][root][INFO] - Training Epoch: 1/2, step 569/53949 completed (loss: 2.4629318714141846, acc: 0.34756097197532654)
[2025-02-17 17:39:57,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:57,223][root][INFO] - Training Epoch: 1/2, step 570/53949 completed (loss: 1.5743895769119263, acc: 0.5882353186607361)
[2025-02-17 17:39:57,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:57,585][root][INFO] - Training Epoch: 1/2, step 571/53949 completed (loss: 2.1262857913970947, acc: 0.3731343150138855)
[2025-02-17 17:39:57,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:58,024][root][INFO] - Training Epoch: 1/2, step 572/53949 completed (loss: 2.1709935665130615, acc: 0.3827160596847534)
[2025-02-17 17:39:58,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:58,400][root][INFO] - Training Epoch: 1/2, step 573/53949 completed (loss: 1.958708643913269, acc: 0.36734694242477417)
[2025-02-17 17:39:58,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:58,756][root][INFO] - Training Epoch: 1/2, step 574/53949 completed (loss: 2.201146125793457, acc: 0.35668790340423584)
[2025-02-17 17:39:58,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:59,136][root][INFO] - Training Epoch: 1/2, step 575/53949 completed (loss: 2.228790044784546, acc: 0.4202898442745209)
[2025-02-17 17:39:59,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:59,517][root][INFO] - Training Epoch: 1/2, step 576/53949 completed (loss: 2.247241258621216, acc: 0.3910891115665436)
[2025-02-17 17:39:59,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:59,873][root][INFO] - Training Epoch: 1/2, step 577/53949 completed (loss: 2.2537765502929688, acc: 0.3252032399177551)
[2025-02-17 17:40:00,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:00,237][root][INFO] - Training Epoch: 1/2, step 578/53949 completed (loss: 2.5002222061157227, acc: 0.37837839126586914)
[2025-02-17 17:40:00,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:00,609][root][INFO] - Training Epoch: 1/2, step 579/53949 completed (loss: 2.498157262802124, acc: 0.3103448152542114)
[2025-02-17 17:40:00,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:00,976][root][INFO] - Training Epoch: 1/2, step 580/53949 completed (loss: 2.177645683288574, acc: 0.4000000059604645)
[2025-02-17 17:40:01,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:01,376][root][INFO] - Training Epoch: 1/2, step 581/53949 completed (loss: 2.2749717235565186, acc: 0.3523809611797333)
[2025-02-17 17:40:01,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:01,728][root][INFO] - Training Epoch: 1/2, step 582/53949 completed (loss: 2.6668014526367188, acc: 0.4000000059604645)
[2025-02-17 17:40:01,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:02,150][root][INFO] - Training Epoch: 1/2, step 583/53949 completed (loss: 2.036911964416504, acc: 0.4492753744125366)
[2025-02-17 17:40:02,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:02,518][root][INFO] - Training Epoch: 1/2, step 584/53949 completed (loss: 1.1276936531066895, acc: 0.75)
[2025-02-17 17:40:02,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:02,885][root][INFO] - Training Epoch: 1/2, step 585/53949 completed (loss: 2.5843772888183594, acc: 0.30434781312942505)
[2025-02-17 17:40:03,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:03,233][root][INFO] - Training Epoch: 1/2, step 586/53949 completed (loss: 1.4548791646957397, acc: 0.6666666865348816)
[2025-02-17 17:40:03,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:03,650][root][INFO] - Training Epoch: 1/2, step 587/53949 completed (loss: 2.222851514816284, acc: 0.3711340129375458)
[2025-02-17 17:40:03,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:04,040][root][INFO] - Training Epoch: 1/2, step 588/53949 completed (loss: 1.9409148693084717, acc: 0.4545454680919647)
[2025-02-17 17:40:04,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:04,455][root][INFO] - Training Epoch: 1/2, step 589/53949 completed (loss: 2.2711949348449707, acc: 0.3243243098258972)
[2025-02-17 17:40:04,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:04,836][root][INFO] - Training Epoch: 1/2, step 590/53949 completed (loss: 2.126981258392334, acc: 0.4285714328289032)
[2025-02-17 17:40:05,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:05,258][root][INFO] - Training Epoch: 1/2, step 591/53949 completed (loss: 2.417567253112793, acc: 0.4838709533214569)
[2025-02-17 17:40:05,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:05,664][root][INFO] - Training Epoch: 1/2, step 592/53949 completed (loss: 1.7272498607635498, acc: 0.52173912525177)
[2025-02-17 17:40:05,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:06,108][root][INFO] - Training Epoch: 1/2, step 593/53949 completed (loss: 2.250275135040283, acc: 0.3499999940395355)
[2025-02-17 17:40:06,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:06,490][root][INFO] - Training Epoch: 1/2, step 594/53949 completed (loss: 1.1918987035751343, acc: 0.75)
[2025-02-17 17:40:06,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:06,864][root][INFO] - Training Epoch: 1/2, step 595/53949 completed (loss: 2.331413984298706, acc: 0.4193548262119293)
[2025-02-17 17:40:07,056][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:07,284][root][INFO] - Training Epoch: 1/2, step 596/53949 completed (loss: 2.235745429992676, acc: 0.4000000059604645)
[2025-02-17 17:40:07,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:07,675][root][INFO] - Training Epoch: 1/2, step 597/53949 completed (loss: 2.516691207885742, acc: 0.335999995470047)
[2025-02-17 17:40:07,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:08,067][root][INFO] - Training Epoch: 1/2, step 598/53949 completed (loss: 1.9901509284973145, acc: 0.4714285731315613)
[2025-02-17 17:40:08,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:08,444][root][INFO] - Training Epoch: 1/2, step 599/53949 completed (loss: 2.177554130554199, acc: 0.4285714328289032)
[2025-02-17 17:40:08,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:08,827][root][INFO] - Training Epoch: 1/2, step 600/53949 completed (loss: 2.151750326156616, acc: 0.4150943458080292)
[2025-02-17 17:40:09,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:09,292][root][INFO] - Training Epoch: 1/2, step 601/53949 completed (loss: 2.1554629802703857, acc: 0.34210526943206787)
[2025-02-17 17:40:09,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:09,711][root][INFO] - Training Epoch: 1/2, step 602/53949 completed (loss: 2.0376102924346924, acc: 0.4047619104385376)
[2025-02-17 17:40:09,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:10,139][root][INFO] - Training Epoch: 1/2, step 603/53949 completed (loss: 2.053133487701416, acc: 0.5)
[2025-02-17 17:40:10,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:10,537][root][INFO] - Training Epoch: 1/2, step 604/53949 completed (loss: 2.287635564804077, acc: 0.3191489279270172)
[2025-02-17 17:40:10,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:10,911][root][INFO] - Training Epoch: 1/2, step 605/53949 completed (loss: 2.3358118534088135, acc: 0.39772728085517883)
[2025-02-17 17:40:11,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:11,301][root][INFO] - Training Epoch: 1/2, step 606/53949 completed (loss: 2.322667121887207, acc: 0.32786884903907776)
[2025-02-17 17:40:11,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:11,761][root][INFO] - Training Epoch: 1/2, step 607/53949 completed (loss: 1.8288991451263428, acc: 0.5277777910232544)
[2025-02-17 17:40:11,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:12,166][root][INFO] - Training Epoch: 1/2, step 608/53949 completed (loss: 2.046354293823242, acc: 0.45652174949645996)
[2025-02-17 17:40:12,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:12,628][root][INFO] - Training Epoch: 1/2, step 609/53949 completed (loss: 2.0029592514038086, acc: 0.5290322303771973)
[2025-02-17 17:40:12,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:13,090][root][INFO] - Training Epoch: 1/2, step 610/53949 completed (loss: 2.496481418609619, acc: 0.35555556416511536)
[2025-02-17 17:40:13,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:13,514][root][INFO] - Training Epoch: 1/2, step 611/53949 completed (loss: 2.4468209743499756, acc: 0.38461539149284363)
[2025-02-17 17:40:13,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:13,941][root][INFO] - Training Epoch: 1/2, step 612/53949 completed (loss: 1.924640417098999, acc: 0.46666666865348816)
[2025-02-17 17:40:14,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:14,351][root][INFO] - Training Epoch: 1/2, step 613/53949 completed (loss: 0.1826772689819336, acc: 1.0)
[2025-02-17 17:40:14,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:14,738][root][INFO] - Training Epoch: 1/2, step 614/53949 completed (loss: 1.9657107591629028, acc: 0.4193548262119293)
[2025-02-17 17:40:14,888][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:15,105][root][INFO] - Training Epoch: 1/2, step 615/53949 completed (loss: 2.242593765258789, acc: 0.4166666567325592)
[2025-02-17 17:40:15,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:15,490][root][INFO] - Training Epoch: 1/2, step 616/53949 completed (loss: 2.1106574535369873, acc: 0.40833333134651184)
[2025-02-17 17:40:15,666][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:15,885][root][INFO] - Training Epoch: 1/2, step 617/53949 completed (loss: 0.3879684507846832, acc: 0.8333333134651184)
[2025-02-17 17:40:16,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:16,303][root][INFO] - Training Epoch: 1/2, step 618/53949 completed (loss: 2.1918537616729736, acc: 0.43421053886413574)
[2025-02-17 17:40:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:16,727][root][INFO] - Training Epoch: 1/2, step 619/53949 completed (loss: 2.362534999847412, acc: 0.26153847575187683)
[2025-02-17 17:40:16,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:17,105][root][INFO] - Training Epoch: 1/2, step 620/53949 completed (loss: 2.4207687377929688, acc: 0.3214285671710968)
[2025-02-17 17:40:17,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:17,532][root][INFO] - Training Epoch: 1/2, step 621/53949 completed (loss: 2.3620827198028564, acc: 0.29885056614875793)
[2025-02-17 17:40:17,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:17,955][root][INFO] - Training Epoch: 1/2, step 622/53949 completed (loss: 2.2122223377227783, acc: 0.37226277589797974)
[2025-02-17 17:40:18,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:18,317][root][INFO] - Training Epoch: 1/2, step 623/53949 completed (loss: 2.2803192138671875, acc: 0.3333333432674408)
[2025-02-17 17:40:18,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:18,679][root][INFO] - Training Epoch: 1/2, step 624/53949 completed (loss: 1.9810980558395386, acc: 0.4444444477558136)
[2025-02-17 17:40:18,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:19,058][root][INFO] - Training Epoch: 1/2, step 625/53949 completed (loss: 1.7141332626342773, acc: 0.5365853905677795)
[2025-02-17 17:40:19,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:19,434][root][INFO] - Training Epoch: 1/2, step 626/53949 completed (loss: 2.2846481800079346, acc: 0.3730158805847168)
[2025-02-17 17:40:19,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:19,857][root][INFO] - Training Epoch: 1/2, step 627/53949 completed (loss: 2.1040661334991455, acc: 0.4848484992980957)
[2025-02-17 17:40:20,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:20,226][root][INFO] - Training Epoch: 1/2, step 628/53949 completed (loss: 2.084352493286133, acc: 0.40458014607429504)
[2025-02-17 17:40:20,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:20,636][root][INFO] - Training Epoch: 1/2, step 629/53949 completed (loss: 2.365044116973877, acc: 0.3076923191547394)
[2025-02-17 17:40:20,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:21,071][root][INFO] - Training Epoch: 1/2, step 630/53949 completed (loss: 2.3722102642059326, acc: 0.3333333432674408)
[2025-02-17 17:40:21,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:21,448][root][INFO] - Training Epoch: 1/2, step 631/53949 completed (loss: 0.8317442536354065, acc: 0.7142857313156128)
[2025-02-17 17:40:21,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:21,807][root][INFO] - Training Epoch: 1/2, step 632/53949 completed (loss: 2.066939115524292, acc: 0.4285714328289032)
[2025-02-17 17:40:21,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:22,147][root][INFO] - Training Epoch: 1/2, step 633/53949 completed (loss: 2.5935094356536865, acc: 0.34210526943206787)
[2025-02-17 17:40:22,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:22,487][root][INFO] - Training Epoch: 1/2, step 634/53949 completed (loss: 2.0955893993377686, acc: 0.3709677457809448)
[2025-02-17 17:40:22,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:23,039][root][INFO] - Training Epoch: 1/2, step 635/53949 completed (loss: 2.1729650497436523, acc: 0.3661971688270569)
[2025-02-17 17:40:23,212][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:23,427][root][INFO] - Training Epoch: 1/2, step 636/53949 completed (loss: 1.7800724506378174, acc: 0.5178571343421936)
[2025-02-17 17:40:23,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:23,789][root][INFO] - Training Epoch: 1/2, step 637/53949 completed (loss: 2.3896331787109375, acc: 0.3777777850627899)
[2025-02-17 17:40:23,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:24,182][root][INFO] - Training Epoch: 1/2, step 638/53949 completed (loss: 2.111363172531128, acc: 0.36206895112991333)
[2025-02-17 17:40:24,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:24,592][root][INFO] - Training Epoch: 1/2, step 639/53949 completed (loss: 2.050144910812378, acc: 0.3852458894252777)
[2025-02-17 17:40:24,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:24,943][root][INFO] - Training Epoch: 1/2, step 640/53949 completed (loss: 1.82501220703125, acc: 0.5063291192054749)
[2025-02-17 17:40:25,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:25,314][root][INFO] - Training Epoch: 1/2, step 641/53949 completed (loss: 2.2329301834106445, acc: 0.42307692766189575)
[2025-02-17 17:40:25,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:25,688][root][INFO] - Training Epoch: 1/2, step 642/53949 completed (loss: 2.1736466884613037, acc: 0.35537189245224)
[2025-02-17 17:40:25,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:26,082][root][INFO] - Training Epoch: 1/2, step 643/53949 completed (loss: 2.2384719848632812, acc: 0.3870967626571655)
[2025-02-17 17:40:26,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:26,505][root][INFO] - Training Epoch: 1/2, step 644/53949 completed (loss: 2.21736478805542, acc: 0.40963855385780334)
[2025-02-17 17:40:26,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:26,893][root][INFO] - Training Epoch: 1/2, step 645/53949 completed (loss: 2.440629482269287, acc: 0.35245901346206665)
[2025-02-17 17:40:27,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:27,254][root][INFO] - Training Epoch: 1/2, step 646/53949 completed (loss: 2.0593955516815186, acc: 0.375)
[2025-02-17 17:40:27,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:27,674][root][INFO] - Training Epoch: 1/2, step 647/53949 completed (loss: 2.155364990234375, acc: 0.3870967626571655)
[2025-02-17 17:40:27,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:28,038][root][INFO] - Training Epoch: 1/2, step 648/53949 completed (loss: 2.081465005874634, acc: 0.5833333134651184)
[2025-02-17 17:40:28,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:28,397][root][INFO] - Training Epoch: 1/2, step 649/53949 completed (loss: 2.182819366455078, acc: 0.3636363744735718)
[2025-02-17 17:40:28,534][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:28,745][root][INFO] - Training Epoch: 1/2, step 650/53949 completed (loss: 1.5666053295135498, acc: 0.6190476417541504)
[2025-02-17 17:40:28,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:29,165][root][INFO] - Training Epoch: 1/2, step 651/53949 completed (loss: 1.9532707929611206, acc: 0.4563106894493103)
[2025-02-17 17:40:29,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:29,541][root][INFO] - Training Epoch: 1/2, step 652/53949 completed (loss: 2.264169216156006, acc: 0.3552631437778473)
[2025-02-17 17:40:29,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:29,907][root][INFO] - Training Epoch: 1/2, step 653/53949 completed (loss: 2.217344045639038, acc: 0.30000001192092896)
[2025-02-17 17:40:30,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:30,255][root][INFO] - Training Epoch: 1/2, step 654/53949 completed (loss: 1.9711089134216309, acc: 0.4545454680919647)
[2025-02-17 17:40:30,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:30,652][root][INFO] - Training Epoch: 1/2, step 655/53949 completed (loss: 2.225098133087158, acc: 0.5)
[2025-02-17 17:40:30,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:31,064][root][INFO] - Training Epoch: 1/2, step 656/53949 completed (loss: 2.261744499206543, acc: 0.3207547068595886)
[2025-02-17 17:40:31,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:31,450][root][INFO] - Training Epoch: 1/2, step 657/53949 completed (loss: 2.1826205253601074, acc: 0.3636363744735718)
[2025-02-17 17:40:31,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:31,838][root][INFO] - Training Epoch: 1/2, step 658/53949 completed (loss: 2.7038254737854004, acc: 0.261904776096344)
[2025-02-17 17:40:32,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:32,234][root][INFO] - Training Epoch: 1/2, step 659/53949 completed (loss: 0.1894066333770752, acc: 1.0)
[2025-02-17 17:40:32,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:32,585][root][INFO] - Training Epoch: 1/2, step 660/53949 completed (loss: 2.127354145050049, acc: 0.3580246865749359)
[2025-02-17 17:40:32,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:32,968][root][INFO] - Training Epoch: 1/2, step 661/53949 completed (loss: 1.8928927183151245, acc: 0.4545454680919647)
[2025-02-17 17:40:33,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:33,380][root][INFO] - Training Epoch: 1/2, step 662/53949 completed (loss: 2.2286128997802734, acc: 0.41025641560554504)
[2025-02-17 17:40:33,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:33,758][root][INFO] - Training Epoch: 1/2, step 663/53949 completed (loss: 2.383000373840332, acc: 0.3366336524486542)
[2025-02-17 17:40:33,901][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:34,127][root][INFO] - Training Epoch: 1/2, step 664/53949 completed (loss: 1.820575475692749, acc: 0.48543688654899597)
[2025-02-17 17:40:34,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:34,534][root][INFO] - Training Epoch: 1/2, step 665/53949 completed (loss: 1.6395608186721802, acc: 0.4318181872367859)
[2025-02-17 17:40:34,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:34,926][root][INFO] - Training Epoch: 1/2, step 666/53949 completed (loss: 2.351003408432007, acc: 0.40243902802467346)
[2025-02-17 17:40:35,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:35,331][root][INFO] - Training Epoch: 1/2, step 667/53949 completed (loss: 2.102186679840088, acc: 0.4093959629535675)
[2025-02-17 17:40:35,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:35,751][root][INFO] - Training Epoch: 1/2, step 668/53949 completed (loss: 1.9877493381500244, acc: 0.4444444477558136)
[2025-02-17 17:40:35,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:36,185][root][INFO] - Training Epoch: 1/2, step 669/53949 completed (loss: 1.8157227039337158, acc: 0.5106382966041565)
[2025-02-17 17:40:36,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:36,593][root][INFO] - Training Epoch: 1/2, step 670/53949 completed (loss: 1.8988428115844727, acc: 0.4769230782985687)
[2025-02-17 17:40:36,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:37,010][root][INFO] - Training Epoch: 1/2, step 671/53949 completed (loss: 1.348874568939209, acc: 0.6315789222717285)
[2025-02-17 17:40:37,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:37,421][root][INFO] - Training Epoch: 1/2, step 672/53949 completed (loss: 1.5868043899536133, acc: 0.6470588445663452)
[2025-02-17 17:40:37,605][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:37,822][root][INFO] - Training Epoch: 1/2, step 673/53949 completed (loss: 1.7669481039047241, acc: 0.5063291192054749)
[2025-02-17 17:40:37,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:38,169][root][INFO] - Training Epoch: 1/2, step 674/53949 completed (loss: 2.270756959915161, acc: 0.3589743673801422)
[2025-02-17 17:40:38,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:38,526][root][INFO] - Training Epoch: 1/2, step 675/53949 completed (loss: 2.413393974304199, acc: 0.3181818127632141)
[2025-02-17 17:40:38,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:38,879][root][INFO] - Training Epoch: 1/2, step 676/53949 completed (loss: 1.870530605316162, acc: 0.41558441519737244)
[2025-02-17 17:40:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:39,256][root][INFO] - Training Epoch: 1/2, step 677/53949 completed (loss: 2.24823260307312, acc: 0.39024388790130615)
[2025-02-17 17:40:39,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:39,644][root][INFO] - Training Epoch: 1/2, step 678/53949 completed (loss: 2.171660900115967, acc: 0.42307692766189575)
[2025-02-17 17:40:39,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:40,082][root][INFO] - Training Epoch: 1/2, step 679/53949 completed (loss: 1.8610514402389526, acc: 0.5040650367736816)
[2025-02-17 17:40:40,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:40,453][root][INFO] - Training Epoch: 1/2, step 680/53949 completed (loss: 2.146214008331299, acc: 0.4126984179019928)
[2025-02-17 17:40:40,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:40,886][root][INFO] - Training Epoch: 1/2, step 681/53949 completed (loss: 1.821696162223816, acc: 0.4909090995788574)
[2025-02-17 17:40:41,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:41,287][root][INFO] - Training Epoch: 1/2, step 682/53949 completed (loss: 2.227968692779541, acc: 0.3448275923728943)
[2025-02-17 17:40:41,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:41,703][root][INFO] - Training Epoch: 1/2, step 683/53949 completed (loss: 0.8956671357154846, acc: 0.6666666865348816)
[2025-02-17 17:40:41,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:42,091][root][INFO] - Training Epoch: 1/2, step 684/53949 completed (loss: 1.9805330038070679, acc: 0.4736842215061188)
[2025-02-17 17:40:42,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:42,508][root][INFO] - Training Epoch: 1/2, step 685/53949 completed (loss: 2.2983877658843994, acc: 0.3287671208381653)
[2025-02-17 17:40:42,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:42,924][root][INFO] - Training Epoch: 1/2, step 686/53949 completed (loss: 1.7563579082489014, acc: 0.6071428656578064)
[2025-02-17 17:40:43,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:43,297][root][INFO] - Training Epoch: 1/2, step 687/53949 completed (loss: 2.0751945972442627, acc: 0.40909090638160706)
[2025-02-17 17:40:43,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:43,649][root][INFO] - Training Epoch: 1/2, step 688/53949 completed (loss: 2.3615124225616455, acc: 0.375)
[2025-02-17 17:40:43,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:44,065][root][INFO] - Training Epoch: 1/2, step 689/53949 completed (loss: 1.6178550720214844, acc: 0.5362318754196167)
[2025-02-17 17:40:44,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:44,438][root][INFO] - Training Epoch: 1/2, step 690/53949 completed (loss: 2.39223575592041, acc: 0.36666667461395264)
[2025-02-17 17:40:44,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:44,801][root][INFO] - Training Epoch: 1/2, step 691/53949 completed (loss: 2.4362096786499023, acc: 0.35849055647850037)
[2025-02-17 17:40:44,947][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:45,169][root][INFO] - Training Epoch: 1/2, step 692/53949 completed (loss: 2.280221462249756, acc: 0.2142857164144516)
[2025-02-17 17:40:45,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:45,568][root][INFO] - Training Epoch: 1/2, step 693/53949 completed (loss: 2.0249688625335693, acc: 0.5666666626930237)
[2025-02-17 17:40:45,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:46,020][root][INFO] - Training Epoch: 1/2, step 694/53949 completed (loss: 2.1345338821411133, acc: 0.4475138187408447)
[2025-02-17 17:40:46,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:46,439][root][INFO] - Training Epoch: 1/2, step 695/53949 completed (loss: 1.1959261894226074, acc: 0.7272727489471436)
[2025-02-17 17:40:46,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:46,839][root][INFO] - Training Epoch: 1/2, step 696/53949 completed (loss: 2.0703749656677246, acc: 0.38235294818878174)
[2025-02-17 17:40:46,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:47,213][root][INFO] - Training Epoch: 1/2, step 697/53949 completed (loss: 2.0672450065612793, acc: 0.49056604504585266)
[2025-02-17 17:40:47,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:47,581][root][INFO] - Training Epoch: 1/2, step 698/53949 completed (loss: 2.09769868850708, acc: 0.43529412150382996)
[2025-02-17 17:40:47,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:47,936][root][INFO] - Training Epoch: 1/2, step 699/53949 completed (loss: 1.920436978340149, acc: 0.44897958636283875)
[2025-02-17 17:40:48,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:48,300][root][INFO] - Training Epoch: 1/2, step 700/53949 completed (loss: 1.9505468606948853, acc: 0.4920634925365448)
[2025-02-17 17:40:48,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:48,727][root][INFO] - Training Epoch: 1/2, step 701/53949 completed (loss: 2.2908225059509277, acc: 0.4000000059604645)
[2025-02-17 17:40:48,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:49,116][root][INFO] - Training Epoch: 1/2, step 702/53949 completed (loss: 2.125771999359131, acc: 0.4189189076423645)
[2025-02-17 17:40:49,254][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:49,473][root][INFO] - Training Epoch: 1/2, step 703/53949 completed (loss: 1.606086254119873, acc: 0.5056179761886597)
[2025-02-17 17:40:49,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:49,886][root][INFO] - Training Epoch: 1/2, step 704/53949 completed (loss: 2.029435634613037, acc: 0.4508196711540222)
[2025-02-17 17:40:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:50,276][root][INFO] - Training Epoch: 1/2, step 705/53949 completed (loss: 2.041753053665161, acc: 0.3932584226131439)
[2025-02-17 17:40:50,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:50,657][root][INFO] - Training Epoch: 1/2, step 706/53949 completed (loss: 1.9916226863861084, acc: 0.4444444477558136)
[2025-02-17 17:40:50,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:51,035][root][INFO] - Training Epoch: 1/2, step 707/53949 completed (loss: 2.3056373596191406, acc: 0.3918918967247009)
[2025-02-17 17:40:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:51,392][root][INFO] - Training Epoch: 1/2, step 708/53949 completed (loss: 2.455907106399536, acc: 0.36734694242477417)
[2025-02-17 17:40:51,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:51,796][root][INFO] - Training Epoch: 1/2, step 709/53949 completed (loss: 2.3518307209014893, acc: 0.290909081697464)
[2025-02-17 17:40:51,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:52,153][root][INFO] - Training Epoch: 1/2, step 710/53949 completed (loss: 2.1297013759613037, acc: 0.44736841320991516)
[2025-02-17 17:40:52,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:52,577][root][INFO] - Training Epoch: 1/2, step 711/53949 completed (loss: 1.912011981010437, acc: 0.4444444477558136)
[2025-02-17 17:40:52,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:52,959][root][INFO] - Training Epoch: 1/2, step 712/53949 completed (loss: 1.8253130912780762, acc: 0.4390243887901306)
[2025-02-17 17:40:53,127][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:53,350][root][INFO] - Training Epoch: 1/2, step 713/53949 completed (loss: 2.1730353832244873, acc: 0.3888888955116272)
[2025-02-17 17:40:53,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:53,710][root][INFO] - Training Epoch: 1/2, step 714/53949 completed (loss: 1.9011961221694946, acc: 0.5555555820465088)
[2025-02-17 17:40:53,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:54,081][root][INFO] - Training Epoch: 1/2, step 715/53949 completed (loss: 0.6731845736503601, acc: 0.8571428656578064)
[2025-02-17 17:40:54,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:54,456][root][INFO] - Training Epoch: 1/2, step 716/53949 completed (loss: 2.1013495922088623, acc: 0.3757575750350952)
[2025-02-17 17:40:54,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:54,805][root][INFO] - Training Epoch: 1/2, step 717/53949 completed (loss: 2.1572864055633545, acc: 0.42592594027519226)
[2025-02-17 17:40:54,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:55,176][root][INFO] - Training Epoch: 1/2, step 718/53949 completed (loss: 2.1390538215637207, acc: 0.43283581733703613)
[2025-02-17 17:40:55,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:55,562][root][INFO] - Training Epoch: 1/2, step 719/53949 completed (loss: 2.0232458114624023, acc: 0.4202898442745209)
[2025-02-17 17:40:55,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:55,962][root][INFO] - Training Epoch: 1/2, step 720/53949 completed (loss: 1.6140105724334717, acc: 0.6153846383094788)
[2025-02-17 17:40:56,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:56,367][root][INFO] - Training Epoch: 1/2, step 721/53949 completed (loss: 2.4720804691314697, acc: 0.30158731341362)
[2025-02-17 17:40:56,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:56,723][root][INFO] - Training Epoch: 1/2, step 722/53949 completed (loss: 2.240987777709961, acc: 0.3502824902534485)
[2025-02-17 17:40:56,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:57,166][root][INFO] - Training Epoch: 1/2, step 723/53949 completed (loss: 2.3681838512420654, acc: 0.3695652186870575)
[2025-02-17 17:40:57,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:57,522][root][INFO] - Training Epoch: 1/2, step 724/53949 completed (loss: 2.147416830062866, acc: 0.40425533056259155)
[2025-02-17 17:40:57,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:57,920][root][INFO] - Training Epoch: 1/2, step 725/53949 completed (loss: 1.9334278106689453, acc: 0.4864864945411682)
[2025-02-17 17:40:58,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:58,285][root][INFO] - Training Epoch: 1/2, step 726/53949 completed (loss: 1.6647478342056274, acc: 0.5)
[2025-02-17 17:40:58,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:58,650][root][INFO] - Training Epoch: 1/2, step 727/53949 completed (loss: 2.0205769538879395, acc: 0.39393940567970276)
[2025-02-17 17:40:58,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:59,029][root][INFO] - Training Epoch: 1/2, step 728/53949 completed (loss: 1.8861000537872314, acc: 0.4534161388874054)
[2025-02-17 17:40:59,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:59,446][root][INFO] - Training Epoch: 1/2, step 729/53949 completed (loss: 2.1167349815368652, acc: 0.3916666805744171)
[2025-02-17 17:40:59,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:59,824][root][INFO] - Training Epoch: 1/2, step 730/53949 completed (loss: 2.1151669025421143, acc: 0.4041095972061157)
[2025-02-17 17:41:00,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:00,231][root][INFO] - Training Epoch: 1/2, step 731/53949 completed (loss: 1.9352113008499146, acc: 0.5)
[2025-02-17 17:41:00,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:00,592][root][INFO] - Training Epoch: 1/2, step 732/53949 completed (loss: 1.7892670631408691, acc: 0.4615384638309479)
[2025-02-17 17:41:00,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:00,990][root][INFO] - Training Epoch: 1/2, step 733/53949 completed (loss: 2.5174851417541504, acc: 0.2631579041481018)
[2025-02-17 17:41:01,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:01,361][root][INFO] - Training Epoch: 1/2, step 734/53949 completed (loss: 1.6945418119430542, acc: 0.5593220591545105)
[2025-02-17 17:41:01,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:01,719][root][INFO] - Training Epoch: 1/2, step 735/53949 completed (loss: 2.4697415828704834, acc: 0.34065935015678406)
[2025-02-17 17:41:01,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:02,124][root][INFO] - Training Epoch: 1/2, step 736/53949 completed (loss: 2.2628495693206787, acc: 0.4375)
[2025-02-17 17:41:02,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:02,515][root][INFO] - Training Epoch: 1/2, step 737/53949 completed (loss: 2.241079330444336, acc: 0.36000001430511475)
[2025-02-17 17:41:02,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:02,931][root][INFO] - Training Epoch: 1/2, step 738/53949 completed (loss: 1.8058263063430786, acc: 0.5882353186607361)
[2025-02-17 17:41:03,062][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:03,280][root][INFO] - Training Epoch: 1/2, step 739/53949 completed (loss: 2.1872055530548096, acc: 0.3235294222831726)
[2025-02-17 17:41:03,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:03,667][root][INFO] - Training Epoch: 1/2, step 740/53949 completed (loss: 2.7509655952453613, acc: 0.3636363744735718)
[2025-02-17 17:41:03,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:04,053][root][INFO] - Training Epoch: 1/2, step 741/53949 completed (loss: 2.1422653198242188, acc: 0.4117647111415863)
[2025-02-17 17:41:04,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:04,412][root][INFO] - Training Epoch: 1/2, step 742/53949 completed (loss: 2.7890937328338623, acc: 0.27272728085517883)
[2025-02-17 17:41:04,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:04,818][root][INFO] - Training Epoch: 1/2, step 743/53949 completed (loss: 2.004561185836792, acc: 0.38805970549583435)
[2025-02-17 17:41:04,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:05,196][root][INFO] - Training Epoch: 1/2, step 744/53949 completed (loss: 2.199720621109009, acc: 0.3734939694404602)
[2025-02-17 17:41:05,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:05,551][root][INFO] - Training Epoch: 1/2, step 745/53949 completed (loss: 2.163675308227539, acc: 0.4117647111415863)
[2025-02-17 17:41:05,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:05,972][root][INFO] - Training Epoch: 1/2, step 746/53949 completed (loss: 2.5934040546417236, acc: 0.30434781312942505)
[2025-02-17 17:41:06,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:06,396][root][INFO] - Training Epoch: 1/2, step 747/53949 completed (loss: 1.935377597808838, acc: 0.4893617033958435)
[2025-02-17 17:41:06,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:06,780][root][INFO] - Training Epoch: 1/2, step 748/53949 completed (loss: 2.1143910884857178, acc: 0.4693877696990967)
[2025-02-17 17:41:06,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:07,142][root][INFO] - Training Epoch: 1/2, step 749/53949 completed (loss: 2.216921329498291, acc: 0.41025641560554504)
[2025-02-17 17:41:07,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:07,538][root][INFO] - Training Epoch: 1/2, step 750/53949 completed (loss: 2.2573301792144775, acc: 0.38461539149284363)
[2025-02-17 17:41:07,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:07,952][root][INFO] - Training Epoch: 1/2, step 751/53949 completed (loss: 1.204380750656128, acc: 0.6666666865348816)
[2025-02-17 17:41:08,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:08,354][root][INFO] - Training Epoch: 1/2, step 752/53949 completed (loss: 1.873264193534851, acc: 0.42424243688583374)
[2025-02-17 17:41:08,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:08,714][root][INFO] - Training Epoch: 1/2, step 753/53949 completed (loss: 1.969159722328186, acc: 0.4057970941066742)
[2025-02-17 17:41:08,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:09,105][root][INFO] - Training Epoch: 1/2, step 754/53949 completed (loss: 2.131129026412964, acc: 0.4471544623374939)
[2025-02-17 17:41:09,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:09,521][root][INFO] - Training Epoch: 1/2, step 755/53949 completed (loss: 1.294764757156372, acc: 0.6428571343421936)
[2025-02-17 17:41:09,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:09,929][root][INFO] - Training Epoch: 1/2, step 756/53949 completed (loss: 1.7095117568969727, acc: 0.511904776096344)
[2025-02-17 17:41:10,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:10,298][root][INFO] - Training Epoch: 1/2, step 757/53949 completed (loss: 1.995959758758545, acc: 0.4754098355770111)
[2025-02-17 17:41:10,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:10,638][root][INFO] - Training Epoch: 1/2, step 758/53949 completed (loss: 1.027185320854187, acc: 0.692307710647583)
[2025-02-17 17:41:10,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:11,022][root][INFO] - Training Epoch: 1/2, step 759/53949 completed (loss: 2.215031862258911, acc: 0.5)
[2025-02-17 17:41:11,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:11,415][root][INFO] - Training Epoch: 1/2, step 760/53949 completed (loss: 2.07979154586792, acc: 0.3333333432674408)
[2025-02-17 17:41:11,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:11,811][root][INFO] - Training Epoch: 1/2, step 761/53949 completed (loss: 1.9646551609039307, acc: 0.5)
[2025-02-17 17:41:11,953][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:12,142][root][INFO] - Training Epoch: 1/2, step 762/53949 completed (loss: 1.4961936473846436, acc: 0.5769230723381042)
[2025-02-17 17:41:12,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:12,508][root][INFO] - Training Epoch: 1/2, step 763/53949 completed (loss: 2.006662607192993, acc: 0.4455445408821106)
[2025-02-17 17:41:12,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:12,926][root][INFO] - Training Epoch: 1/2, step 764/53949 completed (loss: 2.1027631759643555, acc: 0.4385964870452881)
[2025-02-17 17:41:13,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:13,315][root][INFO] - Training Epoch: 1/2, step 765/53949 completed (loss: 1.6844614744186401, acc: 0.6399999856948853)
[2025-02-17 17:41:13,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:13,687][root][INFO] - Training Epoch: 1/2, step 766/53949 completed (loss: 2.157296895980835, acc: 0.37704917788505554)
[2025-02-17 17:41:13,863][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:14,077][root][INFO] - Training Epoch: 1/2, step 767/53949 completed (loss: 2.3651182651519775, acc: 0.3372093141078949)
[2025-02-17 17:41:14,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:14,454][root][INFO] - Training Epoch: 1/2, step 768/53949 completed (loss: 1.7374422550201416, acc: 0.5277777910232544)
[2025-02-17 17:41:14,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:14,816][root][INFO] - Training Epoch: 1/2, step 769/53949 completed (loss: 2.2344462871551514, acc: 0.3333333432674408)
[2025-02-17 17:41:14,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:15,199][root][INFO] - Training Epoch: 1/2, step 770/53949 completed (loss: 2.2231175899505615, acc: 0.3965517282485962)
[2025-02-17 17:41:15,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:15,604][root][INFO] - Training Epoch: 1/2, step 771/53949 completed (loss: 2.1343841552734375, acc: 0.375)
[2025-02-17 17:41:15,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:15,987][root][INFO] - Training Epoch: 1/2, step 772/53949 completed (loss: 2.373870849609375, acc: 0.3243243098258972)
[2025-02-17 17:41:16,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:16,381][root][INFO] - Training Epoch: 1/2, step 773/53949 completed (loss: 2.012446880340576, acc: 0.4025973975658417)
[2025-02-17 17:41:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:16,763][root][INFO] - Training Epoch: 1/2, step 774/53949 completed (loss: 2.048678159713745, acc: 0.39772728085517883)
[2025-02-17 17:41:16,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:17,116][root][INFO] - Training Epoch: 1/2, step 775/53949 completed (loss: 2.4431426525115967, acc: 0.2549019753932953)
[2025-02-17 17:41:17,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:17,498][root][INFO] - Training Epoch: 1/2, step 776/53949 completed (loss: 2.079198122024536, acc: 0.4000000059604645)
[2025-02-17 17:41:17,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:17,871][root][INFO] - Training Epoch: 1/2, step 777/53949 completed (loss: 0.7090030312538147, acc: 0.8888888955116272)
[2025-02-17 17:41:18,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:18,282][root][INFO] - Training Epoch: 1/2, step 778/53949 completed (loss: 2.486619472503662, acc: 0.30000001192092896)
[2025-02-17 17:41:18,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:18,743][root][INFO] - Training Epoch: 1/2, step 779/53949 completed (loss: 1.6815547943115234, acc: 0.5)
[2025-02-17 17:41:18,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:19,140][root][INFO] - Training Epoch: 1/2, step 780/53949 completed (loss: 1.8198360204696655, acc: 0.5)
[2025-02-17 17:41:19,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:19,496][root][INFO] - Training Epoch: 1/2, step 781/53949 completed (loss: 2.0259621143341064, acc: 0.4545454680919647)
[2025-02-17 17:41:19,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:19,849][root][INFO] - Training Epoch: 1/2, step 782/53949 completed (loss: 1.8230658769607544, acc: 0.4444444477558136)
[2025-02-17 17:41:19,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:20,206][root][INFO] - Training Epoch: 1/2, step 783/53949 completed (loss: 2.194317579269409, acc: 0.43103447556495667)
[2025-02-17 17:41:20,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:20,553][root][INFO] - Training Epoch: 1/2, step 784/53949 completed (loss: 1.8067052364349365, acc: 0.45348837971687317)
[2025-02-17 17:41:20,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:20,932][root][INFO] - Training Epoch: 1/2, step 785/53949 completed (loss: 1.920257329940796, acc: 0.4651162922382355)
[2025-02-17 17:41:21,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:21,287][root][INFO] - Training Epoch: 1/2, step 786/53949 completed (loss: 2.2627270221710205, acc: 0.3368421196937561)
[2025-02-17 17:41:21,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:21,711][root][INFO] - Training Epoch: 1/2, step 787/53949 completed (loss: 1.731452226638794, acc: 0.5925925970077515)
[2025-02-17 17:41:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:22,111][root][INFO] - Training Epoch: 1/2, step 788/53949 completed (loss: 1.811220407485962, acc: 0.6153846383094788)
[2025-02-17 17:41:22,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:22,520][root][INFO] - Training Epoch: 1/2, step 789/53949 completed (loss: 1.5085686445236206, acc: 0.614814817905426)
[2025-02-17 17:41:22,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:22,933][root][INFO] - Training Epoch: 1/2, step 790/53949 completed (loss: 1.5741597414016724, acc: 0.5483871102333069)
[2025-02-17 17:41:23,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:23,301][root][INFO] - Training Epoch: 1/2, step 791/53949 completed (loss: 1.8385248184204102, acc: 0.5102040767669678)
[2025-02-17 17:41:23,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:23,655][root][INFO] - Training Epoch: 1/2, step 792/53949 completed (loss: 2.2578160762786865, acc: 0.4000000059604645)
[2025-02-17 17:41:23,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:23,997][root][INFO] - Training Epoch: 1/2, step 793/53949 completed (loss: 0.1854962855577469, acc: 1.0)
[2025-02-17 17:41:24,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:24,349][root][INFO] - Training Epoch: 1/2, step 794/53949 completed (loss: 0.9885542392730713, acc: 0.7272727489471436)
[2025-02-17 17:41:24,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:24,738][root][INFO] - Training Epoch: 1/2, step 795/53949 completed (loss: 1.7660374641418457, acc: 0.5106382966041565)
[2025-02-17 17:41:24,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:25,120][root][INFO] - Training Epoch: 1/2, step 796/53949 completed (loss: 2.177401542663574, acc: 0.42307692766189575)
[2025-02-17 17:41:25,257][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:25,469][root][INFO] - Training Epoch: 1/2, step 797/53949 completed (loss: 1.5785073041915894, acc: 0.6000000238418579)
[2025-02-17 17:41:25,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:25,873][root][INFO] - Training Epoch: 1/2, step 798/53949 completed (loss: 2.341330051422119, acc: 0.41304346919059753)
[2025-02-17 17:41:26,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:26,228][root][INFO] - Training Epoch: 1/2, step 799/53949 completed (loss: 1.991818904876709, acc: 0.3855421543121338)
[2025-02-17 17:41:26,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:26,634][root][INFO] - Training Epoch: 1/2, step 800/53949 completed (loss: 2.163959264755249, acc: 0.4375)
[2025-02-17 17:41:26,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:27,034][root][INFO] - Training Epoch: 1/2, step 801/53949 completed (loss: 1.815230369567871, acc: 0.4842105209827423)
[2025-02-17 17:41:27,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:27,399][root][INFO] - Training Epoch: 1/2, step 802/53949 completed (loss: 1.8525582551956177, acc: 0.4134615361690521)
[2025-02-17 17:41:27,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:27,768][root][INFO] - Training Epoch: 1/2, step 803/53949 completed (loss: 0.923378050327301, acc: 0.7142857313156128)
[2025-02-17 17:41:27,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:28,161][root][INFO] - Training Epoch: 1/2, step 804/53949 completed (loss: 0.6466497778892517, acc: 0.75)
[2025-02-17 17:41:28,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:28,575][root][INFO] - Training Epoch: 1/2, step 805/53949 completed (loss: 0.40306001901626587, acc: 0.75)
[2025-02-17 17:41:28,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:28,940][root][INFO] - Training Epoch: 1/2, step 806/53949 completed (loss: 2.2577693462371826, acc: 0.47727271914482117)
[2025-02-17 17:41:29,077][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:29,300][root][INFO] - Training Epoch: 1/2, step 807/53949 completed (loss: 1.922060489654541, acc: 0.4693877696990967)
[2025-02-17 17:41:29,524][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:29,746][root][INFO] - Training Epoch: 1/2, step 808/53949 completed (loss: 2.2890894412994385, acc: 0.36000001430511475)
[2025-02-17 17:41:29,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:30,097][root][INFO] - Training Epoch: 1/2, step 809/53949 completed (loss: 2.2386770248413086, acc: 0.3916083872318268)
[2025-02-17 17:41:30,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:30,465][root][INFO] - Training Epoch: 1/2, step 810/53949 completed (loss: 2.2532553672790527, acc: 0.375)
[2025-02-17 17:41:30,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:30,813][root][INFO] - Training Epoch: 1/2, step 811/53949 completed (loss: 2.1735289096832275, acc: 0.41818180680274963)
[2025-02-17 17:41:30,957][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:31,172][root][INFO] - Training Epoch: 1/2, step 812/53949 completed (loss: 3.1650469303131104, acc: 0.260869562625885)
[2025-02-17 17:41:31,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:31,548][root][INFO] - Training Epoch: 1/2, step 813/53949 completed (loss: 2.352952718734741, acc: 0.3333333432674408)
[2025-02-17 17:41:31,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:31,911][root][INFO] - Training Epoch: 1/2, step 814/53949 completed (loss: 1.9744244813919067, acc: 0.5)
[2025-02-17 17:41:32,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:32,326][root][INFO] - Training Epoch: 1/2, step 815/53949 completed (loss: 2.3364787101745605, acc: 0.3870967626571655)
[2025-02-17 17:41:32,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:32,704][root][INFO] - Training Epoch: 1/2, step 816/53949 completed (loss: 1.8517972230911255, acc: 0.4333333373069763)
[2025-02-17 17:41:32,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:33,100][root][INFO] - Training Epoch: 1/2, step 817/53949 completed (loss: 2.141899585723877, acc: 0.4193548262119293)
[2025-02-17 17:41:33,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:33,473][root][INFO] - Training Epoch: 1/2, step 818/53949 completed (loss: 1.8718329668045044, acc: 0.4769230782985687)
[2025-02-17 17:41:33,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:33,871][root][INFO] - Training Epoch: 1/2, step 819/53949 completed (loss: 2.2507236003875732, acc: 0.39534884691238403)
[2025-02-17 17:41:34,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:34,246][root][INFO] - Training Epoch: 1/2, step 820/53949 completed (loss: 1.860076904296875, acc: 0.5)
[2025-02-17 17:41:34,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:34,622][root][INFO] - Training Epoch: 1/2, step 821/53949 completed (loss: 2.1506989002227783, acc: 0.41025641560554504)
[2025-02-17 17:41:34,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:34,998][root][INFO] - Training Epoch: 1/2, step 822/53949 completed (loss: 2.0812065601348877, acc: 0.43478259444236755)
[2025-02-17 17:41:35,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:35,382][root][INFO] - Training Epoch: 1/2, step 823/53949 completed (loss: 2.2903265953063965, acc: 0.41558441519737244)
[2025-02-17 17:41:35,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:35,788][root][INFO] - Training Epoch: 1/2, step 824/53949 completed (loss: 2.2277655601501465, acc: 0.40625)
[2025-02-17 17:41:35,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:36,197][root][INFO] - Training Epoch: 1/2, step 825/53949 completed (loss: 2.2800490856170654, acc: 0.3604651093482971)
[2025-02-17 17:41:36,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:36,608][root][INFO] - Training Epoch: 1/2, step 826/53949 completed (loss: 1.1324416399002075, acc: 0.699999988079071)
[2025-02-17 17:41:36,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:37,024][root][INFO] - Training Epoch: 1/2, step 827/53949 completed (loss: 0.8553681969642639, acc: 0.875)
[2025-02-17 17:41:37,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:37,433][root][INFO] - Training Epoch: 1/2, step 828/53949 completed (loss: 2.5224452018737793, acc: 0.3243243098258972)
[2025-02-17 17:41:37,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:37,836][root][INFO] - Training Epoch: 1/2, step 829/53949 completed (loss: 1.9758902788162231, acc: 0.4305555522441864)
[2025-02-17 17:41:38,005][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:38,225][root][INFO] - Training Epoch: 1/2, step 830/53949 completed (loss: 2.497539758682251, acc: 0.4137931168079376)
[2025-02-17 17:41:38,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:38,641][root][INFO] - Training Epoch: 1/2, step 831/53949 completed (loss: 1.9387078285217285, acc: 0.4615384638309479)
[2025-02-17 17:41:38,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:39,042][root][INFO] - Training Epoch: 1/2, step 832/53949 completed (loss: 1.7738105058670044, acc: 0.49367088079452515)
[2025-02-17 17:41:39,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:39,448][root][INFO] - Training Epoch: 1/2, step 833/53949 completed (loss: 2.4948976039886475, acc: 0.28787878155708313)
[2025-02-17 17:41:39,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:39,897][root][INFO] - Training Epoch: 1/2, step 834/53949 completed (loss: 1.3767644166946411, acc: 0.6521739363670349)
[2025-02-17 17:41:40,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:40,291][root][INFO] - Training Epoch: 1/2, step 835/53949 completed (loss: 2.1828885078430176, acc: 0.484375)
[2025-02-17 17:41:40,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:40,649][root][INFO] - Training Epoch: 1/2, step 836/53949 completed (loss: 1.5625925064086914, acc: 0.5)
[2025-02-17 17:41:40,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:41,032][root][INFO] - Training Epoch: 1/2, step 837/53949 completed (loss: 1.8838138580322266, acc: 0.4000000059604645)
[2025-02-17 17:41:41,209][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:41,440][root][INFO] - Training Epoch: 1/2, step 838/53949 completed (loss: 2.129805088043213, acc: 0.4273504316806793)
[2025-02-17 17:41:41,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:41,819][root][INFO] - Training Epoch: 1/2, step 839/53949 completed (loss: 2.1372809410095215, acc: 0.44565218687057495)
[2025-02-17 17:41:42,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:42,224][root][INFO] - Training Epoch: 1/2, step 840/53949 completed (loss: 0.45640575885772705, acc: 0.8333333134651184)
[2025-02-17 17:41:42,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:42,631][root][INFO] - Training Epoch: 1/2, step 841/53949 completed (loss: 2.3873021602630615, acc: 0.3400000035762787)
[2025-02-17 17:41:42,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:43,003][root][INFO] - Training Epoch: 1/2, step 842/53949 completed (loss: 2.0692152976989746, acc: 0.40740740299224854)
[2025-02-17 17:41:43,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:43,389][root][INFO] - Training Epoch: 1/2, step 843/53949 completed (loss: 2.040700912475586, acc: 0.43209877610206604)
[2025-02-17 17:41:43,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:43,784][root][INFO] - Training Epoch: 1/2, step 844/53949 completed (loss: 1.931365728378296, acc: 0.5151515007019043)
[2025-02-17 17:41:43,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:44,198][root][INFO] - Training Epoch: 1/2, step 845/53949 completed (loss: 2.1456031799316406, acc: 0.46078431606292725)
[2025-02-17 17:41:44,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:44,586][root][INFO] - Training Epoch: 1/2, step 846/53949 completed (loss: 2.3235669136047363, acc: 0.3510638177394867)
[2025-02-17 17:41:44,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:45,017][root][INFO] - Training Epoch: 1/2, step 847/53949 completed (loss: 2.282867670059204, acc: 0.37288135290145874)
[2025-02-17 17:41:45,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:45,425][root][INFO] - Training Epoch: 1/2, step 848/53949 completed (loss: 1.9495266675949097, acc: 0.37931033968925476)
[2025-02-17 17:41:45,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:45,833][root][INFO] - Training Epoch: 1/2, step 849/53949 completed (loss: 1.819064736366272, acc: 0.45528456568717957)
[2025-02-17 17:41:46,005][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:46,224][root][INFO] - Training Epoch: 1/2, step 850/53949 completed (loss: 2.036102771759033, acc: 0.3857142925262451)
[2025-02-17 17:41:46,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:46,660][root][INFO] - Training Epoch: 1/2, step 851/53949 completed (loss: 2.255103588104248, acc: 0.4545454680919647)
[2025-02-17 17:41:46,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:47,024][root][INFO] - Training Epoch: 1/2, step 852/53949 completed (loss: 2.041546106338501, acc: 0.4502924084663391)
[2025-02-17 17:41:47,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:47,444][root][INFO] - Training Epoch: 1/2, step 853/53949 completed (loss: 1.9541431665420532, acc: 0.47826087474823)
[2025-02-17 17:41:47,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:47,806][root][INFO] - Training Epoch: 1/2, step 854/53949 completed (loss: 1.9660183191299438, acc: 0.4406779706478119)
[2025-02-17 17:41:47,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:48,176][root][INFO] - Training Epoch: 1/2, step 855/53949 completed (loss: 2.0720431804656982, acc: 0.4423076808452606)
[2025-02-17 17:41:48,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:48,531][root][INFO] - Training Epoch: 1/2, step 856/53949 completed (loss: 1.6656837463378906, acc: 0.5333333611488342)
[2025-02-17 17:41:48,678][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:48,886][root][INFO] - Training Epoch: 1/2, step 857/53949 completed (loss: 1.7223165035247803, acc: 0.4651162922382355)
[2025-02-17 17:41:49,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:49,253][root][INFO] - Training Epoch: 1/2, step 858/53949 completed (loss: 2.2086713314056396, acc: 0.40625)
[2025-02-17 17:41:49,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:49,604][root][INFO] - Training Epoch: 1/2, step 859/53949 completed (loss: 2.1774160861968994, acc: 0.3733333349227905)
[2025-02-17 17:41:49,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:49,968][root][INFO] - Training Epoch: 1/2, step 860/53949 completed (loss: 2.183044195175171, acc: 0.4423076808452606)
[2025-02-17 17:41:50,104][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:50,321][root][INFO] - Training Epoch: 1/2, step 861/53949 completed (loss: 2.1628384590148926, acc: 0.37662336230278015)
[2025-02-17 17:41:50,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:50,707][root][INFO] - Training Epoch: 1/2, step 862/53949 completed (loss: 2.479003429412842, acc: 0.42105263471603394)
[2025-02-17 17:41:50,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:51,094][root][INFO] - Training Epoch: 1/2, step 863/53949 completed (loss: 1.838644027709961, acc: 0.4390243887901306)
[2025-02-17 17:41:51,229][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:51,445][root][INFO] - Training Epoch: 1/2, step 864/53949 completed (loss: 0.9520761370658875, acc: 0.875)
[2025-02-17 17:41:51,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:51,844][root][INFO] - Training Epoch: 1/2, step 865/53949 completed (loss: 2.126096487045288, acc: 0.41818180680274963)
[2025-02-17 17:41:51,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:52,198][root][INFO] - Training Epoch: 1/2, step 866/53949 completed (loss: 2.4129481315612793, acc: 0.3571428656578064)
[2025-02-17 17:41:52,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:52,653][root][INFO] - Training Epoch: 1/2, step 867/53949 completed (loss: 1.8248467445373535, acc: 0.47999998927116394)
[2025-02-17 17:41:52,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:53,084][root][INFO] - Training Epoch: 1/2, step 868/53949 completed (loss: 1.5683166980743408, acc: 0.5588235259056091)
[2025-02-17 17:41:53,227][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:53,447][root][INFO] - Training Epoch: 1/2, step 869/53949 completed (loss: 1.957095742225647, acc: 0.4000000059604645)
[2025-02-17 17:41:53,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:53,882][root][INFO] - Training Epoch: 1/2, step 870/53949 completed (loss: 1.7991234064102173, acc: 0.5591397881507874)
[2025-02-17 17:41:54,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:54,255][root][INFO] - Training Epoch: 1/2, step 871/53949 completed (loss: 2.7524924278259277, acc: 0.20000000298023224)
[2025-02-17 17:41:54,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:54,622][root][INFO] - Training Epoch: 1/2, step 872/53949 completed (loss: 1.8502439260482788, acc: 0.5041322112083435)
[2025-02-17 17:41:54,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:54,987][root][INFO] - Training Epoch: 1/2, step 873/53949 completed (loss: 1.805743932723999, acc: 0.47826087474823)
[2025-02-17 17:41:55,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:55,430][root][INFO] - Training Epoch: 1/2, step 874/53949 completed (loss: 2.429115056991577, acc: 0.37037035822868347)
[2025-02-17 17:41:55,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:55,824][root][INFO] - Training Epoch: 1/2, step 875/53949 completed (loss: 1.9525548219680786, acc: 0.52173912525177)
[2025-02-17 17:41:56,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:56,232][root][INFO] - Training Epoch: 1/2, step 876/53949 completed (loss: 1.828866958618164, acc: 0.42424243688583374)
[2025-02-17 17:41:56,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:56,611][root][INFO] - Training Epoch: 1/2, step 877/53949 completed (loss: 1.9355473518371582, acc: 0.447761207818985)
[2025-02-17 17:41:56,832][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:57,056][root][INFO] - Training Epoch: 1/2, step 878/53949 completed (loss: 1.9032037258148193, acc: 0.48750001192092896)
[2025-02-17 17:41:57,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:57,421][root][INFO] - Training Epoch: 1/2, step 879/53949 completed (loss: 2.1978518962860107, acc: 0.375)
[2025-02-17 17:41:57,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:57,769][root][INFO] - Training Epoch: 1/2, step 880/53949 completed (loss: 2.3972368240356445, acc: 0.3684210479259491)
[2025-02-17 17:41:57,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:58,138][root][INFO] - Training Epoch: 1/2, step 881/53949 completed (loss: 2.0718514919281006, acc: 0.5074626803398132)
[2025-02-17 17:41:58,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:58,512][root][INFO] - Training Epoch: 1/2, step 882/53949 completed (loss: 1.9040435552597046, acc: 0.45783132314682007)
[2025-02-17 17:41:58,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:58,950][root][INFO] - Training Epoch: 1/2, step 883/53949 completed (loss: 2.1458609104156494, acc: 0.3777777850627899)
[2025-02-17 17:41:59,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:59,357][root][INFO] - Training Epoch: 1/2, step 884/53949 completed (loss: 1.8904216289520264, acc: 0.4421052634716034)
[2025-02-17 17:41:59,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:59,855][root][INFO] - Training Epoch: 1/2, step 885/53949 completed (loss: 2.1496036052703857, acc: 0.41085270047187805)
[2025-02-17 17:42:00,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:00,218][root][INFO] - Training Epoch: 1/2, step 886/53949 completed (loss: 2.0874123573303223, acc: 0.4642857015132904)
[2025-02-17 17:42:00,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:00,589][root][INFO] - Training Epoch: 1/2, step 887/53949 completed (loss: 2.3645169734954834, acc: 0.3333333432674408)
[2025-02-17 17:42:00,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:00,936][root][INFO] - Training Epoch: 1/2, step 888/53949 completed (loss: 2.0284817218780518, acc: 0.43478259444236755)
[2025-02-17 17:42:01,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:01,313][root][INFO] - Training Epoch: 1/2, step 889/53949 completed (loss: 2.0768306255340576, acc: 0.450549453496933)
[2025-02-17 17:42:01,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:01,699][root][INFO] - Training Epoch: 1/2, step 890/53949 completed (loss: 1.6653685569763184, acc: 0.5)
[2025-02-17 17:42:01,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:02,026][root][INFO] - Training Epoch: 1/2, step 891/53949 completed (loss: 2.571875810623169, acc: 0.3684210479259491)
[2025-02-17 17:42:02,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:02,415][root][INFO] - Training Epoch: 1/2, step 892/53949 completed (loss: 2.1959240436553955, acc: 0.38693466782569885)
[2025-02-17 17:42:02,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:02,768][root][INFO] - Training Epoch: 1/2, step 893/53949 completed (loss: 1.2441065311431885, acc: 0.8333333134651184)
[2025-02-17 17:42:02,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:03,142][root][INFO] - Training Epoch: 1/2, step 894/53949 completed (loss: 2.2855725288391113, acc: 0.3483146131038666)
[2025-02-17 17:42:03,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:03,504][root][INFO] - Training Epoch: 1/2, step 895/53949 completed (loss: 2.1343910694122314, acc: 0.4888888895511627)
[2025-02-17 17:42:03,651][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:03,865][root][INFO] - Training Epoch: 1/2, step 896/53949 completed (loss: 2.1190121173858643, acc: 0.45945945382118225)
[2025-02-17 17:42:04,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:04,213][root][INFO] - Training Epoch: 1/2, step 897/53949 completed (loss: 0.7328615784645081, acc: 0.8333333134651184)
[2025-02-17 17:42:04,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:04,576][root][INFO] - Training Epoch: 1/2, step 898/53949 completed (loss: 1.8205419778823853, acc: 0.5319148898124695)
[2025-02-17 17:42:04,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:04,927][root][INFO] - Training Epoch: 1/2, step 899/53949 completed (loss: 0.397777795791626, acc: 0.8333333134651184)
[2025-02-17 17:42:05,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:05,321][root][INFO] - Training Epoch: 1/2, step 900/53949 completed (loss: 2.1510703563690186, acc: 0.3913043439388275)
[2025-02-17 17:42:05,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:05,747][root][INFO] - Training Epoch: 1/2, step 901/53949 completed (loss: 1.853314757347107, acc: 0.4716981053352356)
[2025-02-17 17:42:05,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:06,143][root][INFO] - Training Epoch: 1/2, step 902/53949 completed (loss: 1.911781907081604, acc: 0.5128205418586731)
[2025-02-17 17:42:06,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:06,571][root][INFO] - Training Epoch: 1/2, step 903/53949 completed (loss: 2.147582769393921, acc: 0.39240506291389465)
[2025-02-17 17:42:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:06,977][root][INFO] - Training Epoch: 1/2, step 904/53949 completed (loss: 1.7569471597671509, acc: 0.5339806079864502)
[2025-02-17 17:42:07,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:07,356][root][INFO] - Training Epoch: 1/2, step 905/53949 completed (loss: 2.1856472492218018, acc: 0.3968254029750824)
[2025-02-17 17:42:07,499][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:07,712][root][INFO] - Training Epoch: 1/2, step 906/53949 completed (loss: 1.7687463760375977, acc: 0.6000000238418579)
[2025-02-17 17:42:07,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:08,056][root][INFO] - Training Epoch: 1/2, step 907/53949 completed (loss: 1.3405027389526367, acc: 0.5882353186607361)
[2025-02-17 17:42:08,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:08,403][root][INFO] - Training Epoch: 1/2, step 908/53949 completed (loss: 2.3317055702209473, acc: 0.32499998807907104)
[2025-02-17 17:42:08,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:08,784][root][INFO] - Training Epoch: 1/2, step 909/53949 completed (loss: 2.142502546310425, acc: 0.4109589159488678)
[2025-02-17 17:42:08,925][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:09,135][root][INFO] - Training Epoch: 1/2, step 910/53949 completed (loss: 1.697688341140747, acc: 0.529411792755127)
[2025-02-17 17:42:09,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:09,537][root][INFO] - Training Epoch: 1/2, step 911/53949 completed (loss: 1.7671514749526978, acc: 0.5714285969734192)
[2025-02-17 17:42:09,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:09,934][root][INFO] - Training Epoch: 1/2, step 912/53949 completed (loss: 1.9862771034240723, acc: 0.4545454680919647)
[2025-02-17 17:42:10,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:10,340][root][INFO] - Training Epoch: 1/2, step 913/53949 completed (loss: 1.82651686668396, acc: 0.5371900796890259)
[2025-02-17 17:42:10,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:10,694][root][INFO] - Training Epoch: 1/2, step 914/53949 completed (loss: 1.9592208862304688, acc: 0.37735849618911743)
[2025-02-17 17:42:10,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:11,097][root][INFO] - Training Epoch: 1/2, step 915/53949 completed (loss: 2.0589005947113037, acc: 0.38805970549583435)
[2025-02-17 17:42:11,229][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:11,449][root][INFO] - Training Epoch: 1/2, step 916/53949 completed (loss: 2.0858829021453857, acc: 0.42399999499320984)
[2025-02-17 17:42:11,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:11,876][root][INFO] - Training Epoch: 1/2, step 917/53949 completed (loss: 2.0733325481414795, acc: 0.40860214829444885)
[2025-02-17 17:42:12,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:12,238][root][INFO] - Training Epoch: 1/2, step 918/53949 completed (loss: 1.9424386024475098, acc: 0.46296295523643494)
[2025-02-17 17:42:12,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:12,657][root][INFO] - Training Epoch: 1/2, step 919/53949 completed (loss: 1.5566006898880005, acc: 0.5833333134651184)
[2025-02-17 17:42:12,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:13,021][root][INFO] - Training Epoch: 1/2, step 920/53949 completed (loss: 1.6749694347381592, acc: 0.5)
[2025-02-17 17:42:13,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:13,436][root][INFO] - Training Epoch: 1/2, step 921/53949 completed (loss: 2.1959667205810547, acc: 0.3650793731212616)
[2025-02-17 17:42:13,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:13,884][root][INFO] - Training Epoch: 1/2, step 922/53949 completed (loss: 1.8236572742462158, acc: 0.5058823823928833)
[2025-02-17 17:42:14,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:14,336][root][INFO] - Training Epoch: 1/2, step 923/53949 completed (loss: 0.14415884017944336, acc: 1.0)
[2025-02-17 17:42:14,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:14,701][root][INFO] - Training Epoch: 1/2, step 924/53949 completed (loss: 1.623284935951233, acc: 0.5116279125213623)
[2025-02-17 17:42:14,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:15,086][root][INFO] - Training Epoch: 1/2, step 925/53949 completed (loss: 1.9254226684570312, acc: 0.39534884691238403)
[2025-02-17 17:42:15,232][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:15,453][root][INFO] - Training Epoch: 1/2, step 926/53949 completed (loss: 2.0032947063446045, acc: 0.3396226465702057)
[2025-02-17 17:42:15,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:15,820][root][INFO] - Training Epoch: 1/2, step 927/53949 completed (loss: 1.5234910249710083, acc: 0.6020408272743225)
[2025-02-17 17:42:15,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:16,159][root][INFO] - Training Epoch: 1/2, step 928/53949 completed (loss: 1.3744617700576782, acc: 0.6666666865348816)
[2025-02-17 17:42:16,381][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:16,578][root][INFO] - Training Epoch: 1/2, step 929/53949 completed (loss: 1.736356496810913, acc: 0.5446428656578064)
[2025-02-17 17:42:16,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:16,998][root][INFO] - Training Epoch: 1/2, step 930/53949 completed (loss: 2.0753207206726074, acc: 0.44999998807907104)
[2025-02-17 17:42:17,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:17,403][root][INFO] - Training Epoch: 1/2, step 931/53949 completed (loss: 1.9715604782104492, acc: 0.4159291982650757)
[2025-02-17 17:42:17,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:17,869][root][INFO] - Training Epoch: 1/2, step 932/53949 completed (loss: 1.7960553169250488, acc: 0.5271317958831787)
[2025-02-17 17:42:18,036][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:18,258][root][INFO] - Training Epoch: 1/2, step 933/53949 completed (loss: 1.787142276763916, acc: 0.5111111402511597)
[2025-02-17 17:42:18,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:18,716][root][INFO] - Training Epoch: 1/2, step 934/53949 completed (loss: 1.3960964679718018, acc: 0.6216216087341309)
[2025-02-17 17:42:18,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:19,116][root][INFO] - Training Epoch: 1/2, step 935/53949 completed (loss: 2.44564151763916, acc: 0.4000000059604645)
[2025-02-17 17:42:19,317][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:19,560][root][INFO] - Training Epoch: 1/2, step 936/53949 completed (loss: 2.262125015258789, acc: 0.38235294818878174)
[2025-02-17 17:42:19,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:19,993][root][INFO] - Training Epoch: 1/2, step 937/53949 completed (loss: 1.9095450639724731, acc: 0.5)
[2025-02-17 17:42:20,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:20,419][root][INFO] - Training Epoch: 1/2, step 938/53949 completed (loss: 2.167126178741455, acc: 0.3636363744735718)
[2025-02-17 17:42:20,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:20,807][root][INFO] - Training Epoch: 1/2, step 939/53949 completed (loss: 0.2603357136249542, acc: 0.8333333134651184)
[2025-02-17 17:42:20,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:21,212][root][INFO] - Training Epoch: 1/2, step 940/53949 completed (loss: 1.750190258026123, acc: 0.5189873576164246)
[2025-02-17 17:42:21,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:21,625][root][INFO] - Training Epoch: 1/2, step 941/53949 completed (loss: 1.95760178565979, acc: 0.4426877498626709)
[2025-02-17 17:42:21,799][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:22,016][root][INFO] - Training Epoch: 1/2, step 942/53949 completed (loss: 1.5745593309402466, acc: 0.6034482717514038)
[2025-02-17 17:42:22,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:22,434][root][INFO] - Training Epoch: 1/2, step 943/53949 completed (loss: 1.9654196500778198, acc: 0.44594594836235046)
[2025-02-17 17:42:22,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:22,840][root][INFO] - Training Epoch: 1/2, step 944/53949 completed (loss: 2.130136013031006, acc: 0.3333333432674408)
[2025-02-17 17:42:23,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:23,225][root][INFO] - Training Epoch: 1/2, step 945/53949 completed (loss: 2.0407817363739014, acc: 0.4166666567325592)
[2025-02-17 17:42:23,417][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:23,636][root][INFO] - Training Epoch: 1/2, step 946/53949 completed (loss: 1.7472072839736938, acc: 0.5263158082962036)
[2025-02-17 17:42:23,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:24,064][root][INFO] - Training Epoch: 1/2, step 947/53949 completed (loss: 1.8848934173583984, acc: 0.47727271914482117)
[2025-02-17 17:42:24,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:24,462][root][INFO] - Training Epoch: 1/2, step 948/53949 completed (loss: 1.7191734313964844, acc: 0.447761207818985)
[2025-02-17 17:42:24,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:24,878][root][INFO] - Training Epoch: 1/2, step 949/53949 completed (loss: 1.8020572662353516, acc: 0.4645669162273407)
[2025-02-17 17:42:25,061][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:25,285][root][INFO] - Training Epoch: 1/2, step 950/53949 completed (loss: 2.2824995517730713, acc: 0.37078651785850525)
[2025-02-17 17:42:25,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:25,693][root][INFO] - Training Epoch: 1/2, step 951/53949 completed (loss: 2.017155647277832, acc: 0.5555555820465088)
[2025-02-17 17:42:25,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:26,115][root][INFO] - Training Epoch: 1/2, step 952/53949 completed (loss: 1.9644043445587158, acc: 0.5)
[2025-02-17 17:42:26,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:26,495][root][INFO] - Training Epoch: 1/2, step 953/53949 completed (loss: 1.801781177520752, acc: 0.5193798542022705)
[2025-02-17 17:42:26,671][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:26,898][root][INFO] - Training Epoch: 1/2, step 954/53949 completed (loss: 1.6410353183746338, acc: 0.5384615659713745)
[2025-02-17 17:42:27,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:27,258][root][INFO] - Training Epoch: 1/2, step 955/53949 completed (loss: 1.4619495868682861, acc: 0.5540540814399719)
[2025-02-17 17:42:27,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:27,613][root][INFO] - Training Epoch: 1/2, step 956/53949 completed (loss: 1.7801860570907593, acc: 0.5)
[2025-02-17 17:42:27,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:28,016][root][INFO] - Training Epoch: 1/2, step 957/53949 completed (loss: 2.024963855743408, acc: 0.4285714328289032)
[2025-02-17 17:42:28,157][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:28,373][root][INFO] - Training Epoch: 1/2, step 958/53949 completed (loss: 1.0590360164642334, acc: 0.699999988079071)
[2025-02-17 17:42:28,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:28,718][root][INFO] - Training Epoch: 1/2, step 959/53949 completed (loss: 2.512160539627075, acc: 0.5)
[2025-02-17 17:42:28,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:29,167][root][INFO] - Training Epoch: 1/2, step 960/53949 completed (loss: 1.966576099395752, acc: 0.4292452931404114)
[2025-02-17 17:42:29,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:29,579][root][INFO] - Training Epoch: 1/2, step 961/53949 completed (loss: 1.9374233484268188, acc: 0.446153849363327)
[2025-02-17 17:42:29,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:29,980][root][INFO] - Training Epoch: 1/2, step 962/53949 completed (loss: 2.2348268032073975, acc: 0.3606557250022888)
[2025-02-17 17:42:30,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:30,339][root][INFO] - Training Epoch: 1/2, step 963/53949 completed (loss: 2.3108832836151123, acc: 0.42592594027519226)
[2025-02-17 17:42:30,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:30,696][root][INFO] - Training Epoch: 1/2, step 964/53949 completed (loss: 2.0179085731506348, acc: 0.4333333373069763)
[2025-02-17 17:42:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:31,148][root][INFO] - Training Epoch: 1/2, step 965/53949 completed (loss: 2.2113332748413086, acc: 0.3835616409778595)
[2025-02-17 17:42:31,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:31,516][root][INFO] - Training Epoch: 1/2, step 966/53949 completed (loss: 1.9867491722106934, acc: 0.43478259444236755)
[2025-02-17 17:42:31,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:31,918][root][INFO] - Training Epoch: 1/2, step 967/53949 completed (loss: 1.94825279712677, acc: 0.5227272510528564)
[2025-02-17 17:42:32,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:32,336][root][INFO] - Training Epoch: 1/2, step 968/53949 completed (loss: 2.1308228969573975, acc: 0.40336135029792786)
[2025-02-17 17:42:32,525][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:32,760][root][INFO] - Training Epoch: 1/2, step 969/53949 completed (loss: 1.783034324645996, acc: 0.514018714427948)
[2025-02-17 17:42:32,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:33,134][root][INFO] - Training Epoch: 1/2, step 970/53949 completed (loss: 1.8932286500930786, acc: 0.5081967115402222)
[2025-02-17 17:42:33,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:33,501][root][INFO] - Training Epoch: 1/2, step 971/53949 completed (loss: 2.1648306846618652, acc: 0.4237288236618042)
[2025-02-17 17:42:33,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:33,887][root][INFO] - Training Epoch: 1/2, step 972/53949 completed (loss: 1.9027926921844482, acc: 0.4672897160053253)
[2025-02-17 17:42:34,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:34,318][root][INFO] - Training Epoch: 1/2, step 973/53949 completed (loss: 2.2219202518463135, acc: 0.3544303774833679)
[2025-02-17 17:42:34,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:34,716][root][INFO] - Training Epoch: 1/2, step 974/53949 completed (loss: 2.147792339324951, acc: 0.42222222685813904)
[2025-02-17 17:42:34,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:35,108][root][INFO] - Training Epoch: 1/2, step 975/53949 completed (loss: 1.7750060558319092, acc: 0.45378151535987854)
[2025-02-17 17:42:35,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:35,474][root][INFO] - Training Epoch: 1/2, step 976/53949 completed (loss: 2.6770479679107666, acc: 0.3333333432674408)
[2025-02-17 17:42:35,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:35,951][root][INFO] - Training Epoch: 1/2, step 977/53949 completed (loss: 1.8038330078125, acc: 0.5188679099082947)
[2025-02-17 17:42:36,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:36,322][root][INFO] - Training Epoch: 1/2, step 978/53949 completed (loss: 1.2830042839050293, acc: 0.6363636255264282)
[2025-02-17 17:42:36,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:36,689][root][INFO] - Training Epoch: 1/2, step 979/53949 completed (loss: 1.9581644535064697, acc: 0.44999998807907104)
[2025-02-17 17:42:36,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:37,068][root][INFO] - Training Epoch: 1/2, step 980/53949 completed (loss: 1.4628552198410034, acc: 0.6000000238418579)
[2025-02-17 17:42:37,204][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:37,421][root][INFO] - Training Epoch: 1/2, step 981/53949 completed (loss: 2.0018081665039062, acc: 0.42424243688583374)
[2025-02-17 17:42:37,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:37,773][root][INFO] - Training Epoch: 1/2, step 982/53949 completed (loss: 1.797013759613037, acc: 0.5192307829856873)
[2025-02-17 17:42:37,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:38,158][root][INFO] - Training Epoch: 1/2, step 983/53949 completed (loss: 2.0275509357452393, acc: 0.44505494832992554)
[2025-02-17 17:42:38,295][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:38,511][root][INFO] - Training Epoch: 1/2, step 984/53949 completed (loss: 2.0831170082092285, acc: 0.3658536672592163)
[2025-02-17 17:42:38,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:38,859][root][INFO] - Training Epoch: 1/2, step 985/53949 completed (loss: 1.8260388374328613, acc: 0.44186046719551086)
[2025-02-17 17:42:38,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:39,206][root][INFO] - Training Epoch: 1/2, step 986/53949 completed (loss: 1.3359768390655518, acc: 0.6363636255264282)
[2025-02-17 17:42:39,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:39,556][root][INFO] - Training Epoch: 1/2, step 987/53949 completed (loss: 1.695798635482788, acc: 0.5348837375640869)
[2025-02-17 17:42:39,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:39,968][root][INFO] - Training Epoch: 1/2, step 988/53949 completed (loss: 1.9084341526031494, acc: 0.4128440320491791)
[2025-02-17 17:42:40,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:40,378][root][INFO] - Training Epoch: 1/2, step 989/53949 completed (loss: 1.8098219633102417, acc: 0.4647058844566345)
[2025-02-17 17:42:40,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:40,802][root][INFO] - Training Epoch: 1/2, step 990/53949 completed (loss: 2.0665714740753174, acc: 0.4285714328289032)
[2025-02-17 17:42:40,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:41,192][root][INFO] - Training Epoch: 1/2, step 991/53949 completed (loss: 2.2076282501220703, acc: 0.3921568691730499)
[2025-02-17 17:42:41,383][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:41,577][root][INFO] - Training Epoch: 1/2, step 992/53949 completed (loss: 1.9209811687469482, acc: 0.375)
[2025-02-17 17:42:41,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:41,957][root][INFO] - Training Epoch: 1/2, step 993/53949 completed (loss: 1.7866095304489136, acc: 0.5)
[2025-02-17 17:42:42,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:42,309][root][INFO] - Training Epoch: 1/2, step 994/53949 completed (loss: 1.8019585609436035, acc: 0.5098039507865906)
[2025-02-17 17:42:42,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:42,699][root][INFO] - Training Epoch: 1/2, step 995/53949 completed (loss: 1.8423608541488647, acc: 0.4680851101875305)
[2025-02-17 17:42:42,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:43,092][root][INFO] - Training Epoch: 1/2, step 996/53949 completed (loss: 2.0549373626708984, acc: 0.46341463923454285)
[2025-02-17 17:42:43,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:43,498][root][INFO] - Training Epoch: 1/2, step 997/53949 completed (loss: 1.950498342514038, acc: 0.4979591965675354)
[2025-02-17 17:42:43,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:43,858][root][INFO] - Training Epoch: 1/2, step 998/53949 completed (loss: 1.6122238636016846, acc: 0.53125)
[2025-02-17 17:42:43,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:44,212][root][INFO] - Training Epoch: 1/2, step 999/53949 completed (loss: 1.60023033618927, acc: 0.6666666865348816)
[2025-02-17 17:42:44,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:44,563][root][INFO] - Training Epoch: 1/2, step 1000/53949 completed (loss: 1.2952033281326294, acc: 0.6190476417541504)
[2025-02-17 17:42:44,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:44,913][root][INFO] - Training Epoch: 1/2, step 1001/53949 completed (loss: 2.051283597946167, acc: 0.44247788190841675)
[2025-02-17 17:42:45,061][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:45,310][root][INFO] - Training Epoch: 1/2, step 1002/53949 completed (loss: 1.9877164363861084, acc: 0.44247788190841675)
[2025-02-17 17:42:45,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:45,740][root][INFO] - Training Epoch: 1/2, step 1003/53949 completed (loss: 1.8423739671707153, acc: 0.4492753744125366)
[2025-02-17 17:42:45,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:46,090][root][INFO] - Training Epoch: 1/2, step 1004/53949 completed (loss: 0.13316626846790314, acc: 1.0)
[2025-02-17 17:42:46,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:46,473][root][INFO] - Training Epoch: 1/2, step 1005/53949 completed (loss: 1.7408112287521362, acc: 0.43478259444236755)
[2025-02-17 17:42:46,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:46,918][root][INFO] - Training Epoch: 1/2, step 1006/53949 completed (loss: 2.0744454860687256, acc: 0.3741496503353119)
[2025-02-17 17:42:47,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:47,326][root][INFO] - Training Epoch: 1/2, step 1007/53949 completed (loss: 1.6959744691848755, acc: 0.465753436088562)
[2025-02-17 17:42:47,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:47,706][root][INFO] - Training Epoch: 1/2, step 1008/53949 completed (loss: 0.4800157845020294, acc: 0.8333333134651184)
[2025-02-17 17:42:47,838][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:48,073][root][INFO] - Training Epoch: 1/2, step 1009/53949 completed (loss: 1.9685708284378052, acc: 0.4615384638309479)
[2025-02-17 17:42:48,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:48,427][root][INFO] - Training Epoch: 1/2, step 1010/53949 completed (loss: 0.8629021644592285, acc: 0.7777777910232544)
[2025-02-17 17:42:48,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:48,846][root][INFO] - Training Epoch: 1/2, step 1011/53949 completed (loss: 1.742392659187317, acc: 0.5202311873435974)
[2025-02-17 17:42:48,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:49,221][root][INFO] - Training Epoch: 1/2, step 1012/53949 completed (loss: 1.675046682357788, acc: 0.5384615659713745)
[2025-02-17 17:42:49,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:49,601][root][INFO] - Training Epoch: 1/2, step 1013/53949 completed (loss: 1.7378371953964233, acc: 0.529411792755127)
[2025-02-17 17:42:49,757][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:49,981][root][INFO] - Training Epoch: 1/2, step 1014/53949 completed (loss: 1.995234489440918, acc: 0.45205479860305786)
[2025-02-17 17:42:50,119][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:50,350][root][INFO] - Training Epoch: 1/2, step 1015/53949 completed (loss: 1.3433619737625122, acc: 0.6666666865348816)
[2025-02-17 17:42:50,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:50,712][root][INFO] - Training Epoch: 1/2, step 1016/53949 completed (loss: 1.5885611772537231, acc: 0.5882353186607361)
[2025-02-17 17:42:50,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:51,061][root][INFO] - Training Epoch: 1/2, step 1017/53949 completed (loss: 2.0087623596191406, acc: 0.4583333432674408)
[2025-02-17 17:42:51,223][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:51,437][root][INFO] - Training Epoch: 1/2, step 1018/53949 completed (loss: 1.5155854225158691, acc: 0.5909090638160706)
[2025-02-17 17:42:51,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:51,872][root][INFO] - Training Epoch: 1/2, step 1019/53949 completed (loss: 1.8796889781951904, acc: 0.5151515007019043)
[2025-02-17 17:42:52,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:52,250][root][INFO] - Training Epoch: 1/2, step 1020/53949 completed (loss: 2.022104263305664, acc: 0.4345238208770752)
[2025-02-17 17:42:52,378][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:52,593][root][INFO] - Training Epoch: 1/2, step 1021/53949 completed (loss: 1.9010307788848877, acc: 0.45783132314682007)
[2025-02-17 17:42:52,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:52,943][root][INFO] - Training Epoch: 1/2, step 1022/53949 completed (loss: 1.3538126945495605, acc: 0.5517241358757019)
[2025-02-17 17:42:53,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:53,302][root][INFO] - Training Epoch: 1/2, step 1023/53949 completed (loss: 1.6711796522140503, acc: 0.5483871102333069)
[2025-02-17 17:42:53,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:53,661][root][INFO] - Training Epoch: 1/2, step 1024/53949 completed (loss: 1.7145977020263672, acc: 0.5454545617103577)
[2025-02-17 17:42:53,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:54,016][root][INFO] - Training Epoch: 1/2, step 1025/53949 completed (loss: 1.9958010911941528, acc: 0.41818180680274963)
[2025-02-17 17:42:54,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:54,426][root][INFO] - Training Epoch: 1/2, step 1026/53949 completed (loss: 1.8038746118545532, acc: 0.4879518151283264)
[2025-02-17 17:42:54,578][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:54,792][root][INFO] - Training Epoch: 1/2, step 1027/53949 completed (loss: 1.860472321510315, acc: 0.45614033937454224)
[2025-02-17 17:42:54,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:55,179][root][INFO] - Training Epoch: 1/2, step 1028/53949 completed (loss: 2.015427350997925, acc: 0.44329896569252014)
[2025-02-17 17:42:55,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:55,561][root][INFO] - Training Epoch: 1/2, step 1029/53949 completed (loss: 1.919676423072815, acc: 0.4331210255622864)
[2025-02-17 17:42:55,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:55,981][root][INFO] - Training Epoch: 1/2, step 1030/53949 completed (loss: 1.7770485877990723, acc: 0.5411764979362488)
[2025-02-17 17:42:56,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:56,307][root][INFO] - Training Epoch: 1/2, step 1031/53949 completed (loss: 1.627955436706543, acc: 0.5249999761581421)
[2025-02-17 17:42:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:56,673][root][INFO] - Training Epoch: 1/2, step 1032/53949 completed (loss: 1.6337838172912598, acc: 0.5090909004211426)
[2025-02-17 17:42:56,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:57,028][root][INFO] - Training Epoch: 1/2, step 1033/53949 completed (loss: 1.9967808723449707, acc: 0.529411792755127)
[2025-02-17 17:42:57,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:57,390][root][INFO] - Training Epoch: 1/2, step 1034/53949 completed (loss: 1.7569571733474731, acc: 0.5593220591545105)
[2025-02-17 17:42:57,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:57,804][root][INFO] - Training Epoch: 1/2, step 1035/53949 completed (loss: 1.9501136541366577, acc: 0.44117647409439087)
[2025-02-17 17:42:57,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:58,206][root][INFO] - Training Epoch: 1/2, step 1036/53949 completed (loss: 2.0245203971862793, acc: 0.44871795177459717)
[2025-02-17 17:42:58,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:58,591][root][INFO] - Training Epoch: 1/2, step 1037/53949 completed (loss: 1.6435834169387817, acc: 0.5454545617103577)
[2025-02-17 17:42:58,733][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:58,951][root][INFO] - Training Epoch: 1/2, step 1038/53949 completed (loss: 1.6528345346450806, acc: 0.4912280738353729)
[2025-02-17 17:42:59,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:59,351][root][INFO] - Training Epoch: 1/2, step 1039/53949 completed (loss: 1.3846209049224854, acc: 0.5797101259231567)
[2025-02-17 17:42:59,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:59,704][root][INFO] - Training Epoch: 1/2, step 1040/53949 completed (loss: 1.5944063663482666, acc: 0.48275861144065857)
[2025-02-17 17:42:59,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:00,079][root][INFO] - Training Epoch: 1/2, step 1041/53949 completed (loss: 1.3112560510635376, acc: 0.7200000286102295)
[2025-02-17 17:43:00,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:00,425][root][INFO] - Training Epoch: 1/2, step 1042/53949 completed (loss: 0.033475421369075775, acc: 1.0)
[2025-02-17 17:43:00,569][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:00,782][root][INFO] - Training Epoch: 1/2, step 1043/53949 completed (loss: 1.6672552824020386, acc: 0.52173912525177)
[2025-02-17 17:43:00,916][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:01,128][root][INFO] - Training Epoch: 1/2, step 1044/53949 completed (loss: 1.3459300994873047, acc: 0.6666666865348816)
[2025-02-17 17:43:01,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:01,486][root][INFO] - Training Epoch: 1/2, step 1045/53949 completed (loss: 0.8231019377708435, acc: 0.9090909361839294)
[2025-02-17 17:43:01,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:01,876][root][INFO] - Training Epoch: 1/2, step 1046/53949 completed (loss: 1.5712883472442627, acc: 0.5476190447807312)
[2025-02-17 17:43:02,067][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:02,304][root][INFO] - Training Epoch: 1/2, step 1047/53949 completed (loss: 1.8707013130187988, acc: 0.3684210479259491)
[2025-02-17 17:43:02,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:02,691][root][INFO] - Training Epoch: 1/2, step 1048/53949 completed (loss: 1.8552682399749756, acc: 0.5714285969734192)
[2025-02-17 17:43:02,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:03,100][root][INFO] - Training Epoch: 1/2, step 1049/53949 completed (loss: 1.2442224025726318, acc: 0.6538461446762085)
[2025-02-17 17:43:03,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:03,457][root][INFO] - Training Epoch: 1/2, step 1050/53949 completed (loss: 0.14519351720809937, acc: 1.0)
[2025-02-17 17:43:03,608][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:03,818][root][INFO] - Training Epoch: 1/2, step 1051/53949 completed (loss: 1.6369282007217407, acc: 0.5977011322975159)
[2025-02-17 17:43:03,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:04,177][root][INFO] - Training Epoch: 1/2, step 1052/53949 completed (loss: 1.7935360670089722, acc: 0.42553192377090454)
[2025-02-17 17:43:04,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:04,551][root][INFO] - Training Epoch: 1/2, step 1053/53949 completed (loss: 1.626028299331665, acc: 0.54347825050354)
[2025-02-17 17:43:04,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:04,931][root][INFO] - Training Epoch: 1/2, step 1054/53949 completed (loss: 1.9354488849639893, acc: 0.4615384638309479)
[2025-02-17 17:43:05,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:05,273][root][INFO] - Training Epoch: 1/2, step 1055/53949 completed (loss: 0.9738758206367493, acc: 0.6666666865348816)
[2025-02-17 17:43:05,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:05,630][root][INFO] - Training Epoch: 1/2, step 1056/53949 completed (loss: 1.9925472736358643, acc: 0.4416666626930237)
[2025-02-17 17:43:05,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:06,014][root][INFO] - Training Epoch: 1/2, step 1057/53949 completed (loss: 1.9004019498825073, acc: 0.49438202381134033)
[2025-02-17 17:43:06,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:06,382][root][INFO] - Training Epoch: 1/2, step 1058/53949 completed (loss: 1.587952733039856, acc: 0.5670102834701538)
[2025-02-17 17:43:06,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:06,730][root][INFO] - Training Epoch: 1/2, step 1059/53949 completed (loss: 1.5537359714508057, acc: 0.5400000214576721)
[2025-02-17 17:43:06,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:07,077][root][INFO] - Training Epoch: 1/2, step 1060/53949 completed (loss: 1.5384902954101562, acc: 0.54347825050354)
[2025-02-17 17:43:07,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:07,449][root][INFO] - Training Epoch: 1/2, step 1061/53949 completed (loss: 1.6138842105865479, acc: 0.5964912176132202)
[2025-02-17 17:43:07,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:07,853][root][INFO] - Training Epoch: 1/2, step 1062/53949 completed (loss: 1.5588691234588623, acc: 0.4962962865829468)
[2025-02-17 17:43:07,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:08,198][root][INFO] - Training Epoch: 1/2, step 1063/53949 completed (loss: 1.1309415102005005, acc: 0.7586206793785095)
[2025-02-17 17:43:08,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:08,508][root][INFO] - Training Epoch: 1/2, step 1064/53949 completed (loss: 0.6526442766189575, acc: 0.8571428656578064)
[2025-02-17 17:43:08,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:08,881][root][INFO] - Training Epoch: 1/2, step 1065/53949 completed (loss: 1.8124744892120361, acc: 0.45652174949645996)
[2025-02-17 17:43:09,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:09,269][root][INFO] - Training Epoch: 1/2, step 1066/53949 completed (loss: 1.4505656957626343, acc: 0.6428571343421936)
[2025-02-17 17:43:09,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:09,673][root][INFO] - Training Epoch: 1/2, step 1067/53949 completed (loss: 1.4188724756240845, acc: 0.5945945978164673)
[2025-02-17 17:43:09,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:10,096][root][INFO] - Training Epoch: 1/2, step 1068/53949 completed (loss: 1.5286011695861816, acc: 0.5765765905380249)
[2025-02-17 17:43:10,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:10,454][root][INFO] - Training Epoch: 1/2, step 1069/53949 completed (loss: 1.613662600517273, acc: 0.6666666865348816)
[2025-02-17 17:43:10,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:10,762][root][INFO] - Training Epoch: 1/2, step 1070/53949 completed (loss: 1.5524502992630005, acc: 0.5862069129943848)
[2025-02-17 17:43:10,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:11,122][root][INFO] - Training Epoch: 1/2, step 1071/53949 completed (loss: 1.6544387340545654, acc: 0.5)
[2025-02-17 17:43:11,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:11,472][root][INFO] - Training Epoch: 1/2, step 1072/53949 completed (loss: 1.2232083082199097, acc: 0.6025640964508057)
[2025-02-17 17:43:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:11,852][root][INFO] - Training Epoch: 1/2, step 1073/53949 completed (loss: 1.4551364183425903, acc: 0.5757575631141663)
[2025-02-17 17:43:11,984][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:12,190][root][INFO] - Training Epoch: 1/2, step 1074/53949 completed (loss: 0.7653770446777344, acc: 0.7142857313156128)
[2025-02-17 17:43:12,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:12,587][root][INFO] - Training Epoch: 1/2, step 1075/53949 completed (loss: 1.4371095895767212, acc: 0.5736040472984314)
[2025-02-17 17:43:12,776][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:13,004][root][INFO] - Training Epoch: 1/2, step 1076/53949 completed (loss: 1.7141464948654175, acc: 0.5309734344482422)
[2025-02-17 17:43:13,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:13,404][root][INFO] - Training Epoch: 1/2, step 1077/53949 completed (loss: 1.3070061206817627, acc: 0.6538461446762085)
[2025-02-17 17:43:13,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:13,779][root][INFO] - Training Epoch: 1/2, step 1078/53949 completed (loss: 1.6665226221084595, acc: 0.5251798629760742)
[2025-02-17 17:43:13,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:14,151][root][INFO] - Training Epoch: 1/2, step 1079/53949 completed (loss: 1.3450602293014526, acc: 0.5913978219032288)
[2025-02-17 17:43:14,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:14,494][root][INFO] - Training Epoch: 1/2, step 1080/53949 completed (loss: 1.1312649250030518, acc: 0.6363636255264282)
[2025-02-17 17:43:14,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:14,857][root][INFO] - Training Epoch: 1/2, step 1081/53949 completed (loss: 1.307381510734558, acc: 0.6140350699424744)
[2025-02-17 17:43:15,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:15,217][root][INFO] - Training Epoch: 1/2, step 1082/53949 completed (loss: 0.9166306257247925, acc: 0.7068965435028076)
[2025-02-17 17:43:15,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:15,586][root][INFO] - Training Epoch: 1/2, step 1083/53949 completed (loss: 1.30043625831604, acc: 0.6268656849861145)
[2025-02-17 17:43:15,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:15,996][root][INFO] - Training Epoch: 1/2, step 1084/53949 completed (loss: 1.175106406211853, acc: 0.5869565010070801)
[2025-02-17 17:43:16,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:16,394][root][INFO] - Training Epoch: 1/2, step 1085/53949 completed (loss: 1.6751130819320679, acc: 0.5714285969734192)
[2025-02-17 17:43:16,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:16,795][root][INFO] - Training Epoch: 1/2, step 1086/53949 completed (loss: 1.5945810079574585, acc: 0.5384615659713745)
[2025-02-17 17:43:16,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:17,181][root][INFO] - Training Epoch: 1/2, step 1087/53949 completed (loss: 1.8042819499969482, acc: 0.5185185074806213)
[2025-02-17 17:43:17,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:17,605][root][INFO] - Training Epoch: 1/2, step 1088/53949 completed (loss: 1.5993537902832031, acc: 0.5054945349693298)
[2025-02-17 17:43:17,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:18,009][root][INFO] - Training Epoch: 1/2, step 1089/53949 completed (loss: 0.8088539838790894, acc: 0.6739130616188049)
[2025-02-17 17:43:18,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:18,360][root][INFO] - Training Epoch: 1/2, step 1090/53949 completed (loss: 1.3524329662322998, acc: 0.6195651888847351)
[2025-02-17 17:43:18,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:18,772][root][INFO] - Training Epoch: 1/2, step 1091/53949 completed (loss: 1.012176752090454, acc: 0.7058823704719543)
[2025-02-17 17:43:18,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:19,178][root][INFO] - Training Epoch: 1/2, step 1092/53949 completed (loss: 1.389675498008728, acc: 0.5757575631141663)
[2025-02-17 17:43:19,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:19,603][root][INFO] - Training Epoch: 1/2, step 1093/53949 completed (loss: 0.9947687983512878, acc: 0.684684693813324)
[2025-02-17 17:43:19,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:20,014][root][INFO] - Training Epoch: 1/2, step 1094/53949 completed (loss: 1.3290343284606934, acc: 0.5964912176132202)
[2025-02-17 17:43:20,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:20,367][root][INFO] - Training Epoch: 1/2, step 1095/53949 completed (loss: 1.433124303817749, acc: 0.5285714268684387)
[2025-02-17 17:43:20,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:20,728][root][INFO] - Training Epoch: 1/2, step 1096/53949 completed (loss: 0.9478644728660583, acc: 0.7407407164573669)
[2025-02-17 17:43:20,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:21,152][root][INFO] - Training Epoch: 1/2, step 1097/53949 completed (loss: 0.4267466962337494, acc: 0.8823529481887817)
[2025-02-17 17:43:21,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:21,563][root][INFO] - Training Epoch: 1/2, step 1098/53949 completed (loss: 0.695754885673523, acc: 0.7749999761581421)
[2025-02-17 17:43:21,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:21,930][root][INFO] - Training Epoch: 1/2, step 1099/53949 completed (loss: 0.9780469536781311, acc: 0.7346938848495483)
[2025-02-17 17:43:22,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:22,354][root][INFO] - Training Epoch: 1/2, step 1100/53949 completed (loss: 0.7559841871261597, acc: 0.7941176295280457)
[2025-02-17 17:43:22,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:22,753][root][INFO] - Training Epoch: 1/2, step 1101/53949 completed (loss: 1.3905121088027954, acc: 0.6484848260879517)
[2025-02-17 17:43:22,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:23,168][root][INFO] - Training Epoch: 1/2, step 1102/53949 completed (loss: 1.411641001701355, acc: 0.6774193644523621)
[2025-02-17 17:43:23,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:23,628][root][INFO] - Training Epoch: 1/2, step 1103/53949 completed (loss: 1.3144183158874512, acc: 0.6410256624221802)
[2025-02-17 17:43:23,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:24,022][root][INFO] - Training Epoch: 1/2, step 1104/53949 completed (loss: 1.0850977897644043, acc: 0.6833333373069763)
[2025-02-17 17:43:24,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:24,447][root][INFO] - Training Epoch: 1/2, step 1105/53949 completed (loss: 0.8408747315406799, acc: 0.7662337422370911)
[2025-02-17 17:43:24,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:24,866][root][INFO] - Training Epoch: 1/2, step 1106/53949 completed (loss: 0.6682726144790649, acc: 0.7674418687820435)
[2025-02-17 17:43:25,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:25,300][root][INFO] - Training Epoch: 1/2, step 1107/53949 completed (loss: 1.4319069385528564, acc: 0.5913978219032288)
[2025-02-17 17:43:25,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:25,773][root][INFO] - Training Epoch: 1/2, step 1108/53949 completed (loss: 0.6266305446624756, acc: 0.7777777910232544)
[2025-02-17 17:43:25,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:26,148][root][INFO] - Training Epoch: 1/2, step 1109/53949 completed (loss: 0.9408407807350159, acc: 0.7153846025466919)
[2025-02-17 17:43:26,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:26,501][root][INFO] - Training Epoch: 1/2, step 1110/53949 completed (loss: 1.1855388879776, acc: 0.5925925970077515)
[2025-02-17 17:43:26,634][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:26,843][root][INFO] - Training Epoch: 1/2, step 1111/53949 completed (loss: 0.6107164621353149, acc: 0.7894737124443054)
[2025-02-17 17:43:27,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:27,279][root][INFO] - Training Epoch: 1/2, step 1112/53949 completed (loss: 1.2617533206939697, acc: 0.5864661931991577)
[2025-02-17 17:43:27,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:27,740][root][INFO] - Training Epoch: 1/2, step 1113/53949 completed (loss: 0.8867053389549255, acc: 0.7747747898101807)
[2025-02-17 17:43:27,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:28,120][root][INFO] - Training Epoch: 1/2, step 1114/53949 completed (loss: 0.7483499646186829, acc: 0.8125)
[2025-02-17 17:43:28,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:28,514][root][INFO] - Training Epoch: 1/2, step 1115/53949 completed (loss: 1.4418182373046875, acc: 0.5)
[2025-02-17 17:43:28,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:28,924][root][INFO] - Training Epoch: 1/2, step 1116/53949 completed (loss: 0.7752890586853027, acc: 0.7734375)
[2025-02-17 17:43:29,135][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:29,357][root][INFO] - Training Epoch: 1/2, step 1117/53949 completed (loss: 1.4203194379806519, acc: 0.6352201104164124)
[2025-02-17 17:43:29,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:29,735][root][INFO] - Training Epoch: 1/2, step 1118/53949 completed (loss: 1.2173668146133423, acc: 0.6705882549285889)
[2025-02-17 17:43:29,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:30,101][root][INFO] - Training Epoch: 1/2, step 1119/53949 completed (loss: 1.1023783683776855, acc: 0.6855345964431763)
[2025-02-17 17:43:30,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:30,451][root][INFO] - Training Epoch: 1/2, step 1120/53949 completed (loss: 0.9660086035728455, acc: 0.7291666865348816)
[2025-02-17 17:43:30,619][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:30,833][root][INFO] - Training Epoch: 1/2, step 1121/53949 completed (loss: 0.6636286377906799, acc: 0.8196721076965332)
[2025-02-17 17:43:30,971][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:31,184][root][INFO] - Training Epoch: 1/2, step 1122/53949 completed (loss: 1.4010534286499023, acc: 0.6413792967796326)
[2025-02-17 17:43:31,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:31,544][root][INFO] - Training Epoch: 1/2, step 1123/53949 completed (loss: 0.8179289102554321, acc: 0.7476635575294495)
[2025-02-17 17:43:31,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:31,848][root][INFO] - Training Epoch: 1/2, step 1124/53949 completed (loss: 1.2528049945831299, acc: 0.5806451439857483)
[2025-02-17 17:43:31,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:32,200][root][INFO] - Training Epoch: 1/2, step 1125/53949 completed (loss: 1.5175189971923828, acc: 0.5980392098426819)
[2025-02-17 17:43:32,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:32,638][root][INFO] - Training Epoch: 1/2, step 1126/53949 completed (loss: 1.4207748174667358, acc: 0.6153846383094788)
[2025-02-17 17:43:32,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:33,015][root][INFO] - Training Epoch: 1/2, step 1127/53949 completed (loss: 1.0207469463348389, acc: 0.75)
[2025-02-17 17:43:33,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:33,376][root][INFO] - Training Epoch: 1/2, step 1128/53949 completed (loss: 0.7102097272872925, acc: 0.792682945728302)
[2025-02-17 17:43:33,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:33,740][root][INFO] - Training Epoch: 1/2, step 1129/53949 completed (loss: 2.1419780254364014, acc: 0.380952388048172)
[2025-02-17 17:43:33,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:34,130][root][INFO] - Training Epoch: 1/2, step 1130/53949 completed (loss: 1.6718591451644897, acc: 0.5283018946647644)
[2025-02-17 17:43:34,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:34,490][root][INFO] - Training Epoch: 1/2, step 1131/53949 completed (loss: 1.0640265941619873, acc: 0.760869562625885)
[2025-02-17 17:43:34,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:34,858][root][INFO] - Training Epoch: 1/2, step 1132/53949 completed (loss: 0.9077638387680054, acc: 0.7749999761581421)
[2025-02-17 17:43:35,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:35,275][root][INFO] - Training Epoch: 1/2, step 1133/53949 completed (loss: 1.033990740776062, acc: 0.6153846383094788)
[2025-02-17 17:43:35,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:35,689][root][INFO] - Training Epoch: 1/2, step 1134/53949 completed (loss: 0.7035850882530212, acc: 0.8023256063461304)
[2025-02-17 17:43:35,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:36,110][root][INFO] - Training Epoch: 1/2, step 1135/53949 completed (loss: 1.0680128335952759, acc: 0.680672287940979)
[2025-02-17 17:43:36,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:36,491][root][INFO] - Training Epoch: 1/2, step 1136/53949 completed (loss: 0.937313973903656, acc: 0.7472527623176575)
[2025-02-17 17:43:36,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:36,872][root][INFO] - Training Epoch: 1/2, step 1137/53949 completed (loss: 1.1852139234542847, acc: 0.7053571343421936)
[2025-02-17 17:43:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:37,321][root][INFO] - Training Epoch: 1/2, step 1138/53949 completed (loss: 0.6167322993278503, acc: 0.8571428656578064)
[2025-02-17 17:43:37,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:37,753][root][INFO] - Training Epoch: 1/2, step 1139/53949 completed (loss: 1.272953987121582, acc: 0.6176470518112183)
[2025-02-17 17:43:37,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:38,139][root][INFO] - Training Epoch: 1/2, step 1140/53949 completed (loss: 1.1972242593765259, acc: 0.663551390171051)
[2025-02-17 17:43:38,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:38,542][root][INFO] - Training Epoch: 1/2, step 1141/53949 completed (loss: 0.8300827145576477, acc: 0.7555555701255798)
[2025-02-17 17:43:38,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:38,920][root][INFO] - Training Epoch: 1/2, step 1142/53949 completed (loss: 1.0312336683273315, acc: 0.6666666865348816)
[2025-02-17 17:43:39,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:39,392][root][INFO] - Training Epoch: 1/2, step 1143/53949 completed (loss: 0.8980445861816406, acc: 0.7234042286872864)
[2025-02-17 17:43:39,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:39,772][root][INFO] - Training Epoch: 1/2, step 1144/53949 completed (loss: 0.729465663433075, acc: 0.8500000238418579)
[2025-02-17 17:43:39,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:40,143][root][INFO] - Training Epoch: 1/2, step 1145/53949 completed (loss: 0.9247490763664246, acc: 0.7407407164573669)
[2025-02-17 17:43:40,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:40,564][root][INFO] - Training Epoch: 1/2, step 1146/53949 completed (loss: 1.0098812580108643, acc: 0.7884615659713745)
[2025-02-17 17:43:40,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:40,937][root][INFO] - Training Epoch: 1/2, step 1147/53949 completed (loss: 1.5502711534500122, acc: 0.6153846383094788)
[2025-02-17 17:43:41,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:41,304][root][INFO] - Training Epoch: 1/2, step 1148/53949 completed (loss: 1.6811933517456055, acc: 0.604938268661499)
[2025-02-17 17:43:41,486][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:41,719][root][INFO] - Training Epoch: 1/2, step 1149/53949 completed (loss: 0.7077020406723022, acc: 0.8235294222831726)
[2025-02-17 17:43:41,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:42,125][root][INFO] - Training Epoch: 1/2, step 1150/53949 completed (loss: 0.8613083362579346, acc: 0.7596153616905212)
[2025-02-17 17:43:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:42,536][root][INFO] - Training Epoch: 1/2, step 1151/53949 completed (loss: 0.7185913324356079, acc: 0.8387096524238586)
[2025-02-17 17:43:42,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:42,927][root][INFO] - Training Epoch: 1/2, step 1152/53949 completed (loss: 1.2732175588607788, acc: 0.6585366129875183)
[2025-02-17 17:43:43,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:43,300][root][INFO] - Training Epoch: 1/2, step 1153/53949 completed (loss: 0.6353403925895691, acc: 0.8243243098258972)
[2025-02-17 17:43:43,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:43,719][root][INFO] - Training Epoch: 1/2, step 1154/53949 completed (loss: 0.9372526407241821, acc: 0.7663551568984985)
[2025-02-17 17:43:43,888][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:44,117][root][INFO] - Training Epoch: 1/2, step 1155/53949 completed (loss: 1.0912513732910156, acc: 0.6865671873092651)
[2025-02-17 17:43:44,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:44,515][root][INFO] - Training Epoch: 1/2, step 1156/53949 completed (loss: 0.7505562901496887, acc: 0.774193525314331)
[2025-02-17 17:43:44,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:44,921][root][INFO] - Training Epoch: 1/2, step 1157/53949 completed (loss: 0.2809438407421112, acc: 0.9166666865348816)
[2025-02-17 17:43:45,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:45,295][root][INFO] - Training Epoch: 1/2, step 1158/53949 completed (loss: 0.9281238317489624, acc: 0.737864077091217)
[2025-02-17 17:43:45,475][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:45,703][root][INFO] - Training Epoch: 1/2, step 1159/53949 completed (loss: 0.9322340488433838, acc: 0.7241379022598267)
[2025-02-17 17:43:45,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:46,105][root][INFO] - Training Epoch: 1/2, step 1160/53949 completed (loss: 0.03267061710357666, acc: 1.0)
[2025-02-17 17:43:46,244][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:46,457][root][INFO] - Training Epoch: 1/2, step 1161/53949 completed (loss: 1.1347788572311401, acc: 0.692307710647583)
[2025-02-17 17:43:46,637][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:46,865][root][INFO] - Training Epoch: 1/2, step 1162/53949 completed (loss: 0.7173672914505005, acc: 0.707317054271698)
[2025-02-17 17:43:47,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:47,332][root][INFO] - Training Epoch: 1/2, step 1163/53949 completed (loss: 1.2923864126205444, acc: 0.6187050342559814)
[2025-02-17 17:43:47,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:47,705][root][INFO] - Training Epoch: 1/2, step 1164/53949 completed (loss: 1.3344930410385132, acc: 0.699999988079071)
[2025-02-17 17:43:47,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:48,096][root][INFO] - Training Epoch: 1/2, step 1165/53949 completed (loss: 0.6184353232383728, acc: 0.75)
[2025-02-17 17:43:48,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:48,454][root][INFO] - Training Epoch: 1/2, step 1166/53949 completed (loss: 1.0321241617202759, acc: 0.7222222089767456)
[2025-02-17 17:43:48,637][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:48,887][root][INFO] - Training Epoch: 1/2, step 1167/53949 completed (loss: 0.8097608685493469, acc: 0.7730496525764465)
[2025-02-17 17:43:49,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:49,233][root][INFO] - Training Epoch: 1/2, step 1168/53949 completed (loss: 1.395174264907837, acc: 0.5789473652839661)
[2025-02-17 17:43:49,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:49,578][root][INFO] - Training Epoch: 1/2, step 1169/53949 completed (loss: 0.7622213363647461, acc: 0.8048780560493469)
[2025-02-17 17:43:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:49,944][root][INFO] - Training Epoch: 1/2, step 1170/53949 completed (loss: 0.7530108094215393, acc: 0.8415841460227966)
[2025-02-17 17:43:50,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:50,365][root][INFO] - Training Epoch: 1/2, step 1171/53949 completed (loss: 1.2193069458007812, acc: 0.6309523582458496)
[2025-02-17 17:43:50,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:50,826][root][INFO] - Training Epoch: 1/2, step 1172/53949 completed (loss: 1.6447739601135254, acc: 0.6231883764266968)
[2025-02-17 17:43:51,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:51,247][root][INFO] - Training Epoch: 1/2, step 1173/53949 completed (loss: 1.3701764345169067, acc: 0.6091954112052917)
[2025-02-17 17:43:51,385][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:51,603][root][INFO] - Training Epoch: 1/2, step 1174/53949 completed (loss: 1.5030889511108398, acc: 0.7083333134651184)
[2025-02-17 17:43:51,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:51,905][root][INFO] - Training Epoch: 1/2, step 1175/53949 completed (loss: 0.7738074660301208, acc: 0.7441860437393188)
[2025-02-17 17:43:52,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:52,286][root][INFO] - Training Epoch: 1/2, step 1176/53949 completed (loss: 0.8362497687339783, acc: 0.7345678806304932)
[2025-02-17 17:43:52,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:52,653][root][INFO] - Training Epoch: 1/2, step 1177/53949 completed (loss: 1.061147928237915, acc: 0.7142857313156128)
[2025-02-17 17:43:52,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:53,056][root][INFO] - Training Epoch: 1/2, step 1178/53949 completed (loss: 0.8049362897872925, acc: 0.800000011920929)
[2025-02-17 17:43:53,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:53,436][root][INFO] - Training Epoch: 1/2, step 1179/53949 completed (loss: 0.7005171775817871, acc: 0.7945205569267273)
[2025-02-17 17:43:53,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:53,819][root][INFO] - Training Epoch: 1/2, step 1180/53949 completed (loss: 0.8635281324386597, acc: 0.7068965435028076)
[2025-02-17 17:43:53,971][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:54,199][root][INFO] - Training Epoch: 1/2, step 1181/53949 completed (loss: 0.7915248870849609, acc: 0.737500011920929)
[2025-02-17 17:43:54,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:54,583][root][INFO] - Training Epoch: 1/2, step 1182/53949 completed (loss: 0.3773970603942871, acc: 0.8823529481887817)
[2025-02-17 17:43:54,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:54,981][root][INFO] - Training Epoch: 1/2, step 1183/53949 completed (loss: 0.35251665115356445, acc: 0.875)
[2025-02-17 17:43:55,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:55,397][root][INFO] - Training Epoch: 1/2, step 1184/53949 completed (loss: 0.8631141185760498, acc: 0.7532467246055603)
[2025-02-17 17:43:55,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:55,750][root][INFO] - Training Epoch: 1/2, step 1185/53949 completed (loss: 0.5558801889419556, acc: 0.75)
[2025-02-17 17:43:55,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:56,163][root][INFO] - Training Epoch: 1/2, step 1186/53949 completed (loss: 0.8943711519241333, acc: 0.7345132827758789)
[2025-02-17 17:43:56,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:56,590][root][INFO] - Training Epoch: 1/2, step 1187/53949 completed (loss: 1.2346669435501099, acc: 0.7241379022598267)
[2025-02-17 17:43:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:56,944][root][INFO] - Training Epoch: 1/2, step 1188/53949 completed (loss: 0.7788738012313843, acc: 0.778761088848114)
[2025-02-17 17:43:57,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:57,305][root][INFO] - Training Epoch: 1/2, step 1189/53949 completed (loss: 0.5784695148468018, acc: 0.8333333134651184)
[2025-02-17 17:43:57,495][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:57,731][root][INFO] - Training Epoch: 1/2, step 1190/53949 completed (loss: 1.0544977188110352, acc: 0.7096773982048035)
[2025-02-17 17:43:57,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:58,163][root][INFO] - Training Epoch: 1/2, step 1191/53949 completed (loss: 0.6381005644798279, acc: 0.8131868243217468)
[2025-02-17 17:43:58,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:58,533][root][INFO] - Training Epoch: 1/2, step 1192/53949 completed (loss: 1.0876758098602295, acc: 0.7441860437393188)
[2025-02-17 17:43:58,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:58,923][root][INFO] - Training Epoch: 1/2, step 1193/53949 completed (loss: 0.8293108940124512, acc: 0.7027027010917664)
[2025-02-17 17:43:59,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:59,300][root][INFO] - Training Epoch: 1/2, step 1194/53949 completed (loss: 0.7982410788536072, acc: 0.8269230723381042)
[2025-02-17 17:43:59,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:59,659][root][INFO] - Training Epoch: 1/2, step 1195/53949 completed (loss: 0.7391852736473083, acc: 0.8070175647735596)
[2025-02-17 17:43:59,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:00,068][root][INFO] - Training Epoch: 1/2, step 1196/53949 completed (loss: 0.9138981103897095, acc: 0.7384615540504456)
[2025-02-17 17:44:00,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:00,446][root][INFO] - Training Epoch: 1/2, step 1197/53949 completed (loss: 1.500511884689331, acc: 0.5742574334144592)
[2025-02-17 17:44:00,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:00,834][root][INFO] - Training Epoch: 1/2, step 1198/53949 completed (loss: 0.8690020442008972, acc: 0.7403846383094788)
[2025-02-17 17:44:00,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:01,180][root][INFO] - Training Epoch: 1/2, step 1199/53949 completed (loss: 0.978525698184967, acc: 0.800000011920929)
[2025-02-17 17:44:01,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:01,540][root][INFO] - Training Epoch: 1/2, step 1200/53949 completed (loss: 0.7831700444221497, acc: 0.7831325531005859)
[2025-02-17 17:44:01,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:01,930][root][INFO] - Training Epoch: 1/2, step 1201/53949 completed (loss: 0.5754256248474121, acc: 0.8034188151359558)
[2025-02-17 17:44:02,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:02,328][root][INFO] - Training Epoch: 1/2, step 1202/53949 completed (loss: 0.4696609079837799, acc: 0.8611111044883728)
[2025-02-17 17:44:02,482][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:02,704][root][INFO] - Training Epoch: 1/2, step 1203/53949 completed (loss: 0.808138370513916, acc: 0.7457627058029175)
[2025-02-17 17:44:02,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:03,118][root][INFO] - Training Epoch: 1/2, step 1204/53949 completed (loss: 0.8977835178375244, acc: 0.7050359845161438)
[2025-02-17 17:44:03,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:03,490][root][INFO] - Training Epoch: 1/2, step 1205/53949 completed (loss: 0.38231784105300903, acc: 0.8571428656578064)
[2025-02-17 17:44:03,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:03,879][root][INFO] - Training Epoch: 1/2, step 1206/53949 completed (loss: 0.717146635055542, acc: 0.7910447716712952)
[2025-02-17 17:44:04,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:04,275][root][INFO] - Training Epoch: 1/2, step 1207/53949 completed (loss: 1.4898520708084106, acc: 0.5384615659713745)
[2025-02-17 17:44:04,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:04,633][root][INFO] - Training Epoch: 1/2, step 1208/53949 completed (loss: 0.8458536267280579, acc: 0.7749999761581421)
[2025-02-17 17:44:04,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:05,015][root][INFO] - Training Epoch: 1/2, step 1209/53949 completed (loss: 0.9018065929412842, acc: 0.7272727489471436)
[2025-02-17 17:44:05,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:05,393][root][INFO] - Training Epoch: 1/2, step 1210/53949 completed (loss: 1.2778513431549072, acc: 0.6184210777282715)
[2025-02-17 17:44:05,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:05,762][root][INFO] - Training Epoch: 1/2, step 1211/53949 completed (loss: 0.2193477600812912, acc: 1.0)
[2025-02-17 17:44:05,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:06,163][root][INFO] - Training Epoch: 1/2, step 1212/53949 completed (loss: 0.730141282081604, acc: 0.7692307829856873)
[2025-02-17 17:44:06,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:06,543][root][INFO] - Training Epoch: 1/2, step 1213/53949 completed (loss: 0.40200158953666687, acc: 0.930232584476471)
[2025-02-17 17:44:06,675][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:06,881][root][INFO] - Training Epoch: 1/2, step 1214/53949 completed (loss: 0.4749302864074707, acc: 0.859375)
[2025-02-17 17:44:07,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:07,226][root][INFO] - Training Epoch: 1/2, step 1215/53949 completed (loss: 0.9894545078277588, acc: 0.699999988079071)
[2025-02-17 17:44:07,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:07,588][root][INFO] - Training Epoch: 1/2, step 1216/53949 completed (loss: 0.8985028862953186, acc: 0.7254902124404907)
[2025-02-17 17:44:07,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:07,947][root][INFO] - Training Epoch: 1/2, step 1217/53949 completed (loss: 0.9794935584068298, acc: 0.7605633735656738)
[2025-02-17 17:44:08,088][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:08,318][root][INFO] - Training Epoch: 1/2, step 1218/53949 completed (loss: 1.2189738750457764, acc: 0.6774193644523621)
[2025-02-17 17:44:08,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:08,706][root][INFO] - Training Epoch: 1/2, step 1219/53949 completed (loss: 1.2927292585372925, acc: 0.6557376980781555)
[2025-02-17 17:44:08,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:09,165][root][INFO] - Training Epoch: 1/2, step 1220/53949 completed (loss: 0.48324108123779297, acc: 0.8657718300819397)
[2025-02-17 17:44:09,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:09,592][root][INFO] - Training Epoch: 1/2, step 1221/53949 completed (loss: 0.590239405632019, acc: 0.8275862336158752)
[2025-02-17 17:44:09,732][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:09,951][root][INFO] - Training Epoch: 1/2, step 1222/53949 completed (loss: 0.6829050183296204, acc: 0.8226950168609619)
[2025-02-17 17:44:10,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:10,304][root][INFO] - Training Epoch: 1/2, step 1223/53949 completed (loss: 1.1192694902420044, acc: 0.6904761791229248)
[2025-02-17 17:44:10,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:10,654][root][INFO] - Training Epoch: 1/2, step 1224/53949 completed (loss: 0.70564866065979, acc: 0.7698412537574768)
[2025-02-17 17:44:10,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:10,996][root][INFO] - Training Epoch: 1/2, step 1225/53949 completed (loss: 1.9073001146316528, acc: 0.7142857313156128)
[2025-02-17 17:44:11,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:11,362][root][INFO] - Training Epoch: 1/2, step 1226/53949 completed (loss: 1.0367356538772583, acc: 0.7014925479888916)
[2025-02-17 17:44:11,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:11,714][root][INFO] - Training Epoch: 1/2, step 1227/53949 completed (loss: 0.5673556923866272, acc: 0.8936170339584351)
[2025-02-17 17:44:11,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:12,072][root][INFO] - Training Epoch: 1/2, step 1228/53949 completed (loss: 1.1348087787628174, acc: 0.6582278609275818)
[2025-02-17 17:44:12,210][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:12,451][root][INFO] - Training Epoch: 1/2, step 1229/53949 completed (loss: 1.0674442052841187, acc: 0.7157894968986511)
[2025-02-17 17:44:12,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:12,798][root][INFO] - Training Epoch: 1/2, step 1230/53949 completed (loss: 1.0991946458816528, acc: 0.6458333134651184)
[2025-02-17 17:44:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:13,199][root][INFO] - Training Epoch: 1/2, step 1231/53949 completed (loss: 1.179513931274414, acc: 0.6893203854560852)
[2025-02-17 17:44:13,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:13,560][root][INFO] - Training Epoch: 1/2, step 1232/53949 completed (loss: 0.8073665499687195, acc: 0.9375)
[2025-02-17 17:44:13,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:13,932][root][INFO] - Training Epoch: 1/2, step 1233/53949 completed (loss: 0.1349143236875534, acc: 1.0)
[2025-02-17 17:44:14,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:14,312][root][INFO] - Training Epoch: 1/2, step 1234/53949 completed (loss: 0.6993069052696228, acc: 0.8214285969734192)
[2025-02-17 17:44:14,456][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:14,667][root][INFO] - Training Epoch: 1/2, step 1235/53949 completed (loss: 0.4320698082447052, acc: 0.8813559412956238)
[2025-02-17 17:44:14,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:15,012][root][INFO] - Training Epoch: 1/2, step 1236/53949 completed (loss: 0.8705255389213562, acc: 0.782608687877655)
[2025-02-17 17:44:15,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:15,355][root][INFO] - Training Epoch: 1/2, step 1237/53949 completed (loss: 1.010346531867981, acc: 0.800000011920929)
[2025-02-17 17:44:15,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:15,709][root][INFO] - Training Epoch: 1/2, step 1238/53949 completed (loss: 0.6898679137229919, acc: 0.7916666865348816)
[2025-02-17 17:44:15,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:16,108][root][INFO] - Training Epoch: 1/2, step 1239/53949 completed (loss: 0.3548225164413452, acc: 0.9354838728904724)
[2025-02-17 17:44:16,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:16,523][root][INFO] - Training Epoch: 1/2, step 1240/53949 completed (loss: 0.6837651133537292, acc: 0.8387096524238586)
[2025-02-17 17:44:16,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:16,936][root][INFO] - Training Epoch: 1/2, step 1241/53949 completed (loss: 0.7510353326797485, acc: 0.7606837749481201)
[2025-02-17 17:44:17,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:17,316][root][INFO] - Training Epoch: 1/2, step 1242/53949 completed (loss: 0.8625012636184692, acc: 0.7647058963775635)
[2025-02-17 17:44:17,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:17,700][root][INFO] - Training Epoch: 1/2, step 1243/53949 completed (loss: 0.9610937237739563, acc: 0.7674418687820435)
[2025-02-17 17:44:17,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:18,083][root][INFO] - Training Epoch: 1/2, step 1244/53949 completed (loss: 0.9747790098190308, acc: 0.7111111283302307)
[2025-02-17 17:44:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:18,434][root][INFO] - Training Epoch: 1/2, step 1245/53949 completed (loss: 0.538151204586029, acc: 0.8771929740905762)
[2025-02-17 17:44:18,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:18,822][root][INFO] - Training Epoch: 1/2, step 1246/53949 completed (loss: 0.5541670322418213, acc: 0.8395061492919922)
[2025-02-17 17:44:18,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:19,196][root][INFO] - Training Epoch: 1/2, step 1247/53949 completed (loss: 0.700494110584259, acc: 0.804347813129425)
[2025-02-17 17:44:19,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:19,564][root][INFO] - Training Epoch: 1/2, step 1248/53949 completed (loss: 0.7255547642707825, acc: 0.7341772317886353)
[2025-02-17 17:44:19,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:19,909][root][INFO] - Training Epoch: 1/2, step 1249/53949 completed (loss: 0.833767294883728, acc: 0.7555555701255798)
[2025-02-17 17:44:20,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:20,252][root][INFO] - Training Epoch: 1/2, step 1250/53949 completed (loss: 1.0288058519363403, acc: 0.6483516693115234)
[2025-02-17 17:44:20,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:20,611][root][INFO] - Training Epoch: 1/2, step 1251/53949 completed (loss: 0.6779438853263855, acc: 0.78125)
[2025-02-17 17:44:20,757][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:20,974][root][INFO] - Training Epoch: 1/2, step 1252/53949 completed (loss: 0.9797093868255615, acc: 0.7341772317886353)
[2025-02-17 17:44:21,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:21,328][root][INFO] - Training Epoch: 1/2, step 1253/53949 completed (loss: 0.6641569137573242, acc: 0.7692307829856873)
[2025-02-17 17:44:21,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:21,722][root][INFO] - Training Epoch: 1/2, step 1254/53949 completed (loss: 0.475068598985672, acc: 0.8181818127632141)
[2025-02-17 17:44:21,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:22,120][root][INFO] - Training Epoch: 1/2, step 1255/53949 completed (loss: 0.5018573999404907, acc: 0.9130434989929199)
[2025-02-17 17:44:22,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:22,492][root][INFO] - Training Epoch: 1/2, step 1256/53949 completed (loss: 0.38011908531188965, acc: 0.8823529481887817)
[2025-02-17 17:44:22,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:22,898][root][INFO] - Training Epoch: 1/2, step 1257/53949 completed (loss: 1.0367236137390137, acc: 0.5833333134651184)
[2025-02-17 17:44:23,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:23,260][root][INFO] - Training Epoch: 1/2, step 1258/53949 completed (loss: 0.6440285444259644, acc: 0.8571428656578064)
[2025-02-17 17:44:23,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:23,709][root][INFO] - Training Epoch: 1/2, step 1259/53949 completed (loss: 0.5827099084854126, acc: 0.8965517282485962)
[2025-02-17 17:44:23,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:24,128][root][INFO] - Training Epoch: 1/2, step 1260/53949 completed (loss: 1.1512020826339722, acc: 0.6666666865348816)
[2025-02-17 17:44:24,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:24,508][root][INFO] - Training Epoch: 1/2, step 1261/53949 completed (loss: 0.4256775677204132, acc: 0.8787878751754761)
[2025-02-17 17:44:24,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:24,868][root][INFO] - Training Epoch: 1/2, step 1262/53949 completed (loss: 0.8448450565338135, acc: 0.75)
[2025-02-17 17:44:25,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:25,253][root][INFO] - Training Epoch: 1/2, step 1263/53949 completed (loss: 0.7428064942359924, acc: 0.8536585569381714)
[2025-02-17 17:44:25,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:25,605][root][INFO] - Training Epoch: 1/2, step 1264/53949 completed (loss: 0.33887702226638794, acc: 0.8888888955116272)
[2025-02-17 17:44:25,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:26,044][root][INFO] - Training Epoch: 1/2, step 1265/53949 completed (loss: 0.852842390537262, acc: 0.7884615659713745)
[2025-02-17 17:44:26,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:26,560][root][INFO] - Training Epoch: 1/2, step 1266/53949 completed (loss: 1.020607590675354, acc: 0.7022222280502319)
[2025-02-17 17:44:26,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:27,021][root][INFO] - Training Epoch: 1/2, step 1267/53949 completed (loss: 0.8778228163719177, acc: 0.7716535329818726)
[2025-02-17 17:44:27,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:27,396][root][INFO] - Training Epoch: 1/2, step 1268/53949 completed (loss: 0.6204034686088562, acc: 0.8235294222831726)
[2025-02-17 17:44:27,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:27,756][root][INFO] - Training Epoch: 1/2, step 1269/53949 completed (loss: 0.8017361164093018, acc: 0.8181818127632141)
[2025-02-17 17:44:27,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:28,140][root][INFO] - Training Epoch: 1/2, step 1270/53949 completed (loss: 0.8379911184310913, acc: 0.7551020383834839)
[2025-02-17 17:44:28,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:28,550][root][INFO] - Training Epoch: 1/2, step 1271/53949 completed (loss: 1.019038200378418, acc: 0.6883116960525513)
[2025-02-17 17:44:28,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:28,921][root][INFO] - Training Epoch: 1/2, step 1272/53949 completed (loss: 0.5538356900215149, acc: 0.8541666865348816)
[2025-02-17 17:44:29,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:29,327][root][INFO] - Training Epoch: 1/2, step 1273/53949 completed (loss: 0.514737069606781, acc: 0.8214285969734192)
[2025-02-17 17:44:29,468][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:29,689][root][INFO] - Training Epoch: 1/2, step 1274/53949 completed (loss: 0.37858647108078003, acc: 0.9117646813392639)
[2025-02-17 17:44:29,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:30,056][root][INFO] - Training Epoch: 1/2, step 1275/53949 completed (loss: 1.9984740018844604, acc: 0.1875)
[2025-02-17 17:44:30,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:30,449][root][INFO] - Training Epoch: 1/2, step 1276/53949 completed (loss: 1.0107595920562744, acc: 0.7235293984413147)
[2025-02-17 17:44:30,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:30,820][root][INFO] - Training Epoch: 1/2, step 1277/53949 completed (loss: 1.0875033140182495, acc: 0.6774193644523621)
[2025-02-17 17:44:30,959][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:31,171][root][INFO] - Training Epoch: 1/2, step 1278/53949 completed (loss: 0.5501729249954224, acc: 0.8999999761581421)
[2025-02-17 17:44:31,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:31,625][root][INFO] - Training Epoch: 1/2, step 1279/53949 completed (loss: 0.7492489218711853, acc: 0.7722222208976746)
[2025-02-17 17:44:31,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:31,989][root][INFO] - Training Epoch: 1/2, step 1280/53949 completed (loss: 0.27662280201911926, acc: 1.0)
[2025-02-17 17:44:32,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:32,369][root][INFO] - Training Epoch: 1/2, step 1281/53949 completed (loss: 0.8457503914833069, acc: 0.7804877758026123)
[2025-02-17 17:44:32,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:32,771][root][INFO] - Training Epoch: 1/2, step 1282/53949 completed (loss: 0.8549986481666565, acc: 0.7654321193695068)
[2025-02-17 17:44:32,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:33,150][root][INFO] - Training Epoch: 1/2, step 1283/53949 completed (loss: 0.8583860993385315, acc: 0.7777777910232544)
[2025-02-17 17:44:33,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:33,521][root][INFO] - Training Epoch: 1/2, step 1284/53949 completed (loss: 0.6765506267547607, acc: 0.8429751992225647)
[2025-02-17 17:44:33,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:33,921][root][INFO] - Training Epoch: 1/2, step 1285/53949 completed (loss: 0.6431462168693542, acc: 0.8191489577293396)
[2025-02-17 17:44:34,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:34,269][root][INFO] - Training Epoch: 1/2, step 1286/53949 completed (loss: 0.8690314292907715, acc: 0.7640449404716492)
[2025-02-17 17:44:34,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:34,680][root][INFO] - Training Epoch: 1/2, step 1287/53949 completed (loss: 0.6070078015327454, acc: 0.8863636255264282)
[2025-02-17 17:44:34,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:35,021][root][INFO] - Training Epoch: 1/2, step 1288/53949 completed (loss: 1.0730501413345337, acc: 0.75)
[2025-02-17 17:44:35,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:35,410][root][INFO] - Training Epoch: 1/2, step 1289/53949 completed (loss: 0.6319630146026611, acc: 0.800000011920929)
[2025-02-17 17:44:35,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:35,797][root][INFO] - Training Epoch: 1/2, step 1290/53949 completed (loss: 0.5523051619529724, acc: 0.8301886916160583)
[2025-02-17 17:44:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:36,217][root][INFO] - Training Epoch: 1/2, step 1291/53949 completed (loss: 0.4949326515197754, acc: 0.8623188138008118)
[2025-02-17 17:44:36,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:36,623][root][INFO] - Training Epoch: 1/2, step 1292/53949 completed (loss: 1.0111339092254639, acc: 0.7355371713638306)
[2025-02-17 17:44:36,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:36,972][root][INFO] - Training Epoch: 1/2, step 1293/53949 completed (loss: 0.6508002877235413, acc: 0.800000011920929)
[2025-02-17 17:44:37,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:37,331][root][INFO] - Training Epoch: 1/2, step 1294/53949 completed (loss: 0.8965480327606201, acc: 0.7019230723381042)
[2025-02-17 17:44:37,534][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:37,750][root][INFO] - Training Epoch: 1/2, step 1295/53949 completed (loss: 0.5977799296379089, acc: 0.8333333134651184)
[2025-02-17 17:44:37,896][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:38,113][root][INFO] - Training Epoch: 1/2, step 1296/53949 completed (loss: 0.8752738237380981, acc: 0.7659574747085571)
[2025-02-17 17:44:38,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:38,490][root][INFO] - Training Epoch: 1/2, step 1297/53949 completed (loss: 0.46327224373817444, acc: 0.8818181753158569)
[2025-02-17 17:44:38,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:38,833][root][INFO] - Training Epoch: 1/2, step 1298/53949 completed (loss: 0.7022625803947449, acc: 0.8333333134651184)
[2025-02-17 17:44:38,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:39,212][root][INFO] - Training Epoch: 1/2, step 1299/53949 completed (loss: 0.42649078369140625, acc: 0.8648648858070374)
[2025-02-17 17:44:39,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:39,572][root][INFO] - Training Epoch: 1/2, step 1300/53949 completed (loss: 0.38913586735725403, acc: 0.9130434989929199)
[2025-02-17 17:44:39,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:39,933][root][INFO] - Training Epoch: 1/2, step 1301/53949 completed (loss: 0.8536044359207153, acc: 0.7931034564971924)
[2025-02-17 17:44:40,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:40,336][root][INFO] - Training Epoch: 1/2, step 1302/53949 completed (loss: 1.1358811855316162, acc: 0.6764705777168274)
[2025-02-17 17:44:40,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:40,690][root][INFO] - Training Epoch: 1/2, step 1303/53949 completed (loss: 1.326298713684082, acc: 0.6190476417541504)
[2025-02-17 17:44:40,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:41,063][root][INFO] - Training Epoch: 1/2, step 1304/53949 completed (loss: 0.6209808588027954, acc: 0.800000011920929)
[2025-02-17 17:44:41,242][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:41,457][root][INFO] - Training Epoch: 1/2, step 1305/53949 completed (loss: 0.3304925858974457, acc: 0.8938053250312805)
[2025-02-17 17:44:41,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:41,838][root][INFO] - Training Epoch: 1/2, step 1306/53949 completed (loss: 1.0134247541427612, acc: 0.7222222089767456)
[2025-02-17 17:44:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:42,204][root][INFO] - Training Epoch: 1/2, step 1307/53949 completed (loss: 0.7028226256370544, acc: 0.8333333134651184)
[2025-02-17 17:44:42,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:42,561][root][INFO] - Training Epoch: 1/2, step 1308/53949 completed (loss: 0.5163857936859131, acc: 0.8115941882133484)
[2025-02-17 17:44:42,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:42,910][root][INFO] - Training Epoch: 1/2, step 1309/53949 completed (loss: 0.30913180112838745, acc: 0.8636363744735718)
[2025-02-17 17:44:43,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:43,263][root][INFO] - Training Epoch: 1/2, step 1310/53949 completed (loss: 0.04973984509706497, acc: 1.0)
[2025-02-17 17:44:43,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:43,582][root][INFO] - Training Epoch: 1/2, step 1311/53949 completed (loss: 0.27200645208358765, acc: 0.9444444179534912)
[2025-02-17 17:44:43,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:43,943][root][INFO] - Training Epoch: 1/2, step 1312/53949 completed (loss: 1.0789505243301392, acc: 0.7857142686843872)
[2025-02-17 17:44:44,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:44,329][root][INFO] - Training Epoch: 1/2, step 1313/53949 completed (loss: 0.6766279935836792, acc: 0.8051947951316833)
[2025-02-17 17:44:44,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:44,717][root][INFO] - Training Epoch: 1/2, step 1314/53949 completed (loss: 0.26747041940689087, acc: 0.9107142686843872)
[2025-02-17 17:44:44,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:45,142][root][INFO] - Training Epoch: 1/2, step 1315/53949 completed (loss: 0.724662721157074, acc: 0.7837837934494019)
[2025-02-17 17:44:45,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:45,513][root][INFO] - Training Epoch: 1/2, step 1316/53949 completed (loss: 0.5078372955322266, acc: 0.8730158805847168)
[2025-02-17 17:44:45,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:45,878][root][INFO] - Training Epoch: 1/2, step 1317/53949 completed (loss: 0.15793876349925995, acc: 1.0)
[2025-02-17 17:44:46,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:46,241][root][INFO] - Training Epoch: 1/2, step 1318/53949 completed (loss: 0.4950316250324249, acc: 0.8194444179534912)
[2025-02-17 17:44:46,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:46,587][root][INFO] - Training Epoch: 1/2, step 1319/53949 completed (loss: 0.810100257396698, acc: 0.7657657861709595)
[2025-02-17 17:44:46,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:46,927][root][INFO] - Training Epoch: 1/2, step 1320/53949 completed (loss: 1.4564650058746338, acc: 0.6153846383094788)
[2025-02-17 17:44:47,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:47,271][root][INFO] - Training Epoch: 1/2, step 1321/53949 completed (loss: 0.6727848052978516, acc: 0.837837815284729)
[2025-02-17 17:44:47,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:47,623][root][INFO] - Training Epoch: 1/2, step 1322/53949 completed (loss: 0.21458688378334045, acc: 0.9230769276618958)
[2025-02-17 17:44:47,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:47,980][root][INFO] - Training Epoch: 1/2, step 1323/53949 completed (loss: 0.30996936559677124, acc: 0.9230769276618958)
[2025-02-17 17:44:48,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:48,389][root][INFO] - Training Epoch: 1/2, step 1324/53949 completed (loss: 1.2030925750732422, acc: 0.692307710647583)
[2025-02-17 17:44:48,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:48,758][root][INFO] - Training Epoch: 1/2, step 1325/53949 completed (loss: 1.172297716140747, acc: 0.692307710647583)
[2025-02-17 17:44:48,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:49,144][root][INFO] - Training Epoch: 1/2, step 1326/53949 completed (loss: 0.7080590128898621, acc: 0.75)
[2025-02-17 17:44:49,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:49,500][root][INFO] - Training Epoch: 1/2, step 1327/53949 completed (loss: 1.2368520498275757, acc: 0.6428571343421936)
[2025-02-17 17:44:49,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:49,852][root][INFO] - Training Epoch: 1/2, step 1328/53949 completed (loss: 0.8328818082809448, acc: 0.8181818127632141)
[2025-02-17 17:44:49,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:50,205][root][INFO] - Training Epoch: 1/2, step 1329/53949 completed (loss: 1.1582517623901367, acc: 0.6851851940155029)
[2025-02-17 17:44:50,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:50,556][root][INFO] - Training Epoch: 1/2, step 1330/53949 completed (loss: 0.9096972346305847, acc: 0.6666666865348816)
[2025-02-17 17:44:50,734][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:50,962][root][INFO] - Training Epoch: 1/2, step 1331/53949 completed (loss: 0.04587756097316742, acc: 1.0)
[2025-02-17 17:44:51,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:51,364][root][INFO] - Training Epoch: 1/2, step 1332/53949 completed (loss: 0.35257983207702637, acc: 1.0)
[2025-02-17 17:44:51,509][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:51,719][root][INFO] - Training Epoch: 1/2, step 1333/53949 completed (loss: 0.7181856632232666, acc: 0.7457627058029175)
[2025-02-17 17:44:51,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:52,093][root][INFO] - Training Epoch: 1/2, step 1334/53949 completed (loss: 0.8643607497215271, acc: 0.8115941882133484)
[2025-02-17 17:44:52,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:52,445][root][INFO] - Training Epoch: 1/2, step 1335/53949 completed (loss: 0.7745519280433655, acc: 0.7857142686843872)
[2025-02-17 17:44:52,594][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:52,871][root][INFO] - Training Epoch: 1/2, step 1336/53949 completed (loss: 0.7781162858009338, acc: 0.761904776096344)
[2025-02-17 17:44:53,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:53,274][root][INFO] - Training Epoch: 1/2, step 1337/53949 completed (loss: 1.8597756624221802, acc: 0.5357142686843872)
[2025-02-17 17:44:53,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:53,638][root][INFO] - Training Epoch: 1/2, step 1338/53949 completed (loss: 0.8063561916351318, acc: 0.760869562625885)
[2025-02-17 17:44:53,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:54,015][root][INFO] - Training Epoch: 1/2, step 1339/53949 completed (loss: 1.0498673915863037, acc: 0.753731369972229)
[2025-02-17 17:44:54,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:54,437][root][INFO] - Training Epoch: 1/2, step 1340/53949 completed (loss: 1.0659494400024414, acc: 0.7594936490058899)
[2025-02-17 17:44:54,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:54,815][root][INFO] - Training Epoch: 1/2, step 1341/53949 completed (loss: 0.5200143456459045, acc: 0.8333333134651184)
[2025-02-17 17:44:54,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:55,177][root][INFO] - Training Epoch: 1/2, step 1342/53949 completed (loss: 0.34919631481170654, acc: 0.8999999761581421)
[2025-02-17 17:44:55,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:55,520][root][INFO] - Training Epoch: 1/2, step 1343/53949 completed (loss: 1.5039968490600586, acc: 0.6037735939025879)
[2025-02-17 17:44:55,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:55,948][root][INFO] - Training Epoch: 1/2, step 1344/53949 completed (loss: 1.3184814453125, acc: 0.6571428775787354)
[2025-02-17 17:44:56,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:56,318][root][INFO] - Training Epoch: 1/2, step 1345/53949 completed (loss: 0.7965629696846008, acc: 0.7037037014961243)
[2025-02-17 17:44:56,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:56,734][root][INFO] - Training Epoch: 1/2, step 1346/53949 completed (loss: 1.8593919277191162, acc: 0.4761904776096344)
[2025-02-17 17:44:56,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:57,073][root][INFO] - Training Epoch: 1/2, step 1347/53949 completed (loss: 1.2700825929641724, acc: 0.6904761791229248)
[2025-02-17 17:44:57,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:57,429][root][INFO] - Training Epoch: 1/2, step 1348/53949 completed (loss: 1.0368530750274658, acc: 0.7386363744735718)
[2025-02-17 17:44:57,615][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:57,857][root][INFO] - Training Epoch: 1/2, step 1349/53949 completed (loss: 0.9670676589012146, acc: 0.7407407164573669)
[2025-02-17 17:44:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:58,274][root][INFO] - Training Epoch: 1/2, step 1350/53949 completed (loss: 0.33076635003089905, acc: 0.8333333134651184)
[2025-02-17 17:44:58,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:58,627][root][INFO] - Training Epoch: 1/2, step 1351/53949 completed (loss: 0.5827124118804932, acc: 0.8333333134651184)
[2025-02-17 17:44:58,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:59,009][root][INFO] - Training Epoch: 1/2, step 1352/53949 completed (loss: 0.6305102109909058, acc: 0.8904109597206116)
[2025-02-17 17:44:59,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:59,362][root][INFO] - Training Epoch: 1/2, step 1353/53949 completed (loss: 0.7252563834190369, acc: 0.7777777910232544)
[2025-02-17 17:44:59,499][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:59,717][root][INFO] - Training Epoch: 1/2, step 1354/53949 completed (loss: 1.0308486223220825, acc: 0.6805555820465088)
[2025-02-17 17:44:59,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:00,098][root][INFO] - Training Epoch: 1/2, step 1355/53949 completed (loss: 0.9729370474815369, acc: 0.7472527623176575)
[2025-02-17 17:45:00,240][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:00,454][root][INFO] - Training Epoch: 1/2, step 1356/53949 completed (loss: 0.8928059935569763, acc: 0.7977527976036072)
[2025-02-17 17:45:00,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:00,803][root][INFO] - Training Epoch: 1/2, step 1357/53949 completed (loss: 0.8728814721107483, acc: 0.7916666865348816)
[2025-02-17 17:45:00,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:01,146][root][INFO] - Training Epoch: 1/2, step 1358/53949 completed (loss: 0.8551774621009827, acc: 0.7769230604171753)
[2025-02-17 17:45:01,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:01,495][root][INFO] - Training Epoch: 1/2, step 1359/53949 completed (loss: 0.8169146776199341, acc: 0.7765957713127136)
[2025-02-17 17:45:01,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:01,835][root][INFO] - Training Epoch: 1/2, step 1360/53949 completed (loss: 0.6824960112571716, acc: 0.7599999904632568)
[2025-02-17 17:45:02,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:02,242][root][INFO] - Training Epoch: 1/2, step 1361/53949 completed (loss: 0.503718376159668, acc: 0.828125)
[2025-02-17 17:45:02,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:02,639][root][INFO] - Training Epoch: 1/2, step 1362/53949 completed (loss: 0.16488906741142273, acc: 0.9750000238418579)
[2025-02-17 17:45:02,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:02,998][root][INFO] - Training Epoch: 1/2, step 1363/53949 completed (loss: 0.5394608974456787, acc: 0.8666666746139526)
[2025-02-17 17:45:03,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:03,369][root][INFO] - Training Epoch: 1/2, step 1364/53949 completed (loss: 0.985985517501831, acc: 0.7432432174682617)
[2025-02-17 17:45:03,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:03,794][root][INFO] - Training Epoch: 1/2, step 1365/53949 completed (loss: 0.8220174908638, acc: 0.800000011920929)
[2025-02-17 17:45:03,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:04,207][root][INFO] - Training Epoch: 1/2, step 1366/53949 completed (loss: 0.8967610001564026, acc: 0.7321428656578064)
[2025-02-17 17:45:04,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:04,605][root][INFO] - Training Epoch: 1/2, step 1367/53949 completed (loss: 0.6751787662506104, acc: 0.7692307829856873)
[2025-02-17 17:45:04,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:05,023][root][INFO] - Training Epoch: 1/2, step 1368/53949 completed (loss: 0.9480953812599182, acc: 0.7200000286102295)
[2025-02-17 17:45:05,212][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:05,437][root][INFO] - Training Epoch: 1/2, step 1369/53949 completed (loss: 0.980885922908783, acc: 0.6818181872367859)
[2025-02-17 17:45:05,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:05,853][root][INFO] - Training Epoch: 1/2, step 1370/53949 completed (loss: 0.8137364387512207, acc: 0.7872340679168701)
[2025-02-17 17:45:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:06,191][root][INFO] - Training Epoch: 1/2, step 1371/53949 completed (loss: 0.33696305751800537, acc: 0.9230769276618958)
[2025-02-17 17:45:06,326][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:06,545][root][INFO] - Training Epoch: 1/2, step 1372/53949 completed (loss: 1.3284146785736084, acc: 0.717391312122345)
[2025-02-17 17:45:06,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:06,932][root][INFO] - Training Epoch: 1/2, step 1373/53949 completed (loss: 0.4178857207298279, acc: 0.8461538553237915)
[2025-02-17 17:45:07,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:07,296][root][INFO] - Training Epoch: 1/2, step 1374/53949 completed (loss: 1.0392991304397583, acc: 0.70652174949646)
[2025-02-17 17:45:07,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:07,704][root][INFO] - Training Epoch: 1/2, step 1375/53949 completed (loss: 0.5419010519981384, acc: 0.8265306353569031)
[2025-02-17 17:45:07,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:08,055][root][INFO] - Training Epoch: 1/2, step 1376/53949 completed (loss: 0.6964176893234253, acc: 0.8297872543334961)
[2025-02-17 17:45:08,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:08,407][root][INFO] - Training Epoch: 1/2, step 1377/53949 completed (loss: 1.1305266618728638, acc: 0.6478873491287231)
[2025-02-17 17:45:08,570][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:08,794][root][INFO] - Training Epoch: 1/2, step 1378/53949 completed (loss: 1.2565289735794067, acc: 0.7727272510528564)
[2025-02-17 17:45:08,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:09,176][root][INFO] - Training Epoch: 1/2, step 1379/53949 completed (loss: 0.4110548496246338, acc: 0.8928571343421936)
[2025-02-17 17:45:09,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:09,580][root][INFO] - Training Epoch: 1/2, step 1380/53949 completed (loss: 0.5343660712242126, acc: 0.8645833134651184)
[2025-02-17 17:45:09,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:09,941][root][INFO] - Training Epoch: 1/2, step 1381/53949 completed (loss: 0.6140519380569458, acc: 0.7945205569267273)
[2025-02-17 17:45:10,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:10,310][root][INFO] - Training Epoch: 1/2, step 1382/53949 completed (loss: 1.0199565887451172, acc: 0.8064516186714172)
[2025-02-17 17:45:10,450][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:10,677][root][INFO] - Training Epoch: 1/2, step 1383/53949 completed (loss: 0.5839467644691467, acc: 0.8815789222717285)
[2025-02-17 17:45:10,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:11,066][root][INFO] - Training Epoch: 1/2, step 1384/53949 completed (loss: 0.961877167224884, acc: 0.7118644118309021)
[2025-02-17 17:45:11,204][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:11,414][root][INFO] - Training Epoch: 1/2, step 1385/53949 completed (loss: 0.5354907512664795, acc: 0.8676470518112183)
[2025-02-17 17:45:11,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:11,744][root][INFO] - Training Epoch: 1/2, step 1386/53949 completed (loss: 0.42590397596359253, acc: 0.9078947305679321)
[2025-02-17 17:45:11,872][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:12,080][root][INFO] - Training Epoch: 1/2, step 1387/53949 completed (loss: 0.6995617747306824, acc: 0.75)
[2025-02-17 17:45:12,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:12,463][root][INFO] - Training Epoch: 1/2, step 1388/53949 completed (loss: 0.01538433413952589, acc: 1.0)
[2025-02-17 17:45:12,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:12,821][root][INFO] - Training Epoch: 1/2, step 1389/53949 completed (loss: 0.6454464197158813, acc: 0.8032786846160889)
[2025-02-17 17:45:13,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:13,235][root][INFO] - Training Epoch: 1/2, step 1390/53949 completed (loss: 0.8856123685836792, acc: 0.7419354915618896)
[2025-02-17 17:45:13,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:13,619][root][INFO] - Training Epoch: 1/2, step 1391/53949 completed (loss: 0.762245237827301, acc: 0.7777777910232544)
[2025-02-17 17:45:13,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:13,990][root][INFO] - Training Epoch: 1/2, step 1392/53949 completed (loss: 0.6954199075698853, acc: 0.8214285969734192)
[2025-02-17 17:45:14,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:14,359][root][INFO] - Training Epoch: 1/2, step 1393/53949 completed (loss: 0.4595719575881958, acc: 0.953125)
[2025-02-17 17:45:14,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:14,741][root][INFO] - Training Epoch: 1/2, step 1394/53949 completed (loss: 1.2935203313827515, acc: 0.5925925970077515)
[2025-02-17 17:45:14,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:15,101][root][INFO] - Training Epoch: 1/2, step 1395/53949 completed (loss: 0.7190728187561035, acc: 0.761904776096344)
[2025-02-17 17:45:15,252][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:15,447][root][INFO] - Training Epoch: 1/2, step 1396/53949 completed (loss: 0.5691704750061035, acc: 0.8444444537162781)
[2025-02-17 17:45:15,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:15,878][root][INFO] - Training Epoch: 1/2, step 1397/53949 completed (loss: 0.5259749293327332, acc: 0.8148148059844971)
[2025-02-17 17:45:16,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:16,249][root][INFO] - Training Epoch: 1/2, step 1398/53949 completed (loss: 0.9168292880058289, acc: 0.7439024448394775)
[2025-02-17 17:45:16,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:16,695][root][INFO] - Training Epoch: 1/2, step 1399/53949 completed (loss: 1.0025354623794556, acc: 0.7281553149223328)
[2025-02-17 17:45:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:17,097][root][INFO] - Training Epoch: 1/2, step 1400/53949 completed (loss: 0.7379882335662842, acc: 0.7604166865348816)
[2025-02-17 17:45:17,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:17,481][root][INFO] - Training Epoch: 1/2, step 1401/53949 completed (loss: 0.6516515016555786, acc: 0.8190476298332214)
[2025-02-17 17:45:17,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:17,836][root][INFO] - Training Epoch: 1/2, step 1402/53949 completed (loss: 0.9047921299934387, acc: 0.8070175647735596)
[2025-02-17 17:45:17,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:18,193][root][INFO] - Training Epoch: 1/2, step 1403/53949 completed (loss: 1.097692847251892, acc: 0.719298243522644)
[2025-02-17 17:45:18,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:18,549][root][INFO] - Training Epoch: 1/2, step 1404/53949 completed (loss: 0.8473907113075256, acc: 0.7142857313156128)
[2025-02-17 17:45:18,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:18,925][root][INFO] - Training Epoch: 1/2, step 1405/53949 completed (loss: 0.7550406455993652, acc: 0.8571428656578064)
[2025-02-17 17:45:19,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:19,315][root][INFO] - Training Epoch: 1/2, step 1406/53949 completed (loss: 1.067940354347229, acc: 0.726190447807312)
[2025-02-17 17:45:19,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:19,666][root][INFO] - Training Epoch: 1/2, step 1407/53949 completed (loss: 0.5511325001716614, acc: 0.8227847814559937)
[2025-02-17 17:45:19,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:20,072][root][INFO] - Training Epoch: 1/2, step 1408/53949 completed (loss: 1.0390563011169434, acc: 0.6692913174629211)
[2025-02-17 17:45:20,218][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:20,422][root][INFO] - Training Epoch: 1/2, step 1409/53949 completed (loss: 0.6861698627471924, acc: 0.8333333134651184)
[2025-02-17 17:45:20,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:20,814][root][INFO] - Training Epoch: 1/2, step 1410/53949 completed (loss: 0.7454581260681152, acc: 0.7663043737411499)
[2025-02-17 17:45:20,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:21,163][root][INFO] - Training Epoch: 1/2, step 1411/53949 completed (loss: 0.798660397529602, acc: 0.7894737124443054)
[2025-02-17 17:45:21,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:21,580][root][INFO] - Training Epoch: 1/2, step 1412/53949 completed (loss: 0.5709766745567322, acc: 0.8333333134651184)
[2025-02-17 17:45:21,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:21,938][root][INFO] - Training Epoch: 1/2, step 1413/53949 completed (loss: 0.901888370513916, acc: 0.7599999904632568)
[2025-02-17 17:45:22,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:22,358][root][INFO] - Training Epoch: 1/2, step 1414/53949 completed (loss: 0.8881592154502869, acc: 0.7428571581840515)
[2025-02-17 17:45:22,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:22,789][root][INFO] - Training Epoch: 1/2, step 1415/53949 completed (loss: 0.539595901966095, acc: 0.8484848737716675)
[2025-02-17 17:45:22,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:23,131][root][INFO] - Training Epoch: 1/2, step 1416/53949 completed (loss: 0.5270068645477295, acc: 0.8421052694320679)
[2025-02-17 17:45:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:23,472][root][INFO] - Training Epoch: 1/2, step 1417/53949 completed (loss: 0.531285285949707, acc: 0.875)
[2025-02-17 17:45:23,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:23,873][root][INFO] - Training Epoch: 1/2, step 1418/53949 completed (loss: 0.5050753355026245, acc: 0.9069767594337463)
[2025-02-17 17:45:24,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:24,237][root][INFO] - Training Epoch: 1/2, step 1419/53949 completed (loss: 1.0765907764434814, acc: 0.7096773982048035)
[2025-02-17 17:45:24,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:24,658][root][INFO] - Training Epoch: 1/2, step 1420/53949 completed (loss: 0.4701347351074219, acc: 0.8405796885490417)
[2025-02-17 17:45:24,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:25,053][root][INFO] - Training Epoch: 1/2, step 1421/53949 completed (loss: 0.5961341261863708, acc: 0.8230769038200378)
[2025-02-17 17:45:25,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:25,404][root][INFO] - Training Epoch: 1/2, step 1422/53949 completed (loss: 0.10252579301595688, acc: 1.0)
[2025-02-17 17:45:25,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:25,757][root][INFO] - Training Epoch: 1/2, step 1423/53949 completed (loss: 0.25803375244140625, acc: 0.9166666865348816)
[2025-02-17 17:45:25,950][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:26,176][root][INFO] - Training Epoch: 1/2, step 1424/53949 completed (loss: 0.4217985272407532, acc: 0.8785046935081482)
[2025-02-17 17:45:26,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:26,583][root][INFO] - Training Epoch: 1/2, step 1425/53949 completed (loss: 1.0368798971176147, acc: 0.7708333134651184)
[2025-02-17 17:45:26,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:26,930][root][INFO] - Training Epoch: 1/2, step 1426/53949 completed (loss: 1.6277084350585938, acc: 0.6231883764266968)
[2025-02-17 17:45:27,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:27,334][root][INFO] - Training Epoch: 1/2, step 1427/53949 completed (loss: 1.0455513000488281, acc: 0.7209302186965942)
[2025-02-17 17:45:27,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:27,732][root][INFO] - Training Epoch: 1/2, step 1428/53949 completed (loss: 0.026850564405322075, acc: 1.0)
[2025-02-17 17:45:27,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:28,109][root][INFO] - Training Epoch: 1/2, step 1429/53949 completed (loss: 0.41658416390419006, acc: 0.8440366983413696)
[2025-02-17 17:45:28,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:28,468][root][INFO] - Training Epoch: 1/2, step 1430/53949 completed (loss: 0.7115093469619751, acc: 0.7798165082931519)
[2025-02-17 17:45:28,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:28,825][root][INFO] - Training Epoch: 1/2, step 1431/53949 completed (loss: 0.7214091420173645, acc: 0.782608687877655)
[2025-02-17 17:45:29,005][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:29,222][root][INFO] - Training Epoch: 1/2, step 1432/53949 completed (loss: 0.37208840250968933, acc: 0.9285714030265808)
[2025-02-17 17:45:29,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:29,577][root][INFO] - Training Epoch: 1/2, step 1433/53949 completed (loss: 0.15953141450881958, acc: 0.9655172228813171)
[2025-02-17 17:45:29,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:29,931][root][INFO] - Training Epoch: 1/2, step 1434/53949 completed (loss: 0.4860629141330719, acc: 0.8571428656578064)
[2025-02-17 17:45:30,128][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:30,348][root][INFO] - Training Epoch: 1/2, step 1435/53949 completed (loss: 0.45277637243270874, acc: 0.8909090757369995)
[2025-02-17 17:45:30,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:30,714][root][INFO] - Training Epoch: 1/2, step 1436/53949 completed (loss: 0.8827019929885864, acc: 0.7951807379722595)
[2025-02-17 17:45:30,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:31,095][root][INFO] - Training Epoch: 1/2, step 1437/53949 completed (loss: 0.6408206820487976, acc: 0.8181818127632141)
[2025-02-17 17:45:31,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:31,442][root][INFO] - Training Epoch: 1/2, step 1438/53949 completed (loss: 0.7714715003967285, acc: 0.7647058963775635)
[2025-02-17 17:45:31,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:31,829][root][INFO] - Training Epoch: 1/2, step 1439/53949 completed (loss: 0.8442299962043762, acc: 0.7659574747085571)
[2025-02-17 17:45:31,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:32,178][root][INFO] - Training Epoch: 1/2, step 1440/53949 completed (loss: 0.137004092335701, acc: 1.0)
[2025-02-17 17:45:32,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:32,559][root][INFO] - Training Epoch: 1/2, step 1441/53949 completed (loss: 0.5079010128974915, acc: 0.8727272748947144)
[2025-02-17 17:45:32,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:32,892][root][INFO] - Training Epoch: 1/2, step 1442/53949 completed (loss: 0.4564877450466156, acc: 0.8723404407501221)
[2025-02-17 17:45:33,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:33,238][root][INFO] - Training Epoch: 1/2, step 1443/53949 completed (loss: 0.5837017297744751, acc: 0.8181818127632141)
[2025-02-17 17:45:33,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:33,629][root][INFO] - Training Epoch: 1/2, step 1444/53949 completed (loss: 0.5827116966247559, acc: 0.8299319744110107)
[2025-02-17 17:45:33,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:33,997][root][INFO] - Training Epoch: 1/2, step 1445/53949 completed (loss: 0.9734386205673218, acc: 0.7397260069847107)
[2025-02-17 17:45:34,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:34,346][root][INFO] - Training Epoch: 1/2, step 1446/53949 completed (loss: 0.4220077097415924, acc: 0.8857142925262451)
[2025-02-17 17:45:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:34,682][root][INFO] - Training Epoch: 1/2, step 1447/53949 completed (loss: 0.38140788674354553, acc: 0.8888888955116272)
[2025-02-17 17:45:34,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:35,024][root][INFO] - Training Epoch: 1/2, step 1448/53949 completed (loss: 1.0452173948287964, acc: 0.7272727489471436)
[2025-02-17 17:45:35,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:35,362][root][INFO] - Training Epoch: 1/2, step 1449/53949 completed (loss: 1.2645231485366821, acc: 0.7714285850524902)
[2025-02-17 17:45:35,496][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:35,772][root][INFO] - Training Epoch: 1/2, step 1450/53949 completed (loss: 0.50937819480896, acc: 0.8333333134651184)
[2025-02-17 17:45:35,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:36,160][root][INFO] - Training Epoch: 1/2, step 1451/53949 completed (loss: 0.31862688064575195, acc: 0.8888888955116272)
[2025-02-17 17:45:36,291][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:36,506][root][INFO] - Training Epoch: 1/2, step 1452/53949 completed (loss: 0.5930231809616089, acc: 0.8289473652839661)
[2025-02-17 17:45:36,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:36,853][root][INFO] - Training Epoch: 1/2, step 1453/53949 completed (loss: 0.02220575138926506, acc: 1.0)
[2025-02-17 17:45:36,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:37,206][root][INFO] - Training Epoch: 1/2, step 1454/53949 completed (loss: 0.0193345807492733, acc: 1.0)
[2025-02-17 17:45:37,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:37,556][root][INFO] - Training Epoch: 1/2, step 1455/53949 completed (loss: 0.04943796992301941, acc: 1.0)
[2025-02-17 17:45:37,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:37,915][root][INFO] - Training Epoch: 1/2, step 1456/53949 completed (loss: 1.6501396894454956, acc: 0.7142857313156128)
[2025-02-17 17:45:38,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:38,260][root][INFO] - Training Epoch: 1/2, step 1457/53949 completed (loss: 0.5670459270477295, acc: 0.8260869383811951)
[2025-02-17 17:45:38,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:38,621][root][INFO] - Training Epoch: 1/2, step 1458/53949 completed (loss: 0.7841014862060547, acc: 0.7894737124443054)
[2025-02-17 17:45:38,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:39,033][root][INFO] - Training Epoch: 1/2, step 1459/53949 completed (loss: 0.6427453756332397, acc: 0.807692289352417)
[2025-02-17 17:45:39,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:39,379][root][INFO] - Training Epoch: 1/2, step 1460/53949 completed (loss: 0.6088065505027771, acc: 0.8125)
[2025-02-17 17:45:39,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:39,729][root][INFO] - Training Epoch: 1/2, step 1461/53949 completed (loss: 0.4191598892211914, acc: 0.8769230842590332)
[2025-02-17 17:45:39,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:40,109][root][INFO] - Training Epoch: 1/2, step 1462/53949 completed (loss: 0.9758991599082947, acc: 0.7307692170143127)
[2025-02-17 17:45:40,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:40,474][root][INFO] - Training Epoch: 1/2, step 1463/53949 completed (loss: 1.603515863418579, acc: 0.692307710647583)
[2025-02-17 17:45:40,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:40,822][root][INFO] - Training Epoch: 1/2, step 1464/53949 completed (loss: 0.15648259222507477, acc: 0.9583333134651184)
[2025-02-17 17:45:40,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:41,164][root][INFO] - Training Epoch: 1/2, step 1465/53949 completed (loss: 1.1609736680984497, acc: 0.739130437374115)
[2025-02-17 17:45:41,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:41,531][root][INFO] - Training Epoch: 1/2, step 1466/53949 completed (loss: 1.0952284336090088, acc: 0.7560975551605225)
[2025-02-17 17:45:41,731][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:41,941][root][INFO] - Training Epoch: 1/2, step 1467/53949 completed (loss: 0.7384260892868042, acc: 0.8024691343307495)
[2025-02-17 17:45:42,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:42,290][root][INFO] - Training Epoch: 1/2, step 1468/53949 completed (loss: 0.4145977199077606, acc: 0.8795180916786194)
[2025-02-17 17:45:42,456][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:42,689][root][INFO] - Training Epoch: 1/2, step 1469/53949 completed (loss: 0.6379422545433044, acc: 0.8058252334594727)
[2025-02-17 17:45:42,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:43,089][root][INFO] - Training Epoch: 1/2, step 1470/53949 completed (loss: 0.6329982876777649, acc: 0.800000011920929)
[2025-02-17 17:45:43,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:43,426][root][INFO] - Training Epoch: 1/2, step 1471/53949 completed (loss: 0.43624410033226013, acc: 0.8571428656578064)
[2025-02-17 17:45:43,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:43,759][root][INFO] - Training Epoch: 1/2, step 1472/53949 completed (loss: 1.2009241580963135, acc: 0.7333333492279053)
[2025-02-17 17:45:43,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:44,138][root][INFO] - Training Epoch: 1/2, step 1473/53949 completed (loss: 0.24017727375030518, acc: 0.9473684430122375)
[2025-02-17 17:45:44,304][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:44,516][root][INFO] - Training Epoch: 1/2, step 1474/53949 completed (loss: 1.2820736169815063, acc: 0.688524603843689)
[2025-02-17 17:45:44,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:44,871][root][INFO] - Training Epoch: 1/2, step 1475/53949 completed (loss: 1.01669180393219, acc: 0.7105262875556946)
[2025-02-17 17:45:45,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:45,287][root][INFO] - Training Epoch: 1/2, step 1476/53949 completed (loss: 0.8188490867614746, acc: 0.7321428656578064)
[2025-02-17 17:45:45,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:45,670][root][INFO] - Training Epoch: 1/2, step 1477/53949 completed (loss: 1.652604341506958, acc: 0.5625)
[2025-02-17 17:45:45,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:46,037][root][INFO] - Training Epoch: 1/2, step 1478/53949 completed (loss: 0.5553494691848755, acc: 0.8253968358039856)
[2025-02-17 17:45:46,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:46,409][root][INFO] - Training Epoch: 1/2, step 1479/53949 completed (loss: 0.6025466322898865, acc: 0.8383838534355164)
[2025-02-17 17:45:46,577][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:46,790][root][INFO] - Training Epoch: 1/2, step 1480/53949 completed (loss: 1.2112501859664917, acc: 0.6521739363670349)
[2025-02-17 17:45:46,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:47,169][root][INFO] - Training Epoch: 1/2, step 1481/53949 completed (loss: 0.37903958559036255, acc: 0.9012345671653748)
[2025-02-17 17:45:47,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:47,523][root][INFO] - Training Epoch: 1/2, step 1482/53949 completed (loss: 0.21374063193798065, acc: 1.0)
[2025-02-17 17:45:47,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:47,875][root][INFO] - Training Epoch: 1/2, step 1483/53949 completed (loss: 0.5391042232513428, acc: 0.8777777552604675)
[2025-02-17 17:45:48,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:48,227][root][INFO] - Training Epoch: 1/2, step 1484/53949 completed (loss: 0.5986776351928711, acc: 0.8536585569381714)
[2025-02-17 17:45:48,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:48,578][root][INFO] - Training Epoch: 1/2, step 1485/53949 completed (loss: 1.2320576906204224, acc: 0.6499999761581421)
[2025-02-17 17:45:48,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:48,922][root][INFO] - Training Epoch: 1/2, step 1486/53949 completed (loss: 1.291642427444458, acc: 0.6666666865348816)
[2025-02-17 17:45:49,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:49,238][root][INFO] - Training Epoch: 1/2, step 1487/53949 completed (loss: 0.6735126972198486, acc: 0.8170731663703918)
[2025-02-17 17:45:49,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:49,590][root][INFO] - Training Epoch: 1/2, step 1488/53949 completed (loss: 0.9387029409408569, acc: 0.695652186870575)
[2025-02-17 17:45:49,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:50,015][root][INFO] - Training Epoch: 1/2, step 1489/53949 completed (loss: 0.8940048813819885, acc: 0.7818182110786438)
[2025-02-17 17:45:50,156][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:50,376][root][INFO] - Training Epoch: 1/2, step 1490/53949 completed (loss: 1.1635017395019531, acc: 0.7142857313156128)
[2025-02-17 17:45:50,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:50,750][root][INFO] - Training Epoch: 1/2, step 1491/53949 completed (loss: 0.8609070181846619, acc: 0.8048780560493469)
[2025-02-17 17:45:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:51,095][root][INFO] - Training Epoch: 1/2, step 1492/53949 completed (loss: 0.5705410242080688, acc: 0.8846153616905212)
[2025-02-17 17:45:51,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:51,436][root][INFO] - Training Epoch: 1/2, step 1493/53949 completed (loss: 0.4201899468898773, acc: 0.7777777910232544)
[2025-02-17 17:45:51,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:51,794][root][INFO] - Training Epoch: 1/2, step 1494/53949 completed (loss: 0.5084565877914429, acc: 0.8999999761581421)
[2025-02-17 17:45:51,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:52,140][root][INFO] - Training Epoch: 1/2, step 1495/53949 completed (loss: 0.8895542025566101, acc: 0.7599999904632568)
[2025-02-17 17:45:52,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:52,571][root][INFO] - Training Epoch: 1/2, step 1496/53949 completed (loss: 0.7537988424301147, acc: 0.822857141494751)
[2025-02-17 17:45:52,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:52,920][root][INFO] - Training Epoch: 1/2, step 1497/53949 completed (loss: 1.1340405941009521, acc: 0.6964285969734192)
[2025-02-17 17:45:53,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:53,263][root][INFO] - Training Epoch: 1/2, step 1498/53949 completed (loss: 0.7321485877037048, acc: 0.8170731663703918)
[2025-02-17 17:45:53,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:53,610][root][INFO] - Training Epoch: 1/2, step 1499/53949 completed (loss: 0.9008725881576538, acc: 0.7209302186965942)
[2025-02-17 17:45:53,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:53,950][root][INFO] - Training Epoch: 1/2, step 1500/53949 completed (loss: 0.024356625974178314, acc: 1.0)
[2025-02-17 17:45:54,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:54,286][root][INFO] - Training Epoch: 1/2, step 1501/53949 completed (loss: 0.26264575123786926, acc: 0.8333333134651184)
[2025-02-17 17:45:54,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:54,664][root][INFO] - Training Epoch: 1/2, step 1502/53949 completed (loss: 0.547392725944519, acc: 0.8478260636329651)
[2025-02-17 17:45:54,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:55,042][root][INFO] - Training Epoch: 1/2, step 1503/53949 completed (loss: 0.45404282212257385, acc: 0.8765432238578796)
[2025-02-17 17:45:55,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:55,419][root][INFO] - Training Epoch: 1/2, step 1504/53949 completed (loss: 0.7982097268104553, acc: 0.7872340679168701)
[2025-02-17 17:45:55,575][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:55,812][root][INFO] - Training Epoch: 1/2, step 1505/53949 completed (loss: 0.7035011649131775, acc: 0.8121212124824524)
[2025-02-17 17:45:56,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:56,231][root][INFO] - Training Epoch: 1/2, step 1506/53949 completed (loss: 0.9321344494819641, acc: 0.7589285969734192)
[2025-02-17 17:45:56,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:56,577][root][INFO] - Training Epoch: 1/2, step 1507/53949 completed (loss: 0.22348174452781677, acc: 0.8999999761581421)
[2025-02-17 17:45:56,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:56,933][root][INFO] - Training Epoch: 1/2, step 1508/53949 completed (loss: 0.7437053918838501, acc: 0.8150684833526611)
[2025-02-17 17:45:57,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:57,289][root][INFO] - Training Epoch: 1/2, step 1509/53949 completed (loss: 0.41491150856018066, acc: 0.8588235378265381)
[2025-02-17 17:45:57,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:57,703][root][INFO] - Training Epoch: 1/2, step 1510/53949 completed (loss: 0.5635242462158203, acc: 0.828125)
[2025-02-17 17:45:57,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:58,085][root][INFO] - Training Epoch: 1/2, step 1511/53949 completed (loss: 0.6891679167747498, acc: 0.7333333492279053)
[2025-02-17 17:45:58,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:58,428][root][INFO] - Training Epoch: 1/2, step 1512/53949 completed (loss: 0.29363954067230225, acc: 0.8888888955116272)
[2025-02-17 17:45:58,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:58,797][root][INFO] - Training Epoch: 1/2, step 1513/53949 completed (loss: 0.46725332736968994, acc: 0.8421052694320679)
[2025-02-17 17:45:58,929][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:59,140][root][INFO] - Training Epoch: 1/2, step 1514/53949 completed (loss: 0.8901354670524597, acc: 0.8061224222183228)
[2025-02-17 17:45:59,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:59,501][root][INFO] - Training Epoch: 1/2, step 1515/53949 completed (loss: 0.8084670305252075, acc: 0.7727272510528564)
[2025-02-17 17:45:59,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:59,839][root][INFO] - Training Epoch: 1/2, step 1516/53949 completed (loss: 0.31090888381004333, acc: 0.8571428656578064)
[2025-02-17 17:45:59,971][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:00,181][root][INFO] - Training Epoch: 1/2, step 1517/53949 completed (loss: 0.48149457573890686, acc: 0.8780487775802612)
[2025-02-17 17:46:00,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:00,528][root][INFO] - Training Epoch: 1/2, step 1518/53949 completed (loss: 0.2441343516111374, acc: 0.9428571462631226)
[2025-02-17 17:46:00,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:00,915][root][INFO] - Training Epoch: 1/2, step 1519/53949 completed (loss: 0.16437262296676636, acc: 1.0)
[2025-02-17 17:46:01,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:01,273][root][INFO] - Training Epoch: 1/2, step 1520/53949 completed (loss: 0.7407805323600769, acc: 0.7777777910232544)
[2025-02-17 17:46:01,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:01,621][root][INFO] - Training Epoch: 1/2, step 1521/53949 completed (loss: 0.510746419429779, acc: 0.8269230723381042)
[2025-02-17 17:46:01,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:01,944][root][INFO] - Training Epoch: 1/2, step 1522/53949 completed (loss: 0.7660512328147888, acc: 0.800000011920929)
[2025-02-17 17:46:02,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:02,288][root][INFO] - Training Epoch: 1/2, step 1523/53949 completed (loss: 0.6122350692749023, acc: 0.7887324094772339)
[2025-02-17 17:46:02,425][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:02,635][root][INFO] - Training Epoch: 1/2, step 1524/53949 completed (loss: 0.36341437697410583, acc: 0.9166666865348816)
[2025-02-17 17:46:02,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:02,975][root][INFO] - Training Epoch: 1/2, step 1525/53949 completed (loss: 0.5911558866500854, acc: 0.8723404407501221)
[2025-02-17 17:46:03,110][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:03,321][root][INFO] - Training Epoch: 1/2, step 1526/53949 completed (loss: 0.6055529117584229, acc: 0.8448275923728943)
[2025-02-17 17:46:03,479][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:03,687][root][INFO] - Training Epoch: 1/2, step 1527/53949 completed (loss: 0.9072572588920593, acc: 0.8205128312110901)
[2025-02-17 17:46:03,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:04,036][root][INFO] - Training Epoch: 1/2, step 1528/53949 completed (loss: 0.1847357451915741, acc: 0.949999988079071)
[2025-02-17 17:46:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:04,392][root][INFO] - Training Epoch: 1/2, step 1529/53949 completed (loss: 0.39108186960220337, acc: 0.8837209343910217)
[2025-02-17 17:46:04,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:04,768][root][INFO] - Training Epoch: 1/2, step 1530/53949 completed (loss: 1.0782365798950195, acc: 0.75)
[2025-02-17 17:46:04,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:05,119][root][INFO] - Training Epoch: 1/2, step 1531/53949 completed (loss: 0.5353195071220398, acc: 0.8611111044883728)
[2025-02-17 17:46:05,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:05,459][root][INFO] - Training Epoch: 1/2, step 1532/53949 completed (loss: 1.3752456903457642, acc: 0.7272727489471436)
[2025-02-17 17:46:05,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:05,815][root][INFO] - Training Epoch: 1/2, step 1533/53949 completed (loss: 1.0019742250442505, acc: 0.6818181872367859)
[2025-02-17 17:46:05,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:06,208][root][INFO] - Training Epoch: 1/2, step 1534/53949 completed (loss: 0.47710761427879333, acc: 0.8341231942176819)
[2025-02-17 17:46:06,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:06,548][root][INFO] - Training Epoch: 1/2, step 1535/53949 completed (loss: 0.6817348599433899, acc: 0.8494623899459839)
[2025-02-17 17:46:06,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:06,887][root][INFO] - Training Epoch: 1/2, step 1536/53949 completed (loss: 0.457762211561203, acc: 0.8421052694320679)
[2025-02-17 17:46:07,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:07,230][root][INFO] - Training Epoch: 1/2, step 1537/53949 completed (loss: 0.9947273135185242, acc: 0.6952381134033203)
[2025-02-17 17:46:07,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:07,622][root][INFO] - Training Epoch: 1/2, step 1538/53949 completed (loss: 1.0593628883361816, acc: 0.6969696879386902)
[2025-02-17 17:46:07,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:07,966][root][INFO] - Training Epoch: 1/2, step 1539/53949 completed (loss: 0.6429488062858582, acc: 0.7547169923782349)
[2025-02-17 17:46:08,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:08,334][root][INFO] - Training Epoch: 1/2, step 1540/53949 completed (loss: 1.3063414096832275, acc: 0.6666666865348816)
[2025-02-17 17:46:08,471][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:08,691][root][INFO] - Training Epoch: 1/2, step 1541/53949 completed (loss: 0.5621830821037292, acc: 0.9024389982223511)
[2025-02-17 17:46:08,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:09,068][root][INFO] - Training Epoch: 1/2, step 1542/53949 completed (loss: 0.5430306792259216, acc: 0.8333333134651184)
[2025-02-17 17:46:09,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:09,433][root][INFO] - Training Epoch: 1/2, step 1543/53949 completed (loss: 0.8305516839027405, acc: 0.7706422209739685)
[2025-02-17 17:46:09,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:09,776][root][INFO] - Training Epoch: 1/2, step 1544/53949 completed (loss: 0.2910938858985901, acc: 0.8857142925262451)
[2025-02-17 17:46:09,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:10,124][root][INFO] - Training Epoch: 1/2, step 1545/53949 completed (loss: 0.5205410122871399, acc: 0.8484848737716675)
[2025-02-17 17:46:10,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:10,551][root][INFO] - Training Epoch: 1/2, step 1546/53949 completed (loss: 0.6384268999099731, acc: 0.8214285969734192)
[2025-02-17 17:46:10,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:10,903][root][INFO] - Training Epoch: 1/2, step 1547/53949 completed (loss: 0.746260404586792, acc: 0.7984496355056763)
[2025-02-17 17:46:11,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:11,259][root][INFO] - Training Epoch: 1/2, step 1548/53949 completed (loss: 0.4805258810520172, acc: 0.8837209343910217)
[2025-02-17 17:46:11,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:11,600][root][INFO] - Training Epoch: 1/2, step 1549/53949 completed (loss: 1.040883183479309, acc: 0.692307710647583)
[2025-02-17 17:46:11,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:12,003][root][INFO] - Training Epoch: 1/2, step 1550/53949 completed (loss: 0.483786940574646, acc: 0.8352941274642944)
[2025-02-17 17:46:12,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:12,390][root][INFO] - Training Epoch: 1/2, step 1551/53949 completed (loss: 0.5872270464897156, acc: 0.8571428656578064)
[2025-02-17 17:46:12,541][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:12,754][root][INFO] - Training Epoch: 1/2, step 1552/53949 completed (loss: 0.9076374173164368, acc: 0.7659574747085571)
[2025-02-17 17:46:12,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:13,106][root][INFO] - Training Epoch: 1/2, step 1553/53949 completed (loss: 0.584486722946167, acc: 0.8376068472862244)
[2025-02-17 17:46:13,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:13,455][root][INFO] - Training Epoch: 1/2, step 1554/53949 completed (loss: 0.4031793475151062, acc: 0.8918918967247009)
[2025-02-17 17:46:13,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:13,816][root][INFO] - Training Epoch: 1/2, step 1555/53949 completed (loss: 0.5252963304519653, acc: 0.84375)
[2025-02-17 17:46:13,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:14,220][root][INFO] - Training Epoch: 1/2, step 1556/53949 completed (loss: 1.0086491107940674, acc: 0.6891891956329346)
[2025-02-17 17:46:14,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:14,574][root][INFO] - Training Epoch: 1/2, step 1557/53949 completed (loss: 1.1195341348648071, acc: 0.7142857313156128)
[2025-02-17 17:46:14,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:14,933][root][INFO] - Training Epoch: 1/2, step 1558/53949 completed (loss: 0.8133419156074524, acc: 0.7721518874168396)
[2025-02-17 17:46:15,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:15,309][root][INFO] - Training Epoch: 1/2, step 1559/53949 completed (loss: 0.5482515096664429, acc: 0.8294573426246643)
[2025-02-17 17:46:15,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:15,776][root][INFO] - Training Epoch: 1/2, step 1560/53949 completed (loss: 0.7172160744667053, acc: 0.8684210777282715)
[2025-02-17 17:46:15,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:16,183][root][INFO] - Training Epoch: 1/2, step 1561/53949 completed (loss: 0.7348619699478149, acc: 0.8684210777282715)
[2025-02-17 17:46:16,321][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:16,563][root][INFO] - Training Epoch: 1/2, step 1562/53949 completed (loss: 0.6974218487739563, acc: 0.837837815284729)
[2025-02-17 17:46:16,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:16,988][root][INFO] - Training Epoch: 1/2, step 1563/53949 completed (loss: 0.4610058665275574, acc: 0.8761904835700989)
[2025-02-17 17:46:17,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:17,411][root][INFO] - Training Epoch: 1/2, step 1564/53949 completed (loss: 0.6216694116592407, acc: 0.7878788113594055)
[2025-02-17 17:46:17,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:17,836][root][INFO] - Training Epoch: 1/2, step 1565/53949 completed (loss: 1.0126399993896484, acc: 0.6857143044471741)
[2025-02-17 17:46:17,998][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:18,210][root][INFO] - Training Epoch: 1/2, step 1566/53949 completed (loss: 0.4748494625091553, acc: 0.8695651888847351)
[2025-02-17 17:46:18,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:18,563][root][INFO] - Training Epoch: 1/2, step 1567/53949 completed (loss: 0.8976942300796509, acc: 0.7473683953285217)
[2025-02-17 17:46:18,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:18,918][root][INFO] - Training Epoch: 1/2, step 1568/53949 completed (loss: 0.5816254615783691, acc: 0.8507462739944458)
[2025-02-17 17:46:19,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:19,267][root][INFO] - Training Epoch: 1/2, step 1569/53949 completed (loss: 0.3869718313217163, acc: 0.9189189076423645)
[2025-02-17 17:46:19,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:19,681][root][INFO] - Training Epoch: 1/2, step 1570/53949 completed (loss: 0.9748700857162476, acc: 0.71875)
[2025-02-17 17:46:19,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:20,097][root][INFO] - Training Epoch: 1/2, step 1571/53949 completed (loss: 0.732379138469696, acc: 0.8058823347091675)
[2025-02-17 17:46:20,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:20,446][root][INFO] - Training Epoch: 1/2, step 1572/53949 completed (loss: 0.4949786961078644, acc: 0.796875)
[2025-02-17 17:46:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:20,788][root][INFO] - Training Epoch: 1/2, step 1573/53949 completed (loss: 1.1043710708618164, acc: 0.75)
[2025-02-17 17:46:20,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:21,139][root][INFO] - Training Epoch: 1/2, step 1574/53949 completed (loss: 0.5667859315872192, acc: 0.8658536672592163)
[2025-02-17 17:46:21,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:21,485][root][INFO] - Training Epoch: 1/2, step 1575/53949 completed (loss: 1.1256402730941772, acc: 0.7183098793029785)
[2025-02-17 17:46:21,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:21,837][root][INFO] - Training Epoch: 1/2, step 1576/53949 completed (loss: 0.7429810762405396, acc: 0.8433734774589539)
[2025-02-17 17:46:21,974][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:22,182][root][INFO] - Training Epoch: 1/2, step 1577/53949 completed (loss: 0.19114208221435547, acc: 1.0)
[2025-02-17 17:46:22,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:22,537][root][INFO] - Training Epoch: 1/2, step 1578/53949 completed (loss: 0.4807349741458893, acc: 0.8684210777282715)
[2025-02-17 17:46:22,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:22,891][root][INFO] - Training Epoch: 1/2, step 1579/53949 completed (loss: 0.2556215524673462, acc: 0.9305555820465088)
[2025-02-17 17:46:23,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:23,299][root][INFO] - Training Epoch: 1/2, step 1580/53949 completed (loss: 0.36367425322532654, acc: 0.9295774698257446)
[2025-02-17 17:46:23,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:23,700][root][INFO] - Training Epoch: 1/2, step 1581/53949 completed (loss: 0.32399141788482666, acc: 0.8780487775802612)
[2025-02-17 17:46:23,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:24,096][root][INFO] - Training Epoch: 1/2, step 1582/53949 completed (loss: 1.1114939451217651, acc: 0.7142857313156128)
[2025-02-17 17:46:24,246][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:24,462][root][INFO] - Training Epoch: 1/2, step 1583/53949 completed (loss: 0.8322769403457642, acc: 0.7599999904632568)
[2025-02-17 17:46:24,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:24,803][root][INFO] - Training Epoch: 1/2, step 1584/53949 completed (loss: 0.8300537467002869, acc: 0.695652186870575)
[2025-02-17 17:46:24,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:25,136][root][INFO] - Training Epoch: 1/2, step 1585/53949 completed (loss: 1.4494678974151611, acc: 0.6111111044883728)
[2025-02-17 17:46:25,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:25,568][root][INFO] - Training Epoch: 1/2, step 1586/53949 completed (loss: 0.642445981502533, acc: 0.797468364238739)
[2025-02-17 17:46:25,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:25,983][root][INFO] - Training Epoch: 1/2, step 1587/53949 completed (loss: 0.48028555512428284, acc: 0.8895705342292786)
[2025-02-17 17:46:26,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:26,349][root][INFO] - Training Epoch: 1/2, step 1588/53949 completed (loss: 0.6310730576515198, acc: 0.8294573426246643)
[2025-02-17 17:46:26,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:26,697][root][INFO] - Training Epoch: 1/2, step 1589/53949 completed (loss: 0.4826325476169586, acc: 0.8285714387893677)
[2025-02-17 17:46:26,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:27,111][root][INFO] - Training Epoch: 1/2, step 1590/53949 completed (loss: 0.6786931157112122, acc: 0.8461538553237915)
[2025-02-17 17:46:27,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:27,476][root][INFO] - Training Epoch: 1/2, step 1591/53949 completed (loss: 0.69880610704422, acc: 0.7435897588729858)
[2025-02-17 17:46:27,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:27,840][root][INFO] - Training Epoch: 1/2, step 1592/53949 completed (loss: 0.3922542333602905, acc: 0.9375)
[2025-02-17 17:46:28,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:28,235][root][INFO] - Training Epoch: 1/2, step 1593/53949 completed (loss: 0.5774059295654297, acc: 0.800000011920929)
[2025-02-17 17:46:28,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:28,638][root][INFO] - Training Epoch: 1/2, step 1594/53949 completed (loss: 1.0341711044311523, acc: 0.732758641242981)
[2025-02-17 17:46:28,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:29,031][root][INFO] - Training Epoch: 1/2, step 1595/53949 completed (loss: 0.05955985561013222, acc: 1.0)
[2025-02-17 17:46:29,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:29,401][root][INFO] - Training Epoch: 1/2, step 1596/53949 completed (loss: 0.3363335430622101, acc: 0.939393937587738)
[2025-02-17 17:46:29,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:29,816][root][INFO] - Training Epoch: 1/2, step 1597/53949 completed (loss: 1.6345391273498535, acc: 0.6041666865348816)
[2025-02-17 17:46:29,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:30,172][root][INFO] - Training Epoch: 1/2, step 1598/53949 completed (loss: 0.1502271443605423, acc: 1.0)
[2025-02-17 17:46:30,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:30,523][root][INFO] - Training Epoch: 1/2, step 1599/53949 completed (loss: 0.34758660197257996, acc: 0.8787878751754761)
[2025-02-17 17:46:30,693][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:30,918][root][INFO] - Training Epoch: 1/2, step 1600/53949 completed (loss: 0.5142703652381897, acc: 0.8799999952316284)
[2025-02-17 17:46:31,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:31,331][root][INFO] - Training Epoch: 1/2, step 1601/53949 completed (loss: 0.65865159034729, acc: 0.8333333134651184)
[2025-02-17 17:46:31,509][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:31,739][root][INFO] - Training Epoch: 1/2, step 1602/53949 completed (loss: 0.5839487314224243, acc: 0.75)
[2025-02-17 17:46:31,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:32,109][root][INFO] - Training Epoch: 1/2, step 1603/53949 completed (loss: 0.8030350804328918, acc: 0.699999988079071)
[2025-02-17 17:46:32,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:32,484][root][INFO] - Training Epoch: 1/2, step 1604/53949 completed (loss: 1.3111423254013062, acc: 0.6666666865348816)
[2025-02-17 17:46:32,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:32,838][root][INFO] - Training Epoch: 1/2, step 1605/53949 completed (loss: 0.33049309253692627, acc: 0.9047619104385376)
[2025-02-17 17:46:32,974][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:33,183][root][INFO] - Training Epoch: 1/2, step 1606/53949 completed (loss: 0.4035097658634186, acc: 0.9047619104385376)
[2025-02-17 17:46:33,368][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:33,599][root][INFO] - Training Epoch: 1/2, step 1607/53949 completed (loss: 1.2636338472366333, acc: 0.7083333134651184)
[2025-02-17 17:46:33,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:34,002][root][INFO] - Training Epoch: 1/2, step 1608/53949 completed (loss: 0.48689255118370056, acc: 0.8918918967247009)
[2025-02-17 17:46:34,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:34,388][root][INFO] - Training Epoch: 1/2, step 1609/53949 completed (loss: 0.5596708059310913, acc: 0.8333333134651184)
[2025-02-17 17:46:34,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:34,740][root][INFO] - Training Epoch: 1/2, step 1610/53949 completed (loss: 0.409765362739563, acc: 0.8461538553237915)
[2025-02-17 17:46:34,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:35,158][root][INFO] - Training Epoch: 1/2, step 1611/53949 completed (loss: 0.4461888372898102, acc: 0.8947368264198303)
[2025-02-17 17:46:35,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:35,520][root][INFO] - Training Epoch: 1/2, step 1612/53949 completed (loss: 0.8408886790275574, acc: 0.75)
[2025-02-17 17:46:35,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:35,867][root][INFO] - Training Epoch: 1/2, step 1613/53949 completed (loss: 0.9201472997665405, acc: 0.7017543911933899)
[2025-02-17 17:46:36,036][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:36,252][root][INFO] - Training Epoch: 1/2, step 1614/53949 completed (loss: 0.6256889700889587, acc: 0.8404255509376526)
[2025-02-17 17:46:36,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:36,647][root][INFO] - Training Epoch: 1/2, step 1615/53949 completed (loss: 0.9913279414176941, acc: 0.7162162065505981)
[2025-02-17 17:46:36,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:36,995][root][INFO] - Training Epoch: 1/2, step 1616/53949 completed (loss: 1.5150871276855469, acc: 0.5714285969734192)
[2025-02-17 17:46:37,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:37,352][root][INFO] - Training Epoch: 1/2, step 1617/53949 completed (loss: 0.9416220784187317, acc: 0.7395833134651184)
[2025-02-17 17:46:37,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:37,769][root][INFO] - Training Epoch: 1/2, step 1618/53949 completed (loss: 1.2347822189331055, acc: 0.7857142686843872)
[2025-02-17 17:46:37,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:38,194][root][INFO] - Training Epoch: 1/2, step 1619/53949 completed (loss: 0.7157662510871887, acc: 0.7931034564971924)
[2025-02-17 17:46:38,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:38,561][root][INFO] - Training Epoch: 1/2, step 1620/53949 completed (loss: 0.9637453556060791, acc: 0.8181818127632141)
[2025-02-17 17:46:38,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:38,908][root][INFO] - Training Epoch: 1/2, step 1621/53949 completed (loss: 0.4469565153121948, acc: 0.8888888955116272)
[2025-02-17 17:46:39,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:39,255][root][INFO] - Training Epoch: 1/2, step 1622/53949 completed (loss: 0.8108202815055847, acc: 0.7758620977401733)
[2025-02-17 17:46:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:39,625][root][INFO] - Training Epoch: 1/2, step 1623/53949 completed (loss: 0.43864962458610535, acc: 0.8859649300575256)
[2025-02-17 17:46:39,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:39,986][root][INFO] - Training Epoch: 1/2, step 1624/53949 completed (loss: 0.5598646402359009, acc: 0.8543689250946045)
[2025-02-17 17:46:40,124][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:40,351][root][INFO] - Training Epoch: 1/2, step 1625/53949 completed (loss: 0.9759873151779175, acc: 0.695652186870575)
[2025-02-17 17:46:40,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:40,733][root][INFO] - Training Epoch: 1/2, step 1626/53949 completed (loss: 0.6086025238037109, acc: 0.8484848737716675)
[2025-02-17 17:46:40,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:41,093][root][INFO] - Training Epoch: 1/2, step 1627/53949 completed (loss: 0.5128834247589111, acc: 0.8333333134651184)
[2025-02-17 17:46:41,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:41,453][root][INFO] - Training Epoch: 1/2, step 1628/53949 completed (loss: 0.8949968218803406, acc: 0.7681159377098083)
[2025-02-17 17:46:41,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:41,926][root][INFO] - Training Epoch: 1/2, step 1629/53949 completed (loss: 1.0491936206817627, acc: 0.7388888597488403)
[2025-02-17 17:46:42,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:42,349][root][INFO] - Training Epoch: 1/2, step 1630/53949 completed (loss: 0.5510749220848083, acc: 0.8297872543334961)
[2025-02-17 17:46:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:42,716][root][INFO] - Training Epoch: 1/2, step 1631/53949 completed (loss: 0.4446437358856201, acc: 0.9074074029922485)
[2025-02-17 17:46:42,890][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:43,116][root][INFO] - Training Epoch: 1/2, step 1632/53949 completed (loss: 0.734196662902832, acc: 0.7428571581840515)
[2025-02-17 17:46:43,259][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:43,433][root][INFO] - Training Epoch: 1/2, step 1633/53949 completed (loss: 1.4785076379776, acc: 0.699999988079071)
[2025-02-17 17:46:43,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:43,853][root][INFO] - Training Epoch: 1/2, step 1634/53949 completed (loss: 0.6161148548126221, acc: 0.8468468189239502)
[2025-02-17 17:46:43,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:44,212][root][INFO] - Training Epoch: 1/2, step 1635/53949 completed (loss: 0.040539953857660294, acc: 1.0)
[2025-02-17 17:46:44,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:44,608][root][INFO] - Training Epoch: 1/2, step 1636/53949 completed (loss: 0.4786365330219269, acc: 0.8561643958091736)
[2025-02-17 17:46:44,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:44,965][root][INFO] - Training Epoch: 1/2, step 1637/53949 completed (loss: 0.17958474159240723, acc: 0.9428571462631226)
[2025-02-17 17:46:45,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:45,365][root][INFO] - Training Epoch: 1/2, step 1638/53949 completed (loss: 0.5639601945877075, acc: 0.834645688533783)
[2025-02-17 17:46:45,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:45,795][root][INFO] - Training Epoch: 1/2, step 1639/53949 completed (loss: 0.382706880569458, acc: 0.9344262480735779)
[2025-02-17 17:46:45,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:46,154][root][INFO] - Training Epoch: 1/2, step 1640/53949 completed (loss: 1.5597304105758667, acc: 0.6666666865348816)
[2025-02-17 17:46:46,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:46,490][root][INFO] - Training Epoch: 1/2, step 1641/53949 completed (loss: 0.5539544224739075, acc: 0.8644067645072937)
[2025-02-17 17:46:46,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:46,890][root][INFO] - Training Epoch: 1/2, step 1642/53949 completed (loss: 0.7169212102890015, acc: 0.8194444179534912)
[2025-02-17 17:46:47,032][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:47,247][root][INFO] - Training Epoch: 1/2, step 1643/53949 completed (loss: 0.3848128914833069, acc: 0.931034505367279)
[2025-02-17 17:46:47,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:47,590][root][INFO] - Training Epoch: 1/2, step 1644/53949 completed (loss: 0.7594675421714783, acc: 0.8235294222831726)
[2025-02-17 17:46:47,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:47,991][root][INFO] - Training Epoch: 1/2, step 1645/53949 completed (loss: 0.6672859787940979, acc: 0.8357142806053162)
[2025-02-17 17:46:48,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:48,398][root][INFO] - Training Epoch: 1/2, step 1646/53949 completed (loss: 0.5153626799583435, acc: 0.8653846383094788)
[2025-02-17 17:46:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:48,768][root][INFO] - Training Epoch: 1/2, step 1647/53949 completed (loss: 0.6241545081138611, acc: 0.8583333492279053)
[2025-02-17 17:46:48,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:49,128][root][INFO] - Training Epoch: 1/2, step 1648/53949 completed (loss: 1.2948402166366577, acc: 0.6507936716079712)
[2025-02-17 17:46:49,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:49,493][root][INFO] - Training Epoch: 1/2, step 1649/53949 completed (loss: 0.5822426676750183, acc: 0.8461538553237915)
[2025-02-17 17:46:49,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:49,902][root][INFO] - Training Epoch: 1/2, step 1650/53949 completed (loss: 0.43912944197654724, acc: 0.8684210777282715)
[2025-02-17 17:46:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:50,268][root][INFO] - Training Epoch: 1/2, step 1651/53949 completed (loss: 0.8422917723655701, acc: 0.8072289228439331)
[2025-02-17 17:46:50,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:50,625][root][INFO] - Training Epoch: 1/2, step 1652/53949 completed (loss: 1.8069757223129272, acc: 0.5600000023841858)
[2025-02-17 17:46:50,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:51,016][root][INFO] - Training Epoch: 1/2, step 1653/53949 completed (loss: 0.7521504759788513, acc: 0.7560975551605225)
[2025-02-17 17:46:51,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:51,409][root][INFO] - Training Epoch: 1/2, step 1654/53949 completed (loss: 0.9701679348945618, acc: 0.7446808218955994)
[2025-02-17 17:46:51,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:51,791][root][INFO] - Training Epoch: 1/2, step 1655/53949 completed (loss: 0.6121522784233093, acc: 0.828125)
[2025-02-17 17:46:51,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:52,151][root][INFO] - Training Epoch: 1/2, step 1656/53949 completed (loss: 0.877318799495697, acc: 0.7191011309623718)
[2025-02-17 17:46:52,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:52,528][root][INFO] - Training Epoch: 1/2, step 1657/53949 completed (loss: 0.5330575704574585, acc: 0.8571428656578064)
[2025-02-17 17:46:52,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:52,941][root][INFO] - Training Epoch: 1/2, step 1658/53949 completed (loss: 0.7011305093765259, acc: 0.7770700454711914)
[2025-02-17 17:46:53,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:53,337][root][INFO] - Training Epoch: 1/2, step 1659/53949 completed (loss: 0.7313064932823181, acc: 0.8181818127632141)
[2025-02-17 17:46:53,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:53,735][root][INFO] - Training Epoch: 1/2, step 1660/53949 completed (loss: 0.5426886677742004, acc: 0.8068181872367859)
[2025-02-17 17:46:53,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:54,130][root][INFO] - Training Epoch: 1/2, step 1661/53949 completed (loss: 0.8542765378952026, acc: 0.7721518874168396)
[2025-02-17 17:46:54,280][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:54,491][root][INFO] - Training Epoch: 1/2, step 1662/53949 completed (loss: 0.664497971534729, acc: 0.8245614171028137)
[2025-02-17 17:46:54,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:54,836][root][INFO] - Training Epoch: 1/2, step 1663/53949 completed (loss: 0.5173700451850891, acc: 0.8571428656578064)
[2025-02-17 17:46:55,003][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:55,221][root][INFO] - Training Epoch: 1/2, step 1664/53949 completed (loss: 0.5070928335189819, acc: 0.8775510191917419)
[2025-02-17 17:46:55,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:55,566][root][INFO] - Training Epoch: 1/2, step 1665/53949 completed (loss: 0.5001311898231506, acc: 0.8571428656578064)
[2025-02-17 17:46:55,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:55,972][root][INFO] - Training Epoch: 1/2, step 1666/53949 completed (loss: 0.2654750347137451, acc: 0.9080459475517273)
[2025-02-17 17:46:56,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:56,351][root][INFO] - Training Epoch: 1/2, step 1667/53949 completed (loss: 1.0941290855407715, acc: 0.7428571581840515)
[2025-02-17 17:46:56,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:56,724][root][INFO] - Training Epoch: 1/2, step 1668/53949 completed (loss: 0.5334482789039612, acc: 0.8382353186607361)
[2025-02-17 17:46:56,849][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:57,065][root][INFO] - Training Epoch: 1/2, step 1669/53949 completed (loss: 1.3141931295394897, acc: 0.699999988079071)
[2025-02-17 17:46:57,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:57,434][root][INFO] - Training Epoch: 1/2, step 1670/53949 completed (loss: 0.6929225325584412, acc: 0.8636363744735718)
[2025-02-17 17:46:57,570][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:57,782][root][INFO] - Training Epoch: 1/2, step 1671/53949 completed (loss: 0.5147725939750671, acc: 0.8235294222831726)
[2025-02-17 17:46:57,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:58,128][root][INFO] - Training Epoch: 1/2, step 1672/53949 completed (loss: 0.6088336110115051, acc: 0.8279569745063782)
[2025-02-17 17:46:58,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:58,495][root][INFO] - Training Epoch: 1/2, step 1673/53949 completed (loss: 0.5586718916893005, acc: 0.8369565010070801)
[2025-02-17 17:46:58,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:58,829][root][INFO] - Training Epoch: 1/2, step 1674/53949 completed (loss: 0.6122374534606934, acc: 0.8125)
[2025-02-17 17:46:58,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:59,208][root][INFO] - Training Epoch: 1/2, step 1675/53949 completed (loss: 0.6707927584648132, acc: 0.8051947951316833)
[2025-02-17 17:46:59,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:59,555][root][INFO] - Training Epoch: 1/2, step 1676/53949 completed (loss: 0.4754951596260071, acc: 0.8631578683853149)
[2025-02-17 17:46:59,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:59,912][root][INFO] - Training Epoch: 1/2, step 1677/53949 completed (loss: 0.74615478515625, acc: 0.8333333134651184)
[2025-02-17 17:47:00,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:00,251][root][INFO] - Training Epoch: 1/2, step 1678/53949 completed (loss: 1.0840837955474854, acc: 0.800000011920929)
[2025-02-17 17:47:00,388][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:00,600][root][INFO] - Training Epoch: 1/2, step 1679/53949 completed (loss: 0.5748611688613892, acc: 0.8666666746139526)
[2025-02-17 17:47:00,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:00,972][root][INFO] - Training Epoch: 1/2, step 1680/53949 completed (loss: 0.5159156918525696, acc: 0.8235294222831726)
[2025-02-17 17:47:01,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:01,327][root][INFO] - Training Epoch: 1/2, step 1681/53949 completed (loss: 0.3624175786972046, acc: 0.9166666865348816)
[2025-02-17 17:47:01,492][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:01,704][root][INFO] - Training Epoch: 1/2, step 1682/53949 completed (loss: 0.4213021695613861, acc: 0.8709677457809448)
[2025-02-17 17:47:01,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:02,043][root][INFO] - Training Epoch: 1/2, step 1683/53949 completed (loss: 0.23949480056762695, acc: 0.9506173133850098)
[2025-02-17 17:47:02,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:02,404][root][INFO] - Training Epoch: 1/2, step 1684/53949 completed (loss: 0.3872252106666565, acc: 0.8444444537162781)
[2025-02-17 17:47:02,540][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:02,746][root][INFO] - Training Epoch: 1/2, step 1685/53949 completed (loss: 0.20311787724494934, acc: 0.949367105960846)
[2025-02-17 17:47:02,882][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:03,100][root][INFO] - Training Epoch: 1/2, step 1686/53949 completed (loss: 0.5257111191749573, acc: 0.8554216623306274)
[2025-02-17 17:47:03,239][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:03,449][root][INFO] - Training Epoch: 1/2, step 1687/53949 completed (loss: 0.5312435030937195, acc: 0.8468468189239502)
[2025-02-17 17:47:03,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:03,871][root][INFO] - Training Epoch: 1/2, step 1688/53949 completed (loss: 1.0114362239837646, acc: 0.800000011920929)
[2025-02-17 17:47:04,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:04,254][root][INFO] - Training Epoch: 1/2, step 1689/53949 completed (loss: 0.5518975853919983, acc: 0.8275862336158752)
[2025-02-17 17:47:04,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:04,614][root][INFO] - Training Epoch: 1/2, step 1690/53949 completed (loss: 0.45699796080589294, acc: 0.8518518805503845)
[2025-02-17 17:47:04,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:04,962][root][INFO] - Training Epoch: 1/2, step 1691/53949 completed (loss: 0.7690932750701904, acc: 0.800000011920929)
[2025-02-17 17:47:05,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:05,307][root][INFO] - Training Epoch: 1/2, step 1692/53949 completed (loss: 0.8628313541412354, acc: 0.7884615659713745)
[2025-02-17 17:47:05,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:05,704][root][INFO] - Training Epoch: 1/2, step 1693/53949 completed (loss: 0.4259067475795746, acc: 0.907216489315033)
[2025-02-17 17:47:05,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:06,080][root][INFO] - Training Epoch: 1/2, step 1694/53949 completed (loss: 2.1472504138946533, acc: 0.5)
[2025-02-17 17:47:06,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:06,542][root][INFO] - Training Epoch: 1/2, step 1695/53949 completed (loss: 0.6373173594474792, acc: 0.8020833134651184)
[2025-02-17 17:47:06,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:06,919][root][INFO] - Training Epoch: 1/2, step 1696/53949 completed (loss: 0.3927114009857178, acc: 0.9130434989929199)
[2025-02-17 17:47:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:07,256][root][INFO] - Training Epoch: 1/2, step 1697/53949 completed (loss: 0.49834969639778137, acc: 0.8333333134651184)
[2025-02-17 17:47:07,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:07,632][root][INFO] - Training Epoch: 1/2, step 1698/53949 completed (loss: 0.9248691201210022, acc: 0.800000011920929)
[2025-02-17 17:47:07,774][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:07,987][root][INFO] - Training Epoch: 1/2, step 1699/53949 completed (loss: 0.679050087928772, acc: 0.8053691387176514)
[2025-02-17 17:47:08,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:08,350][root][INFO] - Training Epoch: 1/2, step 1700/53949 completed (loss: 0.6525607109069824, acc: 0.7570093274116516)
[2025-02-17 17:47:08,528][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:08,805][root][INFO] - Training Epoch: 1/2, step 1701/53949 completed (loss: 0.45564472675323486, acc: 0.8421052694320679)
[2025-02-17 17:47:08,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:09,198][root][INFO] - Training Epoch: 1/2, step 1702/53949 completed (loss: 0.6342437863349915, acc: 0.7941176295280457)
[2025-02-17 17:47:09,373][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:09,603][root][INFO] - Training Epoch: 1/2, step 1703/53949 completed (loss: 1.2432708740234375, acc: 0.6363636255264282)
[2025-02-17 17:47:09,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:09,981][root][INFO] - Training Epoch: 1/2, step 1704/53949 completed (loss: 0.4690104126930237, acc: 0.875)
[2025-02-17 17:47:10,171][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:10,371][root][INFO] - Training Epoch: 1/2, step 1705/53949 completed (loss: 0.35987013578414917, acc: 0.8444444537162781)
[2025-02-17 17:47:10,517][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:10,732][root][INFO] - Training Epoch: 1/2, step 1706/53949 completed (loss: 0.6981738805770874, acc: 0.8113207817077637)
[2025-02-17 17:47:10,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:11,098][root][INFO] - Training Epoch: 1/2, step 1707/53949 completed (loss: 0.5918952822685242, acc: 0.8348624110221863)
[2025-02-17 17:47:11,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:11,458][root][INFO] - Training Epoch: 1/2, step 1708/53949 completed (loss: 0.6080847382545471, acc: 0.8421052694320679)
[2025-02-17 17:47:11,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:11,796][root][INFO] - Training Epoch: 1/2, step 1709/53949 completed (loss: 0.6543940901756287, acc: 0.8461538553237915)
[2025-02-17 17:47:11,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:12,155][root][INFO] - Training Epoch: 1/2, step 1710/53949 completed (loss: 0.4043557047843933, acc: 0.8943089246749878)
[2025-02-17 17:47:12,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:12,539][root][INFO] - Training Epoch: 1/2, step 1711/53949 completed (loss: 0.3666970133781433, acc: 0.9090909361839294)
[2025-02-17 17:47:12,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:12,915][root][INFO] - Training Epoch: 1/2, step 1712/53949 completed (loss: 0.8858650326728821, acc: 0.7857142686843872)
[2025-02-17 17:47:13,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:13,254][root][INFO] - Training Epoch: 1/2, step 1713/53949 completed (loss: 0.7773997783660889, acc: 0.7745097875595093)
[2025-02-17 17:47:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:13,603][root][INFO] - Training Epoch: 1/2, step 1714/53949 completed (loss: 0.95684814453125, acc: 0.7948718070983887)
[2025-02-17 17:47:13,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:13,944][root][INFO] - Training Epoch: 1/2, step 1715/53949 completed (loss: 0.3341902196407318, acc: 0.9333333373069763)
[2025-02-17 17:47:14,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:14,288][root][INFO] - Training Epoch: 1/2, step 1716/53949 completed (loss: 0.7689732909202576, acc: 0.8235294222831726)
[2025-02-17 17:47:14,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:14,644][root][INFO] - Training Epoch: 1/2, step 1717/53949 completed (loss: 0.8388561010360718, acc: 0.8181818127632141)
[2025-02-17 17:47:14,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:15,033][root][INFO] - Training Epoch: 1/2, step 1718/53949 completed (loss: 0.5387733578681946, acc: 0.8522727489471436)
[2025-02-17 17:47:15,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:15,422][root][INFO] - Training Epoch: 1/2, step 1719/53949 completed (loss: 0.8025904893875122, acc: 0.7333333492279053)
[2025-02-17 17:47:15,589][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:15,798][root][INFO] - Training Epoch: 1/2, step 1720/53949 completed (loss: 0.4490770101547241, acc: 0.9032257795333862)
[2025-02-17 17:47:15,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:16,159][root][INFO] - Training Epoch: 1/2, step 1721/53949 completed (loss: 0.9951989054679871, acc: 0.7230769395828247)
[2025-02-17 17:47:16,335][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:16,554][root][INFO] - Training Epoch: 1/2, step 1722/53949 completed (loss: 0.5879868865013123, acc: 0.8187134265899658)
[2025-02-17 17:47:16,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:16,929][root][INFO] - Training Epoch: 1/2, step 1723/53949 completed (loss: 0.19002453982830048, acc: 1.0)
[2025-02-17 17:47:17,064][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:17,275][root][INFO] - Training Epoch: 1/2, step 1724/53949 completed (loss: 0.22610428929328918, acc: 0.9215686321258545)
[2025-02-17 17:47:17,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:17,620][root][INFO] - Training Epoch: 1/2, step 1725/53949 completed (loss: 0.8493167757987976, acc: 0.8085106611251831)
[2025-02-17 17:47:17,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:17,972][root][INFO] - Training Epoch: 1/2, step 1726/53949 completed (loss: 0.4926266074180603, acc: 0.8839285969734192)
[2025-02-17 17:47:18,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:18,347][root][INFO] - Training Epoch: 1/2, step 1727/53949 completed (loss: 0.26355886459350586, acc: 0.9436619877815247)
[2025-02-17 17:47:18,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:18,703][root][INFO] - Training Epoch: 1/2, step 1728/53949 completed (loss: 0.30159950256347656, acc: 0.800000011920929)
[2025-02-17 17:47:18,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:19,080][root][INFO] - Training Epoch: 1/2, step 1729/53949 completed (loss: 0.5073114633560181, acc: 0.8500000238418579)
[2025-02-17 17:47:19,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:19,447][root][INFO] - Training Epoch: 1/2, step 1730/53949 completed (loss: 0.2564890682697296, acc: 0.9285714030265808)
[2025-02-17 17:47:19,582][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:19,799][root][INFO] - Training Epoch: 1/2, step 1731/53949 completed (loss: 0.4273350238800049, acc: 0.8695651888847351)
[2025-02-17 17:47:19,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:20,150][root][INFO] - Training Epoch: 1/2, step 1732/53949 completed (loss: 0.6426130533218384, acc: 0.8235294222831726)
[2025-02-17 17:47:20,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:20,562][root][INFO] - Training Epoch: 1/2, step 1733/53949 completed (loss: 0.644877016544342, acc: 0.8157894611358643)
[2025-02-17 17:47:20,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:20,912][root][INFO] - Training Epoch: 1/2, step 1734/53949 completed (loss: 0.504143476486206, acc: 0.8666666746139526)
[2025-02-17 17:47:21,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:21,253][root][INFO] - Training Epoch: 1/2, step 1735/53949 completed (loss: 0.6920962929725647, acc: 0.7837837934494019)
[2025-02-17 17:47:21,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:21,609][root][INFO] - Training Epoch: 1/2, step 1736/53949 completed (loss: 0.46133187413215637, acc: 0.8181818127632141)
[2025-02-17 17:47:21,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:21,965][root][INFO] - Training Epoch: 1/2, step 1737/53949 completed (loss: 0.25857433676719666, acc: 0.9512194991111755)
[2025-02-17 17:47:22,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:22,308][root][INFO] - Training Epoch: 1/2, step 1738/53949 completed (loss: 0.8295749425888062, acc: 0.71875)
[2025-02-17 17:47:22,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:22,654][root][INFO] - Training Epoch: 1/2, step 1739/53949 completed (loss: 0.35976168513298035, acc: 0.9333333373069763)
[2025-02-17 17:47:22,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:23,012][root][INFO] - Training Epoch: 1/2, step 1740/53949 completed (loss: 0.5566328167915344, acc: 0.8163265585899353)
[2025-02-17 17:47:23,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:23,351][root][INFO] - Training Epoch: 1/2, step 1741/53949 completed (loss: 1.054885745048523, acc: 0.7560975551605225)
[2025-02-17 17:47:23,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:23,740][root][INFO] - Training Epoch: 1/2, step 1742/53949 completed (loss: 0.759606122970581, acc: 0.7910447716712952)
[2025-02-17 17:47:23,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:24,112][root][INFO] - Training Epoch: 1/2, step 1743/53949 completed (loss: 0.5775211453437805, acc: 0.8306451439857483)
[2025-02-17 17:47:24,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:24,543][root][INFO] - Training Epoch: 1/2, step 1744/53949 completed (loss: 0.47230589389801025, acc: 0.8571428656578064)
[2025-02-17 17:47:24,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:24,952][root][INFO] - Training Epoch: 1/2, step 1745/53949 completed (loss: 0.5299331545829773, acc: 0.84112149477005)
[2025-02-17 17:47:25,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:25,293][root][INFO] - Training Epoch: 1/2, step 1746/53949 completed (loss: 0.9941120743751526, acc: 0.692307710647583)
[2025-02-17 17:47:25,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:25,655][root][INFO] - Training Epoch: 1/2, step 1747/53949 completed (loss: 0.596620500087738, acc: 0.8702290058135986)
[2025-02-17 17:47:25,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:26,014][root][INFO] - Training Epoch: 1/2, step 1748/53949 completed (loss: 0.4543718099594116, acc: 0.8690476417541504)
[2025-02-17 17:47:26,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:26,367][root][INFO] - Training Epoch: 1/2, step 1749/53949 completed (loss: 0.46687519550323486, acc: 0.8636363744735718)
[2025-02-17 17:47:26,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:26,769][root][INFO] - Training Epoch: 1/2, step 1750/53949 completed (loss: 0.07437208294868469, acc: 1.0)
[2025-02-17 17:47:26,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:27,180][root][INFO] - Training Epoch: 1/2, step 1751/53949 completed (loss: 0.5343901515007019, acc: 0.7948718070983887)
[2025-02-17 17:47:27,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:27,595][root][INFO] - Training Epoch: 1/2, step 1752/53949 completed (loss: 0.8816164135932922, acc: 0.7653061151504517)
[2025-02-17 17:47:27,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:27,959][root][INFO] - Training Epoch: 1/2, step 1753/53949 completed (loss: 0.5815869569778442, acc: 0.7931034564971924)
[2025-02-17 17:47:28,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:28,367][root][INFO] - Training Epoch: 1/2, step 1754/53949 completed (loss: 0.7286177277565002, acc: 0.8271604776382446)
[2025-02-17 17:47:28,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:28,806][root][INFO] - Training Epoch: 1/2, step 1755/53949 completed (loss: 0.950242280960083, acc: 0.6818181872367859)
[2025-02-17 17:47:28,996][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:29,221][root][INFO] - Training Epoch: 1/2, step 1756/53949 completed (loss: 0.4729863405227661, acc: 0.8488371968269348)
[2025-02-17 17:47:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:29,695][root][INFO] - Training Epoch: 1/2, step 1757/53949 completed (loss: 0.5511341691017151, acc: 0.8535031676292419)
[2025-02-17 17:47:29,842][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:30,072][root][INFO] - Training Epoch: 1/2, step 1758/53949 completed (loss: 0.5570326447486877, acc: 0.9230769276618958)
[2025-02-17 17:47:30,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:30,457][root][INFO] - Training Epoch: 1/2, step 1759/53949 completed (loss: 0.3261372745037079, acc: 0.9230769276618958)
[2025-02-17 17:47:30,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:30,830][root][INFO] - Training Epoch: 1/2, step 1760/53949 completed (loss: 0.41212883591651917, acc: 0.8916666507720947)
[2025-02-17 17:47:30,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:31,178][root][INFO] - Training Epoch: 1/2, step 1761/53949 completed (loss: 0.3030894696712494, acc: 0.9047619104385376)
[2025-02-17 17:47:31,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:31,595][root][INFO] - Training Epoch: 1/2, step 1762/53949 completed (loss: 0.5466777086257935, acc: 0.843137264251709)
[2025-02-17 17:47:31,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:32,029][root][INFO] - Training Epoch: 1/2, step 1763/53949 completed (loss: 0.38309788703918457, acc: 0.8571428656578064)
[2025-02-17 17:47:32,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:32,396][root][INFO] - Training Epoch: 1/2, step 1764/53949 completed (loss: 0.49495357275009155, acc: 0.8571428656578064)
[2025-02-17 17:47:32,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:32,730][root][INFO] - Training Epoch: 1/2, step 1765/53949 completed (loss: 0.3342505395412445, acc: 0.8962264060974121)
[2025-02-17 17:47:32,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:33,110][root][INFO] - Training Epoch: 1/2, step 1766/53949 completed (loss: 1.0618345737457275, acc: 0.7714285850524902)
[2025-02-17 17:47:33,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:33,514][root][INFO] - Training Epoch: 1/2, step 1767/53949 completed (loss: 0.3234855532646179, acc: 0.8214285969734192)
[2025-02-17 17:47:33,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:33,924][root][INFO] - Training Epoch: 1/2, step 1768/53949 completed (loss: 0.7071027159690857, acc: 0.8354430198669434)
[2025-02-17 17:47:34,080][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:34,295][root][INFO] - Training Epoch: 1/2, step 1769/53949 completed (loss: 0.8544707894325256, acc: 0.7916666865348816)
[2025-02-17 17:47:34,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:34,657][root][INFO] - Training Epoch: 1/2, step 1770/53949 completed (loss: 0.6313238143920898, acc: 0.7820512652397156)
[2025-02-17 17:47:34,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:35,010][root][INFO] - Training Epoch: 1/2, step 1771/53949 completed (loss: 1.0722111463546753, acc: 0.6666666865348816)
[2025-02-17 17:47:35,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:35,358][root][INFO] - Training Epoch: 1/2, step 1772/53949 completed (loss: 3.288907766342163, acc: 0.3333333432674408)
[2025-02-17 17:47:35,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:35,715][root][INFO] - Training Epoch: 1/2, step 1773/53949 completed (loss: 0.6238049864768982, acc: 0.8148148059844971)
[2025-02-17 17:47:35,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:36,123][root][INFO] - Training Epoch: 1/2, step 1774/53949 completed (loss: 0.5107848644256592, acc: 0.8272727131843567)
[2025-02-17 17:47:36,291][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:36,517][root][INFO] - Training Epoch: 1/2, step 1775/53949 completed (loss: 1.2080016136169434, acc: 0.699999988079071)
[2025-02-17 17:47:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:36,906][root][INFO] - Training Epoch: 1/2, step 1776/53949 completed (loss: 0.3084246814250946, acc: 0.9104477763175964)
[2025-02-17 17:47:37,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:37,266][root][INFO] - Training Epoch: 1/2, step 1777/53949 completed (loss: 0.8273810744285583, acc: 0.7799999713897705)
[2025-02-17 17:47:37,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:37,691][root][INFO] - Training Epoch: 1/2, step 1778/53949 completed (loss: 0.6082583069801331, acc: 0.8728813529014587)
[2025-02-17 17:47:37,894][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:38,107][root][INFO] - Training Epoch: 1/2, step 1779/53949 completed (loss: 0.14680825173854828, acc: 1.0)
[2025-02-17 17:47:38,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:38,541][root][INFO] - Training Epoch: 1/2, step 1780/53949 completed (loss: 0.45354312658309937, acc: 0.8799999952316284)
[2025-02-17 17:47:38,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:38,915][root][INFO] - Training Epoch: 1/2, step 1781/53949 completed (loss: 0.19764894247055054, acc: 0.9253731369972229)
[2025-02-17 17:47:39,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:39,272][root][INFO] - Training Epoch: 1/2, step 1782/53949 completed (loss: 1.2998294830322266, acc: 0.5714285969734192)
[2025-02-17 17:47:39,456][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:39,693][root][INFO] - Training Epoch: 1/2, step 1783/53949 completed (loss: 0.6463263630867004, acc: 0.8399999737739563)
[2025-02-17 17:47:39,865][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:40,080][root][INFO] - Training Epoch: 1/2, step 1784/53949 completed (loss: 0.48741060495376587, acc: 0.8461538553237915)
[2025-02-17 17:47:40,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:40,429][root][INFO] - Training Epoch: 1/2, step 1785/53949 completed (loss: 0.11166480928659439, acc: 1.0)
[2025-02-17 17:47:40,563][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:40,777][root][INFO] - Training Epoch: 1/2, step 1786/53949 completed (loss: 0.30626875162124634, acc: 0.9130434989929199)
[2025-02-17 17:47:40,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:41,134][root][INFO] - Training Epoch: 1/2, step 1787/53949 completed (loss: 0.04779446870088577, acc: 1.0)
[2025-02-17 17:47:41,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:41,494][root][INFO] - Training Epoch: 1/2, step 1788/53949 completed (loss: 0.4218428134918213, acc: 0.8333333134651184)
[2025-02-17 17:47:41,627][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:41,841][root][INFO] - Training Epoch: 1/2, step 1789/53949 completed (loss: 0.6195845603942871, acc: 0.8450704216957092)
[2025-02-17 17:47:41,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:42,199][root][INFO] - Training Epoch: 1/2, step 1790/53949 completed (loss: 0.3655183017253876, acc: 0.8933333158493042)
[2025-02-17 17:47:42,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:42,548][root][INFO] - Training Epoch: 1/2, step 1791/53949 completed (loss: 0.5478698015213013, acc: 0.800000011920929)
[2025-02-17 17:47:42,705][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:42,918][root][INFO] - Training Epoch: 1/2, step 1792/53949 completed (loss: 0.7161545753479004, acc: 0.8428571224212646)
[2025-02-17 17:47:43,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:43,264][root][INFO] - Training Epoch: 1/2, step 1793/53949 completed (loss: 1.0903393030166626, acc: 0.774193525314331)
[2025-02-17 17:47:43,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:43,641][root][INFO] - Training Epoch: 1/2, step 1794/53949 completed (loss: 0.2225673645734787, acc: 0.949999988079071)
[2025-02-17 17:47:43,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:43,984][root][INFO] - Training Epoch: 1/2, step 1795/53949 completed (loss: 0.8981212377548218, acc: 0.7976190447807312)
[2025-02-17 17:47:44,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:44,326][root][INFO] - Training Epoch: 1/2, step 1796/53949 completed (loss: 0.45900586247444153, acc: 0.8222222328186035)
[2025-02-17 17:47:44,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:44,669][root][INFO] - Training Epoch: 1/2, step 1797/53949 completed (loss: 0.9268942475318909, acc: 0.7777777910232544)
[2025-02-17 17:47:44,835][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:45,047][root][INFO] - Training Epoch: 1/2, step 1798/53949 completed (loss: 0.7536150217056274, acc: 0.7702702879905701)
[2025-02-17 17:47:45,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:45,409][root][INFO] - Training Epoch: 1/2, step 1799/53949 completed (loss: 0.49094080924987793, acc: 0.8617886304855347)
[2025-02-17 17:47:45,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:45,819][root][INFO] - Training Epoch: 1/2, step 1800/53949 completed (loss: 0.6525039672851562, acc: 0.7450980544090271)
[2025-02-17 17:47:45,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:46,212][root][INFO] - Training Epoch: 1/2, step 1801/53949 completed (loss: 0.8985079526901245, acc: 0.7424242496490479)
[2025-02-17 17:47:46,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:46,579][root][INFO] - Training Epoch: 1/2, step 1802/53949 completed (loss: 0.7649766802787781, acc: 0.7162162065505981)
[2025-02-17 17:47:46,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:46,933][root][INFO] - Training Epoch: 1/2, step 1803/53949 completed (loss: 0.5371446013450623, acc: 0.8522727489471436)
[2025-02-17 17:47:47,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:47,314][root][INFO] - Training Epoch: 1/2, step 1804/53949 completed (loss: 1.0513560771942139, acc: 0.6818181872367859)
[2025-02-17 17:47:47,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:47,737][root][INFO] - Training Epoch: 1/2, step 1805/53949 completed (loss: 0.9990795850753784, acc: 0.8064516186714172)
[2025-02-17 17:47:47,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:48,107][root][INFO] - Training Epoch: 1/2, step 1806/53949 completed (loss: 0.6474480032920837, acc: 0.8333333134651184)
[2025-02-17 17:47:48,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:48,500][root][INFO] - Training Epoch: 1/2, step 1807/53949 completed (loss: 0.6422063112258911, acc: 0.8387096524238586)
[2025-02-17 17:47:48,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:48,858][root][INFO] - Training Epoch: 1/2, step 1808/53949 completed (loss: 0.6574180722236633, acc: 0.8260869383811951)
[2025-02-17 17:47:48,996][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:49,205][root][INFO] - Training Epoch: 1/2, step 1809/53949 completed (loss: 0.6609177589416504, acc: 0.813725471496582)
[2025-02-17 17:47:49,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:49,615][root][INFO] - Training Epoch: 1/2, step 1810/53949 completed (loss: 0.2656957507133484, acc: 1.0)
[2025-02-17 17:47:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:49,969][root][INFO] - Training Epoch: 1/2, step 1811/53949 completed (loss: 0.9105257987976074, acc: 0.7142857313156128)
[2025-02-17 17:47:50,105][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:50,319][root][INFO] - Training Epoch: 1/2, step 1812/53949 completed (loss: 0.46666452288627625, acc: 0.8799999952316284)
[2025-02-17 17:47:50,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:50,679][root][INFO] - Training Epoch: 1/2, step 1813/53949 completed (loss: 0.6925771832466125, acc: 0.800000011920929)
[2025-02-17 17:47:50,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:51,102][root][INFO] - Training Epoch: 1/2, step 1814/53949 completed (loss: 0.50178462266922, acc: 0.8714285492897034)
[2025-02-17 17:47:51,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:51,518][root][INFO] - Training Epoch: 1/2, step 1815/53949 completed (loss: 0.6303733587265015, acc: 0.8333333134651184)
[2025-02-17 17:47:51,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:51,922][root][INFO] - Training Epoch: 1/2, step 1816/53949 completed (loss: 0.5652584433555603, acc: 0.8850574493408203)
[2025-02-17 17:47:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:52,271][root][INFO] - Training Epoch: 1/2, step 1817/53949 completed (loss: 0.6274062395095825, acc: 0.8571428656578064)
[2025-02-17 17:47:52,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:52,665][root][INFO] - Training Epoch: 1/2, step 1818/53949 completed (loss: 0.5371864438056946, acc: 0.8780487775802612)
[2025-02-17 17:47:52,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:53,011][root][INFO] - Training Epoch: 1/2, step 1819/53949 completed (loss: 1.2805520296096802, acc: 0.6086956262588501)
[2025-02-17 17:47:53,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:53,435][root][INFO] - Training Epoch: 1/2, step 1820/53949 completed (loss: 0.4249677360057831, acc: 0.8756756782531738)
[2025-02-17 17:47:53,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:53,770][root][INFO] - Training Epoch: 1/2, step 1821/53949 completed (loss: 0.7397403120994568, acc: 0.800000011920929)
[2025-02-17 17:47:53,905][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:54,118][root][INFO] - Training Epoch: 1/2, step 1822/53949 completed (loss: 0.8990620374679565, acc: 0.8461538553237915)
[2025-02-17 17:47:54,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:54,468][root][INFO] - Training Epoch: 1/2, step 1823/53949 completed (loss: 0.5025221705436707, acc: 0.8585858345031738)
[2025-02-17 17:47:54,601][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:54,812][root][INFO] - Training Epoch: 1/2, step 1824/53949 completed (loss: 0.7128726243972778, acc: 0.8041236996650696)
[2025-02-17 17:47:54,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:55,155][root][INFO] - Training Epoch: 1/2, step 1825/53949 completed (loss: 0.2125367373228073, acc: 0.9444444179534912)
[2025-02-17 17:47:55,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:55,512][root][INFO] - Training Epoch: 1/2, step 1826/53949 completed (loss: 0.3163239061832428, acc: 0.9259259104728699)
[2025-02-17 17:47:55,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:55,896][root][INFO] - Training Epoch: 1/2, step 1827/53949 completed (loss: 0.453843355178833, acc: 0.89673912525177)
[2025-02-17 17:47:56,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:56,312][root][INFO] - Training Epoch: 1/2, step 1828/53949 completed (loss: 0.3608572781085968, acc: 0.8888888955116272)
[2025-02-17 17:47:56,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:56,690][root][INFO] - Training Epoch: 1/2, step 1829/53949 completed (loss: 0.7387048006057739, acc: 0.8105263113975525)
[2025-02-17 17:47:56,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:57,079][root][INFO] - Training Epoch: 1/2, step 1830/53949 completed (loss: 0.4671441912651062, acc: 0.8571428656578064)
[2025-02-17 17:47:57,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:57,481][root][INFO] - Training Epoch: 1/2, step 1831/53949 completed (loss: 0.4071071445941925, acc: 0.8651685118675232)
[2025-02-17 17:47:57,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:57,866][root][INFO] - Training Epoch: 1/2, step 1832/53949 completed (loss: 0.41676145792007446, acc: 0.8783068656921387)
[2025-02-17 17:47:58,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:58,301][root][INFO] - Training Epoch: 1/2, step 1833/53949 completed (loss: 0.5340061187744141, acc: 0.8315789699554443)
[2025-02-17 17:47:58,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:58,708][root][INFO] - Training Epoch: 1/2, step 1834/53949 completed (loss: 0.8312985301017761, acc: 0.7307692170143127)
[2025-02-17 17:47:58,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:59,091][root][INFO] - Training Epoch: 1/2, step 1835/53949 completed (loss: 0.5640603303909302, acc: 0.8365384340286255)
[2025-02-17 17:47:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:59,430][root][INFO] - Training Epoch: 1/2, step 1836/53949 completed (loss: 0.6311086416244507, acc: 0.8125)
[2025-02-17 17:47:59,569][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:59,746][root][INFO] - Training Epoch: 1/2, step 1837/53949 completed (loss: 0.5440393686294556, acc: 0.8571428656578064)
[2025-02-17 17:47:59,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:00,134][root][INFO] - Training Epoch: 1/2, step 1838/53949 completed (loss: 1.0249937772750854, acc: 0.7444444298744202)
[2025-02-17 17:48:00,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:00,525][root][INFO] - Training Epoch: 1/2, step 1839/53949 completed (loss: 0.4347817599773407, acc: 0.8999999761581421)
[2025-02-17 17:48:00,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:00,881][root][INFO] - Training Epoch: 1/2, step 1840/53949 completed (loss: 0.7053274512290955, acc: 0.8484848737716675)
[2025-02-17 17:48:01,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:01,266][root][INFO] - Training Epoch: 1/2, step 1841/53949 completed (loss: 1.0098416805267334, acc: 0.7352941036224365)
[2025-02-17 17:48:01,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:01,640][root][INFO] - Training Epoch: 1/2, step 1842/53949 completed (loss: 0.5890171527862549, acc: 0.8153846263885498)
[2025-02-17 17:48:01,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:02,051][root][INFO] - Training Epoch: 1/2, step 1843/53949 completed (loss: 0.2514204680919647, acc: 0.875)
[2025-02-17 17:48:02,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:02,466][root][INFO] - Training Epoch: 1/2, step 1844/53949 completed (loss: 0.7497290372848511, acc: 0.7777777910232544)
[2025-02-17 17:48:02,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:02,875][root][INFO] - Training Epoch: 1/2, step 1845/53949 completed (loss: 0.76523357629776, acc: 0.8115941882133484)
[2025-02-17 17:48:03,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:03,285][root][INFO] - Training Epoch: 1/2, step 1846/53949 completed (loss: 1.054125428199768, acc: 0.7799999713897705)
[2025-02-17 17:48:03,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:03,652][root][INFO] - Training Epoch: 1/2, step 1847/53949 completed (loss: 0.43752390146255493, acc: 0.8809523582458496)
[2025-02-17 17:48:03,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:04,011][root][INFO] - Training Epoch: 1/2, step 1848/53949 completed (loss: 0.787567675113678, acc: 0.8666666746139526)
[2025-02-17 17:48:04,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:04,376][root][INFO] - Training Epoch: 1/2, step 1849/53949 completed (loss: 0.17772331833839417, acc: 0.949999988079071)
[2025-02-17 17:48:04,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:04,795][root][INFO] - Training Epoch: 1/2, step 1850/53949 completed (loss: 0.5562310218811035, acc: 0.8225806355476379)
[2025-02-17 17:48:04,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:05,165][root][INFO] - Training Epoch: 1/2, step 1851/53949 completed (loss: 0.8875349164009094, acc: 0.7567567825317383)
[2025-02-17 17:48:05,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:05,531][root][INFO] - Training Epoch: 1/2, step 1852/53949 completed (loss: 0.4551449716091156, acc: 0.8333333134651184)
[2025-02-17 17:48:05,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:05,890][root][INFO] - Training Epoch: 1/2, step 1853/53949 completed (loss: 0.2101811319589615, acc: 0.9605262875556946)
[2025-02-17 17:48:06,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:06,284][root][INFO] - Training Epoch: 1/2, step 1854/53949 completed (loss: 0.4973168671131134, acc: 0.8571428656578064)
[2025-02-17 17:48:06,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:06,649][root][INFO] - Training Epoch: 1/2, step 1855/53949 completed (loss: 0.6758436560630798, acc: 0.8260869383811951)
[2025-02-17 17:48:06,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:07,009][root][INFO] - Training Epoch: 1/2, step 1856/53949 completed (loss: 1.0180246829986572, acc: 0.800000011920929)
[2025-02-17 17:48:07,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:07,389][root][INFO] - Training Epoch: 1/2, step 1857/53949 completed (loss: 0.5118770599365234, acc: 0.8701298832893372)
[2025-02-17 17:48:07,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:07,754][root][INFO] - Training Epoch: 1/2, step 1858/53949 completed (loss: 0.4789949953556061, acc: 0.8974359035491943)
[2025-02-17 17:48:07,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:08,154][root][INFO] - Training Epoch: 1/2, step 1859/53949 completed (loss: 0.45970067381858826, acc: 0.8157894611358643)
[2025-02-17 17:48:08,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:08,527][root][INFO] - Training Epoch: 1/2, step 1860/53949 completed (loss: 0.38527947664260864, acc: 0.8863636255264282)
[2025-02-17 17:48:08,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:08,920][root][INFO] - Training Epoch: 1/2, step 1861/53949 completed (loss: 0.030095500871539116, acc: 1.0)
[2025-02-17 17:48:09,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:09,326][root][INFO] - Training Epoch: 1/2, step 1862/53949 completed (loss: 0.7068528532981873, acc: 0.7857142686843872)
[2025-02-17 17:48:09,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:09,695][root][INFO] - Training Epoch: 1/2, step 1863/53949 completed (loss: 0.7143958210945129, acc: 0.8018018007278442)
[2025-02-17 17:48:09,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:10,068][root][INFO] - Training Epoch: 1/2, step 1864/53949 completed (loss: 0.06613805145025253, acc: 1.0)
[2025-02-17 17:48:10,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:10,430][root][INFO] - Training Epoch: 1/2, step 1865/53949 completed (loss: 0.7060185074806213, acc: 0.8170731663703918)
[2025-02-17 17:48:10,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:10,850][root][INFO] - Training Epoch: 1/2, step 1866/53949 completed (loss: 0.5222468376159668, acc: 0.8666666746139526)
[2025-02-17 17:48:11,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:11,262][root][INFO] - Training Epoch: 1/2, step 1867/53949 completed (loss: 0.4370454251766205, acc: 0.9107142686843872)
[2025-02-17 17:48:11,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:11,668][root][INFO] - Training Epoch: 1/2, step 1868/53949 completed (loss: 0.3706994652748108, acc: 0.9054054021835327)
[2025-02-17 17:48:11,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:12,057][root][INFO] - Training Epoch: 1/2, step 1869/53949 completed (loss: 0.6649298071861267, acc: 0.7758620977401733)
[2025-02-17 17:48:12,209][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:12,425][root][INFO] - Training Epoch: 1/2, step 1870/53949 completed (loss: 0.5097514390945435, acc: 0.8374999761581421)
[2025-02-17 17:48:12,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:12,816][root][INFO] - Training Epoch: 1/2, step 1871/53949 completed (loss: 0.30948126316070557, acc: 0.9268292784690857)
[2025-02-17 17:48:13,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:13,219][root][INFO] - Training Epoch: 1/2, step 1872/53949 completed (loss: 0.37992075085639954, acc: 0.8461538553237915)
[2025-02-17 17:48:13,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:13,585][root][INFO] - Training Epoch: 1/2, step 1873/53949 completed (loss: 0.5947754383087158, acc: 0.8333333134651184)
[2025-02-17 17:48:13,723][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:13,980][root][INFO] - Training Epoch: 1/2, step 1874/53949 completed (loss: 0.8931266069412231, acc: 0.7777777910232544)
[2025-02-17 17:48:14,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:14,434][root][INFO] - Training Epoch: 1/2, step 1875/53949 completed (loss: 0.30399835109710693, acc: 0.8909090757369995)
[2025-02-17 17:48:14,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:14,790][root][INFO] - Training Epoch: 1/2, step 1876/53949 completed (loss: 0.6112348437309265, acc: 0.8548387289047241)
[2025-02-17 17:48:14,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:15,198][root][INFO] - Training Epoch: 1/2, step 1877/53949 completed (loss: 0.40451160073280334, acc: 0.8611111044883728)
[2025-02-17 17:48:15,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:15,566][root][INFO] - Training Epoch: 1/2, step 1878/53949 completed (loss: 0.47014424204826355, acc: 0.8723404407501221)
[2025-02-17 17:48:15,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:15,978][root][INFO] - Training Epoch: 1/2, step 1879/53949 completed (loss: 0.7799976468086243, acc: 0.7179487347602844)
[2025-02-17 17:48:16,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:16,328][root][INFO] - Training Epoch: 1/2, step 1880/53949 completed (loss: 0.1331150382757187, acc: 0.9629629850387573)
[2025-02-17 17:48:16,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:16,691][root][INFO] - Training Epoch: 1/2, step 1881/53949 completed (loss: 0.6923787593841553, acc: 0.800000011920929)
[2025-02-17 17:48:16,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:17,102][root][INFO] - Training Epoch: 1/2, step 1882/53949 completed (loss: 0.3872421085834503, acc: 0.904411792755127)
[2025-02-17 17:48:17,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:17,456][root][INFO] - Training Epoch: 1/2, step 1883/53949 completed (loss: 1.1527233123779297, acc: 0.7115384340286255)
[2025-02-17 17:48:17,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:17,842][root][INFO] - Training Epoch: 1/2, step 1884/53949 completed (loss: 0.014483656734228134, acc: 1.0)
[2025-02-17 17:48:18,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:18,239][root][INFO] - Training Epoch: 1/2, step 1885/53949 completed (loss: 0.6146023273468018, acc: 0.8513513803482056)
[2025-02-17 17:48:18,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:18,626][root][INFO] - Training Epoch: 1/2, step 1886/53949 completed (loss: 0.4040695130825043, acc: 0.876288652420044)
[2025-02-17 17:48:18,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:18,992][root][INFO] - Training Epoch: 1/2, step 1887/53949 completed (loss: 0.3888457417488098, acc: 0.8857142925262451)
[2025-02-17 17:48:19,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:19,363][root][INFO] - Training Epoch: 1/2, step 1888/53949 completed (loss: 0.3268278241157532, acc: 0.925000011920929)
[2025-02-17 17:48:19,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:19,783][root][INFO] - Training Epoch: 1/2, step 1889/53949 completed (loss: 0.2693885862827301, acc: 0.9555555582046509)
[2025-02-17 17:48:19,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:20,162][root][INFO] - Training Epoch: 1/2, step 1890/53949 completed (loss: 0.44308221340179443, acc: 0.9024389982223511)
[2025-02-17 17:48:20,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:20,556][root][INFO] - Training Epoch: 1/2, step 1891/53949 completed (loss: 0.06231072172522545, acc: 1.0)
[2025-02-17 17:48:20,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:20,929][root][INFO] - Training Epoch: 1/2, step 1892/53949 completed (loss: 0.5329792499542236, acc: 0.8316831588745117)
[2025-02-17 17:48:21,066][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:21,288][root][INFO] - Training Epoch: 1/2, step 1893/53949 completed (loss: 0.25023919343948364, acc: 0.9047619104385376)
[2025-02-17 17:48:21,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:21,685][root][INFO] - Training Epoch: 1/2, step 1894/53949 completed (loss: 0.2998794615268707, acc: 0.90625)
[2025-02-17 17:48:21,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:22,107][root][INFO] - Training Epoch: 1/2, step 1895/53949 completed (loss: 0.4328138530254364, acc: 0.9272727370262146)
[2025-02-17 17:48:22,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:22,534][root][INFO] - Training Epoch: 1/2, step 1896/53949 completed (loss: 0.35548141598701477, acc: 0.8833333253860474)
[2025-02-17 17:48:22,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:22,943][root][INFO] - Training Epoch: 1/2, step 1897/53949 completed (loss: 0.20877328515052795, acc: 0.9552238583564758)
[2025-02-17 17:48:23,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:23,369][root][INFO] - Training Epoch: 1/2, step 1898/53949 completed (loss: 0.579965353012085, acc: 0.7704917788505554)
[2025-02-17 17:48:23,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:23,745][root][INFO] - Training Epoch: 1/2, step 1899/53949 completed (loss: 0.46788880228996277, acc: 0.8571428656578064)
[2025-02-17 17:48:23,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:24,101][root][INFO] - Training Epoch: 1/2, step 1900/53949 completed (loss: 0.5793876647949219, acc: 0.805031418800354)
[2025-02-17 17:48:24,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:24,439][root][INFO] - Training Epoch: 1/2, step 1901/53949 completed (loss: 0.5257182121276855, acc: 0.9047619104385376)
[2025-02-17 17:48:24,576][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:24,798][root][INFO] - Training Epoch: 1/2, step 1902/53949 completed (loss: 0.5784258842468262, acc: 0.8540145754814148)
[2025-02-17 17:48:24,964][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:25,178][root][INFO] - Training Epoch: 1/2, step 1903/53949 completed (loss: 1.0017930269241333, acc: 0.7209302186965942)
[2025-02-17 17:48:25,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:25,534][root][INFO] - Training Epoch: 1/2, step 1904/53949 completed (loss: 0.7932742834091187, acc: 0.807692289352417)
[2025-02-17 17:48:25,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:25,953][root][INFO] - Training Epoch: 1/2, step 1905/53949 completed (loss: 0.4219610095024109, acc: 0.8832116723060608)
[2025-02-17 17:48:26,086][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:26,297][root][INFO] - Training Epoch: 1/2, step 1906/53949 completed (loss: 0.48825037479400635, acc: 0.8672566413879395)
[2025-02-17 17:48:26,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:26,671][root][INFO] - Training Epoch: 1/2, step 1907/53949 completed (loss: 0.2670488655567169, acc: 0.9090909361839294)
[2025-02-17 17:48:26,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:27,090][root][INFO] - Training Epoch: 1/2, step 1908/53949 completed (loss: 0.3810933530330658, acc: 0.8842105269432068)
[2025-02-17 17:48:27,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:27,447][root][INFO] - Training Epoch: 1/2, step 1909/53949 completed (loss: 0.3005066514015198, acc: 0.90625)
[2025-02-17 17:48:27,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:27,843][root][INFO] - Training Epoch: 1/2, step 1910/53949 completed (loss: 0.651421070098877, acc: 0.8505747318267822)
[2025-02-17 17:48:27,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:28,193][root][INFO] - Training Epoch: 1/2, step 1911/53949 completed (loss: 0.21950626373291016, acc: 1.0)
[2025-02-17 17:48:28,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:28,593][root][INFO] - Training Epoch: 1/2, step 1912/53949 completed (loss: 0.40582433342933655, acc: 0.8813559412956238)
[2025-02-17 17:48:28,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:28,957][root][INFO] - Training Epoch: 1/2, step 1913/53949 completed (loss: 1.7965154647827148, acc: 0.0)
[2025-02-17 17:48:29,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:29,275][root][INFO] - Training Epoch: 1/2, step 1914/53949 completed (loss: 0.6488080024719238, acc: 0.773809552192688)
[2025-02-17 17:48:29,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:29,621][root][INFO] - Training Epoch: 1/2, step 1915/53949 completed (loss: 0.6241427659988403, acc: 0.8360655903816223)
[2025-02-17 17:48:29,760][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:29,969][root][INFO] - Training Epoch: 1/2, step 1916/53949 completed (loss: 0.7085782289505005, acc: 0.7931034564971924)
[2025-02-17 17:48:30,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:30,321][root][INFO] - Training Epoch: 1/2, step 1917/53949 completed (loss: 1.5975477695465088, acc: 0.5714285969734192)
[2025-02-17 17:48:30,458][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:30,669][root][INFO] - Training Epoch: 1/2, step 1918/53949 completed (loss: 1.5718638896942139, acc: 0.6341463327407837)
[2025-02-17 17:48:30,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:31,011][root][INFO] - Training Epoch: 1/2, step 1919/53949 completed (loss: 0.38996991515159607, acc: 0.8571428656578064)
[2025-02-17 17:48:31,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:31,353][root][INFO] - Training Epoch: 1/2, step 1920/53949 completed (loss: 1.9614231586456299, acc: 0.875)
[2025-02-17 17:48:31,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:31,706][root][INFO] - Training Epoch: 1/2, step 1921/53949 completed (loss: 2.456866979598999, acc: 0.7272727489471436)
[2025-02-17 17:48:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:32,139][root][INFO] - Training Epoch: 1/2, step 1922/53949 completed (loss: 0.5068400502204895, acc: 0.8536585569381714)
[2025-02-17 17:48:32,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:32,522][root][INFO] - Training Epoch: 1/2, step 1923/53949 completed (loss: 0.4600718319416046, acc: 0.8623853325843811)
[2025-02-17 17:48:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:32,874][root][INFO] - Training Epoch: 1/2, step 1924/53949 completed (loss: 0.6360698938369751, acc: 0.8428571224212646)
[2025-02-17 17:48:33,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:33,222][root][INFO] - Training Epoch: 1/2, step 1925/53949 completed (loss: 0.7404258251190186, acc: 0.8181818127632141)
