[2025-02-12 22:10:02,896][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_transfer_psst_phoneme', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False}
[2025-02-12 22:10:02,897][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-12 22:10:02,898][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'aphasia_phoneme_wavlm_llama32_1b_linear_peft_transfer_psst_phoneme'}
[2025-02-12 22:10:04,104][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-12 22:10:08,961][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-12 22:10:08,962][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-12 22:10:08,964][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-12 22:10:08,965][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-12 22:10:12,818][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-12 22:10:12,820][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-12 22:10:12,822][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-12 22:10:12,934][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-12 22:10:12,936][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-12 22:10:13,024][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-12 22:10:13,024][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2025-02-12 22:10:13,024][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_transfer_psst_phoneme/asr_epoch_2_step_284_loss_0.5118914246559143/model.pt
[2025-02-12 22:10:13,102][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-12 22:10:13,106][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2025-02-12 22:10:14,839][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-12 22:10:16,409][root][INFO] - --> Training Set Length = 652
[2025-02-12 22:10:16,410][root][INFO] - =====================================
[2025-02-12 22:10:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:18,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:19,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:19,837][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:20,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:21,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:24,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:24,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:25,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:26,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:27,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:28,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:30,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:31,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:32,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:32,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:33,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:35,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:36,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:36,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:37,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:37,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:38,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:39,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:40,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:41,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:41,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:42,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:43,231][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:43,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:44,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:44,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:45,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:45,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:46,693][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:47,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:48,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:48,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:49,517][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:50,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:51,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:51,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:52,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:53,023][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:53,706][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:54,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:54,931][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:56,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:57,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:10:59,206][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:00,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:01,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:01,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:02,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:02,711][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:03,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:04,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:05,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:07,358][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:08,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:08,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:10,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:11,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:12,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:14,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:17,047][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:17,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:18,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:18,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:19,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:20,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:21,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:22,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:23,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:24,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:24,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:25,534][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:31,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:33,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:35,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:39,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:40,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:40,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:40,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:41,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:41,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:42,504][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:43,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:44,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:46,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:48,646][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:50,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:53,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:54,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:55,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:57,234][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:58,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:11:59,580][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:01,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:04,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:05,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:05,816][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:06,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:06,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:07,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:08,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:09,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:09,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:10,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:10,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:11,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:12,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:12,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:13,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:14,457][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:15,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:15,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:16,525][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:17,077][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:17,694][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:18,102][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:18,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:19,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:20,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:21,867][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:22,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:22,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:23,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:24,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:24,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:25,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:26,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:26,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:27,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:28,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:29,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:29,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:30,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:31,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:31,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:32,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:33,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:34,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:34,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:36,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:37,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:38,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:39,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:40,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:42,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:44,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:45,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:46,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:46,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:47,349][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:47,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:48,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:49,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:50,644][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:53,454][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-12 22:12:54,368][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_transfer_psst_phoneme/decode_test_beam4_pred_20250212_221016
[2025-02-12 22:12:54,368][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_transfer_psst_phoneme/decode_test_beam4_gt_20250212_221016
