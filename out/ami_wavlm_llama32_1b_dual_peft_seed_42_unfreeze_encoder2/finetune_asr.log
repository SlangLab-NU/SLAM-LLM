[2025-02-17 17:36:53,697][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 2, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False, 'test_flag': True}
[2025-02-17 17:36:53,698][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-17 17:36:53,699][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'repetition_penalty', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'ami_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2'}
[2025-02-17 17:36:53,699][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2025-02-17_17-36-52.txt', 'log_interval': 5}
[2025-02-17 17:37:29,254][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2025-02-17 17:37:35,159][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-17 17:37:35,161][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-17 17:37:35,163][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-17 17:37:35,164][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-17 17:37:37,396][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-17 17:37:37,401][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-17 17:37:37,401][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-02-17 17:37:37,402][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-02-17 17:37:52,759][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-17 17:37:52,762][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-17 17:37:52,762][slam_llm.models.slam_model][INFO] - setup peft...
[2025-02-17 17:37:52,886][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-17 17:37:52,888][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-17 17:37:53,088][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-02-17 17:37:53,088][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-02-17 17:37:53,089][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-17 17:37:53,094][slam_llm.utils.train_utils][INFO] - --> asr has 346.244736 Million params

[2025-02-17 17:37:56,158][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-17 17:38:02,907][root][INFO] - --> Training Set Length = 107898
[2025-02-17 17:38:02,996][root][INFO] - --> Validation Set Length = 8351
[2025-02-17 17:38:02,996][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-17 17:38:02,997][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-17 17:38:06,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:07,827][root][INFO] - Training Epoch: 1/2, step 0/53949 completed (loss: 6.9088335037231445, acc: 0.1875)
[2025-02-17 17:38:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:08,229][root][INFO] - Training Epoch: 1/2, step 1/53949 completed (loss: 6.858987808227539, acc: 0.0731707289814949)
[2025-02-17 17:38:08,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:08,707][root][INFO] - Training Epoch: 1/2, step 2/53949 completed (loss: 9.715091705322266, acc: 0.0)
[2025-02-17 17:38:08,957][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:09,325][root][INFO] - Training Epoch: 1/2, step 3/53949 completed (loss: 7.5825042724609375, acc: 0.125)
[2025-02-17 17:38:09,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:09,700][root][INFO] - Training Epoch: 1/2, step 4/53949 completed (loss: 6.8673481941223145, acc: 0.057692307978868484)
[2025-02-17 17:38:09,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:10,139][root][INFO] - Training Epoch: 1/2, step 5/53949 completed (loss: 5.901630878448486, acc: 0.19354838132858276)
[2025-02-17 17:38:10,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:10,576][root][INFO] - Training Epoch: 1/2, step 6/53949 completed (loss: 6.665114879608154, acc: 0.20000000298023224)
[2025-02-17 17:38:10,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:11,005][root][INFO] - Training Epoch: 1/2, step 7/53949 completed (loss: 6.600313663482666, acc: 0.0625)
[2025-02-17 17:38:11,213][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:11,437][root][INFO] - Training Epoch: 1/2, step 8/53949 completed (loss: 6.376683712005615, acc: 0.11764705926179886)
[2025-02-17 17:38:11,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:11,876][root][INFO] - Training Epoch: 1/2, step 9/53949 completed (loss: 8.553061485290527, acc: 0.0)
[2025-02-17 17:38:12,091][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:12,299][root][INFO] - Training Epoch: 1/2, step 10/53949 completed (loss: 7.195906162261963, acc: 0.0)
[2025-02-17 17:38:12,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:12,755][root][INFO] - Training Epoch: 1/2, step 11/53949 completed (loss: 7.745419502258301, acc: 0.08695652335882187)
[2025-02-17 17:38:12,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:13,156][root][INFO] - Training Epoch: 1/2, step 12/53949 completed (loss: 6.355225086212158, acc: 0.02777777798473835)
[2025-02-17 17:38:13,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:13,517][root][INFO] - Training Epoch: 1/2, step 13/53949 completed (loss: 7.4422736167907715, acc: 0.0)
[2025-02-17 17:38:13,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:13,935][root][INFO] - Training Epoch: 1/2, step 14/53949 completed (loss: 6.811000347137451, acc: 0.04545454680919647)
[2025-02-17 17:38:14,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:14,383][root][INFO] - Training Epoch: 1/2, step 15/53949 completed (loss: 7.085338115692139, acc: 0.0476190485060215)
[2025-02-17 17:38:14,564][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:14,784][root][INFO] - Training Epoch: 1/2, step 16/53949 completed (loss: 6.421704292297363, acc: 0.1111111119389534)
[2025-02-17 17:38:15,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:15,234][root][INFO] - Training Epoch: 1/2, step 17/53949 completed (loss: 8.590372085571289, acc: 0.10000000149011612)
[2025-02-17 17:38:15,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:15,609][root][INFO] - Training Epoch: 1/2, step 18/53949 completed (loss: 6.251246452331543, acc: 0.0)
[2025-02-17 17:38:15,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:16,026][root][INFO] - Training Epoch: 1/2, step 19/53949 completed (loss: 7.584179401397705, acc: 0.06666667014360428)
[2025-02-17 17:38:16,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:16,486][root][INFO] - Training Epoch: 1/2, step 20/53949 completed (loss: 11.640376091003418, acc: 0.0)
[2025-02-17 17:38:16,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:16,936][root][INFO] - Training Epoch: 1/2, step 21/53949 completed (loss: 6.535778999328613, acc: 0.31578946113586426)
[2025-02-17 17:38:17,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:17,395][root][INFO] - Training Epoch: 1/2, step 22/53949 completed (loss: 7.662724018096924, acc: 0.0)
[2025-02-17 17:38:17,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:17,826][root][INFO] - Training Epoch: 1/2, step 23/53949 completed (loss: 5.454185962677002, acc: 0.1538461595773697)
[2025-02-17 17:38:18,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:18,251][root][INFO] - Training Epoch: 1/2, step 24/53949 completed (loss: 6.01657772064209, acc: 0.17777778208255768)
[2025-02-17 17:38:18,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:18,686][root][INFO] - Training Epoch: 1/2, step 25/53949 completed (loss: 7.889170169830322, acc: 0.0476190485060215)
[2025-02-17 17:38:18,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:19,093][root][INFO] - Training Epoch: 1/2, step 26/53949 completed (loss: 6.223111152648926, acc: 0.15217390656471252)
[2025-02-17 17:38:19,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:19,491][root][INFO] - Training Epoch: 1/2, step 27/53949 completed (loss: 8.1315279006958, acc: 0.0)
[2025-02-17 17:38:19,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:19,949][root][INFO] - Training Epoch: 1/2, step 28/53949 completed (loss: 7.285277843475342, acc: 0.0833333358168602)
[2025-02-17 17:38:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:20,381][root][INFO] - Training Epoch: 1/2, step 29/53949 completed (loss: 7.939333915710449, acc: 0.13333334028720856)
[2025-02-17 17:38:20,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:20,786][root][INFO] - Training Epoch: 1/2, step 30/53949 completed (loss: 6.0498738288879395, acc: 0.08695652335882187)
[2025-02-17 17:38:21,020][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:21,253][root][INFO] - Training Epoch: 1/2, step 31/53949 completed (loss: 4.046872615814209, acc: 0.25)
[2025-02-17 17:38:21,488][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:21,718][root][INFO] - Training Epoch: 1/2, step 32/53949 completed (loss: 6.023270130157471, acc: 0.07692307978868484)
[2025-02-17 17:38:21,905][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:22,120][root][INFO] - Training Epoch: 1/2, step 33/53949 completed (loss: 5.265655517578125, acc: 0.0882352963089943)
[2025-02-17 17:38:22,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:22,574][root][INFO] - Training Epoch: 1/2, step 34/53949 completed (loss: 5.443015098571777, acc: 0.17777778208255768)
[2025-02-17 17:38:22,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:23,021][root][INFO] - Training Epoch: 1/2, step 35/53949 completed (loss: 6.011398792266846, acc: 0.1666666716337204)
[2025-02-17 17:38:23,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:23,432][root][INFO] - Training Epoch: 1/2, step 36/53949 completed (loss: 6.774209976196289, acc: 0.1111111119389534)
[2025-02-17 17:38:23,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:23,851][root][INFO] - Training Epoch: 1/2, step 37/53949 completed (loss: 6.434291839599609, acc: 0.09756097197532654)
[2025-02-17 17:38:24,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:24,233][root][INFO] - Training Epoch: 1/2, step 38/53949 completed (loss: 6.209972381591797, acc: 0.1428571492433548)
[2025-02-17 17:38:24,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:24,682][root][INFO] - Training Epoch: 1/2, step 39/53949 completed (loss: 10.451249122619629, acc: 0.0)
[2025-02-17 17:38:24,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:25,119][root][INFO] - Training Epoch: 1/2, step 40/53949 completed (loss: 6.189943790435791, acc: 0.1666666716337204)
[2025-02-17 17:38:25,312][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:25,526][root][INFO] - Training Epoch: 1/2, step 41/53949 completed (loss: 5.906571865081787, acc: 0.22499999403953552)
[2025-02-17 17:38:25,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:25,966][root][INFO] - Training Epoch: 1/2, step 42/53949 completed (loss: 5.729900360107422, acc: 0.1428571492433548)
[2025-02-17 17:38:26,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:26,425][root][INFO] - Training Epoch: 1/2, step 43/53949 completed (loss: 6.744280815124512, acc: 0.05882352963089943)
[2025-02-17 17:38:26,603][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:26,830][root][INFO] - Training Epoch: 1/2, step 44/53949 completed (loss: 5.321375370025635, acc: 0.1428571492433548)
[2025-02-17 17:38:27,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:27,280][root][INFO] - Training Epoch: 1/2, step 45/53949 completed (loss: 7.523027420043945, acc: 0.07692307978868484)
[2025-02-17 17:38:27,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:27,810][root][INFO] - Training Epoch: 1/2, step 46/53949 completed (loss: 7.257526397705078, acc: 0.05263157933950424)
[2025-02-17 17:38:28,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:28,241][root][INFO] - Training Epoch: 1/2, step 47/53949 completed (loss: 7.535643100738525, acc: 0.0)
[2025-02-17 17:38:28,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:28,656][root][INFO] - Training Epoch: 1/2, step 48/53949 completed (loss: 7.378210067749023, acc: 0.0)
[2025-02-17 17:38:28,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:29,059][root][INFO] - Training Epoch: 1/2, step 49/53949 completed (loss: 7.724198341369629, acc: 0.13333334028720856)
[2025-02-17 17:38:29,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:29,454][root][INFO] - Training Epoch: 1/2, step 50/53949 completed (loss: 5.277939319610596, acc: 0.0)
[2025-02-17 17:38:29,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:29,779][root][INFO] - Training Epoch: 1/2, step 51/53949 completed (loss: 6.747610092163086, acc: 0.09090909361839294)
[2025-02-17 17:38:29,965][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:30,186][root][INFO] - Training Epoch: 1/2, step 52/53949 completed (loss: 6.134366512298584, acc: 0.0625)
[2025-02-17 17:38:30,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:30,595][root][INFO] - Training Epoch: 1/2, step 53/53949 completed (loss: 6.960341930389404, acc: 0.0810810774564743)
[2025-02-17 17:38:30,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:30,973][root][INFO] - Training Epoch: 1/2, step 54/53949 completed (loss: 6.6121506690979, acc: 0.0)
[2025-02-17 17:38:31,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:31,361][root][INFO] - Training Epoch: 1/2, step 55/53949 completed (loss: 6.789363384246826, acc: 0.0)
[2025-02-17 17:38:31,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:31,738][root][INFO] - Training Epoch: 1/2, step 56/53949 completed (loss: 5.479921817779541, acc: 0.02631578966975212)
[2025-02-17 17:38:31,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:32,124][root][INFO] - Training Epoch: 1/2, step 57/53949 completed (loss: 5.0686516761779785, acc: 0.2222222238779068)
[2025-02-17 17:38:32,366][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:32,598][root][INFO] - Training Epoch: 1/2, step 58/53949 completed (loss: 5.7930521965026855, acc: 0.16129031777381897)
[2025-02-17 17:38:32,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:33,014][root][INFO] - Training Epoch: 1/2, step 59/53949 completed (loss: 5.796820640563965, acc: 0.16129031777381897)
[2025-02-17 17:38:33,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:33,409][root][INFO] - Training Epoch: 1/2, step 60/53949 completed (loss: 5.904300212860107, acc: 0.17777778208255768)
[2025-02-17 17:38:33,585][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:33,809][root][INFO] - Training Epoch: 1/2, step 61/53949 completed (loss: 5.120710849761963, acc: 0.13513512909412384)
[2025-02-17 17:38:33,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:34,207][root][INFO] - Training Epoch: 1/2, step 62/53949 completed (loss: 6.695948123931885, acc: 0.125)
[2025-02-17 17:38:34,424][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:34,646][root][INFO] - Training Epoch: 1/2, step 63/53949 completed (loss: 5.7133636474609375, acc: 0.1428571492433548)
[2025-02-17 17:38:34,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:35,078][root][INFO] - Training Epoch: 1/2, step 64/53949 completed (loss: 4.149799823760986, acc: 0.3333333432674408)
[2025-02-17 17:38:35,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:35,493][root][INFO] - Training Epoch: 1/2, step 65/53949 completed (loss: 3.7058329582214355, acc: 0.37704917788505554)
[2025-02-17 17:38:35,664][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:35,879][root][INFO] - Training Epoch: 1/2, step 66/53949 completed (loss: 5.332114219665527, acc: 0.1818181872367859)
[2025-02-17 17:38:36,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:36,255][root][INFO] - Training Epoch: 1/2, step 67/53949 completed (loss: 4.560379981994629, acc: 0.25)
[2025-02-17 17:38:36,456][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:36,694][root][INFO] - Training Epoch: 1/2, step 68/53949 completed (loss: 4.798198223114014, acc: 0.20000000298023224)
[2025-02-17 17:38:36,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:37,108][root][INFO] - Training Epoch: 1/2, step 69/53949 completed (loss: 6.880505561828613, acc: 0.06896551698446274)
[2025-02-17 17:38:37,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:37,495][root][INFO] - Training Epoch: 1/2, step 70/53949 completed (loss: 4.561986446380615, acc: 0.19354838132858276)
[2025-02-17 17:38:37,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:37,958][root][INFO] - Training Epoch: 1/2, step 71/53949 completed (loss: 5.143112659454346, acc: 0.07692307978868484)
[2025-02-17 17:38:38,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:38,441][root][INFO] - Training Epoch: 1/2, step 72/53949 completed (loss: 4.359609127044678, acc: 0.1666666716337204)
[2025-02-17 17:38:38,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:38,836][root][INFO] - Training Epoch: 1/2, step 73/53949 completed (loss: 6.0817413330078125, acc: 0.0833333358168602)
[2025-02-17 17:38:39,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:39,218][root][INFO] - Training Epoch: 1/2, step 74/53949 completed (loss: 4.781388759613037, acc: 0.1621621549129486)
[2025-02-17 17:38:39,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:39,577][root][INFO] - Training Epoch: 1/2, step 75/53949 completed (loss: 7.065951347351074, acc: 0.0)
[2025-02-17 17:38:39,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:39,974][root][INFO] - Training Epoch: 1/2, step 76/53949 completed (loss: 6.545449256896973, acc: 0.03703703731298447)
[2025-02-17 17:38:40,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:40,414][root][INFO] - Training Epoch: 1/2, step 77/53949 completed (loss: 7.204138278961182, acc: 0.0)
[2025-02-17 17:38:40,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:40,824][root][INFO] - Training Epoch: 1/2, step 78/53949 completed (loss: 6.993664264678955, acc: 0.0)
[2025-02-17 17:38:40,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:41,209][root][INFO] - Training Epoch: 1/2, step 79/53949 completed (loss: 5.14025354385376, acc: 0.16129031777381897)
[2025-02-17 17:38:41,343][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:41,564][root][INFO] - Training Epoch: 1/2, step 80/53949 completed (loss: 5.276815891265869, acc: 0.0)
[2025-02-17 17:38:41,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:41,981][root][INFO] - Training Epoch: 1/2, step 81/53949 completed (loss: 4.789916038513184, acc: 0.1666666716337204)
[2025-02-17 17:38:42,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:42,350][root][INFO] - Training Epoch: 1/2, step 82/53949 completed (loss: 4.994253635406494, acc: 0.0)
[2025-02-17 17:38:42,575][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:42,813][root][INFO] - Training Epoch: 1/2, step 83/53949 completed (loss: 5.350256443023682, acc: 0.1818181872367859)
[2025-02-17 17:38:43,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:43,259][root][INFO] - Training Epoch: 1/2, step 84/53949 completed (loss: 5.973959445953369, acc: 0.0625)
[2025-02-17 17:38:43,404][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:43,628][root][INFO] - Training Epoch: 1/2, step 85/53949 completed (loss: 3.5040595531463623, acc: 0.1666666716337204)
[2025-02-17 17:38:43,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:44,008][root][INFO] - Training Epoch: 1/2, step 86/53949 completed (loss: 4.55072546005249, acc: 0.190476194024086)
[2025-02-17 17:38:44,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:44,434][root][INFO] - Training Epoch: 1/2, step 87/53949 completed (loss: 5.508656978607178, acc: 0.16129031777381897)
[2025-02-17 17:38:44,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:44,870][root][INFO] - Training Epoch: 1/2, step 88/53949 completed (loss: 4.661124229431152, acc: 0.0714285746216774)
[2025-02-17 17:38:45,046][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:45,260][root][INFO] - Training Epoch: 1/2, step 89/53949 completed (loss: 4.7157182693481445, acc: 0.2857142984867096)
[2025-02-17 17:38:45,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:45,648][root][INFO] - Training Epoch: 1/2, step 90/53949 completed (loss: 5.083428382873535, acc: 0.1463414579629898)
[2025-02-17 17:38:45,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:46,066][root][INFO] - Training Epoch: 1/2, step 91/53949 completed (loss: 4.291353225708008, acc: 0.13793103396892548)
[2025-02-17 17:38:46,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:46,495][root][INFO] - Training Epoch: 1/2, step 92/53949 completed (loss: 4.5143513679504395, acc: 0.1388888955116272)
[2025-02-17 17:38:46,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:46,945][root][INFO] - Training Epoch: 1/2, step 93/53949 completed (loss: 3.8110499382019043, acc: 0.4000000059604645)
[2025-02-17 17:38:47,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:47,355][root][INFO] - Training Epoch: 1/2, step 94/53949 completed (loss: 3.9415130615234375, acc: 0.25)
[2025-02-17 17:38:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:47,775][root][INFO] - Training Epoch: 1/2, step 95/53949 completed (loss: 4.503641605377197, acc: 0.1794871836900711)
[2025-02-17 17:38:48,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:48,240][root][INFO] - Training Epoch: 1/2, step 96/53949 completed (loss: 4.212831020355225, acc: 0.21978022158145905)
[2025-02-17 17:38:48,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:48,585][root][INFO] - Training Epoch: 1/2, step 97/53949 completed (loss: 5.192541122436523, acc: 0.03448275849223137)
[2025-02-17 17:38:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:48,969][root][INFO] - Training Epoch: 1/2, step 98/53949 completed (loss: 5.006396293640137, acc: 0.1666666716337204)
[2025-02-17 17:38:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:49,422][root][INFO] - Training Epoch: 1/2, step 99/53949 completed (loss: 3.3144540786743164, acc: 0.3333333432674408)
[2025-02-17 17:38:49,619][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:49,846][root][INFO] - Training Epoch: 1/2, step 100/53949 completed (loss: 5.417520999908447, acc: 0.1111111119389534)
[2025-02-17 17:38:50,048][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:50,277][root][INFO] - Training Epoch: 1/2, step 101/53949 completed (loss: 3.3064024448394775, acc: 0.3333333432674408)
[2025-02-17 17:38:50,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:50,657][root][INFO] - Training Epoch: 1/2, step 102/53949 completed (loss: 5.091057777404785, acc: 0.125)
[2025-02-17 17:38:50,877][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:51,126][root][INFO] - Training Epoch: 1/2, step 103/53949 completed (loss: 5.793226718902588, acc: 0.1428571492433548)
[2025-02-17 17:38:51,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:51,581][root][INFO] - Training Epoch: 1/2, step 104/53949 completed (loss: 4.667297840118408, acc: 0.26923078298568726)
[2025-02-17 17:38:51,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:51,996][root][INFO] - Training Epoch: 1/2, step 105/53949 completed (loss: 4.066614151000977, acc: 0.19354838132858276)
[2025-02-17 17:38:52,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:52,419][root][INFO] - Training Epoch: 1/2, step 106/53949 completed (loss: 4.216925144195557, acc: 0.32258063554763794)
[2025-02-17 17:38:52,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:52,882][root][INFO] - Training Epoch: 1/2, step 107/53949 completed (loss: 5.622586250305176, acc: 0.18518517911434174)
[2025-02-17 17:38:53,122][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:53,354][root][INFO] - Training Epoch: 1/2, step 108/53949 completed (loss: 3.394274950027466, acc: 0.25)
[2025-02-17 17:38:53,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:53,811][root][INFO] - Training Epoch: 1/2, step 109/53949 completed (loss: 5.382603645324707, acc: 0.125)
[2025-02-17 17:38:54,037][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:54,260][root][INFO] - Training Epoch: 1/2, step 110/53949 completed (loss: 3.748175621032715, acc: 0.1764705926179886)
[2025-02-17 17:38:54,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:54,658][root][INFO] - Training Epoch: 1/2, step 111/53949 completed (loss: 4.37083625793457, acc: 0.29629629850387573)
[2025-02-17 17:38:54,825][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:55,052][root][INFO] - Training Epoch: 1/2, step 112/53949 completed (loss: 5.215750694274902, acc: 0.23076923191547394)
[2025-02-17 17:38:55,237][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:55,433][root][INFO] - Training Epoch: 1/2, step 113/53949 completed (loss: 3.8796515464782715, acc: 0.27272728085517883)
[2025-02-17 17:38:55,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:55,900][root][INFO] - Training Epoch: 1/2, step 114/53949 completed (loss: 2.8423044681549072, acc: 0.25)
[2025-02-17 17:38:56,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:56,301][root][INFO] - Training Epoch: 1/2, step 115/53949 completed (loss: 4.630319118499756, acc: 0.19230769574642181)
[2025-02-17 17:38:56,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:56,743][root][INFO] - Training Epoch: 1/2, step 116/53949 completed (loss: 4.81834602355957, acc: 0.23076923191547394)
[2025-02-17 17:38:56,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:57,153][root][INFO] - Training Epoch: 1/2, step 117/53949 completed (loss: 3.3325839042663574, acc: 0.3125)
[2025-02-17 17:38:57,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:57,605][root][INFO] - Training Epoch: 1/2, step 118/53949 completed (loss: 7.147871017456055, acc: 0.09090909361839294)
[2025-02-17 17:38:57,848][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:58,075][root][INFO] - Training Epoch: 1/2, step 119/53949 completed (loss: 4.110841274261475, acc: 0.0)
[2025-02-17 17:38:58,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:58,506][root][INFO] - Training Epoch: 1/2, step 120/53949 completed (loss: 3.007601261138916, acc: 0.5)
[2025-02-17 17:38:58,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:58,978][root][INFO] - Training Epoch: 1/2, step 121/53949 completed (loss: 4.182583808898926, acc: 0.19565217196941376)
[2025-02-17 17:38:59,160][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:59,381][root][INFO] - Training Epoch: 1/2, step 122/53949 completed (loss: 4.503687858581543, acc: 0.20338982343673706)
[2025-02-17 17:38:59,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:38:59,784][root][INFO] - Training Epoch: 1/2, step 123/53949 completed (loss: 3.4904608726501465, acc: 0.26923078298568726)
[2025-02-17 17:38:59,962][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:00,180][root][INFO] - Training Epoch: 1/2, step 124/53949 completed (loss: 3.7140283584594727, acc: 0.2777777910232544)
[2025-02-17 17:39:00,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:00,576][root][INFO] - Training Epoch: 1/2, step 125/53949 completed (loss: 3.8511695861816406, acc: 0.34285715222358704)
[2025-02-17 17:39:00,746][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:00,975][root][INFO] - Training Epoch: 1/2, step 126/53949 completed (loss: 5.147681713104248, acc: 0.27272728085517883)
[2025-02-17 17:39:01,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:01,410][root][INFO] - Training Epoch: 1/2, step 127/53949 completed (loss: 4.446688175201416, acc: 0.27272728085517883)
[2025-02-17 17:39:01,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:01,834][root][INFO] - Training Epoch: 1/2, step 128/53949 completed (loss: 4.072354316711426, acc: 0.3571428656578064)
[2025-02-17 17:39:01,992][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:02,215][root][INFO] - Training Epoch: 1/2, step 129/53949 completed (loss: 2.9620823860168457, acc: 0.625)
[2025-02-17 17:39:02,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:02,611][root][INFO] - Training Epoch: 1/2, step 130/53949 completed (loss: 5.280638217926025, acc: 0.15789473056793213)
[2025-02-17 17:39:02,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:03,063][root][INFO] - Training Epoch: 1/2, step 131/53949 completed (loss: 4.831674575805664, acc: 0.13333334028720856)
[2025-02-17 17:39:03,291][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:03,524][root][INFO] - Training Epoch: 1/2, step 132/53949 completed (loss: 4.629081726074219, acc: 0.29629629850387573)
[2025-02-17 17:39:03,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:03,985][root][INFO] - Training Epoch: 1/2, step 133/53949 completed (loss: 3.895460605621338, acc: 0.18518517911434174)
[2025-02-17 17:39:04,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:04,448][root][INFO] - Training Epoch: 1/2, step 134/53949 completed (loss: 4.946732044219971, acc: 0.22727273404598236)
[2025-02-17 17:39:04,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:04,879][root][INFO] - Training Epoch: 1/2, step 135/53949 completed (loss: 0.3098195493221283, acc: 1.0)
[2025-02-17 17:39:05,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:05,255][root][INFO] - Training Epoch: 1/2, step 136/53949 completed (loss: 4.50666618347168, acc: 0.25)
[2025-02-17 17:39:05,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:05,711][root][INFO] - Training Epoch: 1/2, step 137/53949 completed (loss: 4.765022277832031, acc: 0.1666666716337204)
[2025-02-17 17:39:05,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:06,142][root][INFO] - Training Epoch: 1/2, step 138/53949 completed (loss: 3.4287500381469727, acc: 0.3888888955116272)
[2025-02-17 17:39:06,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:06,547][root][INFO] - Training Epoch: 1/2, step 139/53949 completed (loss: 4.581385612487793, acc: 0.25)
[2025-02-17 17:39:06,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:06,968][root][INFO] - Training Epoch: 1/2, step 140/53949 completed (loss: 1.3544026613235474, acc: 0.75)
[2025-02-17 17:39:07,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:07,375][root][INFO] - Training Epoch: 1/2, step 141/53949 completed (loss: 3.213136911392212, acc: 0.3636363744735718)
[2025-02-17 17:39:07,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:07,828][root][INFO] - Training Epoch: 1/2, step 142/53949 completed (loss: 4.175218105316162, acc: 0.25)
[2025-02-17 17:39:08,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:08,274][root][INFO] - Training Epoch: 1/2, step 143/53949 completed (loss: 4.365813732147217, acc: 0.2916666567325592)
[2025-02-17 17:39:08,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:08,684][root][INFO] - Training Epoch: 1/2, step 144/53949 completed (loss: 3.942323923110962, acc: 0.2857142984867096)
[2025-02-17 17:39:08,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:09,075][root][INFO] - Training Epoch: 1/2, step 145/53949 completed (loss: 4.765279293060303, acc: 0.1515151560306549)
[2025-02-17 17:39:09,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:09,490][root][INFO] - Training Epoch: 1/2, step 146/53949 completed (loss: 2.2031095027923584, acc: 0.4166666567325592)
[2025-02-17 17:39:09,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:09,935][root][INFO] - Training Epoch: 1/2, step 147/53949 completed (loss: 5.778923034667969, acc: 0.25)
[2025-02-17 17:39:10,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:10,372][root][INFO] - Training Epoch: 1/2, step 148/53949 completed (loss: 0.84596186876297, acc: 0.800000011920929)
[2025-02-17 17:39:10,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:10,808][root][INFO] - Training Epoch: 1/2, step 149/53949 completed (loss: 3.647165298461914, acc: 0.380952388048172)
[2025-02-17 17:39:10,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:11,199][root][INFO] - Training Epoch: 1/2, step 150/53949 completed (loss: 3.2264339923858643, acc: 0.5)
[2025-02-17 17:39:11,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:11,608][root][INFO] - Training Epoch: 1/2, step 151/53949 completed (loss: 4.065325736999512, acc: 0.3333333432674408)
[2025-02-17 17:39:11,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:12,015][root][INFO] - Training Epoch: 1/2, step 152/53949 completed (loss: 3.0953867435455322, acc: 0.375)
[2025-02-17 17:39:12,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:12,387][root][INFO] - Training Epoch: 1/2, step 153/53949 completed (loss: 3.174285411834717, acc: 0.3947368562221527)
[2025-02-17 17:39:12,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:12,759][root][INFO] - Training Epoch: 1/2, step 154/53949 completed (loss: 1.0014435052871704, acc: 0.75)
[2025-02-17 17:39:12,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:13,176][root][INFO] - Training Epoch: 1/2, step 155/53949 completed (loss: 4.272158145904541, acc: 0.2291666716337204)
[2025-02-17 17:39:13,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:13,576][root][INFO] - Training Epoch: 1/2, step 156/53949 completed (loss: 3.3719379901885986, acc: 0.6000000238418579)
[2025-02-17 17:39:13,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:13,964][root][INFO] - Training Epoch: 1/2, step 157/53949 completed (loss: 3.952476978302002, acc: 0.24561403691768646)
[2025-02-17 17:39:14,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:14,341][root][INFO] - Training Epoch: 1/2, step 158/53949 completed (loss: 3.9919116497039795, acc: 0.2222222238779068)
[2025-02-17 17:39:14,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:14,743][root][INFO] - Training Epoch: 1/2, step 159/53949 completed (loss: 3.693580389022827, acc: 0.39024388790130615)
[2025-02-17 17:39:14,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:15,123][root][INFO] - Training Epoch: 1/2, step 160/53949 completed (loss: 4.578545093536377, acc: 0.24242424964904785)
[2025-02-17 17:39:15,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:15,550][root][INFO] - Training Epoch: 1/2, step 161/53949 completed (loss: 3.1068906784057617, acc: 0.3333333432674408)
[2025-02-17 17:39:15,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:15,970][root][INFO] - Training Epoch: 1/2, step 162/53949 completed (loss: 4.840273857116699, acc: 0.1599999964237213)
[2025-02-17 17:39:16,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:16,373][root][INFO] - Training Epoch: 1/2, step 163/53949 completed (loss: 3.80106782913208, acc: 0.2857142984867096)
[2025-02-17 17:39:16,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:16,786][root][INFO] - Training Epoch: 1/2, step 164/53949 completed (loss: 3.195094347000122, acc: 0.3181818127632141)
[2025-02-17 17:39:17,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:17,233][root][INFO] - Training Epoch: 1/2, step 165/53949 completed (loss: 0.19498668611049652, acc: 1.0)
[2025-02-17 17:39:17,429][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:17,633][root][INFO] - Training Epoch: 1/2, step 166/53949 completed (loss: 4.646336555480957, acc: 0.1964285671710968)
[2025-02-17 17:39:17,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:18,006][root][INFO] - Training Epoch: 1/2, step 167/53949 completed (loss: 4.943126201629639, acc: 0.15909090638160706)
[2025-02-17 17:39:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:18,450][root][INFO] - Training Epoch: 1/2, step 168/53949 completed (loss: 3.886388063430786, acc: 0.3333333432674408)
[2025-02-17 17:39:18,680][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:18,910][root][INFO] - Training Epoch: 1/2, step 169/53949 completed (loss: 3.382579803466797, acc: 0.4444444477558136)
[2025-02-17 17:39:19,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:19,358][root][INFO] - Training Epoch: 1/2, step 170/53949 completed (loss: 3.653377056121826, acc: 0.4000000059604645)
[2025-02-17 17:39:19,552][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:19,767][root][INFO] - Training Epoch: 1/2, step 171/53949 completed (loss: 3.736750364303589, acc: 0.15625)
[2025-02-17 17:39:19,990][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:20,215][root][INFO] - Training Epoch: 1/2, step 172/53949 completed (loss: 3.354949951171875, acc: 0.25)
[2025-02-17 17:39:20,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:20,643][root][INFO] - Training Epoch: 1/2, step 173/53949 completed (loss: 3.570814371109009, acc: 0.2702702581882477)
[2025-02-17 17:39:20,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:21,012][root][INFO] - Training Epoch: 1/2, step 174/53949 completed (loss: 3.553300619125366, acc: 0.2857142984867096)
[2025-02-17 17:39:21,195][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:21,407][root][INFO] - Training Epoch: 1/2, step 175/53949 completed (loss: 3.662980556488037, acc: 0.28125)
[2025-02-17 17:39:21,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:21,781][root][INFO] - Training Epoch: 1/2, step 176/53949 completed (loss: 3.1944684982299805, acc: 0.27586206793785095)
[2025-02-17 17:39:21,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:22,164][root][INFO] - Training Epoch: 1/2, step 177/53949 completed (loss: 2.734471321105957, acc: 0.5454545617103577)
[2025-02-17 17:39:22,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:22,615][root][INFO] - Training Epoch: 1/2, step 178/53949 completed (loss: 4.884970664978027, acc: 0.21739129722118378)
[2025-02-17 17:39:22,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:22,975][root][INFO] - Training Epoch: 1/2, step 179/53949 completed (loss: 4.411858081817627, acc: 0.260869562625885)
[2025-02-17 17:39:23,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:23,355][root][INFO] - Training Epoch: 1/2, step 180/53949 completed (loss: 4.082718372344971, acc: 0.18421052396297455)
[2025-02-17 17:39:23,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:23,792][root][INFO] - Training Epoch: 1/2, step 181/53949 completed (loss: 3.568074941635132, acc: 0.3870967626571655)
[2025-02-17 17:39:24,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:24,263][root][INFO] - Training Epoch: 1/2, step 182/53949 completed (loss: 4.571392059326172, acc: 0.261904776096344)
[2025-02-17 17:39:24,492][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:24,731][root][INFO] - Training Epoch: 1/2, step 183/53949 completed (loss: 3.416995048522949, acc: 0.3442623019218445)
[2025-02-17 17:39:24,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:25,137][root][INFO] - Training Epoch: 1/2, step 184/53949 completed (loss: 4.2682647705078125, acc: 0.12121212482452393)
[2025-02-17 17:39:25,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:25,549][root][INFO] - Training Epoch: 1/2, step 185/53949 completed (loss: 4.358458042144775, acc: 0.31578946113586426)
[2025-02-17 17:39:25,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:25,930][root][INFO] - Training Epoch: 1/2, step 186/53949 completed (loss: 2.9368205070495605, acc: 0.625)
[2025-02-17 17:39:26,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:26,397][root][INFO] - Training Epoch: 1/2, step 187/53949 completed (loss: 4.240180492401123, acc: 0.3125)
[2025-02-17 17:39:26,600][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:26,829][root][INFO] - Training Epoch: 1/2, step 188/53949 completed (loss: 2.4286980628967285, acc: 0.5)
[2025-02-17 17:39:27,078][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:27,308][root][INFO] - Training Epoch: 1/2, step 189/53949 completed (loss: 4.05686092376709, acc: 0.2291666716337204)
[2025-02-17 17:39:27,478][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:27,671][root][INFO] - Training Epoch: 1/2, step 190/53949 completed (loss: 1.7178229093551636, acc: 0.5)
[2025-02-17 17:39:27,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:28,068][root][INFO] - Training Epoch: 1/2, step 191/53949 completed (loss: 3.0749166011810303, acc: 0.3529411852359772)
[2025-02-17 17:39:28,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:28,504][root][INFO] - Training Epoch: 1/2, step 192/53949 completed (loss: 4.074950218200684, acc: 0.2068965584039688)
[2025-02-17 17:39:28,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:28,910][root][INFO] - Training Epoch: 1/2, step 193/53949 completed (loss: 3.8124940395355225, acc: 0.2666666805744171)
[2025-02-17 17:39:29,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:29,371][root][INFO] - Training Epoch: 1/2, step 194/53949 completed (loss: 1.3349672555923462, acc: 0.800000011920929)
[2025-02-17 17:39:29,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:29,765][root][INFO] - Training Epoch: 1/2, step 195/53949 completed (loss: 4.106417179107666, acc: 0.2368421107530594)
[2025-02-17 17:39:29,925][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:30,135][root][INFO] - Training Epoch: 1/2, step 196/53949 completed (loss: 2.973106861114502, acc: 0.4000000059604645)
[2025-02-17 17:39:30,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:30,570][root][INFO] - Training Epoch: 1/2, step 197/53949 completed (loss: 3.8453009128570557, acc: 0.2380952388048172)
[2025-02-17 17:39:30,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:31,004][root][INFO] - Training Epoch: 1/2, step 198/53949 completed (loss: 3.970409631729126, acc: 0.3404255211353302)
[2025-02-17 17:39:31,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:31,396][root][INFO] - Training Epoch: 1/2, step 199/53949 completed (loss: 3.4812753200531006, acc: 0.3333333432674408)
[2025-02-17 17:39:31,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:31,868][root][INFO] - Training Epoch: 1/2, step 200/53949 completed (loss: 4.445051670074463, acc: 0.1666666716337204)
[2025-02-17 17:39:32,097][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:32,330][root][INFO] - Training Epoch: 1/2, step 201/53949 completed (loss: 3.4435033798217773, acc: 0.2571428716182709)
[2025-02-17 17:39:32,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:32,689][root][INFO] - Training Epoch: 1/2, step 202/53949 completed (loss: 3.184824228286743, acc: 0.375)
[2025-02-17 17:39:32,863][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:33,080][root][INFO] - Training Epoch: 1/2, step 203/53949 completed (loss: 0.3627546727657318, acc: 1.0)
[2025-02-17 17:39:33,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:33,460][root][INFO] - Training Epoch: 1/2, step 204/53949 completed (loss: 1.891129493713379, acc: 0.6000000238418579)
[2025-02-17 17:39:33,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:33,859][root][INFO] - Training Epoch: 1/2, step 205/53949 completed (loss: 3.2181708812713623, acc: 0.4000000059604645)
[2025-02-17 17:39:34,118][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:34,344][root][INFO] - Training Epoch: 1/2, step 206/53949 completed (loss: 4.268528461456299, acc: 0.21621622145175934)
[2025-02-17 17:39:34,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:34,824][root][INFO] - Training Epoch: 1/2, step 207/53949 completed (loss: 4.00202751159668, acc: 0.3181818127632141)
[2025-02-17 17:39:34,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:35,204][root][INFO] - Training Epoch: 1/2, step 208/53949 completed (loss: 3.2332406044006348, acc: 0.75)
[2025-02-17 17:39:35,376][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:35,593][root][INFO] - Training Epoch: 1/2, step 209/53949 completed (loss: 4.281671047210693, acc: 0.25806450843811035)
[2025-02-17 17:39:35,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:36,027][root][INFO] - Training Epoch: 1/2, step 210/53949 completed (loss: 5.360257148742676, acc: 0.23999999463558197)
[2025-02-17 17:39:36,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:36,433][root][INFO] - Training Epoch: 1/2, step 211/53949 completed (loss: 3.3596417903900146, acc: 0.1818181872367859)
[2025-02-17 17:39:36,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:36,903][root][INFO] - Training Epoch: 1/2, step 212/53949 completed (loss: 3.895639657974243, acc: 0.2777777910232544)
[2025-02-17 17:39:37,109][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:37,336][root][INFO] - Training Epoch: 1/2, step 213/53949 completed (loss: 4.610367298126221, acc: 0.20930232107639313)
[2025-02-17 17:39:37,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:37,728][root][INFO] - Training Epoch: 1/2, step 214/53949 completed (loss: 4.040295600891113, acc: 0.25)
[2025-02-17 17:39:37,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:38,091][root][INFO] - Training Epoch: 1/2, step 215/53949 completed (loss: 4.154323577880859, acc: 0.3333333432674408)
[2025-02-17 17:39:38,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:38,436][root][INFO] - Training Epoch: 1/2, step 216/53949 completed (loss: 1.7181882858276367, acc: 0.6000000238418579)
[2025-02-17 17:39:38,599][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:38,811][root][INFO] - Training Epoch: 1/2, step 217/53949 completed (loss: 1.7750067710876465, acc: 0.6666666865348816)
[2025-02-17 17:39:38,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:39,184][root][INFO] - Training Epoch: 1/2, step 218/53949 completed (loss: 2.4900498390197754, acc: 0.25)
[2025-02-17 17:39:39,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:39,551][root][INFO] - Training Epoch: 1/2, step 219/53949 completed (loss: 2.0062968730926514, acc: 0.6666666865348816)
[2025-02-17 17:39:39,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:39,975][root][INFO] - Training Epoch: 1/2, step 220/53949 completed (loss: 4.573429584503174, acc: 0.3333333432674408)
[2025-02-17 17:39:40,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:40,448][root][INFO] - Training Epoch: 1/2, step 221/53949 completed (loss: 3.8566253185272217, acc: 0.2368421107530594)
[2025-02-17 17:39:40,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:40,835][root][INFO] - Training Epoch: 1/2, step 222/53949 completed (loss: 4.1684064865112305, acc: 0.21875)
[2025-02-17 17:39:40,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:41,191][root][INFO] - Training Epoch: 1/2, step 223/53949 completed (loss: 5.188144683837891, acc: 0.25)
[2025-02-17 17:39:41,344][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:41,584][root][INFO] - Training Epoch: 1/2, step 224/53949 completed (loss: 5.1761088371276855, acc: 0.30434781312942505)
[2025-02-17 17:39:41,849][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:42,075][root][INFO] - Training Epoch: 1/2, step 225/53949 completed (loss: 3.565073251724243, acc: 0.30909091234207153)
[2025-02-17 17:39:42,249][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:42,466][root][INFO] - Training Epoch: 1/2, step 226/53949 completed (loss: 0.2721017003059387, acc: 1.0)
[2025-02-17 17:39:42,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:42,903][root][INFO] - Training Epoch: 1/2, step 227/53949 completed (loss: 4.854160785675049, acc: 0.11764705926179886)
[2025-02-17 17:39:43,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:43,349][root][INFO] - Training Epoch: 1/2, step 228/53949 completed (loss: 3.6318647861480713, acc: 0.42105263471603394)
[2025-02-17 17:39:43,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:43,749][root][INFO] - Training Epoch: 1/2, step 229/53949 completed (loss: 0.7713424563407898, acc: 0.75)
[2025-02-17 17:39:43,957][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:44,180][root][INFO] - Training Epoch: 1/2, step 230/53949 completed (loss: 3.5636298656463623, acc: 0.1818181872367859)
[2025-02-17 17:39:44,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:44,639][root][INFO] - Training Epoch: 1/2, step 231/53949 completed (loss: 4.369324207305908, acc: 0.260869562625885)
[2025-02-17 17:39:44,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:45,055][root][INFO] - Training Epoch: 1/2, step 232/53949 completed (loss: 5.069197177886963, acc: 0.1764705926179886)
[2025-02-17 17:39:45,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:45,454][root][INFO] - Training Epoch: 1/2, step 233/53949 completed (loss: 3.849350690841675, acc: 0.3571428656578064)
[2025-02-17 17:39:45,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:45,881][root][INFO] - Training Epoch: 1/2, step 234/53949 completed (loss: 3.2326676845550537, acc: 0.5)
[2025-02-17 17:39:46,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:46,297][root][INFO] - Training Epoch: 1/2, step 235/53949 completed (loss: 3.6825637817382812, acc: 0.3125)
[2025-02-17 17:39:46,459][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:46,686][root][INFO] - Training Epoch: 1/2, step 236/53949 completed (loss: 0.03930608555674553, acc: 1.0)
[2025-02-17 17:39:46,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:47,083][root][INFO] - Training Epoch: 1/2, step 237/53949 completed (loss: 4.603116035461426, acc: 0.2380952388048172)
[2025-02-17 17:39:47,271][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:47,487][root][INFO] - Training Epoch: 1/2, step 238/53949 completed (loss: 2.696976661682129, acc: 0.30000001192092896)
[2025-02-17 17:39:47,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:47,867][root][INFO] - Training Epoch: 1/2, step 239/53949 completed (loss: 1.8211307525634766, acc: 0.800000011920929)
[2025-02-17 17:39:48,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:48,279][root][INFO] - Training Epoch: 1/2, step 240/53949 completed (loss: 4.3227858543396, acc: 0.23333333432674408)
[2025-02-17 17:39:48,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:48,732][root][INFO] - Training Epoch: 1/2, step 241/53949 completed (loss: 4.938602447509766, acc: 0.1785714328289032)
[2025-02-17 17:39:48,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:49,077][root][INFO] - Training Epoch: 1/2, step 242/53949 completed (loss: 3.3274128437042236, acc: 0.3461538553237915)
[2025-02-17 17:39:49,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:49,456][root][INFO] - Training Epoch: 1/2, step 243/53949 completed (loss: 3.9622154235839844, acc: 0.3499999940395355)
[2025-02-17 17:39:49,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:49,833][root][INFO] - Training Epoch: 1/2, step 244/53949 completed (loss: 3.336050271987915, acc: 0.27272728085517883)
[2025-02-17 17:39:49,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:50,215][root][INFO] - Training Epoch: 1/2, step 245/53949 completed (loss: 4.655984878540039, acc: 0.1764705926179886)
[2025-02-17 17:39:50,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:50,618][root][INFO] - Training Epoch: 1/2, step 246/53949 completed (loss: 5.472309589385986, acc: 0.0833333358168602)
[2025-02-17 17:39:50,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:51,047][root][INFO] - Training Epoch: 1/2, step 247/53949 completed (loss: 3.751629114151001, acc: 0.24242424964904785)
[2025-02-17 17:39:51,229][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:51,451][root][INFO] - Training Epoch: 1/2, step 248/53949 completed (loss: 3.8095946311950684, acc: 0.21875)
[2025-02-17 17:39:51,634][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:51,861][root][INFO] - Training Epoch: 1/2, step 249/53949 completed (loss: 3.7954447269439697, acc: 0.23529411852359772)
[2025-02-17 17:39:52,028][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:52,264][root][INFO] - Training Epoch: 1/2, step 250/53949 completed (loss: 3.759268283843994, acc: 0.2380952388048172)
[2025-02-17 17:39:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:52,696][root][INFO] - Training Epoch: 1/2, step 251/53949 completed (loss: 4.591665744781494, acc: 0.20588235557079315)
[2025-02-17 17:39:52,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:53,168][root][INFO] - Training Epoch: 1/2, step 252/53949 completed (loss: 3.3000640869140625, acc: 0.3076923191547394)
[2025-02-17 17:39:53,337][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:53,557][root][INFO] - Training Epoch: 1/2, step 253/53949 completed (loss: 2.6230499744415283, acc: 0.2857142984867096)
[2025-02-17 17:39:53,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:53,971][root][INFO] - Training Epoch: 1/2, step 254/53949 completed (loss: 4.563345909118652, acc: 0.1428571492433548)
[2025-02-17 17:39:54,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:54,369][root][INFO] - Training Epoch: 1/2, step 255/53949 completed (loss: 3.7079334259033203, acc: 0.32499998807907104)
[2025-02-17 17:39:54,547][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:54,763][root][INFO] - Training Epoch: 1/2, step 256/53949 completed (loss: 3.317753314971924, acc: 0.3461538553237915)
[2025-02-17 17:39:54,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:55,201][root][INFO] - Training Epoch: 1/2, step 257/53949 completed (loss: 3.5272698402404785, acc: 0.3076923191547394)
[2025-02-17 17:39:55,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:55,647][root][INFO] - Training Epoch: 1/2, step 258/53949 completed (loss: 3.5037732124328613, acc: 0.29411765933036804)
[2025-02-17 17:39:55,797][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:56,019][root][INFO] - Training Epoch: 1/2, step 259/53949 completed (loss: 4.08367919921875, acc: 0.29032257199287415)
[2025-02-17 17:39:56,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:56,411][root][INFO] - Training Epoch: 1/2, step 260/53949 completed (loss: 2.3510141372680664, acc: 0.3636363744735718)
[2025-02-17 17:39:56,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:56,859][root][INFO] - Training Epoch: 1/2, step 261/53949 completed (loss: 3.8749818801879883, acc: 0.2926829159259796)
[2025-02-17 17:39:57,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:57,221][root][INFO] - Training Epoch: 1/2, step 262/53949 completed (loss: 5.006817817687988, acc: 0.25)
[2025-02-17 17:39:57,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:57,566][root][INFO] - Training Epoch: 1/2, step 263/53949 completed (loss: 1.6923929452896118, acc: 0.5)
[2025-02-17 17:39:57,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:57,942][root][INFO] - Training Epoch: 1/2, step 264/53949 completed (loss: 4.363193511962891, acc: 0.08695652335882187)
[2025-02-17 17:39:58,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:58,264][root][INFO] - Training Epoch: 1/2, step 265/53949 completed (loss: 1.8989040851593018, acc: 0.6000000238418579)
[2025-02-17 17:39:58,408][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:58,617][root][INFO] - Training Epoch: 1/2, step 266/53949 completed (loss: 0.5206362009048462, acc: 0.75)
[2025-02-17 17:39:58,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:59,007][root][INFO] - Training Epoch: 1/2, step 267/53949 completed (loss: 4.099161148071289, acc: 0.2857142984867096)
[2025-02-17 17:39:59,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:59,427][root][INFO] - Training Epoch: 1/2, step 268/53949 completed (loss: 2.819155693054199, acc: 0.42105263471603394)
[2025-02-17 17:39:59,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:39:59,863][root][INFO] - Training Epoch: 1/2, step 269/53949 completed (loss: 4.199146747589111, acc: 0.2631579041481018)
[2025-02-17 17:40:00,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:00,179][root][INFO] - Training Epoch: 1/2, step 270/53949 completed (loss: 5.835620403289795, acc: 0.25)
[2025-02-17 17:40:00,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:00,616][root][INFO] - Training Epoch: 1/2, step 271/53949 completed (loss: 4.520895004272461, acc: 0.2916666567325592)
[2025-02-17 17:40:00,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:01,017][root][INFO] - Training Epoch: 1/2, step 272/53949 completed (loss: 0.03248092532157898, acc: 1.0)
[2025-02-17 17:40:01,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:01,373][root][INFO] - Training Epoch: 1/2, step 273/53949 completed (loss: 3.8064911365509033, acc: 0.3589743673801422)
[2025-02-17 17:40:01,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:01,726][root][INFO] - Training Epoch: 1/2, step 274/53949 completed (loss: 0.12657421827316284, acc: 1.0)
[2025-02-17 17:40:01,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:02,158][root][INFO] - Training Epoch: 1/2, step 275/53949 completed (loss: 3.2353897094726562, acc: 0.4444444477558136)
[2025-02-17 17:40:02,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:02,530][root][INFO] - Training Epoch: 1/2, step 276/53949 completed (loss: 4.20933723449707, acc: 0.22727273404598236)
[2025-02-17 17:40:02,719][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:02,952][root][INFO] - Training Epoch: 1/2, step 277/53949 completed (loss: 4.202928066253662, acc: 0.17777778208255768)
[2025-02-17 17:40:03,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:03,384][root][INFO] - Training Epoch: 1/2, step 278/53949 completed (loss: 2.4407031536102295, acc: 0.3333333432674408)
[2025-02-17 17:40:03,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:03,756][root][INFO] - Training Epoch: 1/2, step 279/53949 completed (loss: 3.2452330589294434, acc: 0.4285714328289032)
[2025-02-17 17:40:03,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:04,096][root][INFO] - Training Epoch: 1/2, step 280/53949 completed (loss: 0.05630958825349808, acc: 1.0)
[2025-02-17 17:40:04,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:04,551][root][INFO] - Training Epoch: 1/2, step 281/53949 completed (loss: 0.16950705647468567, acc: 1.0)
[2025-02-17 17:40:04,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:04,953][root][INFO] - Training Epoch: 1/2, step 282/53949 completed (loss: 4.161081790924072, acc: 0.2916666567325592)
[2025-02-17 17:40:05,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:05,397][root][INFO] - Training Epoch: 1/2, step 283/53949 completed (loss: 4.164391994476318, acc: 0.15789473056793213)
[2025-02-17 17:40:05,577][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:05,807][root][INFO] - Training Epoch: 1/2, step 284/53949 completed (loss: 3.23940110206604, acc: 0.3076923191547394)
[2025-02-17 17:40:05,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:06,183][root][INFO] - Training Epoch: 1/2, step 285/53949 completed (loss: 4.25028133392334, acc: 0.21875)
[2025-02-17 17:40:06,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:06,631][root][INFO] - Training Epoch: 1/2, step 286/53949 completed (loss: 2.2627451419830322, acc: 0.5)
[2025-02-17 17:40:06,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:07,020][root][INFO] - Training Epoch: 1/2, step 287/53949 completed (loss: 3.265115261077881, acc: 0.3333333432674408)
[2025-02-17 17:40:07,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:07,440][root][INFO] - Training Epoch: 1/2, step 288/53949 completed (loss: 4.123073101043701, acc: 0.2083333283662796)
[2025-02-17 17:40:07,602][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:07,821][root][INFO] - Training Epoch: 1/2, step 289/53949 completed (loss: 2.9830121994018555, acc: 0.38181817531585693)
[2025-02-17 17:40:07,986][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:08,210][root][INFO] - Training Epoch: 1/2, step 290/53949 completed (loss: 3.980823278427124, acc: 0.2647058963775635)
[2025-02-17 17:40:08,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:08,583][root][INFO] - Training Epoch: 1/2, step 291/53949 completed (loss: 3.7019383907318115, acc: 0.3333333432674408)
[2025-02-17 17:40:08,756][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:08,969][root][INFO] - Training Epoch: 1/2, step 292/53949 completed (loss: 4.051068305969238, acc: 0.1428571492433548)
[2025-02-17 17:40:09,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:09,414][root][INFO] - Training Epoch: 1/2, step 293/53949 completed (loss: 4.1814093589782715, acc: 0.3125)
[2025-02-17 17:40:09,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:09,854][root][INFO] - Training Epoch: 1/2, step 294/53949 completed (loss: 0.8691118359565735, acc: 0.6666666865348816)
[2025-02-17 17:40:10,087][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:10,310][root][INFO] - Training Epoch: 1/2, step 295/53949 completed (loss: 2.288722515106201, acc: 0.4285714328289032)
[2025-02-17 17:40:10,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:10,703][root][INFO] - Training Epoch: 1/2, step 296/53949 completed (loss: 4.327171325683594, acc: 0.23333333432674408)
[2025-02-17 17:40:10,871][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:11,100][root][INFO] - Training Epoch: 1/2, step 297/53949 completed (loss: 3.314598560333252, acc: 0.31578946113586426)
[2025-02-17 17:40:11,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:11,541][root][INFO] - Training Epoch: 1/2, step 298/53949 completed (loss: 4.22948694229126, acc: 0.2222222238779068)
[2025-02-17 17:40:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:11,966][root][INFO] - Training Epoch: 1/2, step 299/53949 completed (loss: 1.7971762418746948, acc: 0.75)
[2025-02-17 17:40:12,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:12,331][root][INFO] - Training Epoch: 1/2, step 300/53949 completed (loss: 0.35061952471733093, acc: 1.0)
[2025-02-17 17:40:12,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:12,745][root][INFO] - Training Epoch: 1/2, step 301/53949 completed (loss: 2.843780279159546, acc: 0.43589743971824646)
[2025-02-17 17:40:12,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:13,185][root][INFO] - Training Epoch: 1/2, step 302/53949 completed (loss: 3.97059965133667, acc: 0.09375)
[2025-02-17 17:40:13,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:13,579][root][INFO] - Training Epoch: 1/2, step 303/53949 completed (loss: 4.009957313537598, acc: 0.29629629850387573)
[2025-02-17 17:40:13,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:14,000][root][INFO] - Training Epoch: 1/2, step 304/53949 completed (loss: 3.9339959621429443, acc: 0.3095238208770752)
[2025-02-17 17:40:14,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:14,360][root][INFO] - Training Epoch: 1/2, step 305/53949 completed (loss: 2.1230993270874023, acc: 0.5)
[2025-02-17 17:40:14,533][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:14,760][root][INFO] - Training Epoch: 1/2, step 306/53949 completed (loss: 5.081111431121826, acc: 0.15555556118488312)
[2025-02-17 17:40:14,950][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:15,172][root][INFO] - Training Epoch: 1/2, step 307/53949 completed (loss: 4.49646520614624, acc: 0.30000001192092896)
[2025-02-17 17:40:15,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:15,525][root][INFO] - Training Epoch: 1/2, step 308/53949 completed (loss: 3.895163059234619, acc: 0.2068965584039688)
[2025-02-17 17:40:15,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:15,942][root][INFO] - Training Epoch: 1/2, step 309/53949 completed (loss: 3.611865997314453, acc: 0.3125)
[2025-02-17 17:40:16,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:16,350][root][INFO] - Training Epoch: 1/2, step 310/53949 completed (loss: 4.359315872192383, acc: 0.20000000298023224)
[2025-02-17 17:40:16,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:16,803][root][INFO] - Training Epoch: 1/2, step 311/53949 completed (loss: 2.4201579093933105, acc: 0.3499999940395355)
[2025-02-17 17:40:16,951][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:17,167][root][INFO] - Training Epoch: 1/2, step 312/53949 completed (loss: 4.116213321685791, acc: 0.3055555522441864)
[2025-02-17 17:40:17,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:17,524][root][INFO] - Training Epoch: 1/2, step 313/53949 completed (loss: 3.5278608798980713, acc: 0.3333333432674408)
[2025-02-17 17:40:17,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:17,881][root][INFO] - Training Epoch: 1/2, step 314/53949 completed (loss: 4.023334980010986, acc: 0.36666667461395264)
[2025-02-17 17:40:18,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:18,179][root][INFO] - Training Epoch: 1/2, step 315/53949 completed (loss: 3.302994966506958, acc: 0.3499999940395355)
[2025-02-17 17:40:18,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:18,551][root][INFO] - Training Epoch: 1/2, step 316/53949 completed (loss: 1.1949089765548706, acc: 0.800000011920929)
[2025-02-17 17:40:18,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:18,982][root][INFO] - Training Epoch: 1/2, step 317/53949 completed (loss: 3.8705451488494873, acc: 0.3103448152542114)
[2025-02-17 17:40:19,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:19,357][root][INFO] - Training Epoch: 1/2, step 318/53949 completed (loss: 2.9151675701141357, acc: 0.2777777910232544)
[2025-02-17 17:40:19,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:19,765][root][INFO] - Training Epoch: 1/2, step 319/53949 completed (loss: 3.2974135875701904, acc: 0.29411765933036804)
[2025-02-17 17:40:19,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:20,177][root][INFO] - Training Epoch: 1/2, step 320/53949 completed (loss: 4.445127964019775, acc: 0.27586206793785095)
[2025-02-17 17:40:20,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:20,671][root][INFO] - Training Epoch: 1/2, step 321/53949 completed (loss: 4.311577320098877, acc: 0.22727273404598236)
[2025-02-17 17:40:20,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:21,111][root][INFO] - Training Epoch: 1/2, step 322/53949 completed (loss: 3.726733446121216, acc: 0.22727273404598236)
[2025-02-17 17:40:21,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:21,456][root][INFO] - Training Epoch: 1/2, step 323/53949 completed (loss: 3.6155805587768555, acc: 0.24390244483947754)
[2025-02-17 17:40:21,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:21,839][root][INFO] - Training Epoch: 1/2, step 324/53949 completed (loss: 3.8163089752197266, acc: 0.2857142984867096)
[2025-02-17 17:40:22,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:22,310][root][INFO] - Training Epoch: 1/2, step 325/53949 completed (loss: 4.541434288024902, acc: 0.3199999928474426)
[2025-02-17 17:40:22,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:22,754][root][INFO] - Training Epoch: 1/2, step 326/53949 completed (loss: 5.136382579803467, acc: 0.25)
[2025-02-17 17:40:22,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:23,142][root][INFO] - Training Epoch: 1/2, step 327/53949 completed (loss: 3.2483179569244385, acc: 0.27272728085517883)
[2025-02-17 17:40:23,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:23,545][root][INFO] - Training Epoch: 1/2, step 328/53949 completed (loss: 3.433580160140991, acc: 0.31111112236976624)
[2025-02-17 17:40:23,716][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:23,939][root][INFO] - Training Epoch: 1/2, step 329/53949 completed (loss: 3.979841709136963, acc: 0.3478260934352875)
[2025-02-17 17:40:24,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:24,367][root][INFO] - Training Epoch: 1/2, step 330/53949 completed (loss: 3.3932313919067383, acc: 0.25925925374031067)
[2025-02-17 17:40:24,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:24,728][root][INFO] - Training Epoch: 1/2, step 331/53949 completed (loss: 3.149657726287842, acc: 0.4444444477558136)
[2025-02-17 17:40:24,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:25,101][root][INFO] - Training Epoch: 1/2, step 332/53949 completed (loss: 3.0071170330047607, acc: 0.44999998807907104)
[2025-02-17 17:40:25,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:25,529][root][INFO] - Training Epoch: 1/2, step 333/53949 completed (loss: 3.5729401111602783, acc: 0.23529411852359772)
[2025-02-17 17:40:25,749][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:25,969][root][INFO] - Training Epoch: 1/2, step 334/53949 completed (loss: 2.6065022945404053, acc: 0.43478259444236755)
[2025-02-17 17:40:26,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:26,329][root][INFO] - Training Epoch: 1/2, step 335/53949 completed (loss: 4.519270420074463, acc: 0.1818181872367859)
[2025-02-17 17:40:26,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:26,777][root][INFO] - Training Epoch: 1/2, step 336/53949 completed (loss: 3.3510665893554688, acc: 0.3214285671710968)
[2025-02-17 17:40:26,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:27,179][root][INFO] - Training Epoch: 1/2, step 337/53949 completed (loss: 4.2721476554870605, acc: 0.15625)
[2025-02-17 17:40:27,354][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:27,587][root][INFO] - Training Epoch: 1/2, step 338/53949 completed (loss: 3.5099921226501465, acc: 0.23529411852359772)
[2025-02-17 17:40:27,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:28,001][root][INFO] - Training Epoch: 1/2, step 339/53949 completed (loss: 4.139034271240234, acc: 0.261904776096344)
[2025-02-17 17:40:28,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:28,441][root][INFO] - Training Epoch: 1/2, step 340/53949 completed (loss: 4.15276575088501, acc: 0.190476194024086)
[2025-02-17 17:40:28,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:28,882][root][INFO] - Training Epoch: 1/2, step 341/53949 completed (loss: 3.4972429275512695, acc: 0.2549019753932953)
[2025-02-17 17:40:29,083][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:29,289][root][INFO] - Training Epoch: 1/2, step 342/53949 completed (loss: 3.656719923019409, acc: 0.2542372941970825)
[2025-02-17 17:40:29,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:29,653][root][INFO] - Training Epoch: 1/2, step 343/53949 completed (loss: 2.63588809967041, acc: 0.5)
[2025-02-17 17:40:29,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:30,033][root][INFO] - Training Epoch: 1/2, step 344/53949 completed (loss: 3.103971242904663, acc: 0.3333333432674408)
[2025-02-17 17:40:30,186][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:30,409][root][INFO] - Training Epoch: 1/2, step 345/53949 completed (loss: 3.01745867729187, acc: 0.1428571492433548)
[2025-02-17 17:40:30,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:30,880][root][INFO] - Training Epoch: 1/2, step 346/53949 completed (loss: 4.680099964141846, acc: 0.2142857164144516)
[2025-02-17 17:40:31,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:31,265][root][INFO] - Training Epoch: 1/2, step 347/53949 completed (loss: 2.820126533508301, acc: 0.4375)
[2025-02-17 17:40:31,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:31,655][root][INFO] - Training Epoch: 1/2, step 348/53949 completed (loss: 3.064556360244751, acc: 0.3333333432674408)
[2025-02-17 17:40:31,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:32,052][root][INFO] - Training Epoch: 1/2, step 349/53949 completed (loss: 2.0428173542022705, acc: 0.5454545617103577)
[2025-02-17 17:40:32,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:32,492][root][INFO] - Training Epoch: 1/2, step 350/53949 completed (loss: 4.32841157913208, acc: 0.2666666805744171)
[2025-02-17 17:40:32,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:32,884][root][INFO] - Training Epoch: 1/2, step 351/53949 completed (loss: 3.3991658687591553, acc: 0.3333333432674408)
[2025-02-17 17:40:33,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:33,271][root][INFO] - Training Epoch: 1/2, step 352/53949 completed (loss: 1.6351945400238037, acc: 0.800000011920929)
[2025-02-17 17:40:33,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:33,666][root][INFO] - Training Epoch: 1/2, step 353/53949 completed (loss: 4.693648815155029, acc: 0.1818181872367859)
[2025-02-17 17:40:33,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:34,057][root][INFO] - Training Epoch: 1/2, step 354/53949 completed (loss: 1.8440698385238647, acc: 0.6000000238418579)
[2025-02-17 17:40:34,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:34,491][root][INFO] - Training Epoch: 1/2, step 355/53949 completed (loss: 2.8979363441467285, acc: 0.4137931168079376)
[2025-02-17 17:40:34,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:34,906][root][INFO] - Training Epoch: 1/2, step 356/53949 completed (loss: 4.048877239227295, acc: 0.3333333432674408)
[2025-02-17 17:40:35,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:35,270][root][INFO] - Training Epoch: 1/2, step 357/53949 completed (loss: 3.115368366241455, acc: 0.4285714328289032)
[2025-02-17 17:40:35,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:35,675][root][INFO] - Training Epoch: 1/2, step 358/53949 completed (loss: 4.103902816772461, acc: 0.20000000298023224)
[2025-02-17 17:40:35,854][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:36,075][root][INFO] - Training Epoch: 1/2, step 359/53949 completed (loss: 3.477753162384033, acc: 0.3333333432674408)
[2025-02-17 17:40:36,283][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:36,502][root][INFO] - Training Epoch: 1/2, step 360/53949 completed (loss: 3.3782432079315186, acc: 0.3199999928474426)
[2025-02-17 17:40:36,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:36,864][root][INFO] - Training Epoch: 1/2, step 361/53949 completed (loss: 3.012509822845459, acc: 0.3695652186870575)
[2025-02-17 17:40:37,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:37,326][root][INFO] - Training Epoch: 1/2, step 362/53949 completed (loss: 3.9350342750549316, acc: 0.30434781312942505)
[2025-02-17 17:40:37,498][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:37,724][root][INFO] - Training Epoch: 1/2, step 363/53949 completed (loss: 1.4719973802566528, acc: 0.75)
[2025-02-17 17:40:37,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:38,121][root][INFO] - Training Epoch: 1/2, step 364/53949 completed (loss: 2.968217611312866, acc: 0.4000000059604645)
[2025-02-17 17:40:38,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:38,516][root][INFO] - Training Epoch: 1/2, step 365/53949 completed (loss: 3.6140897274017334, acc: 0.3461538553237915)
[2025-02-17 17:40:38,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:38,947][root][INFO] - Training Epoch: 1/2, step 366/53949 completed (loss: 3.87070631980896, acc: 0.3035714328289032)
[2025-02-17 17:40:39,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:39,349][root][INFO] - Training Epoch: 1/2, step 367/53949 completed (loss: 1.7010475397109985, acc: 0.75)
[2025-02-17 17:40:39,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:39,784][root][INFO] - Training Epoch: 1/2, step 368/53949 completed (loss: 3.5473177433013916, acc: 0.2647058963775635)
[2025-02-17 17:40:39,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:40,204][root][INFO] - Training Epoch: 1/2, step 369/53949 completed (loss: 3.4615437984466553, acc: 0.37837839126586914)
[2025-02-17 17:40:40,394][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:40,626][root][INFO] - Training Epoch: 1/2, step 370/53949 completed (loss: 2.2040302753448486, acc: 0.6666666865348816)
[2025-02-17 17:40:40,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:41,086][root][INFO] - Training Epoch: 1/2, step 371/53949 completed (loss: 3.60250186920166, acc: 0.3333333432674408)
[2025-02-17 17:40:41,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:41,433][root][INFO] - Training Epoch: 1/2, step 372/53949 completed (loss: 4.354520320892334, acc: 0.4285714328289032)
[2025-02-17 17:40:41,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:41,795][root][INFO] - Training Epoch: 1/2, step 373/53949 completed (loss: 3.574502468109131, acc: 0.4117647111415863)
[2025-02-17 17:40:41,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:42,198][root][INFO] - Training Epoch: 1/2, step 374/53949 completed (loss: 2.8816099166870117, acc: 0.4533333480358124)
[2025-02-17 17:40:42,331][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:42,545][root][INFO] - Training Epoch: 1/2, step 375/53949 completed (loss: 2.7401862144470215, acc: 0.2857142984867096)
[2025-02-17 17:40:42,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:42,960][root][INFO] - Training Epoch: 1/2, step 376/53949 completed (loss: 3.1497132778167725, acc: 0.29411765933036804)
[2025-02-17 17:40:43,157][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:43,380][root][INFO] - Training Epoch: 1/2, step 377/53949 completed (loss: 3.188993453979492, acc: 0.4000000059604645)
[2025-02-17 17:40:43,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:43,794][root][INFO] - Training Epoch: 1/2, step 378/53949 completed (loss: 3.9819324016571045, acc: 0.46666666865348816)
[2025-02-17 17:40:43,982][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:44,195][root][INFO] - Training Epoch: 1/2, step 379/53949 completed (loss: 3.2495458126068115, acc: 0.3333333432674408)
[2025-02-17 17:40:44,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:44,639][root][INFO] - Training Epoch: 1/2, step 380/53949 completed (loss: 4.502643585205078, acc: 0.16129031777381897)
[2025-02-17 17:40:44,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:45,041][root][INFO] - Training Epoch: 1/2, step 381/53949 completed (loss: 3.749723196029663, acc: 0.3199999928474426)
[2025-02-17 17:40:45,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:45,510][root][INFO] - Training Epoch: 1/2, step 382/53949 completed (loss: 4.467081546783447, acc: 0.17241379618644714)
[2025-02-17 17:40:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:45,873][root][INFO] - Training Epoch: 1/2, step 383/53949 completed (loss: 3.7530875205993652, acc: 0.30434781312942505)
[2025-02-17 17:40:46,063][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:46,291][root][INFO] - Training Epoch: 1/2, step 384/53949 completed (loss: 4.190741062164307, acc: 0.23076923191547394)
[2025-02-17 17:40:46,441][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:46,666][root][INFO] - Training Epoch: 1/2, step 385/53949 completed (loss: 2.5966203212738037, acc: 0.4166666567325592)
[2025-02-17 17:40:46,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:47,053][root][INFO] - Training Epoch: 1/2, step 386/53949 completed (loss: 2.609623670578003, acc: 0.5)
[2025-02-17 17:40:47,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:47,468][root][INFO] - Training Epoch: 1/2, step 387/53949 completed (loss: 3.4246020317077637, acc: 0.30434781312942505)
[2025-02-17 17:40:47,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:47,875][root][INFO] - Training Epoch: 1/2, step 388/53949 completed (loss: 3.5175628662109375, acc: 0.29729729890823364)
[2025-02-17 17:40:48,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:48,282][root][INFO] - Training Epoch: 1/2, step 389/53949 completed (loss: 6.02766752243042, acc: 0.1666666716337204)
[2025-02-17 17:40:48,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:48,673][root][INFO] - Training Epoch: 1/2, step 390/53949 completed (loss: 3.90311598777771, acc: 0.27272728085517883)
[2025-02-17 17:40:48,805][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:49,057][root][INFO] - Training Epoch: 1/2, step 391/53949 completed (loss: 1.7387436628341675, acc: 0.6666666865348816)
[2025-02-17 17:40:49,279][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:49,492][root][INFO] - Training Epoch: 1/2, step 392/53949 completed (loss: 3.2590677738189697, acc: 0.32608696818351746)
[2025-02-17 17:40:49,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:49,892][root][INFO] - Training Epoch: 1/2, step 393/53949 completed (loss: 2.98089337348938, acc: 0.4444444477558136)
[2025-02-17 17:40:50,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:50,314][root][INFO] - Training Epoch: 1/2, step 394/53949 completed (loss: 4.274395942687988, acc: 0.28205129504203796)
[2025-02-17 17:40:50,465][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:50,679][root][INFO] - Training Epoch: 1/2, step 395/53949 completed (loss: 3.899765968322754, acc: 0.23529411852359772)
[2025-02-17 17:40:50,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:51,120][root][INFO] - Training Epoch: 1/2, step 396/53949 completed (loss: 3.8542332649230957, acc: 0.33870968222618103)
[2025-02-17 17:40:51,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:51,542][root][INFO] - Training Epoch: 1/2, step 397/53949 completed (loss: 2.7274081707000732, acc: 0.5)
[2025-02-17 17:40:51,710][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:51,930][root][INFO] - Training Epoch: 1/2, step 398/53949 completed (loss: 4.485141754150391, acc: 0.20000000298023224)
[2025-02-17 17:40:52,108][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:52,322][root][INFO] - Training Epoch: 1/2, step 399/53949 completed (loss: 4.798654079437256, acc: 0.13513512909412384)
[2025-02-17 17:40:52,483][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:52,705][root][INFO] - Training Epoch: 1/2, step 400/53949 completed (loss: 3.5737457275390625, acc: 0.23529411852359772)
[2025-02-17 17:40:52,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:53,136][root][INFO] - Training Epoch: 1/2, step 401/53949 completed (loss: 3.829296827316284, acc: 0.3636363744735718)
[2025-02-17 17:40:53,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:53,545][root][INFO] - Training Epoch: 1/2, step 402/53949 completed (loss: 3.778125524520874, acc: 0.380952388048172)
[2025-02-17 17:40:53,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:54,000][root][INFO] - Training Epoch: 1/2, step 403/53949 completed (loss: 3.770911693572998, acc: 0.2631579041481018)
[2025-02-17 17:40:54,198][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:54,415][root][INFO] - Training Epoch: 1/2, step 404/53949 completed (loss: 3.6998937129974365, acc: 0.18333333730697632)
[2025-02-17 17:40:54,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:54,838][root][INFO] - Training Epoch: 1/2, step 405/53949 completed (loss: 3.9292550086975098, acc: 0.25806450843811035)
[2025-02-17 17:40:54,974][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:55,182][root][INFO] - Training Epoch: 1/2, step 406/53949 completed (loss: 0.1500086635351181, acc: 1.0)
[2025-02-17 17:40:55,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:55,598][root][INFO] - Training Epoch: 1/2, step 407/53949 completed (loss: 3.6981453895568848, acc: 0.22499999403953552)
[2025-02-17 17:40:55,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:55,992][root][INFO] - Training Epoch: 1/2, step 408/53949 completed (loss: 0.40640345215797424, acc: 0.800000011920929)
[2025-02-17 17:40:56,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:56,357][root][INFO] - Training Epoch: 1/2, step 409/53949 completed (loss: 4.2266764640808105, acc: 0.30000001192092896)
[2025-02-17 17:40:56,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:56,725][root][INFO] - Training Epoch: 1/2, step 410/53949 completed (loss: 3.939821243286133, acc: 0.20000000298023224)
[2025-02-17 17:40:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:57,141][root][INFO] - Training Epoch: 1/2, step 411/53949 completed (loss: 3.3412234783172607, acc: 0.3333333432674408)
[2025-02-17 17:40:57,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:57,541][root][INFO] - Training Epoch: 1/2, step 412/53949 completed (loss: 3.580261707305908, acc: 0.4035087823867798)
[2025-02-17 17:40:57,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:57,975][root][INFO] - Training Epoch: 1/2, step 413/53949 completed (loss: 3.7293365001678467, acc: 0.20512820780277252)
[2025-02-17 17:40:58,217][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:58,441][root][INFO] - Training Epoch: 1/2, step 414/53949 completed (loss: 4.292259693145752, acc: 0.3235294222831726)
[2025-02-17 17:40:58,614][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:58,862][root][INFO] - Training Epoch: 1/2, step 415/53949 completed (loss: 3.846259832382202, acc: 0.2800000011920929)
[2025-02-17 17:40:59,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:59,248][root][INFO] - Training Epoch: 1/2, step 416/53949 completed (loss: 4.177762985229492, acc: 0.37931033968925476)
[2025-02-17 17:40:59,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:40:59,617][root][INFO] - Training Epoch: 1/2, step 417/53949 completed (loss: 3.6666691303253174, acc: 0.2857142984867096)
[2025-02-17 17:40:59,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:00,002][root][INFO] - Training Epoch: 1/2, step 418/53949 completed (loss: 2.4176864624023438, acc: 0.5)
[2025-02-17 17:41:00,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:00,463][root][INFO] - Training Epoch: 1/2, step 419/53949 completed (loss: 3.7311713695526123, acc: 0.3499999940395355)
[2025-02-17 17:41:00,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:00,850][root][INFO] - Training Epoch: 1/2, step 420/53949 completed (loss: 4.318418502807617, acc: 0.1818181872367859)
[2025-02-17 17:41:01,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:01,243][root][INFO] - Training Epoch: 1/2, step 421/53949 completed (loss: 0.9995850324630737, acc: 0.75)
[2025-02-17 17:41:01,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:01,633][root][INFO] - Training Epoch: 1/2, step 422/53949 completed (loss: 2.8288161754608154, acc: 0.31578946113586426)
[2025-02-17 17:41:01,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:02,043][root][INFO] - Training Epoch: 1/2, step 423/53949 completed (loss: 3.9451260566711426, acc: 0.2926829159259796)
[2025-02-17 17:41:02,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:02,441][root][INFO] - Training Epoch: 1/2, step 424/53949 completed (loss: 4.381081581115723, acc: 0.2777777910232544)
[2025-02-17 17:41:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:02,894][root][INFO] - Training Epoch: 1/2, step 425/53949 completed (loss: 4.145476818084717, acc: 0.190476194024086)
[2025-02-17 17:41:03,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:03,434][root][INFO] - Training Epoch: 1/2, step 426/53949 completed (loss: 3.429547071456909, acc: 0.2631579041481018)
[2025-02-17 17:41:03,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:03,861][root][INFO] - Training Epoch: 1/2, step 427/53949 completed (loss: 4.44346809387207, acc: 0.25925925374031067)
[2025-02-17 17:41:04,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:04,264][root][INFO] - Training Epoch: 1/2, step 428/53949 completed (loss: 4.072032928466797, acc: 0.23076923191547394)
[2025-02-17 17:41:04,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:04,651][root][INFO] - Training Epoch: 1/2, step 429/53949 completed (loss: 3.058492422103882, acc: 0.3214285671710968)
[2025-02-17 17:41:04,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:05,045][root][INFO] - Training Epoch: 1/2, step 430/53949 completed (loss: 3.457615375518799, acc: 0.2222222238779068)
[2025-02-17 17:41:05,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:05,454][root][INFO] - Training Epoch: 1/2, step 431/53949 completed (loss: 4.645931243896484, acc: 0.2631579041481018)
[2025-02-17 17:41:05,622][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:05,848][root][INFO] - Training Epoch: 1/2, step 432/53949 completed (loss: 2.8026695251464844, acc: 0.38461539149284363)
[2025-02-17 17:41:06,029][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:06,272][root][INFO] - Training Epoch: 1/2, step 433/53949 completed (loss: 3.0391900539398193, acc: 0.42307692766189575)
[2025-02-17 17:41:06,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:06,703][root][INFO] - Training Epoch: 1/2, step 434/53949 completed (loss: 3.3930726051330566, acc: 0.3589743673801422)
[2025-02-17 17:41:06,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:07,098][root][INFO] - Training Epoch: 1/2, step 435/53949 completed (loss: 3.371210813522339, acc: 0.3720930218696594)
[2025-02-17 17:41:07,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:07,520][root][INFO] - Training Epoch: 1/2, step 436/53949 completed (loss: 3.8583130836486816, acc: 0.27272728085517883)
[2025-02-17 17:41:07,683][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:07,900][root][INFO] - Training Epoch: 1/2, step 437/53949 completed (loss: 2.403249740600586, acc: 0.4166666567325592)
[2025-02-17 17:41:08,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:08,259][root][INFO] - Training Epoch: 1/2, step 438/53949 completed (loss: 3.6128833293914795, acc: 0.23529411852359772)
[2025-02-17 17:41:08,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:08,675][root][INFO] - Training Epoch: 1/2, step 439/53949 completed (loss: 4.693514823913574, acc: 0.1304347813129425)
[2025-02-17 17:41:08,846][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:09,078][root][INFO] - Training Epoch: 1/2, step 440/53949 completed (loss: 2.646946430206299, acc: 0.40625)
[2025-02-17 17:41:09,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:09,524][root][INFO] - Training Epoch: 1/2, step 441/53949 completed (loss: 3.5234408378601074, acc: 0.26923078298568726)
[2025-02-17 17:41:09,690][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:09,902][root][INFO] - Training Epoch: 1/2, step 442/53949 completed (loss: 3.668323516845703, acc: 0.2916666567325592)
[2025-02-17 17:41:10,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:10,320][root][INFO] - Training Epoch: 1/2, step 443/53949 completed (loss: 4.033279895782471, acc: 0.22580644488334656)
[2025-02-17 17:41:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:10,735][root][INFO] - Training Epoch: 1/2, step 444/53949 completed (loss: 3.304722309112549, acc: 0.3333333432674408)
[2025-02-17 17:41:10,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:11,221][root][INFO] - Training Epoch: 1/2, step 445/53949 completed (loss: 4.017843246459961, acc: 0.2368421107530594)
[2025-02-17 17:41:11,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:11,597][root][INFO] - Training Epoch: 1/2, step 446/53949 completed (loss: 4.005070686340332, acc: 0.21276596188545227)
[2025-02-17 17:41:11,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:12,038][root][INFO] - Training Epoch: 1/2, step 447/53949 completed (loss: 3.3546934127807617, acc: 0.40909090638160706)
[2025-02-17 17:41:12,201][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:12,412][root][INFO] - Training Epoch: 1/2, step 448/53949 completed (loss: 1.9443544149398804, acc: 0.3333333432674408)
[2025-02-17 17:41:12,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:12,786][root][INFO] - Training Epoch: 1/2, step 449/53949 completed (loss: 2.712449312210083, acc: 0.6000000238418579)
[2025-02-17 17:41:12,961][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:13,182][root][INFO] - Training Epoch: 1/2, step 450/53949 completed (loss: 2.384453773498535, acc: 0.5333333611488342)
[2025-02-17 17:41:13,364][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:13,601][root][INFO] - Training Epoch: 1/2, step 451/53949 completed (loss: 3.118117094039917, acc: 0.34210526943206787)
[2025-02-17 17:41:13,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:14,026][root][INFO] - Training Epoch: 1/2, step 452/53949 completed (loss: 3.5708303451538086, acc: 0.38461539149284363)
[2025-02-17 17:41:14,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:14,387][root][INFO] - Training Epoch: 1/2, step 453/53949 completed (loss: 4.521254539489746, acc: 0.125)
[2025-02-17 17:41:14,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:14,820][root][INFO] - Training Epoch: 1/2, step 454/53949 completed (loss: 3.8580639362335205, acc: 0.2083333283662796)
[2025-02-17 17:41:15,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:15,252][root][INFO] - Training Epoch: 1/2, step 455/53949 completed (loss: 2.342158079147339, acc: 0.5714285969734192)
[2025-02-17 17:41:15,430][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:15,656][root][INFO] - Training Epoch: 1/2, step 456/53949 completed (loss: 4.086178302764893, acc: 0.30000001192092896)
[2025-02-17 17:41:15,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:16,054][root][INFO] - Training Epoch: 1/2, step 457/53949 completed (loss: 4.513911247253418, acc: 0.17499999701976776)
[2025-02-17 17:41:16,228][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:16,443][root][INFO] - Training Epoch: 1/2, step 458/53949 completed (loss: 3.232908248901367, acc: 0.4444444477558136)
[2025-02-17 17:41:16,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:16,832][root][INFO] - Training Epoch: 1/2, step 459/53949 completed (loss: 2.6392643451690674, acc: 0.4285714328289032)
[2025-02-17 17:41:17,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:17,284][root][INFO] - Training Epoch: 1/2, step 460/53949 completed (loss: 3.8376593589782715, acc: 0.3214285671710968)
[2025-02-17 17:41:17,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:17,689][root][INFO] - Training Epoch: 1/2, step 461/53949 completed (loss: 3.5329315662384033, acc: 0.4000000059604645)
[2025-02-17 17:41:17,852][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:18,092][root][INFO] - Training Epoch: 1/2, step 462/53949 completed (loss: 2.518739700317383, acc: 0.4736842215061188)
[2025-02-17 17:41:18,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:18,550][root][INFO] - Training Epoch: 1/2, step 463/53949 completed (loss: 3.4259960651397705, acc: 0.4000000059604645)
[2025-02-17 17:41:18,730][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:18,960][root][INFO] - Training Epoch: 1/2, step 464/53949 completed (loss: 2.170684814453125, acc: 0.6666666865348816)
[2025-02-17 17:41:19,164][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:19,385][root][INFO] - Training Epoch: 1/2, step 465/53949 completed (loss: 4.537420272827148, acc: 0.16129031777381897)
[2025-02-17 17:41:19,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:19,773][root][INFO] - Training Epoch: 1/2, step 466/53949 completed (loss: 2.35089373588562, acc: 0.375)
[2025-02-17 17:41:19,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:20,134][root][INFO] - Training Epoch: 1/2, step 467/53949 completed (loss: 3.6989614963531494, acc: 0.5555555820465088)
[2025-02-17 17:41:20,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:20,563][root][INFO] - Training Epoch: 1/2, step 468/53949 completed (loss: 3.1270129680633545, acc: 0.3414634168148041)
[2025-02-17 17:41:20,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:20,912][root][INFO] - Training Epoch: 1/2, step 469/53949 completed (loss: 0.075340636074543, acc: 1.0)
[2025-02-17 17:41:21,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:21,287][root][INFO] - Training Epoch: 1/2, step 470/53949 completed (loss: 2.920193672180176, acc: 0.3333333432674408)
[2025-02-17 17:41:21,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:21,740][root][INFO] - Training Epoch: 1/2, step 471/53949 completed (loss: 2.77445387840271, acc: 0.30000001192092896)
[2025-02-17 17:41:21,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:22,213][root][INFO] - Training Epoch: 1/2, step 472/53949 completed (loss: 3.557907819747925, acc: 0.30000001192092896)
[2025-02-17 17:41:22,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:22,638][root][INFO] - Training Epoch: 1/2, step 473/53949 completed (loss: 3.9313442707061768, acc: 0.2631579041481018)
[2025-02-17 17:41:22,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:23,087][root][INFO] - Training Epoch: 1/2, step 474/53949 completed (loss: 2.7310454845428467, acc: 0.25)
[2025-02-17 17:41:23,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:23,458][root][INFO] - Training Epoch: 1/2, step 475/53949 completed (loss: 3.080514907836914, acc: 0.3571428656578064)
[2025-02-17 17:41:23,629][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:23,874][root][INFO] - Training Epoch: 1/2, step 476/53949 completed (loss: 2.520341634750366, acc: 0.48148149251937866)
[2025-02-17 17:41:24,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:24,270][root][INFO] - Training Epoch: 1/2, step 477/53949 completed (loss: 3.995581865310669, acc: 0.260869562625885)
[2025-02-17 17:41:24,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:24,663][root][INFO] - Training Epoch: 1/2, step 478/53949 completed (loss: 3.5190160274505615, acc: 0.31578946113586426)
[2025-02-17 17:41:24,807][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:25,021][root][INFO] - Training Epoch: 1/2, step 479/53949 completed (loss: 3.9996376037597656, acc: 0.2926829159259796)
[2025-02-17 17:41:25,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:25,391][root][INFO] - Training Epoch: 1/2, step 480/53949 completed (loss: 3.1303391456604004, acc: 0.25)
[2025-02-17 17:41:25,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:25,769][root][INFO] - Training Epoch: 1/2, step 481/53949 completed (loss: 4.345469951629639, acc: 0.1538461595773697)
[2025-02-17 17:41:25,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:26,197][root][INFO] - Training Epoch: 1/2, step 482/53949 completed (loss: 5.563484191894531, acc: 0.25)
[2025-02-17 17:41:26,355][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:26,582][root][INFO] - Training Epoch: 1/2, step 483/53949 completed (loss: 2.4194469451904297, acc: 0.4444444477558136)
[2025-02-17 17:41:26,788][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:27,019][root][INFO] - Training Epoch: 1/2, step 484/53949 completed (loss: 3.6102468967437744, acc: 0.3333333432674408)
[2025-02-17 17:41:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:27,428][root][INFO] - Training Epoch: 1/2, step 485/53949 completed (loss: 1.545103907585144, acc: 0.7142857313156128)
[2025-02-17 17:41:27,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:27,847][root][INFO] - Training Epoch: 1/2, step 486/53949 completed (loss: 3.44120454788208, acc: 0.2857142984867096)
[2025-02-17 17:41:28,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:28,278][root][INFO] - Training Epoch: 1/2, step 487/53949 completed (loss: 3.8248701095581055, acc: 0.25806450843811035)
[2025-02-17 17:41:28,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:28,714][root][INFO] - Training Epoch: 1/2, step 488/53949 completed (loss: 1.3443474769592285, acc: 0.75)
[2025-02-17 17:41:28,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:29,120][root][INFO] - Training Epoch: 1/2, step 489/53949 completed (loss: 3.702620506286621, acc: 0.23999999463558197)
[2025-02-17 17:41:29,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:29,516][root][INFO] - Training Epoch: 1/2, step 490/53949 completed (loss: 3.3620717525482178, acc: 0.4545454680919647)
[2025-02-17 17:41:29,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:29,948][root][INFO] - Training Epoch: 1/2, step 491/53949 completed (loss: 4.117579460144043, acc: 0.2666666805744171)
[2025-02-17 17:41:30,104][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:30,326][root][INFO] - Training Epoch: 1/2, step 492/53949 completed (loss: 3.7621066570281982, acc: 0.23076923191547394)
[2025-02-17 17:41:30,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:30,699][root][INFO] - Training Epoch: 1/2, step 493/53949 completed (loss: 3.1523373126983643, acc: 0.3125)
[2025-02-17 17:41:30,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:31,117][root][INFO] - Training Epoch: 1/2, step 494/53949 completed (loss: 4.946234703063965, acc: 0.3684210479259491)
[2025-02-17 17:41:31,362][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:31,594][root][INFO] - Training Epoch: 1/2, step 495/53949 completed (loss: 3.923842668533325, acc: 0.26530611515045166)
[2025-02-17 17:41:31,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:32,056][root][INFO] - Training Epoch: 1/2, step 496/53949 completed (loss: 4.1118245124816895, acc: 0.2666666805744171)
[2025-02-17 17:41:32,289][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:32,517][root][INFO] - Training Epoch: 1/2, step 497/53949 completed (loss: 3.931323766708374, acc: 0.2666666805744171)
[2025-02-17 17:41:32,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:32,893][root][INFO] - Training Epoch: 1/2, step 498/53949 completed (loss: 3.902761459350586, acc: 0.1034482792019844)
[2025-02-17 17:41:33,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:33,344][root][INFO] - Training Epoch: 1/2, step 499/53949 completed (loss: 3.848388195037842, acc: 0.1428571492433548)
[2025-02-17 17:41:33,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:33,771][root][INFO] - Training Epoch: 1/2, step 500/53949 completed (loss: 3.2803289890289307, acc: 0.38461539149284363)
[2025-02-17 17:41:33,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:34,121][root][INFO] - Training Epoch: 1/2, step 501/53949 completed (loss: 3.0207626819610596, acc: 0.3571428656578064)
[2025-02-17 17:41:34,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:34,518][root][INFO] - Training Epoch: 1/2, step 502/53949 completed (loss: 1.733199119567871, acc: 0.5714285969734192)
[2025-02-17 17:41:34,715][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:34,956][root][INFO] - Training Epoch: 1/2, step 503/53949 completed (loss: 5.7008562088012695, acc: 0.5)
[2025-02-17 17:41:35,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:35,457][root][INFO] - Training Epoch: 1/2, step 504/53949 completed (loss: 3.8981945514678955, acc: 0.3125)
[2025-02-17 17:41:35,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:35,819][root][INFO] - Training Epoch: 1/2, step 505/53949 completed (loss: 3.472397565841675, acc: 0.3333333432674408)
[2025-02-17 17:41:35,976][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:36,171][root][INFO] - Training Epoch: 1/2, step 506/53949 completed (loss: 3.1973071098327637, acc: 0.3461538553237915)
[2025-02-17 17:41:36,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:36,531][root][INFO] - Training Epoch: 1/2, step 507/53949 completed (loss: 2.0322697162628174, acc: 0.5)
[2025-02-17 17:41:36,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:36,903][root][INFO] - Training Epoch: 1/2, step 508/53949 completed (loss: 0.16458681225776672, acc: 1.0)
[2025-02-17 17:41:37,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:37,255][root][INFO] - Training Epoch: 1/2, step 509/53949 completed (loss: 2.827096462249756, acc: 0.5)
[2025-02-17 17:41:37,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:37,651][root][INFO] - Training Epoch: 1/2, step 510/53949 completed (loss: 4.189937591552734, acc: 0.25925925374031067)
[2025-02-17 17:41:37,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:38,045][root][INFO] - Training Epoch: 1/2, step 511/53949 completed (loss: 4.108794212341309, acc: 0.3499999940395355)
[2025-02-17 17:41:38,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:38,515][root][INFO] - Training Epoch: 1/2, step 512/53949 completed (loss: 3.952484369277954, acc: 0.27659574151039124)
[2025-02-17 17:41:38,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:38,902][root][INFO] - Training Epoch: 1/2, step 513/53949 completed (loss: 3.150887966156006, acc: 0.3333333432674408)
[2025-02-17 17:41:39,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:39,354][root][INFO] - Training Epoch: 1/2, step 514/53949 completed (loss: 3.3009698390960693, acc: 0.3888888955116272)
[2025-02-17 17:41:39,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:39,805][root][INFO] - Training Epoch: 1/2, step 515/53949 completed (loss: 3.981365203857422, acc: 0.3142857253551483)
[2025-02-17 17:41:40,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:40,236][root][INFO] - Training Epoch: 1/2, step 516/53949 completed (loss: 3.440063953399658, acc: 0.4000000059604645)
[2025-02-17 17:41:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:40,663][root][INFO] - Training Epoch: 1/2, step 517/53949 completed (loss: 4.122237682342529, acc: 0.13793103396892548)
[2025-02-17 17:41:40,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:41,156][root][INFO] - Training Epoch: 1/2, step 518/53949 completed (loss: 0.6109030842781067, acc: 0.75)
[2025-02-17 17:41:41,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:41,600][root][INFO] - Training Epoch: 1/2, step 519/53949 completed (loss: 2.78507661819458, acc: 0.4399999976158142)
[2025-02-17 17:41:41,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:42,006][root][INFO] - Training Epoch: 1/2, step 520/53949 completed (loss: 2.540639638900757, acc: 0.27272728085517883)
[2025-02-17 17:41:42,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:42,362][root][INFO] - Training Epoch: 1/2, step 521/53949 completed (loss: 3.3527867794036865, acc: 0.3333333432674408)
[2025-02-17 17:41:42,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:42,829][root][INFO] - Training Epoch: 1/2, step 522/53949 completed (loss: 4.1236162185668945, acc: 0.09090909361839294)
[2025-02-17 17:41:43,007][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:43,227][root][INFO] - Training Epoch: 1/2, step 523/53949 completed (loss: 1.950640082359314, acc: 0.5)
[2025-02-17 17:41:43,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:43,571][root][INFO] - Training Epoch: 1/2, step 524/53949 completed (loss: 1.4285004138946533, acc: 0.5454545617103577)
[2025-02-17 17:41:43,714][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:43,928][root][INFO] - Training Epoch: 1/2, step 525/53949 completed (loss: 3.3406269550323486, acc: 0.30000001192092896)
[2025-02-17 17:41:44,046][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:44,266][root][INFO] - Training Epoch: 1/2, step 526/53949 completed (loss: 3.165799617767334, acc: 0.27272728085517883)
[2025-02-17 17:41:44,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:44,654][root][INFO] - Training Epoch: 1/2, step 527/53949 completed (loss: 3.965198278427124, acc: 0.1538461595773697)
[2025-02-17 17:41:44,826][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:45,047][root][INFO] - Training Epoch: 1/2, step 528/53949 completed (loss: 3.9227914810180664, acc: 0.28125)
[2025-02-17 17:41:45,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:45,472][root][INFO] - Training Epoch: 1/2, step 529/53949 completed (loss: 1.9485543966293335, acc: 0.699999988079071)
[2025-02-17 17:41:45,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:45,885][root][INFO] - Training Epoch: 1/2, step 530/53949 completed (loss: 3.251401424407959, acc: 0.3333333432674408)
[2025-02-17 17:41:46,073][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:46,311][root][INFO] - Training Epoch: 1/2, step 531/53949 completed (loss: 4.57417106628418, acc: 0.25)
[2025-02-17 17:41:46,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:46,762][root][INFO] - Training Epoch: 1/2, step 532/53949 completed (loss: 4.282602787017822, acc: 0.25)
[2025-02-17 17:41:46,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:47,141][root][INFO] - Training Epoch: 1/2, step 533/53949 completed (loss: 3.3684427738189697, acc: 0.3333333432674408)
[2025-02-17 17:41:47,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:47,601][root][INFO] - Training Epoch: 1/2, step 534/53949 completed (loss: 4.483298301696777, acc: 0.1111111119389534)
[2025-02-17 17:41:47,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:48,021][root][INFO] - Training Epoch: 1/2, step 535/53949 completed (loss: 4.540865898132324, acc: 0.3448275923728943)
[2025-02-17 17:41:48,265][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:48,537][root][INFO] - Training Epoch: 1/2, step 536/53949 completed (loss: 3.5980324745178223, acc: 0.21875)
[2025-02-17 17:41:48,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:48,989][root][INFO] - Training Epoch: 1/2, step 537/53949 completed (loss: 3.7121264934539795, acc: 0.2222222238779068)
[2025-02-17 17:41:49,189][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:49,424][root][INFO] - Training Epoch: 1/2, step 538/53949 completed (loss: 3.451730251312256, acc: 0.2857142984867096)
[2025-02-17 17:41:49,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:49,802][root][INFO] - Training Epoch: 1/2, step 539/53949 completed (loss: 3.1402666568756104, acc: 0.3913043439388275)
[2025-02-17 17:41:49,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:50,206][root][INFO] - Training Epoch: 1/2, step 540/53949 completed (loss: 3.4334232807159424, acc: 0.44999998807907104)
[2025-02-17 17:41:50,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:50,594][root][INFO] - Training Epoch: 1/2, step 541/53949 completed (loss: 2.014385461807251, acc: 0.6363636255264282)
[2025-02-17 17:41:50,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:50,999][root][INFO] - Training Epoch: 1/2, step 542/53949 completed (loss: 4.714791297912598, acc: 0.25)
[2025-02-17 17:41:51,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:51,396][root][INFO] - Training Epoch: 1/2, step 543/53949 completed (loss: 3.164794921875, acc: 0.2857142984867096)
[2025-02-17 17:41:51,575][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:51,798][root][INFO] - Training Epoch: 1/2, step 544/53949 completed (loss: 3.5587873458862305, acc: 0.261904776096344)
[2025-02-17 17:41:51,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:52,156][root][INFO] - Training Epoch: 1/2, step 545/53949 completed (loss: 5.09985876083374, acc: 0.375)
[2025-02-17 17:41:52,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:52,575][root][INFO] - Training Epoch: 1/2, step 546/53949 completed (loss: 3.392526865005493, acc: 0.3333333432674408)
[2025-02-17 17:41:52,791][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:53,018][root][INFO] - Training Epoch: 1/2, step 547/53949 completed (loss: 3.3977038860321045, acc: 0.29411765933036804)
[2025-02-17 17:41:53,222][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:53,457][root][INFO] - Training Epoch: 1/2, step 548/53949 completed (loss: 3.2019307613372803, acc: 0.37931033968925476)
[2025-02-17 17:41:53,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:53,904][root][INFO] - Training Epoch: 1/2, step 549/53949 completed (loss: 3.018184185028076, acc: 0.3333333432674408)
[2025-02-17 17:41:54,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:54,323][root][INFO] - Training Epoch: 1/2, step 550/53949 completed (loss: 3.2633910179138184, acc: 0.34375)
[2025-02-17 17:41:54,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:54,728][root][INFO] - Training Epoch: 1/2, step 551/53949 completed (loss: 2.918804883956909, acc: 0.4150943458080292)
[2025-02-17 17:41:54,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:55,092][root][INFO] - Training Epoch: 1/2, step 552/53949 completed (loss: 3.472341537475586, acc: 0.25)
[2025-02-17 17:41:55,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:55,527][root][INFO] - Training Epoch: 1/2, step 553/53949 completed (loss: 4.5658979415893555, acc: 0.2777777910232544)
[2025-02-17 17:41:55,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:55,917][root][INFO] - Training Epoch: 1/2, step 554/53949 completed (loss: 2.715705394744873, acc: 0.3499999940395355)
[2025-02-17 17:41:56,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:56,273][root][INFO] - Training Epoch: 1/2, step 555/53949 completed (loss: 2.905999183654785, acc: 0.5)
[2025-02-17 17:41:56,446][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:56,667][root][INFO] - Training Epoch: 1/2, step 556/53949 completed (loss: 3.6958088874816895, acc: 0.24137930572032928)
[2025-02-17 17:41:56,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:57,037][root][INFO] - Training Epoch: 1/2, step 557/53949 completed (loss: 2.7107152938842773, acc: 0.5)
[2025-02-17 17:41:57,203][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:57,440][root][INFO] - Training Epoch: 1/2, step 558/53949 completed (loss: 2.341913938522339, acc: 0.529411792755127)
[2025-02-17 17:41:57,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:57,798][root][INFO] - Training Epoch: 1/2, step 559/53949 completed (loss: 2.2505440711975098, acc: 0.4285714328289032)
[2025-02-17 17:41:57,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:58,193][root][INFO] - Training Epoch: 1/2, step 560/53949 completed (loss: 3.426104784011841, acc: 0.27586206793785095)
[2025-02-17 17:41:58,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:58,601][root][INFO] - Training Epoch: 1/2, step 561/53949 completed (loss: 0.09330496937036514, acc: 1.0)
[2025-02-17 17:41:58,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:59,028][root][INFO] - Training Epoch: 1/2, step 562/53949 completed (loss: 2.4911253452301025, acc: 0.4545454680919647)
[2025-02-17 17:41:59,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:59,439][root][INFO] - Training Epoch: 1/2, step 563/53949 completed (loss: 3.0179121494293213, acc: 0.3636363744735718)
[2025-02-17 17:41:59,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:41:59,869][root][INFO] - Training Epoch: 1/2, step 564/53949 completed (loss: 3.6894278526306152, acc: 0.27272728085517883)
[2025-02-17 17:42:00,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:00,244][root][INFO] - Training Epoch: 1/2, step 565/53949 completed (loss: 2.9583632946014404, acc: 0.4761904776096344)
[2025-02-17 17:42:00,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:00,613][root][INFO] - Training Epoch: 1/2, step 566/53949 completed (loss: 3.315312147140503, acc: 0.2666666805744171)
[2025-02-17 17:42:00,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:01,042][root][INFO] - Training Epoch: 1/2, step 567/53949 completed (loss: 2.305455446243286, acc: 0.375)
[2025-02-17 17:42:01,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:01,412][root][INFO] - Training Epoch: 1/2, step 568/53949 completed (loss: 3.2066259384155273, acc: 0.3181818127632141)
[2025-02-17 17:42:01,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:01,800][root][INFO] - Training Epoch: 1/2, step 569/53949 completed (loss: 3.8178327083587646, acc: 0.2448979616165161)
[2025-02-17 17:42:01,967][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:02,197][root][INFO] - Training Epoch: 1/2, step 570/53949 completed (loss: 4.39323091506958, acc: 0.25925925374031067)
[2025-02-17 17:42:02,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:02,583][root][INFO] - Training Epoch: 1/2, step 571/53949 completed (loss: 3.2074391841888428, acc: 0.27272728085517883)
[2025-02-17 17:42:02,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:03,011][root][INFO] - Training Epoch: 1/2, step 572/53949 completed (loss: 4.106967926025391, acc: 0.17391304671764374)
[2025-02-17 17:42:03,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:03,416][root][INFO] - Training Epoch: 1/2, step 573/53949 completed (loss: 3.1502420902252197, acc: 0.4000000059604645)
[2025-02-17 17:42:03,562][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:03,785][root][INFO] - Training Epoch: 1/2, step 574/53949 completed (loss: 3.5676231384277344, acc: 0.2083333283662796)
[2025-02-17 17:42:03,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:04,171][root][INFO] - Training Epoch: 1/2, step 575/53949 completed (loss: 3.461590528488159, acc: 0.20000000298023224)
[2025-02-17 17:42:04,395][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:04,609][root][INFO] - Training Epoch: 1/2, step 576/53949 completed (loss: 3.2430717945098877, acc: 0.32758620381355286)
[2025-02-17 17:42:04,755][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:04,976][root][INFO] - Training Epoch: 1/2, step 577/53949 completed (loss: 4.741730690002441, acc: 0.16129031777381897)
[2025-02-17 17:42:05,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:05,425][root][INFO] - Training Epoch: 1/2, step 578/53949 completed (loss: 3.841972827911377, acc: 0.4285714328289032)
[2025-02-17 17:42:05,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:05,784][root][INFO] - Training Epoch: 1/2, step 579/53949 completed (loss: 5.285712718963623, acc: 0.2857142984867096)
[2025-02-17 17:42:05,963][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:06,187][root][INFO] - Training Epoch: 1/2, step 580/53949 completed (loss: 3.815560817718506, acc: 0.29411765933036804)
[2025-02-17 17:42:06,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:06,551][root][INFO] - Training Epoch: 1/2, step 581/53949 completed (loss: 3.3046374320983887, acc: 0.27272728085517883)
[2025-02-17 17:42:06,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:06,890][root][INFO] - Training Epoch: 1/2, step 582/53949 completed (loss: 3.387706995010376, acc: 0.625)
[2025-02-17 17:42:07,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:07,297][root][INFO] - Training Epoch: 1/2, step 583/53949 completed (loss: 3.173478364944458, acc: 0.28947368264198303)
[2025-02-17 17:42:07,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:07,666][root][INFO] - Training Epoch: 1/2, step 584/53949 completed (loss: 0.265671044588089, acc: 1.0)
[2025-02-17 17:42:07,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:08,085][root][INFO] - Training Epoch: 1/2, step 585/53949 completed (loss: 3.720815658569336, acc: 0.18518517911434174)
[2025-02-17 17:42:08,291][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:08,523][root][INFO] - Training Epoch: 1/2, step 586/53949 completed (loss: 1.5048021078109741, acc: 0.625)
[2025-02-17 17:42:08,698][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:08,913][root][INFO] - Training Epoch: 1/2, step 587/53949 completed (loss: 2.8013088703155518, acc: 0.5161290168762207)
[2025-02-17 17:42:09,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:09,340][root][INFO] - Training Epoch: 1/2, step 588/53949 completed (loss: 1.8264559507369995, acc: 0.6000000238418579)
[2025-02-17 17:42:09,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:09,775][root][INFO] - Training Epoch: 1/2, step 589/53949 completed (loss: 2.8756003379821777, acc: 0.3448275923728943)
[2025-02-17 17:42:09,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:10,143][root][INFO] - Training Epoch: 1/2, step 590/53949 completed (loss: 4.556186199188232, acc: 0.38461539149284363)
[2025-02-17 17:42:10,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:10,520][root][INFO] - Training Epoch: 1/2, step 591/53949 completed (loss: 3.5782182216644287, acc: 0.25)
[2025-02-17 17:42:10,704][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:10,936][root][INFO] - Training Epoch: 1/2, step 592/53949 completed (loss: 3.200397491455078, acc: 0.31578946113586426)
[2025-02-17 17:42:11,157][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:11,385][root][INFO] - Training Epoch: 1/2, step 593/53949 completed (loss: 3.1854798793792725, acc: 0.4444444477558136)
[2025-02-17 17:42:11,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:11,861][root][INFO] - Training Epoch: 1/2, step 594/53949 completed (loss: 0.5368039608001709, acc: 0.6666666865348816)
[2025-02-17 17:42:12,000][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:12,204][root][INFO] - Training Epoch: 1/2, step 595/53949 completed (loss: 4.133145809173584, acc: 0.3076923191547394)
[2025-02-17 17:42:12,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:12,565][root][INFO] - Training Epoch: 1/2, step 596/53949 completed (loss: 4.337030410766602, acc: 0.3030303120613098)
[2025-02-17 17:42:12,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:12,957][root][INFO] - Training Epoch: 1/2, step 597/53949 completed (loss: 3.614013195037842, acc: 0.3076923191547394)
[2025-02-17 17:42:13,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:13,362][root][INFO] - Training Epoch: 1/2, step 598/53949 completed (loss: 3.2085182666778564, acc: 0.3181818127632141)
[2025-02-17 17:42:13,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:13,787][root][INFO] - Training Epoch: 1/2, step 599/53949 completed (loss: 3.576176881790161, acc: 0.3333333432674408)
[2025-02-17 17:42:14,005][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:14,231][root][INFO] - Training Epoch: 1/2, step 600/53949 completed (loss: 3.1193325519561768, acc: 0.4285714328289032)
[2025-02-17 17:42:14,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:14,599][root][INFO] - Training Epoch: 1/2, step 601/53949 completed (loss: 2.7786216735839844, acc: 0.5454545617103577)
[2025-02-17 17:42:14,781][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:15,002][root][INFO] - Training Epoch: 1/2, step 602/53949 completed (loss: 2.374868392944336, acc: 0.5)
[2025-02-17 17:42:15,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:15,392][root][INFO] - Training Epoch: 1/2, step 603/53949 completed (loss: 2.934516429901123, acc: 0.5)
[2025-02-17 17:42:15,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:15,773][root][INFO] - Training Epoch: 1/2, step 604/53949 completed (loss: 3.6348013877868652, acc: 0.3103448152542114)
[2025-02-17 17:42:15,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:16,124][root][INFO] - Training Epoch: 1/2, step 605/53949 completed (loss: 3.7184154987335205, acc: 0.3571428656578064)
[2025-02-17 17:42:16,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:16,526][root][INFO] - Training Epoch: 1/2, step 606/53949 completed (loss: 3.819451093673706, acc: 0.2368421107530594)
[2025-02-17 17:42:16,729][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:16,954][root][INFO] - Training Epoch: 1/2, step 607/53949 completed (loss: 3.4388599395751953, acc: 0.3636363744735718)
[2025-02-17 17:42:17,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:17,378][root][INFO] - Training Epoch: 1/2, step 608/53949 completed (loss: 2.809314489364624, acc: 0.4375)
[2025-02-17 17:42:17,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:17,748][root][INFO] - Training Epoch: 1/2, step 609/53949 completed (loss: 3.0892574787139893, acc: 0.375)
[2025-02-17 17:42:17,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:18,128][root][INFO] - Training Epoch: 1/2, step 610/53949 completed (loss: 3.2637388706207275, acc: 0.3125)
[2025-02-17 17:42:18,370][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:18,596][root][INFO] - Training Epoch: 1/2, step 611/53949 completed (loss: 3.8979878425598145, acc: 0.3055555522441864)
[2025-02-17 17:42:18,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:18,988][root][INFO] - Training Epoch: 1/2, step 612/53949 completed (loss: 3.074497699737549, acc: 0.5)
[2025-02-17 17:42:19,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:19,352][root][INFO] - Training Epoch: 1/2, step 613/53949 completed (loss: 0.05177341401576996, acc: 1.0)
[2025-02-17 17:42:19,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:19,836][root][INFO] - Training Epoch: 1/2, step 614/53949 completed (loss: 4.312901496887207, acc: 0.2631579041481018)
[2025-02-17 17:42:19,996][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:20,219][root][INFO] - Training Epoch: 1/2, step 615/53949 completed (loss: 4.235275745391846, acc: 0.1666666716337204)
[2025-02-17 17:42:20,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:20,592][root][INFO] - Training Epoch: 1/2, step 616/53949 completed (loss: 4.566588401794434, acc: 0.17142857611179352)
[2025-02-17 17:42:20,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:20,956][root][INFO] - Training Epoch: 1/2, step 617/53949 completed (loss: 0.4507461488246918, acc: 0.75)
[2025-02-17 17:42:21,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:21,392][root][INFO] - Training Epoch: 1/2, step 618/53949 completed (loss: 3.8601982593536377, acc: 0.17391304671764374)
[2025-02-17 17:42:21,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:21,778][root][INFO] - Training Epoch: 1/2, step 619/53949 completed (loss: 4.1887383460998535, acc: 0.260869562625885)
[2025-02-17 17:42:21,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:22,169][root][INFO] - Training Epoch: 1/2, step 620/53949 completed (loss: 5.438721656799316, acc: 0.30000001192092896)
[2025-02-17 17:42:22,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:22,526][root][INFO] - Training Epoch: 1/2, step 621/53949 completed (loss: 3.4185681343078613, acc: 0.32258063554763794)
[2025-02-17 17:42:22,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:22,927][root][INFO] - Training Epoch: 1/2, step 622/53949 completed (loss: 4.189334392547607, acc: 0.19354838132858276)
[2025-02-17 17:42:23,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:23,305][root][INFO] - Training Epoch: 1/2, step 623/53949 completed (loss: 3.2885966300964355, acc: 0.3333333432674408)
[2025-02-17 17:42:23,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:23,690][root][INFO] - Training Epoch: 1/2, step 624/53949 completed (loss: 2.01887845993042, acc: 0.5714285969734192)
[2025-02-17 17:42:23,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:24,046][root][INFO] - Training Epoch: 1/2, step 625/53949 completed (loss: 2.1084342002868652, acc: 0.5714285969734192)
[2025-02-17 17:42:24,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:24,411][root][INFO] - Training Epoch: 1/2, step 626/53949 completed (loss: 2.7648658752441406, acc: 0.3414634168148041)
[2025-02-17 17:42:24,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:24,787][root][INFO] - Training Epoch: 1/2, step 627/53949 completed (loss: 3.792071580886841, acc: 0.30000001192092896)
[2025-02-17 17:42:24,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:25,161][root][INFO] - Training Epoch: 1/2, step 628/53949 completed (loss: 3.3851895332336426, acc: 0.4146341383457184)
[2025-02-17 17:42:25,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:25,613][root][INFO] - Training Epoch: 1/2, step 629/53949 completed (loss: 3.3777270317077637, acc: 0.4000000059604645)
[2025-02-17 17:42:25,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:26,062][root][INFO] - Training Epoch: 1/2, step 630/53949 completed (loss: 3.981865406036377, acc: 0.28947368264198303)
[2025-02-17 17:42:26,206][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:26,416][root][INFO] - Training Epoch: 1/2, step 631/53949 completed (loss: 1.2660987377166748, acc: 0.5)
[2025-02-17 17:42:26,560][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:26,777][root][INFO] - Training Epoch: 1/2, step 632/53949 completed (loss: 2.922483205795288, acc: 0.4736842215061188)
[2025-02-17 17:42:26,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:27,180][root][INFO] - Training Epoch: 1/2, step 633/53949 completed (loss: 3.1883597373962402, acc: 0.23076923191547394)
[2025-02-17 17:42:27,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:27,573][root][INFO] - Training Epoch: 1/2, step 634/53949 completed (loss: 3.527118682861328, acc: 0.4000000059604645)
[2025-02-17 17:42:27,934][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:28,216][root][INFO] - Training Epoch: 1/2, step 635/53949 completed (loss: 3.947608232498169, acc: 0.21212121844291687)
[2025-02-17 17:42:28,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:28,634][root][INFO] - Training Epoch: 1/2, step 636/53949 completed (loss: 3.7912328243255615, acc: 0.25)
[2025-02-17 17:42:28,774][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:29,000][root][INFO] - Training Epoch: 1/2, step 637/53949 completed (loss: 2.9276034832000732, acc: 0.4285714328289032)
[2025-02-17 17:42:29,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:29,400][root][INFO] - Training Epoch: 1/2, step 638/53949 completed (loss: 4.159749984741211, acc: 0.2432432472705841)
[2025-02-17 17:42:29,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:29,779][root][INFO] - Training Epoch: 1/2, step 639/53949 completed (loss: 3.921807289123535, acc: 0.25)
[2025-02-17 17:42:29,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:30,144][root][INFO] - Training Epoch: 1/2, step 640/53949 completed (loss: 4.1430864334106445, acc: 0.2222222238779068)
[2025-02-17 17:42:30,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:30,535][root][INFO] - Training Epoch: 1/2, step 641/53949 completed (loss: 3.2269883155822754, acc: 0.27272728085517883)
[2025-02-17 17:42:30,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:30,974][root][INFO] - Training Epoch: 1/2, step 642/53949 completed (loss: 3.5075533390045166, acc: 0.27586206793785095)
[2025-02-17 17:42:31,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:31,398][root][INFO] - Training Epoch: 1/2, step 643/53949 completed (loss: 3.3876142501831055, acc: 0.4444444477558136)
[2025-02-17 17:42:31,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:31,833][root][INFO] - Training Epoch: 1/2, step 644/53949 completed (loss: 3.347933292388916, acc: 0.4117647111415863)
[2025-02-17 17:42:32,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:32,194][root][INFO] - Training Epoch: 1/2, step 645/53949 completed (loss: 4.01301383972168, acc: 0.2777777910232544)
[2025-02-17 17:42:32,349][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:32,569][root][INFO] - Training Epoch: 1/2, step 646/53949 completed (loss: 2.5533838272094727, acc: 0.5333333611488342)
[2025-02-17 17:42:32,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:32,969][root][INFO] - Training Epoch: 1/2, step 647/53949 completed (loss: 4.674112796783447, acc: 0.27586206793785095)
[2025-02-17 17:42:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:33,332][root][INFO] - Training Epoch: 1/2, step 648/53949 completed (loss: 3.620605945587158, acc: 0.4285714328289032)
[2025-02-17 17:42:33,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:33,653][root][INFO] - Training Epoch: 1/2, step 649/53949 completed (loss: 3.727118492126465, acc: 0.3125)
[2025-02-17 17:42:33,794][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:34,017][root][INFO] - Training Epoch: 1/2, step 650/53949 completed (loss: 2.836287021636963, acc: 0.3333333432674408)
[2025-02-17 17:42:34,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:34,367][root][INFO] - Training Epoch: 1/2, step 651/53949 completed (loss: 2.317145586013794, acc: 0.4324324429035187)
[2025-02-17 17:42:34,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:34,720][root][INFO] - Training Epoch: 1/2, step 652/53949 completed (loss: 3.599196434020996, acc: 0.3333333432674408)
[2025-02-17 17:42:34,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:35,153][root][INFO] - Training Epoch: 1/2, step 653/53949 completed (loss: 2.985041618347168, acc: 0.20000000298023224)
[2025-02-17 17:42:35,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:35,574][root][INFO] - Training Epoch: 1/2, step 654/53949 completed (loss: 2.177372694015503, acc: 0.5555555820465088)
[2025-02-17 17:42:35,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:35,962][root][INFO] - Training Epoch: 1/2, step 655/53949 completed (loss: 3.4050021171569824, acc: 0.3571428656578064)
[2025-02-17 17:42:36,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:36,377][root][INFO] - Training Epoch: 1/2, step 656/53949 completed (loss: 3.2464358806610107, acc: 0.42105263471603394)
[2025-02-17 17:42:36,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:36,778][root][INFO] - Training Epoch: 1/2, step 657/53949 completed (loss: 2.82723069190979, acc: 0.4000000059604645)
[2025-02-17 17:42:36,910][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:37,136][root][INFO] - Training Epoch: 1/2, step 658/53949 completed (loss: 3.5037789344787598, acc: 0.20000000298023224)
[2025-02-17 17:42:37,308][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:37,533][root][INFO] - Training Epoch: 1/2, step 659/53949 completed (loss: 0.6939181685447693, acc: 0.75)
[2025-02-17 17:42:37,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:37,986][root][INFO] - Training Epoch: 1/2, step 660/53949 completed (loss: 4.245019435882568, acc: 0.3181818127632141)
[2025-02-17 17:42:38,187][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:38,421][root][INFO] - Training Epoch: 1/2, step 661/53949 completed (loss: 1.6417511701583862, acc: 0.7142857313156128)
[2025-02-17 17:42:38,633][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:38,854][root][INFO] - Training Epoch: 1/2, step 662/53949 completed (loss: 3.9487569332122803, acc: 0.3333333432674408)
[2025-02-17 17:42:39,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:39,325][root][INFO] - Training Epoch: 1/2, step 663/53949 completed (loss: 3.977243423461914, acc: 0.17241379618644714)
[2025-02-17 17:42:39,481][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:39,709][root][INFO] - Training Epoch: 1/2, step 664/53949 completed (loss: 3.688532590866089, acc: 0.3513513505458832)
[2025-02-17 17:42:39,868][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:40,118][root][INFO] - Training Epoch: 1/2, step 665/53949 completed (loss: 2.9173567295074463, acc: 0.4166666567325592)
[2025-02-17 17:42:40,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:40,519][root][INFO] - Training Epoch: 1/2, step 666/53949 completed (loss: 3.2497446537017822, acc: 0.3076923191547394)
[2025-02-17 17:42:40,742][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:40,963][root][INFO] - Training Epoch: 1/2, step 667/53949 completed (loss: 3.1413826942443848, acc: 0.32499998807907104)
[2025-02-17 17:42:41,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:41,418][root][INFO] - Training Epoch: 1/2, step 668/53949 completed (loss: 3.361264944076538, acc: 0.29032257199287415)
[2025-02-17 17:42:41,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:41,807][root][INFO] - Training Epoch: 1/2, step 669/53949 completed (loss: 3.8916070461273193, acc: 0.20000000298023224)
[2025-02-17 17:42:42,034][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:42,273][root][INFO] - Training Epoch: 1/2, step 670/53949 completed (loss: 3.348834276199341, acc: 0.25)
[2025-02-17 17:42:42,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:42,658][root][INFO] - Training Epoch: 1/2, step 671/53949 completed (loss: 1.790928602218628, acc: 0.4285714328289032)
[2025-02-17 17:42:42,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:43,007][root][INFO] - Training Epoch: 1/2, step 672/53949 completed (loss: 1.4841541051864624, acc: 0.5)
[2025-02-17 17:42:43,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:43,402][root][INFO] - Training Epoch: 1/2, step 673/53949 completed (loss: 3.936163902282715, acc: 0.1666666716337204)
[2025-02-17 17:42:43,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:43,751][root][INFO] - Training Epoch: 1/2, step 674/53949 completed (loss: 2.3879523277282715, acc: 0.4285714328289032)
[2025-02-17 17:42:43,930][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:44,179][root][INFO] - Training Epoch: 1/2, step 675/53949 completed (loss: 4.208061218261719, acc: 0.23529411852359772)
[2025-02-17 17:42:44,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:44,565][root][INFO] - Training Epoch: 1/2, step 676/53949 completed (loss: 3.0959675312042236, acc: 0.3076923191547394)
[2025-02-17 17:42:44,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:44,945][root][INFO] - Training Epoch: 1/2, step 677/53949 completed (loss: 3.618043899536133, acc: 0.21052631735801697)
[2025-02-17 17:42:45,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:45,397][root][INFO] - Training Epoch: 1/2, step 678/53949 completed (loss: 3.216419219970703, acc: 0.25)
[2025-02-17 17:42:45,620][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:45,847][root][INFO] - Training Epoch: 1/2, step 679/53949 completed (loss: 4.202322006225586, acc: 0.3333333432674408)
[2025-02-17 17:42:46,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:46,249][root][INFO] - Training Epoch: 1/2, step 680/53949 completed (loss: 2.9780547618865967, acc: 0.42105263471603394)
[2025-02-17 17:42:46,418][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:46,631][root][INFO] - Training Epoch: 1/2, step 681/53949 completed (loss: 2.6839895248413086, acc: 0.22727273404598236)
[2025-02-17 17:42:46,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:47,030][root][INFO] - Training Epoch: 1/2, step 682/53949 completed (loss: 3.2416176795959473, acc: 0.27586206793785095)
[2025-02-17 17:42:47,215][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:47,450][root][INFO] - Training Epoch: 1/2, step 683/53949 completed (loss: 1.3944189548492432, acc: 0.75)
[2025-02-17 17:42:47,587][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:47,810][root][INFO] - Training Epoch: 1/2, step 684/53949 completed (loss: 3.411867380142212, acc: 0.23076923191547394)
[2025-02-17 17:42:47,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:48,177][root][INFO] - Training Epoch: 1/2, step 685/53949 completed (loss: 4.711698532104492, acc: 0.2222222238779068)
[2025-02-17 17:42:48,324][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:48,503][root][INFO] - Training Epoch: 1/2, step 686/53949 completed (loss: 2.921689987182617, acc: 0.5)
[2025-02-17 17:42:48,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:48,876][root][INFO] - Training Epoch: 1/2, step 687/53949 completed (loss: 2.7741734981536865, acc: 0.4375)
[2025-02-17 17:42:49,062][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:49,249][root][INFO] - Training Epoch: 1/2, step 688/53949 completed (loss: 4.176451206207275, acc: 0.5)
[2025-02-17 17:42:49,412][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:49,694][root][INFO] - Training Epoch: 1/2, step 689/53949 completed (loss: 3.02986478805542, acc: 0.2857142984867096)
[2025-02-17 17:42:49,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:50,129][root][INFO] - Training Epoch: 1/2, step 690/53949 completed (loss: 3.4218027591705322, acc: 0.21052631735801697)
[2025-02-17 17:42:50,309][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:50,528][root][INFO] - Training Epoch: 1/2, step 691/53949 completed (loss: 4.105733394622803, acc: 0.2857142984867096)
[2025-02-17 17:42:50,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:50,893][root][INFO] - Training Epoch: 1/2, step 692/53949 completed (loss: 2.340984344482422, acc: 0.4285714328289032)
[2025-02-17 17:42:51,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:51,267][root][INFO] - Training Epoch: 1/2, step 693/53949 completed (loss: 3.2902865409851074, acc: 0.4615384638309479)
[2025-02-17 17:42:51,521][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:51,767][root][INFO] - Training Epoch: 1/2, step 694/53949 completed (loss: 3.6513822078704834, acc: 0.2666666805744171)
[2025-02-17 17:42:51,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:52,149][root][INFO] - Training Epoch: 1/2, step 695/53949 completed (loss: 1.7578750848770142, acc: 0.6000000238418579)
[2025-02-17 17:42:52,291][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:52,518][root][INFO] - Training Epoch: 1/2, step 696/53949 completed (loss: 3.262315034866333, acc: 0.3333333432674408)
[2025-02-17 17:42:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:52,945][root][INFO] - Training Epoch: 1/2, step 697/53949 completed (loss: 2.5733649730682373, acc: 0.5)
[2025-02-17 17:42:53,149][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:53,385][root][INFO] - Training Epoch: 1/2, step 698/53949 completed (loss: 2.8763246536254883, acc: 0.38461539149284363)
[2025-02-17 17:42:53,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:53,725][root][INFO] - Training Epoch: 1/2, step 699/53949 completed (loss: 2.2188429832458496, acc: 0.5)
[2025-02-17 17:42:53,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:54,153][root][INFO] - Training Epoch: 1/2, step 700/53949 completed (loss: 2.8467423915863037, acc: 0.3461538553237915)
[2025-02-17 17:42:54,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:54,606][root][INFO] - Training Epoch: 1/2, step 701/53949 completed (loss: 4.129984378814697, acc: 0.3333333432674408)
[2025-02-17 17:42:54,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:55,027][root][INFO] - Training Epoch: 1/2, step 702/53949 completed (loss: 3.795109510421753, acc: 0.260869562625885)
[2025-02-17 17:42:55,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:55,398][root][INFO] - Training Epoch: 1/2, step 703/53949 completed (loss: 3.076326847076416, acc: 0.32258063554763794)
[2025-02-17 17:42:55,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:55,814][root][INFO] - Training Epoch: 1/2, step 704/53949 completed (loss: 3.404149055480957, acc: 0.3333333432674408)
[2025-02-17 17:42:56,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:56,264][root][INFO] - Training Epoch: 1/2, step 705/53949 completed (loss: 3.169574737548828, acc: 0.3461538553237915)
[2025-02-17 17:42:56,463][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:56,703][root][INFO] - Training Epoch: 1/2, step 706/53949 completed (loss: 2.6918745040893555, acc: 0.5714285969734192)
[2025-02-17 17:42:56,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:57,105][root][INFO] - Training Epoch: 1/2, step 707/53949 completed (loss: 3.232391595840454, acc: 0.4166666567325592)
[2025-02-17 17:42:57,281][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:57,522][root][INFO] - Training Epoch: 1/2, step 708/53949 completed (loss: 4.093379020690918, acc: 0.32258063554763794)
[2025-02-17 17:42:57,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:57,991][root][INFO] - Training Epoch: 1/2, step 709/53949 completed (loss: 3.7881627082824707, acc: 0.24242424964904785)
[2025-02-17 17:42:58,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:58,373][root][INFO] - Training Epoch: 1/2, step 710/53949 completed (loss: 3.2034971714019775, acc: 0.47058823704719543)
[2025-02-17 17:42:58,510][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:58,723][root][INFO] - Training Epoch: 1/2, step 711/53949 completed (loss: 3.1369588375091553, acc: 0.2857142984867096)
[2025-02-17 17:42:58,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:59,113][root][INFO] - Training Epoch: 1/2, step 712/53949 completed (loss: 3.239075183868408, acc: 0.4000000059604645)
[2025-02-17 17:42:59,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:59,515][root][INFO] - Training Epoch: 1/2, step 713/53949 completed (loss: 3.9152133464813232, acc: 0.3888888955116272)
[2025-02-17 17:42:59,651][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:42:59,865][root][INFO] - Training Epoch: 1/2, step 714/53949 completed (loss: 2.3073196411132812, acc: 0.5714285969734192)
[2025-02-17 17:43:00,013][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:00,236][root][INFO] - Training Epoch: 1/2, step 715/53949 completed (loss: 1.7220094203948975, acc: 0.5)
[2025-02-17 17:43:00,402][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:00,623][root][INFO] - Training Epoch: 1/2, step 716/53949 completed (loss: 3.989858627319336, acc: 0.24444444477558136)
[2025-02-17 17:43:00,759][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:00,974][root][INFO] - Training Epoch: 1/2, step 717/53949 completed (loss: 4.340038776397705, acc: 0.16129031777381897)
[2025-02-17 17:43:01,121][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:01,339][root][INFO] - Training Epoch: 1/2, step 718/53949 completed (loss: 3.556302547454834, acc: 0.31578946113586426)
[2025-02-17 17:43:01,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:01,706][root][INFO] - Training Epoch: 1/2, step 719/53949 completed (loss: 2.8435890674591064, acc: 0.3913043439388275)
[2025-02-17 17:43:01,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:02,120][root][INFO] - Training Epoch: 1/2, step 720/53949 completed (loss: 3.6148762702941895, acc: 0.20000000298023224)
[2025-02-17 17:43:02,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:02,541][root][INFO] - Training Epoch: 1/2, step 721/53949 completed (loss: 3.538248062133789, acc: 0.42105263471603394)
[2025-02-17 17:43:02,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:02,958][root][INFO] - Training Epoch: 1/2, step 722/53949 completed (loss: 3.8842484951019287, acc: 0.2222222238779068)
[2025-02-17 17:43:03,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:03,409][root][INFO] - Training Epoch: 1/2, step 723/53949 completed (loss: 4.012416362762451, acc: 0.3333333432674408)
[2025-02-17 17:43:03,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:03,879][root][INFO] - Training Epoch: 1/2, step 724/53949 completed (loss: 2.0842645168304443, acc: 0.5333333611488342)
[2025-02-17 17:43:04,074][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:04,314][root][INFO] - Training Epoch: 1/2, step 725/53949 completed (loss: 2.9560327529907227, acc: 0.4399999976158142)
[2025-02-17 17:43:04,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:04,693][root][INFO] - Training Epoch: 1/2, step 726/53949 completed (loss: 2.108389139175415, acc: 0.7142857313156128)
[2025-02-17 17:43:04,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:05,072][root][INFO] - Training Epoch: 1/2, step 727/53949 completed (loss: 3.735219717025757, acc: 0.21212121844291687)
[2025-02-17 17:43:05,228][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:05,423][root][INFO] - Training Epoch: 1/2, step 728/53949 completed (loss: 3.172926425933838, acc: 0.2380952388048172)
[2025-02-17 17:43:05,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:05,847][root][INFO] - Training Epoch: 1/2, step 729/53949 completed (loss: 3.328479766845703, acc: 0.23076923191547394)
[2025-02-17 17:43:06,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:06,248][root][INFO] - Training Epoch: 1/2, step 730/53949 completed (loss: 3.989267110824585, acc: 0.21276596188545227)
[2025-02-17 17:43:06,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:06,726][root][INFO] - Training Epoch: 1/2, step 731/53949 completed (loss: 3.1676888465881348, acc: 0.38461539149284363)
[2025-02-17 17:43:06,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:07,124][root][INFO] - Training Epoch: 1/2, step 732/53949 completed (loss: 2.272456407546997, acc: 0.4444444477558136)
[2025-02-17 17:43:07,292][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:07,506][root][INFO] - Training Epoch: 1/2, step 733/53949 completed (loss: 3.2270917892456055, acc: 0.2222222238779068)
[2025-02-17 17:43:07,656][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:07,869][root][INFO] - Training Epoch: 1/2, step 734/53949 completed (loss: 2.667865514755249, acc: 0.3636363744735718)
[2025-02-17 17:43:08,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:08,293][root][INFO] - Training Epoch: 1/2, step 735/53949 completed (loss: 4.301640033721924, acc: 0.3103448152542114)
[2025-02-17 17:43:08,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:08,697][root][INFO] - Training Epoch: 1/2, step 736/53949 completed (loss: 3.9304330348968506, acc: 0.3928571343421936)
[2025-02-17 17:43:08,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:09,050][root][INFO] - Training Epoch: 1/2, step 737/53949 completed (loss: 4.457457542419434, acc: 0.2666666805744171)
[2025-02-17 17:43:09,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:09,394][root][INFO] - Training Epoch: 1/2, step 738/53949 completed (loss: 2.7757420539855957, acc: 0.38461539149284363)
[2025-02-17 17:43:09,570][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:09,798][root][INFO] - Training Epoch: 1/2, step 739/53949 completed (loss: 2.75632381439209, acc: 0.3333333432674408)
[2025-02-17 17:43:09,989][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:10,219][root][INFO] - Training Epoch: 1/2, step 740/53949 completed (loss: 2.912761926651001, acc: 0.6000000238418579)
[2025-02-17 17:43:10,385][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:10,616][root][INFO] - Training Epoch: 1/2, step 741/53949 completed (loss: 3.1374359130859375, acc: 0.38461539149284363)
[2025-02-17 17:43:10,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:10,983][root][INFO] - Training Epoch: 1/2, step 742/53949 completed (loss: 5.888803482055664, acc: 0.2222222238779068)
[2025-02-17 17:43:11,163][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:11,381][root][INFO] - Training Epoch: 1/2, step 743/53949 completed (loss: 3.6397757530212402, acc: 0.29729729890823364)
[2025-02-17 17:43:11,555][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:11,774][root][INFO] - Training Epoch: 1/2, step 744/53949 completed (loss: 3.399832010269165, acc: 0.35483869910240173)
[2025-02-17 17:43:11,921][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:12,140][root][INFO] - Training Epoch: 1/2, step 745/53949 completed (loss: 3.1954545974731445, acc: 0.3333333432674408)
[2025-02-17 17:43:12,305][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:12,525][root][INFO] - Training Epoch: 1/2, step 746/53949 completed (loss: 4.041928768157959, acc: 0.2631579041481018)
[2025-02-17 17:43:12,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:12,902][root][INFO] - Training Epoch: 1/2, step 747/53949 completed (loss: 3.107233762741089, acc: 0.36666667461395264)
[2025-02-17 17:43:13,071][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:13,302][root][INFO] - Training Epoch: 1/2, step 748/53949 completed (loss: 3.957869052886963, acc: 0.29411765933036804)
[2025-02-17 17:43:13,477][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:13,721][root][INFO] - Training Epoch: 1/2, step 749/53949 completed (loss: 3.5199365615844727, acc: 0.3414634168148041)
[2025-02-17 17:43:13,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:14,156][root][INFO] - Training Epoch: 1/2, step 750/53949 completed (loss: 2.8303213119506836, acc: 0.47058823704719543)
[2025-02-17 17:43:14,333][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:14,558][root][INFO] - Training Epoch: 1/2, step 751/53949 completed (loss: 1.6713008880615234, acc: 0.6000000238418579)
[2025-02-17 17:43:14,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:14,945][root][INFO] - Training Epoch: 1/2, step 752/53949 completed (loss: 3.335566520690918, acc: 0.38461539149284363)
[2025-02-17 17:43:15,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:15,293][root][INFO] - Training Epoch: 1/2, step 753/53949 completed (loss: 2.9210667610168457, acc: 0.4285714328289032)
[2025-02-17 17:43:15,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:15,718][root][INFO] - Training Epoch: 1/2, step 754/53949 completed (loss: 2.4572792053222656, acc: 0.4615384638309479)
[2025-02-17 17:43:15,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:16,126][root][INFO] - Training Epoch: 1/2, step 755/53949 completed (loss: 1.2208930253982544, acc: 0.6000000238418579)
[2025-02-17 17:43:16,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:16,557][root][INFO] - Training Epoch: 1/2, step 756/53949 completed (loss: 2.7542150020599365, acc: 0.3333333432674408)
[2025-02-17 17:43:16,739][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:16,955][root][INFO] - Training Epoch: 1/2, step 757/53949 completed (loss: 3.874765396118164, acc: 0.23529411852359772)
[2025-02-17 17:43:17,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:17,315][root][INFO] - Training Epoch: 1/2, step 758/53949 completed (loss: 1.4490749835968018, acc: 0.800000011920929)
[2025-02-17 17:43:17,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:17,692][root][INFO] - Training Epoch: 1/2, step 759/53949 completed (loss: 4.210783004760742, acc: 0.3333333432674408)
[2025-02-17 17:43:17,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:18,066][root][INFO] - Training Epoch: 1/2, step 760/53949 completed (loss: 3.086134195327759, acc: 0.4444444477558136)
[2025-02-17 17:43:18,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:18,450][root][INFO] - Training Epoch: 1/2, step 761/53949 completed (loss: 3.2039077281951904, acc: 0.36000001430511475)
[2025-02-17 17:43:18,591][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:18,814][root][INFO] - Training Epoch: 1/2, step 762/53949 completed (loss: 1.7730213403701782, acc: 0.5263158082962036)
[2025-02-17 17:43:18,970][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:19,186][root][INFO] - Training Epoch: 1/2, step 763/53949 completed (loss: 3.796060800552368, acc: 0.26923078298568726)
[2025-02-17 17:43:19,339][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:19,572][root][INFO] - Training Epoch: 1/2, step 764/53949 completed (loss: 2.9662678241729736, acc: 0.3888888955116272)
[2025-02-17 17:43:19,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:20,008][root][INFO] - Training Epoch: 1/2, step 765/53949 completed (loss: 2.561830759048462, acc: 0.4444444477558136)
[2025-02-17 17:43:20,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:20,392][root][INFO] - Training Epoch: 1/2, step 766/53949 completed (loss: 3.937450647354126, acc: 0.25)
[2025-02-17 17:43:20,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:20,819][root][INFO] - Training Epoch: 1/2, step 767/53949 completed (loss: 3.599372386932373, acc: 0.30000001192092896)
[2025-02-17 17:43:20,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:21,235][root][INFO] - Training Epoch: 1/2, step 768/53949 completed (loss: 2.6583611965179443, acc: 0.5454545617103577)
[2025-02-17 17:43:21,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:21,675][root][INFO] - Training Epoch: 1/2, step 769/53949 completed (loss: 3.8031609058380127, acc: 0.1428571492433548)
[2025-02-17 17:43:21,883][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:22,103][root][INFO] - Training Epoch: 1/2, step 770/53949 completed (loss: 3.6485648155212402, acc: 0.23333333432674408)
[2025-02-17 17:43:22,269][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:22,516][root][INFO] - Training Epoch: 1/2, step 771/53949 completed (loss: 3.6436896324157715, acc: 0.3499999940395355)
[2025-02-17 17:43:22,663][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:22,891][root][INFO] - Training Epoch: 1/2, step 772/53949 completed (loss: 4.129171848297119, acc: 0.2857142984867096)
[2025-02-17 17:43:23,132][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:23,365][root][INFO] - Training Epoch: 1/2, step 773/53949 completed (loss: 3.1209375858306885, acc: 0.27272728085517883)
[2025-02-17 17:43:23,613][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:23,903][root][INFO] - Training Epoch: 1/2, step 774/53949 completed (loss: 3.7841076850891113, acc: 0.29032257199287415)
[2025-02-17 17:43:24,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:24,308][root][INFO] - Training Epoch: 1/2, step 775/53949 completed (loss: 4.338772296905518, acc: 0.2777777910232544)
[2025-02-17 17:43:24,476][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:24,705][root][INFO] - Training Epoch: 1/2, step 776/53949 completed (loss: 3.2085909843444824, acc: 0.3137255012989044)
[2025-02-17 17:43:24,885][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:25,098][root][INFO] - Training Epoch: 1/2, step 777/53949 completed (loss: 1.3063732385635376, acc: 0.6000000238418579)
[2025-02-17 17:43:25,238][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:25,460][root][INFO] - Training Epoch: 1/2, step 778/53949 completed (loss: 3.2183823585510254, acc: 0.2857142984867096)
[2025-02-17 17:43:25,647][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:25,870][root][INFO] - Training Epoch: 1/2, step 779/53949 completed (loss: 3.1748924255371094, acc: 0.29411765933036804)
[2025-02-17 17:43:26,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:26,280][root][INFO] - Training Epoch: 1/2, step 780/53949 completed (loss: 2.885380268096924, acc: 0.38461539149284363)
[2025-02-17 17:43:26,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:26,677][root][INFO] - Training Epoch: 1/2, step 781/53949 completed (loss: 3.173441171646118, acc: 0.3888888955116272)
[2025-02-17 17:43:26,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:27,084][root][INFO] - Training Epoch: 1/2, step 782/53949 completed (loss: 2.7358171939849854, acc: 0.43478259444236755)
[2025-02-17 17:43:27,215][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:27,444][root][INFO] - Training Epoch: 1/2, step 783/53949 completed (loss: 4.519702434539795, acc: 0.4000000059604645)
[2025-02-17 17:43:27,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:27,909][root][INFO] - Training Epoch: 1/2, step 784/53949 completed (loss: 3.205782890319824, acc: 0.23999999463558197)
[2025-02-17 17:43:28,123][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:28,343][root][INFO] - Training Epoch: 1/2, step 785/53949 completed (loss: 3.551413059234619, acc: 0.2750000059604645)
[2025-02-17 17:43:28,470][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:28,693][root][INFO] - Training Epoch: 1/2, step 786/53949 completed (loss: 3.4030981063842773, acc: 0.39393940567970276)
[2025-02-17 17:43:28,882][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:29,103][root][INFO] - Training Epoch: 1/2, step 787/53949 completed (loss: 2.701429605484009, acc: 0.5625)
[2025-02-17 17:43:29,282][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:29,510][root][INFO] - Training Epoch: 1/2, step 788/53949 completed (loss: 2.600379467010498, acc: 0.5)
[2025-02-17 17:43:29,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:29,906][root][INFO] - Training Epoch: 1/2, step 789/53949 completed (loss: 2.794191360473633, acc: 0.42424243688583374)
[2025-02-17 17:43:30,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:30,274][root][INFO] - Training Epoch: 1/2, step 790/53949 completed (loss: 3.603496551513672, acc: 0.4000000059604645)
[2025-02-17 17:43:30,499][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:30,721][root][INFO] - Training Epoch: 1/2, step 791/53949 completed (loss: 2.8970134258270264, acc: 0.3888888955116272)
[2025-02-17 17:43:30,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:31,078][root][INFO] - Training Epoch: 1/2, step 792/53949 completed (loss: 2.0418217182159424, acc: 0.5555555820465088)
[2025-02-17 17:43:31,251][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:31,468][root][INFO] - Training Epoch: 1/2, step 793/53949 completed (loss: 0.28202584385871887, acc: 1.0)
[2025-02-17 17:43:31,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:31,885][root][INFO] - Training Epoch: 1/2, step 794/53949 completed (loss: 0.9910111427307129, acc: 0.800000011920929)
[2025-02-17 17:43:32,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:32,363][root][INFO] - Training Epoch: 1/2, step 795/53949 completed (loss: 3.40071702003479, acc: 0.3076923191547394)
[2025-02-17 17:43:32,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:32,744][root][INFO] - Training Epoch: 1/2, step 796/53949 completed (loss: 4.39000940322876, acc: 0.29032257199287415)
[2025-02-17 17:43:32,887][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:33,109][root][INFO] - Training Epoch: 1/2, step 797/53949 completed (loss: 3.4365477561950684, acc: 0.2800000011920929)
[2025-02-17 17:43:33,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:33,527][root][INFO] - Training Epoch: 1/2, step 798/53949 completed (loss: 2.5075185298919678, acc: 0.5)
[2025-02-17 17:43:33,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:33,934][root][INFO] - Training Epoch: 1/2, step 799/53949 completed (loss: 3.1130220890045166, acc: 0.4444444477558136)
[2025-02-17 17:43:34,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:34,382][root][INFO] - Training Epoch: 1/2, step 800/53949 completed (loss: 3.6517813205718994, acc: 0.4444444477558136)
[2025-02-17 17:43:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:34,763][root][INFO] - Training Epoch: 1/2, step 801/53949 completed (loss: 4.46544885635376, acc: 0.25)
[2025-02-17 17:43:34,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:35,123][root][INFO] - Training Epoch: 1/2, step 802/53949 completed (loss: 3.7528445720672607, acc: 0.2571428716182709)
[2025-02-17 17:43:35,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:35,528][root][INFO] - Training Epoch: 1/2, step 803/53949 completed (loss: 1.3022401332855225, acc: 0.75)
[2025-02-17 17:43:35,674][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:35,891][root][INFO] - Training Epoch: 1/2, step 804/53949 completed (loss: 1.9547431468963623, acc: 0.5)
[2025-02-17 17:43:36,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:36,256][root][INFO] - Training Epoch: 1/2, step 805/53949 completed (loss: 0.5443326234817505, acc: 0.75)
[2025-02-17 17:43:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:36,622][root][INFO] - Training Epoch: 1/2, step 806/53949 completed (loss: 4.145885944366455, acc: 0.4615384638309479)
[2025-02-17 17:43:36,795][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:37,013][root][INFO] - Training Epoch: 1/2, step 807/53949 completed (loss: 4.0730767250061035, acc: 0.3125)
[2025-02-17 17:43:37,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:37,440][root][INFO] - Training Epoch: 1/2, step 808/53949 completed (loss: 3.8157413005828857, acc: 0.25531914830207825)
[2025-02-17 17:43:37,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:37,823][root][INFO] - Training Epoch: 1/2, step 809/53949 completed (loss: 3.5325324535369873, acc: 0.23255814611911774)
[2025-02-17 17:43:37,960][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:38,167][root][INFO] - Training Epoch: 1/2, step 810/53949 completed (loss: 3.05619740486145, acc: 0.4000000059604645)
[2025-02-17 17:43:38,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:38,541][root][INFO] - Training Epoch: 1/2, step 811/53949 completed (loss: 3.0426089763641357, acc: 0.3684210479259491)
[2025-02-17 17:43:38,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:38,912][root][INFO] - Training Epoch: 1/2, step 812/53949 completed (loss: 4.233315944671631, acc: 0.375)
[2025-02-17 17:43:39,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:39,297][root][INFO] - Training Epoch: 1/2, step 813/53949 completed (loss: 3.7293624877929688, acc: 0.26923078298568726)
[2025-02-17 17:43:39,436][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:39,650][root][INFO] - Training Epoch: 1/2, step 814/53949 completed (loss: 2.9736406803131104, acc: 0.4000000059604645)
[2025-02-17 17:43:39,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:40,063][root][INFO] - Training Epoch: 1/2, step 815/53949 completed (loss: 6.043872356414795, acc: 0.25)
[2025-02-17 17:43:40,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:40,517][root][INFO] - Training Epoch: 1/2, step 816/53949 completed (loss: 3.6138885021209717, acc: 0.3499999940395355)
[2025-02-17 17:43:40,718][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:40,944][root][INFO] - Training Epoch: 1/2, step 817/53949 completed (loss: 3.9553205966949463, acc: 0.22807016968727112)
[2025-02-17 17:43:41,114][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:41,338][root][INFO] - Training Epoch: 1/2, step 818/53949 completed (loss: 3.435579776763916, acc: 0.3478260934352875)
[2025-02-17 17:43:41,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:41,745][root][INFO] - Training Epoch: 1/2, step 819/53949 completed (loss: 3.688776731491089, acc: 0.3076923191547394)
[2025-02-17 17:43:41,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:42,179][root][INFO] - Training Epoch: 1/2, step 820/53949 completed (loss: 3.556737184524536, acc: 0.2222222238779068)
[2025-02-17 17:43:42,348][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:42,583][root][INFO] - Training Epoch: 1/2, step 821/53949 completed (loss: 3.185704231262207, acc: 0.36000001430511475)
[2025-02-17 17:43:42,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:43,036][root][INFO] - Training Epoch: 1/2, step 822/53949 completed (loss: 4.219405651092529, acc: 0.29411765933036804)
[2025-02-17 17:43:43,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:43,431][root][INFO] - Training Epoch: 1/2, step 823/53949 completed (loss: 4.350766658782959, acc: 0.3181818127632141)
[2025-02-17 17:43:43,585][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:43,775][root][INFO] - Training Epoch: 1/2, step 824/53949 completed (loss: 4.1153082847595215, acc: 0.2916666567325592)
[2025-02-17 17:43:43,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:44,151][root][INFO] - Training Epoch: 1/2, step 825/53949 completed (loss: 3.657768726348877, acc: 0.3076923191547394)
[2025-02-17 17:43:44,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:44,540][root][INFO] - Training Epoch: 1/2, step 826/53949 completed (loss: 1.8373286724090576, acc: 0.5)
[2025-02-17 17:43:44,691][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:44,903][root][INFO] - Training Epoch: 1/2, step 827/53949 completed (loss: 2.6074461936950684, acc: 0.4000000059604645)
[2025-02-17 17:43:45,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:45,254][root][INFO] - Training Epoch: 1/2, step 828/53949 completed (loss: 3.73030161857605, acc: 0.3333333432674408)
[2025-02-17 17:43:45,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:45,630][root][INFO] - Training Epoch: 1/2, step 829/53949 completed (loss: 2.5848500728607178, acc: 0.3199999928474426)
[2025-02-17 17:43:45,853][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:46,087][root][INFO] - Training Epoch: 1/2, step 830/53949 completed (loss: 2.2700657844543457, acc: 0.5625)
[2025-02-17 17:43:46,285][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:46,540][root][INFO] - Training Epoch: 1/2, step 831/53949 completed (loss: 3.652834415435791, acc: 0.30000001192092896)
[2025-02-17 17:43:46,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:47,004][root][INFO] - Training Epoch: 1/2, step 832/53949 completed (loss: 3.2630367279052734, acc: 0.31578946113586426)
[2025-02-17 17:43:47,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:47,367][root][INFO] - Training Epoch: 1/2, step 833/53949 completed (loss: 4.90626859664917, acc: 0.25)
[2025-02-17 17:43:47,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:47,817][root][INFO] - Training Epoch: 1/2, step 834/53949 completed (loss: 1.9039058685302734, acc: 0.5)
[2025-02-17 17:43:48,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:48,235][root][INFO] - Training Epoch: 1/2, step 835/53949 completed (loss: 3.783869981765747, acc: 0.21052631735801697)
[2025-02-17 17:43:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:48,607][root][INFO] - Training Epoch: 1/2, step 836/53949 completed (loss: 1.872863531112671, acc: 0.5)
[2025-02-17 17:43:48,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:48,990][root][INFO] - Training Epoch: 1/2, step 837/53949 completed (loss: 1.4131121635437012, acc: 0.6000000238418579)
[2025-02-17 17:43:49,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:49,362][root][INFO] - Training Epoch: 1/2, step 838/53949 completed (loss: 2.9971976280212402, acc: 0.2857142984867096)
[2025-02-17 17:43:49,539][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:49,794][root][INFO] - Training Epoch: 1/2, step 839/53949 completed (loss: 4.550202369689941, acc: 0.29629629850387573)
[2025-02-17 17:43:49,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:50,175][root][INFO] - Training Epoch: 1/2, step 840/53949 completed (loss: 1.6719862222671509, acc: 0.5)
[2025-02-17 17:43:50,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:50,528][root][INFO] - Training Epoch: 1/2, step 841/53949 completed (loss: 3.2367513179779053, acc: 0.375)
[2025-02-17 17:43:50,736][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:50,973][root][INFO] - Training Epoch: 1/2, step 842/53949 completed (loss: 3.0230798721313477, acc: 0.3333333432674408)
[2025-02-17 17:43:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:51,387][root][INFO] - Training Epoch: 1/2, step 843/53949 completed (loss: 3.491180658340454, acc: 0.40909090638160706)
[2025-02-17 17:43:51,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:51,710][root][INFO] - Training Epoch: 1/2, step 844/53949 completed (loss: 3.1453230381011963, acc: 0.5)
[2025-02-17 17:43:51,846][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:52,062][root][INFO] - Training Epoch: 1/2, step 845/53949 completed (loss: 4.561439037322998, acc: 0.18518517911434174)
[2025-02-17 17:43:52,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:52,491][root][INFO] - Training Epoch: 1/2, step 846/53949 completed (loss: 3.322740077972412, acc: 0.4615384638309479)
[2025-02-17 17:43:52,688][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:52,909][root][INFO] - Training Epoch: 1/2, step 847/53949 completed (loss: 3.8422064781188965, acc: 0.2222222238779068)
[2025-02-17 17:43:53,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:53,264][root][INFO] - Training Epoch: 1/2, step 848/53949 completed (loss: 3.850778102874756, acc: 0.375)
[2025-02-17 17:43:53,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:53,666][root][INFO] - Training Epoch: 1/2, step 849/53949 completed (loss: 3.4452857971191406, acc: 0.3055555522441864)
[2025-02-17 17:43:53,839][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:54,067][root][INFO] - Training Epoch: 1/2, step 850/53949 completed (loss: 3.465111255645752, acc: 0.3461538553237915)
[2025-02-17 17:43:54,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:54,504][root][INFO] - Training Epoch: 1/2, step 851/53949 completed (loss: 4.342187881469727, acc: 0.4444444477558136)
[2025-02-17 17:43:54,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:54,956][root][INFO] - Training Epoch: 1/2, step 852/53949 completed (loss: 3.8186190128326416, acc: 0.1702127605676651)
[2025-02-17 17:43:55,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:55,409][root][INFO] - Training Epoch: 1/2, step 853/53949 completed (loss: 3.944154977798462, acc: 0.13333334028720856)
[2025-02-17 17:43:55,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:55,773][root][INFO] - Training Epoch: 1/2, step 854/53949 completed (loss: 3.4870598316192627, acc: 0.3529411852359772)
[2025-02-17 17:43:55,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:56,211][root][INFO] - Training Epoch: 1/2, step 855/53949 completed (loss: 4.1040849685668945, acc: 0.23333333432674408)
[2025-02-17 17:43:56,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:56,588][root][INFO] - Training Epoch: 1/2, step 856/53949 completed (loss: 3.4985129833221436, acc: 0.3333333432674408)
[2025-02-17 17:43:56,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:56,999][root][INFO] - Training Epoch: 1/2, step 857/53949 completed (loss: 3.9812912940979004, acc: 0.20000000298023224)
[2025-02-17 17:43:57,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:57,346][root][INFO] - Training Epoch: 1/2, step 858/53949 completed (loss: 3.4267613887786865, acc: 0.08695652335882187)
[2025-02-17 17:43:57,478][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:57,700][root][INFO] - Training Epoch: 1/2, step 859/53949 completed (loss: 4.506484031677246, acc: 0.190476194024086)
[2025-02-17 17:43:57,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:58,081][root][INFO] - Training Epoch: 1/2, step 860/53949 completed (loss: 3.8829596042633057, acc: 0.27272728085517883)
[2025-02-17 17:43:58,215][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:58,446][root][INFO] - Training Epoch: 1/2, step 861/53949 completed (loss: 4.032031059265137, acc: 0.190476194024086)
[2025-02-17 17:43:58,630][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:58,845][root][INFO] - Training Epoch: 1/2, step 862/53949 completed (loss: 4.335174083709717, acc: 0.375)
[2025-02-17 17:43:59,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:59,266][root][INFO] - Training Epoch: 1/2, step 863/53949 completed (loss: 3.062136173248291, acc: 0.38461539149284363)
[2025-02-17 17:43:59,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:43:59,654][root][INFO] - Training Epoch: 1/2, step 864/53949 completed (loss: 1.5629825592041016, acc: 0.6000000238418579)
[2025-02-17 17:43:59,822][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:00,042][root][INFO] - Training Epoch: 1/2, step 865/53949 completed (loss: 3.859065532684326, acc: 0.2222222238779068)
[2025-02-17 17:44:00,178][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:00,392][root][INFO] - Training Epoch: 1/2, step 866/53949 completed (loss: 3.6602330207824707, acc: 0.3888888955116272)
[2025-02-17 17:44:00,569][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:00,790][root][INFO] - Training Epoch: 1/2, step 867/53949 completed (loss: 4.156414985656738, acc: 0.2666666805744171)
[2025-02-17 17:44:01,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:01,252][root][INFO] - Training Epoch: 1/2, step 868/53949 completed (loss: 3.283798933029175, acc: 0.37931033968925476)
[2025-02-17 17:44:01,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:01,641][root][INFO] - Training Epoch: 1/2, step 869/53949 completed (loss: 3.609384536743164, acc: 0.4166666567325592)
[2025-02-17 17:44:01,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:02,027][root][INFO] - Training Epoch: 1/2, step 870/53949 completed (loss: 3.7422704696655273, acc: 0.2800000011920929)
[2025-02-17 17:44:02,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:02,412][root][INFO] - Training Epoch: 1/2, step 871/53949 completed (loss: 3.6520071029663086, acc: 0.0)
[2025-02-17 17:44:02,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:02,873][root][INFO] - Training Epoch: 1/2, step 872/53949 completed (loss: 3.9242615699768066, acc: 0.2857142984867096)
[2025-02-17 17:44:03,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:03,260][root][INFO] - Training Epoch: 1/2, step 873/53949 completed (loss: 4.415123462677002, acc: 0.1818181872367859)
[2025-02-17 17:44:03,494][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:03,710][root][INFO] - Training Epoch: 1/2, step 874/53949 completed (loss: 4.397919654846191, acc: 0.20000000298023224)
[2025-02-17 17:44:03,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:04,168][root][INFO] - Training Epoch: 1/2, step 875/53949 completed (loss: 4.186021327972412, acc: 0.23529411852359772)
[2025-02-17 17:44:04,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:04,550][root][INFO] - Training Epoch: 1/2, step 876/53949 completed (loss: 2.433509111404419, acc: 0.5)
[2025-02-17 17:44:04,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:04,910][root][INFO] - Training Epoch: 1/2, step 877/53949 completed (loss: 3.131876230239868, acc: 0.3181818127632141)
[2025-02-17 17:44:05,085][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:05,300][root][INFO] - Training Epoch: 1/2, step 878/53949 completed (loss: 4.095688819885254, acc: 0.2857142984867096)
[2025-02-17 17:44:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:05,749][root][INFO] - Training Epoch: 1/2, step 879/53949 completed (loss: 3.904513359069824, acc: 0.2777777910232544)
[2025-02-17 17:44:05,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:06,159][root][INFO] - Training Epoch: 1/2, step 880/53949 completed (loss: 3.2587876319885254, acc: 0.375)
[2025-02-17 17:44:06,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:06,524][root][INFO] - Training Epoch: 1/2, step 881/53949 completed (loss: 3.1563141345977783, acc: 0.40909090638160706)
[2025-02-17 17:44:06,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:06,954][root][INFO] - Training Epoch: 1/2, step 882/53949 completed (loss: 3.5323657989501953, acc: 0.260869562625885)
[2025-02-17 17:44:07,136][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:07,383][root][INFO] - Training Epoch: 1/2, step 883/53949 completed (loss: 4.437039375305176, acc: 0.3448275923728943)
[2025-02-17 17:44:07,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:07,781][root][INFO] - Training Epoch: 1/2, step 884/53949 completed (loss: 3.2853541374206543, acc: 0.3030303120613098)
[2025-02-17 17:44:07,966][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:08,187][root][INFO] - Training Epoch: 1/2, step 885/53949 completed (loss: 3.54789400100708, acc: 0.2432432472705841)
[2025-02-17 17:44:08,326][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:08,551][root][INFO] - Training Epoch: 1/2, step 886/53949 completed (loss: 3.382038116455078, acc: 0.30000001192092896)
[2025-02-17 17:44:08,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:08,970][root][INFO] - Training Epoch: 1/2, step 887/53949 completed (loss: 3.38777494430542, acc: 0.4000000059604645)
[2025-02-17 17:44:09,126][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:09,348][root][INFO] - Training Epoch: 1/2, step 888/53949 completed (loss: 3.3149452209472656, acc: 0.31578946113586426)
[2025-02-17 17:44:09,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:09,727][root][INFO] - Training Epoch: 1/2, step 889/53949 completed (loss: 3.733093023300171, acc: 0.2142857164144516)
[2025-02-17 17:44:09,924][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:10,181][root][INFO] - Training Epoch: 1/2, step 890/53949 completed (loss: 3.7803027629852295, acc: 0.10000000149011612)
[2025-02-17 17:44:10,346][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:10,570][root][INFO] - Training Epoch: 1/2, step 891/53949 completed (loss: 3.347905158996582, acc: 0.125)
[2025-02-17 17:44:10,782][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:11,002][root][INFO] - Training Epoch: 1/2, step 892/53949 completed (loss: 3.8325798511505127, acc: 0.2586206793785095)
[2025-02-17 17:44:11,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:11,348][root][INFO] - Training Epoch: 1/2, step 893/53949 completed (loss: 1.4854474067687988, acc: 0.800000011920929)
[2025-02-17 17:44:11,513][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:11,733][root][INFO] - Training Epoch: 1/2, step 894/53949 completed (loss: 3.1889729499816895, acc: 0.25806450843811035)
[2025-02-17 17:44:11,918][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:12,147][root][INFO] - Training Epoch: 1/2, step 895/53949 completed (loss: 3.904034376144409, acc: 0.20000000298023224)
[2025-02-17 17:44:12,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:12,549][root][INFO] - Training Epoch: 1/2, step 896/53949 completed (loss: 3.9458351135253906, acc: 0.4166666567325592)
[2025-02-17 17:44:12,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:12,957][root][INFO] - Training Epoch: 1/2, step 897/53949 completed (loss: 0.872389018535614, acc: 0.800000011920929)
[2025-02-17 17:44:13,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:13,401][root][INFO] - Training Epoch: 1/2, step 898/53949 completed (loss: 3.7163126468658447, acc: 0.3333333432674408)
[2025-02-17 17:44:13,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:13,769][root][INFO] - Training Epoch: 1/2, step 899/53949 completed (loss: 0.27740687131881714, acc: 1.0)
[2025-02-17 17:44:13,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:14,154][root][INFO] - Training Epoch: 1/2, step 900/53949 completed (loss: 3.4042348861694336, acc: 0.3636363744735718)
[2025-02-17 17:44:14,360][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:14,587][root][INFO] - Training Epoch: 1/2, step 901/53949 completed (loss: 3.903074026107788, acc: 0.24137930572032928)
[2025-02-17 17:44:14,767][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:14,990][root][INFO] - Training Epoch: 1/2, step 902/53949 completed (loss: 4.188421249389648, acc: 0.14814814925193787)
[2025-02-17 17:44:15,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:15,405][root][INFO] - Training Epoch: 1/2, step 903/53949 completed (loss: 3.93166446685791, acc: 0.260869562625885)
[2025-02-17 17:44:15,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:15,794][root][INFO] - Training Epoch: 1/2, step 904/53949 completed (loss: 3.6850745677948, acc: 0.2068965584039688)
[2025-02-17 17:44:16,014][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:16,257][root][INFO] - Training Epoch: 1/2, step 905/53949 completed (loss: 3.0125668048858643, acc: 0.380952388048172)
[2025-02-17 17:44:16,444][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:16,663][root][INFO] - Training Epoch: 1/2, step 906/53949 completed (loss: 0.7571560144424438, acc: 0.800000011920929)
[2025-02-17 17:44:16,855][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:17,083][root][INFO] - Training Epoch: 1/2, step 907/53949 completed (loss: 2.5861732959747314, acc: 0.5)
[2025-02-17 17:44:17,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:17,494][root][INFO] - Training Epoch: 1/2, step 908/53949 completed (loss: 5.445711612701416, acc: 0.25)
[2025-02-17 17:44:17,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:17,939][root][INFO] - Training Epoch: 1/2, step 909/53949 completed (loss: 3.885801076889038, acc: 0.380952388048172)
[2025-02-17 17:44:18,104][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:18,365][root][INFO] - Training Epoch: 1/2, step 910/53949 completed (loss: 2.657538414001465, acc: 0.47058823704719543)
[2025-02-17 17:44:18,535][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:18,751][root][INFO] - Training Epoch: 1/2, step 911/53949 completed (loss: 1.6150254011154175, acc: 0.75)
[2025-02-17 17:44:18,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:19,106][root][INFO] - Training Epoch: 1/2, step 912/53949 completed (loss: 3.470525026321411, acc: 0.32258063554763794)
[2025-02-17 17:44:19,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:19,542][root][INFO] - Training Epoch: 1/2, step 913/53949 completed (loss: 4.568911075592041, acc: 0.1818181872367859)
[2025-02-17 17:44:19,677][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:19,901][root][INFO] - Training Epoch: 1/2, step 914/53949 completed (loss: 3.6749212741851807, acc: 0.3333333432674408)
[2025-02-17 17:44:20,050][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:20,279][root][INFO] - Training Epoch: 1/2, step 915/53949 completed (loss: 4.2721638679504395, acc: 0.380952388048172)
[2025-02-17 17:44:20,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:20,630][root][INFO] - Training Epoch: 1/2, step 916/53949 completed (loss: 4.473689079284668, acc: 0.23529411852359772)
[2025-02-17 17:44:20,759][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:20,976][root][INFO] - Training Epoch: 1/2, step 917/53949 completed (loss: 3.4532463550567627, acc: 0.36666667461395264)
[2025-02-17 17:44:21,120][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:21,346][root][INFO] - Training Epoch: 1/2, step 918/53949 completed (loss: 3.099686622619629, acc: 0.4615384638309479)
[2025-02-17 17:44:21,497][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:21,718][root][INFO] - Training Epoch: 1/2, step 919/53949 completed (loss: 3.9220011234283447, acc: 0.2380952388048172)
[2025-02-17 17:44:21,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:22,121][root][INFO] - Training Epoch: 1/2, step 920/53949 completed (loss: 2.0165586471557617, acc: 0.6000000238418579)
[2025-02-17 17:44:22,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:22,580][root][INFO] - Training Epoch: 1/2, step 921/53949 completed (loss: 4.130493640899658, acc: 0.13636364042758942)
[2025-02-17 17:44:22,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:23,083][root][INFO] - Training Epoch: 1/2, step 922/53949 completed (loss: 4.614559173583984, acc: 0.095238097012043)
[2025-02-17 17:44:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:23,449][root][INFO] - Training Epoch: 1/2, step 923/53949 completed (loss: 0.18258075416088104, acc: 1.0)
[2025-02-17 17:44:23,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:23,801][root][INFO] - Training Epoch: 1/2, step 924/53949 completed (loss: 2.534868001937866, acc: 0.5333333611488342)
[2025-02-17 17:44:23,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:24,161][root][INFO] - Training Epoch: 1/2, step 925/53949 completed (loss: 3.257528066635132, acc: 0.3529411852359772)
[2025-02-17 17:44:24,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:24,527][root][INFO] - Training Epoch: 1/2, step 926/53949 completed (loss: 3.405825614929199, acc: 0.3125)
[2025-02-17 17:44:24,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:24,918][root][INFO] - Training Epoch: 1/2, step 927/53949 completed (loss: 3.345106840133667, acc: 0.35483869910240173)
[2025-02-17 17:44:25,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:25,340][root][INFO] - Training Epoch: 1/2, step 928/53949 completed (loss: 2.0099356174468994, acc: 0.6000000238418579)
[2025-02-17 17:44:25,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:25,729][root][INFO] - Training Epoch: 1/2, step 929/53949 completed (loss: 3.581092119216919, acc: 0.3333333432674408)
[2025-02-17 17:44:25,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:26,131][root][INFO] - Training Epoch: 1/2, step 930/53949 completed (loss: 4.317901134490967, acc: 0.3199999928474426)
[2025-02-17 17:44:26,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:26,528][root][INFO] - Training Epoch: 1/2, step 931/53949 completed (loss: 3.836564064025879, acc: 0.3125)
[2025-02-17 17:44:26,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:26,922][root][INFO] - Training Epoch: 1/2, step 932/53949 completed (loss: 3.5040283203125, acc: 0.32499998807907104)
[2025-02-17 17:44:27,050][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:27,254][root][INFO] - Training Epoch: 1/2, step 933/53949 completed (loss: 2.0330586433410645, acc: 0.6875)
[2025-02-17 17:44:27,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:27,614][root][INFO] - Training Epoch: 1/2, step 934/53949 completed (loss: 1.5332475900650024, acc: 0.6666666865348816)
[2025-02-17 17:44:27,779][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:28,002][root][INFO] - Training Epoch: 1/2, step 935/53949 completed (loss: 4.436631202697754, acc: 0.16129031777381897)
[2025-02-17 17:44:28,250][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:28,473][root][INFO] - Training Epoch: 1/2, step 936/53949 completed (loss: 4.094562530517578, acc: 0.2857142984867096)
[2025-02-17 17:44:28,642][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:28,906][root][INFO] - Training Epoch: 1/2, step 937/53949 completed (loss: 3.6758859157562256, acc: 0.3333333432674408)
[2025-02-17 17:44:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:29,330][root][INFO] - Training Epoch: 1/2, step 938/53949 completed (loss: 4.303172588348389, acc: 0.3636363744735718)
[2025-02-17 17:44:29,475][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:29,692][root][INFO] - Training Epoch: 1/2, step 939/53949 completed (loss: 0.24584002792835236, acc: 1.0)
[2025-02-17 17:44:29,920][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:30,152][root][INFO] - Training Epoch: 1/2, step 940/53949 completed (loss: 3.2063493728637695, acc: 0.23076923191547394)
[2025-02-17 17:44:30,351][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:30,568][root][INFO] - Training Epoch: 1/2, step 941/53949 completed (loss: 3.1457438468933105, acc: 0.3733333349227905)
[2025-02-17 17:44:30,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:30,895][root][INFO] - Training Epoch: 1/2, step 942/53949 completed (loss: 2.360508918762207, acc: 0.4375)
[2025-02-17 17:44:31,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:31,383][root][INFO] - Training Epoch: 1/2, step 943/53949 completed (loss: 3.122814178466797, acc: 0.2978723347187042)
[2025-02-17 17:44:31,567][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:31,802][root][INFO] - Training Epoch: 1/2, step 944/53949 completed (loss: 4.0450968742370605, acc: 0.2222222238779068)
[2025-02-17 17:44:31,983][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:32,207][root][INFO] - Training Epoch: 1/2, step 945/53949 completed (loss: 3.6815216541290283, acc: 0.32499998807907104)
[2025-02-17 17:44:32,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:32,596][root][INFO] - Training Epoch: 1/2, step 946/53949 completed (loss: 2.3921117782592773, acc: 0.4375)
[2025-02-17 17:44:32,771][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:32,991][root][INFO] - Training Epoch: 1/2, step 947/53949 completed (loss: 4.2819671630859375, acc: 0.1304347813129425)
[2025-02-17 17:44:33,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:33,427][root][INFO] - Training Epoch: 1/2, step 948/53949 completed (loss: 3.0138039588928223, acc: 0.2857142984867096)
[2025-02-17 17:44:33,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:33,828][root][INFO] - Training Epoch: 1/2, step 949/53949 completed (loss: 3.5641472339630127, acc: 0.2631579041481018)
[2025-02-17 17:44:33,955][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:34,159][root][INFO] - Training Epoch: 1/2, step 950/53949 completed (loss: 4.103909492492676, acc: 0.24137930572032928)
[2025-02-17 17:44:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:34,517][root][INFO] - Training Epoch: 1/2, step 951/53949 completed (loss: 2.4963252544403076, acc: 0.800000011920929)
[2025-02-17 17:44:34,657][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:34,846][root][INFO] - Training Epoch: 1/2, step 952/53949 completed (loss: 3.2703590393066406, acc: 0.3030303120613098)
[2025-02-17 17:44:35,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:35,276][root][INFO] - Training Epoch: 1/2, step 953/53949 completed (loss: 3.77710223197937, acc: 0.3235294222831726)
[2025-02-17 17:44:35,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:35,652][root][INFO] - Training Epoch: 1/2, step 954/53949 completed (loss: 2.734204053878784, acc: 0.5)
[2025-02-17 17:44:35,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:36,059][root][INFO] - Training Epoch: 1/2, step 955/53949 completed (loss: 2.74869704246521, acc: 0.3461538553237915)
[2025-02-17 17:44:36,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:36,420][root][INFO] - Training Epoch: 1/2, step 956/53949 completed (loss: 3.4950056076049805, acc: 0.4444444477558136)
[2025-02-17 17:44:36,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:36,771][root][INFO] - Training Epoch: 1/2, step 957/53949 completed (loss: 3.627307891845703, acc: 0.2222222238779068)
[2025-02-17 17:44:36,909][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:37,098][root][INFO] - Training Epoch: 1/2, step 958/53949 completed (loss: 1.1898186206817627, acc: 0.5714285969734192)
[2025-02-17 17:44:37,273][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:37,497][root][INFO] - Training Epoch: 1/2, step 959/53949 completed (loss: 2.9558541774749756, acc: 0.3333333432674408)
[2025-02-17 17:44:37,726][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:37,959][root][INFO] - Training Epoch: 1/2, step 960/53949 completed (loss: 3.5024683475494385, acc: 0.2881355881690979)
[2025-02-17 17:44:38,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:38,329][root][INFO] - Training Epoch: 1/2, step 961/53949 completed (loss: 3.732118606567383, acc: 0.25)
[2025-02-17 17:44:38,467][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:38,690][root][INFO] - Training Epoch: 1/2, step 962/53949 completed (loss: 3.7614247798919678, acc: 0.2631579041481018)
[2025-02-17 17:44:38,832][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:39,057][root][INFO] - Training Epoch: 1/2, step 963/53949 completed (loss: 2.859835624694824, acc: 0.4444444477558136)
[2025-02-17 17:44:39,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:39,426][root][INFO] - Training Epoch: 1/2, step 964/53949 completed (loss: 4.690664768218994, acc: 0.29411765933036804)
[2025-02-17 17:44:39,623][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:39,845][root][INFO] - Training Epoch: 1/2, step 965/53949 completed (loss: 3.721055507659912, acc: 0.27272728085517883)
[2025-02-17 17:44:40,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:40,258][root][INFO] - Training Epoch: 1/2, step 966/53949 completed (loss: 3.1538398265838623, acc: 0.42105263471603394)
[2025-02-17 17:44:40,437][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:40,659][root][INFO] - Training Epoch: 1/2, step 967/53949 completed (loss: 2.469564199447632, acc: 0.5)
[2025-02-17 17:44:40,821][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:41,045][root][INFO] - Training Epoch: 1/2, step 968/53949 completed (loss: 3.150529384613037, acc: 0.3636363744735718)
[2025-02-17 17:44:41,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:41,404][root][INFO] - Training Epoch: 1/2, step 969/53949 completed (loss: 4.0770368576049805, acc: 0.25)
[2025-02-17 17:44:41,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:41,757][root][INFO] - Training Epoch: 1/2, step 970/53949 completed (loss: 4.362680435180664, acc: 0.3499999940395355)
[2025-02-17 17:44:41,908][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:42,139][root][INFO] - Training Epoch: 1/2, step 971/53949 completed (loss: 3.696911096572876, acc: 0.3684210479259491)
[2025-02-17 17:44:42,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:42,578][root][INFO] - Training Epoch: 1/2, step 972/53949 completed (loss: 4.304507732391357, acc: 0.25806450843811035)
[2025-02-17 17:44:42,763][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:42,988][root][INFO] - Training Epoch: 1/2, step 973/53949 completed (loss: 3.701070785522461, acc: 0.25)
[2025-02-17 17:44:43,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:43,381][root][INFO] - Training Epoch: 1/2, step 974/53949 completed (loss: 4.178049087524414, acc: 0.2777777910232544)
[2025-02-17 17:44:43,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:43,776][root][INFO] - Training Epoch: 1/2, step 975/53949 completed (loss: 3.927568197250366, acc: 0.25806450843811035)
[2025-02-17 17:44:43,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:44,178][root][INFO] - Training Epoch: 1/2, step 976/53949 completed (loss: 4.467994689941406, acc: 0.4000000059604645)
[2025-02-17 17:44:44,411][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:44,630][root][INFO] - Training Epoch: 1/2, step 977/53949 completed (loss: 3.0084924697875977, acc: 0.3947368562221527)
[2025-02-17 17:44:44,810][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:45,060][root][INFO] - Training Epoch: 1/2, step 978/53949 completed (loss: 3.609318971633911, acc: 0.25)
[2025-02-17 17:44:45,286][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:45,520][root][INFO] - Training Epoch: 1/2, step 979/53949 completed (loss: 3.1742188930511475, acc: 0.30000001192092896)
[2025-02-17 17:44:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:45,882][root][INFO] - Training Epoch: 1/2, step 980/53949 completed (loss: 1.826991319656372, acc: 0.5)
[2025-02-17 17:44:46,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:46,312][root][INFO] - Training Epoch: 1/2, step 981/53949 completed (loss: 3.0761666297912598, acc: 0.4166666567325592)
[2025-02-17 17:44:46,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:46,760][root][INFO] - Training Epoch: 1/2, step 982/53949 completed (loss: 2.6300604343414307, acc: 0.47058823704719543)
[2025-02-17 17:44:46,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:47,163][root][INFO] - Training Epoch: 1/2, step 983/53949 completed (loss: 3.887197971343994, acc: 0.3050847351551056)
[2025-02-17 17:44:47,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:47,526][root][INFO] - Training Epoch: 1/2, step 984/53949 completed (loss: 4.449859142303467, acc: 0.2631579041481018)
[2025-02-17 17:44:47,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:47,900][root][INFO] - Training Epoch: 1/2, step 985/53949 completed (loss: 2.8207740783691406, acc: 0.42105263471603394)
[2025-02-17 17:44:48,045][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:48,271][root][INFO] - Training Epoch: 1/2, step 986/53949 completed (loss: 2.0023064613342285, acc: 0.5)
[2025-02-17 17:44:48,410][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:48,638][root][INFO] - Training Epoch: 1/2, step 987/53949 completed (loss: 3.2524561882019043, acc: 0.3333333432674408)
[2025-02-17 17:44:48,831][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:49,046][root][INFO] - Training Epoch: 1/2, step 988/53949 completed (loss: 3.4896981716156006, acc: 0.30000001192092896)
[2025-02-17 17:44:49,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:49,453][root][INFO] - Training Epoch: 1/2, step 989/53949 completed (loss: 3.213059425354004, acc: 0.3400000035762787)
[2025-02-17 17:44:49,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:49,830][root][INFO] - Training Epoch: 1/2, step 990/53949 completed (loss: 2.2008213996887207, acc: 0.625)
[2025-02-17 17:44:49,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:50,202][root][INFO] - Training Epoch: 1/2, step 991/53949 completed (loss: 3.541368246078491, acc: 0.32258063554763794)
[2025-02-17 17:44:50,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:50,575][root][INFO] - Training Epoch: 1/2, step 992/53949 completed (loss: 3.0888586044311523, acc: 0.3103448152542114)
[2025-02-17 17:44:50,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:51,006][root][INFO] - Training Epoch: 1/2, step 993/53949 completed (loss: 4.066315174102783, acc: 0.3181818127632141)
[2025-02-17 17:44:51,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:51,355][root][INFO] - Training Epoch: 1/2, step 994/53949 completed (loss: 2.6712472438812256, acc: 0.529411792755127)
[2025-02-17 17:44:51,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:51,802][root][INFO] - Training Epoch: 1/2, step 995/53949 completed (loss: 3.5803818702697754, acc: 0.23529411852359772)
[2025-02-17 17:44:52,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:52,227][root][INFO] - Training Epoch: 1/2, step 996/53949 completed (loss: 3.922429323196411, acc: 0.2666666805744171)
[2025-02-17 17:44:52,455][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:52,678][root][INFO] - Training Epoch: 1/2, step 997/53949 completed (loss: 4.003404140472412, acc: 0.21621622145175934)
[2025-02-17 17:44:52,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:53,043][root][INFO] - Training Epoch: 1/2, step 998/53949 completed (loss: 3.046083450317383, acc: 0.25)
[2025-02-17 17:44:53,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:53,391][root][INFO] - Training Epoch: 1/2, step 999/53949 completed (loss: 1.6566662788391113, acc: 0.4444444477558136)
[2025-02-17 17:44:53,532][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:53,748][root][INFO] - Training Epoch: 1/2, step 1000/53949 completed (loss: 2.82770037651062, acc: 0.375)
[2025-02-17 17:44:53,882][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:54,097][root][INFO] - Training Epoch: 1/2, step 1001/53949 completed (loss: 3.3292734622955322, acc: 0.29411765933036804)
[2025-02-17 17:44:54,233][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:54,447][root][INFO] - Training Epoch: 1/2, step 1002/53949 completed (loss: 3.5233161449432373, acc: 0.3030303120613098)
[2025-02-17 17:44:54,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:54,799][root][INFO] - Training Epoch: 1/2, step 1003/53949 completed (loss: 3.053093194961548, acc: 0.4000000059604645)
[2025-02-17 17:44:54,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:55,164][root][INFO] - Training Epoch: 1/2, step 1004/53949 completed (loss: 0.13990825414657593, acc: 1.0)
[2025-02-17 17:44:55,380][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:55,597][root][INFO] - Training Epoch: 1/2, step 1005/53949 completed (loss: 3.895538330078125, acc: 0.25)
[2025-02-17 17:44:55,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:56,048][root][INFO] - Training Epoch: 1/2, step 1006/53949 completed (loss: 2.9992027282714844, acc: 0.3095238208770752)
[2025-02-17 17:44:56,256][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:56,475][root][INFO] - Training Epoch: 1/2, step 1007/53949 completed (loss: 2.9374895095825195, acc: 0.4000000059604645)
[2025-02-17 17:44:56,625][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:56,847][root][INFO] - Training Epoch: 1/2, step 1008/53949 completed (loss: 0.5863470435142517, acc: 0.6666666865348816)
[2025-02-17 17:44:57,004][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:57,264][root][INFO] - Training Epoch: 1/2, step 1009/53949 completed (loss: 3.0961861610412598, acc: 0.4615384638309479)
[2025-02-17 17:44:57,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:57,700][root][INFO] - Training Epoch: 1/2, step 1010/53949 completed (loss: 2.1824803352355957, acc: 0.6000000238418579)
[2025-02-17 17:44:57,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:58,166][root][INFO] - Training Epoch: 1/2, step 1011/53949 completed (loss: 3.2605416774749756, acc: 0.3076923191547394)
[2025-02-17 17:44:58,345][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:58,576][root][INFO] - Training Epoch: 1/2, step 1012/53949 completed (loss: 2.929368495941162, acc: 0.3571428656578064)
[2025-02-17 17:44:58,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:59,020][root][INFO] - Training Epoch: 1/2, step 1013/53949 completed (loss: 2.6503987312316895, acc: 0.5263158082962036)
[2025-02-17 17:44:59,220][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:59,447][root][INFO] - Training Epoch: 1/2, step 1014/53949 completed (loss: 3.562009811401367, acc: 0.2800000011920929)
[2025-02-17 17:44:59,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:44:59,811][root][INFO] - Training Epoch: 1/2, step 1015/53949 completed (loss: 2.602965831756592, acc: 0.5454545617103577)
[2025-02-17 17:44:59,950][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:00,178][root][INFO] - Training Epoch: 1/2, step 1016/53949 completed (loss: 3.343980550765991, acc: 0.3636363744735718)
[2025-02-17 17:45:00,383][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:00,609][root][INFO] - Training Epoch: 1/2, step 1017/53949 completed (loss: 3.1829426288604736, acc: 0.375)
[2025-02-17 17:45:00,783][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:01,005][root][INFO] - Training Epoch: 1/2, step 1018/53949 completed (loss: 2.900458812713623, acc: 0.5714285969734192)
[2025-02-17 17:45:01,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:01,333][root][INFO] - Training Epoch: 1/2, step 1019/53949 completed (loss: 3.583799123764038, acc: 0.42307692766189575)
[2025-02-17 17:45:01,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:01,757][root][INFO] - Training Epoch: 1/2, step 1020/53949 completed (loss: 3.6547045707702637, acc: 0.3529411852359772)
[2025-02-17 17:45:01,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:02,111][root][INFO] - Training Epoch: 1/2, step 1021/53949 completed (loss: 3.1053595542907715, acc: 0.27586206793785095)
[2025-02-17 17:45:02,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:02,531][root][INFO] - Training Epoch: 1/2, step 1022/53949 completed (loss: 3.7905797958374023, acc: 0.3333333432674408)
[2025-02-17 17:45:02,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:02,948][root][INFO] - Training Epoch: 1/2, step 1023/53949 completed (loss: 3.3752553462982178, acc: 0.3333333432674408)
[2025-02-17 17:45:03,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:03,327][root][INFO] - Training Epoch: 1/2, step 1024/53949 completed (loss: 3.128338575363159, acc: 0.30000001192092896)
[2025-02-17 17:45:03,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:03,731][root][INFO] - Training Epoch: 1/2, step 1025/53949 completed (loss: 3.406229257583618, acc: 0.3125)
[2025-02-17 17:45:03,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:04,187][root][INFO] - Training Epoch: 1/2, step 1026/53949 completed (loss: 2.9535269737243652, acc: 0.2830188572406769)
[2025-02-17 17:45:04,367][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:04,596][root][INFO] - Training Epoch: 1/2, step 1027/53949 completed (loss: 2.942722797393799, acc: 0.44736841320991516)
[2025-02-17 17:45:04,851][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:05,085][root][INFO] - Training Epoch: 1/2, step 1028/53949 completed (loss: 3.6942503452301025, acc: 0.2830188572406769)
[2025-02-17 17:45:05,276][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:05,504][root][INFO] - Training Epoch: 1/2, step 1029/53949 completed (loss: 3.911227226257324, acc: 0.2199999988079071)
[2025-02-17 17:45:05,727][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:05,955][root][INFO] - Training Epoch: 1/2, step 1030/53949 completed (loss: 3.3852052688598633, acc: 0.3333333432674408)
[2025-02-17 17:45:06,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:06,412][root][INFO] - Training Epoch: 1/2, step 1031/53949 completed (loss: 2.8501431941986084, acc: 0.3921568691730499)
[2025-02-17 17:45:06,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:06,793][root][INFO] - Training Epoch: 1/2, step 1032/53949 completed (loss: 2.766688346862793, acc: 0.3333333432674408)
[2025-02-17 17:45:06,937][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:07,157][root][INFO] - Training Epoch: 1/2, step 1033/53949 completed (loss: 2.7238223552703857, acc: 0.5)
[2025-02-17 17:45:07,357][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:07,609][root][INFO] - Training Epoch: 1/2, step 1034/53949 completed (loss: 2.7605276107788086, acc: 0.4399999976158142)
[2025-02-17 17:45:07,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:08,053][root][INFO] - Training Epoch: 1/2, step 1035/53949 completed (loss: 3.62551212310791, acc: 0.4166666567325592)
[2025-02-17 17:45:08,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:08,489][root][INFO] - Training Epoch: 1/2, step 1036/53949 completed (loss: 2.6536877155303955, acc: 0.45652174949645996)
[2025-02-17 17:45:08,713][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:08,936][root][INFO] - Training Epoch: 1/2, step 1037/53949 completed (loss: 3.0461394786834717, acc: 0.2800000011920929)
[2025-02-17 17:45:09,151][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:09,407][root][INFO] - Training Epoch: 1/2, step 1038/53949 completed (loss: 2.930302381515503, acc: 0.26829269528388977)
[2025-02-17 17:45:09,584][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:09,812][root][INFO] - Training Epoch: 1/2, step 1039/53949 completed (loss: 3.1812169551849365, acc: 0.2380952388048172)
[2025-02-17 17:45:09,999][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:10,219][root][INFO] - Training Epoch: 1/2, step 1040/53949 completed (loss: 3.5454893112182617, acc: 0.3333333432674408)
[2025-02-17 17:45:10,363][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:10,589][root][INFO] - Training Epoch: 1/2, step 1041/53949 completed (loss: 3.657181978225708, acc: 0.4444444477558136)
[2025-02-17 17:45:10,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:11,003][root][INFO] - Training Epoch: 1/2, step 1042/53949 completed (loss: 0.12341857701539993, acc: 1.0)
[2025-02-17 17:45:11,184][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:11,402][root][INFO] - Training Epoch: 1/2, step 1043/53949 completed (loss: 3.0636045932769775, acc: 0.260869562625885)
[2025-02-17 17:45:11,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:11,760][root][INFO] - Training Epoch: 1/2, step 1044/53949 completed (loss: 4.882218360900879, acc: 0.4000000059604645)
[2025-02-17 17:45:11,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:12,108][root][INFO] - Training Epoch: 1/2, step 1045/53949 completed (loss: 2.17075252532959, acc: 0.6000000238418579)
[2025-02-17 17:45:12,241][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:12,463][root][INFO] - Training Epoch: 1/2, step 1046/53949 completed (loss: 3.7984347343444824, acc: 0.2666666805744171)
[2025-02-17 17:45:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:12,862][root][INFO] - Training Epoch: 1/2, step 1047/53949 completed (loss: 2.3683698177337646, acc: 0.44999998807907104)
[2025-02-17 17:45:13,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:13,275][root][INFO] - Training Epoch: 1/2, step 1048/53949 completed (loss: 3.868462085723877, acc: 0.3529411852359772)
[2025-02-17 17:45:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:13,661][root][INFO] - Training Epoch: 1/2, step 1049/53949 completed (loss: 3.275789976119995, acc: 0.3333333432674408)
[2025-02-17 17:45:13,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:14,015][root][INFO] - Training Epoch: 1/2, step 1050/53949 completed (loss: 0.35775744915008545, acc: 1.0)
[2025-02-17 17:45:14,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:14,382][root][INFO] - Training Epoch: 1/2, step 1051/53949 completed (loss: 3.6347670555114746, acc: 0.3030303120613098)
[2025-02-17 17:45:14,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:14,758][root][INFO] - Training Epoch: 1/2, step 1052/53949 completed (loss: 4.1683430671691895, acc: 0.2631579041481018)
[2025-02-17 17:45:14,958][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:15,186][root][INFO] - Training Epoch: 1/2, step 1053/53949 completed (loss: 3.7915828227996826, acc: 0.2857142984867096)
[2025-02-17 17:45:15,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:15,568][root][INFO] - Training Epoch: 1/2, step 1054/53949 completed (loss: 3.660806655883789, acc: 0.2631579041481018)
[2025-02-17 17:45:15,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:15,924][root][INFO] - Training Epoch: 1/2, step 1055/53949 completed (loss: 2.2327167987823486, acc: 0.75)
[2025-02-17 17:45:16,068][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:16,294][root][INFO] - Training Epoch: 1/2, step 1056/53949 completed (loss: 4.194058895111084, acc: 0.20000000298023224)
[2025-02-17 17:45:16,469][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:16,692][root][INFO] - Training Epoch: 1/2, step 1057/53949 completed (loss: 4.016639232635498, acc: 0.2222222238779068)
[2025-02-17 17:45:16,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:17,133][root][INFO] - Training Epoch: 1/2, step 1058/53949 completed (loss: 3.136230945587158, acc: 0.24137930572032928)
[2025-02-17 17:45:17,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:17,570][root][INFO] - Training Epoch: 1/2, step 1059/53949 completed (loss: 2.947098731994629, acc: 0.375)
[2025-02-17 17:45:17,752][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:17,975][root][INFO] - Training Epoch: 1/2, step 1060/53949 completed (loss: 2.5521881580352783, acc: 0.5625)
[2025-02-17 17:45:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:18,328][root][INFO] - Training Epoch: 1/2, step 1061/53949 completed (loss: 3.3422744274139404, acc: 0.20000000298023224)
[2025-02-17 17:45:18,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:18,737][root][INFO] - Training Epoch: 1/2, step 1062/53949 completed (loss: 3.083893060684204, acc: 0.4000000059604645)
[2025-02-17 17:45:18,882][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:19,116][root][INFO] - Training Epoch: 1/2, step 1063/53949 completed (loss: 1.78184175491333, acc: 0.692307710647583)
[2025-02-17 17:45:19,311][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:19,532][root][INFO] - Training Epoch: 1/2, step 1064/53949 completed (loss: 0.06119214743375778, acc: 1.0)
[2025-02-17 17:45:19,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:19,906][root][INFO] - Training Epoch: 1/2, step 1065/53949 completed (loss: 3.8115432262420654, acc: 0.37037035822868347)
[2025-02-17 17:45:20,052][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:20,272][root][INFO] - Training Epoch: 1/2, step 1066/53949 completed (loss: 3.9646475315093994, acc: 0.1818181872367859)
[2025-02-17 17:45:20,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:20,651][root][INFO] - Training Epoch: 1/2, step 1067/53949 completed (loss: 3.7860429286956787, acc: 0.125)
[2025-02-17 17:45:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:21,125][root][INFO] - Training Epoch: 1/2, step 1068/53949 completed (loss: 3.196988344192505, acc: 0.3513513505458832)
[2025-02-17 17:45:21,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:21,455][root][INFO] - Training Epoch: 1/2, step 1069/53949 completed (loss: 0.9326505661010742, acc: 0.800000011920929)
[2025-02-17 17:45:21,604][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:21,836][root][INFO] - Training Epoch: 1/2, step 1070/53949 completed (loss: 2.765143871307373, acc: 0.3333333432674408)
[2025-02-17 17:45:21,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:22,219][root][INFO] - Training Epoch: 1/2, step 1071/53949 completed (loss: 4.106805324554443, acc: 0.3055555522441864)
[2025-02-17 17:45:22,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:22,633][root][INFO] - Training Epoch: 1/2, step 1072/53949 completed (loss: 3.8054111003875732, acc: 0.2083333283662796)
[2025-02-17 17:45:22,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:23,116][root][INFO] - Training Epoch: 1/2, step 1073/53949 completed (loss: 3.2840230464935303, acc: 0.39393940567970276)
[2025-02-17 17:45:23,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:23,523][root][INFO] - Training Epoch: 1/2, step 1074/53949 completed (loss: 2.46895694732666, acc: 0.3333333432674408)
[2025-02-17 17:45:23,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:24,014][root][INFO] - Training Epoch: 1/2, step 1075/53949 completed (loss: 3.815418243408203, acc: 0.2075471729040146)
[2025-02-17 17:45:24,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:24,466][root][INFO] - Training Epoch: 1/2, step 1076/53949 completed (loss: 4.382102012634277, acc: 0.3333333432674408)
[2025-02-17 17:45:24,626][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:24,851][root][INFO] - Training Epoch: 1/2, step 1077/53949 completed (loss: 4.222957611083984, acc: 0.16326530277729034)
[2025-02-17 17:45:25,015][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:25,287][root][INFO] - Training Epoch: 1/2, step 1078/53949 completed (loss: 3.4099113941192627, acc: 0.2978723347187042)
[2025-02-17 17:45:25,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:25,751][root][INFO] - Training Epoch: 1/2, step 1079/53949 completed (loss: 3.253669500350952, acc: 0.4000000059604645)
[2025-02-17 17:45:25,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:26,113][root][INFO] - Training Epoch: 1/2, step 1080/53949 completed (loss: 3.006375789642334, acc: 0.3333333432674408)
[2025-02-17 17:45:26,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:26,471][root][INFO] - Training Epoch: 1/2, step 1081/53949 completed (loss: 3.462312698364258, acc: 0.25)
[2025-02-17 17:45:26,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:26,829][root][INFO] - Training Epoch: 1/2, step 1082/53949 completed (loss: 2.2993900775909424, acc: 0.47058823704719543)
[2025-02-17 17:45:26,978][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:27,191][root][INFO] - Training Epoch: 1/2, step 1083/53949 completed (loss: 4.184026718139648, acc: 0.24390244483947754)
[2025-02-17 17:45:27,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:27,543][root][INFO] - Training Epoch: 1/2, step 1084/53949 completed (loss: 5.312148094177246, acc: 0.3333333432674408)
[2025-02-17 17:45:27,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:27,961][root][INFO] - Training Epoch: 1/2, step 1085/53949 completed (loss: 1.415704607963562, acc: 0.5)
[2025-02-17 17:45:28,101][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:28,324][root][INFO] - Training Epoch: 1/2, step 1086/53949 completed (loss: 5.028968334197998, acc: 0.20000000298023224)
[2025-02-17 17:45:28,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:28,687][root][INFO] - Training Epoch: 1/2, step 1087/53949 completed (loss: 3.488845109939575, acc: 0.34090909361839294)
[2025-02-17 17:45:28,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:29,052][root][INFO] - Training Epoch: 1/2, step 1088/53949 completed (loss: 4.306964874267578, acc: 0.23076923191547394)
[2025-02-17 17:45:29,194][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:29,431][root][INFO] - Training Epoch: 1/2, step 1089/53949 completed (loss: 2.937866449356079, acc: 0.3571428656578064)
[2025-02-17 17:45:29,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:29,826][root][INFO] - Training Epoch: 1/2, step 1090/53949 completed (loss: 3.854985475540161, acc: 0.1785714328289032)
[2025-02-17 17:45:30,002][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:30,256][root][INFO] - Training Epoch: 1/2, step 1091/53949 completed (loss: 3.0434470176696777, acc: 0.44999998807907104)
[2025-02-17 17:45:30,432][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:30,656][root][INFO] - Training Epoch: 1/2, step 1092/53949 completed (loss: 2.852935552597046, acc: 0.3478260934352875)
[2025-02-17 17:45:30,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:31,017][root][INFO] - Training Epoch: 1/2, step 1093/53949 completed (loss: 3.4767587184906006, acc: 0.2432432472705841)
[2025-02-17 17:45:31,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:31,412][root][INFO] - Training Epoch: 1/2, step 1094/53949 completed (loss: 2.905973434448242, acc: 0.5)
[2025-02-17 17:45:31,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:31,779][root][INFO] - Training Epoch: 1/2, step 1095/53949 completed (loss: 3.6249659061431885, acc: 0.3333333432674408)
[2025-02-17 17:45:31,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:32,147][root][INFO] - Training Epoch: 1/2, step 1096/53949 completed (loss: 3.309523105621338, acc: 0.28947368264198303)
[2025-02-17 17:45:32,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:32,521][root][INFO] - Training Epoch: 1/2, step 1097/53949 completed (loss: 1.9471272230148315, acc: 0.6666666865348816)
[2025-02-17 17:45:32,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:32,904][root][INFO] - Training Epoch: 1/2, step 1098/53949 completed (loss: 2.3195149898529053, acc: 0.3333333432674408)
[2025-02-17 17:45:33,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:33,257][root][INFO] - Training Epoch: 1/2, step 1099/53949 completed (loss: 2.906582832336426, acc: 0.3333333432674408)
[2025-02-17 17:45:33,396][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:33,665][root][INFO] - Training Epoch: 1/2, step 1100/53949 completed (loss: 3.673837900161743, acc: 0.25)
[2025-02-17 17:45:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:34,138][root][INFO] - Training Epoch: 1/2, step 1101/53949 completed (loss: 3.651768445968628, acc: 0.2083333283662796)
[2025-02-17 17:45:34,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:34,508][root][INFO] - Training Epoch: 1/2, step 1102/53949 completed (loss: 2.8982231616973877, acc: 0.5)
[2025-02-17 17:45:34,650][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:34,845][root][INFO] - Training Epoch: 1/2, step 1103/53949 completed (loss: 3.321476459503174, acc: 0.3076923191547394)
[2025-02-17 17:45:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:35,231][root][INFO] - Training Epoch: 1/2, step 1104/53949 completed (loss: 3.3350753784179688, acc: 0.375)
[2025-02-17 17:45:35,434][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:35,682][root][INFO] - Training Epoch: 1/2, step 1105/53949 completed (loss: 2.5065858364105225, acc: 0.40740740299224854)
[2025-02-17 17:45:35,886][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:36,118][root][INFO] - Training Epoch: 1/2, step 1106/53949 completed (loss: 2.5416171550750732, acc: 0.4615384638309479)
[2025-02-17 17:45:36,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:36,550][root][INFO] - Training Epoch: 1/2, step 1107/53949 completed (loss: 3.6313650608062744, acc: 0.3636363744735718)
[2025-02-17 17:45:36,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:36,982][root][INFO] - Training Epoch: 1/2, step 1108/53949 completed (loss: 1.6497763395309448, acc: 0.75)
[2025-02-17 17:45:37,158][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:37,382][root][INFO] - Training Epoch: 1/2, step 1109/53949 completed (loss: 2.7844583988189697, acc: 0.3513513505458832)
[2025-02-17 17:45:37,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:37,773][root][INFO] - Training Epoch: 1/2, step 1110/53949 completed (loss: 3.222844123840332, acc: 0.25925925374031067)
[2025-02-17 17:45:37,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:38,203][root][INFO] - Training Epoch: 1/2, step 1111/53949 completed (loss: 3.2802822589874268, acc: 0.25)
[2025-02-17 17:45:38,392][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:38,668][root][INFO] - Training Epoch: 1/2, step 1112/53949 completed (loss: 3.9882359504699707, acc: 0.1538461595773697)
[2025-02-17 17:45:38,862][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:39,098][root][INFO] - Training Epoch: 1/2, step 1113/53949 completed (loss: 3.5640757083892822, acc: 0.31578946113586426)
[2025-02-17 17:45:39,277][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:39,497][root][INFO] - Training Epoch: 1/2, step 1114/53949 completed (loss: 1.6028289794921875, acc: 0.8571428656578064)
[2025-02-17 17:45:39,678][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:39,927][root][INFO] - Training Epoch: 1/2, step 1115/53949 completed (loss: 1.0171664953231812, acc: 0.3333333432674408)
[2025-02-17 17:45:40,131][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:40,353][root][INFO] - Training Epoch: 1/2, step 1116/53949 completed (loss: 2.7198984622955322, acc: 0.31707316637039185)
[2025-02-17 17:45:40,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:40,746][root][INFO] - Training Epoch: 1/2, step 1117/53949 completed (loss: 3.2312798500061035, acc: 0.41304346919059753)
[2025-02-17 17:45:40,995][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:41,227][root][INFO] - Training Epoch: 1/2, step 1118/53949 completed (loss: 2.8332226276397705, acc: 0.2857142984867096)
[2025-02-17 17:45:41,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:41,633][root][INFO] - Training Epoch: 1/2, step 1119/53949 completed (loss: 3.4835126399993896, acc: 0.28260868787765503)
[2025-02-17 17:45:41,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:42,059][root][INFO] - Training Epoch: 1/2, step 1120/53949 completed (loss: 3.0732555389404297, acc: 0.3214285671710968)
[2025-02-17 17:45:42,230][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:42,455][root][INFO] - Training Epoch: 1/2, step 1121/53949 completed (loss: 3.463698148727417, acc: 0.2631579041481018)
[2025-02-17 17:45:42,595][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:42,822][root][INFO] - Training Epoch: 1/2, step 1122/53949 completed (loss: 3.528041362762451, acc: 0.21739129722118378)
[2025-02-17 17:45:43,009][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:43,258][root][INFO] - Training Epoch: 1/2, step 1123/53949 completed (loss: 3.9266371726989746, acc: 0.3333333432674408)
[2025-02-17 17:45:43,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:43,643][root][INFO] - Training Epoch: 1/2, step 1124/53949 completed (loss: 4.381351947784424, acc: 0.0833333358168602)
[2025-02-17 17:45:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:44,019][root][INFO] - Training Epoch: 1/2, step 1125/53949 completed (loss: 4.125741481781006, acc: 0.32258063554763794)
[2025-02-17 17:45:44,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:44,406][root][INFO] - Training Epoch: 1/2, step 1126/53949 completed (loss: 3.486616373062134, acc: 0.3611111044883728)
[2025-02-17 17:45:44,599][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:44,854][root][INFO] - Training Epoch: 1/2, step 1127/53949 completed (loss: 2.5727927684783936, acc: 0.3888888955116272)
[2025-02-17 17:45:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:45,235][root][INFO] - Training Epoch: 1/2, step 1128/53949 completed (loss: 3.2313523292541504, acc: 0.3333333432674408)
[2025-02-17 17:45:45,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:45,584][root][INFO] - Training Epoch: 1/2, step 1129/53949 completed (loss: 3.9709854125976562, acc: 0.2222222238779068)
[2025-02-17 17:45:45,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:45,977][root][INFO] - Training Epoch: 1/2, step 1130/53949 completed (loss: 5.17919921875, acc: 0.1875)
[2025-02-17 17:45:46,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:46,425][root][INFO] - Training Epoch: 1/2, step 1131/53949 completed (loss: 3.5871853828430176, acc: 0.3499999940395355)
[2025-02-17 17:45:46,638][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:46,871][root][INFO] - Training Epoch: 1/2, step 1132/53949 completed (loss: 3.461472272872925, acc: 0.20000000298023224)
[2025-02-17 17:45:47,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:47,315][root][INFO] - Training Epoch: 1/2, step 1133/53949 completed (loss: 1.3505425453186035, acc: 0.7272727489471436)
[2025-02-17 17:45:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:47,759][root][INFO] - Training Epoch: 1/2, step 1134/53949 completed (loss: 3.0217294692993164, acc: 0.37037035822868347)
[2025-02-17 17:45:47,945][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:48,174][root][INFO] - Training Epoch: 1/2, step 1135/53949 completed (loss: 3.8857622146606445, acc: 0.3055555522441864)
[2025-02-17 17:45:48,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:48,557][root][INFO] - Training Epoch: 1/2, step 1136/53949 completed (loss: 3.448582172393799, acc: 0.1428571492433548)
[2025-02-17 17:45:48,757][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:48,981][root][INFO] - Training Epoch: 1/2, step 1137/53949 completed (loss: 4.080333709716797, acc: 0.21875)
[2025-02-17 17:45:49,125][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:49,349][root][INFO] - Training Epoch: 1/2, step 1138/53949 completed (loss: 2.5955235958099365, acc: 0.625)
[2025-02-17 17:45:49,548][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:49,792][root][INFO] - Training Epoch: 1/2, step 1139/53949 completed (loss: 3.2766966819763184, acc: 0.31111112236976624)
[2025-02-17 17:45:49,952][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:50,157][root][INFO] - Training Epoch: 1/2, step 1140/53949 completed (loss: 3.3653740882873535, acc: 0.3333333432674408)
[2025-02-17 17:45:50,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:50,504][root][INFO] - Training Epoch: 1/2, step 1141/53949 completed (loss: 3.1116316318511963, acc: 0.3333333432674408)
[2025-02-17 17:45:50,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:50,889][root][INFO] - Training Epoch: 1/2, step 1142/53949 completed (loss: 4.385692119598389, acc: 0.2857142984867096)
[2025-02-17 17:45:51,077][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:51,315][root][INFO] - Training Epoch: 1/2, step 1143/53949 completed (loss: 3.7378005981445312, acc: 0.3571428656578064)
[2025-02-17 17:45:51,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:51,760][root][INFO] - Training Epoch: 1/2, step 1144/53949 completed (loss: 3.1186375617980957, acc: 0.3333333432674408)
[2025-02-17 17:45:51,939][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:52,166][root][INFO] - Training Epoch: 1/2, step 1145/53949 completed (loss: 3.5204029083251953, acc: 0.3499999940395355)
[2025-02-17 17:45:52,377][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:52,612][root][INFO] - Training Epoch: 1/2, step 1146/53949 completed (loss: 3.2954976558685303, acc: 0.3333333432674408)
[2025-02-17 17:45:52,834][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:53,074][root][INFO] - Training Epoch: 1/2, step 1147/53949 completed (loss: 3.3590142726898193, acc: 0.4545454680919647)
[2025-02-17 17:45:53,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:53,502][root][INFO] - Training Epoch: 1/2, step 1148/53949 completed (loss: 4.108851432800293, acc: 0.38461539149284363)
[2025-02-17 17:45:53,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:53,928][root][INFO] - Training Epoch: 1/2, step 1149/53949 completed (loss: 3.107820987701416, acc: 0.3928571343421936)
[2025-02-17 17:45:54,099][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:54,320][root][INFO] - Training Epoch: 1/2, step 1150/53949 completed (loss: 4.1751532554626465, acc: 0.21875)
[2025-02-17 17:45:54,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:54,695][root][INFO] - Training Epoch: 1/2, step 1151/53949 completed (loss: 3.012683629989624, acc: 0.27272728085517883)
[2025-02-17 17:45:54,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:55,061][root][INFO] - Training Epoch: 1/2, step 1152/53949 completed (loss: 5.160940170288086, acc: 0.27272728085517883)
[2025-02-17 17:45:55,189][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:55,464][root][INFO] - Training Epoch: 1/2, step 1153/53949 completed (loss: 2.485304594039917, acc: 0.4444444477558136)
[2025-02-17 17:45:55,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:55,920][root][INFO] - Training Epoch: 1/2, step 1154/53949 completed (loss: 3.1108696460723877, acc: 0.27272728085517883)
[2025-02-17 17:45:56,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:56,385][root][INFO] - Training Epoch: 1/2, step 1155/53949 completed (loss: 3.8871829509735107, acc: 0.20000000298023224)
[2025-02-17 17:45:56,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:56,774][root][INFO] - Training Epoch: 1/2, step 1156/53949 completed (loss: 2.652294397354126, acc: 0.5555555820465088)
[2025-02-17 17:45:56,947][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:57,164][root][INFO] - Training Epoch: 1/2, step 1157/53949 completed (loss: 2.5126304626464844, acc: 0.5)
[2025-02-17 17:45:57,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:57,582][root][INFO] - Training Epoch: 1/2, step 1158/53949 completed (loss: 2.8059847354888916, acc: 0.44999998807907104)
[2025-02-17 17:45:57,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:58,083][root][INFO] - Training Epoch: 1/2, step 1159/53949 completed (loss: 3.1726126670837402, acc: 0.3050847351551056)
[2025-02-17 17:45:58,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:58,515][root][INFO] - Training Epoch: 1/2, step 1160/53949 completed (loss: 0.08950181305408478, acc: 1.0)
[2025-02-17 17:45:58,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:58,876][root][INFO] - Training Epoch: 1/2, step 1161/53949 completed (loss: 4.847437381744385, acc: 0.2857142984867096)
[2025-02-17 17:45:59,043][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:59,317][root][INFO] - Training Epoch: 1/2, step 1162/53949 completed (loss: 3.645467758178711, acc: 0.2857142984867096)
[2025-02-17 17:45:59,588][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:45:59,824][root][INFO] - Training Epoch: 1/2, step 1163/53949 completed (loss: 3.867316961288452, acc: 0.23076923191547394)
[2025-02-17 17:46:00,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:00,256][root][INFO] - Training Epoch: 1/2, step 1164/53949 completed (loss: 2.0808961391448975, acc: 0.3333333432674408)
[2025-02-17 17:46:00,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:00,642][root][INFO] - Training Epoch: 1/2, step 1165/53949 completed (loss: 3.2805566787719727, acc: 0.4444444477558136)
[2025-02-17 17:46:00,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:01,082][root][INFO] - Training Epoch: 1/2, step 1166/53949 completed (loss: 3.770827531814575, acc: 0.21052631735801697)
[2025-02-17 17:46:01,293][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:01,533][root][INFO] - Training Epoch: 1/2, step 1167/53949 completed (loss: 3.411257266998291, acc: 0.27906978130340576)
[2025-02-17 17:46:01,731][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:01,978][root][INFO] - Training Epoch: 1/2, step 1168/53949 completed (loss: 1.6747537851333618, acc: 0.375)
[2025-02-17 17:46:02,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:02,417][root][INFO] - Training Epoch: 1/2, step 1169/53949 completed (loss: 2.738906145095825, acc: 0.4285714328289032)
[2025-02-17 17:46:02,573][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:02,794][root][INFO] - Training Epoch: 1/2, step 1170/53949 completed (loss: 2.630429983139038, acc: 0.3529411852359772)
[2025-02-17 17:46:02,975][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:03,207][root][INFO] - Training Epoch: 1/2, step 1171/53949 completed (loss: 3.5480921268463135, acc: 0.13793103396892548)
[2025-02-17 17:46:03,480][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:03,716][root][INFO] - Training Epoch: 1/2, step 1172/53949 completed (loss: 2.935000419616699, acc: 0.3636363744735718)
[2025-02-17 17:46:03,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:04,121][root][INFO] - Training Epoch: 1/2, step 1173/53949 completed (loss: 3.983616352081299, acc: 0.3448275923728943)
[2025-02-17 17:46:04,253][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:04,542][root][INFO] - Training Epoch: 1/2, step 1174/53949 completed (loss: 4.932445526123047, acc: 0.29411765933036804)
[2025-02-17 17:46:04,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:05,004][root][INFO] - Training Epoch: 1/2, step 1175/53949 completed (loss: 2.194700002670288, acc: 0.5)
[2025-02-17 17:46:05,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:05,408][root][INFO] - Training Epoch: 1/2, step 1176/53949 completed (loss: 3.141016960144043, acc: 0.41999998688697815)
[2025-02-17 17:46:05,546][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:05,793][root][INFO] - Training Epoch: 1/2, step 1177/53949 completed (loss: 3.6874964237213135, acc: 0.3103448152542114)
[2025-02-17 17:46:05,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:06,241][root][INFO] - Training Epoch: 1/2, step 1178/53949 completed (loss: 3.387355089187622, acc: 0.5)
[2025-02-17 17:46:06,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:06,644][root][INFO] - Training Epoch: 1/2, step 1179/53949 completed (loss: 3.0286483764648438, acc: 0.4285714328289032)
[2025-02-17 17:46:06,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:07,091][root][INFO] - Training Epoch: 1/2, step 1180/53949 completed (loss: 3.7145228385925293, acc: 0.3888888955116272)
[2025-02-17 17:46:07,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:07,530][root][INFO] - Training Epoch: 1/2, step 1181/53949 completed (loss: 3.7985806465148926, acc: 0.3404255211353302)
[2025-02-17 17:46:07,665][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:07,888][root][INFO] - Training Epoch: 1/2, step 1182/53949 completed (loss: 2.122628927230835, acc: 0.4615384638309479)
[2025-02-17 17:46:08,024][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:08,238][root][INFO] - Training Epoch: 1/2, step 1183/53949 completed (loss: 1.1021968126296997, acc: 0.75)
[2025-02-17 17:46:08,416][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:08,634][root][INFO] - Training Epoch: 1/2, step 1184/53949 completed (loss: 4.032140254974365, acc: 0.0833333358168602)
[2025-02-17 17:46:08,812][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:09,037][root][INFO] - Training Epoch: 1/2, step 1185/53949 completed (loss: 0.6800509691238403, acc: 0.75)
[2025-02-17 17:46:09,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:09,437][root][INFO] - Training Epoch: 1/2, step 1186/53949 completed (loss: 4.087594032287598, acc: 0.2857142984867096)
[2025-02-17 17:46:09,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:09,885][root][INFO] - Training Epoch: 1/2, step 1187/53949 completed (loss: 4.37055778503418, acc: 0.21052631735801697)
[2025-02-17 17:46:10,086][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:10,321][root][INFO] - Training Epoch: 1/2, step 1188/53949 completed (loss: 3.616495132446289, acc: 0.29411765933036804)
[2025-02-17 17:46:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:10,714][root][INFO] - Training Epoch: 1/2, step 1189/53949 completed (loss: 3.042513370513916, acc: 0.40909090638160706)
[2025-02-17 17:46:10,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:11,110][root][INFO] - Training Epoch: 1/2, step 1190/53949 completed (loss: 3.844923734664917, acc: 0.4000000059604645)
[2025-02-17 17:46:11,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:11,554][root][INFO] - Training Epoch: 1/2, step 1191/53949 completed (loss: 4.031522750854492, acc: 0.22641509771347046)
[2025-02-17 17:46:11,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:11,932][root][INFO] - Training Epoch: 1/2, step 1192/53949 completed (loss: 2.587477684020996, acc: 0.47058823704719543)
[2025-02-17 17:46:12,112][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:12,369][root][INFO] - Training Epoch: 1/2, step 1193/53949 completed (loss: 2.677349328994751, acc: 0.4285714328289032)
[2025-02-17 17:46:12,550][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:12,765][root][INFO] - Training Epoch: 1/2, step 1194/53949 completed (loss: 3.190565824508667, acc: 0.30000001192092896)
[2025-02-17 17:46:12,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:13,136][root][INFO] - Training Epoch: 1/2, step 1195/53949 completed (loss: 2.8829567432403564, acc: 0.4444444477558136)
[2025-02-17 17:46:13,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:13,561][root][INFO] - Training Epoch: 1/2, step 1196/53949 completed (loss: 3.4528584480285645, acc: 0.31707316637039185)
[2025-02-17 17:46:13,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:13,981][root][INFO] - Training Epoch: 1/2, step 1197/53949 completed (loss: 2.895421028137207, acc: 0.375)
[2025-02-17 17:46:14,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:14,366][root][INFO] - Training Epoch: 1/2, step 1198/53949 completed (loss: 4.129088878631592, acc: 0.3214285671710968)
[2025-02-17 17:46:14,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:14,734][root][INFO] - Training Epoch: 1/2, step 1199/53949 completed (loss: 3.339228391647339, acc: 0.21052631735801697)
[2025-02-17 17:46:14,879][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:15,109][root][INFO] - Training Epoch: 1/2, step 1200/53949 completed (loss: 3.9178898334503174, acc: 0.29629629850387573)
[2025-02-17 17:46:15,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:15,510][root][INFO] - Training Epoch: 1/2, step 1201/53949 completed (loss: 2.989715814590454, acc: 0.3947368562221527)
[2025-02-17 17:46:15,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:15,863][root][INFO] - Training Epoch: 1/2, step 1202/53949 completed (loss: 3.56251859664917, acc: 0.3076923191547394)
[2025-02-17 17:46:16,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:16,302][root][INFO] - Training Epoch: 1/2, step 1203/53949 completed (loss: 3.9729251861572266, acc: 0.2380952388048172)
[2025-02-17 17:46:16,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:16,708][root][INFO] - Training Epoch: 1/2, step 1204/53949 completed (loss: 3.6352345943450928, acc: 0.3333333432674408)
[2025-02-17 17:46:16,849][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:17,078][root][INFO] - Training Epoch: 1/2, step 1205/53949 completed (loss: 2.3542723655700684, acc: 0.2857142984867096)
[2025-02-17 17:46:17,266][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:17,493][root][INFO] - Training Epoch: 1/2, step 1206/53949 completed (loss: 2.689127206802368, acc: 0.4137931168079376)
[2025-02-17 17:46:17,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:17,928][root][INFO] - Training Epoch: 1/2, step 1207/53949 completed (loss: 5.370220184326172, acc: 0.11764705926179886)
[2025-02-17 17:46:18,147][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:18,376][root][INFO] - Training Epoch: 1/2, step 1208/53949 completed (loss: 3.9477624893188477, acc: 0.38461539149284363)
[2025-02-17 17:46:18,607][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:18,834][root][INFO] - Training Epoch: 1/2, step 1209/53949 completed (loss: 3.0997722148895264, acc: 0.3913043439388275)
[2025-02-17 17:46:18,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:19,251][root][INFO] - Training Epoch: 1/2, step 1210/53949 completed (loss: 2.80855393409729, acc: 0.47826087474823)
[2025-02-17 17:46:19,427][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:19,654][root][INFO] - Training Epoch: 1/2, step 1211/53949 completed (loss: 1.1828968524932861, acc: 0.75)
[2025-02-17 17:46:19,800][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:20,012][root][INFO] - Training Epoch: 1/2, step 1212/53949 completed (loss: 4.375855922698975, acc: 0.25)
[2025-02-17 17:46:20,221][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:20,460][root][INFO] - Training Epoch: 1/2, step 1213/53949 completed (loss: 3.390214443206787, acc: 0.21739129722118378)
[2025-02-17 17:46:20,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:20,888][root][INFO] - Training Epoch: 1/2, step 1214/53949 completed (loss: 3.4739789962768555, acc: 0.23529411852359772)
[2025-02-17 17:46:21,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:21,274][root][INFO] - Training Epoch: 1/2, step 1215/53949 completed (loss: 4.006799697875977, acc: 0.2222222238779068)
[2025-02-17 17:46:21,415][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:21,629][root][INFO] - Training Epoch: 1/2, step 1216/53949 completed (loss: 3.5307371616363525, acc: 0.3571428656578064)
[2025-02-17 17:46:21,772][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:21,956][root][INFO] - Training Epoch: 1/2, step 1217/53949 completed (loss: 3.7061355113983154, acc: 0.25)
[2025-02-17 17:46:22,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:22,384][root][INFO] - Training Epoch: 1/2, step 1218/53949 completed (loss: 4.387697696685791, acc: 0.1599999964237213)
[2025-02-17 17:46:22,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:22,822][root][INFO] - Training Epoch: 1/2, step 1219/53949 completed (loss: 3.0343379974365234, acc: 0.4736842215061188)
[2025-02-17 17:46:23,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:23,289][root][INFO] - Training Epoch: 1/2, step 1220/53949 completed (loss: 3.4558629989624023, acc: 0.31111112236976624)
[2025-02-17 17:46:23,508][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:23,749][root][INFO] - Training Epoch: 1/2, step 1221/53949 completed (loss: 2.393240451812744, acc: 0.2631579041481018)
[2025-02-17 17:46:23,911][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:24,131][root][INFO] - Training Epoch: 1/2, step 1222/53949 completed (loss: 3.414108991622925, acc: 0.23255814611911774)
[2025-02-17 17:46:24,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:24,492][root][INFO] - Training Epoch: 1/2, step 1223/53949 completed (loss: 4.047813415527344, acc: 0.23529411852359772)
[2025-02-17 17:46:24,672][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:24,903][root][INFO] - Training Epoch: 1/2, step 1224/53949 completed (loss: 3.0198974609375, acc: 0.4054054021835327)
[2025-02-17 17:46:25,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:25,316][root][INFO] - Training Epoch: 1/2, step 1225/53949 completed (loss: 0.17134927213191986, acc: 1.0)
[2025-02-17 17:46:25,460][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:25,686][root][INFO] - Training Epoch: 1/2, step 1226/53949 completed (loss: 4.135132789611816, acc: 0.1315789520740509)
[2025-02-17 17:46:25,893][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:26,094][root][INFO] - Training Epoch: 1/2, step 1227/53949 completed (loss: 3.2834134101867676, acc: 0.23076923191547394)
[2025-02-17 17:46:26,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:26,503][root][INFO] - Training Epoch: 1/2, step 1228/53949 completed (loss: 4.134411334991455, acc: 0.2631579041481018)
[2025-02-17 17:46:26,708][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:26,948][root][INFO] - Training Epoch: 1/2, step 1229/53949 completed (loss: 3.981503963470459, acc: 0.29411765933036804)
[2025-02-17 17:46:27,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:27,399][root][INFO] - Training Epoch: 1/2, step 1230/53949 completed (loss: 3.386746644973755, acc: 0.29411765933036804)
[2025-02-17 17:46:27,598][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:27,830][root][INFO] - Training Epoch: 1/2, step 1231/53949 completed (loss: 4.503733158111572, acc: 0.14705882966518402)
[2025-02-17 17:46:28,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:28,228][root][INFO] - Training Epoch: 1/2, step 1232/53949 completed (loss: 2.083968162536621, acc: 0.375)
[2025-02-17 17:46:28,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:28,591][root][INFO] - Training Epoch: 1/2, step 1233/53949 completed (loss: 1.520050287246704, acc: 0.75)
[2025-02-17 17:46:28,725][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:28,943][root][INFO] - Training Epoch: 1/2, step 1234/53949 completed (loss: 3.2949116230010986, acc: 0.375)
[2025-02-17 17:46:29,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:29,309][root][INFO] - Training Epoch: 1/2, step 1235/53949 completed (loss: 3.567183494567871, acc: 0.3333333432674408)
[2025-02-17 17:46:29,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:29,740][root][INFO] - Training Epoch: 1/2, step 1236/53949 completed (loss: 3.126793384552002, acc: 0.3571428656578064)
[2025-02-17 17:46:29,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:30,112][root][INFO] - Training Epoch: 1/2, step 1237/53949 completed (loss: 2.4036824703216553, acc: 0.4000000059604645)
[2025-02-17 17:46:30,321][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:30,556][root][INFO] - Training Epoch: 1/2, step 1238/53949 completed (loss: 2.84359073638916, acc: 0.36000001430511475)
[2025-02-17 17:46:30,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:30,998][root][INFO] - Training Epoch: 1/2, step 1239/53949 completed (loss: 3.0971617698669434, acc: 0.2857142984867096)
[2025-02-17 17:46:31,205][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:31,439][root][INFO] - Training Epoch: 1/2, step 1240/53949 completed (loss: 3.246387481689453, acc: 0.3265306055545807)
[2025-02-17 17:46:31,648][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:31,876][root][INFO] - Training Epoch: 1/2, step 1241/53949 completed (loss: 3.312788724899292, acc: 0.34285715222358704)
[2025-02-17 17:46:32,017][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:32,237][root][INFO] - Training Epoch: 1/2, step 1242/53949 completed (loss: 4.344757556915283, acc: 0.190476194024086)
[2025-02-17 17:46:32,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:32,649][root][INFO] - Training Epoch: 1/2, step 1243/53949 completed (loss: 3.626025676727295, acc: 0.380952388048172)
[2025-02-17 17:46:32,790][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:33,014][root][INFO] - Training Epoch: 1/2, step 1244/53949 completed (loss: 3.048837661743164, acc: 0.29411765933036804)
[2025-02-17 17:46:33,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:33,387][root][INFO] - Training Epoch: 1/2, step 1245/53949 completed (loss: 2.9193153381347656, acc: 0.5555555820465088)
[2025-02-17 17:46:33,531][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:33,759][root][INFO] - Training Epoch: 1/2, step 1246/53949 completed (loss: 3.0885159969329834, acc: 0.1599999964237213)
[2025-02-17 17:46:33,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:34,139][root][INFO] - Training Epoch: 1/2, step 1247/53949 completed (loss: 3.1049487590789795, acc: 0.34210526943206787)
[2025-02-17 17:46:34,298][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:34,524][root][INFO] - Training Epoch: 1/2, step 1248/53949 completed (loss: 3.247178792953491, acc: 0.2916666567325592)
[2025-02-17 17:46:34,712][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:34,944][root][INFO] - Training Epoch: 1/2, step 1249/53949 completed (loss: 4.310770511627197, acc: 0.2142857164144516)
[2025-02-17 17:46:35,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:35,372][root][INFO] - Training Epoch: 1/2, step 1250/53949 completed (loss: 2.4705984592437744, acc: 0.4117647111415863)
[2025-02-17 17:46:35,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:35,825][root][INFO] - Training Epoch: 1/2, step 1251/53949 completed (loss: 4.651504039764404, acc: 0.29411765933036804)
[2025-02-17 17:46:35,988][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:36,222][root][INFO] - Training Epoch: 1/2, step 1252/53949 completed (loss: 2.645716428756714, acc: 0.5555555820465088)
[2025-02-17 17:46:36,393][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:36,610][root][INFO] - Training Epoch: 1/2, step 1253/53949 completed (loss: 2.9455933570861816, acc: 0.30000001192092896)
[2025-02-17 17:46:36,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:37,003][root][INFO] - Training Epoch: 1/2, step 1254/53949 completed (loss: 3.3419673442840576, acc: 0.375)
[2025-02-17 17:46:37,169][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:37,422][root][INFO] - Training Epoch: 1/2, step 1255/53949 completed (loss: 2.735377788543701, acc: 0.4000000059604645)
[2025-02-17 17:46:37,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:37,877][root][INFO] - Training Epoch: 1/2, step 1256/53949 completed (loss: 1.1305873394012451, acc: 0.6666666865348816)
[2025-02-17 17:46:38,077][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:38,310][root][INFO] - Training Epoch: 1/2, step 1257/53949 completed (loss: 2.2646052837371826, acc: 0.6666666865348816)
[2025-02-17 17:46:38,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:38,789][root][INFO] - Training Epoch: 1/2, step 1258/53949 completed (loss: 4.020873546600342, acc: 0.3333333432674408)
[2025-02-17 17:46:38,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:39,217][root][INFO] - Training Epoch: 1/2, step 1259/53949 completed (loss: 2.249933958053589, acc: 0.5555555820465088)
[2025-02-17 17:46:39,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:39,665][root][INFO] - Training Epoch: 1/2, step 1260/53949 completed (loss: 3.1897120475769043, acc: 0.375)
[2025-02-17 17:46:39,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:40,068][root][INFO] - Training Epoch: 1/2, step 1261/53949 completed (loss: 3.244565486907959, acc: 0.5)
[2025-02-17 17:46:40,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:40,443][root][INFO] - Training Epoch: 1/2, step 1262/53949 completed (loss: 3.2904884815216064, acc: 0.35483869910240173)
[2025-02-17 17:46:40,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:40,811][root][INFO] - Training Epoch: 1/2, step 1263/53949 completed (loss: 2.510432004928589, acc: 0.5714285969734192)
[2025-02-17 17:46:40,940][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:41,167][root][INFO] - Training Epoch: 1/2, step 1264/53949 completed (loss: 1.9504059553146362, acc: 0.5384615659713745)
[2025-02-17 17:46:41,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:41,527][root][INFO] - Training Epoch: 1/2, step 1265/53949 completed (loss: 2.8987679481506348, acc: 0.44999998807907104)
[2025-02-17 17:46:41,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:42,023][root][INFO] - Training Epoch: 1/2, step 1266/53949 completed (loss: 3.3224997520446777, acc: 0.30882352590560913)
[2025-02-17 17:46:42,167][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:42,386][root][INFO] - Training Epoch: 1/2, step 1267/53949 completed (loss: 3.6066558361053467, acc: 0.2954545319080353)
[2025-02-17 17:46:42,518][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:42,742][root][INFO] - Training Epoch: 1/2, step 1268/53949 completed (loss: 3.4978349208831787, acc: 0.2631579041481018)
[2025-02-17 17:46:42,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:43,149][root][INFO] - Training Epoch: 1/2, step 1269/53949 completed (loss: 4.263281345367432, acc: 0.5)
[2025-02-17 17:46:43,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:43,599][root][INFO] - Training Epoch: 1/2, step 1270/53949 completed (loss: 3.251070261001587, acc: 0.24390244483947754)
[2025-02-17 17:46:43,818][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:44,042][root][INFO] - Training Epoch: 1/2, step 1271/53949 completed (loss: 4.117299556732178, acc: 0.27450981736183167)
[2025-02-17 17:46:44,193][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:44,419][root][INFO] - Training Epoch: 1/2, step 1272/53949 completed (loss: 2.0664877891540527, acc: 0.4444444477558136)
[2025-02-17 17:46:44,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:44,781][root][INFO] - Training Epoch: 1/2, step 1273/53949 completed (loss: 3.447024345397949, acc: 0.2954545319080353)
[2025-02-17 17:46:44,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:45,128][root][INFO] - Training Epoch: 1/2, step 1274/53949 completed (loss: 2.680011749267578, acc: 0.5)
[2025-02-17 17:46:45,257][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:45,535][root][INFO] - Training Epoch: 1/2, step 1275/53949 completed (loss: 4.854560852050781, acc: 0.1428571492433548)
[2025-02-17 17:46:45,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:45,977][root][INFO] - Training Epoch: 1/2, step 1276/53949 completed (loss: 3.5975396633148193, acc: 0.3333333432674408)
[2025-02-17 17:46:46,168][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:46,399][root][INFO] - Training Epoch: 1/2, step 1277/53949 completed (loss: 3.383723735809326, acc: 0.3166666626930237)
[2025-02-17 17:46:46,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:46,784][root][INFO] - Training Epoch: 1/2, step 1278/53949 completed (loss: 1.504045009613037, acc: 0.6666666865348816)
[2025-02-17 17:46:46,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:47,203][root][INFO] - Training Epoch: 1/2, step 1279/53949 completed (loss: 3.6091411113739014, acc: 0.23529411852359772)
[2025-02-17 17:46:47,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:47,587][root][INFO] - Training Epoch: 1/2, step 1280/53949 completed (loss: 0.026585299521684647, acc: 1.0)
[2025-02-17 17:46:47,735][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:47,959][root][INFO] - Training Epoch: 1/2, step 1281/53949 completed (loss: 3.0978598594665527, acc: 0.3636363744735718)
[2025-02-17 17:46:48,092][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:48,313][root][INFO] - Training Epoch: 1/2, step 1282/53949 completed (loss: 3.0337257385253906, acc: 0.4583333432674408)
[2025-02-17 17:46:48,528][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:48,772][root][INFO] - Training Epoch: 1/2, step 1283/53949 completed (loss: 3.64398193359375, acc: 0.3529411852359772)
[2025-02-17 17:46:48,981][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:49,215][root][INFO] - Training Epoch: 1/2, step 1284/53949 completed (loss: 3.045684337615967, acc: 0.3235294222831726)
[2025-02-17 17:46:49,449][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:49,683][root][INFO] - Training Epoch: 1/2, step 1285/53949 completed (loss: 2.941908121109009, acc: 0.3333333432674408)
[2025-02-17 17:46:49,850][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:50,076][root][INFO] - Training Epoch: 1/2, step 1286/53949 completed (loss: 2.842733144760132, acc: 0.4399999976158142)
[2025-02-17 17:46:50,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:50,491][root][INFO] - Training Epoch: 1/2, step 1287/53949 completed (loss: 2.747933864593506, acc: 0.3333333432674408)
[2025-02-17 17:46:50,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:50,854][root][INFO] - Training Epoch: 1/2, step 1288/53949 completed (loss: 3.4351789951324463, acc: 0.2666666805744171)
[2025-02-17 17:46:51,035][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:51,273][root][INFO] - Training Epoch: 1/2, step 1289/53949 completed (loss: 3.0253958702087402, acc: 0.46666666865348816)
[2025-02-17 17:46:51,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:51,676][root][INFO] - Training Epoch: 1/2, step 1290/53949 completed (loss: 3.6222567558288574, acc: 0.31111112236976624)
[2025-02-17 17:46:51,824][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:52,047][root][INFO] - Training Epoch: 1/2, step 1291/53949 completed (loss: 3.267815113067627, acc: 0.3333333432674408)
[2025-02-17 17:46:52,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:52,435][root][INFO] - Training Epoch: 1/2, step 1292/53949 completed (loss: 4.456242561340332, acc: 0.15000000596046448)
[2025-02-17 17:46:52,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:52,803][root][INFO] - Training Epoch: 1/2, step 1293/53949 completed (loss: 4.007324695587158, acc: 0.22499999403953552)
[2025-02-17 17:46:52,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:53,165][root][INFO] - Training Epoch: 1/2, step 1294/53949 completed (loss: 3.302856206893921, acc: 0.2857142984867096)
[2025-02-17 17:46:53,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:53,582][root][INFO] - Training Epoch: 1/2, step 1295/53949 completed (loss: 4.109029293060303, acc: 0.20000000298023224)
[2025-02-17 17:46:53,722][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:53,944][root][INFO] - Training Epoch: 1/2, step 1296/53949 completed (loss: 3.5726828575134277, acc: 0.20000000298023224)
[2025-02-17 17:46:54,096][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:54,320][root][INFO] - Training Epoch: 1/2, step 1297/53949 completed (loss: 3.055877208709717, acc: 0.1764705926179886)
[2025-02-17 17:46:54,461][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:54,682][root][INFO] - Training Epoch: 1/2, step 1298/53949 completed (loss: 5.486160755157471, acc: 0.23999999463558197)
[2025-02-17 17:46:54,827][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:55,053][root][INFO] - Training Epoch: 1/2, step 1299/53949 completed (loss: 3.236656665802002, acc: 0.3571428656578064)
[2025-02-17 17:46:55,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:55,412][root][INFO] - Training Epoch: 1/2, step 1300/53949 completed (loss: 1.9161927700042725, acc: 0.4444444477558136)
[2025-02-17 17:46:55,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:55,843][root][INFO] - Training Epoch: 1/2, step 1301/53949 completed (loss: 3.693621873855591, acc: 0.3499999940395355)
[2025-02-17 17:46:56,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:56,281][root][INFO] - Training Epoch: 1/2, step 1302/53949 completed (loss: 3.5411741733551025, acc: 0.3076923191547394)
[2025-02-17 17:46:56,473][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:56,714][root][INFO] - Training Epoch: 1/2, step 1303/53949 completed (loss: 3.3260090351104736, acc: 0.4615384638309479)
[2025-02-17 17:46:56,897][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:57,112][root][INFO] - Training Epoch: 1/2, step 1304/53949 completed (loss: 2.7107036113739014, acc: 0.4444444477558136)
[2025-02-17 17:46:57,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:57,523][root][INFO] - Training Epoch: 1/2, step 1305/53949 completed (loss: 3.2301290035247803, acc: 0.27272728085517883)
[2025-02-17 17:46:57,738][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:57,975][root][INFO] - Training Epoch: 1/2, step 1306/53949 completed (loss: 1.4992753267288208, acc: 0.5714285969734192)
[2025-02-17 17:46:58,134][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:58,368][root][INFO] - Training Epoch: 1/2, step 1307/53949 completed (loss: 4.2732930183410645, acc: 0.4166666567325592)
[2025-02-17 17:46:58,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:58,731][root][INFO] - Training Epoch: 1/2, step 1308/53949 completed (loss: 3.3969674110412598, acc: 0.30434781312942505)
[2025-02-17 17:46:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:59,169][root][INFO] - Training Epoch: 1/2, step 1309/53949 completed (loss: 1.6516588926315308, acc: 0.5454545617103577)
[2025-02-17 17:46:59,341][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:59,530][root][INFO] - Training Epoch: 1/2, step 1310/53949 completed (loss: 0.7095720767974854, acc: 0.75)
[2025-02-17 17:46:59,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:46:59,883][root][INFO] - Training Epoch: 1/2, step 1311/53949 completed (loss: 3.226360321044922, acc: 0.23076923191547394)
[2025-02-17 17:47:00,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:00,242][root][INFO] - Training Epoch: 1/2, step 1312/53949 completed (loss: 3.116353750228882, acc: 0.4285714328289032)
[2025-02-17 17:47:00,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:00,655][root][INFO] - Training Epoch: 1/2, step 1313/53949 completed (loss: 3.9964497089385986, acc: 0.10000000149011612)
[2025-02-17 17:47:00,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:01,098][root][INFO] - Training Epoch: 1/2, step 1314/53949 completed (loss: 3.238542079925537, acc: 0.2666666805744171)
[2025-02-17 17:47:01,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:01,508][root][INFO] - Training Epoch: 1/2, step 1315/53949 completed (loss: 2.4797651767730713, acc: 0.38461539149284363)
[2025-02-17 17:47:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:01,921][root][INFO] - Training Epoch: 1/2, step 1316/53949 completed (loss: 2.4266414642333984, acc: 0.42105263471603394)
[2025-02-17 17:47:02,079][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:02,304][root][INFO] - Training Epoch: 1/2, step 1317/53949 completed (loss: 0.05735890939831734, acc: 1.0)
[2025-02-17 17:47:02,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:02,786][root][INFO] - Training Epoch: 1/2, step 1318/53949 completed (loss: 2.7294278144836426, acc: 0.3214285671710968)
[2025-02-17 17:47:02,985][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:03,211][root][INFO] - Training Epoch: 1/2, step 1319/53949 completed (loss: 2.645754814147949, acc: 0.39393940567970276)
[2025-02-17 17:47:03,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:03,582][root][INFO] - Training Epoch: 1/2, step 1320/53949 completed (loss: 3.840409517288208, acc: 0.3333333432674408)
[2025-02-17 17:47:03,703][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:03,933][root][INFO] - Training Epoch: 1/2, step 1321/53949 completed (loss: 2.1019253730773926, acc: 0.4000000059604645)
[2025-02-17 17:47:04,106][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:04,339][root][INFO] - Training Epoch: 1/2, step 1322/53949 completed (loss: 0.5426462888717651, acc: 0.8571428656578064)
[2025-02-17 17:47:04,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:04,705][root][INFO] - Training Epoch: 1/2, step 1323/53949 completed (loss: 3.416224718093872, acc: 0.2702702581882477)
[2025-02-17 17:47:04,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:05,059][root][INFO] - Training Epoch: 1/2, step 1324/53949 completed (loss: 4.077322959899902, acc: 0.5714285969734192)
[2025-02-17 17:47:05,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:05,437][root][INFO] - Training Epoch: 1/2, step 1325/53949 completed (loss: 2.4565179347991943, acc: 0.4545454680919647)
[2025-02-17 17:47:05,624][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:05,848][root][INFO] - Training Epoch: 1/2, step 1326/53949 completed (loss: 3.0308334827423096, acc: 0.4000000059604645)
[2025-02-17 17:47:05,994][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:06,218][root][INFO] - Training Epoch: 1/2, step 1327/53949 completed (loss: 3.648789644241333, acc: 0.30000001192092896)
[2025-02-17 17:47:06,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:06,622][root][INFO] - Training Epoch: 1/2, step 1328/53949 completed (loss: 3.7368264198303223, acc: 0.3913043439388275)
[2025-02-17 17:47:06,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:07,036][root][INFO] - Training Epoch: 1/2, step 1329/53949 completed (loss: 4.366605281829834, acc: 0.2777777910232544)
[2025-02-17 17:47:07,214][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:07,444][root][INFO] - Training Epoch: 1/2, step 1330/53949 completed (loss: 3.454878807067871, acc: 0.25)
[2025-02-17 17:47:07,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:07,803][root][INFO] - Training Epoch: 1/2, step 1331/53949 completed (loss: 0.015466746874153614, acc: 1.0)
[2025-02-17 17:47:07,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:08,164][root][INFO] - Training Epoch: 1/2, step 1332/53949 completed (loss: 1.6208628416061401, acc: 0.3333333432674408)
[2025-02-17 17:47:08,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:08,590][root][INFO] - Training Epoch: 1/2, step 1333/53949 completed (loss: 3.425140142440796, acc: 0.2571428716182709)
[2025-02-17 17:47:08,804][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:09,034][root][INFO] - Training Epoch: 1/2, step 1334/53949 completed (loss: 4.014985084533691, acc: 0.31707316637039185)
[2025-02-17 17:47:09,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:09,373][root][INFO] - Training Epoch: 1/2, step 1335/53949 completed (loss: 4.339781284332275, acc: 0.23529411852359772)
[2025-02-17 17:47:09,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:09,772][root][INFO] - Training Epoch: 1/2, step 1336/53949 completed (loss: 3.62312388420105, acc: 0.3095238208770752)
[2025-02-17 17:47:09,928][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:10,146][root][INFO] - Training Epoch: 1/2, step 1337/53949 completed (loss: 2.881329298019409, acc: 0.2222222238779068)
[2025-02-17 17:47:10,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:10,560][root][INFO] - Training Epoch: 1/2, step 1338/53949 completed (loss: 3.467682361602783, acc: 0.2666666805744171)
[2025-02-17 17:47:10,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:10,876][root][INFO] - Training Epoch: 1/2, step 1339/53949 completed (loss: 3.930530071258545, acc: 0.2888889014720917)
[2025-02-17 17:47:11,025][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:11,246][root][INFO] - Training Epoch: 1/2, step 1340/53949 completed (loss: 3.7339982986450195, acc: 0.29629629850387573)
[2025-02-17 17:47:11,431][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:11,662][root][INFO] - Training Epoch: 1/2, step 1341/53949 completed (loss: 0.3722093105316162, acc: 0.75)
[2025-02-17 17:47:11,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:12,022][root][INFO] - Training Epoch: 1/2, step 1342/53949 completed (loss: 2.9745430946350098, acc: 0.30000001192092896)
[2025-02-17 17:47:12,161][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:12,382][root][INFO] - Training Epoch: 1/2, step 1343/53949 completed (loss: 3.566545248031616, acc: 0.36666667461395264)
[2025-02-17 17:47:12,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:12,761][root][INFO] - Training Epoch: 1/2, step 1344/53949 completed (loss: 4.467534065246582, acc: 0.4000000059604645)
[2025-02-17 17:47:12,947][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:13,193][root][INFO] - Training Epoch: 1/2, step 1345/53949 completed (loss: 3.0547587871551514, acc: 0.3333333432674408)
[2025-02-17 17:47:13,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:13,641][root][INFO] - Training Epoch: 1/2, step 1346/53949 completed (loss: 3.7672457695007324, acc: 0.375)
[2025-02-17 17:47:13,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:14,023][root][INFO] - Training Epoch: 1/2, step 1347/53949 completed (loss: 4.732609272003174, acc: 0.29411765933036804)
[2025-02-17 17:47:14,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:14,435][root][INFO] - Training Epoch: 1/2, step 1348/53949 completed (loss: 2.9518065452575684, acc: 0.3571428656578064)
[2025-02-17 17:47:14,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:14,805][root][INFO] - Training Epoch: 1/2, step 1349/53949 completed (loss: 2.3193371295928955, acc: 0.38461539149284363)
[2025-02-17 17:47:14,946][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:15,165][root][INFO] - Training Epoch: 1/2, step 1350/53949 completed (loss: 0.7518187761306763, acc: 0.800000011920929)
[2025-02-17 17:47:15,336][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:15,581][root][INFO] - Training Epoch: 1/2, step 1351/53949 completed (loss: 3.0560379028320312, acc: 0.5)
[2025-02-17 17:47:15,770][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:15,992][root][INFO] - Training Epoch: 1/2, step 1352/53949 completed (loss: 4.305906295776367, acc: 0.29411765933036804)
[2025-02-17 17:47:16,182][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:16,418][root][INFO] - Training Epoch: 1/2, step 1353/53949 completed (loss: 3.3392434120178223, acc: 0.42307692766189575)
[2025-02-17 17:47:16,579][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:16,774][root][INFO] - Training Epoch: 1/2, step 1354/53949 completed (loss: 3.842988967895508, acc: 0.21739129722118378)
[2025-02-17 17:47:16,936][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:17,150][root][INFO] - Training Epoch: 1/2, step 1355/53949 completed (loss: 4.051559925079346, acc: 0.40740740299224854)
[2025-02-17 17:47:17,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:17,533][root][INFO] - Training Epoch: 1/2, step 1356/53949 completed (loss: 4.056002616882324, acc: 0.2068965584039688)
[2025-02-17 17:47:17,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:17,888][root][INFO] - Training Epoch: 1/2, step 1357/53949 completed (loss: 4.489467144012451, acc: 0.11764705926179886)
[2025-02-17 17:47:18,059][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:18,278][root][INFO] - Training Epoch: 1/2, step 1358/53949 completed (loss: 3.81892991065979, acc: 0.3589743673801422)
[2025-02-17 17:47:18,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:18,663][root][INFO] - Training Epoch: 1/2, step 1359/53949 completed (loss: 2.875511407852173, acc: 0.38235294818878174)
[2025-02-17 17:47:18,801][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:19,015][root][INFO] - Training Epoch: 1/2, step 1360/53949 completed (loss: 4.040646553039551, acc: 0.29411765933036804)
[2025-02-17 17:47:19,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:19,441][root][INFO] - Training Epoch: 1/2, step 1361/53949 completed (loss: 3.185993194580078, acc: 0.2222222238779068)
[2025-02-17 17:47:19,592][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:19,813][root][INFO] - Training Epoch: 1/2, step 1362/53949 completed (loss: 2.734107494354248, acc: 0.3571428656578064)
[2025-02-17 17:47:19,987][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:20,222][root][INFO] - Training Epoch: 1/2, step 1363/53949 completed (loss: 3.5542688369750977, acc: 0.3076923191547394)
[2025-02-17 17:47:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:20,650][root][INFO] - Training Epoch: 1/2, step 1364/53949 completed (loss: 4.311366081237793, acc: 0.1785714328289032)
[2025-02-17 17:47:20,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:21,003][root][INFO] - Training Epoch: 1/2, step 1365/53949 completed (loss: 0.40969014167785645, acc: 1.0)
[2025-02-17 17:47:21,152][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:21,372][root][INFO] - Training Epoch: 1/2, step 1366/53949 completed (loss: 3.7941386699676514, acc: 0.2777777910232544)
[2025-02-17 17:47:21,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:21,717][root][INFO] - Training Epoch: 1/2, step 1367/53949 completed (loss: 2.493868112564087, acc: 0.3888888955116272)
[2025-02-17 17:47:21,881][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:22,103][root][INFO] - Training Epoch: 1/2, step 1368/53949 completed (loss: 3.1538143157958984, acc: 0.3243243098258972)
[2025-02-17 17:47:22,258][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:22,480][root][INFO] - Training Epoch: 1/2, step 1369/53949 completed (loss: 2.8941118717193604, acc: 0.4375)
[2025-02-17 17:47:22,687][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:22,909][root][INFO] - Training Epoch: 1/2, step 1370/53949 completed (loss: 3.7298402786254883, acc: 0.375)
[2025-02-17 17:47:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:23,322][root][INFO] - Training Epoch: 1/2, step 1371/53949 completed (loss: 3.1933329105377197, acc: 0.38461539149284363)
[2025-02-17 17:47:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:23,705][root][INFO] - Training Epoch: 1/2, step 1372/53949 completed (loss: 4.686800956726074, acc: 0.20000000298023224)
[2025-02-17 17:47:23,841][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:24,072][root][INFO] - Training Epoch: 1/2, step 1373/53949 completed (loss: 3.36550235748291, acc: 0.22727273404598236)
[2025-02-17 17:47:24,300][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:24,523][root][INFO] - Training Epoch: 1/2, step 1374/53949 completed (loss: 3.310495615005493, acc: 0.32258063554763794)
[2025-02-17 17:47:24,662][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:24,890][root][INFO] - Training Epoch: 1/2, step 1375/53949 completed (loss: 4.382166862487793, acc: 0.3103448152542114)
[2025-02-17 17:47:25,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:25,251][root][INFO] - Training Epoch: 1/2, step 1376/53949 completed (loss: 3.6028473377227783, acc: 0.25)
[2025-02-17 17:47:25,387][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:25,612][root][INFO] - Training Epoch: 1/2, step 1377/53949 completed (loss: 3.255660057067871, acc: 0.3636363744735718)
[2025-02-17 17:47:25,792][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:26,010][root][INFO] - Training Epoch: 1/2, step 1378/53949 completed (loss: 2.1817052364349365, acc: 0.5)
[2025-02-17 17:47:26,148][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:26,364][root][INFO] - Training Epoch: 1/2, step 1379/53949 completed (loss: 3.2945358753204346, acc: 0.3571428656578064)
[2025-02-17 17:47:26,530][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:26,754][root][INFO] - Training Epoch: 1/2, step 1380/53949 completed (loss: 3.533968210220337, acc: 0.29032257199287415)
[2025-02-17 17:47:26,927][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:27,145][root][INFO] - Training Epoch: 1/2, step 1381/53949 completed (loss: 3.3815815448760986, acc: 0.2380952388048172)
[2025-02-17 17:47:27,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:27,507][root][INFO] - Training Epoch: 1/2, step 1382/53949 completed (loss: 4.417630195617676, acc: 0.2222222238779068)
[2025-02-17 17:47:27,653][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:27,879][root][INFO] - Training Epoch: 1/2, step 1383/53949 completed (loss: 4.0007100105285645, acc: 0.3333333432674408)
[2025-02-17 17:47:28,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:28,256][root][INFO] - Training Epoch: 1/2, step 1384/53949 completed (loss: 3.966134786605835, acc: 0.3684210479259491)
[2025-02-17 17:47:28,428][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:28,686][root][INFO] - Training Epoch: 1/2, step 1385/53949 completed (loss: 3.177518844604492, acc: 0.25)
[2025-02-17 17:47:28,899][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:29,123][root][INFO] - Training Epoch: 1/2, step 1386/53949 completed (loss: 4.4059247970581055, acc: 0.13636364042758942)
[2025-02-17 17:47:29,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:29,489][root][INFO] - Training Epoch: 1/2, step 1387/53949 completed (loss: 0.4337449073791504, acc: 0.75)
[2025-02-17 17:47:29,656][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:29,883][root][INFO] - Training Epoch: 1/2, step 1388/53949 completed (loss: 0.030782848596572876, acc: 1.0)
[2025-02-17 17:47:30,065][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:30,294][root][INFO] - Training Epoch: 1/2, step 1389/53949 completed (loss: 3.219094753265381, acc: 0.4285714328289032)
[2025-02-17 17:47:30,485][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:30,772][root][INFO] - Training Epoch: 1/2, step 1390/53949 completed (loss: 4.407564163208008, acc: 0.30000001192092896)
[2025-02-17 17:47:31,021][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:31,299][root][INFO] - Training Epoch: 1/2, step 1391/53949 completed (loss: 3.5150208473205566, acc: 0.36666667461395264)
[2025-02-17 17:47:31,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:31,678][root][INFO] - Training Epoch: 1/2, step 1392/53949 completed (loss: 3.517909288406372, acc: 0.23529411852359772)
[2025-02-17 17:47:31,813][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:32,040][root][INFO] - Training Epoch: 1/2, step 1393/53949 completed (loss: 2.5682032108306885, acc: 0.5909090638160706)
[2025-02-17 17:47:32,181][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:32,396][root][INFO] - Training Epoch: 1/2, step 1394/53949 completed (loss: 3.735534191131592, acc: 0.31578946113586426)
[2025-02-17 17:47:32,527][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:32,754][root][INFO] - Training Epoch: 1/2, step 1395/53949 completed (loss: 3.889333486557007, acc: 0.2666666805744171)
[2025-02-17 17:47:32,892][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:33,108][root][INFO] - Training Epoch: 1/2, step 1396/53949 completed (loss: 3.5662031173706055, acc: 0.5384615659713745)
[2025-02-17 17:47:33,262][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:33,485][root][INFO] - Training Epoch: 1/2, step 1397/53949 completed (loss: 3.4493322372436523, acc: 0.2954545319080353)
[2025-02-17 17:47:33,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:33,844][root][INFO] - Training Epoch: 1/2, step 1398/53949 completed (loss: 3.3503975868225098, acc: 0.3913043439388275)
[2025-02-17 17:47:34,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:34,234][root][INFO] - Training Epoch: 1/2, step 1399/53949 completed (loss: 3.380629301071167, acc: 0.28125)
[2025-02-17 17:47:34,407][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:34,645][root][INFO] - Training Epoch: 1/2, step 1400/53949 completed (loss: 3.3701531887054443, acc: 0.34375)
[2025-02-17 17:47:34,833][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:35,059][root][INFO] - Training Epoch: 1/2, step 1401/53949 completed (loss: 3.6121413707733154, acc: 0.29032257199287415)
[2025-02-17 17:47:35,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:35,439][root][INFO] - Training Epoch: 1/2, step 1402/53949 completed (loss: 2.9274260997772217, acc: 0.31578946113586426)
[2025-02-17 17:47:35,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:35,891][root][INFO] - Training Epoch: 1/2, step 1403/53949 completed (loss: 3.058568000793457, acc: 0.380952388048172)
[2025-02-17 17:47:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:36,337][root][INFO] - Training Epoch: 1/2, step 1404/53949 completed (loss: 0.10522639751434326, acc: 1.0)
[2025-02-17 17:47:36,517][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:36,754][root][INFO] - Training Epoch: 1/2, step 1405/53949 completed (loss: 4.027528762817383, acc: 0.260869562625885)
[2025-02-17 17:47:36,943][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:37,174][root][INFO] - Training Epoch: 1/2, step 1406/53949 completed (loss: 3.5160908699035645, acc: 0.24137930572032928)
[2025-02-17 17:47:37,327][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:37,558][root][INFO] - Training Epoch: 1/2, step 1407/53949 completed (loss: 3.437732219696045, acc: 0.3103448152542114)
[2025-02-17 17:47:37,765][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:37,992][root][INFO] - Training Epoch: 1/2, step 1408/53949 completed (loss: 3.7206740379333496, acc: 0.20454545319080353)
[2025-02-17 17:47:38,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:38,352][root][INFO] - Training Epoch: 1/2, step 1409/53949 completed (loss: 3.110947847366333, acc: 0.25806450843811035)
[2025-02-17 17:47:38,581][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:38,815][root][INFO] - Training Epoch: 1/2, step 1410/53949 completed (loss: 4.182568073272705, acc: 0.2549019753932953)
[2025-02-17 17:47:39,010][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:39,242][root][INFO] - Training Epoch: 1/2, step 1411/53949 completed (loss: 3.0973360538482666, acc: 0.2916666567325592)
[2025-02-17 17:47:39,452][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:39,687][root][INFO] - Training Epoch: 1/2, step 1412/53949 completed (loss: 1.7134287357330322, acc: 0.5714285969734192)
[2025-02-17 17:47:39,884][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:40,124][root][INFO] - Training Epoch: 1/2, step 1413/53949 completed (loss: 3.2284419536590576, acc: 0.5625)
[2025-02-17 17:47:40,296][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:40,527][root][INFO] - Training Epoch: 1/2, step 1414/53949 completed (loss: 2.9176511764526367, acc: 0.40909090638160706)
[2025-02-17 17:47:40,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:40,940][root][INFO] - Training Epoch: 1/2, step 1415/53949 completed (loss: 3.7431633472442627, acc: 0.2195121943950653)
[2025-02-17 17:47:41,075][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:41,292][root][INFO] - Training Epoch: 1/2, step 1416/53949 completed (loss: 3.1956725120544434, acc: 0.4000000059604645)
[2025-02-17 17:47:41,435][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:41,661][root][INFO] - Training Epoch: 1/2, step 1417/53949 completed (loss: 3.176280975341797, acc: 0.3235294222831726)
[2025-02-17 17:47:41,809][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:42,031][root][INFO] - Training Epoch: 1/2, step 1418/53949 completed (loss: 2.8496642112731934, acc: 0.4615384638309479)
[2025-02-17 17:47:42,190][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:42,432][root][INFO] - Training Epoch: 1/2, step 1419/53949 completed (loss: 5.665200710296631, acc: 0.21052631735801697)
[2025-02-17 17:47:42,610][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:42,832][root][INFO] - Training Epoch: 1/2, step 1420/53949 completed (loss: 2.789996385574341, acc: 0.3199999928474426)
[2025-02-17 17:47:42,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:43,209][root][INFO] - Training Epoch: 1/2, step 1421/53949 completed (loss: 3.49007248878479, acc: 0.2857142984867096)
[2025-02-17 17:47:43,372][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:43,659][root][INFO] - Training Epoch: 1/2, step 1422/53949 completed (loss: 2.262357473373413, acc: 0.5)
[2025-02-17 17:47:43,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:44,110][root][INFO] - Training Epoch: 1/2, step 1423/53949 completed (loss: 2.0711209774017334, acc: 0.5714285969734192)
[2025-02-17 17:47:44,323][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:44,545][root][INFO] - Training Epoch: 1/2, step 1424/53949 completed (loss: 3.4576785564422607, acc: 0.3870967626571655)
[2025-02-17 17:47:44,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:44,984][root][INFO] - Training Epoch: 1/2, step 1425/53949 completed (loss: 4.079570293426514, acc: 0.20000000298023224)
[2025-02-17 17:47:45,145][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:45,369][root][INFO] - Training Epoch: 1/2, step 1426/53949 completed (loss: 3.712956190109253, acc: 0.29629629850387573)
[2025-02-17 17:47:45,534][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:45,758][root][INFO] - Training Epoch: 1/2, step 1427/53949 completed (loss: 3.4352915287017822, acc: 0.375)
[2025-02-17 17:47:45,914][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:46,181][root][INFO] - Training Epoch: 1/2, step 1428/53949 completed (loss: 0.008439194411039352, acc: 1.0)
[2025-02-17 17:47:46,353][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:46,581][root][INFO] - Training Epoch: 1/2, step 1429/53949 completed (loss: 4.464327812194824, acc: 0.1666666716337204)
[2025-02-17 17:47:46,796][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:47,023][root][INFO] - Training Epoch: 1/2, step 1430/53949 completed (loss: 2.8405604362487793, acc: 0.3333333432674408)
[2025-02-17 17:47:47,179][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:47,407][root][INFO] - Training Epoch: 1/2, step 1431/53949 completed (loss: 3.3567631244659424, acc: 0.29629629850387573)
[2025-02-17 17:47:47,566][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:47,833][root][INFO] - Training Epoch: 1/2, step 1432/53949 completed (loss: 1.0613185167312622, acc: 0.75)
[2025-02-17 17:47:48,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:48,234][root][INFO] - Training Epoch: 1/2, step 1433/53949 completed (loss: 1.0672370195388794, acc: 0.6666666865348816)
[2025-02-17 17:47:48,369][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:48,588][root][INFO] - Training Epoch: 1/2, step 1434/53949 completed (loss: 2.7948203086853027, acc: 0.4000000059604645)
[2025-02-17 17:47:48,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:48,940][root][INFO] - Training Epoch: 1/2, step 1435/53949 completed (loss: 2.5277178287506104, acc: 0.4444444477558136)
[2025-02-17 17:47:49,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:49,301][root][INFO] - Training Epoch: 1/2, step 1436/53949 completed (loss: 3.8590149879455566, acc: 0.1875)
[2025-02-17 17:47:49,472][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:49,711][root][INFO] - Training Epoch: 1/2, step 1437/53949 completed (loss: 3.607146978378296, acc: 0.4545454680919647)
[2025-02-17 17:47:49,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:50,074][root][INFO] - Training Epoch: 1/2, step 1438/53949 completed (loss: 1.5081510543823242, acc: 0.4166666567325592)
[2025-02-17 17:47:50,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:50,495][root][INFO] - Training Epoch: 1/2, step 1439/53949 completed (loss: 4.086231708526611, acc: 0.19354838132858276)
[2025-02-17 17:47:50,689][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:50,917][root][INFO] - Training Epoch: 1/2, step 1440/53949 completed (loss: 1.737788438796997, acc: 0.75)
[2025-02-17 17:47:51,056][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:51,277][root][INFO] - Training Epoch: 1/2, step 1441/53949 completed (loss: 3.053891658782959, acc: 0.27272728085517883)
[2025-02-17 17:47:51,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:51,632][root][INFO] - Training Epoch: 1/2, step 1442/53949 completed (loss: 2.683955669403076, acc: 0.4375)
[2025-02-17 17:47:51,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:52,041][root][INFO] - Training Epoch: 1/2, step 1443/53949 completed (loss: 3.926586627960205, acc: 0.2666666805744171)
[2025-02-17 17:47:52,226][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:52,442][root][INFO] - Training Epoch: 1/2, step 1444/53949 completed (loss: 4.292183876037598, acc: 0.17499999701976776)
[2025-02-17 17:47:52,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:52,807][root][INFO] - Training Epoch: 1/2, step 1445/53949 completed (loss: 4.237905502319336, acc: 0.2777777910232544)
[2025-02-17 17:47:52,942][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:53,156][root][INFO] - Training Epoch: 1/2, step 1446/53949 completed (loss: 2.0732359886169434, acc: 0.6153846383094788)
[2025-02-17 17:47:53,290][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:53,503][root][INFO] - Training Epoch: 1/2, step 1447/53949 completed (loss: 2.0244224071502686, acc: 0.75)
[2025-02-17 17:47:53,636][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:53,851][root][INFO] - Training Epoch: 1/2, step 1448/53949 completed (loss: 2.7414681911468506, acc: 0.3684210479259491)
[2025-02-17 17:47:54,040][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:54,225][root][INFO] - Training Epoch: 1/2, step 1449/53949 completed (loss: 2.7674877643585205, acc: 0.4615384638309479)
[2025-02-17 17:47:54,405][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:54,638][root][INFO] - Training Epoch: 1/2, step 1450/53949 completed (loss: 0.010801805183291435, acc: 1.0)
[2025-02-17 17:47:54,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:54,994][root][INFO] - Training Epoch: 1/2, step 1451/53949 completed (loss: 2.538850784301758, acc: 0.4736842215061188)
[2025-02-17 17:47:55,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:55,398][root][INFO] - Training Epoch: 1/2, step 1452/53949 completed (loss: 3.437819480895996, acc: 0.3478260934352875)
[2025-02-17 17:47:55,554][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:55,778][root][INFO] - Training Epoch: 1/2, step 1453/53949 completed (loss: 1.7634261846542358, acc: 0.6000000238418579)
[2025-02-17 17:47:55,969][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:56,203][root][INFO] - Training Epoch: 1/2, step 1454/53949 completed (loss: 0.07458925992250443, acc: 1.0)
[2025-02-17 17:47:56,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:56,582][root][INFO] - Training Epoch: 1/2, step 1455/53949 completed (loss: 0.11097027361392975, acc: 1.0)
[2025-02-17 17:47:56,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:57,006][root][INFO] - Training Epoch: 1/2, step 1456/53949 completed (loss: 1.148185133934021, acc: 0.6666666865348816)
[2025-02-17 17:47:57,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:57,389][root][INFO] - Training Epoch: 1/2, step 1457/53949 completed (loss: 3.106901168823242, acc: 0.3529411852359772)
[2025-02-17 17:47:57,526][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:57,745][root][INFO] - Training Epoch: 1/2, step 1458/53949 completed (loss: 4.049312114715576, acc: 0.2666666805744171)
[2025-02-17 17:47:57,944][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:58,170][root][INFO] - Training Epoch: 1/2, step 1459/53949 completed (loss: 2.6609785556793213, acc: 0.4444444477558136)
[2025-02-17 17:47:58,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:58,543][root][INFO] - Training Epoch: 1/2, step 1460/53949 completed (loss: 2.3103761672973633, acc: 0.3076923191547394)
[2025-02-17 17:47:58,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:58,903][root][INFO] - Training Epoch: 1/2, step 1461/53949 completed (loss: 3.7047066688537598, acc: 0.34210526943206787)
[2025-02-17 17:47:59,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:59,316][root][INFO] - Training Epoch: 1/2, step 1462/53949 completed (loss: 3.5643980503082275, acc: 0.3125)
[2025-02-17 17:47:59,505][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:47:59,746][root][INFO] - Training Epoch: 1/2, step 1463/53949 completed (loss: 2.8115575313568115, acc: 0.4285714328289032)
[2025-02-17 17:47:59,903][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:00,122][root][INFO] - Training Epoch: 1/2, step 1464/53949 completed (loss: 1.6611192226409912, acc: 0.699999988079071)
[2025-02-17 17:48:00,260][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:00,482][root][INFO] - Training Epoch: 1/2, step 1465/53949 completed (loss: 3.0586483478546143, acc: 0.375)
[2025-02-17 17:48:00,692][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:00,937][root][INFO] - Training Epoch: 1/2, step 1466/53949 completed (loss: 3.9379982948303223, acc: 0.36000001430511475)
[2025-02-17 17:48:01,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:01,353][root][INFO] - Training Epoch: 1/2, step 1467/53949 completed (loss: 3.383960008621216, acc: 0.25925925374031067)
[2025-02-17 17:48:01,502][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:01,727][root][INFO] - Training Epoch: 1/2, step 1468/53949 completed (loss: 2.770385980606079, acc: 0.4166666567325592)
[2025-02-17 17:48:01,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:02,127][root][INFO] - Training Epoch: 1/2, step 1469/53949 completed (loss: 3.6267876625061035, acc: 0.2181818187236786)
[2025-02-17 17:48:02,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:02,526][root][INFO] - Training Epoch: 1/2, step 1470/53949 completed (loss: 4.321582317352295, acc: 0.25)
[2025-02-17 17:48:02,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:02,891][root][INFO] - Training Epoch: 1/2, step 1471/53949 completed (loss: 3.441608190536499, acc: 0.3076923191547394)
[2025-02-17 17:48:03,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:03,315][root][INFO] - Training Epoch: 1/2, step 1472/53949 completed (loss: 3.365934133529663, acc: 0.3076923191547394)
[2025-02-17 17:48:03,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:03,745][root][INFO] - Training Epoch: 1/2, step 1473/53949 completed (loss: 2.664249897003174, acc: 0.4000000059604645)
[2025-02-17 17:48:03,876][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:04,102][root][INFO] - Training Epoch: 1/2, step 1474/53949 completed (loss: 4.640660285949707, acc: 0.26923078298568726)
[2025-02-17 17:48:04,288][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:04,522][root][INFO] - Training Epoch: 1/2, step 1475/53949 completed (loss: 3.050629138946533, acc: 0.4615384638309479)
[2025-02-17 17:48:04,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:04,896][root][INFO] - Training Epoch: 1/2, step 1476/53949 completed (loss: 3.937638282775879, acc: 0.3888888955116272)
[2025-02-17 17:48:05,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:05,254][root][INFO] - Training Epoch: 1/2, step 1477/53949 completed (loss: 2.5249428749084473, acc: 0.5)
[2025-02-17 17:48:05,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:05,612][root][INFO] - Training Epoch: 1/2, step 1478/53949 completed (loss: 3.2974836826324463, acc: 0.25)
[2025-02-17 17:48:05,777][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:05,988][root][INFO] - Training Epoch: 1/2, step 1479/53949 completed (loss: 3.4427764415740967, acc: 0.3333333432674408)
[2025-02-17 17:48:06,146][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:06,364][root][INFO] - Training Epoch: 1/2, step 1480/53949 completed (loss: 3.3017418384552, acc: 0.2666666805744171)
[2025-02-17 17:48:06,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:06,764][root][INFO] - Training Epoch: 1/2, step 1481/53949 completed (loss: 2.4981017112731934, acc: 0.48275861144065857)
[2025-02-17 17:48:06,895][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:07,126][root][INFO] - Training Epoch: 1/2, step 1482/53949 completed (loss: 3.032238483428955, acc: 0.4000000059604645)
[2025-02-17 17:48:07,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:07,528][root][INFO] - Training Epoch: 1/2, step 1483/53949 completed (loss: 3.170450210571289, acc: 0.2800000011920929)
[2025-02-17 17:48:07,669][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:07,897][root][INFO] - Training Epoch: 1/2, step 1484/53949 completed (loss: 2.5464870929718018, acc: 0.3125)
[2025-02-17 17:48:08,100][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:08,336][root][INFO] - Training Epoch: 1/2, step 1485/53949 completed (loss: 4.058917999267578, acc: 0.27586206793785095)
[2025-02-17 17:48:08,490][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:08,712][root][INFO] - Training Epoch: 1/2, step 1486/53949 completed (loss: 9.656693458557129, acc: 0.10000000149011612)
[2025-02-17 17:48:08,858][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:09,082][root][INFO] - Training Epoch: 1/2, step 1487/53949 completed (loss: 9.022165298461914, acc: 0.0833333358168602)
[2025-02-17 17:48:09,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:09,466][root][INFO] - Training Epoch: 1/2, step 1488/53949 completed (loss: 10.507113456726074, acc: 0.0)
[2025-02-17 17:48:09,645][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:09,867][root][INFO] - Training Epoch: 1/2, step 1489/53949 completed (loss: 8.696756362915039, acc: 0.0)
[2025-02-17 17:48:10,011][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:10,235][root][INFO] - Training Epoch: 1/2, step 1490/53949 completed (loss: 8.756468772888184, acc: 0.0)
[2025-02-17 17:48:10,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:10,651][root][INFO] - Training Epoch: 1/2, step 1491/53949 completed (loss: 9.736639976501465, acc: 0.0)
[2025-02-17 17:48:10,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:11,041][root][INFO] - Training Epoch: 1/2, step 1492/53949 completed (loss: 8.821081161499023, acc: 0.06666667014360428)
[2025-02-17 17:48:11,174][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:11,389][root][INFO] - Training Epoch: 1/2, step 1493/53949 completed (loss: 11.507852554321289, acc: 0.0)
[2025-02-17 17:48:11,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:11,745][root][INFO] - Training Epoch: 1/2, step 1494/53949 completed (loss: 8.250067710876465, acc: 0.0833333358168602)
[2025-02-17 17:48:11,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:12,092][root][INFO] - Training Epoch: 1/2, step 1495/53949 completed (loss: 9.616348266601562, acc: 0.0)
[2025-02-17 17:48:12,294][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:12,517][root][INFO] - Training Epoch: 1/2, step 1496/53949 completed (loss: 7.101279258728027, acc: 0.03921568766236305)
[2025-02-17 17:48:12,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:12,880][root][INFO] - Training Epoch: 1/2, step 1497/53949 completed (loss: 9.170246124267578, acc: 0.095238097012043)
[2025-02-17 17:48:13,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:13,253][root][INFO] - Training Epoch: 1/2, step 1498/53949 completed (loss: 7.087766170501709, acc: 0.0714285746216774)
[2025-02-17 17:48:13,422][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:13,654][root][INFO] - Training Epoch: 1/2, step 1499/53949 completed (loss: 7.223267078399658, acc: 0.125)
[2025-02-17 17:48:13,830][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:14,051][root][INFO] - Training Epoch: 1/2, step 1500/53949 completed (loss: 6.279983043670654, acc: 0.25)
[2025-02-17 17:48:14,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:14,410][root][INFO] - Training Epoch: 1/2, step 1501/53949 completed (loss: 3.6784591674804688, acc: 0.6666666865348816)
[2025-02-17 17:48:14,640][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:14,865][root][INFO] - Training Epoch: 1/2, step 1502/53949 completed (loss: 6.942554473876953, acc: 0.032258063554763794)
[2025-02-17 17:48:15,053][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:15,313][root][INFO] - Training Epoch: 1/2, step 1503/53949 completed (loss: 6.189375877380371, acc: 0.06896551698446274)
[2025-02-17 17:48:15,499][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:15,718][root][INFO] - Training Epoch: 1/2, step 1504/53949 completed (loss: 7.11939811706543, acc: 0.06896551698446274)
[2025-02-17 17:48:15,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:16,099][root][INFO] - Training Epoch: 1/2, step 1505/53949 completed (loss: 7.547430992126465, acc: 0.0476190485060215)
[2025-02-17 17:48:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:16,491][root][INFO] - Training Epoch: 1/2, step 1506/53949 completed (loss: 6.091833114624023, acc: 0.0625)
[2025-02-17 17:48:16,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:16,908][root][INFO] - Training Epoch: 1/2, step 1507/53949 completed (loss: 3.9494311809539795, acc: 0.4000000059604645)
[2025-02-17 17:48:17,089][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:17,315][root][INFO] - Training Epoch: 1/2, step 1508/53949 completed (loss: 6.151704788208008, acc: 0.06976744532585144)
[2025-02-17 17:48:17,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:17,666][root][INFO] - Training Epoch: 1/2, step 1509/53949 completed (loss: 6.664947509765625, acc: 0.08695652335882187)
[2025-02-17 17:48:17,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:18,108][root][INFO] - Training Epoch: 1/2, step 1510/53949 completed (loss: 5.893113613128662, acc: 0.15789473056793213)
[2025-02-17 17:48:18,264][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:18,450][root][INFO] - Training Epoch: 1/2, step 1511/53949 completed (loss: 5.967247486114502, acc: 0.1666666716337204)
[2025-02-17 17:48:18,583][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:18,795][root][INFO] - Training Epoch: 1/2, step 1512/53949 completed (loss: 3.4774842262268066, acc: 0.5)
[2025-02-17 17:48:19,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:19,257][root][INFO] - Training Epoch: 1/2, step 1513/53949 completed (loss: 6.115029335021973, acc: 0.0476190485060215)
[2025-02-17 17:48:19,414][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:19,646][root][INFO] - Training Epoch: 1/2, step 1514/53949 completed (loss: 6.348258972167969, acc: 0.02857142873108387)
[2025-02-17 17:48:19,836][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:20,071][root][INFO] - Training Epoch: 1/2, step 1515/53949 completed (loss: 6.7999677658081055, acc: 0.01923076994717121)
[2025-02-17 17:48:20,208][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:20,415][root][INFO] - Training Epoch: 1/2, step 1516/53949 completed (loss: 4.402975559234619, acc: 0.4285714328289032)
[2025-02-17 17:48:20,609][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:20,836][root][INFO] - Training Epoch: 1/2, step 1517/53949 completed (loss: 4.633273601531982, acc: 0.1111111119389534)
[2025-02-17 17:48:21,006][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:21,267][root][INFO] - Training Epoch: 1/2, step 1518/53949 completed (loss: 5.2807297706604, acc: 0.125)
[2025-02-17 17:48:21,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:21,669][root][INFO] - Training Epoch: 1/2, step 1519/53949 completed (loss: 3.632345676422119, acc: 0.4000000059604645)
[2025-02-17 17:48:21,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:22,037][root][INFO] - Training Epoch: 1/2, step 1520/53949 completed (loss: 6.583016872406006, acc: 0.03921568766236305)
[2025-02-17 17:48:22,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:22,454][root][INFO] - Training Epoch: 1/2, step 1521/53949 completed (loss: 5.434993743896484, acc: 0.10526315867900848)
[2025-02-17 17:48:22,627][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:22,848][root][INFO] - Training Epoch: 1/2, step 1522/53949 completed (loss: 6.672861099243164, acc: 0.1764705926179886)
[2025-02-17 17:48:22,991][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:23,222][root][INFO] - Training Epoch: 1/2, step 1523/53949 completed (loss: 5.440926551818848, acc: 0.1428571492433548)
[2025-02-17 17:48:23,361][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:23,578][root][INFO] - Training Epoch: 1/2, step 1524/53949 completed (loss: 5.911981105804443, acc: 0.06060606241226196)
[2025-02-17 17:48:23,775][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:24,013][root][INFO] - Training Epoch: 1/2, step 1525/53949 completed (loss: 5.076019287109375, acc: 0.1875)
[2025-02-17 17:48:24,176][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:24,397][root][INFO] - Training Epoch: 1/2, step 1526/53949 completed (loss: 5.6378374099731445, acc: 0.15000000596046448)
[2025-02-17 17:48:24,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:24,780][root][INFO] - Training Epoch: 1/2, step 1527/53949 completed (loss: 6.59388542175293, acc: 0.125)
[2025-02-17 17:48:24,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:25,142][root][INFO] - Training Epoch: 1/2, step 1528/53949 completed (loss: 5.269134521484375, acc: 0.1538461595773697)
[2025-02-17 17:48:25,284][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:25,506][root][INFO] - Training Epoch: 1/2, step 1529/53949 completed (loss: 5.015315532684326, acc: 0.1818181872367859)
[2025-02-17 17:48:25,661][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:25,887][root][INFO] - Training Epoch: 1/2, step 1530/53949 completed (loss: 3.5724194049835205, acc: 0.4285714328289032)
[2025-02-17 17:48:26,027][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:26,241][root][INFO] - Training Epoch: 1/2, step 1531/53949 completed (loss: 5.838763236999512, acc: 0.02500000037252903)
[2025-02-17 17:48:26,375][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:26,623][root][INFO] - Training Epoch: 1/2, step 1532/53949 completed (loss: 2.5993871688842773, acc: 0.6000000238418579)
[2025-02-17 17:48:26,844][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:27,084][root][INFO] - Training Epoch: 1/2, step 1533/53949 completed (loss: 4.706160068511963, acc: 0.2222222238779068)
[2025-02-17 17:48:27,316][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:27,535][root][INFO] - Training Epoch: 1/2, step 1534/53949 completed (loss: 6.402712821960449, acc: 0.04918032884597778)
[2025-02-17 17:48:27,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:27,885][root][INFO] - Training Epoch: 1/2, step 1535/53949 completed (loss: 6.40149450302124, acc: 0.07407407462596893)
[2025-02-17 17:48:28,019][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:28,239][root][INFO] - Training Epoch: 1/2, step 1536/53949 completed (loss: 5.36432409286499, acc: 0.1666666716337204)
[2025-02-17 17:48:28,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:28,647][root][INFO] - Training Epoch: 1/2, step 1537/53949 completed (loss: 6.093093395233154, acc: 0.04651162773370743)
[2025-02-17 17:48:28,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:29,050][root][INFO] - Training Epoch: 1/2, step 1538/53949 completed (loss: 6.1831536293029785, acc: 0.1538461595773697)
[2025-02-17 17:48:29,235][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:29,473][root][INFO] - Training Epoch: 1/2, step 1539/53949 completed (loss: 5.128852844238281, acc: 0.13333334028720856)
[2025-02-17 17:48:29,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:29,846][root][INFO] - Training Epoch: 1/2, step 1540/53949 completed (loss: 5.32170295715332, acc: 0.27272728085517883)
[2025-02-17 17:48:30,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:30,275][root][INFO] - Training Epoch: 1/2, step 1541/53949 completed (loss: 4.572436332702637, acc: 0.1875)
[2025-02-17 17:48:30,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:30,694][root][INFO] - Training Epoch: 1/2, step 1542/53949 completed (loss: 6.098178863525391, acc: 0.0833333358168602)
[2025-02-17 17:48:30,864][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:31,083][root][INFO] - Training Epoch: 1/2, step 1543/53949 completed (loss: 6.237249851226807, acc: 0.05714285746216774)
[2025-02-17 17:48:31,236][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:31,462][root][INFO] - Training Epoch: 1/2, step 1544/53949 completed (loss: 5.323869705200195, acc: 0.13333334028720856)
[2025-02-17 17:48:31,670][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:31,908][root][INFO] - Training Epoch: 1/2, step 1545/53949 completed (loss: 4.443699359893799, acc: 0.1538461595773697)
[2025-02-17 17:48:32,095][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:32,372][root][INFO] - Training Epoch: 1/2, step 1546/53949 completed (loss: 6.463064670562744, acc: 0.11627907305955887)
[2025-02-17 17:48:32,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:32,769][root][INFO] - Training Epoch: 1/2, step 1547/53949 completed (loss: 6.026770114898682, acc: 0.02500000037252903)
[2025-02-17 17:48:32,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:33,120][root][INFO] - Training Epoch: 1/2, step 1548/53949 completed (loss: 4.85589075088501, acc: 0.2666666805744171)
[2025-02-17 17:48:33,268][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:33,484][root][INFO] - Training Epoch: 1/2, step 1549/53949 completed (loss: 2.796229362487793, acc: 0.5)
[2025-02-17 17:48:33,628][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:33,860][root][INFO] - Training Epoch: 1/2, step 1550/53949 completed (loss: 5.552440643310547, acc: 0.03703703731298447)
[2025-02-17 17:48:34,032][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:34,251][root][INFO] - Training Epoch: 1/2, step 1551/53949 completed (loss: 3.518881320953369, acc: 0.30000001192092896)
[2025-02-17 17:48:34,409][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:34,592][root][INFO] - Training Epoch: 1/2, step 1552/53949 completed (loss: 5.656572341918945, acc: 0.09375)
[2025-02-17 17:48:34,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:35,022][root][INFO] - Training Epoch: 1/2, step 1553/53949 completed (loss: 5.536721229553223, acc: 0.09375)
[2025-02-17 17:48:35,199][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:35,450][root][INFO] - Training Epoch: 1/2, step 1554/53949 completed (loss: 5.645266532897949, acc: 0.1428571492433548)
[2025-02-17 17:48:35,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:35,818][root][INFO] - Training Epoch: 1/2, step 1555/53949 completed (loss: 5.578391075134277, acc: 0.07999999821186066)
[2025-02-17 17:48:35,973][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:36,204][root][INFO] - Training Epoch: 1/2, step 1556/53949 completed (loss: 5.685889720916748, acc: 0.13636364042758942)
[2025-02-17 17:48:36,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:36,580][root][INFO] - Training Epoch: 1/2, step 1557/53949 completed (loss: 4.991933822631836, acc: 0.1666666716337204)
[2025-02-17 17:48:36,762][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:36,984][root][INFO] - Training Epoch: 1/2, step 1558/53949 completed (loss: 6.318281173706055, acc: 0.07692307978868484)
[2025-02-17 17:48:37,117][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:37,357][root][INFO] - Training Epoch: 1/2, step 1559/53949 completed (loss: 5.934858322143555, acc: 0.054054055362939835)
[2025-02-17 17:48:37,572][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:37,804][root][INFO] - Training Epoch: 1/2, step 1560/53949 completed (loss: 3.6532983779907227, acc: 0.3076923191547394)
[2025-02-17 17:48:37,972][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:38,210][root][INFO] - Training Epoch: 1/2, step 1561/53949 completed (loss: 6.065640926361084, acc: 0.4000000059604645)
[2025-02-17 17:48:38,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:38,652][root][INFO] - Training Epoch: 1/2, step 1562/53949 completed (loss: 5.820170879364014, acc: 0.13636364042758942)
[2025-02-17 17:48:38,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:39,027][root][INFO] - Training Epoch: 1/2, step 1563/53949 completed (loss: 5.557063579559326, acc: 0.0)
[2025-02-17 17:48:39,172][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:39,397][root][INFO] - Training Epoch: 1/2, step 1564/53949 completed (loss: 5.307786464691162, acc: 0.08695652335882187)
[2025-02-17 17:48:39,596][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:39,833][root][INFO] - Training Epoch: 1/2, step 1565/53949 completed (loss: 6.892275333404541, acc: 0.03125)
[2025-02-17 17:48:40,026][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:40,253][root][INFO] - Training Epoch: 1/2, step 1566/53949 completed (loss: 3.899852752685547, acc: 0.375)
[2025-02-17 17:48:40,398][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:40,623][root][INFO] - Training Epoch: 1/2, step 1567/53949 completed (loss: 5.27987003326416, acc: 0.12903225421905518)
[2025-02-17 17:48:40,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:40,973][root][INFO] - Training Epoch: 1/2, step 1568/53949 completed (loss: 5.704178333282471, acc: 0.17391304671764374)
[2025-02-17 17:48:41,143][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:41,399][root][INFO] - Training Epoch: 1/2, step 1569/53949 completed (loss: 4.237048149108887, acc: 0.2142857164144516)
[2025-02-17 17:48:41,597][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:41,817][root][INFO] - Training Epoch: 1/2, step 1570/53949 completed (loss: 5.918827056884766, acc: 0.1875)
[2025-02-17 17:48:42,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:42,224][root][INFO] - Training Epoch: 1/2, step 1571/53949 completed (loss: 5.752045631408691, acc: 0.036363635212183)
[2025-02-17 17:48:42,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:42,616][root][INFO] - Training Epoch: 1/2, step 1572/53949 completed (loss: 4.515030860900879, acc: 0.2777777910232544)
[2025-02-17 17:48:42,819][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:43,046][root][INFO] - Training Epoch: 1/2, step 1573/53949 completed (loss: 3.2768993377685547, acc: 0.5)
[2025-02-17 17:48:43,211][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:43,458][root][INFO] - Training Epoch: 1/2, step 1574/53949 completed (loss: 5.9515061378479, acc: 0.1428571492433548)
[2025-02-17 17:48:43,621][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:43,842][root][INFO] - Training Epoch: 1/2, step 1575/53949 completed (loss: 6.251150608062744, acc: 0.08695652335882187)
[2025-02-17 17:48:43,977][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:44,203][root][INFO] - Training Epoch: 1/2, step 1576/53949 completed (loss: 4.983009338378906, acc: 0.07999999821186066)
[2025-02-17 17:48:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:44,569][root][INFO] - Training Epoch: 1/2, step 1577/53949 completed (loss: 0.4249195456504822, acc: 1.0)
[2025-02-17 17:48:44,768][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:45,023][root][INFO] - Training Epoch: 1/2, step 1578/53949 completed (loss: 6.321330547332764, acc: 0.056603774428367615)
[2025-02-17 17:48:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:45,414][root][INFO] - Training Epoch: 1/2, step 1579/53949 completed (loss: 5.021607875823975, acc: 0.15789473056793213)
[2025-02-17 17:48:45,571][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:45,848][root][INFO] - Training Epoch: 1/2, step 1580/53949 completed (loss: 4.542926788330078, acc: 0.08695652335882187)
[2025-02-17 17:48:46,070][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:46,298][root][INFO] - Training Epoch: 1/2, step 1581/53949 completed (loss: 4.879171371459961, acc: 0.12820513546466827)
[2025-02-17 17:48:46,501][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:46,732][root][INFO] - Training Epoch: 1/2, step 1582/53949 completed (loss: 5.526205539703369, acc: 0.11428571492433548)
[2025-02-17 17:48:46,875][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:47,104][root][INFO] - Training Epoch: 1/2, step 1583/53949 completed (loss: 4.790910243988037, acc: 0.25)
[2025-02-17 17:48:47,274][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:47,503][root][INFO] - Training Epoch: 1/2, step 1584/53949 completed (loss: 6.24229621887207, acc: 0.1818181872367859)
[2025-02-17 17:48:47,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:47,928][root][INFO] - Training Epoch: 1/2, step 1585/53949 completed (loss: 4.296170711517334, acc: 0.4285714328289032)
[2025-02-17 17:48:48,188][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:48,421][root][INFO] - Training Epoch: 1/2, step 1586/53949 completed (loss: 5.931512832641602, acc: 0.13636364042758942)
[2025-02-17 17:48:48,612][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:48,863][root][INFO] - Training Epoch: 1/2, step 1587/53949 completed (loss: 5.163096904754639, acc: 0.13333334028720856)
[2025-02-17 17:48:49,034][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:49,257][root][INFO] - Training Epoch: 1/2, step 1588/53949 completed (loss: 5.5251264572143555, acc: 0.04651162773370743)
[2025-02-17 17:48:49,397][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:49,622][root][INFO] - Training Epoch: 1/2, step 1589/53949 completed (loss: 5.732596397399902, acc: 0.10000000149011612)
[2025-02-17 17:48:49,803][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:50,022][root][INFO] - Training Epoch: 1/2, step 1590/53949 completed (loss: 3.453244209289551, acc: 0.5)
[2025-02-17 17:48:50,183][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:50,405][root][INFO] - Training Epoch: 1/2, step 1591/53949 completed (loss: 4.536393165588379, acc: 0.23076923191547394)
[2025-02-17 17:48:50,586][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:50,832][root][INFO] - Training Epoch: 1/2, step 1592/53949 completed (loss: 4.446852684020996, acc: 0.3076923191547394)
[2025-02-17 17:48:51,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:51,217][root][INFO] - Training Epoch: 1/2, step 1593/53949 completed (loss: 4.318934440612793, acc: 0.27272728085517883)
[2025-02-17 17:48:51,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:51,552][root][INFO] - Training Epoch: 1/2, step 1594/53949 completed (loss: 6.138784408569336, acc: 0.027027027681469917)
[2025-02-17 17:48:51,682][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:51,894][root][INFO] - Training Epoch: 1/2, step 1595/53949 completed (loss: 0.8014695644378662, acc: 0.75)
[2025-02-17 17:48:52,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:52,247][root][INFO] - Training Epoch: 1/2, step 1596/53949 completed (loss: 4.511291980743408, acc: 0.25)
[2025-02-17 17:48:52,384][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:52,598][root][INFO] - Training Epoch: 1/2, step 1597/53949 completed (loss: 4.332263946533203, acc: 0.15789473056793213)
[2025-02-17 17:48:52,740][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:52,963][root][INFO] - Training Epoch: 1/2, step 1598/53949 completed (loss: 1.2251170873641968, acc: 0.75)
[2025-02-17 17:48:53,155][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:53,379][root][INFO] - Training Epoch: 1/2, step 1599/53949 completed (loss: 3.927889347076416, acc: 0.23076923191547394)
[2025-02-17 17:48:53,549][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:53,769][root][INFO] - Training Epoch: 1/2, step 1600/53949 completed (loss: 5.678500652313232, acc: 0.10256410390138626)
[2025-02-17 17:48:53,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:54,186][root][INFO] - Training Epoch: 1/2, step 1601/53949 completed (loss: 5.716183185577393, acc: 0.0625)
[2025-02-17 17:48:54,330][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:54,554][root][INFO] - Training Epoch: 1/2, step 1602/53949 completed (loss: 1.26095712184906, acc: 1.0)
[2025-02-17 17:48:54,724][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:54,938][root][INFO] - Training Epoch: 1/2, step 1603/53949 completed (loss: 1.1150023937225342, acc: 0.75)
[2025-02-17 17:48:55,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:55,284][root][INFO] - Training Epoch: 1/2, step 1604/53949 completed (loss: 4.111441135406494, acc: 0.3333333432674408)
[2025-02-17 17:48:55,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:55,651][root][INFO] - Training Epoch: 1/2, step 1605/53949 completed (loss: 2.6663882732391357, acc: 0.4444444477558136)
[2025-02-17 17:48:55,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:55,996][root][INFO] - Training Epoch: 1/2, step 1606/53949 completed (loss: 4.24086856842041, acc: 0.25)
[2025-02-17 17:48:56,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:56,388][root][INFO] - Training Epoch: 1/2, step 1607/53949 completed (loss: 7.291182041168213, acc: 0.30000001192092896)
[2025-02-17 17:48:56,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:56,826][root][INFO] - Training Epoch: 1/2, step 1608/53949 completed (loss: 4.357173442840576, acc: 0.2142857164144516)
[2025-02-17 17:48:57,012][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:57,235][root][INFO] - Training Epoch: 1/2, step 1609/53949 completed (loss: 3.784996747970581, acc: 0.3333333432674408)
[2025-02-17 17:48:57,379][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:57,607][root][INFO] - Training Epoch: 1/2, step 1610/53949 completed (loss: 4.655033588409424, acc: 0.14814814925193787)
[2025-02-17 17:48:57,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:58,009][root][INFO] - Training Epoch: 1/2, step 1611/53949 completed (loss: 4.003741264343262, acc: 0.2857142984867096)
[2025-02-17 17:48:58,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:58,386][root][INFO] - Training Epoch: 1/2, step 1612/53949 completed (loss: 5.239598274230957, acc: 0.13793103396892548)
[2025-02-17 17:48:58,537][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:58,788][root][INFO] - Training Epoch: 1/2, step 1613/53949 completed (loss: 4.285548210144043, acc: 0.20000000298023224)
[2025-02-17 17:48:58,935][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:59,155][root][INFO] - Training Epoch: 1/2, step 1614/53949 completed (loss: 4.577864170074463, acc: 0.1875)
[2025-02-17 17:48:59,338][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:59,570][root][INFO] - Training Epoch: 1/2, step 1615/53949 completed (loss: 4.41110372543335, acc: 0.24137930572032928)
[2025-02-17 17:48:59,741][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:48:59,967][root][INFO] - Training Epoch: 1/2, step 1616/53949 completed (loss: 3.7055153846740723, acc: 0.4000000059604645)
[2025-02-17 17:49:00,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:00,353][root][INFO] - Training Epoch: 1/2, step 1617/53949 completed (loss: 5.087740898132324, acc: 0.1034482792019844)
[2025-02-17 17:49:00,487][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:00,699][root][INFO] - Training Epoch: 1/2, step 1618/53949 completed (loss: 4.027140140533447, acc: 0.27272728085517883)
[2025-02-17 17:49:00,839][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:01,064][root][INFO] - Training Epoch: 1/2, step 1619/53949 completed (loss: 5.902043342590332, acc: 0.0625)
[2025-02-17 17:49:01,197][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:01,417][root][INFO] - Training Epoch: 1/2, step 1620/53949 completed (loss: 2.009507894515991, acc: 0.800000011920929)
[2025-02-17 17:49:01,551][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:01,775][root][INFO] - Training Epoch: 1/2, step 1621/53949 completed (loss: 3.93056583404541, acc: 0.21739129722118378)
[2025-02-17 17:49:01,906][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:02,154][root][INFO] - Training Epoch: 1/2, step 1622/53949 completed (loss: 6.1715192794799805, acc: 0.06451612710952759)
[2025-02-17 17:49:02,347][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:02,574][root][INFO] - Training Epoch: 1/2, step 1623/53949 completed (loss: 5.383879661560059, acc: 0.15625)
[2025-02-17 17:49:02,725][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:02,947][root][INFO] - Training Epoch: 1/2, step 1624/53949 completed (loss: 4.797666072845459, acc: 0.1428571492433548)
[2025-02-17 17:49:03,090][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:03,287][root][INFO] - Training Epoch: 1/2, step 1625/53949 completed (loss: 3.230827808380127, acc: 0.30000001192092896)
[2025-02-17 17:49:03,420][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:03,642][root][INFO] - Training Epoch: 1/2, step 1626/53949 completed (loss: 5.134274959564209, acc: 0.27272728085517883)
[2025-02-17 17:49:03,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:04,029][root][INFO] - Training Epoch: 1/2, step 1627/53949 completed (loss: 4.124034404754639, acc: 0.3333333432674408)
[2025-02-17 17:49:04,162][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:04,382][root][INFO] - Training Epoch: 1/2, step 1628/53949 completed (loss: 5.454644203186035, acc: 0.190476194024086)
[2025-02-17 17:49:04,568][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:04,834][root][INFO] - Training Epoch: 1/2, step 1629/53949 completed (loss: 4.879589080810547, acc: 0.1090909093618393)
[2025-02-17 17:49:05,051][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:05,271][root][INFO] - Training Epoch: 1/2, step 1630/53949 completed (loss: 5.325274467468262, acc: 0.12121212482452393)
[2025-02-17 17:49:05,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:05,639][root][INFO] - Training Epoch: 1/2, step 1631/53949 completed (loss: 4.7941741943359375, acc: 0.15625)
[2025-02-17 17:49:05,820][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:06,054][root][INFO] - Training Epoch: 1/2, step 1632/53949 completed (loss: 5.160786151885986, acc: 0.2083333283662796)
[2025-02-17 17:49:06,202][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:06,423][root][INFO] - Training Epoch: 1/2, step 1633/53949 completed (loss: 2.224231719970703, acc: 0.5)
[2025-02-17 17:49:06,575][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:06,788][root][INFO] - Training Epoch: 1/2, step 1634/53949 completed (loss: 5.506629467010498, acc: 0.10000000149011612)
[2025-02-17 17:49:06,968][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:07,205][root][INFO] - Training Epoch: 1/2, step 1635/53949 completed (loss: 0.3516921103000641, acc: 1.0)
[2025-02-17 17:49:07,382][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:07,606][root][INFO] - Training Epoch: 1/2, step 1636/53949 completed (loss: 5.425120830535889, acc: 0.1111111119389534)
[2025-02-17 17:49:07,811][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:08,049][root][INFO] - Training Epoch: 1/2, step 1637/53949 completed (loss: 4.785027027130127, acc: 0.05263157933950424)
[2025-02-17 17:49:08,245][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:08,471][root][INFO] - Training Epoch: 1/2, step 1638/53949 completed (loss: 4.598970413208008, acc: 0.1621621549129486)
[2025-02-17 17:49:08,649][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:08,885][root][INFO] - Training Epoch: 1/2, step 1639/53949 completed (loss: 3.373006582260132, acc: 0.3333333432674408)
[2025-02-17 17:49:09,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:09,260][root][INFO] - Training Epoch: 1/2, step 1640/53949 completed (loss: 1.021218180656433, acc: 0.6666666865348816)
[2025-02-17 17:49:09,406][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:09,631][root][INFO] - Training Epoch: 1/2, step 1641/53949 completed (loss: 4.656106948852539, acc: 0.1388888955116272)
[2025-02-17 17:49:09,769][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:09,992][root][INFO] - Training Epoch: 1/2, step 1642/53949 completed (loss: 4.5498270988464355, acc: 0.260869562625885)
[2025-02-17 17:49:10,137][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:10,358][root][INFO] - Training Epoch: 1/2, step 1643/53949 completed (loss: 4.025292873382568, acc: 0.1428571492433548)
[2025-02-17 17:49:10,523][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:10,765][root][INFO] - Training Epoch: 1/2, step 1644/53949 completed (loss: 5.0832109451293945, acc: 0.20000000298023224)
[2025-02-17 17:49:11,016][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:11,243][root][INFO] - Training Epoch: 1/2, step 1645/53949 completed (loss: 5.552188873291016, acc: 0.0833333358168602)
[2025-02-17 17:49:11,413][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:11,626][root][INFO] - Training Epoch: 1/2, step 1646/53949 completed (loss: 5.5963850021362305, acc: 0.15217390656471252)
[2025-02-17 17:49:11,784][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:12,003][root][INFO] - Training Epoch: 1/2, step 1647/53949 completed (loss: 4.61582088470459, acc: 0.2571428716182709)
[2025-02-17 17:49:12,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:12,369][root][INFO] - Training Epoch: 1/2, step 1648/53949 completed (loss: 5.035624980926514, acc: 0.20000000298023224)
[2025-02-17 17:49:12,529][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:12,743][root][INFO] - Training Epoch: 1/2, step 1649/53949 completed (loss: 4.831259250640869, acc: 0.11538461595773697)
[2025-02-17 17:49:12,891][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:13,106][root][INFO] - Training Epoch: 1/2, step 1650/53949 completed (loss: 2.670766592025757, acc: 0.3333333432674408)
[2025-02-17 17:49:13,299][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:13,533][root][INFO] - Training Epoch: 1/2, step 1651/53949 completed (loss: 4.82225227355957, acc: 0.1111111119389534)
[2025-02-17 17:49:13,699][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:13,918][root][INFO] - Training Epoch: 1/2, step 1652/53949 completed (loss: 6.262750625610352, acc: 0.3333333432674408)
[2025-02-17 17:49:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:14,338][root][INFO] - Training Epoch: 1/2, step 1653/53949 completed (loss: 3.4869461059570312, acc: 0.2666666805744171)
[2025-02-17 17:49:14,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:14,711][root][INFO] - Training Epoch: 1/2, step 1654/53949 completed (loss: 4.558097839355469, acc: 0.10810811072587967)
[2025-02-17 17:49:14,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:15,081][root][INFO] - Training Epoch: 1/2, step 1655/53949 completed (loss: 3.3073196411132812, acc: 0.2800000011920929)
[2025-02-17 17:49:15,219][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:15,433][root][INFO] - Training Epoch: 1/2, step 1656/53949 completed (loss: 4.341479301452637, acc: 0.25806450843811035)
[2025-02-17 17:49:15,618][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:15,808][root][INFO] - Training Epoch: 1/2, step 1657/53949 completed (loss: 2.7925846576690674, acc: 0.38461539149284363)
[2025-02-17 17:49:15,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:16,173][root][INFO] - Training Epoch: 1/2, step 1658/53949 completed (loss: 4.409972667694092, acc: 0.20408163964748383)
[2025-02-17 17:49:16,310][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:16,533][root][INFO] - Training Epoch: 1/2, step 1659/53949 completed (loss: 2.2427120208740234, acc: 0.6000000238418579)
[2025-02-17 17:49:16,721][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:16,944][root][INFO] - Training Epoch: 1/2, step 1660/53949 completed (loss: 4.135110855102539, acc: 0.3333333432674408)
[2025-02-17 17:49:17,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:17,275][root][INFO] - Training Epoch: 1/2, step 1661/53949 completed (loss: 4.5195698738098145, acc: 0.1599999964237213)
[2025-02-17 17:49:17,440][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:17,673][root][INFO] - Training Epoch: 1/2, step 1662/53949 completed (loss: 3.8687140941619873, acc: 0.27272728085517883)
[2025-02-17 17:49:17,869][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:18,116][root][INFO] - Training Epoch: 1/2, step 1663/53949 completed (loss: 4.537112712860107, acc: 0.1428571492433548)
[2025-02-17 17:49:18,325][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:18,549][root][INFO] - Training Epoch: 1/2, step 1664/53949 completed (loss: 4.808199882507324, acc: 0.2750000059604645)
[2025-02-17 17:49:18,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:18,963][root][INFO] - Training Epoch: 1/2, step 1665/53949 completed (loss: 1.8586199283599854, acc: 0.5555555820465088)
[2025-02-17 17:49:19,153][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:19,382][root][INFO] - Training Epoch: 1/2, step 1666/53949 completed (loss: 3.726715087890625, acc: 0.24528302252292633)
[2025-02-17 17:49:19,536][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:19,760][root][INFO] - Training Epoch: 1/2, step 1667/53949 completed (loss: 3.8651819229125977, acc: 0.3333333432674408)
[2025-02-17 17:49:19,956][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:20,189][root][INFO] - Training Epoch: 1/2, step 1668/53949 completed (loss: 5.209386825561523, acc: 0.4375)
[2025-02-17 17:49:20,359][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:20,593][root][INFO] - Training Epoch: 1/2, step 1669/53949 completed (loss: 0.09780893474817276, acc: 1.0)
[2025-02-17 17:49:20,789][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:20,983][root][INFO] - Training Epoch: 1/2, step 1670/53949 completed (loss: 1.7970198392868042, acc: 0.5)
[2025-02-17 17:49:21,129][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:21,343][root][INFO] - Training Epoch: 1/2, step 1671/53949 completed (loss: 3.273902177810669, acc: 0.4545454680919647)
[2025-02-17 17:49:21,522][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:21,754][root][INFO] - Training Epoch: 1/2, step 1672/53949 completed (loss: 4.2475504875183105, acc: 0.2142857164144516)
[2025-02-17 17:49:21,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:22,130][root][INFO] - Training Epoch: 1/2, step 1673/53949 completed (loss: 4.41234827041626, acc: 0.25925925374031067)
[2025-02-17 17:49:22,270][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:22,483][root][INFO] - Training Epoch: 1/2, step 1674/53949 completed (loss: 3.6237149238586426, acc: 0.3333333432674408)
[2025-02-17 17:49:22,658][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:22,881][root][INFO] - Training Epoch: 1/2, step 1675/53949 completed (loss: 4.468156337738037, acc: 0.1666666716337204)
[2025-02-17 17:49:23,081][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:23,312][root][INFO] - Training Epoch: 1/2, step 1676/53949 completed (loss: 3.6395230293273926, acc: 0.34375)
[2025-02-17 17:49:23,503][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:23,744][root][INFO] - Training Epoch: 1/2, step 1677/53949 completed (loss: 3.0869171619415283, acc: 0.5714285969734192)
[2025-02-17 17:49:23,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:24,130][root][INFO] - Training Epoch: 1/2, step 1678/53949 completed (loss: 2.07025146484375, acc: 0.800000011920929)
[2025-02-17 17:49:24,322][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:24,541][root][INFO] - Training Epoch: 1/2, step 1679/53949 completed (loss: 4.211427211761475, acc: 0.3142857253551483)
[2025-02-17 17:49:24,764][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:24,992][root][INFO] - Training Epoch: 1/2, step 1680/53949 completed (loss: 4.918612480163574, acc: 0.07894736528396606)
[2025-02-17 17:49:25,142][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:25,356][root][INFO] - Training Epoch: 1/2, step 1681/53949 completed (loss: 3.4059815406799316, acc: 0.3076923191547394)
[2025-02-17 17:49:25,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:25,717][root][INFO] - Training Epoch: 1/2, step 1682/53949 completed (loss: 3.9103314876556396, acc: 0.19230769574642181)
[2025-02-17 17:49:25,856][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:26,062][root][INFO] - Training Epoch: 1/2, step 1683/53949 completed (loss: 3.4358768463134766, acc: 0.37931033968925476)
[2025-02-17 17:49:26,207][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:26,425][root][INFO] - Training Epoch: 1/2, step 1684/53949 completed (loss: 2.6414992809295654, acc: 0.4285714328289032)
[2025-02-17 17:49:26,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:26,783][root][INFO] - Training Epoch: 1/2, step 1685/53949 completed (loss: 2.6365325450897217, acc: 0.4444444477558136)
[2025-02-17 17:49:26,919][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:27,141][root][INFO] - Training Epoch: 1/2, step 1686/53949 completed (loss: 3.891465425491333, acc: 0.26923078298568726)
[2025-02-17 17:49:27,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:27,550][root][INFO] - Training Epoch: 1/2, step 1687/53949 completed (loss: 5.16892147064209, acc: 0.06451612710952759)
[2025-02-17 17:49:27,744][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:27,964][root][INFO] - Training Epoch: 1/2, step 1688/53949 completed (loss: 2.780970811843872, acc: 0.3333333432674408)
[2025-02-17 17:49:28,144][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:28,379][root][INFO] - Training Epoch: 1/2, step 1689/53949 completed (loss: 3.1914753913879395, acc: 0.5)
[2025-02-17 17:49:28,557][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:28,781][root][INFO] - Training Epoch: 1/2, step 1690/53949 completed (loss: 4.192382335662842, acc: 0.20454545319080353)
[2025-02-17 17:49:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:29,137][root][INFO] - Training Epoch: 1/2, step 1691/53949 completed (loss: 3.0953681468963623, acc: 0.4000000059604645)
[2025-02-17 17:49:29,287][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:29,506][root][INFO] - Training Epoch: 1/2, step 1692/53949 completed (loss: 3.824089527130127, acc: 0.20000000298023224)
[2025-02-17 17:49:29,687][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:29,912][root][INFO] - Training Epoch: 1/2, step 1693/53949 completed (loss: 3.4470486640930176, acc: 0.4000000059604645)
[2025-02-17 17:49:30,044][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:30,263][root][INFO] - Training Epoch: 1/2, step 1694/53949 completed (loss: 3.297316789627075, acc: 0.375)
[2025-02-17 17:49:30,474][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:30,678][root][INFO] - Training Epoch: 1/2, step 1695/53949 completed (loss: 4.311994552612305, acc: 0.21212121844291687)
[2025-02-17 17:49:30,859][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:31,099][root][INFO] - Training Epoch: 1/2, step 1696/53949 completed (loss: 4.4436821937561035, acc: 0.17391304671764374)
[2025-02-17 17:49:31,301][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:31,527][root][INFO] - Training Epoch: 1/2, step 1697/53949 completed (loss: 0.2140081524848938, acc: 1.0)
[2025-02-17 17:49:31,709][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:31,931][root][INFO] - Training Epoch: 1/2, step 1698/53949 completed (loss: 3.624250888824463, acc: 0.37037035822868347)
[2025-02-17 17:49:32,077][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:32,270][root][INFO] - Training Epoch: 1/2, step 1699/53949 completed (loss: 3.8251216411590576, acc: 0.2222222238779068)
[2025-02-17 17:49:32,439][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:32,673][root][INFO] - Training Epoch: 1/2, step 1700/53949 completed (loss: 2.6206579208374023, acc: 0.37142857909202576)
[2025-02-17 17:49:32,823][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:33,041][root][INFO] - Training Epoch: 1/2, step 1701/53949 completed (loss: 3.295750141143799, acc: 0.3333333432674408)
[2025-02-17 17:49:33,216][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:33,474][root][INFO] - Training Epoch: 1/2, step 1702/53949 completed (loss: 3.8225460052490234, acc: 0.25806450843811035)
[2025-02-17 17:49:33,668][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:33,890][root][INFO] - Training Epoch: 1/2, step 1703/53949 completed (loss: 3.7867488861083984, acc: 0.3333333432674408)
[2025-02-17 17:49:34,033][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:34,266][root][INFO] - Training Epoch: 1/2, step 1704/53949 completed (loss: 3.2975940704345703, acc: 0.20000000298023224)
[2025-02-17 17:49:34,443][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:34,666][root][INFO] - Training Epoch: 1/2, step 1705/53949 completed (loss: 4.180709362030029, acc: 0.29411765933036804)
[2025-02-17 17:49:34,802][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:35,007][root][INFO] - Training Epoch: 1/2, step 1706/53949 completed (loss: 3.7924482822418213, acc: 0.2777777910232544)
[2025-02-17 17:49:35,133][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:35,343][root][INFO] - Training Epoch: 1/2, step 1707/53949 completed (loss: 3.7675366401672363, acc: 0.17142857611179352)
[2025-02-17 17:49:35,489][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:35,706][root][INFO] - Training Epoch: 1/2, step 1708/53949 completed (loss: 3.1703460216522217, acc: 0.30434781312942505)
[2025-02-17 17:49:35,874][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:36,117][root][INFO] - Training Epoch: 1/2, step 1709/53949 completed (loss: 2.638869524002075, acc: 0.5)
[2025-02-17 17:49:36,306][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:36,533][root][INFO] - Training Epoch: 1/2, step 1710/53949 completed (loss: 3.3793153762817383, acc: 0.380952388048172)
[2025-02-17 17:49:36,679][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:36,902][root][INFO] - Training Epoch: 1/2, step 1711/53949 completed (loss: 4.816771507263184, acc: 0.10000000149011612)
[2025-02-17 17:49:37,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:37,291][root][INFO] - Training Epoch: 1/2, step 1712/53949 completed (loss: 2.204512596130371, acc: 0.5833333134651184)
[2025-02-17 17:49:37,438][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:37,657][root][INFO] - Training Epoch: 1/2, step 1713/53949 completed (loss: 3.9713118076324463, acc: 0.37037035822868347)
[2025-02-17 17:49:37,847][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:38,072][root][INFO] - Training Epoch: 1/2, step 1714/53949 completed (loss: 4.671548843383789, acc: 0.27272728085517883)
[2025-02-17 17:49:38,254][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:38,491][root][INFO] - Training Epoch: 1/2, step 1715/53949 completed (loss: 3.2523584365844727, acc: 0.375)
[2025-02-17 17:49:38,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:38,853][root][INFO] - Training Epoch: 1/2, step 1716/53949 completed (loss: 6.048332214355469, acc: 0.375)
[2025-02-17 17:49:39,054][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:39,306][root][INFO] - Training Epoch: 1/2, step 1717/53949 completed (loss: 4.337021350860596, acc: 0.4117647111415863)
[2025-02-17 17:49:39,500][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:39,725][root][INFO] - Training Epoch: 1/2, step 1718/53949 completed (loss: 4.3240766525268555, acc: 0.2142857164144516)
[2025-02-17 17:49:39,898][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:40,119][root][INFO] - Training Epoch: 1/2, step 1719/53949 completed (loss: 4.269896984100342, acc: 0.1818181872367859)
[2025-02-17 17:49:40,315][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:40,543][root][INFO] - Training Epoch: 1/2, step 1720/53949 completed (loss: 2.681528329849243, acc: 0.3636363744735718)
[2025-02-17 17:49:40,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:40,907][root][INFO] - Training Epoch: 1/2, step 1721/53949 completed (loss: 3.6071789264678955, acc: 0.375)
[2025-02-17 17:49:41,039][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:41,233][root][INFO] - Training Epoch: 1/2, step 1722/53949 completed (loss: 3.8330209255218506, acc: 0.2916666567325592)
[2025-02-17 17:49:41,386][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:41,603][root][INFO] - Training Epoch: 1/2, step 1723/53949 completed (loss: 0.9011805057525635, acc: 0.6666666865348816)
[2025-02-17 17:49:41,747][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:41,966][root][INFO] - Training Epoch: 1/2, step 1724/53949 completed (loss: 3.217958688735962, acc: 0.29411765933036804)
[2025-02-17 17:49:42,098][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:42,302][root][INFO] - Training Epoch: 1/2, step 1725/53949 completed (loss: 4.060489177703857, acc: 0.1764705926179886)
[2025-02-17 17:49:42,491][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:42,722][root][INFO] - Training Epoch: 1/2, step 1726/53949 completed (loss: 4.036139011383057, acc: 0.23529411852359772)
[2025-02-17 17:49:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:43,098][root][INFO] - Training Epoch: 1/2, step 1727/53949 completed (loss: 2.9373176097869873, acc: 0.5199999809265137)
[2025-02-17 17:49:43,307][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:43,539][root][INFO] - Training Epoch: 1/2, step 1728/53949 completed (loss: 0.030800465494394302, acc: 1.0)
[2025-02-17 17:49:43,707][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:43,930][root][INFO] - Training Epoch: 1/2, step 1729/53949 completed (loss: 3.7726802825927734, acc: 0.2708333432674408)
[2025-02-17 17:49:44,104][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:44,366][root][INFO] - Training Epoch: 1/2, step 1730/53949 completed (loss: 2.7962100505828857, acc: 0.4285714328289032)
[2025-02-17 17:49:44,553][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:44,788][root][INFO] - Training Epoch: 1/2, step 1731/53949 completed (loss: 3.6582016944885254, acc: 0.375)
[2025-02-17 17:49:44,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:45,166][root][INFO] - Training Epoch: 1/2, step 1732/53949 completed (loss: 4.463705062866211, acc: 0.32258063554763794)
[2025-02-17 17:49:45,391][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:45,599][root][INFO] - Training Epoch: 1/2, step 1733/53949 completed (loss: 3.3994524478912354, acc: 0.38461539149284363)
[2025-02-17 17:49:45,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:45,969][root][INFO] - Training Epoch: 1/2, step 1734/53949 completed (loss: 3.0256569385528564, acc: 0.3055555522441864)
[2025-02-17 17:49:46,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:46,323][root][INFO] - Training Epoch: 1/2, step 1735/53949 completed (loss: 2.9377408027648926, acc: 0.3333333432674408)
[2025-02-17 17:49:46,464][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:46,694][root][INFO] - Training Epoch: 1/2, step 1736/53949 completed (loss: 2.8048436641693115, acc: 0.4000000059604645)
[2025-02-17 17:49:46,907][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:47,143][root][INFO] - Training Epoch: 1/2, step 1737/53949 completed (loss: 3.0476033687591553, acc: 0.3571428656578064)
[2025-02-17 17:49:47,319][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:47,545][root][INFO] - Training Epoch: 1/2, step 1738/53949 completed (loss: 3.010927200317383, acc: 0.3333333432674408)
[2025-02-17 17:49:47,681][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:47,963][root][INFO] - Training Epoch: 1/2, step 1739/53949 completed (loss: 2.8432295322418213, acc: 0.3333333432674408)
[2025-02-17 17:49:48,138][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:48,367][root][INFO] - Training Epoch: 1/2, step 1740/53949 completed (loss: 3.696042776107788, acc: 0.261904776096344)
[2025-02-17 17:49:48,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:48,801][root][INFO] - Training Epoch: 1/2, step 1741/53949 completed (loss: 2.694272756576538, acc: 0.4444444477558136)
[2025-02-17 17:49:48,997][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:49,214][root][INFO] - Training Epoch: 1/2, step 1742/53949 completed (loss: 4.780555248260498, acc: 0.3199999928474426)
[2025-02-17 17:49:49,374][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:49,608][root][INFO] - Training Epoch: 1/2, step 1743/53949 completed (loss: 3.4988338947296143, acc: 0.31578946113586426)
[2025-02-17 17:49:49,816][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:50,062][root][INFO] - Training Epoch: 1/2, step 1744/53949 completed (loss: 4.177616119384766, acc: 0.24242424964904785)
[2025-02-17 17:49:50,302][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:50,529][root][INFO] - Training Epoch: 1/2, step 1745/53949 completed (loss: 2.859297752380371, acc: 0.3636363744735718)
[2025-02-17 17:49:50,671][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:50,893][root][INFO] - Training Epoch: 1/2, step 1746/53949 completed (loss: 2.380232095718384, acc: 0.4444444477558136)
[2025-02-17 17:49:51,031][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:51,248][root][INFO] - Training Epoch: 1/2, step 1747/53949 completed (loss: 3.6128296852111816, acc: 0.23076923191547394)
[2025-02-17 17:49:51,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:51,698][root][INFO] - Training Epoch: 1/2, step 1748/53949 completed (loss: 3.7117583751678467, acc: 0.2222222238779068)
[2025-02-17 17:49:51,889][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:52,121][root][INFO] - Training Epoch: 1/2, step 1749/53949 completed (loss: 3.831598997116089, acc: 0.3513513505458832)
[2025-02-17 17:49:52,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:52,480][root][INFO] - Training Epoch: 1/2, step 1750/53949 completed (loss: 2.300553798675537, acc: 0.6000000238418579)
[2025-02-17 17:49:52,632][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:52,856][root][INFO] - Training Epoch: 1/2, step 1751/53949 completed (loss: 3.9008030891418457, acc: 0.3333333432674408)
[2025-02-17 17:49:52,993][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:53,218][root][INFO] - Training Epoch: 1/2, step 1752/53949 completed (loss: 4.333847522735596, acc: 0.25)
[2025-02-17 17:49:53,356][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:53,580][root][INFO] - Training Epoch: 1/2, step 1753/53949 completed (loss: 3.678173780441284, acc: 0.21052631735801697)
[2025-02-17 17:49:53,785][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:54,008][root][INFO] - Training Epoch: 1/2, step 1754/53949 completed (loss: 3.6281826496124268, acc: 0.23999999463558197)
[2025-02-17 17:49:54,140][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:54,367][root][INFO] - Training Epoch: 1/2, step 1755/53949 completed (loss: 3.7419626712799072, acc: 0.30434781312942505)
[2025-02-17 17:49:54,516][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:54,736][root][INFO] - Training Epoch: 1/2, step 1756/53949 completed (loss: 2.5305099487304688, acc: 0.5)
[2025-02-17 17:49:54,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:55,182][root][INFO] - Training Epoch: 1/2, step 1757/53949 completed (loss: 4.351193428039551, acc: 0.18918919563293457)
[2025-02-17 17:49:55,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:55,530][root][INFO] - Training Epoch: 1/2, step 1758/53949 completed (loss: 1.955965518951416, acc: 0.75)
[2025-02-17 17:49:55,667][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:55,889][root][INFO] - Training Epoch: 1/2, step 1759/53949 completed (loss: 1.3685836791992188, acc: 0.6666666865348816)
[2025-02-17 17:49:56,049][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:56,269][root][INFO] - Training Epoch: 1/2, step 1760/53949 completed (loss: 3.720874786376953, acc: 0.3142857253551483)
[2025-02-17 17:49:56,400][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:56,620][root][INFO] - Training Epoch: 1/2, step 1761/53949 completed (loss: 2.861093759536743, acc: 0.2222222238779068)
[2025-02-17 17:49:56,828][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:57,053][root][INFO] - Training Epoch: 1/2, step 1762/53949 completed (loss: 3.620818614959717, acc: 0.4375)
[2025-02-17 17:49:57,200][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:57,423][root][INFO] - Training Epoch: 1/2, step 1763/53949 completed (loss: 2.1331865787506104, acc: 0.5)
[2025-02-17 17:49:57,558][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:57,782][root][INFO] - Training Epoch: 1/2, step 1764/53949 completed (loss: 0.13148938119411469, acc: 1.0)
[2025-02-17 17:49:57,954][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:58,182][root][INFO] - Training Epoch: 1/2, step 1765/53949 completed (loss: 2.8562123775482178, acc: 0.4285714328289032)
[2025-02-17 17:49:58,313][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:58,541][root][INFO] - Training Epoch: 1/2, step 1766/53949 completed (loss: 3.0603060722351074, acc: 0.4444444477558136)
[2025-02-17 17:49:58,697][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:58,920][root][INFO] - Training Epoch: 1/2, step 1767/53949 completed (loss: 2.1713967323303223, acc: 0.6000000238418579)
[2025-02-17 17:49:59,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:59,284][root][INFO] - Training Epoch: 1/2, step 1768/53949 completed (loss: 3.3631842136383057, acc: 0.3928571343421936)
[2025-02-17 17:49:59,421][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:49:59,635][root][INFO] - Training Epoch: 1/2, step 1769/53949 completed (loss: 3.2510690689086914, acc: 0.27272728085517883)
[2025-02-17 17:49:59,773][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:00,001][root][INFO] - Training Epoch: 1/2, step 1770/53949 completed (loss: 2.8412768840789795, acc: 0.5)
[2025-02-17 17:50:00,192][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:00,415][root][INFO] - Training Epoch: 1/2, step 1771/53949 completed (loss: 2.9628283977508545, acc: 0.5)
[2025-02-17 17:50:00,574][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:00,784][root][INFO] - Training Epoch: 1/2, step 1772/53949 completed (loss: 2.36041522026062, acc: 0.5)
[2025-02-17 17:50:00,926][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:01,146][root][INFO] - Training Epoch: 1/2, step 1773/53949 completed (loss: 4.089182376861572, acc: 0.2142857164144516)
[2025-02-17 17:50:01,342][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:01,531][root][INFO] - Training Epoch: 1/2, step 1774/53949 completed (loss: 4.5446391105651855, acc: 0.25806450843811035)
[2025-02-17 17:50:01,720][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:01,955][root][INFO] - Training Epoch: 1/2, step 1775/53949 completed (loss: 2.8072423934936523, acc: 0.2222222238779068)
[2025-02-17 17:50:02,141][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:02,368][root][INFO] - Training Epoch: 1/2, step 1776/53949 completed (loss: 3.2528741359710693, acc: 0.2380952388048172)
[2025-02-17 17:50:02,515][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:02,735][root][INFO] - Training Epoch: 1/2, step 1777/53949 completed (loss: 3.8242053985595703, acc: 0.1818181872367859)
[2025-02-17 17:50:02,913][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:03,145][root][INFO] - Training Epoch: 1/2, step 1778/53949 completed (loss: 3.675586700439453, acc: 0.28205129504203796)
[2025-02-17 17:50:03,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:03,539][root][INFO] - Training Epoch: 1/2, step 1779/53949 completed (loss: 0.23516923189163208, acc: 1.0)
[2025-02-17 17:50:03,695][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:03,925][root][INFO] - Training Epoch: 1/2, step 1780/53949 completed (loss: 2.045170783996582, acc: 0.6111111044883728)
[2025-02-17 17:50:04,060][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:04,275][root][INFO] - Training Epoch: 1/2, step 1781/53949 completed (loss: 2.5091989040374756, acc: 0.40909090638160706)
[2025-02-17 17:50:04,451][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:04,680][root][INFO] - Training Epoch: 1/2, step 1782/53949 completed (loss: 3.1875052452087402, acc: 0.3636363744735718)
[2025-02-17 17:50:04,857][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:05,077][root][INFO] - Training Epoch: 1/2, step 1783/53949 completed (loss: 4.641656398773193, acc: 0.15000000596046448)
[2025-02-17 17:50:05,225][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:05,450][root][INFO] - Training Epoch: 1/2, step 1784/53949 completed (loss: 3.4858696460723877, acc: 0.15000000596046448)
[2025-02-17 17:50:05,593][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:05,787][root][INFO] - Training Epoch: 1/2, step 1785/53949 completed (loss: 0.07220238447189331, acc: 1.0)
[2025-02-17 17:50:05,932][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:06,137][root][INFO] - Training Epoch: 1/2, step 1786/53949 completed (loss: 1.606499195098877, acc: 0.5)
[2025-02-17 17:50:06,297][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:06,519][root][INFO] - Training Epoch: 1/2, step 1787/53949 completed (loss: 1.1898547410964966, acc: 0.6666666865348816)
[2025-02-17 17:50:06,717][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:06,943][root][INFO] - Training Epoch: 1/2, step 1788/53949 completed (loss: 1.767469048500061, acc: 0.800000011920929)
[2025-02-17 17:50:07,130][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:07,361][root][INFO] - Training Epoch: 1/2, step 1789/53949 completed (loss: 3.9056389331817627, acc: 0.27272728085517883)
[2025-02-17 17:50:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:07,727][root][INFO] - Training Epoch: 1/2, step 1790/53949 completed (loss: 3.0553383827209473, acc: 0.40909090638160706)
[2025-02-17 17:50:07,900][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:08,147][root][INFO] - Training Epoch: 1/2, step 1791/53949 completed (loss: 4.238163948059082, acc: 0.1428571492433548)
[2025-02-17 17:50:08,340][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:08,563][root][INFO] - Training Epoch: 1/2, step 1792/53949 completed (loss: 3.745335340499878, acc: 0.30000001192092896)
[2025-02-17 17:50:08,700][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:08,923][root][INFO] - Training Epoch: 1/2, step 1793/53949 completed (loss: 3.5721895694732666, acc: 0.3636363744735718)
[2025-02-17 17:50:09,076][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:09,294][root][INFO] - Training Epoch: 1/2, step 1794/53949 completed (loss: 3.532221794128418, acc: 0.3684210479259491)
[2025-02-17 17:50:09,433][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:09,653][root][INFO] - Training Epoch: 1/2, step 1795/53949 completed (loss: 3.5024139881134033, acc: 0.25)
[2025-02-17 17:50:09,793][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:10,012][root][INFO] - Training Epoch: 1/2, step 1796/53949 completed (loss: 3.344315528869629, acc: 0.4117647111415863)
[2025-02-17 17:50:10,150][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:10,373][root][INFO] - Training Epoch: 1/2, step 1797/53949 completed (loss: 2.4737980365753174, acc: 0.4000000059604645)
[2025-02-17 17:50:10,514][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:10,712][root][INFO] - Training Epoch: 1/2, step 1798/53949 completed (loss: 2.790997266769409, acc: 0.3636363744735718)
[2025-02-17 17:50:10,861][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:11,090][root][INFO] - Training Epoch: 1/2, step 1799/53949 completed (loss: 4.119583606719971, acc: 0.1818181872367859)
[2025-02-17 17:50:11,263][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:11,479][root][INFO] - Training Epoch: 1/2, step 1800/53949 completed (loss: 2.518299102783203, acc: 0.4285714328289032)
[2025-02-17 17:50:11,617][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:11,825][root][INFO] - Training Epoch: 1/2, step 1801/53949 completed (loss: 4.338774681091309, acc: 0.3461538553237915)
[2025-02-17 17:50:11,998][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:12,216][root][INFO] - Training Epoch: 1/2, step 1802/53949 completed (loss: 3.07646107673645, acc: 0.3199999928474426)
[2025-02-17 17:50:12,365][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:12,588][root][INFO] - Training Epoch: 1/2, step 1803/53949 completed (loss: 4.452980995178223, acc: 0.20000000298023224)
[2025-02-17 17:50:12,758][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:12,971][root][INFO] - Training Epoch: 1/2, step 1804/53949 completed (loss: 2.932737350463867, acc: 0.5714285969734192)
[2025-02-17 17:50:13,111][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:13,336][root][INFO] - Training Epoch: 1/2, step 1805/53949 completed (loss: 2.08011531829834, acc: 0.692307710647583)
[2025-02-17 17:50:13,519][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:13,739][root][INFO] - Training Epoch: 1/2, step 1806/53949 completed (loss: 3.598928689956665, acc: 0.2222222238779068)
[2025-02-17 17:50:13,880][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:14,149][root][INFO] - Training Epoch: 1/2, step 1807/53949 completed (loss: 2.9989891052246094, acc: 0.38461539149284363)
[2025-02-17 17:50:14,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:14,585][root][INFO] - Training Epoch: 1/2, step 1808/53949 completed (loss: 4.330979347229004, acc: 0.2631579041481018)
[2025-02-17 17:50:14,761][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:14,986][root][INFO] - Training Epoch: 1/2, step 1809/53949 completed (loss: 4.228520393371582, acc: 0.22580644488334656)
[2025-02-17 17:50:15,177][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:15,401][root][INFO] - Training Epoch: 1/2, step 1810/53949 completed (loss: 0.018124261870980263, acc: 1.0)
[2025-02-17 17:50:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:15,771][root][INFO] - Training Epoch: 1/2, step 1811/53949 completed (loss: 1.755292534828186, acc: 0.5)
[2025-02-17 17:50:15,980][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:16,212][root][INFO] - Training Epoch: 1/2, step 1812/53949 completed (loss: 3.22622013092041, acc: 0.29629629850387573)
[2025-02-17 17:50:16,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:16,583][root][INFO] - Training Epoch: 1/2, step 1813/53949 completed (loss: 1.6118773221969604, acc: 0.4285714328289032)
[2025-02-17 17:50:16,766][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:16,990][root][INFO] - Training Epoch: 1/2, step 1814/53949 completed (loss: 4.209329605102539, acc: 0.19512194395065308)
[2025-02-17 17:50:17,139][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:17,355][root][INFO] - Training Epoch: 1/2, step 1815/53949 completed (loss: 3.7672226428985596, acc: 0.21875)
[2025-02-17 17:50:17,493][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:17,709][root][INFO] - Training Epoch: 1/2, step 1816/53949 completed (loss: 3.0465304851531982, acc: 0.36666667461395264)
[2025-02-17 17:50:17,845][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:18,055][root][INFO] - Training Epoch: 1/2, step 1817/53949 completed (loss: 2.991943836212158, acc: 0.4000000059604645)
[2025-02-17 17:50:18,191][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:18,400][root][INFO] - Training Epoch: 1/2, step 1818/53949 completed (loss: 3.9953763484954834, acc: 0.1538461595773697)
[2025-02-17 17:50:18,544][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:18,751][root][INFO] - Training Epoch: 1/2, step 1819/53949 completed (loss: 3.7135307788848877, acc: 0.3333333432674408)
[2025-02-17 17:50:18,938][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:19,131][root][INFO] - Training Epoch: 1/2, step 1820/53949 completed (loss: 3.5307908058166504, acc: 0.2857142984867096)
[2025-02-17 17:50:19,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:19,556][root][INFO] - Training Epoch: 1/2, step 1821/53949 completed (loss: 4.307094573974609, acc: 0.4000000059604645)
[2025-02-17 17:50:19,748][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:19,931][root][INFO] - Training Epoch: 1/2, step 1822/53949 completed (loss: 2.813272714614868, acc: 0.27272728085517883)
[2025-02-17 17:50:20,057][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:20,281][root][INFO] - Training Epoch: 1/2, step 1823/53949 completed (loss: 2.9637973308563232, acc: 0.30000001192092896)
[2025-02-17 17:50:20,445][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:20,663][root][INFO] - Training Epoch: 1/2, step 1824/53949 completed (loss: 4.62507963180542, acc: 0.17241379618644714)
[2025-02-17 17:50:20,798][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:21,014][root][INFO] - Training Epoch: 1/2, step 1825/53949 completed (loss: 2.0798704624176025, acc: 0.5)
[2025-02-17 17:50:21,159][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:21,376][root][INFO] - Training Epoch: 1/2, step 1826/53949 completed (loss: 3.4078049659729004, acc: 0.3461538553237915)
[2025-02-17 17:50:21,561][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:21,822][root][INFO] - Training Epoch: 1/2, step 1827/53949 completed (loss: 4.078918933868408, acc: 0.290909081697464)
[2025-02-17 17:50:22,041][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:22,276][root][INFO] - Training Epoch: 1/2, step 1828/53949 completed (loss: 3.6137607097625732, acc: 0.261904776096344)
[2025-02-17 17:50:22,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:22,690][root][INFO] - Training Epoch: 1/2, step 1829/53949 completed (loss: 3.5377330780029297, acc: 0.375)
[2025-02-17 17:50:22,873][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:23,116][root][INFO] - Training Epoch: 1/2, step 1830/53949 completed (loss: 3.8349287509918213, acc: 0.2777777910232544)
[2025-02-17 17:50:23,278][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:23,492][root][INFO] - Training Epoch: 1/2, step 1831/53949 completed (loss: 3.4014766216278076, acc: 0.23333333432674408)
[2025-02-17 17:50:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:23,905][root][INFO] - Training Epoch: 1/2, step 1832/53949 completed (loss: 4.105818748474121, acc: 0.24074074625968933)
[2025-02-17 17:50:24,082][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:24,303][root][INFO] - Training Epoch: 1/2, step 1833/53949 completed (loss: 3.380462408065796, acc: 0.2068965584039688)
[2025-02-17 17:50:24,442][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:24,664][root][INFO] - Training Epoch: 1/2, step 1834/53949 completed (loss: 3.638366222381592, acc: 0.37037035822868347)
[2025-02-17 17:50:24,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:25,139][root][INFO] - Training Epoch: 1/2, step 1835/53949 completed (loss: 3.5064094066619873, acc: 0.3448275923728943)
[2025-02-17 17:50:25,303][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:25,519][root][INFO] - Training Epoch: 1/2, step 1836/53949 completed (loss: 3.6800429821014404, acc: 0.2142857164144516)
[2025-02-17 17:50:25,701][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:25,931][root][INFO] - Training Epoch: 1/2, step 1837/53949 completed (loss: 3.5664539337158203, acc: 0.30434781312942505)
[2025-02-17 17:50:26,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:26,448][root][INFO] - Training Epoch: 1/2, step 1838/53949 completed (loss: 4.671257019042969, acc: 0.1785714328289032)
[2025-02-17 17:50:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:26,879][root][INFO] - Training Epoch: 1/2, step 1839/53949 completed (loss: 3.8053274154663086, acc: 0.375)
[2025-02-17 17:50:27,084][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:27,314][root][INFO] - Training Epoch: 1/2, step 1840/53949 completed (loss: 2.678614377975464, acc: 0.2857142984867096)
[2025-02-17 17:50:27,507][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:27,729][root][INFO] - Training Epoch: 1/2, step 1841/53949 completed (loss: 3.682859182357788, acc: 0.27272728085517883)
[2025-02-17 17:50:27,888][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:28,103][root][INFO] - Training Epoch: 1/2, step 1842/53949 completed (loss: 3.8467586040496826, acc: 0.380952388048172)
[2025-02-17 17:50:28,261][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:28,520][root][INFO] - Training Epoch: 1/2, step 1843/53949 completed (loss: 0.4104999601840973, acc: 0.800000011920929)
[2025-02-17 17:50:28,702][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:28,922][root][INFO] - Training Epoch: 1/2, step 1844/53949 completed (loss: 2.679704427719116, acc: 0.5)
[2025-02-17 17:50:29,058][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:29,272][root][INFO] - Training Epoch: 1/2, step 1845/53949 completed (loss: 3.9754951000213623, acc: 0.3333333432674408)
[2025-02-17 17:50:29,390][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:29,610][root][INFO] - Training Epoch: 1/2, step 1846/53949 completed (loss: 3.360867738723755, acc: 0.3499999940395355)
[2025-02-17 17:50:29,745][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:29,960][root][INFO] - Training Epoch: 1/2, step 1847/53949 completed (loss: 3.044221878051758, acc: 0.4166666567325592)
[2025-02-17 17:50:30,094][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:30,306][root][INFO] - Training Epoch: 1/2, step 1848/53949 completed (loss: 1.3782845735549927, acc: 0.6000000238418579)
[2025-02-17 17:50:30,453][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:30,665][root][INFO] - Training Epoch: 1/2, step 1849/53949 completed (loss: 3.6352601051330566, acc: 0.27272728085517883)
[2025-02-17 17:50:30,846][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:31,066][root][INFO] - Training Epoch: 1/2, step 1850/53949 completed (loss: 2.6144280433654785, acc: 0.43478259444236755)
[2025-02-17 17:50:31,247][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:31,495][root][INFO] - Training Epoch: 1/2, step 1851/53949 completed (loss: 3.976043939590454, acc: 0.38461539149284363)
[2025-02-17 17:50:31,655][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:31,868][root][INFO] - Training Epoch: 1/2, step 1852/53949 completed (loss: 0.10547806322574615, acc: 1.0)
[2025-02-17 17:50:32,072][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:32,291][root][INFO] - Training Epoch: 1/2, step 1853/53949 completed (loss: 2.863273859024048, acc: 0.37037035822868347)
[2025-02-17 17:50:32,426][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:32,660][root][INFO] - Training Epoch: 1/2, step 1854/53949 completed (loss: 3.5463459491729736, acc: 0.2857142984867096)
[2025-02-17 17:50:32,829][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:33,062][root][INFO] - Training Epoch: 1/2, step 1855/53949 completed (loss: 2.5251879692077637, acc: 0.529411792755127)
[2025-02-17 17:50:33,180][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:33,394][root][INFO] - Training Epoch: 1/2, step 1856/53949 completed (loss: 1.0604251623153687, acc: 0.75)
[2025-02-17 17:50:33,565][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:33,787][root][INFO] - Training Epoch: 1/2, step 1857/53949 completed (loss: 2.9945945739746094, acc: 0.35849055647850037)
[2025-02-17 17:50:33,941][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:34,163][root][INFO] - Training Epoch: 1/2, step 1858/53949 completed (loss: 3.3785040378570557, acc: 0.20000000298023224)
[2025-02-17 17:50:34,329][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:34,596][root][INFO] - Training Epoch: 1/2, step 1859/53949 completed (loss: 4.056118965148926, acc: 0.3333333432674408)
[2025-02-17 17:50:34,815][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:35,040][root][INFO] - Training Epoch: 1/2, step 1860/53949 completed (loss: 2.4602956771850586, acc: 0.5161290168762207)
[2025-02-17 17:50:35,224][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:35,459][root][INFO] - Training Epoch: 1/2, step 1861/53949 completed (loss: 0.06281787157058716, acc: 1.0)
[2025-02-17 17:50:35,639][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:35,866][root][INFO] - Training Epoch: 1/2, step 1862/53949 completed (loss: 2.4254634380340576, acc: 0.5)
[2025-02-17 17:50:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:36,334][root][INFO] - Training Epoch: 1/2, step 1863/53949 completed (loss: 3.0478920936584473, acc: 0.3333333432674408)
[2025-02-17 17:50:36,538][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:36,764][root][INFO] - Training Epoch: 1/2, step 1864/53949 completed (loss: 0.6048870086669922, acc: 0.75)
[2025-02-17 17:50:36,923][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:37,201][root][INFO] - Training Epoch: 1/2, step 1865/53949 completed (loss: 4.2532782554626465, acc: 0.2222222238779068)
[2025-02-17 17:50:37,419][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:37,648][root][INFO] - Training Epoch: 1/2, step 1866/53949 completed (loss: 3.6966867446899414, acc: 0.3199999928474426)
[2025-02-17 17:50:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:38,028][root][INFO] - Training Epoch: 1/2, step 1867/53949 completed (loss: 3.6805105209350586, acc: 0.2222222238779068)
[2025-02-17 17:50:38,165][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:38,357][root][INFO] - Training Epoch: 1/2, step 1868/53949 completed (loss: 2.9586353302001953, acc: 0.3684210479259491)
[2025-02-17 17:50:38,590][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:38,839][root][INFO] - Training Epoch: 1/2, step 1869/53949 completed (loss: 3.6843364238739014, acc: 0.29032257199287415)
[2025-02-17 17:50:39,008][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:39,227][root][INFO] - Training Epoch: 1/2, step 1870/53949 completed (loss: 3.5674221515655518, acc: 0.3499999940395355)
[2025-02-17 17:50:39,371][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:39,597][root][INFO] - Training Epoch: 1/2, step 1871/53949 completed (loss: 3.278867721557617, acc: 0.3199999928474426)
[2025-02-17 17:50:39,754][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:39,994][root][INFO] - Training Epoch: 1/2, step 1872/53949 completed (loss: 2.6454482078552246, acc: 0.3529411852359772)
[2025-02-17 17:50:40,166][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:40,390][root][INFO] - Training Epoch: 1/2, step 1873/53949 completed (loss: 2.2929527759552, acc: 0.4375)
[2025-02-17 17:50:40,528][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:40,759][root][INFO] - Training Epoch: 1/2, step 1874/53949 completed (loss: 3.5594353675842285, acc: 0.20000000298023224)
[2025-02-17 17:50:40,965][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:41,182][root][INFO] - Training Epoch: 1/2, step 1875/53949 completed (loss: 3.881505250930786, acc: 0.29032257199287415)
[2025-02-17 17:50:41,318][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:41,546][root][INFO] - Training Epoch: 1/2, step 1876/53949 completed (loss: 2.51469087600708, acc: 0.43478259444236755)
[2025-02-17 17:50:41,753][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:41,982][root][INFO] - Training Epoch: 1/2, step 1877/53949 completed (loss: 2.6322500705718994, acc: 0.4285714328289032)
[2025-02-17 17:50:42,170][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:42,393][root][INFO] - Training Epoch: 1/2, step 1878/53949 completed (loss: 4.685225963592529, acc: 0.1428571492433548)
[2025-02-17 17:50:42,543][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:42,762][root][INFO] - Training Epoch: 1/2, step 1879/53949 completed (loss: 3.152270793914795, acc: 0.4615384638309479)
[2025-02-17 17:50:42,933][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:43,171][root][INFO] - Training Epoch: 1/2, step 1880/53949 completed (loss: 3.3777356147766113, acc: 0.38461539149284363)
[2025-02-17 17:50:43,334][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:43,553][root][INFO] - Training Epoch: 1/2, step 1881/53949 completed (loss: 3.2440505027770996, acc: 0.4736842215061188)
[2025-02-17 17:50:43,684][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:43,907][root][INFO] - Training Epoch: 1/2, step 1882/53949 completed (loss: 3.206244945526123, acc: 0.3777777850627899)
[2025-02-17 17:50:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:44,350][root][INFO] - Training Epoch: 1/2, step 1883/53949 completed (loss: 3.4610378742218018, acc: 0.2857142984867096)
[2025-02-17 17:50:44,520][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:44,733][root][INFO] - Training Epoch: 1/2, step 1884/53949 completed (loss: 0.009014640003442764, acc: 1.0)
[2025-02-17 17:50:44,870][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:45,090][root][INFO] - Training Epoch: 1/2, step 1885/53949 completed (loss: 3.6905224323272705, acc: 0.3214285671710968)
[2025-02-17 17:50:45,255][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:45,468][root][INFO] - Training Epoch: 1/2, step 1886/53949 completed (loss: 3.4265248775482178, acc: 0.42424243688583374)
[2025-02-17 17:50:45,673][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:45,884][root][INFO] - Training Epoch: 1/2, step 1887/53949 completed (loss: 3.926835775375366, acc: 0.2291666716337204)
[2025-02-17 17:50:46,038][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:46,262][root][INFO] - Training Epoch: 1/2, step 1888/53949 completed (loss: 2.9968104362487793, acc: 0.5384615659713745)
[2025-02-17 17:50:46,462][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:46,689][root][INFO] - Training Epoch: 1/2, step 1889/53949 completed (loss: 5.0179057121276855, acc: 0.2857142984867096)
[2025-02-17 17:50:46,878][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:47,097][root][INFO] - Training Epoch: 1/2, step 1890/53949 completed (loss: 2.685591459274292, acc: 0.375)
[2025-02-17 17:50:47,320][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:47,559][root][INFO] - Training Epoch: 1/2, step 1891/53949 completed (loss: 1.5836544036865234, acc: 0.75)
[2025-02-17 17:50:47,737][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:47,967][root][INFO] - Training Epoch: 1/2, step 1892/53949 completed (loss: 3.578460454940796, acc: 0.23529411852359772)
[2025-02-17 17:50:48,175][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:48,416][root][INFO] - Training Epoch: 1/2, step 1893/53949 completed (loss: 2.7288577556610107, acc: 0.5555555820465088)
[2025-02-17 17:50:48,616][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:48,848][root][INFO] - Training Epoch: 1/2, step 1894/53949 completed (loss: 3.99112868309021, acc: 0.31578946113586426)
[2025-02-17 17:50:49,022][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:49,250][root][INFO] - Training Epoch: 1/2, step 1895/53949 completed (loss: 2.3209705352783203, acc: 0.4736842215061188)
[2025-02-17 17:50:49,423][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:49,636][root][INFO] - Training Epoch: 1/2, step 1896/53949 completed (loss: 3.4046683311462402, acc: 0.3478260934352875)
[2025-02-17 17:50:49,780][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:50,002][root][INFO] - Training Epoch: 1/2, step 1897/53949 completed (loss: 3.0938031673431396, acc: 0.3913043439388275)
[2025-02-17 17:50:50,189][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:50,409][root][INFO] - Training Epoch: 1/2, step 1898/53949 completed (loss: 3.4158544540405273, acc: 0.3181818127632141)
[2025-02-17 17:50:50,556][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:50,780][root][INFO] - Training Epoch: 1/2, step 1899/53949 completed (loss: 3.5455539226531982, acc: 0.3333333432674408)
[2025-02-17 17:50:50,922][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:51,147][root][INFO] - Training Epoch: 1/2, step 1900/53949 completed (loss: 4.2018208503723145, acc: 0.22727273404598236)
[2025-02-17 17:50:51,328][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:51,548][root][INFO] - Training Epoch: 1/2, step 1901/53949 completed (loss: 2.3545820713043213, acc: 0.5)
[2025-02-17 17:50:51,686][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:51,901][root][INFO] - Training Epoch: 1/2, step 1902/53949 completed (loss: 3.6428961753845215, acc: 0.31111112236976624)
[2025-02-17 17:50:52,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:52,261][root][INFO] - Training Epoch: 1/2, step 1903/53949 completed (loss: 3.751253366470337, acc: 0.37142857909202576)
[2025-02-17 17:50:52,403][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:52,683][root][INFO] - Training Epoch: 1/2, step 1904/53949 completed (loss: 2.786120653152466, acc: 0.5)
[2025-02-17 17:50:52,915][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:53,144][root][INFO] - Training Epoch: 1/2, step 1905/53949 completed (loss: 3.7194766998291016, acc: 0.3214285671710968)
[2025-02-17 17:50:53,350][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:53,594][root][INFO] - Training Epoch: 1/2, step 1906/53949 completed (loss: 3.1079506874084473, acc: 0.38235294818878174)
[2025-02-17 17:50:53,786][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:54,011][root][INFO] - Training Epoch: 1/2, step 1907/53949 completed (loss: 4.344169616699219, acc: 0.26923078298568726)
[2025-02-17 17:50:54,248][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:54,490][root][INFO] - Training Epoch: 1/2, step 1908/53949 completed (loss: 3.641680955886841, acc: 0.32258063554763794)
[2025-02-17 17:50:54,654][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:54,898][root][INFO] - Training Epoch: 1/2, step 1909/53949 completed (loss: 3.1309189796447754, acc: 0.3333333432674408)
[2025-02-17 17:50:55,042][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:55,255][root][INFO] - Training Epoch: 1/2, step 1910/53949 completed (loss: 3.7971925735473633, acc: 0.3103448152542114)
[2025-02-17 17:50:55,399][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:55,604][root][INFO] - Training Epoch: 1/2, step 1911/53949 completed (loss: 0.7991414666175842, acc: 0.75)
[2025-02-17 17:50:55,817][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:56,040][root][INFO] - Training Epoch: 1/2, step 1912/53949 completed (loss: 4.235047817230225, acc: 0.3636363744735718)
[2025-02-17 17:50:56,243][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:56,477][root][INFO] - Training Epoch: 1/2, step 1913/53949 completed (loss: 3.4457459449768066, acc: 0.0)
[2025-02-17 17:50:56,643][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:56,860][root][INFO] - Training Epoch: 1/2, step 1914/53949 completed (loss: 3.2163751125335693, acc: 0.2222222238779068)
[2025-02-17 17:50:57,001][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:57,218][root][INFO] - Training Epoch: 1/2, step 1915/53949 completed (loss: 3.1112163066864014, acc: 0.3913043439388275)
[2025-02-17 17:50:57,401][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:57,642][root][INFO] - Training Epoch: 1/2, step 1916/53949 completed (loss: 3.31693434715271, acc: 0.3142857253551483)
[2025-02-17 17:50:57,808][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:58,027][root][INFO] - Training Epoch: 1/2, step 1917/53949 completed (loss: 1.1248213052749634, acc: 0.800000011920929)
[2025-02-17 17:50:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:58,370][root][INFO] - Training Epoch: 1/2, step 1918/53949 completed (loss: 2.775461435317993, acc: 0.5454545617103577)
[2025-02-17 17:50:58,506][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:58,726][root][INFO] - Training Epoch: 1/2, step 1919/53949 completed (loss: 1.4468261003494263, acc: 0.75)
[2025-02-17 17:50:58,860][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:59,093][root][INFO] - Training Epoch: 1/2, step 1920/53949 completed (loss: 1.4812614917755127, acc: 0.800000011920929)
[2025-02-17 17:50:59,267][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:59,492][root][INFO] - Training Epoch: 1/2, step 1921/53949 completed (loss: 2.9540162086486816, acc: 0.6000000238418579)
[2025-02-17 17:50:59,728][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:50:59,954][root][INFO] - Training Epoch: 1/2, step 1922/53949 completed (loss: 3.3510231971740723, acc: 0.2800000011920929)
[2025-02-17 17:51:00,154][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:51:00,387][root][INFO] - Training Epoch: 1/2, step 1923/53949 completed (loss: 3.0490522384643555, acc: 0.3142857253551483)
[2025-02-17 17:51:00,542][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:51:00,771][root][INFO] - Training Epoch: 1/2, step 1924/53949 completed (loss: 3.602388381958008, acc: 0.17391304671764374)
[2025-02-17 17:51:00,948][slam_llm.models.slam_model][INFO] - modality encoder
[2025-02-17 17:51:01,172][root][INFO] - Training Epoch: 1/2, step 1925/53949 completed (loss: 3.3471310138702393, acc: 0.1875)
