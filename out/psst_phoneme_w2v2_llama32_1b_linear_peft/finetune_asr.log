[2024-11-13 07:29:11,398][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-13 07:29:11,399][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-13 07:29:11,399][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'w2v2', 'encoder_ds_rate': 2, 'encoder_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-13 07:29:11,399][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_w2v2_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-13_07-29-10.txt', 'log_interval': 5}
[2024-11-13 07:29:32,872][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-11-13 07:29:32,874][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2024-11-13 07:29:32,876][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-11-13 07:29:32,877][slam_llm.utils.train_utils][INFO] - --> w2v2 has 0.0 Million params

[2024-11-13 07:29:38,884][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 07:29:38,889][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-13 07:29:38,889][slam_llm.models.slam_model][INFO] - setup peft...
[2024-11-13 07:29:39,020][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 07:29:39,022][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-11-13 07:29:39,141][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-13 07:29:39,141][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-11-13 07:29:39,141][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-13 07:29:39,146][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-11-13 07:29:41,876][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-11-13 07:29:42,852][root][INFO] - --> Training Set Length = 2298
[2024-11-13 07:29:42,872][root][INFO] - --> Validation Set Length = 341
[2024-11-13 07:29:42,873][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 07:29:42,874][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 07:29:44,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:45,312][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-13 07:29:46,052][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 8.974398612976074, acc: 0.03703703731298447)
[2024-11-13 07:29:46,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:46,487][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 8.256830215454102, acc: 0.03999999910593033)
[2024-11-13 07:29:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:46,829][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 8.073149681091309, acc: 0.054054055362939835)
[2024-11-13 07:29:46,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:47,169][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 7.6276936531066895, acc: 0.0)
[2024-11-13 07:29:47,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:47,527][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 7.375458717346191, acc: 0.054054055362939835)
[2024-11-13 07:29:47,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:47,860][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 8.02211856842041, acc: 0.0)
[2024-11-13 07:29:47,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:48,188][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 7.982990264892578, acc: 0.06122449040412903)
[2024-11-13 07:29:48,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:48,538][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 8.1155366897583, acc: 0.0)
[2024-11-13 07:29:48,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:48,938][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.770994186401367, acc: 0.0)
[2024-11-13 07:29:49,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:49,291][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 7.707411766052246, acc: 0.03846153989434242)
[2024-11-13 07:29:49,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:49,669][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.716306686401367, acc: 0.0)
[2024-11-13 07:29:49,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:50,026][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 7.47192907333374, acc: 0.0)
[2024-11-13 07:29:50,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:50,339][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 8.099906921386719, acc: 0.0)
[2024-11-13 07:29:50,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:50,645][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 7.3204665184021, acc: 0.043478261679410934)
[2024-11-13 07:29:50,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:51,026][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 7.535820484161377, acc: 0.0)
[2024-11-13 07:29:51,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:51,371][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 6.826731204986572, acc: 0.020408162847161293)
[2024-11-13 07:29:51,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:51,741][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.676382064819336, acc: 0.05263157933950424)
[2024-11-13 07:29:51,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:52,073][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.452349662780762, acc: 0.0)
[2024-11-13 07:29:52,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:52,328][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.670334815979004, acc: 0.0555555559694767)
[2024-11-13 07:29:52,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:52,638][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 8.124948501586914, acc: 0.05263157933950424)
[2024-11-13 07:29:52,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:52,946][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 8.181944847106934, acc: 0.03846153989434242)
[2024-11-13 07:29:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:53,299][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 7.700227737426758, acc: 0.0)
[2024-11-13 07:29:53,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:53,629][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.469430923461914, acc: 0.0)
[2024-11-13 07:29:53,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:53,987][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 9.040410995483398, acc: 0.0)
[2024-11-13 07:29:54,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:54,296][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.742673873901367, acc: 0.0)
[2024-11-13 07:29:54,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:54,608][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 6.359769344329834, acc: 0.0)
[2024-11-13 07:29:54,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:54,891][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 5.944367408752441, acc: 0.06849315017461777)
[2024-11-13 07:29:55,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:55,623][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 4.423493385314941, acc: 0.17786560952663422)
[2024-11-13 07:29:55,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:55,987][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.8986992835998535, acc: 0.023255813866853714)
[2024-11-13 07:29:56,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:56,372][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.561773300170898, acc: 0.16867469251155853)
[2024-11-13 07:29:56,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:56,768][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.493265151977539, acc: 0.07407407462596893)
[2024-11-13 07:29:56,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:57,139][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 8.134904861450195, acc: 0.0)
[2024-11-13 07:29:57,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:57,474][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 7.490019798278809, acc: 0.03703703731298447)
[2024-11-13 07:29:57,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:57,878][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 8.2925386428833, acc: 0.043478261679410934)
[2024-11-13 07:29:57,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:58,213][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 5.817830562591553, acc: 0.10924369841814041)
[2024-11-13 07:29:58,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:58,601][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.771071910858154, acc: 0.14754098653793335)
[2024-11-13 07:29:58,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:58,959][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.69469690322876, acc: 0.0793650820851326)
[2024-11-13 07:29:59,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:59,310][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 6.5835065841674805, acc: 0.016949152573943138)
[2024-11-13 07:29:59,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:59,643][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 5.306333541870117, acc: 0.17241379618644714)
[2024-11-13 07:29:59,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:29:59,954][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 8.63062858581543, acc: 0.0476190485060215)
[2024-11-13 07:30:00,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:00,275][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 7.257203102111816, acc: 0.03846153989434242)
[2024-11-13 07:30:00,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:00,623][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.218310356140137, acc: 0.1621621549129486)
[2024-11-13 07:30:00,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:00,963][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.802536964416504, acc: 0.0923076942563057)
[2024-11-13 07:30:01,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:01,334][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.446286678314209, acc: 0.17171716690063477)
[2024-11-13 07:30:01,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:01,674][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.700647830963135, acc: 0.22680412232875824)
[2024-11-13 07:30:01,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:02,023][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 5.145084381103516, acc: 0.14705882966518402)
[2024-11-13 07:30:02,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:02,352][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 8.354604721069336, acc: 0.0)
[2024-11-13 07:30:02,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:02,670][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 7.069103240966797, acc: 0.07407407462596893)
[2024-11-13 07:30:02,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:02,972][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 7.533895969390869, acc: 0.0357142873108387)
[2024-11-13 07:30:03,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:03,277][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.628357887268066, acc: 0.0)
[2024-11-13 07:30:03,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:03,626][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.613229751586914, acc: 0.14035087823867798)
[2024-11-13 07:30:03,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:03,974][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.64641809463501, acc: 0.1269841343164444)
[2024-11-13 07:30:04,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:04,322][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.8071136474609375, acc: 0.0845070406794548)
[2024-11-13 07:30:04,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:04,696][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.712855339050293, acc: 0.23999999463558197)
[2024-11-13 07:30:04,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:05,074][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.979629993438721, acc: 0.027027027681469917)
[2024-11-13 07:30:05,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:05,477][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 7.597611427307129, acc: 0.0)
[2024-11-13 07:30:05,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:06,789][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.511812925338745, acc: 0.35494881868362427)
[2024-11-13 07:30:06,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:07,614][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.8060295581817627, acc: 0.27886709570884705)
[2024-11-13 07:30:07,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:08,098][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 4.18028450012207, acc: 0.23863635957241058)
[2024-11-13 07:30:08,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:08,559][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.408628463745117, acc: 0.2132352888584137)
[2024-11-13 07:30:08,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:09,004][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 4.173986911773682, acc: 0.2246376872062683)
[2024-11-13 07:30:09,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:09,351][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.52354097366333, acc: 0.22499999403953552)
[2024-11-13 07:30:09,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:09,666][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 6.046751976013184, acc: 0.05882352963089943)
[2024-11-13 07:30:09,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:09,983][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 6.258238315582275, acc: 0.0555555559694767)
[2024-11-13 07:30:10,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:10,309][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 4.2247633934021, acc: 0.3125)
[2024-11-13 07:30:10,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:10,644][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 5.204136371612549, acc: 0.3103448152542114)
[2024-11-13 07:30:10,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:10,977][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 4.884118556976318, acc: 0.2142857164144516)
[2024-11-13 07:30:11,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:11,329][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 5.235986709594727, acc: 0.06666667014360428)
[2024-11-13 07:30:11,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:11,658][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 6.78494119644165, acc: 0.03999999910593033)
[2024-11-13 07:30:11,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:12,004][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 5.797680854797363, acc: 0.1111111119389534)
[2024-11-13 07:30:12,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:12,376][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 6.360249996185303, acc: 0.06060606241226196)
[2024-11-13 07:30:12,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:12,699][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 4.310651779174805, acc: 0.23529411852359772)
[2024-11-13 07:30:12,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:13,070][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 3.833754301071167, acc: 0.2380952388048172)
[2024-11-13 07:30:13,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:13,451][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.144560813903809, acc: 0.2153846174478531)
[2024-11-13 07:30:13,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:13,821][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 4.92059326171875, acc: 0.08163265138864517)
[2024-11-13 07:30:13,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:14,153][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.6097259521484375, acc: 0.09701492637395859)
[2024-11-13 07:30:14,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:14,494][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 3.911032199859619, acc: 0.2664233446121216)
[2024-11-13 07:30:14,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:14,874][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 6.90743350982666, acc: 0.0)
[2024-11-13 07:30:14,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:15,168][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 5.857879638671875, acc: 0.0833333358168602)
[2024-11-13 07:30:15,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:15,415][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 5.28285551071167, acc: 0.03030303120613098)
[2024-11-13 07:30:15,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:15,690][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 5.582126140594482, acc: 0.03846153989434242)
[2024-11-13 07:30:15,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:16,007][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 4.873898029327393, acc: 0.13461539149284363)
[2024-11-13 07:30:16,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:16,272][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 4.871005535125732, acc: 0.1538461595773697)
[2024-11-13 07:30:16,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:16,525][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 4.253353118896484, acc: 0.15625)
[2024-11-13 07:30:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:16,819][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 4.757024765014648, acc: 0.15942029654979706)
[2024-11-13 07:30:16,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:17,127][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 4.6134796142578125, acc: 0.10000000149011612)
[2024-11-13 07:30:17,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:17,399][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 5.717226982116699, acc: 0.08695652335882187)
[2024-11-13 07:30:17,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:17,778][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 4.737129211425781, acc: 0.20000000298023224)
[2024-11-13 07:30:17,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:18,082][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 4.043354511260986, acc: 0.25242719054222107)
[2024-11-13 07:30:18,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:18,803][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 3.8872873783111572, acc: 0.29611650109291077)
[2024-11-13 07:30:18,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:19,421][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 4.224654197692871, acc: 0.1827957034111023)
[2024-11-13 07:30:19,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:20,015][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.38142466545105, acc: 0.34913793206214905)
[2024-11-13 07:30:20,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:20,588][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 3.7807767391204834, acc: 0.31578946113586426)
[2024-11-13 07:30:20,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:21,280][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 3.818939447402954, acc: 0.22772277891635895)
[2024-11-13 07:30:21,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:21,567][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 4.066069602966309, acc: 0.20967741310596466)
[2024-11-13 07:30:21,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:21,920][root][INFO] - Training Epoch: 1/10, step 95/574 completed (loss: 4.228768825531006, acc: 0.24637681245803833)
[2024-11-13 07:30:22,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:22,276][root][INFO] - Training Epoch: 1/10, step 96/574 completed (loss: 4.08372163772583, acc: 0.1596638709306717)
[2024-11-13 07:30:22,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:22,612][root][INFO] - Training Epoch: 1/10, step 97/574 completed (loss: 4.0375494956970215, acc: 0.16346153616905212)
[2024-11-13 07:30:22,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:22,977][root][INFO] - Training Epoch: 1/10, step 98/574 completed (loss: 4.04451847076416, acc: 0.18248175084590912)
[2024-11-13 07:30:23,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:23,287][root][INFO] - Training Epoch: 1/10, step 99/574 completed (loss: 4.791856288909912, acc: 0.1492537260055542)
[2024-11-13 07:30:23,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:23,629][root][INFO] - Training Epoch: 1/10, step 100/574 completed (loss: 5.416748046875, acc: 0.05000000074505806)
[2024-11-13 07:30:23,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:23,953][root][INFO] - Training Epoch: 1/10, step 101/574 completed (loss: 4.734107494354248, acc: 0.09090909361839294)
[2024-11-13 07:30:24,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:24,302][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 3.9195938110351562, acc: 0.17391304671764374)
[2024-11-13 07:30:24,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:24,614][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 3.758864641189575, acc: 0.09090909361839294)
[2024-11-13 07:30:24,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:24,944][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 4.046804904937744, acc: 0.1551724076271057)
[2024-11-13 07:30:25,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:25,284][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 3.9867563247680664, acc: 0.1627907007932663)
[2024-11-13 07:30:25,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:25,667][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 3.623384714126587, acc: 0.2800000011920929)
[2024-11-13 07:30:25,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:25,991][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 3.9263641834259033, acc: 0.1764705926179886)
[2024-11-13 07:30:26,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:26,329][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 3.914875030517578, acc: 0.26923078298568726)
[2024-11-13 07:30:26,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:26,676][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 4.018535614013672, acc: 0.2142857164144516)
[2024-11-13 07:30:26,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:27,006][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 3.982481002807617, acc: 0.2769230902194977)
[2024-11-13 07:30:27,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:27,361][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 3.6746561527252197, acc: 0.22807016968727112)
[2024-11-13 07:30:27,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:27,747][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 3.3731956481933594, acc: 0.2982456088066101)
[2024-11-13 07:30:27,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:28,134][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 3.866631031036377, acc: 0.3333333432674408)
[2024-11-13 07:30:28,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:28,499][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 3.4814391136169434, acc: 0.36734694242477417)
[2024-11-13 07:30:28,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:28,840][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 3.64982533454895, acc: 0.22727273404598236)
[2024-11-13 07:30:28,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:29,181][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.227961301803589, acc: 0.2857142984867096)
[2024-11-13 07:30:29,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:29,484][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.28452730178833, acc: 0.30894309282302856)
[2024-11-13 07:30:29,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:29,848][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 3.2216830253601074, acc: 0.35483869910240173)
[2024-11-13 07:30:29,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:30,479][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.115737199783325, acc: 0.32699620723724365)
[2024-11-13 07:30:30,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:30,801][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 3.269768714904785, acc: 0.2666666805744171)
[2024-11-13 07:30:30,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:31,128][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 3.4903292655944824, acc: 0.2884615361690521)
[2024-11-13 07:30:31,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:31,415][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 3.9264917373657227, acc: 0.125)
[2024-11-13 07:30:31,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:31,726][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 3.2951877117156982, acc: 0.21052631735801697)
[2024-11-13 07:30:31,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:32,098][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.446242332458496, acc: 0.20858895778656006)
[2024-11-13 07:30:32,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:32,434][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 2.6485965251922607, acc: 0.3680555522441864)
[2024-11-13 07:30:32,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:32,824][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.198154926300049, acc: 0.24166665971279144)
[2024-11-13 07:30:32,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:33,155][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.1387219429016113, acc: 0.2380952388048172)
[2024-11-13 07:30:33,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:33,491][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.2275259494781494, acc: 0.26153847575187683)
[2024-11-13 07:30:33,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:33,867][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 2.6697940826416016, acc: 0.38235294818878174)
[2024-11-13 07:30:33,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:34,186][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.540029287338257, acc: 0.3076923191547394)
[2024-11-13 07:30:34,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:34,503][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 2.6549952030181885, acc: 0.43478259444236755)
[2024-11-13 07:30:34,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:34,861][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.4939167499542236, acc: 0.21875)
[2024-11-13 07:30:34,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:35,192][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 2.616297721862793, acc: 0.30434781312942505)
[2024-11-13 07:30:35,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:35,568][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 2.9598207473754883, acc: 0.2571428716182709)
[2024-11-13 07:30:35,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:35,918][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 2.805856466293335, acc: 0.3076923191547394)
[2024-11-13 07:30:36,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:36,235][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.4736502170562744, acc: 0.190476194024086)
[2024-11-13 07:30:36,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:36,555][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 2.4188528060913086, acc: 0.4000000059604645)
[2024-11-13 07:30:36,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:36,898][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 2.552429437637329, acc: 0.3478260934352875)
[2024-11-13 07:30:36,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:37,222][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 3.7149829864501953, acc: 0.2857142984867096)
[2024-11-13 07:30:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:37,527][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 3.0215213298797607, acc: 0.3461538553237915)
[2024-11-13 07:30:37,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:37,878][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 3.2228901386260986, acc: 0.25806450843811035)
[2024-11-13 07:30:37,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:38,228][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.0377814769744873, acc: 0.2432432472705841)
[2024-11-13 07:30:39,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:39,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:39,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:40,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:40,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:40,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:41,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:41,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:41,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:42,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:42,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:42,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:43,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:43,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:43,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:43,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:44,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:44,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:44,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:44,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:45,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:45,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:45,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:45,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:46,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:46,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:46,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:47,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:47,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:47,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:48,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:48,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:48,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:49,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:49,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:49,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:50,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:50,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:50,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:50,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:51,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:51,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:51,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:52,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:52,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:52,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:52,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:53,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:53,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:53,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:53,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:54,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:54,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:54,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:55,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:55,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:55,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:56,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:56,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:56,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:57,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:57,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:57,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:58,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:58,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:58,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:59,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:59,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:30:59,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:00,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:00,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:00,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:00,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:01,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:02,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:02,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:02,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:03,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:03,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:03,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:03,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:04,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:04,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:05,163][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(20.9305, device='cuda:0') eval_epoch_loss=tensor(3.0412, device='cuda:0') eval_epoch_acc=tensor(0.2740, device='cuda:0')
[2024-11-13 07:31:05,166][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:31:05,166][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:31:05,535][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_1_step_143_loss_3.041207790374756/model.pt
[2024-11-13 07:31:05,538][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:31:05,539][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.041207790374756
[2024-11-13 07:31:05,539][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.27402061223983765
[2024-11-13 07:31:05,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:05,995][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 2.530250310897827, acc: 0.4035087823867798)
[2024-11-13 07:31:06,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:06,303][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 2.412576675415039, acc: 0.4776119291782379)
[2024-11-13 07:31:06,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:06,626][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 2.9032208919525146, acc: 0.29591837525367737)
[2024-11-13 07:31:06,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:06,994][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 2.72711181640625, acc: 0.2978723347187042)
[2024-11-13 07:31:07,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:07,296][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 2.5990214347839355, acc: 0.37142857909202576)
[2024-11-13 07:31:07,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:07,615][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 3.3121635913848877, acc: 0.25)
[2024-11-13 07:31:07,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:07,853][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 2.522514581680298, acc: 0.3913043439388275)
[2024-11-13 07:31:07,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:08,129][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 2.9704320430755615, acc: 0.27586206793785095)
[2024-11-13 07:31:08,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:08,462][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 2.6866049766540527, acc: 0.28260868787765503)
[2024-11-13 07:31:08,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:08,775][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 2.5407142639160156, acc: 0.2711864411830902)
[2024-11-13 07:31:08,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:09,047][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 3.1686391830444336, acc: 0.24561403691768646)
[2024-11-13 07:31:09,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:09,362][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 2.7466299533843994, acc: 0.3513513505458832)
[2024-11-13 07:31:09,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:09,665][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 2.899967670440674, acc: 0.3928571343421936)
[2024-11-13 07:31:09,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:09,936][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.287092685699463, acc: 0.47826087474823)
[2024-11-13 07:31:09,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:10,283][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 2.818674325942993, acc: 0.2631579041481018)
[2024-11-13 07:31:10,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:11,157][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 3.022181510925293, acc: 0.3918918967247009)
[2024-11-13 07:31:11,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:11,465][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 2.8269460201263428, acc: 0.31481480598449707)
[2024-11-13 07:31:11,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:11,864][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 2.950258255004883, acc: 0.3488371968269348)
[2024-11-13 07:31:11,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:12,317][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 2.694476366043091, acc: 0.364705890417099)
[2024-11-13 07:31:12,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:12,746][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 2.9776899814605713, acc: 0.31460675597190857)
[2024-11-13 07:31:12,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:13,046][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 2.638868808746338, acc: 0.3863636255264282)
[2024-11-13 07:31:13,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:13,357][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 2.69816255569458, acc: 0.3333333432674408)
[2024-11-13 07:31:13,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:13,702][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 3.0696568489074707, acc: 0.2068965584039688)
[2024-11-13 07:31:13,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:14,014][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 2.0895609855651855, acc: 0.5102040767669678)
[2024-11-13 07:31:14,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:14,321][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 2.5816855430603027, acc: 0.3199999928474426)
[2024-11-13 07:31:14,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:14,662][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 2.4550347328186035, acc: 0.3888888955116272)
[2024-11-13 07:31:14,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:14,977][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 2.566807270050049, acc: 0.3235294222831726)
[2024-11-13 07:31:15,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:15,684][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 3.0638043880462646, acc: 0.28082191944122314)
[2024-11-13 07:31:15,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:16,027][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 2.6310348510742188, acc: 0.3333333432674408)
[2024-11-13 07:31:16,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:16,328][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 3.2989587783813477, acc: 0.18518517911434174)
[2024-11-13 07:31:16,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:16,668][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 2.7426886558532715, acc: 0.3214285671710968)
[2024-11-13 07:31:16,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:17,097][root][INFO] - Training Epoch: 1/10, step 174/574 completed (loss: 2.2388014793395996, acc: 0.45132744312286377)
[2024-11-13 07:31:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:17,399][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 2.6543691158294678, acc: 0.30434781312942505)
[2024-11-13 07:31:17,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:17,736][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 2.9102120399475098, acc: 0.25)
[2024-11-13 07:31:17,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:18,381][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 2.937011957168579, acc: 0.2748091518878937)
[2024-11-13 07:31:18,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:18,884][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 3.059983253479004, acc: 0.24444444477558136)
[2024-11-13 07:31:18,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:19,179][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 2.747084379196167, acc: 0.2950819730758667)
[2024-11-13 07:31:19,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:19,493][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 2.450287103652954, acc: 0.375)
[2024-11-13 07:31:19,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:19,822][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 2.607741117477417, acc: 0.36000001430511475)
[2024-11-13 07:31:19,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:20,160][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 2.9332244396209717, acc: 0.1785714328289032)
[2024-11-13 07:31:20,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:20,491][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 2.991710662841797, acc: 0.24390244483947754)
[2024-11-13 07:31:20,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:20,849][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 2.9107728004455566, acc: 0.2839879095554352)
[2024-11-13 07:31:20,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:21,122][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 2.953428268432617, acc: 0.24207492172718048)
[2024-11-13 07:31:21,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:21,540][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 2.976200819015503, acc: 0.24375000596046448)
[2024-11-13 07:31:21,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:21,988][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 2.7209460735321045, acc: 0.2926829159259796)
[2024-11-13 07:31:22,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:22,353][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 2.7194244861602783, acc: 0.29893237352371216)
[2024-11-13 07:31:22,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:22,675][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 3.499717950820923, acc: 0.23999999463558197)
[2024-11-13 07:31:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:23,124][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 2.730987071990967, acc: 0.2906976640224457)
[2024-11-13 07:31:23,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:23,695][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 2.746683359146118, acc: 0.3253968358039856)
[2024-11-13 07:31:23,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:24,323][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 2.6783766746520996, acc: 0.34090909361839294)
[2024-11-13 07:31:24,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:24,863][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 2.3895103931427, acc: 0.4000000059604645)
[2024-11-13 07:31:25,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:25,592][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 2.3566925525665283, acc: 0.40740740299224854)
[2024-11-13 07:31:25,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:26,246][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 2.4071760177612305, acc: 0.4032258093357086)
[2024-11-13 07:31:26,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:26,523][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 2.162256956100464, acc: 0.3928571343421936)
[2024-11-13 07:31:26,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:26,852][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 2.8678908348083496, acc: 0.25)
[2024-11-13 07:31:26,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:27,137][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 3.121939182281494, acc: 0.25)
[2024-11-13 07:31:27,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:27,441][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 2.5819783210754395, acc: 0.40441176295280457)
[2024-11-13 07:31:27,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:27,786][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 2.6583669185638428, acc: 0.32203391194343567)
[2024-11-13 07:31:27,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:28,113][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 2.7233502864837646, acc: 0.38805970549583435)
[2024-11-13 07:31:28,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:28,437][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 2.887894630432129, acc: 0.3106796145439148)
[2024-11-13 07:31:28,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:28,736][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 2.5896646976470947, acc: 0.3650793731212616)
[2024-11-13 07:31:28,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:29,032][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 2.707721471786499, acc: 0.2637362778186798)
[2024-11-13 07:31:29,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:29,351][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 2.7646355628967285, acc: 0.2959641218185425)
[2024-11-13 07:31:29,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:29,694][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 2.6100425720214844, acc: 0.3700787425041199)
[2024-11-13 07:31:29,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:30,008][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 2.682917594909668, acc: 0.32758620381355286)
[2024-11-13 07:31:30,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:30,332][root][INFO] - Training Epoch: 1/10, step 208/574 completed (loss: 2.429851531982422, acc: 0.4311594069004059)
[2024-11-13 07:31:30,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:30,660][root][INFO] - Training Epoch: 1/10, step 209/574 completed (loss: 2.6985037326812744, acc: 0.32295718789100647)
[2024-11-13 07:31:30,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:30,987][root][INFO] - Training Epoch: 1/10, step 210/574 completed (loss: 2.811387777328491, acc: 0.260869562625885)
[2024-11-13 07:31:31,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:31,295][root][INFO] - Training Epoch: 1/10, step 211/574 completed (loss: 2.5709033012390137, acc: 0.43478259444236755)
[2024-11-13 07:31:31,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:31,562][root][INFO] - Training Epoch: 1/10, step 212/574 completed (loss: 2.915243625640869, acc: 0.25)
[2024-11-13 07:31:31,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:31,865][root][INFO] - Training Epoch: 1/10, step 213/574 completed (loss: 2.5152318477630615, acc: 0.27659574151039124)
[2024-11-13 07:31:31,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:32,374][root][INFO] - Training Epoch: 1/10, step 214/574 completed (loss: 2.569110870361328, acc: 0.3076923191547394)
[2024-11-13 07:31:32,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:32,711][root][INFO] - Training Epoch: 1/10, step 215/574 completed (loss: 2.408407688140869, acc: 0.29729729890823364)
[2024-11-13 07:31:32,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:33,057][root][INFO] - Training Epoch: 1/10, step 216/574 completed (loss: 2.5024662017822266, acc: 0.3604651093482971)
[2024-11-13 07:31:33,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:33,478][root][INFO] - Training Epoch: 1/10, step 217/574 completed (loss: 2.3554980754852295, acc: 0.36036035418510437)
[2024-11-13 07:31:33,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:33,813][root][INFO] - Training Epoch: 1/10, step 218/574 completed (loss: 2.427034854888916, acc: 0.3222222328186035)
[2024-11-13 07:31:33,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:34,105][root][INFO] - Training Epoch: 1/10, step 219/574 completed (loss: 1.9936437606811523, acc: 0.39393940567970276)
[2024-11-13 07:31:34,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:34,339][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 1.8441945314407349, acc: 0.5555555820465088)
[2024-11-13 07:31:34,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:34,651][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 1.8386681079864502, acc: 0.4000000059604645)
[2024-11-13 07:31:34,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:34,954][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 2.619170904159546, acc: 0.3461538553237915)
[2024-11-13 07:31:35,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:35,511][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 2.3148789405822754, acc: 0.3695652186870575)
[2024-11-13 07:31:35,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:35,945][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 2.5599751472473145, acc: 0.3068181872367859)
[2024-11-13 07:31:36,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:36,316][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 2.615328311920166, acc: 0.3191489279270172)
[2024-11-13 07:31:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:36,635][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 2.8495771884918213, acc: 0.2641509473323822)
[2024-11-13 07:31:36,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:36,952][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 2.40779447555542, acc: 0.4000000059604645)
[2024-11-13 07:31:37,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:37,234][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 2.090728759765625, acc: 0.4651162922382355)
[2024-11-13 07:31:37,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:37,601][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 2.248162269592285, acc: 0.4333333373069763)
[2024-11-13 07:31:37,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:37,934][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 2.80733060836792, acc: 0.3052631616592407)
[2024-11-13 07:31:38,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:38,234][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 2.3522720336914062, acc: 0.3444444537162781)
[2024-11-13 07:31:38,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:38,593][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 2.19642972946167, acc: 0.4888888895511627)
[2024-11-13 07:31:38,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:38,996][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 2.1510655879974365, acc: 0.4678899049758911)
[2024-11-13 07:31:39,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:39,373][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 2.169612169265747, acc: 0.4153846204280853)
[2024-11-13 07:31:39,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:39,688][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 2.0430898666381836, acc: 0.4736842215061188)
[2024-11-13 07:31:39,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:39,984][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 1.9587072134017944, acc: 0.4166666567325592)
[2024-11-13 07:31:40,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:40,323][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 2.5611352920532227, acc: 0.3181818127632141)
[2024-11-13 07:31:40,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:40,658][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 1.943426489830017, acc: 0.4444444477558136)
[2024-11-13 07:31:40,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:40,959][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.0523645877838135, acc: 0.4571428596973419)
[2024-11-13 07:31:41,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:41,289][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 2.0070791244506836, acc: 0.40909090638160706)
[2024-11-13 07:31:41,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:41,596][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 2.284311056137085, acc: 0.47727271914482117)
[2024-11-13 07:31:41,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:42,057][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 2.3131256103515625, acc: 0.35483869910240173)
[2024-11-13 07:31:42,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:42,455][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 2.2121007442474365, acc: 0.3636363744735718)
[2024-11-13 07:31:42,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:42,754][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 1.7032661437988281, acc: 0.523809552192688)
[2024-11-13 07:31:42,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:43,067][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 2.349632740020752, acc: 0.3461538553237915)
[2024-11-13 07:31:43,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:43,372][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 2.856135368347168, acc: 0.19354838132858276)
[2024-11-13 07:31:43,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:43,647][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.1101632118225098, acc: 0.30000001192092896)
[2024-11-13 07:31:43,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:44,003][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 2.271272897720337, acc: 0.4324324429035187)
[2024-11-13 07:31:44,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:44,351][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 2.3973045349121094, acc: 0.37837839126586914)
[2024-11-13 07:31:44,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:44,685][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 2.406244993209839, acc: 0.3243243098258972)
[2024-11-13 07:31:44,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:45,006][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 2.486368179321289, acc: 0.4117647111415863)
[2024-11-13 07:31:45,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:45,377][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 1.6922707557678223, acc: 0.5853658318519592)
[2024-11-13 07:31:45,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:45,714][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 1.56609308719635, acc: 0.6800000071525574)
[2024-11-13 07:31:45,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:46,039][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 1.4192181825637817, acc: 0.5199999809265137)
[2024-11-13 07:31:46,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:46,353][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 2.3804244995117188, acc: 0.35483869910240173)
[2024-11-13 07:31:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:46,651][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 2.467153549194336, acc: 0.2982456088066101)
[2024-11-13 07:31:46,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:46,976][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 2.422433853149414, acc: 0.37142857909202576)
[2024-11-13 07:31:47,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:47,360][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 2.3646793365478516, acc: 0.43421053886413574)
[2024-11-13 07:31:47,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:47,831][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 2.3909060955047607, acc: 0.38679245114326477)
[2024-11-13 07:31:47,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:48,283][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 2.572303295135498, acc: 0.40833333134651184)
[2024-11-13 07:31:48,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:48,578][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 2.2418642044067383, acc: 0.4722222089767456)
[2024-11-13 07:31:48,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:48,925][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 2.4908902645111084, acc: 0.35483869910240173)
[2024-11-13 07:31:49,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:49,267][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 2.8043456077575684, acc: 0.23999999463558197)
[2024-11-13 07:31:49,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:49,583][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 2.5372111797332764, acc: 0.3541666567325592)
[2024-11-13 07:31:49,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:50,170][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 2.6926145553588867, acc: 0.31200000643730164)
[2024-11-13 07:31:50,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:50,475][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 2.413862705230713, acc: 0.3932584226131439)
[2024-11-13 07:31:50,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:50,801][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 2.5471749305725098, acc: 0.3513513505458832)
[2024-11-13 07:31:50,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:51,166][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 1.933364748954773, acc: 0.48275861144065857)
[2024-11-13 07:31:51,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:51,438][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 1.9573615789413452, acc: 0.40909090638160706)
[2024-11-13 07:31:51,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:51,746][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 1.7047611474990845, acc: 0.40909090638160706)
[2024-11-13 07:31:51,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:52,039][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 1.7573809623718262, acc: 0.53125)
[2024-11-13 07:31:52,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:52,336][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 1.960695505142212, acc: 0.5333333611488342)
[2024-11-13 07:31:52,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:52,730][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 2.61966609954834, acc: 0.38333332538604736)
[2024-11-13 07:31:52,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:53,133][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.159550189971924, acc: 0.53125)
[2024-11-13 07:31:53,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:53,465][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 1.7082849740982056, acc: 0.6000000238418579)
[2024-11-13 07:31:53,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:53,782][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 2.171419143676758, acc: 0.37931033968925476)
[2024-11-13 07:31:53,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:54,077][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 1.9022237062454224, acc: 0.4000000059604645)
[2024-11-13 07:31:54,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:54,381][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 2.584202289581299, acc: 0.38297873735427856)
[2024-11-13 07:31:54,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:54,692][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 2.1326112747192383, acc: 0.4375)
[2024-11-13 07:31:54,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:55,018][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.2249348163604736, acc: 0.4318181872367859)
[2024-11-13 07:31:55,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:55,349][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 2.684157609939575, acc: 0.33734938502311707)
[2024-11-13 07:31:55,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:55,639][root][INFO] - Training Epoch: 1/10, step 282/574 completed (loss: 2.5388102531433105, acc: 0.37962964177131653)
[2024-11-13 07:31:55,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:55,943][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 2.644667863845825, acc: 0.34210526943206787)
[2024-11-13 07:31:56,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:56,281][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 2.5576462745666504, acc: 0.3529411852359772)
[2024-11-13 07:31:56,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:56,580][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 2.3527088165283203, acc: 0.32499998807907104)
[2024-11-13 07:31:57,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:57,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:57,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:58,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:58,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:58,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:58,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:59,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:59,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:59,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:31:59,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:00,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:00,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:00,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:01,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:01,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:01,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:01,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:02,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:02,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:02,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:03,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:03,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:03,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:03,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:04,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:04,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:04,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:05,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:05,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:05,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:05,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:06,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:06,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:06,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:07,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:07,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:07,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:07,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:08,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:08,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:08,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:08,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:09,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:09,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:09,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:10,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:10,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:10,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:10,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:11,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:11,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:11,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:11,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:12,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:12,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:12,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:12,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:13,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:13,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:13,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:14,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:14,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:14,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:14,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:15,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:15,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:15,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:16,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:16,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:16,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:16,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:17,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:17,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:17,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:17,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:18,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:18,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:18,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:18,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:19,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:19,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:19,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:20,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:20,647][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(10.7442, device='cuda:0') eval_epoch_loss=tensor(2.3744, device='cuda:0') eval_epoch_acc=tensor(0.3880, device='cuda:0')
[2024-11-13 07:32:20,648][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:32:20,649][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:32:21,116][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_1_step_286_loss_2.3743627071380615/model.pt
[2024-11-13 07:32:21,129][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:32:21,131][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.3743627071380615
[2024-11-13 07:32:21,131][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.38802528381347656
[2024-11-13 07:32:21,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:21,555][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 2.4267196655273438, acc: 0.3203125)
[2024-11-13 07:32:21,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:21,920][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 2.7088446617126465, acc: 0.2240000069141388)
[2024-11-13 07:32:22,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:22,303][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 2.321094274520874, acc: 0.3956044018268585)
[2024-11-13 07:32:22,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:22,699][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 2.7153983116149902, acc: 0.27950310707092285)
[2024-11-13 07:32:22,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:23,095][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 2.731562376022339, acc: 0.3041236996650696)
[2024-11-13 07:32:23,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:23,464][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 1.7118892669677734, acc: 0.6363636255264282)
[2024-11-13 07:32:23,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:23,795][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.4582090377807617, acc: 0.4047619104385376)
[2024-11-13 07:32:23,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:24,159][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 2.1618056297302246, acc: 0.4655172526836395)
[2024-11-13 07:32:24,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:24,530][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 1.7782056331634521, acc: 0.5636363625526428)
[2024-11-13 07:32:24,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:24,976][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.1277570724487305, acc: 0.47422680258750916)
[2024-11-13 07:32:25,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:25,273][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 2.3717799186706543, acc: 0.37931033968925476)
[2024-11-13 07:32:25,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:25,617][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 2.0240299701690674, acc: 0.5185185074806213)
[2024-11-13 07:32:25,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:25,992][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 2.2611441612243652, acc: 0.42105263471603394)
[2024-11-13 07:32:26,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:26,388][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 2.491250514984131, acc: 0.4464285671710968)
[2024-11-13 07:32:26,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:26,720][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 2.2542450428009033, acc: 0.375)
[2024-11-13 07:32:26,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:27,028][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 2.6293227672576904, acc: 0.35849055647850037)
[2024-11-13 07:32:27,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:27,358][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 1.7273067235946655, acc: 0.5094339847564697)
[2024-11-13 07:32:27,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:27,678][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 1.9422645568847656, acc: 0.47058823704719543)
[2024-11-13 07:32:27,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:28,073][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 2.616553783416748, acc: 0.34375)
[2024-11-13 07:32:28,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:28,419][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 2.0271267890930176, acc: 0.5409836173057556)
[2024-11-13 07:32:28,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:28,792][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 1.6678603887557983, acc: 0.5666666626930237)
[2024-11-13 07:32:28,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:29,123][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 1.3728984594345093, acc: 0.6842105388641357)
[2024-11-13 07:32:29,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:29,444][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 2.672734498977661, acc: 0.3333333432674408)
[2024-11-13 07:32:29,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:29,801][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.218581199645996, acc: 0.4444444477558136)
[2024-11-13 07:32:29,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:30,155][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 2.2758638858795166, acc: 0.3253012001514435)
[2024-11-13 07:32:30,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:30,493][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 2.725527048110962, acc: 0.28205129504203796)
[2024-11-13 07:32:30,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:30,828][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 2.7766172885894775, acc: 0.2857142984867096)
[2024-11-13 07:32:30,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:31,215][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 0.9166218638420105, acc: 0.8333333134651184)
[2024-11-13 07:32:31,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:31,610][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 1.8981084823608398, acc: 0.5)
[2024-11-13 07:32:31,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:31,949][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 1.9886937141418457, acc: 0.3870967626571655)
[2024-11-13 07:32:32,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:32,259][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 2.271968126296997, acc: 0.35483869910240173)
[2024-11-13 07:32:32,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:32,661][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 1.9209579229354858, acc: 0.5373134613037109)
[2024-11-13 07:32:32,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:33,002][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 1.7699294090270996, acc: 0.557692289352417)
[2024-11-13 07:32:33,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:33,290][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 2.6395912170410156, acc: 0.24444444477558136)
[2024-11-13 07:32:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:33,667][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 2.1788747310638428, acc: 0.4193548262119293)
[2024-11-13 07:32:33,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:34,083][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 1.5486198663711548, acc: 0.6800000071525574)
[2024-11-13 07:32:34,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:34,431][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 2.909930944442749, acc: 0.25925925374031067)
[2024-11-13 07:32:34,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:34,742][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 3.8915627002716064, acc: 0.02857142873108387)
[2024-11-13 07:32:34,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:35,134][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 2.9726903438568115, acc: 0.20512820780277252)
[2024-11-13 07:32:35,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:35,520][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 2.8717715740203857, acc: 0.26829269528388977)
[2024-11-13 07:32:35,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:35,869][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 2.4205291271209717, acc: 0.3684210479259491)
[2024-11-13 07:32:35,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:36,197][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 1.7654569149017334, acc: 0.5263158082962036)
[2024-11-13 07:32:36,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:36,545][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 1.6864798069000244, acc: 0.4642857015132904)
[2024-11-13 07:32:36,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:36,960][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 2.3903372287750244, acc: 0.25925925374031067)
[2024-11-13 07:32:37,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:37,353][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 1.5091753005981445, acc: 0.59375)
[2024-11-13 07:32:37,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:37,749][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 2.513505458831787, acc: 0.30645161867141724)
[2024-11-13 07:32:37,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:38,146][root][INFO] - Training Epoch: 1/10, step 332/574 completed (loss: 2.015148878097534, acc: 0.42105263471603394)
[2024-11-13 07:32:38,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:38,530][root][INFO] - Training Epoch: 1/10, step 333/574 completed (loss: 2.6081149578094482, acc: 0.25)
[2024-11-13 07:32:38,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:38,881][root][INFO] - Training Epoch: 1/10, step 334/574 completed (loss: 1.8824433088302612, acc: 0.5333333611488342)
[2024-11-13 07:32:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:39,207][root][INFO] - Training Epoch: 1/10, step 335/574 completed (loss: 2.366126537322998, acc: 0.31578946113586426)
[2024-11-13 07:32:39,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:39,614][root][INFO] - Training Epoch: 1/10, step 336/574 completed (loss: 2.314234972000122, acc: 0.30000001192092896)
[2024-11-13 07:32:39,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:40,004][root][INFO] - Training Epoch: 1/10, step 337/574 completed (loss: 2.47615647315979, acc: 0.3563218414783478)
[2024-11-13 07:32:40,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:40,351][root][INFO] - Training Epoch: 1/10, step 338/574 completed (loss: 2.6006019115448, acc: 0.3404255211353302)
[2024-11-13 07:32:40,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:40,715][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 2.6587705612182617, acc: 0.34939759969711304)
[2024-11-13 07:32:40,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:41,029][root][INFO] - Training Epoch: 1/10, step 340/574 completed (loss: 1.7396893501281738, acc: 0.5652173757553101)
[2024-11-13 07:32:41,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:41,301][root][INFO] - Training Epoch: 1/10, step 341/574 completed (loss: 2.6764910221099854, acc: 0.23076923191547394)
[2024-11-13 07:32:41,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:41,632][root][INFO] - Training Epoch: 1/10, step 342/574 completed (loss: 2.8613686561584473, acc: 0.3012048304080963)
[2024-11-13 07:32:41,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:42,010][root][INFO] - Training Epoch: 1/10, step 343/574 completed (loss: 2.1430070400238037, acc: 0.3962264060974121)
[2024-11-13 07:32:42,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:42,397][root][INFO] - Training Epoch: 1/10, step 344/574 completed (loss: 2.6434526443481445, acc: 0.3291139304637909)
[2024-11-13 07:32:42,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:42,772][root][INFO] - Training Epoch: 1/10, step 345/574 completed (loss: 2.4569814205169678, acc: 0.3333333432674408)
[2024-11-13 07:32:42,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:43,151][root][INFO] - Training Epoch: 1/10, step 346/574 completed (loss: 2.775282621383667, acc: 0.34328359365463257)
[2024-11-13 07:32:43,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:43,525][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 2.0161900520324707, acc: 0.6000000238418579)
[2024-11-13 07:32:43,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:43,855][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 1.8494535684585571, acc: 0.5199999809265137)
[2024-11-13 07:32:43,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:44,244][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 1.6360374689102173, acc: 0.6111111044883728)
[2024-11-13 07:32:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:44,623][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 2.203673839569092, acc: 0.41860464215278625)
[2024-11-13 07:32:44,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:44,977][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 2.193080425262451, acc: 0.38461539149284363)
[2024-11-13 07:32:45,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:45,383][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 2.231419801712036, acc: 0.3777777850627899)
[2024-11-13 07:32:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:45,803][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 1.4797613620758057, acc: 0.52173912525177)
[2024-11-13 07:32:45,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:46,136][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 2.9214651584625244, acc: 0.26923078298568726)
[2024-11-13 07:32:46,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:46,480][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 2.7382099628448486, acc: 0.2967033088207245)
[2024-11-13 07:32:46,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:46,879][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.173121213912964, acc: 0.3913043439388275)
[2024-11-13 07:32:46,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:47,247][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 2.4337775707244873, acc: 0.31521740555763245)
[2024-11-13 07:32:47,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:47,615][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 2.389756441116333, acc: 0.3265306055545807)
[2024-11-13 07:32:47,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:47,895][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 0.8552655577659607, acc: 0.75)
[2024-11-13 07:32:47,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:48,209][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 1.8796794414520264, acc: 0.42307692766189575)
[2024-11-13 07:32:48,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:48,498][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 2.403855562210083, acc: 0.31707316637039185)
[2024-11-13 07:32:48,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:48,841][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 2.0357933044433594, acc: 0.5111111402511597)
[2024-11-13 07:32:48,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:49,225][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 2.383976936340332, acc: 0.3684210479259491)
[2024-11-13 07:32:49,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:49,567][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 2.4868409633636475, acc: 0.39024388790130615)
[2024-11-13 07:32:49,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:49,911][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 2.437784194946289, acc: 0.39393940567970276)
[2024-11-13 07:32:50,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:50,289][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 1.1218708753585815, acc: 0.7083333134651184)
[2024-11-13 07:32:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:50,629][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 0.9186714291572571, acc: 0.782608687877655)
[2024-11-13 07:32:50,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:50,964][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 1.7285000085830688, acc: 0.4642857015132904)
[2024-11-13 07:32:51,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:51,270][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 1.8648240566253662, acc: 0.5)
[2024-11-13 07:32:51,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:51,743][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 2.273848533630371, acc: 0.46666666865348816)
[2024-11-13 07:32:51,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:52,328][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 1.7307466268539429, acc: 0.5754716992378235)
[2024-11-13 07:32:52,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:52,684][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.14459490776062, acc: 0.41111111640930176)
[2024-11-13 07:32:52,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:53,062][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 2.273587703704834, acc: 0.4107142984867096)
[2024-11-13 07:32:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:53,437][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 1.310766577720642, acc: 0.7142857313156128)
[2024-11-13 07:32:53,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:53,809][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 0.7627121806144714, acc: 0.8399999737739563)
[2024-11-13 07:32:53,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:54,179][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 1.1294569969177246, acc: 0.6086956262588501)
[2024-11-13 07:32:54,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:54,536][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 2.7003262042999268, acc: 0.2708333432674408)
[2024-11-13 07:32:54,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:54,918][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 2.092663049697876, acc: 0.42105263471603394)
[2024-11-13 07:32:55,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:55,417][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.0938045978546143, acc: 0.46706587076187134)
[2024-11-13 07:32:55,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:55,766][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 1.9330183267593384, acc: 0.5037593841552734)
[2024-11-13 07:32:55,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:56,505][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 2.0151968002319336, acc: 0.47593581676483154)
[2024-11-13 07:32:56,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:56,951][root][INFO] - Training Epoch: 1/10, step 382/574 completed (loss: 1.7595646381378174, acc: 0.5405405163764954)
[2024-11-13 07:32:57,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:57,292][root][INFO] - Training Epoch: 1/10, step 383/574 completed (loss: 1.3822578191757202, acc: 0.5714285969734192)
[2024-11-13 07:32:57,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:57,624][root][INFO] - Training Epoch: 1/10, step 384/574 completed (loss: 1.1542396545410156, acc: 0.6785714030265808)
[2024-11-13 07:32:57,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:57,980][root][INFO] - Training Epoch: 1/10, step 385/574 completed (loss: 2.1915946006774902, acc: 0.4375)
[2024-11-13 07:32:58,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:58,305][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 2.102996587753296, acc: 0.4722222089767456)
[2024-11-13 07:32:58,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:58,617][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 2.0242297649383545, acc: 0.4736842215061188)
[2024-11-13 07:32:58,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:58,919][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 1.6120269298553467, acc: 0.5909090638160706)
[2024-11-13 07:32:58,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:59,214][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 2.060311794281006, acc: 0.5)
[2024-11-13 07:32:59,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:59,485][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 1.9381897449493408, acc: 0.4285714328289032)
[2024-11-13 07:32:59,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:32:59,810][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 2.5385560989379883, acc: 0.35185185074806213)
[2024-11-13 07:32:59,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:00,110][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 2.614072561264038, acc: 0.34951457381248474)
[2024-11-13 07:33:00,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:00,530][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.179032564163208, acc: 0.47058823704719543)
[2024-11-13 07:33:00,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:00,854][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 2.5284299850463867, acc: 0.3733333349227905)
[2024-11-13 07:33:00,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:01,175][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.37600040435791, acc: 0.4375)
[2024-11-13 07:33:01,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:01,465][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 2.38387131690979, acc: 0.4883720874786377)
[2024-11-13 07:33:01,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:01,762][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 1.5407994985580444, acc: 0.5416666865348816)
[2024-11-13 07:33:01,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:02,068][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 1.7661159038543701, acc: 0.44186046719551086)
[2024-11-13 07:33:02,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:02,370][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 1.9573712348937988, acc: 0.47999998927116394)
[2024-11-13 07:33:02,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:02,804][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 2.0856618881225586, acc: 0.47058823704719543)
[2024-11-13 07:33:02,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:03,114][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.0813591480255127, acc: 0.4933333396911621)
[2024-11-13 07:33:03,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:03,463][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 1.6381149291992188, acc: 0.6060606241226196)
[2024-11-13 07:33:03,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:03,746][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 1.9755605459213257, acc: 0.5151515007019043)
[2024-11-13 07:33:03,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:04,062][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 1.6124873161315918, acc: 0.5161290168762207)
[2024-11-13 07:33:04,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:04,368][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 2.195024251937866, acc: 0.48148149251937866)
[2024-11-13 07:33:04,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:04,625][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 0.9421269297599792, acc: 0.7599999904632568)
[2024-11-13 07:33:04,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:04,864][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 1.2674217224121094, acc: 0.6666666865348816)
[2024-11-13 07:33:04,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:05,148][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.359285831451416, acc: 0.5925925970077515)
[2024-11-13 07:33:05,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:05,413][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.6931520700454712, acc: 0.6153846383094788)
[2024-11-13 07:33:05,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:05,726][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 1.6831868886947632, acc: 0.5862069129943848)
[2024-11-13 07:33:05,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:06,059][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 1.3067512512207031, acc: 0.6785714030265808)
[2024-11-13 07:33:06,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:06,383][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 1.3633533716201782, acc: 0.6000000238418579)
[2024-11-13 07:33:06,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:06,675][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 1.6965543031692505, acc: 0.5151515007019043)
[2024-11-13 07:33:06,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:06,923][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 2.098740577697754, acc: 0.3181818127632141)
[2024-11-13 07:33:07,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:07,215][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.266969919204712, acc: 0.4901960790157318)
[2024-11-13 07:33:07,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:07,512][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 2.132429599761963, acc: 0.38461539149284363)
[2024-11-13 07:33:07,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:07,802][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 2.0812299251556396, acc: 0.4444444477558136)
[2024-11-13 07:33:07,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:08,108][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.1061558723449707, acc: 0.5249999761581421)
[2024-11-13 07:33:08,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:08,404][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 3.1895322799682617, acc: 0.30000001192092896)
[2024-11-13 07:33:08,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:08,710][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 1.3228528499603271, acc: 0.5714285969734192)
[2024-11-13 07:33:08,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:09,027][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 2.1302578449249268, acc: 0.36666667461395264)
[2024-11-13 07:33:09,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:09,327][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 1.8245681524276733, acc: 0.5)
[2024-11-13 07:33:09,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:09,641][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 1.9735887050628662, acc: 0.4722222089767456)
[2024-11-13 07:33:09,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:09,934][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 1.814792513847351, acc: 0.5185185074806213)
[2024-11-13 07:33:10,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:10,234][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 1.6297322511672974, acc: 0.5757575631141663)
[2024-11-13 07:33:10,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:10,544][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.4324743747711182, acc: 0.6521739363670349)
[2024-11-13 07:33:10,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:10,878][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.580094575881958, acc: 0.5945945978164673)
[2024-11-13 07:33:10,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:11,193][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 1.3685051202774048, acc: 0.6296296119689941)
[2024-11-13 07:33:11,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:12,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:12,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:12,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:13,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:13,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:13,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:13,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:14,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:14,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:14,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:15,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:15,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:15,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:15,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:16,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:16,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:16,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:17,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:17,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:17,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:17,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:18,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:18,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:18,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:18,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:18,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:19,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:19,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:19,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:19,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:20,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:20,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:20,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:20,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:21,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:21,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:21,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:21,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:22,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:22,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:22,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:22,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:22,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:23,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:23,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:23,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:24,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:24,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:24,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:24,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:25,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:25,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:25,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:25,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:25,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:26,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:26,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:26,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:26,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:27,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:27,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:27,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:27,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:28,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:28,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:28,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:29,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:29,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:29,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:29,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:30,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:30,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:30,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:30,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:31,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:31,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:31,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:31,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:32,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:32,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:32,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:32,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:32,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:33,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:33,878][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(11.0107, device='cuda:0') eval_epoch_loss=tensor(2.3989, device='cuda:0') eval_epoch_acc=tensor(0.3953, device='cuda:0')
[2024-11-13 07:33:33,879][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:33:33,880][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:33:34,194][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_1_step_429_loss_2.398869276046753/model.pt
[2024-11-13 07:33:34,199][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:33:34,199][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.3952697813510895
[2024-11-13 07:33:34,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:34,543][root][INFO] - Training Epoch: 1/10, step 429/574 completed (loss: 2.0649044513702393, acc: 0.43478259444236755)
[2024-11-13 07:33:34,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:34,860][root][INFO] - Training Epoch: 1/10, step 430/574 completed (loss: 1.060045599937439, acc: 0.6666666865348816)
[2024-11-13 07:33:34,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:35,154][root][INFO] - Training Epoch: 1/10, step 431/574 completed (loss: 1.1031793355941772, acc: 0.7037037014961243)
[2024-11-13 07:33:35,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:35,469][root][INFO] - Training Epoch: 1/10, step 432/574 completed (loss: 2.0862746238708496, acc: 0.3913043439388275)
[2024-11-13 07:33:35,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:35,795][root][INFO] - Training Epoch: 1/10, step 433/574 completed (loss: 1.5436758995056152, acc: 0.6388888955116272)
[2024-11-13 07:33:35,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:36,126][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 0.8266457915306091, acc: 0.7599999904632568)
[2024-11-13 07:33:36,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:36,424][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 1.6771010160446167, acc: 0.4848484992980957)
[2024-11-13 07:33:36,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:36,698][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 1.762498378753662, acc: 0.5)
[2024-11-13 07:33:36,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:37,004][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 1.9370219707489014, acc: 0.5227272510528564)
[2024-11-13 07:33:37,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:37,275][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 0.639340341091156, acc: 0.8095238208770752)
[2024-11-13 07:33:37,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:37,584][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 2.4251956939697266, acc: 0.43589743971824646)
[2024-11-13 07:33:37,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:37,962][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.337151288986206, acc: 0.42424243688583374)
[2024-11-13 07:33:38,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:38,469][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 2.89540696144104, acc: 0.30399999022483826)
[2024-11-13 07:33:38,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:38,801][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 2.730276584625244, acc: 0.35483869910240173)
[2024-11-13 07:33:38,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:39,294][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 2.576223134994507, acc: 0.3333333432674408)
[2024-11-13 07:33:39,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:39,572][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.440901041030884, acc: 0.3207547068595886)
[2024-11-13 07:33:39,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:39,915][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 1.7115378379821777, acc: 0.5454545617103577)
[2024-11-13 07:33:39,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:40,207][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.129912853240967, acc: 0.52173912525177)
[2024-11-13 07:33:40,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:40,482][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 1.868618130683899, acc: 0.5384615659713745)
[2024-11-13 07:33:40,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:40,777][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.6240359544754028, acc: 0.6071428656578064)
[2024-11-13 07:33:40,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:41,072][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.589150905609131, acc: 0.34328359365463257)
[2024-11-13 07:33:41,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:41,355][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.1336123943328857, acc: 0.4861111044883728)
[2024-11-13 07:33:41,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:41,659][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 2.4375569820404053, acc: 0.3913043439388275)
[2024-11-13 07:33:41,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:41,998][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.5144708156585693, acc: 0.3461538553237915)
[2024-11-13 07:33:42,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:42,295][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.703561544418335, acc: 0.3815789520740509)
[2024-11-13 07:33:42,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:42,582][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 1.9768805503845215, acc: 0.5102040767669678)
[2024-11-13 07:33:42,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:42,960][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 1.8552329540252686, acc: 0.5757575631141663)
[2024-11-13 07:33:43,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:43,288][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.374276876449585, acc: 0.2886597812175751)
[2024-11-13 07:33:43,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:43,636][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.222572088241577, acc: 0.3857142925262451)
[2024-11-13 07:33:43,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:43,963][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.3168394565582275, acc: 0.36627906560897827)
[2024-11-13 07:33:44,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:44,273][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.618138551712036, acc: 0.3571428656578064)
[2024-11-13 07:33:44,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:44,578][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 2.332879066467285, acc: 0.395061731338501)
[2024-11-13 07:33:44,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:44,899][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 1.8551262617111206, acc: 0.5277777910232544)
[2024-11-13 07:33:44,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:45,212][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 1.8837013244628906, acc: 0.5625)
[2024-11-13 07:33:45,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:45,536][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 1.830080270767212, acc: 0.5)
[2024-11-13 07:33:45,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:45,833][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 2.275096893310547, acc: 0.41304346919059753)
[2024-11-13 07:33:45,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:46,136][root][INFO] - Training Epoch: 1/10, step 465/574 completed (loss: 2.4157609939575195, acc: 0.25)
[2024-11-13 07:33:46,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:46,437][root][INFO] - Training Epoch: 1/10, step 466/574 completed (loss: 2.4171388149261475, acc: 0.3253012001514435)
[2024-11-13 07:33:46,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:46,742][root][INFO] - Training Epoch: 1/10, step 467/574 completed (loss: 2.1640689373016357, acc: 0.4234234094619751)
[2024-11-13 07:33:46,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:47,066][root][INFO] - Training Epoch: 1/10, step 468/574 completed (loss: 2.280127763748169, acc: 0.446601927280426)
[2024-11-13 07:33:47,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:47,403][root][INFO] - Training Epoch: 1/10, step 469/574 completed (loss: 2.0796706676483154, acc: 0.43089431524276733)
[2024-11-13 07:33:47,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:47,696][root][INFO] - Training Epoch: 1/10, step 470/574 completed (loss: 1.9774442911148071, acc: 0.5416666865348816)
[2024-11-13 07:33:47,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:48,003][root][INFO] - Training Epoch: 1/10, step 471/574 completed (loss: 2.6349165439605713, acc: 0.3214285671710968)
[2024-11-13 07:33:48,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:48,351][root][INFO] - Training Epoch: 1/10, step 472/574 completed (loss: 2.3125996589660645, acc: 0.3921568691730499)
[2024-11-13 07:33:48,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:48,674][root][INFO] - Training Epoch: 1/10, step 473/574 completed (loss: 2.489161491394043, acc: 0.34061136841773987)
[2024-11-13 07:33:48,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:49,014][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 2.3556058406829834, acc: 0.375)
[2024-11-13 07:33:49,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:49,288][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.3839542865753174, acc: 0.3680981695652008)
[2024-11-13 07:33:49,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:49,613][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 2.529096841812134, acc: 0.32374101877212524)
[2024-11-13 07:33:49,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:50,019][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 2.417755603790283, acc: 0.37688443064689636)
[2024-11-13 07:33:50,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:50,328][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 1.847583532333374, acc: 0.5)
[2024-11-13 07:33:50,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:50,624][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 1.7034847736358643, acc: 0.5757575631141663)
[2024-11-13 07:33:50,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:50,915][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 1.8624197244644165, acc: 0.40740740299224854)
[2024-11-13 07:33:50,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:51,209][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 1.8823992013931274, acc: 0.550000011920929)
[2024-11-13 07:33:51,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:51,537][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 1.120754361152649, acc: 0.75)
[2024-11-13 07:33:51,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:51,891][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 1.8861546516418457, acc: 0.5)
[2024-11-13 07:33:51,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:52,217][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 1.5602971315383911, acc: 0.6774193644523621)
[2024-11-13 07:33:52,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:52,549][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.284979224205017, acc: 0.7368420958518982)
[2024-11-13 07:33:52,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:52,856][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.420186758041382, acc: 0.40740740299224854)
[2024-11-13 07:33:52,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:53,185][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.235504627227783, acc: 0.3333333432674408)
[2024-11-13 07:33:53,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:53,507][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 1.7961368560791016, acc: 0.5)
[2024-11-13 07:33:53,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:53,912][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.0728068351745605, acc: 0.4153846204280853)
[2024-11-13 07:33:54,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:54,234][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 1.6150377988815308, acc: 0.6000000238418579)
[2024-11-13 07:33:54,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:54,557][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 1.765040636062622, acc: 0.5517241358757019)
[2024-11-13 07:33:54,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:54,885][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.2573513984680176, acc: 0.3529411852359772)
[2024-11-13 07:33:54,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:55,227][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 1.991602897644043, acc: 0.48275861144065857)
[2024-11-13 07:33:55,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:55,552][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 0.8618737459182739, acc: 0.7368420958518982)
[2024-11-13 07:33:55,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:55,895][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.2250258922576904, acc: 0.31578946113586426)
[2024-11-13 07:33:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:56,254][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.2256875038146973, acc: 0.4107142984867096)
[2024-11-13 07:33:56,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:56,618][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.133547067642212, acc: 0.43820226192474365)
[2024-11-13 07:33:56,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:56,948][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.4421863555908203, acc: 0.3483146131038666)
[2024-11-13 07:33:57,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:57,281][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.570281744003296, acc: 0.304964542388916)
[2024-11-13 07:33:57,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:57,630][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.636162757873535, acc: 0.3695652186870575)
[2024-11-13 07:33:57,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:57,938][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 1.084487795829773, acc: 0.800000011920929)
[2024-11-13 07:33:58,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:58,281][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 1.4041963815689087, acc: 0.6153846383094788)
[2024-11-13 07:33:58,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:58,626][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 1.2469840049743652, acc: 0.6296296119689941)
[2024-11-13 07:33:58,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:58,964][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 2.002504587173462, acc: 0.4444444477558136)
[2024-11-13 07:33:59,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:59,294][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 1.8408585786819458, acc: 0.49056604504585266)
[2024-11-13 07:33:59,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:33:59,632][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 1.5836440324783325, acc: 0.6206896305084229)
[2024-11-13 07:33:59,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:00,092][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.2532777786254883, acc: 0.3963963985443115)
[2024-11-13 07:34:00,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:00,443][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 2.1848483085632324, acc: 0.4225352108478546)
[2024-11-13 07:34:00,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:00,721][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 0.6042419672012329, acc: 0.8500000238418579)
[2024-11-13 07:34:00,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:01,005][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 1.0173760652542114, acc: 0.7333333492279053)
[2024-11-13 07:34:01,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:01,351][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 1.5241408348083496, acc: 0.5769230723381042)
[2024-11-13 07:34:01,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:02,551][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 2.2907919883728027, acc: 0.4285714328289032)
[2024-11-13 07:34:02,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:03,103][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 2.32127046585083, acc: 0.4444444477558136)
[2024-11-13 07:34:03,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:03,387][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 1.7622406482696533, acc: 0.5714285969734192)
[2024-11-13 07:34:03,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:03,720][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 1.8809486627578735, acc: 0.5166666507720947)
[2024-11-13 07:34:03,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:04,251][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.0133941173553467, acc: 0.5416666865348816)
[2024-11-13 07:34:04,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:04,530][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 0.7000493407249451, acc: 0.7307692170143127)
[2024-11-13 07:34:04,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:04,854][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 2.1097519397735596, acc: 0.4838709533214569)
[2024-11-13 07:34:04,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:05,154][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 2.8708536624908447, acc: 0.44999998807907104)
[2024-11-13 07:34:05,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:05,465][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.5998518466949463, acc: 0.3333333432674408)
[2024-11-13 07:34:05,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:06,159][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.3189191818237305, acc: 0.39830508828163147)
[2024-11-13 07:34:06,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:06,475][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.341982364654541, acc: 0.38805970549583435)
[2024-11-13 07:34:06,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:06,801][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.3760745525360107, acc: 0.35036495327949524)
[2024-11-13 07:34:06,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:07,248][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.1896562576293945, acc: 0.41499999165534973)
[2024-11-13 07:34:07,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:07,556][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.3424148559570312, acc: 0.3333333432674408)
[2024-11-13 07:34:07,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:07,890][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.058983087539673, acc: 0.4423076808452606)
[2024-11-13 07:34:07,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:08,190][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.6302130222320557, acc: 0.2380952388048172)
[2024-11-13 07:34:08,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:08,511][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 2.9587700366973877, acc: 0.2295081913471222)
[2024-11-13 07:34:08,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:08,840][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.0239920616149902, acc: 0.47457626461982727)
[2024-11-13 07:34:08,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:09,150][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 2.4940781593322754, acc: 0.3255814015865326)
[2024-11-13 07:34:09,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:09,464][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.3743960857391357, acc: 0.47727271914482117)
[2024-11-13 07:34:09,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:09,786][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.538837432861328, acc: 0.3207547068595886)
[2024-11-13 07:34:09,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:10,084][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.19918155670166, acc: 0.5)
[2024-11-13 07:34:10,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:10,342][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 1.8658967018127441, acc: 0.6399999856948853)
[2024-11-13 07:34:10,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:10,659][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 1.9729515314102173, acc: 0.5)
[2024-11-13 07:34:10,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:10,968][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 1.6430720090866089, acc: 0.5454545617103577)
[2024-11-13 07:34:11,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:11,324][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 2.0964550971984863, acc: 0.446153849363327)
[2024-11-13 07:34:11,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:11,652][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 1.9202276468276978, acc: 0.5)
[2024-11-13 07:34:11,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:11,989][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 1.297087550163269, acc: 0.625)
[2024-11-13 07:34:12,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:12,297][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 2.093233585357666, acc: 0.42424243688583374)
[2024-11-13 07:34:12,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:12,604][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 0.9665447473526001, acc: 0.625)
[2024-11-13 07:34:12,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:12,869][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 1.2752201557159424, acc: 0.5806451439857483)
[2024-11-13 07:34:12,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:13,175][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 0.8814983367919922, acc: 0.782608687877655)
[2024-11-13 07:34:13,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:13,463][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 2.44974422454834, acc: 0.4333333373069763)
[2024-11-13 07:34:13,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:13,841][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 1.9896446466445923, acc: 0.39024388790130615)
[2024-11-13 07:34:13,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:14,160][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 1.285828948020935, acc: 0.6285714507102966)
[2024-11-13 07:34:14,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:14,474][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 1.8096548318862915, acc: 0.5526315569877625)
[2024-11-13 07:34:14,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:14,763][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 1.9323433637619019, acc: 0.4838709533214569)
[2024-11-13 07:34:14,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:15,035][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 0.9930130839347839, acc: 0.7200000286102295)
[2024-11-13 07:34:15,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:15,328][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.6699594259262085, acc: 0.5454545617103577)
[2024-11-13 07:34:15,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:15,602][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 1.4216134548187256, acc: 0.6499999761581421)
[2024-11-13 07:34:15,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:15,905][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.7022680044174194, acc: 0.5)
[2024-11-13 07:34:16,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:16,242][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.5355892181396484, acc: 0.31386861205101013)
[2024-11-13 07:34:16,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:16,552][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.1371099948883057, acc: 0.48275861144065857)
[2024-11-13 07:34:16,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:16,887][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.8503994941711426, acc: 0.2857142984867096)
[2024-11-13 07:34:17,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:17,230][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.8392040729522705, acc: 0.22516556084156036)
[2024-11-13 07:34:17,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:17,541][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 2.3937206268310547, acc: 0.41025641560554504)
[2024-11-13 07:34:17,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:17,812][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 0.8360550403594971, acc: 0.8399999737739563)
[2024-11-13 07:34:17,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:18,098][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.5488756895065308, acc: 0.5769230723381042)
[2024-11-13 07:34:18,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:18,388][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.146464467048645, acc: 0.6153846383094788)
[2024-11-13 07:34:18,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:18,688][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 1.9771965742111206, acc: 0.4871794879436493)
[2024-11-13 07:34:18,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:19,011][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 1.9273039102554321, acc: 0.5)
[2024-11-13 07:34:19,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:19,304][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.230884313583374, acc: 0.3896103799343109)
[2024-11-13 07:34:19,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:19,589][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.188873529434204, acc: 0.375)
[2024-11-13 07:34:19,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:19,892][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.41465425491333, acc: 0.37931033968925476)
[2024-11-13 07:34:19,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:20,168][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.112056255340576, acc: 0.380952388048172)
[2024-11-13 07:34:20,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:20,443][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.7415187358856201, acc: 0.4736842215061188)
[2024-11-13 07:34:20,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:20,827][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 1.967241883277893, acc: 0.40740740299224854)
[2024-11-13 07:34:20,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:21,229][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.2530715465545654, acc: 0.3689839541912079)
[2024-11-13 07:34:21,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:21,558][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 1.7867119312286377, acc: 0.5161290168762207)
[2024-11-13 07:34:21,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:21,889][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 2.288827419281006, acc: 0.4017094075679779)
[2024-11-13 07:34:22,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:22,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:23,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:23,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:23,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:23,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:24,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:24,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:24,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:24,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:25,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:25,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:26,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:26,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:26,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:26,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:27,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:27,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:27,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:27,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:28,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:28,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:28,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:28,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:29,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:29,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:29,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:29,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:30,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:30,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:30,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:31,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:31,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:31,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:32,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:32,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:32,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:32,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:33,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:33,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:33,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:33,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:34,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:34,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:34,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:34,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:35,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:35,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:35,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:36,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:36,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:36,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:36,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:37,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:37,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:37,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:38,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:38,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:38,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:38,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:39,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:39,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:39,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:39,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:39,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:40,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:40,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:40,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:41,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:41,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:41,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:41,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:42,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:42,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:42,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:42,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:43,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:43,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:43,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:43,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:44,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:44,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:44,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:45,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:45,764][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.9180, device='cuda:0') eval_epoch_loss=tensor(2.0691, device='cuda:0') eval_epoch_acc=tensor(0.4546, device='cuda:0')
[2024-11-13 07:34:45,765][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:34:45,766][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:34:46,191][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_1_step_572_loss_2.0691447257995605/model.pt
[2024-11-13 07:34:46,194][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:34:46,195][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.0691447257995605
[2024-11-13 07:34:46,195][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.4545733332633972
[2024-11-13 07:34:46,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:46,538][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 2.4984021186828613, acc: 0.3316326439380646)
[2024-11-13 07:34:46,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:46,891][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 2.4093010425567627, acc: 0.3333333432674408)
[2024-11-13 07:34:47,270][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=19.2661, train_epoch_loss=2.9583, epoch time 304.3814526088536s
[2024-11-13 07:34:47,270][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-11-13 07:34:47,270][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 07:34:47,270][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-11-13 07:34:47,270][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 07:34:47,270][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 3 GB
[2024-11-13 07:34:47,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:48,188][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 1.8934670686721802, acc: 0.5185185074806213)
[2024-11-13 07:34:48,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:48,503][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 2.3514108657836914, acc: 0.36000001430511475)
[2024-11-13 07:34:48,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:48,807][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 2.739816904067993, acc: 0.37837839126586914)
[2024-11-13 07:34:48,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:49,084][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 2.5134527683258057, acc: 0.28947368264198303)
[2024-11-13 07:34:49,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:49,373][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 2.17828369140625, acc: 0.37837839126586914)
[2024-11-13 07:34:49,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:49,689][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.094515562057495, acc: 0.3571428656578064)
[2024-11-13 07:34:49,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:50,011][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.531808614730835, acc: 0.3265306055545807)
[2024-11-13 07:34:50,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:50,303][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 2.155491590499878, acc: 0.4000000059604645)
[2024-11-13 07:34:50,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:50,601][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 0.5059670805931091, acc: 0.8181818127632141)
[2024-11-13 07:34:50,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:50,900][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 0.8147366642951965, acc: 0.7307692170143127)
[2024-11-13 07:34:50,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:51,237][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 1.3695813417434692, acc: 0.6296296119689941)
[2024-11-13 07:34:51,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:51,531][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.1187171936035156, acc: 0.4615384638309479)
[2024-11-13 07:34:51,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:51,834][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.867114543914795, acc: 0.4848484992980957)
[2024-11-13 07:34:51,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:52,194][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 1.9555809497833252, acc: 0.47826087474823)
[2024-11-13 07:34:52,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:52,479][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.3966686725616455, acc: 0.37254902720451355)
[2024-11-13 07:34:52,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:52,772][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 1.8845566511154175, acc: 0.44897958636283875)
[2024-11-13 07:34:52,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:53,109][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.3107823133468628, acc: 0.7368420958518982)
[2024-11-13 07:34:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:53,414][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 1.9955676794052124, acc: 0.3333333432674408)
[2024-11-13 07:34:53,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:53,715][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.6066665649414062, acc: 0.3055555522441864)
[2024-11-13 07:34:53,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:54,030][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 2.0502889156341553, acc: 0.4736842215061188)
[2024-11-13 07:34:54,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:54,339][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 2.0929453372955322, acc: 0.4615384638309479)
[2024-11-13 07:34:54,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:54,633][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 2.1840524673461914, acc: 0.517241358757019)
[2024-11-13 07:34:54,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:54,940][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 1.794875979423523, acc: 0.47999998927116394)
[2024-11-13 07:34:55,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:55,272][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 1.1979286670684814, acc: 0.6190476417541504)
[2024-11-13 07:34:55,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:55,588][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 1.9746372699737549, acc: 0.375)
[2024-11-13 07:34:55,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:55,917][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 2.8400795459747314, acc: 0.22641509771347046)
[2024-11-13 07:34:55,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:56,238][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.5538196563720703, acc: 0.34246575832366943)
[2024-11-13 07:34:56,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:56,968][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 2.585803508758545, acc: 0.31620553135871887)
[2024-11-13 07:34:57,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:57,312][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 2.3692450523376465, acc: 0.39534884691238403)
[2024-11-13 07:34:57,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:57,645][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 2.374337911605835, acc: 0.3012048304080963)
[2024-11-13 07:34:57,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:57,978][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.389456272125244, acc: 0.4197530746459961)
[2024-11-13 07:34:58,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:58,284][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 2.3933663368225098, acc: 0.3928571343421936)
[2024-11-13 07:34:58,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:58,607][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 1.6193760633468628, acc: 0.5925925970077515)
[2024-11-13 07:34:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:58,918][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 1.628259539604187, acc: 0.52173912525177)
[2024-11-13 07:34:58,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:59,217][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 2.3181865215301514, acc: 0.3613445460796356)
[2024-11-13 07:34:59,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:59,508][root][INFO] - Training Epoch: 2/10, step 35/574 completed (loss: 2.0023701190948486, acc: 0.37704917788505554)
[2024-11-13 07:34:59,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:34:59,837][root][INFO] - Training Epoch: 2/10, step 36/574 completed (loss: 2.176003932952881, acc: 0.3968254029750824)
[2024-11-13 07:34:59,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:00,122][root][INFO] - Training Epoch: 2/10, step 37/574 completed (loss: 2.3189454078674316, acc: 0.37288135290145874)
[2024-11-13 07:35:00,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:00,435][root][INFO] - Training Epoch: 2/10, step 38/574 completed (loss: 1.758109450340271, acc: 0.5057471394538879)
[2024-11-13 07:35:00,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:00,715][root][INFO] - Training Epoch: 2/10, step 39/574 completed (loss: 1.2113873958587646, acc: 0.6666666865348816)
[2024-11-13 07:35:00,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:01,007][root][INFO] - Training Epoch: 2/10, step 40/574 completed (loss: 2.4683618545532227, acc: 0.26923078298568726)
[2024-11-13 07:35:01,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:01,340][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 2.7702932357788086, acc: 0.28378379344940186)
[2024-11-13 07:35:01,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:01,655][root][INFO] - Training Epoch: 2/10, step 42/574 completed (loss: 2.2505929470062256, acc: 0.4000000059604645)
[2024-11-13 07:35:01,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:02,011][root][INFO] - Training Epoch: 2/10, step 43/574 completed (loss: 2.5356028079986572, acc: 0.35353535413742065)
[2024-11-13 07:35:02,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:02,359][root][INFO] - Training Epoch: 2/10, step 44/574 completed (loss: 2.092684745788574, acc: 0.44329896569252014)
[2024-11-13 07:35:02,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:02,714][root][INFO] - Training Epoch: 2/10, step 45/574 completed (loss: 2.296400308609009, acc: 0.40441176295280457)
[2024-11-13 07:35:02,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:03,002][root][INFO] - Training Epoch: 2/10, step 46/574 completed (loss: 0.873973548412323, acc: 0.7307692170143127)
[2024-11-13 07:35:03,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:03,314][root][INFO] - Training Epoch: 2/10, step 47/574 completed (loss: 1.0506428480148315, acc: 0.7777777910232544)
[2024-11-13 07:35:03,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:03,682][root][INFO] - Training Epoch: 2/10, step 48/574 completed (loss: 1.4710032939910889, acc: 0.5357142686843872)
[2024-11-13 07:35:03,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:04,006][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 1.3510146141052246, acc: 0.5833333134651184)
[2024-11-13 07:35:04,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:04,320][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 1.6843923330307007, acc: 0.5438596606254578)
[2024-11-13 07:35:04,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:04,589][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 1.7686110734939575, acc: 0.5396825671195984)
[2024-11-13 07:35:04,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:04,990][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.277909755706787, acc: 0.3802816867828369)
[2024-11-13 07:35:05,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:05,439][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 2.5262715816497803, acc: 0.41333332657814026)
[2024-11-13 07:35:05,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:05,801][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 1.4512653350830078, acc: 0.5945945978164673)
[2024-11-13 07:35:05,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:06,101][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 0.8747581839561462, acc: 0.7692307829856873)
[2024-11-13 07:35:06,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:07,400][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 1.9737972021102905, acc: 0.49146756529808044)
[2024-11-13 07:35:07,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:08,213][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 2.567561149597168, acc: 0.37690630555152893)
[2024-11-13 07:35:08,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:08,713][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.1302168369293213, acc: 0.46022728085517883)
[2024-11-13 07:35:08,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:09,157][root][INFO] - Training Epoch: 2/10, step 59/574 completed (loss: 2.438335418701172, acc: 0.375)
[2024-11-13 07:35:09,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:09,607][root][INFO] - Training Epoch: 2/10, step 60/574 completed (loss: 2.4599907398223877, acc: 0.32608696818351746)
[2024-11-13 07:35:09,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:09,995][root][INFO] - Training Epoch: 2/10, step 61/574 completed (loss: 1.9004781246185303, acc: 0.550000011920929)
[2024-11-13 07:35:10,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:10,384][root][INFO] - Training Epoch: 2/10, step 62/574 completed (loss: 1.7039222717285156, acc: 0.5)
[2024-11-13 07:35:10,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:10,707][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 2.162667989730835, acc: 0.3888888955116272)
[2024-11-13 07:35:10,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:11,033][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 1.9202537536621094, acc: 0.53125)
[2024-11-13 07:35:11,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:11,388][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 1.0121334791183472, acc: 0.7931034564971924)
[2024-11-13 07:35:11,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:11,724][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 2.5220882892608643, acc: 0.3928571343421936)
[2024-11-13 07:35:11,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:12,065][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 2.3021955490112305, acc: 0.4000000059604645)
[2024-11-13 07:35:12,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:12,368][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 1.0812608003616333, acc: 0.6399999856948853)
[2024-11-13 07:35:12,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:12,637][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 1.4584808349609375, acc: 0.6666666865348816)
[2024-11-13 07:35:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:12,925][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 1.607628345489502, acc: 0.5454545617103577)
[2024-11-13 07:35:13,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:13,326][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 2.2681586742401123, acc: 0.4264705777168274)
[2024-11-13 07:35:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:13,642][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.1330626010894775, acc: 0.4126984179019928)
[2024-11-13 07:35:13,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:13,982][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.4189791679382324, acc: 0.3948718011379242)
[2024-11-13 07:35:14,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:14,362][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.182750701904297, acc: 0.4183673560619354)
[2024-11-13 07:35:14,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:14,721][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.6880030632019043, acc: 0.26119402050971985)
[2024-11-13 07:35:14,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:15,096][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.3523616790771484, acc: 0.36496350169181824)
[2024-11-13 07:35:15,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:15,432][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.7241730690002441, acc: 0.7142857313156128)
[2024-11-13 07:35:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:15,752][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 0.7209946513175964, acc: 0.7916666865348816)
[2024-11-13 07:35:15,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:16,101][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.3047232627868652, acc: 0.5757575631141663)
[2024-11-13 07:35:16,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:16,442][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.245821237564087, acc: 0.6153846383094788)
[2024-11-13 07:35:16,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:16,782][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 1.9966596364974976, acc: 0.4423076808452606)
[2024-11-13 07:35:16,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:17,138][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.328038454055786, acc: 0.4615384638309479)
[2024-11-13 07:35:17,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:17,451][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 1.8263057470321655, acc: 0.46875)
[2024-11-13 07:35:17,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:17,827][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 2.226638078689575, acc: 0.43478259444236755)
[2024-11-13 07:35:17,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:18,184][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.842423915863037, acc: 0.47999998927116394)
[2024-11-13 07:35:18,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:18,527][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 2.330321788787842, acc: 0.3913043439388275)
[2024-11-13 07:35:18,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:18,917][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.5376994609832764, acc: 0.3400000035762787)
[2024-11-13 07:35:18,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:19,243][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 2.002056121826172, acc: 0.49514561891555786)
[2024-11-13 07:35:19,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:19,964][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 2.081509590148926, acc: 0.48543688654899597)
[2024-11-13 07:35:20,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:20,579][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.193972110748291, acc: 0.39247313141822815)
[2024-11-13 07:35:20,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:21,173][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 1.9978848695755005, acc: 0.5043103694915771)
[2024-11-13 07:35:21,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:21,746][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 1.654714822769165, acc: 0.5473684072494507)
[2024-11-13 07:35:21,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:22,434][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 2.399634599685669, acc: 0.3465346395969391)
[2024-11-13 07:35:22,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:22,719][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 2.4693238735198975, acc: 0.32258063554763794)
[2024-11-13 07:35:22,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:23,035][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.523822069168091, acc: 0.3478260934352875)
[2024-11-13 07:35:23,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:23,373][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 2.634833574295044, acc: 0.2521008551120758)
[2024-11-13 07:35:23,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:23,681][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.741455554962158, acc: 0.25)
[2024-11-13 07:35:23,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:24,067][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.541055679321289, acc: 0.33576643466949463)
[2024-11-13 07:35:24,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:24,411][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 2.6341793537139893, acc: 0.35820895433425903)
[2024-11-13 07:35:24,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:24,743][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 1.4615329504013062, acc: 0.699999988079071)
[2024-11-13 07:35:24,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:25,058][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 1.141096591949463, acc: 0.5909090638160706)
[2024-11-13 07:35:25,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:25,401][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.282287359237671, acc: 0.6086956262588501)
[2024-11-13 07:35:25,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:25,759][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 1.778548002243042, acc: 0.47727271914482117)
[2024-11-13 07:35:25,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:26,084][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.146315336227417, acc: 0.37931033968925476)
[2024-11-13 07:35:26,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:26,372][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 2.031003475189209, acc: 0.4883720874786377)
[2024-11-13 07:35:26,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:26,653][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.5728915929794312, acc: 0.6000000238418579)
[2024-11-13 07:35:26,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:26,991][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.9018217921257019, acc: 0.7058823704719543)
[2024-11-13 07:35:27,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:27,307][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.6408360600471497, acc: 0.807692289352417)
[2024-11-13 07:35:27,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:27,632][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.7910377979278564, acc: 0.5)
[2024-11-13 07:35:27,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:27,936][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.033627986907959, acc: 0.4769230782985687)
[2024-11-13 07:35:28,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:28,309][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.0323097705841064, acc: 0.4385964870452881)
[2024-11-13 07:35:28,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:28,603][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 2.014777660369873, acc: 0.4035087823867798)
[2024-11-13 07:35:28,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:28,949][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.287336587905884, acc: 0.38461539149284363)
[2024-11-13 07:35:29,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:29,349][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.5644164085388184, acc: 0.6530612111091614)
[2024-11-13 07:35:29,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:29,628][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 0.5990540981292725, acc: 0.8636363744735718)
[2024-11-13 07:35:29,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:30,000][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.2098796367645264, acc: 0.4285714328289032)
[2024-11-13 07:35:30,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:30,320][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.126805305480957, acc: 0.49593496322631836)
[2024-11-13 07:35:30,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:30,631][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.732567310333252, acc: 0.5645161271095276)
[2024-11-13 07:35:30,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:31,263][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.1171555519104004, acc: 0.4220532178878784)
[2024-11-13 07:35:31,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:31,585][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.7861350774765015, acc: 0.5199999809265137)
[2024-11-13 07:35:31,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:31,962][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.688535213470459, acc: 0.6153846383094788)
[2024-11-13 07:35:32,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:32,267][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 0.975071907043457, acc: 0.7916666865348816)
[2024-11-13 07:35:32,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:32,503][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.8665851354599, acc: 0.42105263471603394)
[2024-11-13 07:35:32,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:32,812][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.3195037841796875, acc: 0.3680981695652008)
[2024-11-13 07:35:32,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:33,188][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 1.8703703880310059, acc: 0.5069444179534912)
[2024-11-13 07:35:33,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:33,529][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.3874003887176514, acc: 0.32499998807907104)
[2024-11-13 07:35:33,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:33,918][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.40716814994812, acc: 0.3154761791229248)
[2024-11-13 07:35:34,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:34,280][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.2051479816436768, acc: 0.4153846204280853)
[2024-11-13 07:35:34,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:34,642][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 2.030252695083618, acc: 0.49264705181121826)
[2024-11-13 07:35:34,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:34,915][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.3708584308624268, acc: 0.5769230723381042)
[2024-11-13 07:35:34,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:35,200][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 0.7463187575340271, acc: 0.739130437374115)
[2024-11-13 07:35:35,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:35,547][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 1.7361838817596436, acc: 0.5)
[2024-11-13 07:35:35,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:35,917][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 2.122008800506592, acc: 0.47826087474823)
[2024-11-13 07:35:35,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:36,241][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 1.5709424018859863, acc: 0.6000000238418579)
[2024-11-13 07:35:36,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:36,519][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 1.4817073345184326, acc: 0.5769230723381042)
[2024-11-13 07:35:36,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:36,866][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 2.2842748165130615, acc: 0.2857142984867096)
[2024-11-13 07:35:36,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:37,243][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 1.695558786392212, acc: 0.5333333611488342)
[2024-11-13 07:35:37,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:37,584][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.9221305847167969, acc: 0.3478260934352875)
[2024-11-13 07:35:37,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:37,964][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 2.428969144821167, acc: 0.523809552192688)
[2024-11-13 07:35:38,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:38,364][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 2.3500559329986572, acc: 0.38461539149284363)
[2024-11-13 07:35:39,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:39,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:39,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:39,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:40,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:40,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:40,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:41,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:41,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:41,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:42,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:42,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:42,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:43,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:43,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:43,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:43,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:44,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:44,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:44,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:45,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:45,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:45,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:45,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:46,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:46,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:46,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:46,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:47,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:47,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:47,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:47,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:48,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:48,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:48,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:49,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:49,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:49,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:49,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:50,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:50,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:50,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:51,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:51,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:51,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:51,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:52,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:52,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:52,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:53,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:53,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:53,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:53,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:54,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:54,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:54,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:55,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:55,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:55,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:55,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:56,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:56,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:56,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:56,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:57,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:57,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:57,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:58,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:58,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:58,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:59,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:59,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:35:59,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:00,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:00,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:00,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:01,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:01,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:01,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:02,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:02,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:02,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:03,397][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.8800, device='cuda:0') eval_epoch_loss=tensor(2.0643, device='cuda:0') eval_epoch_acc=tensor(0.4445, device='cuda:0')
[2024-11-13 07:36:03,398][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:36:03,398][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:36:03,779][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_2_step_141_loss_2.064324378967285/model.pt
[2024-11-13 07:36:03,783][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:36:03,783][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 2.064324378967285
[2024-11-13 07:36:03,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:04,117][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.984147548675537, acc: 0.16129031777381897)
[2024-11-13 07:36:04,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:04,455][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 2.3792364597320557, acc: 0.3513513505458832)
[2024-11-13 07:36:04,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:04,873][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.3078064918518066, acc: 0.3333333432674408)
[2024-11-13 07:36:04,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:05,183][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.9285656213760376, acc: 0.44029849767684937)
[2024-11-13 07:36:05,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:05,494][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.427016019821167, acc: 0.3469387888908386)
[2024-11-13 07:36:05,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:05,858][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.2556257247924805, acc: 0.3723404109477997)
[2024-11-13 07:36:05,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:06,138][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.023954153060913, acc: 0.4714285731315613)
[2024-11-13 07:36:06,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:06,410][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 2.4908528327941895, acc: 0.4642857015132904)
[2024-11-13 07:36:06,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:06,713][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.626227855682373, acc: 0.5652173757553101)
[2024-11-13 07:36:06,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:06,995][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.120620012283325, acc: 0.27586206793785095)
[2024-11-13 07:36:07,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:07,312][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.2357594966888428, acc: 0.45652174949645996)
[2024-11-13 07:36:07,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:07,612][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.128751754760742, acc: 0.4237288236618042)
[2024-11-13 07:36:07,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:07,861][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.420854091644287, acc: 0.3684210479259491)
[2024-11-13 07:36:07,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:08,151][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.022749900817871, acc: 0.4864864945411682)
[2024-11-13 07:36:08,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:08,426][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.7891780138015747, acc: 0.5714285969734192)
[2024-11-13 07:36:08,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:08,735][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.4138203859329224, acc: 0.6521739363670349)
[2024-11-13 07:36:08,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:09,040][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 2.1505184173583984, acc: 0.3684210479259491)
[2024-11-13 07:36:09,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:09,896][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 1.949777603149414, acc: 0.4864864945411682)
[2024-11-13 07:36:09,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:10,130][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.1141457557678223, acc: 0.4444444477558136)
[2024-11-13 07:36:10,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:10,469][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 2.0398030281066895, acc: 0.43023255467414856)
[2024-11-13 07:36:10,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:10,919][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 1.9309145212173462, acc: 0.4588235318660736)
[2024-11-13 07:36:11,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:11,346][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 2.3258190155029297, acc: 0.3932584226131439)
[2024-11-13 07:36:11,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:11,644][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 2.0011727809906006, acc: 0.5)
[2024-11-13 07:36:11,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:11,902][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 1.8302037715911865, acc: 0.4761904776096344)
[2024-11-13 07:36:11,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:12,217][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 1.8841243982315063, acc: 0.48275861144065857)
[2024-11-13 07:36:12,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:12,517][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.6893259286880493, acc: 0.4897959232330322)
[2024-11-13 07:36:12,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:12,804][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 2.0198891162872314, acc: 0.46000000834465027)
[2024-11-13 07:36:12,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:13,148][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.7846094369888306, acc: 0.5138888955116272)
[2024-11-13 07:36:13,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:13,460][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.09631085395813, acc: 0.4215686321258545)
[2024-11-13 07:36:13,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:14,180][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.4835071563720703, acc: 0.3904109597206116)
[2024-11-13 07:36:14,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:14,470][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.3147259950637817, acc: 0.7083333134651184)
[2024-11-13 07:36:14,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:14,787][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 1.168002963066101, acc: 0.6666666865348816)
[2024-11-13 07:36:14,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:15,082][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.6907235383987427, acc: 0.6071428656578064)
[2024-11-13 07:36:15,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:15,521][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 1.8702486753463745, acc: 0.5221238732337952)
[2024-11-13 07:36:15,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:15,830][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 1.9094364643096924, acc: 0.47826087474823)
[2024-11-13 07:36:15,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:16,151][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 2.0062544345855713, acc: 0.46590909361839294)
[2024-11-13 07:36:16,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:16,787][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 2.460853338241577, acc: 0.37404578924179077)
[2024-11-13 07:36:16,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:17,283][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 2.3435466289520264, acc: 0.34074074029922485)
[2024-11-13 07:36:17,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:17,562][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 1.7268832921981812, acc: 0.5245901346206665)
[2024-11-13 07:36:17,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:17,832][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 0.9981827735900879, acc: 0.6666666865348816)
[2024-11-13 07:36:17,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:18,123][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 1.7180262804031372, acc: 0.6000000238418579)
[2024-11-13 07:36:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:18,442][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 1.3932859897613525, acc: 0.6428571343421936)
[2024-11-13 07:36:18,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:18,760][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 2.277790069580078, acc: 0.353658527135849)
[2024-11-13 07:36:18,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:19,080][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 2.450852394104004, acc: 0.347432017326355)
[2024-11-13 07:36:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:19,374][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.491992473602295, acc: 0.33717578649520874)
[2024-11-13 07:36:19,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:19,767][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.504121780395508, acc: 0.36250001192092896)
[2024-11-13 07:36:19,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:20,213][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.3008110523223877, acc: 0.38273921608924866)
[2024-11-13 07:36:20,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:20,551][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.2868003845214844, acc: 0.3701067566871643)
[2024-11-13 07:36:20,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:20,875][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 2.7472140789031982, acc: 0.4000000059604645)
[2024-11-13 07:36:20,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:21,301][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.4471869468688965, acc: 0.41860464215278625)
[2024-11-13 07:36:21,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:21,864][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.1162781715393066, acc: 0.5079365372657776)
[2024-11-13 07:36:22,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:22,491][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.1683297157287598, acc: 0.469696968793869)
[2024-11-13 07:36:22,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:23,027][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 1.9289418458938599, acc: 0.5176470875740051)
[2024-11-13 07:36:23,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:23,762][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 1.8654347658157349, acc: 0.5123456716537476)
[2024-11-13 07:36:23,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:24,415][root][INFO] - Training Epoch: 2/10, step 195/574 completed (loss: 1.524627447128296, acc: 0.5806451439857483)
[2024-11-13 07:36:24,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:24,719][root][INFO] - Training Epoch: 2/10, step 196/574 completed (loss: 0.9178179502487183, acc: 0.8214285969734192)
[2024-11-13 07:36:24,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:25,042][root][INFO] - Training Epoch: 2/10, step 197/574 completed (loss: 2.0957586765289307, acc: 0.5)
[2024-11-13 07:36:25,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:25,382][root][INFO] - Training Epoch: 2/10, step 198/574 completed (loss: 2.298678159713745, acc: 0.3970588147640228)
[2024-11-13 07:36:25,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:25,668][root][INFO] - Training Epoch: 2/10, step 199/574 completed (loss: 2.211225986480713, acc: 0.4485294222831726)
[2024-11-13 07:36:25,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:26,003][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 2.377401113510132, acc: 0.3813559412956238)
[2024-11-13 07:36:26,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:26,312][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 2.408346652984619, acc: 0.4253731369972229)
[2024-11-13 07:36:26,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:26,700][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.343329906463623, acc: 0.35922330617904663)
[2024-11-13 07:36:26,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:26,992][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 2.105029344558716, acc: 0.460317462682724)
[2024-11-13 07:36:27,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:27,251][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 2.070655345916748, acc: 0.4285714328289032)
[2024-11-13 07:36:27,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:27,622][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.3216400146484375, acc: 0.3856502175331116)
[2024-11-13 07:36:27,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:28,002][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.1730387210845947, acc: 0.4488188922405243)
[2024-11-13 07:36:28,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:28,324][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 2.200617790222168, acc: 0.4051724076271057)
[2024-11-13 07:36:28,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:28,702][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.113795518875122, acc: 0.4384058117866516)
[2024-11-13 07:36:28,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:29,064][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.3375518321990967, acc: 0.33852139115333557)
[2024-11-13 07:36:29,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:29,439][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.4389290809631348, acc: 0.3695652186870575)
[2024-11-13 07:36:29,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:29,772][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.8011999130249023, acc: 0.5652173757553101)
[2024-11-13 07:36:29,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:30,066][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 2.083170175552368, acc: 0.5)
[2024-11-13 07:36:30,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:30,389][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.6974300146102905, acc: 0.4893617033958435)
[2024-11-13 07:36:30,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:30,897][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 1.8895220756530762, acc: 0.5)
[2024-11-13 07:36:30,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:31,213][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 1.7503563165664673, acc: 0.5)
[2024-11-13 07:36:31,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:31,514][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 1.7602964639663696, acc: 0.4767441749572754)
[2024-11-13 07:36:31,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:31,945][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 1.8675140142440796, acc: 0.5135135054588318)
[2024-11-13 07:36:32,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:32,296][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 1.841404676437378, acc: 0.5)
[2024-11-13 07:36:32,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:32,559][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 1.0153335332870483, acc: 0.6666666865348816)
[2024-11-13 07:36:32,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:32,815][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.49529939889907837, acc: 0.8888888955116272)
[2024-11-13 07:36:32,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:33,107][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 1.0395920276641846, acc: 0.6800000071525574)
[2024-11-13 07:36:33,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:33,413][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 2.2172064781188965, acc: 0.4038461446762085)
[2024-11-13 07:36:33,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:33,979][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 1.8582038879394531, acc: 0.510869562625885)
[2024-11-13 07:36:34,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:34,412][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 2.105752944946289, acc: 0.40909090638160706)
[2024-11-13 07:36:34,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:34,811][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 2.3326938152313232, acc: 0.3617021143436432)
[2024-11-13 07:36:34,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:35,191][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 1.804323434829712, acc: 0.5471698045730591)
[2024-11-13 07:36:35,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:35,549][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 1.9944521188735962, acc: 0.46666666865348816)
[2024-11-13 07:36:35,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:35,837][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.421069860458374, acc: 0.6279069781303406)
[2024-11-13 07:36:35,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:36,141][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 1.137585163116455, acc: 0.7333333492279053)
[2024-11-13 07:36:36,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:36,544][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 2.4297373294830322, acc: 0.3368421196937561)
[2024-11-13 07:36:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:36,870][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 1.9001725912094116, acc: 0.5111111402511597)
[2024-11-13 07:36:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:37,235][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 1.7311152219772339, acc: 0.550000011920929)
[2024-11-13 07:36:37,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:37,636][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 1.8564953804016113, acc: 0.5412843823432922)
[2024-11-13 07:36:37,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:38,028][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 1.786146879196167, acc: 0.5307692289352417)
[2024-11-13 07:36:38,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:38,367][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 1.720534086227417, acc: 0.4736842215061188)
[2024-11-13 07:36:38,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:38,681][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.5285873413085938, acc: 0.625)
[2024-11-13 07:36:38,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:38,959][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 2.814218759536743, acc: 0.27272728085517883)
[2024-11-13 07:36:39,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:39,234][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.7018495798110962, acc: 0.4444444477558136)
[2024-11-13 07:36:39,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:39,534][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.6804150342941284, acc: 0.5428571701049805)
[2024-11-13 07:36:39,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:39,789][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.5747030973434448, acc: 0.5909090638160706)
[2024-11-13 07:36:39,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:40,036][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 2.1062867641448975, acc: 0.40909090638160706)
[2024-11-13 07:36:40,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:40,488][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.09397292137146, acc: 0.4032258093357086)
[2024-11-13 07:36:40,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:40,883][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 1.6803587675094604, acc: 0.5454545617103577)
[2024-11-13 07:36:40,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:41,191][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 0.816009521484375, acc: 0.761904776096344)
[2024-11-13 07:36:41,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:41,510][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.3291059732437134, acc: 0.692307710647583)
[2024-11-13 07:36:41,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:41,864][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.5269759893417358, acc: 0.5806451439857483)
[2024-11-13 07:36:41,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:42,165][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.2123290300369263, acc: 0.5)
[2024-11-13 07:36:42,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:42,490][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.5149346590042114, acc: 0.45945945382118225)
[2024-11-13 07:36:42,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:42,787][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.697313666343689, acc: 0.4054054021835327)
[2024-11-13 07:36:42,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:43,068][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.6175756454467773, acc: 0.4864864945411682)
[2024-11-13 07:36:43,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:43,434][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 2.010457992553711, acc: 0.47058823704719543)
[2024-11-13 07:36:43,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:43,781][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 0.7869822978973389, acc: 0.7560975551605225)
[2024-11-13 07:36:43,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:44,095][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 0.46013563871383667, acc: 0.8399999737739563)
[2024-11-13 07:36:44,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:44,396][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.4819534718990326, acc: 0.8799999952316284)
[2024-11-13 07:36:44,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:44,660][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 0.6192604899406433, acc: 0.8709677457809448)
[2024-11-13 07:36:44,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:45,037][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 1.9224308729171753, acc: 0.4736842215061188)
[2024-11-13 07:36:45,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:45,374][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 1.9792554378509521, acc: 0.5)
[2024-11-13 07:36:45,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:45,746][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.5876706838607788, acc: 0.5789473652839661)
[2024-11-13 07:36:45,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:46,202][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 1.8755383491516113, acc: 0.4811320900917053)
[2024-11-13 07:36:46,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:46,656][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 2.016280174255371, acc: 0.5083333253860474)
[2024-11-13 07:36:46,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:46,999][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 1.4403414726257324, acc: 0.5833333134651184)
[2024-11-13 07:36:47,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:47,314][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 2.2432868480682373, acc: 0.4516128897666931)
[2024-11-13 07:36:47,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:47,680][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 2.9143013954162598, acc: 0.3199999928474426)
[2024-11-13 07:36:47,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:48,004][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 2.409391164779663, acc: 0.4166666567325592)
[2024-11-13 07:36:48,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:48,590][root][INFO] - Training Epoch: 2/10, step 265/574 completed (loss: 2.5185303688049316, acc: 0.35199999809265137)
[2024-11-13 07:36:48,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:48,912][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 2.1706435680389404, acc: 0.4157303273677826)
[2024-11-13 07:36:49,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:49,277][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 2.3183178901672363, acc: 0.4324324429035187)
[2024-11-13 07:36:49,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:49,646][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 1.641902208328247, acc: 0.568965494632721)
[2024-11-13 07:36:49,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:49,911][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 1.5521811246871948, acc: 0.6363636255264282)
[2024-11-13 07:36:49,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:50,207][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 1.452669620513916, acc: 0.5909090638160706)
[2024-11-13 07:36:50,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:50,545][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 1.09342622756958, acc: 0.65625)
[2024-11-13 07:36:50,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:50,882][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 1.2771695852279663, acc: 0.6666666865348816)
[2024-11-13 07:36:50,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:51,244][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 2.1234312057495117, acc: 0.46666666865348816)
[2024-11-13 07:36:51,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:51,497][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 1.5545729398727417, acc: 0.53125)
[2024-11-13 07:36:51,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:51,861][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 1.2191650867462158, acc: 0.6666666865348816)
[2024-11-13 07:36:51,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:52,171][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 1.65646231174469, acc: 0.6551724076271057)
[2024-11-13 07:36:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:52,530][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 1.439017653465271, acc: 0.6000000238418579)
[2024-11-13 07:36:52,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:52,840][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 2.307644844055176, acc: 0.3404255211353302)
[2024-11-13 07:36:52,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:53,081][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.9789611101150513, acc: 0.5416666865348816)
[2024-11-13 07:36:53,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:53,374][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 1.6743264198303223, acc: 0.5909090638160706)
[2024-11-13 07:36:53,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:53,723][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.258815050125122, acc: 0.40963855385780334)
[2024-11-13 07:36:53,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:54,035][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 2.1009998321533203, acc: 0.45370370149612427)
[2024-11-13 07:36:54,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:54,350][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 2.4237239360809326, acc: 0.2368421107530594)
[2024-11-13 07:36:55,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:55,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:55,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:56,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:56,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:56,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:56,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:57,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:57,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:57,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:57,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:58,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:58,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:58,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:59,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:59,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:59,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:36:59,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:00,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:00,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:00,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:00,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:01,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:01,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:01,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:01,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:02,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:02,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:02,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:02,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:03,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:03,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:03,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:04,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:04,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:04,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:05,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:05,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:05,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:05,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:06,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:06,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:06,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:07,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:07,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:07,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:07,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:07,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:08,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:08,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:08,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:09,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:09,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:09,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:09,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:10,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:10,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:10,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:11,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:11,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:11,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:12,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:12,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:12,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:12,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:13,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:13,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:13,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:14,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:14,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:14,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:14,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:15,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:15,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:15,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:15,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:16,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:16,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:16,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:17,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:17,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:17,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:18,066][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.9412, device='cuda:0') eval_epoch_loss=tensor(1.9375, device='cuda:0') eval_epoch_acc=tensor(0.4905, device='cuda:0')
[2024-11-13 07:37:18,068][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:37:18,068][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:37:18,410][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_2_step_284_loss_1.9374691247940063/model.pt
[2024-11-13 07:37:18,413][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:37:18,414][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.9374691247940063
[2024-11-13 07:37:18,414][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.4904656410217285
[2024-11-13 07:37:18,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:18,800][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 2.4417824745178223, acc: 0.29411765933036804)
[2024-11-13 07:37:18,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:19,097][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 2.129774808883667, acc: 0.30000001192092896)
[2024-11-13 07:37:19,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:19,456][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.1854870319366455, acc: 0.359375)
[2024-11-13 07:37:19,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:19,762][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 2.400296449661255, acc: 0.36000001430511475)
[2024-11-13 07:37:19,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:20,016][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 2.0243289470672607, acc: 0.4395604431629181)
[2024-11-13 07:37:20,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:20,294][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 2.4098451137542725, acc: 0.3354037404060364)
[2024-11-13 07:37:20,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:20,596][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.4471330642700195, acc: 0.3659793734550476)
[2024-11-13 07:37:20,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:20,875][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.020371675491333, acc: 0.7272727489471436)
[2024-11-13 07:37:20,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:21,167][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 2.1104207038879395, acc: 0.4285714328289032)
[2024-11-13 07:37:21,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:21,477][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.554917812347412, acc: 0.6206896305084229)
[2024-11-13 07:37:21,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:21,839][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.3574060201644897, acc: 0.6363636255264282)
[2024-11-13 07:37:21,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:22,278][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 1.865118384361267, acc: 0.5206185579299927)
[2024-11-13 07:37:22,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:22,548][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 2.1862428188323975, acc: 0.4482758641242981)
[2024-11-13 07:37:22,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:22,835][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 1.937347173690796, acc: 0.48148149251937866)
[2024-11-13 07:37:22,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:23,126][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 2.043519973754883, acc: 0.42105263471603394)
[2024-11-13 07:37:23,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:23,429][root][INFO] - Training Epoch: 2/10, step 299/574 completed (loss: 1.8789396286010742, acc: 0.5714285969734192)
[2024-11-13 07:37:23,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:23,742][root][INFO] - Training Epoch: 2/10, step 300/574 completed (loss: 1.8811143636703491, acc: 0.53125)
[2024-11-13 07:37:23,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:24,059][root][INFO] - Training Epoch: 2/10, step 301/574 completed (loss: 2.0176994800567627, acc: 0.49056604504585266)
[2024-11-13 07:37:24,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:24,369][root][INFO] - Training Epoch: 2/10, step 302/574 completed (loss: 1.1343400478363037, acc: 0.698113203048706)
[2024-11-13 07:37:24,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:24,675][root][INFO] - Training Epoch: 2/10, step 303/574 completed (loss: 1.3258315324783325, acc: 0.6764705777168274)
[2024-11-13 07:37:24,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:24,958][root][INFO] - Training Epoch: 2/10, step 304/574 completed (loss: 2.0620384216308594, acc: 0.4375)
[2024-11-13 07:37:25,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:25,294][root][INFO] - Training Epoch: 2/10, step 305/574 completed (loss: 1.5134451389312744, acc: 0.6229507923126221)
[2024-11-13 07:37:25,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:25,611][root][INFO] - Training Epoch: 2/10, step 306/574 completed (loss: 0.9279793500900269, acc: 0.800000011920929)
[2024-11-13 07:37:25,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:25,922][root][INFO] - Training Epoch: 2/10, step 307/574 completed (loss: 0.5305285453796387, acc: 0.8421052694320679)
[2024-11-13 07:37:25,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:26,230][root][INFO] - Training Epoch: 2/10, step 308/574 completed (loss: 2.147015333175659, acc: 0.43478259444236755)
[2024-11-13 07:37:26,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:26,593][root][INFO] - Training Epoch: 2/10, step 309/574 completed (loss: 1.889853835105896, acc: 0.5694444179534912)
[2024-11-13 07:37:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:26,881][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 1.8337863683700562, acc: 0.4939759075641632)
[2024-11-13 07:37:26,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:27,171][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 2.323479175567627, acc: 0.3461538553237915)
[2024-11-13 07:37:27,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:27,473][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 2.387267589569092, acc: 0.3979591727256775)
[2024-11-13 07:37:27,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:27,744][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.3328295052051544, acc: 0.9166666865348816)
[2024-11-13 07:37:27,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:28,059][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 1.5332351922988892, acc: 0.625)
[2024-11-13 07:37:28,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:28,370][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 0.9769280552864075, acc: 0.7096773982048035)
[2024-11-13 07:37:28,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:28,658][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 1.3615188598632812, acc: 0.6129032373428345)
[2024-11-13 07:37:28,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:28,946][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 1.5563212633132935, acc: 0.5671641826629639)
[2024-11-13 07:37:29,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:29,241][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 1.4933202266693115, acc: 0.5961538553237915)
[2024-11-13 07:37:29,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:29,499][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 2.057887077331543, acc: 0.35555556416511536)
[2024-11-13 07:37:29,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:29,802][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 1.6829630136489868, acc: 0.5322580933570862)
[2024-11-13 07:37:29,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:30,105][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 1.1047992706298828, acc: 0.7200000286102295)
[2024-11-13 07:37:30,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:30,386][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.4281771183013916, acc: 0.3333333432674408)
[2024-11-13 07:37:30,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:30,669][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.3972203731536865, acc: 0.1428571492433548)
[2024-11-13 07:37:30,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:30,977][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 2.474930763244629, acc: 0.3076923191547394)
[2024-11-13 07:37:31,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:31,280][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 2.4433107376098633, acc: 0.4390243887901306)
[2024-11-13 07:37:31,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:31,578][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.126575231552124, acc: 0.42105263471603394)
[2024-11-13 07:37:31,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:31,902][root][INFO] - Training Epoch: 2/10, step 327/574 completed (loss: 1.6098225116729736, acc: 0.4736842215061188)
[2024-11-13 07:37:31,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:32,218][root][INFO] - Training Epoch: 2/10, step 328/574 completed (loss: 1.0184447765350342, acc: 0.7142857313156128)
[2024-11-13 07:37:32,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:32,531][root][INFO] - Training Epoch: 2/10, step 329/574 completed (loss: 2.046686887741089, acc: 0.48148149251937866)
[2024-11-13 07:37:32,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:32,837][root][INFO] - Training Epoch: 2/10, step 330/574 completed (loss: 0.9680963158607483, acc: 0.75)
[2024-11-13 07:37:32,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:33,156][root][INFO] - Training Epoch: 2/10, step 331/574 completed (loss: 2.041409730911255, acc: 0.4838709533214569)
[2024-11-13 07:37:33,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:33,483][root][INFO] - Training Epoch: 2/10, step 332/574 completed (loss: 1.8230057954788208, acc: 0.45614033937454224)
[2024-11-13 07:37:33,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:33,762][root][INFO] - Training Epoch: 2/10, step 333/574 completed (loss: 2.4038889408111572, acc: 0.3125)
[2024-11-13 07:37:33,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:34,089][root][INFO] - Training Epoch: 2/10, step 334/574 completed (loss: 1.5338512659072876, acc: 0.5333333611488342)
[2024-11-13 07:37:34,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:34,378][root][INFO] - Training Epoch: 2/10, step 335/574 completed (loss: 1.996660590171814, acc: 0.42105263471603394)
[2024-11-13 07:37:34,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:34,699][root][INFO] - Training Epoch: 2/10, step 336/574 completed (loss: 2.1873366832733154, acc: 0.41999998688697815)
[2024-11-13 07:37:34,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:35,008][root][INFO] - Training Epoch: 2/10, step 337/574 completed (loss: 2.2534568309783936, acc: 0.40229883790016174)
[2024-11-13 07:37:35,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:35,317][root][INFO] - Training Epoch: 2/10, step 338/574 completed (loss: 2.372434377670288, acc: 0.3723404109477997)
[2024-11-13 07:37:35,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:35,612][root][INFO] - Training Epoch: 2/10, step 339/574 completed (loss: 2.498856782913208, acc: 0.3855421543121338)
[2024-11-13 07:37:35,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:35,880][root][INFO] - Training Epoch: 2/10, step 340/574 completed (loss: 1.4074013233184814, acc: 0.52173912525177)
[2024-11-13 07:37:35,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:36,170][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 2.197791814804077, acc: 0.5128205418586731)
[2024-11-13 07:37:36,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:36,490][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 2.4478394985198975, acc: 0.3855421543121338)
[2024-11-13 07:37:36,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:36,789][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 1.8418047428131104, acc: 0.5471698045730591)
[2024-11-13 07:37:36,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:37,107][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 2.0779340267181396, acc: 0.4556961953639984)
[2024-11-13 07:37:37,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:37,413][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 1.9431854486465454, acc: 0.5490196347236633)
[2024-11-13 07:37:37,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:37,755][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.454637050628662, acc: 0.3283582031726837)
[2024-11-13 07:37:37,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:38,064][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 1.1581461429595947, acc: 0.699999988079071)
[2024-11-13 07:37:38,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:38,376][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 1.6592007875442505, acc: 0.5600000023841858)
[2024-11-13 07:37:38,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:38,683][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.3863381147384644, acc: 0.6388888955116272)
[2024-11-13 07:37:38,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:38,968][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.9773533344268799, acc: 0.5116279125213623)
[2024-11-13 07:37:39,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:39,295][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 1.9038602113723755, acc: 0.43589743971824646)
[2024-11-13 07:37:39,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:39,623][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 1.9682722091674805, acc: 0.3777777850627899)
[2024-11-13 07:37:39,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:39,898][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.9851705431938171, acc: 0.695652186870575)
[2024-11-13 07:37:39,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:40,212][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.469332218170166, acc: 0.4615384638309479)
[2024-11-13 07:37:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:40,544][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.448931932449341, acc: 0.3956044018268585)
[2024-11-13 07:37:40,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:40,949][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 1.9264824390411377, acc: 0.5043478012084961)
[2024-11-13 07:37:41,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:41,279][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 2.0864815711975098, acc: 0.489130437374115)
[2024-11-13 07:37:41,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:41,613][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 2.163783073425293, acc: 0.40816327929496765)
[2024-11-13 07:37:41,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:41,899][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.5238747000694275, acc: 0.875)
[2024-11-13 07:37:41,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:42,171][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 1.096336841583252, acc: 0.692307710647583)
[2024-11-13 07:37:42,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:42,455][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.7112505435943604, acc: 0.5853658318519592)
[2024-11-13 07:37:42,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:42,749][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 1.8290609121322632, acc: 0.5777778029441833)
[2024-11-13 07:37:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:43,066][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 2.0358827114105225, acc: 0.43421053886413574)
[2024-11-13 07:37:43,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:43,380][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 2.0577070713043213, acc: 0.4878048896789551)
[2024-11-13 07:37:43,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:43,707][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 2.0459060668945312, acc: 0.42424243688583374)
[2024-11-13 07:37:43,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:43,976][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.8410492539405823, acc: 0.75)
[2024-11-13 07:37:44,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:44,252][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.534547746181488, acc: 0.8260869383811951)
[2024-11-13 07:37:44,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:44,534][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.8827958703041077, acc: 0.7142857313156128)
[2024-11-13 07:37:44,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:44,816][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.456747055053711, acc: 0.53125)
[2024-11-13 07:37:44,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:45,280][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 1.8958029747009277, acc: 0.5030303001403809)
[2024-11-13 07:37:45,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:45,861][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.507083535194397, acc: 0.6603773832321167)
[2024-11-13 07:37:45,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:46,155][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.7619420289993286, acc: 0.5222222208976746)
[2024-11-13 07:37:46,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:46,488][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 1.7899305820465088, acc: 0.5178571343421936)
[2024-11-13 07:37:46,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:46,820][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 1.2168775796890259, acc: 0.6285714507102966)
[2024-11-13 07:37:46,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:47,082][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.5164934396743774, acc: 0.9200000166893005)
[2024-11-13 07:37:47,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:47,403][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.7011995911598206, acc: 0.695652186870575)
[2024-11-13 07:37:47,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:47,726][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 2.3084182739257812, acc: 0.375)
[2024-11-13 07:37:47,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:48,022][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 1.8513766527175903, acc: 0.5052631497383118)
[2024-11-13 07:37:48,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:48,486][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 1.865588903427124, acc: 0.5508981943130493)
[2024-11-13 07:37:48,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:48,836][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.748873233795166, acc: 0.5338345766067505)
[2024-11-13 07:37:49,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:49,582][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.7462431192398071, acc: 0.5240641832351685)
[2024-11-13 07:37:49,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:50,028][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 1.5355501174926758, acc: 0.6036036014556885)
[2024-11-13 07:37:50,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:50,306][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 0.8359648585319519, acc: 0.75)
[2024-11-13 07:37:50,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:50,620][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 0.7666543126106262, acc: 0.7857142686843872)
[2024-11-13 07:37:50,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:50,918][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 1.5770087242126465, acc: 0.59375)
[2024-11-13 07:37:50,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:51,257][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 1.402330994606018, acc: 0.6111111044883728)
[2024-11-13 07:37:51,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:51,576][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 1.3634182214736938, acc: 0.6842105388641357)
[2024-11-13 07:37:51,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:51,879][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.7841798663139343, acc: 0.7272727489471436)
[2024-11-13 07:37:51,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:52,198][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 1.2620737552642822, acc: 0.6000000238418579)
[2024-11-13 07:37:52,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:52,497][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.4424717426300049, acc: 0.6190476417541504)
[2024-11-13 07:37:52,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:52,794][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 2.6388211250305176, acc: 0.3888888955116272)
[2024-11-13 07:37:52,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:53,083][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 2.4402756690979004, acc: 0.40776699781417847)
[2024-11-13 07:37:53,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:53,500][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 1.9933466911315918, acc: 0.5220588445663452)
[2024-11-13 07:37:53,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:53,815][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 2.3158631324768066, acc: 0.4466666579246521)
[2024-11-13 07:37:53,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:54,149][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 2.161064386367798, acc: 0.4583333432674408)
[2024-11-13 07:37:54,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:54,462][root][INFO] - Training Epoch: 2/10, step 396/574 completed (loss: 2.199031352996826, acc: 0.5116279125213623)
[2024-11-13 07:37:54,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:54,768][root][INFO] - Training Epoch: 2/10, step 397/574 completed (loss: 1.160462498664856, acc: 0.6666666865348816)
[2024-11-13 07:37:54,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:55,093][root][INFO] - Training Epoch: 2/10, step 398/574 completed (loss: 1.62860107421875, acc: 0.5581395626068115)
[2024-11-13 07:37:55,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:55,403][root][INFO] - Training Epoch: 2/10, step 399/574 completed (loss: 1.553907036781311, acc: 0.5600000023841858)
[2024-11-13 07:37:55,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:55,837][root][INFO] - Training Epoch: 2/10, step 400/574 completed (loss: 2.122852087020874, acc: 0.45588234066963196)
[2024-11-13 07:37:55,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:56,122][root][INFO] - Training Epoch: 2/10, step 401/574 completed (loss: 1.8619065284729004, acc: 0.5066666603088379)
[2024-11-13 07:37:56,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:56,401][root][INFO] - Training Epoch: 2/10, step 402/574 completed (loss: 1.4684089422225952, acc: 0.5757575631141663)
[2024-11-13 07:37:56,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:56,689][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 1.5150750875473022, acc: 0.6060606241226196)
[2024-11-13 07:37:56,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:57,011][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 0.9298697113990784, acc: 0.774193525314331)
[2024-11-13 07:37:57,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:57,321][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 1.44655179977417, acc: 0.5555555820465088)
[2024-11-13 07:37:57,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:57,633][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 0.7554978728294373, acc: 0.800000011920929)
[2024-11-13 07:37:57,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:57,957][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 0.7930156588554382, acc: 0.7777777910232544)
[2024-11-13 07:37:58,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:58,267][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 0.9536686539649963, acc: 0.7037037014961243)
[2024-11-13 07:37:58,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:58,569][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 1.01091468334198, acc: 0.692307710647583)
[2024-11-13 07:37:58,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:58,901][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.4159936904907227, acc: 0.6379310488700867)
[2024-11-13 07:37:58,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:59,229][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 0.9460484385490417, acc: 0.75)
[2024-11-13 07:37:59,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:59,558][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 1.1321215629577637, acc: 0.699999988079071)
[2024-11-13 07:37:59,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:37:59,873][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.3001880645751953, acc: 0.6666666865348816)
[2024-11-13 07:37:59,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:00,176][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 1.3151527643203735, acc: 0.5909090638160706)
[2024-11-13 07:38:00,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:00,521][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 2.273836135864258, acc: 0.4901960790157318)
[2024-11-13 07:38:00,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:00,818][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 2.3364522457122803, acc: 0.5769230723381042)
[2024-11-13 07:38:00,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:01,093][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 2.0693726539611816, acc: 0.5555555820465088)
[2024-11-13 07:38:01,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:01,399][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 1.7591276168823242, acc: 0.5249999761581421)
[2024-11-13 07:38:01,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:01,725][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 2.1475672721862793, acc: 0.4000000059604645)
[2024-11-13 07:38:01,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:02,012][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.6783782839775085, acc: 0.7142857313156128)
[2024-11-13 07:38:02,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:02,301][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.606243371963501, acc: 0.5333333611488342)
[2024-11-13 07:38:02,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:02,641][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.54904043674469, acc: 0.53125)
[2024-11-13 07:38:02,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:02,958][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 1.9663418531417847, acc: 0.5277777910232544)
[2024-11-13 07:38:03,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:03,281][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 1.568573236465454, acc: 0.5925925970077515)
[2024-11-13 07:38:03,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:03,580][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 1.484527826309204, acc: 0.6060606241226196)
[2024-11-13 07:38:03,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:03,910][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 1.38137686252594, acc: 0.6086956262588501)
[2024-11-13 07:38:04,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:04,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:05,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:05,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:05,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:06,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:06,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:06,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:06,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:07,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:07,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:07,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:08,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:08,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:08,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:09,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:09,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:09,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:10,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:10,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:10,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:11,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:11,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:11,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:12,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:12,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:13,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:13,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:13,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:13,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:14,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:14,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:14,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:14,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:15,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:15,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:15,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:16,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:16,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:16,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:16,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:17,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:17,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:17,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:17,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:18,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:18,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:18,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:18,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:19,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:19,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:19,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:20,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:20,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:20,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:21,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:21,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:21,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:22,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:22,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:22,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:23,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:23,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:23,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:23,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:24,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:24,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:24,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:25,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:25,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:25,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:25,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:26,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:26,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:26,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:26,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:27,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:27,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:27,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:28,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:28,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:28,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:29,279][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.2033, device='cuda:0') eval_epoch_loss=tensor(2.1045, device='cuda:0') eval_epoch_acc=tensor(0.4174, device='cuda:0')
[2024-11-13 07:38:29,280][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:38:29,281][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:38:29,651][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_2_step_427_loss_2.1045329570770264/model.pt
[2024-11-13 07:38:29,654][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:38:29,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:29,992][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 1.557411789894104, acc: 0.5945945978164673)
[2024-11-13 07:38:30,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:30,340][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 1.251921534538269, acc: 0.7037037014961243)
[2024-11-13 07:38:30,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:30,652][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 1.6797794103622437, acc: 0.43478259444236755)
[2024-11-13 07:38:30,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:30,949][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.8851471543312073, acc: 0.7777777910232544)
[2024-11-13 07:38:31,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:31,255][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.7303429245948792, acc: 0.7777777910232544)
[2024-11-13 07:38:31,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:31,555][root][INFO] - Training Epoch: 2/10, step 432/574 completed (loss: 1.2124683856964111, acc: 0.6521739363670349)
[2024-11-13 07:38:31,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:31,824][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 1.4255080223083496, acc: 0.6666666865348816)
[2024-11-13 07:38:31,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:32,097][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 0.7547244429588318, acc: 0.800000011920929)
[2024-11-13 07:38:32,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:32,420][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 1.660366415977478, acc: 0.5151515007019043)
[2024-11-13 07:38:32,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:32,755][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 1.5565640926361084, acc: 0.5833333134651184)
[2024-11-13 07:38:32,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:33,069][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 1.6061387062072754, acc: 0.6136363744735718)
[2024-11-13 07:38:33,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:33,355][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.5887283682823181, acc: 0.8571428656578064)
[2024-11-13 07:38:33,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:33,660][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 2.19887375831604, acc: 0.4871794879436493)
[2024-11-13 07:38:33,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:34,033][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 2.205693483352661, acc: 0.43939393758773804)
[2024-11-13 07:38:34,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:34,548][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.6180317401885986, acc: 0.29600000381469727)
[2024-11-13 07:38:34,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:34,891][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.4702296257019043, acc: 0.3629032373428345)
[2024-11-13 07:38:35,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:35,392][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 2.325685739517212, acc: 0.4029850661754608)
[2024-11-13 07:38:35,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:35,696][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 2.157332420349121, acc: 0.4150943458080292)
[2024-11-13 07:38:35,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:36,026][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.3400664329528809, acc: 0.6363636255264282)
[2024-11-13 07:38:36,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:36,295][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 1.7167434692382812, acc: 0.5652173757553101)
[2024-11-13 07:38:36,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:36,565][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.9690455198287964, acc: 0.42307692766189575)
[2024-11-13 07:38:36,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:36,851][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 1.23654043674469, acc: 0.7142857313156128)
[2024-11-13 07:38:36,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:37,135][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 2.207080125808716, acc: 0.38805970549583435)
[2024-11-13 07:38:37,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:37,437][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 1.9497675895690918, acc: 0.4861111044883728)
[2024-11-13 07:38:37,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:37,727][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 2.1291258335113525, acc: 0.3913043439388275)
[2024-11-13 07:38:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:38,018][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 2.245452642440796, acc: 0.43589743971824646)
[2024-11-13 07:38:38,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:38,317][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 2.558346748352051, acc: 0.3947368562221527)
[2024-11-13 07:38:38,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:38,627][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.9203475713729858, acc: 0.4897959232330322)
[2024-11-13 07:38:38,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:38,942][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.5891133546829224, acc: 0.6060606241226196)
[2024-11-13 07:38:39,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:39,246][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 2.1876237392425537, acc: 0.3814432919025421)
[2024-11-13 07:38:39,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:39,541][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.8963254690170288, acc: 0.48571428656578064)
[2024-11-13 07:38:39,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:39,883][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 2.0783092975616455, acc: 0.447674423456192)
[2024-11-13 07:38:39,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:40,179][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 2.406836748123169, acc: 0.375)
[2024-11-13 07:38:40,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:40,485][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 2.12809419631958, acc: 0.40740740299224854)
[2024-11-13 07:38:40,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:40,818][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.6937692165374756, acc: 0.5277777910232544)
[2024-11-13 07:38:40,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:41,129][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 1.5994408130645752, acc: 0.5625)
[2024-11-13 07:38:41,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:41,420][root][INFO] - Training Epoch: 2/10, step 463/574 completed (loss: 1.567123293876648, acc: 0.5)
[2024-11-13 07:38:41,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:41,727][root][INFO] - Training Epoch: 2/10, step 464/574 completed (loss: 1.938531756401062, acc: 0.5)
[2024-11-13 07:38:41,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:41,985][root][INFO] - Training Epoch: 2/10, step 465/574 completed (loss: 2.1203410625457764, acc: 0.369047611951828)
[2024-11-13 07:38:42,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:42,265][root][INFO] - Training Epoch: 2/10, step 466/574 completed (loss: 2.120058059692383, acc: 0.3614457845687866)
[2024-11-13 07:38:42,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:42,553][root][INFO] - Training Epoch: 2/10, step 467/574 completed (loss: 1.8803088665008545, acc: 0.46846845746040344)
[2024-11-13 07:38:42,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:42,834][root][INFO] - Training Epoch: 2/10, step 468/574 completed (loss: 1.96786630153656, acc: 0.4757281541824341)
[2024-11-13 07:38:42,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:43,142][root][INFO] - Training Epoch: 2/10, step 469/574 completed (loss: 1.7645922899246216, acc: 0.5528455376625061)
[2024-11-13 07:38:43,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:43,469][root][INFO] - Training Epoch: 2/10, step 470/574 completed (loss: 1.670197606086731, acc: 0.5833333134651184)
[2024-11-13 07:38:43,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:43,757][root][INFO] - Training Epoch: 2/10, step 471/574 completed (loss: 2.4646224975585938, acc: 0.25)
[2024-11-13 07:38:43,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:44,099][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 2.3059964179992676, acc: 0.36274510622024536)
[2024-11-13 07:38:44,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:44,443][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 2.3620543479919434, acc: 0.37991267442703247)
[2024-11-13 07:38:44,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:44,738][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 2.276323080062866, acc: 0.3958333432674408)
[2024-11-13 07:38:44,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:45,038][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 2.285083293914795, acc: 0.349693238735199)
[2024-11-13 07:38:45,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:45,357][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 2.3121190071105957, acc: 0.3884892165660858)
[2024-11-13 07:38:45,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:45,716][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 2.294086456298828, acc: 0.38693466782569885)
[2024-11-13 07:38:45,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:46,023][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.4945825338363647, acc: 0.5555555820465088)
[2024-11-13 07:38:46,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:46,334][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.5396690368652344, acc: 0.5454545617103577)
[2024-11-13 07:38:46,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:46,662][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.35434091091156, acc: 0.5925925970077515)
[2024-11-13 07:38:46,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:46,988][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.612539291381836, acc: 0.5)
[2024-11-13 07:38:47,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:47,265][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 0.8618966341018677, acc: 0.75)
[2024-11-13 07:38:47,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:47,589][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.6468660831451416, acc: 0.5517241358757019)
[2024-11-13 07:38:47,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:47,863][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 1.3442715406417847, acc: 0.7096773982048035)
[2024-11-13 07:38:47,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:48,151][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 0.9547637104988098, acc: 0.8947368264198303)
[2024-11-13 07:38:48,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:48,412][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 2.066906690597534, acc: 0.4444444477558136)
[2024-11-13 07:38:48,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:48,713][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 2.158740282058716, acc: 0.3333333432674408)
[2024-11-13 07:38:48,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:49,030][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 1.7559094429016113, acc: 0.5)
[2024-11-13 07:38:49,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:49,382][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 1.9422216415405273, acc: 0.4923076927661896)
[2024-11-13 07:38:49,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:49,670][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 1.4400146007537842, acc: 0.6000000238418579)
[2024-11-13 07:38:49,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:49,985][root][INFO] - Training Epoch: 2/10, step 491/574 completed (loss: 1.569267988204956, acc: 0.517241358757019)
[2024-11-13 07:38:50,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:50,266][root][INFO] - Training Epoch: 2/10, step 492/574 completed (loss: 2.013965606689453, acc: 0.45098039507865906)
[2024-11-13 07:38:50,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:50,580][root][INFO] - Training Epoch: 2/10, step 493/574 completed (loss: 1.7517927885055542, acc: 0.48275861144065857)
[2024-11-13 07:38:50,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:50,925][root][INFO] - Training Epoch: 2/10, step 494/574 completed (loss: 0.8116558194160461, acc: 0.7368420958518982)
[2024-11-13 07:38:51,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:51,285][root][INFO] - Training Epoch: 2/10, step 495/574 completed (loss: 2.747448444366455, acc: 0.2631579041481018)
[2024-11-13 07:38:51,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:51,626][root][INFO] - Training Epoch: 2/10, step 496/574 completed (loss: 1.9676485061645508, acc: 0.4642857015132904)
[2024-11-13 07:38:51,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:51,970][root][INFO] - Training Epoch: 2/10, step 497/574 completed (loss: 2.0595321655273438, acc: 0.43820226192474365)
[2024-11-13 07:38:52,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:52,260][root][INFO] - Training Epoch: 2/10, step 498/574 completed (loss: 2.2676730155944824, acc: 0.3820224702358246)
[2024-11-13 07:38:52,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:52,594][root][INFO] - Training Epoch: 2/10, step 499/574 completed (loss: 2.4123380184173584, acc: 0.3333333432674408)
[2024-11-13 07:38:52,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:52,921][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 2.480560541152954, acc: 0.3695652186870575)
[2024-11-13 07:38:52,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:53,269][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.9751872420310974, acc: 0.800000011920929)
[2024-11-13 07:38:53,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:53,623][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 0.9627549052238464, acc: 0.7692307829856873)
[2024-11-13 07:38:53,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:53,970][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 0.9697749614715576, acc: 0.7407407164573669)
[2024-11-13 07:38:54,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:54,271][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 1.7126710414886475, acc: 0.48148149251937866)
[2024-11-13 07:38:54,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:54,549][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.6542876958847046, acc: 0.5094339847564697)
[2024-11-13 07:38:54,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:54,816][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.2808343172073364, acc: 0.6551724076271057)
[2024-11-13 07:38:54,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:55,264][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 1.9996320009231567, acc: 0.45945945382118225)
[2024-11-13 07:38:55,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:55,640][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.775524616241455, acc: 0.5211267471313477)
[2024-11-13 07:38:55,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:55,972][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.5134655237197876, acc: 0.800000011920929)
[2024-11-13 07:38:56,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:56,295][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.7073000073432922, acc: 0.800000011920929)
[2024-11-13 07:38:56,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:56,652][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 1.221444010734558, acc: 0.692307710647583)
[2024-11-13 07:38:56,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:57,853][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.078251838684082, acc: 0.5)
[2024-11-13 07:38:57,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:58,403][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 2.028898000717163, acc: 0.5079365372657776)
[2024-11-13 07:38:58,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:58,629][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.515163540840149, acc: 0.6071428656578064)
[2024-11-13 07:38:58,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:58,988][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 1.641151785850525, acc: 0.550000011920929)
[2024-11-13 07:38:59,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:59,518][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.6723456382751465, acc: 0.6111111044883728)
[2024-11-13 07:38:59,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:38:59,776][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.5226622819900513, acc: 0.807692289352417)
[2024-11-13 07:38:59,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:00,102][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 1.5689257383346558, acc: 0.6129032373428345)
[2024-11-13 07:39:00,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:00,403][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 2.002197742462158, acc: 0.550000011920929)
[2024-11-13 07:39:00,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:00,696][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 2.203462839126587, acc: 0.4444444477558136)
[2024-11-13 07:39:00,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:01,385][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 2.145212173461914, acc: 0.43220338225364685)
[2024-11-13 07:39:01,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:01,691][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 2.2226293087005615, acc: 0.44029849767684937)
[2024-11-13 07:39:01,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:02,006][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 2.2497708797454834, acc: 0.38686132431030273)
[2024-11-13 07:39:02,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:02,446][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 2.0483620166778564, acc: 0.44999998807907104)
[2024-11-13 07:39:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:02,749][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 2.150576114654541, acc: 0.40740740299224854)
[2024-11-13 07:39:02,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:03,067][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 1.8397343158721924, acc: 0.48076921701431274)
[2024-11-13 07:39:03,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:03,357][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 2.358375310897827, acc: 0.2380952388048172)
[2024-11-13 07:39:03,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:03,708][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.8697972297668457, acc: 0.24590164422988892)
[2024-11-13 07:39:03,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:03,996][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 1.899561882019043, acc: 0.49152541160583496)
[2024-11-13 07:39:04,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:04,289][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.372253656387329, acc: 0.41860464215278625)
[2024-11-13 07:39:04,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:04,577][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 2.2056081295013428, acc: 0.47727271914482117)
[2024-11-13 07:39:04,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:04,903][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.422095775604248, acc: 0.43396225571632385)
[2024-11-13 07:39:04,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:05,215][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.852027416229248, acc: 0.5681818127632141)
[2024-11-13 07:39:05,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:05,479][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.7504229545593262, acc: 0.6000000238418579)
[2024-11-13 07:39:05,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:05,770][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 1.6426624059677124, acc: 0.44999998807907104)
[2024-11-13 07:39:05,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:06,046][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 1.2371070384979248, acc: 0.6363636255264282)
[2024-11-13 07:39:06,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:06,385][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 1.9450548887252808, acc: 0.5230769515037537)
[2024-11-13 07:39:06,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:06,667][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 1.8045085668563843, acc: 0.53125)
[2024-11-13 07:39:06,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:06,992][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 1.2025947570800781, acc: 0.75)
[2024-11-13 07:39:07,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:07,257][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 1.772762417793274, acc: 0.5151515007019043)
[2024-11-13 07:39:07,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:07,539][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.8193225264549255, acc: 0.75)
[2024-11-13 07:39:07,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:07,846][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 0.9233133792877197, acc: 0.774193525314331)
[2024-11-13 07:39:07,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:08,144][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.626278817653656, acc: 0.782608687877655)
[2024-11-13 07:39:08,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:08,426][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 1.9529577493667603, acc: 0.46666666865348816)
[2024-11-13 07:39:08,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:08,730][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 1.592084527015686, acc: 0.46341463923454285)
[2024-11-13 07:39:08,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:09,001][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 1.2028124332427979, acc: 0.6857143044471741)
[2024-11-13 07:39:09,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:09,293][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 1.3288946151733398, acc: 0.6052631735801697)
[2024-11-13 07:39:09,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:09,585][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 1.2321537733078003, acc: 0.6129032373428345)
[2024-11-13 07:39:09,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:09,899][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.74981290102005, acc: 0.800000011920929)
[2024-11-13 07:39:09,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:10,214][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 1.4565399885177612, acc: 0.5757575631141663)
[2024-11-13 07:39:10,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:10,497][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 1.1813232898712158, acc: 0.6499999761581421)
[2024-11-13 07:39:10,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:10,769][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 1.4727587699890137, acc: 0.5857142806053162)
[2024-11-13 07:39:10,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:11,084][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 2.269780397415161, acc: 0.37226277589797974)
[2024-11-13 07:39:11,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:11,399][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.852203130722046, acc: 0.5103448033332825)
[2024-11-13 07:39:11,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:11,720][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 2.518040657043457, acc: 0.3928571343421936)
[2024-11-13 07:39:11,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:12,050][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 2.3933358192443848, acc: 0.34437087178230286)
[2024-11-13 07:39:12,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:12,370][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 1.9425389766693115, acc: 0.5213675498962402)
[2024-11-13 07:39:12,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:12,666][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.6851351857185364, acc: 0.8799999952316284)
[2024-11-13 07:39:12,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:12,962][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 1.267301321029663, acc: 0.6153846383094788)
[2024-11-13 07:39:13,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:13,242][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.7193995714187622, acc: 0.807692289352417)
[2024-11-13 07:39:13,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:13,532][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.8432198762893677, acc: 0.4871794879436493)
[2024-11-13 07:39:13,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:13,861][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.6962164640426636, acc: 0.5222222208976746)
[2024-11-13 07:39:13,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:14,161][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.8347116708755493, acc: 0.4935064911842346)
[2024-11-13 07:39:14,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:14,471][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 1.7691987752914429, acc: 0.4791666567325592)
[2024-11-13 07:39:14,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:14,790][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 1.7010473012924194, acc: 0.5862069129943848)
[2024-11-13 07:39:14,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:15,103][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.8810300827026367, acc: 0.4404761791229248)
[2024-11-13 07:39:15,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:15,410][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 1.7657890319824219, acc: 0.4736842215061188)
[2024-11-13 07:39:15,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:15,706][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 1.4172132015228271, acc: 0.5925925970077515)
[2024-11-13 07:39:15,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:16,046][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 2.047457218170166, acc: 0.4331550896167755)
[2024-11-13 07:39:16,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:17,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:17,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:17,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:17,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:18,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:18,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:18,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:18,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:19,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:19,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:19,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:20,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:20,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:20,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:20,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:21,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:21,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:21,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:22,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:22,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:22,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:23,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:23,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:23,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:23,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:24,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:24,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:24,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:25,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:25,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:25,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:25,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:25,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:26,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:26,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:26,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:27,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:27,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:27,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:27,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:27,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:28,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:28,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:28,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:28,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:29,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:29,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:29,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:29,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:30,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:30,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:30,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:30,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:31,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:31,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:31,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:32,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:32,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:32,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:32,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:33,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:33,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:33,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:34,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:34,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:34,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:34,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:35,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:36,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:36,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:36,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:36,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:37,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:37,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:37,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:37,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:37,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:38,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:38,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:38,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:38,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:39,498][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.5116, device='cuda:0') eval_epoch_loss=tensor(1.8736, device='cuda:0') eval_epoch_acc=tensor(0.5084, device='cuda:0')
[2024-11-13 07:39:39,500][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:39:39,500][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:39:39,850][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_2_step_570_loss_1.8735848665237427/model.pt
[2024-11-13 07:39:39,853][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:39:39,854][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.8735848665237427
[2024-11-13 07:39:39,854][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.508421778678894
[2024-11-13 07:39:39,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:40,243][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 1.4499845504760742, acc: 0.6129032373428345)
[2024-11-13 07:39:40,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:40,593][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 1.9555906057357788, acc: 0.47863247990608215)
[2024-11-13 07:39:40,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:40,898][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 2.2688896656036377, acc: 0.3877550959587097)
[2024-11-13 07:39:40,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:41,209][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 2.198531150817871, acc: 0.3962264060974121)
[2024-11-13 07:39:41,592][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=6.1649, train_epoch_loss=1.8189, epoch time 294.32030698657036s
[2024-11-13 07:39:41,592][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-11-13 07:39:41,592][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 07:39:41,592][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-11-13 07:39:41,592][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 07:39:41,592][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 07:39:42,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:42,280][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.5932790040969849, acc: 0.5555555820465088)
[2024-11-13 07:39:42,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:42,479][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 2.19301176071167, acc: 0.36000001430511475)
[2024-11-13 07:39:42,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:42,819][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 2.5338668823242188, acc: 0.37837839126586914)
[2024-11-13 07:39:42,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:43,139][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 2.195905923843384, acc: 0.2631579041481018)
[2024-11-13 07:39:43,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:43,517][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 2.035567045211792, acc: 0.4864864945411682)
[2024-11-13 07:39:43,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:43,848][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 1.9443503618240356, acc: 0.4285714328289032)
[2024-11-13 07:39:43,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:44,224][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 2.2314627170562744, acc: 0.40816327929496765)
[2024-11-13 07:39:44,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:44,567][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 1.831430196762085, acc: 0.46666666865348816)
[2024-11-13 07:39:44,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:44,881][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.45276546478271484, acc: 0.8181818127632141)
[2024-11-13 07:39:44,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:45,213][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.6834093332290649, acc: 0.7692307829856873)
[2024-11-13 07:39:45,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:45,514][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 1.0826677083969116, acc: 0.7407407164573669)
[2024-11-13 07:39:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:45,850][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 1.819665789604187, acc: 0.5384615659713745)
[2024-11-13 07:39:45,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:46,219][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 1.5400620698928833, acc: 0.5151515007019043)
[2024-11-13 07:39:46,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:46,575][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 1.6686851978302002, acc: 0.5)
[2024-11-13 07:39:46,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:46,903][root][INFO] - Training Epoch: 3/10, step 14/574 completed (loss: 2.0566885471343994, acc: 0.45098039507865906)
[2024-11-13 07:39:46,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:47,149][root][INFO] - Training Epoch: 3/10, step 15/574 completed (loss: 1.6818839311599731, acc: 0.4897959232330322)
[2024-11-13 07:39:47,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:47,443][root][INFO] - Training Epoch: 3/10, step 16/574 completed (loss: 0.9122305512428284, acc: 0.7894737124443054)
[2024-11-13 07:39:47,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:47,768][root][INFO] - Training Epoch: 3/10, step 17/574 completed (loss: 1.5624645948410034, acc: 0.5416666865348816)
[2024-11-13 07:39:47,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:48,116][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 2.104276180267334, acc: 0.3888888955116272)
[2024-11-13 07:39:48,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:48,453][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 1.6040971279144287, acc: 0.5789473652839661)
[2024-11-13 07:39:48,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:48,789][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 1.5135523080825806, acc: 0.5384615659713745)
[2024-11-13 07:39:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:49,125][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 1.625615119934082, acc: 0.6206896305084229)
[2024-11-13 07:39:49,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:49,494][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 1.565037488937378, acc: 0.47999998927116394)
[2024-11-13 07:39:49,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:49,777][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 0.862395703792572, acc: 0.761904776096344)
[2024-11-13 07:39:49,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:50,014][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 1.6037274599075317, acc: 0.5625)
[2024-11-13 07:39:50,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:50,267][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 2.529327154159546, acc: 0.30188679695129395)
[2024-11-13 07:39:50,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:50,504][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 2.3448808193206787, acc: 0.42465752363204956)
[2024-11-13 07:39:50,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:51,242][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.2864885330200195, acc: 0.3913043439388275)
[2024-11-13 07:39:51,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:51,602][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 2.071791410446167, acc: 0.44186046719551086)
[2024-11-13 07:39:51,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:51,935][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 2.168321371078491, acc: 0.40963855385780334)
[2024-11-13 07:39:52,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:52,242][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 2.12768292427063, acc: 0.4197530746459961)
[2024-11-13 07:39:52,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:52,508][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 2.2609450817108154, acc: 0.3928571343421936)
[2024-11-13 07:39:52,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:52,802][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 1.5493462085723877, acc: 0.6296296119689941)
[2024-11-13 07:39:52,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:53,080][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 1.2224719524383545, acc: 0.6086956262588501)
[2024-11-13 07:39:53,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:53,442][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 2.056070566177368, acc: 0.40336135029792786)
[2024-11-13 07:39:53,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:53,796][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 1.7779715061187744, acc: 0.5081967115402222)
[2024-11-13 07:39:53,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:54,071][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 2.0805037021636963, acc: 0.4444444477558136)
[2024-11-13 07:39:54,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:54,382][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 2.1246511936187744, acc: 0.4237288236618042)
[2024-11-13 07:39:54,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:54,720][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 1.5238434076309204, acc: 0.5287356376647949)
[2024-11-13 07:39:54,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:55,023][root][INFO] - Training Epoch: 3/10, step 39/574 completed (loss: 0.8679790496826172, acc: 0.7142857313156128)
[2024-11-13 07:39:55,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:55,397][root][INFO] - Training Epoch: 3/10, step 40/574 completed (loss: 1.7169119119644165, acc: 0.5769230723381042)
[2024-11-13 07:39:55,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:55,771][root][INFO] - Training Epoch: 3/10, step 41/574 completed (loss: 2.548644781112671, acc: 0.3513513505458832)
[2024-11-13 07:39:55,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:56,128][root][INFO] - Training Epoch: 3/10, step 42/574 completed (loss: 1.9915574789047241, acc: 0.4615384638309479)
[2024-11-13 07:39:56,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:56,516][root][INFO] - Training Epoch: 3/10, step 43/574 completed (loss: 2.2900583744049072, acc: 0.46464645862579346)
[2024-11-13 07:39:56,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:56,846][root][INFO] - Training Epoch: 3/10, step 44/574 completed (loss: 1.8098045587539673, acc: 0.5360824465751648)
[2024-11-13 07:39:56,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:57,177][root][INFO] - Training Epoch: 3/10, step 45/574 completed (loss: 2.138902187347412, acc: 0.5)
[2024-11-13 07:39:57,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:57,480][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.8261462450027466, acc: 0.7692307829856873)
[2024-11-13 07:39:57,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:57,749][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.8544237613677979, acc: 0.8148148059844971)
[2024-11-13 07:39:57,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:58,110][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 1.2576667070388794, acc: 0.7142857313156128)
[2024-11-13 07:39:58,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:58,391][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 0.9473329186439514, acc: 0.7222222089767456)
[2024-11-13 07:39:58,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:58,769][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.3804832696914673, acc: 0.6140350699424744)
[2024-11-13 07:39:58,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:59,088][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.4455918073654175, acc: 0.6349206566810608)
[2024-11-13 07:39:59,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:59,426][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 2.0521323680877686, acc: 0.49295774102211)
[2024-11-13 07:39:59,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:39:59,835][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 2.318345308303833, acc: 0.46666666865348816)
[2024-11-13 07:39:59,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:00,178][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.240702748298645, acc: 0.6216216087341309)
[2024-11-13 07:40:00,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:00,470][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.7194704413414001, acc: 0.7692307829856873)
[2024-11-13 07:40:00,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:01,777][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 1.8778440952301025, acc: 0.5051194429397583)
[2024-11-13 07:40:01,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:02,595][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 2.4815597534179688, acc: 0.4008714556694031)
[2024-11-13 07:40:02,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:03,094][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 2.015796661376953, acc: 0.4886363744735718)
[2024-11-13 07:40:03,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:03,552][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 2.2004687786102295, acc: 0.44117647409439087)
[2024-11-13 07:40:03,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:04,016][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 2.384303092956543, acc: 0.3840579688549042)
[2024-11-13 07:40:04,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:04,410][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.7886202335357666, acc: 0.550000011920929)
[2024-11-13 07:40:04,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:04,733][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 1.4757928848266602, acc: 0.6176470518112183)
[2024-11-13 07:40:04,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:05,017][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 1.7761821746826172, acc: 0.5)
[2024-11-13 07:40:05,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:05,283][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 1.630824327468872, acc: 0.578125)
[2024-11-13 07:40:05,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:05,550][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 0.9059122204780579, acc: 0.7586206793785095)
[2024-11-13 07:40:05,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:05,867][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 2.249387264251709, acc: 0.4285714328289032)
[2024-11-13 07:40:05,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:06,204][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 2.021507740020752, acc: 0.46666666865348816)
[2024-11-13 07:40:06,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:06,535][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.6810997128486633, acc: 0.7599999904632568)
[2024-11-13 07:40:06,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:06,877][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.3476743698120117, acc: 0.6111111044883728)
[2024-11-13 07:40:06,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:07,259][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 1.6083698272705078, acc: 0.5757575631141663)
[2024-11-13 07:40:07,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:07,639][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 2.099219560623169, acc: 0.45588234066963196)
[2024-11-13 07:40:07,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:07,988][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 1.9016205072402954, acc: 0.4444444477558136)
[2024-11-13 07:40:08,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:08,271][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 2.223104238510132, acc: 0.3897435963153839)
[2024-11-13 07:40:08,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:08,556][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 1.999810814857483, acc: 0.4591836631298065)
[2024-11-13 07:40:08,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:08,897][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 2.4636125564575195, acc: 0.33582088351249695)
[2024-11-13 07:40:08,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:09,250][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.222358465194702, acc: 0.4051094949245453)
[2024-11-13 07:40:09,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:09,582][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.5328784584999084, acc: 0.9047619104385376)
[2024-11-13 07:40:09,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:09,884][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.5592635273933411, acc: 0.8333333134651184)
[2024-11-13 07:40:09,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:10,228][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 1.2045689821243286, acc: 0.6666666865348816)
[2024-11-13 07:40:10,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:10,489][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.8487842082977295, acc: 0.6538461446762085)
[2024-11-13 07:40:10,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:10,856][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 1.7669752836227417, acc: 0.48076921701431274)
[2024-11-13 07:40:10,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:11,180][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 2.1485800743103027, acc: 0.48076921701431274)
[2024-11-13 07:40:11,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:11,554][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 1.6733776330947876, acc: 0.46875)
[2024-11-13 07:40:11,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:11,900][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 1.9811567068099976, acc: 0.4492753744125366)
[2024-11-13 07:40:11,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:12,247][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.5919712781906128, acc: 0.5600000023841858)
[2024-11-13 07:40:12,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:12,586][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 1.5802048444747925, acc: 0.5652173757553101)
[2024-11-13 07:40:12,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:12,974][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 2.375833511352539, acc: 0.36000001430511475)
[2024-11-13 07:40:13,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:13,308][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.8795275688171387, acc: 0.5145630836486816)
[2024-11-13 07:40:13,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:14,033][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 1.8519129753112793, acc: 0.5145630836486816)
[2024-11-13 07:40:14,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:14,646][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 2.0096609592437744, acc: 0.4516128897666931)
[2024-11-13 07:40:14,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:15,234][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 1.842900276184082, acc: 0.5344827771186829)
[2024-11-13 07:40:15,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:15,796][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.5073730945587158, acc: 0.5684210658073425)
[2024-11-13 07:40:15,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:16,493][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 2.2671995162963867, acc: 0.3465346395969391)
[2024-11-13 07:40:16,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:16,790][root][INFO] - Training Epoch: 3/10, step 94/574 completed (loss: 2.314338207244873, acc: 0.30645161867141724)
[2024-11-13 07:40:16,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:17,085][root][INFO] - Training Epoch: 3/10, step 95/574 completed (loss: 2.27595591545105, acc: 0.4057970941066742)
[2024-11-13 07:40:17,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:17,435][root][INFO] - Training Epoch: 3/10, step 96/574 completed (loss: 2.325706958770752, acc: 0.32773110270500183)
[2024-11-13 07:40:17,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:17,786][root][INFO] - Training Epoch: 3/10, step 97/574 completed (loss: 2.531327247619629, acc: 0.29807692766189575)
[2024-11-13 07:40:17,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:18,149][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 2.3148722648620605, acc: 0.37226277589797974)
[2024-11-13 07:40:18,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:18,494][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 2.407019853591919, acc: 0.3731343150138855)
[2024-11-13 07:40:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:18,816][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 1.0990016460418701, acc: 0.699999988079071)
[2024-11-13 07:40:18,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:19,145][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.9154044985771179, acc: 0.7272727489471436)
[2024-11-13 07:40:19,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:19,469][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 1.059349775314331, acc: 0.695652186870575)
[2024-11-13 07:40:19,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:19,792][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 1.3634450435638428, acc: 0.5681818127632141)
[2024-11-13 07:40:19,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:20,138][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 1.9697318077087402, acc: 0.5)
[2024-11-13 07:40:20,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:20,481][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 1.6931934356689453, acc: 0.5581395626068115)
[2024-11-13 07:40:20,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:20,804][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 1.3471966981887817, acc: 0.6399999856948853)
[2024-11-13 07:40:20,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:21,140][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.6038596630096436, acc: 0.8235294222831726)
[2024-11-13 07:40:21,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:21,470][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.5323962569236755, acc: 0.8461538553237915)
[2024-11-13 07:40:21,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:21,715][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 1.520481824874878, acc: 0.5714285969734192)
[2024-11-13 07:40:21,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:22,071][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 1.8522833585739136, acc: 0.5230769515037537)
[2024-11-13 07:40:22,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:22,445][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.7727504968643188, acc: 0.5614035129547119)
[2024-11-13 07:40:22,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:22,817][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.6436208486557007, acc: 0.5087719559669495)
[2024-11-13 07:40:22,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:23,176][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.829581618309021, acc: 0.5641025900840759)
[2024-11-13 07:40:23,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:23,541][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 1.3566285371780396, acc: 0.6734693646430969)
[2024-11-13 07:40:23,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:23,925][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.49472424387931824, acc: 0.8636363744735718)
[2024-11-13 07:40:24,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:24,288][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 1.9716655015945435, acc: 0.460317462682724)
[2024-11-13 07:40:24,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:24,636][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 1.9047725200653076, acc: 0.5121951103210449)
[2024-11-13 07:40:24,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:24,929][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 1.594909906387329, acc: 0.5806451439857483)
[2024-11-13 07:40:25,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:25,552][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 2.0266335010528564, acc: 0.42965778708457947)
[2024-11-13 07:40:25,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:25,869][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 1.5604445934295654, acc: 0.5866666436195374)
[2024-11-13 07:40:25,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:26,240][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 1.51350998878479, acc: 0.6153846383094788)
[2024-11-13 07:40:26,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:26,592][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.8485288023948669, acc: 0.8333333134651184)
[2024-11-13 07:40:26,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:26,937][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 1.2331302165985107, acc: 0.7368420958518982)
[2024-11-13 07:40:27,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:27,262][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 2.058960199356079, acc: 0.43558281660079956)
[2024-11-13 07:40:27,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:27,644][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.726503610610962, acc: 0.5416666865348816)
[2024-11-13 07:40:27,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:28,003][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 2.1280312538146973, acc: 0.3916666805744171)
[2024-11-13 07:40:28,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:28,358][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.140969753265381, acc: 0.3928571343421936)
[2024-11-13 07:40:28,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:28,715][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.9718844890594482, acc: 0.4923076927661896)
[2024-11-13 07:40:28,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:29,088][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.870893120765686, acc: 0.5073529481887817)
[2024-11-13 07:40:29,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:29,420][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 1.1190197467803955, acc: 0.6538461446762085)
[2024-11-13 07:40:29,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:29,737][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.5733534097671509, acc: 0.782608687877655)
[2024-11-13 07:40:29,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:30,074][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 1.408359408378601, acc: 0.59375)
[2024-11-13 07:40:30,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:30,411][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.9370266199111938, acc: 0.5652173757553101)
[2024-11-13 07:40:30,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:30,706][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.4148846864700317, acc: 0.5714285969734192)
[2024-11-13 07:40:30,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:31,057][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.2387735843658447, acc: 0.6153846383094788)
[2024-11-13 07:40:31,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:31,343][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 2.0551040172576904, acc: 0.3095238208770752)
[2024-11-13 07:40:31,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:31,629][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.6513197422027588, acc: 0.46666666865348816)
[2024-11-13 07:40:31,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:31,924][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 1.7899754047393799, acc: 0.43478259444236755)
[2024-11-13 07:40:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:32,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:33,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:33,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:33,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:33,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:34,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:34,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:34,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:35,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:35,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:35,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:36,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:36,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:36,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:37,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:37,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:37,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:37,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:38,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:38,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:38,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:39,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:39,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:39,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:39,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:40,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:40,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:41,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:41,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:41,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:41,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:42,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:42,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:42,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:42,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:43,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:43,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:43,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:43,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:44,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:44,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:44,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:44,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:45,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:45,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:45,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:46,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:46,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:46,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:46,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:47,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:47,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:47,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:47,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:48,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:48,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:48,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:49,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:49,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:49,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:49,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:50,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:50,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:50,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:50,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:51,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:51,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:51,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:51,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:52,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:52,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:52,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:53,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:53,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:53,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:53,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:54,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:54,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:54,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:55,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:55,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:55,953][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.5265, device='cuda:0') eval_epoch_loss=tensor(1.8759, device='cuda:0') eval_epoch_acc=tensor(0.4978, device='cuda:0')
[2024-11-13 07:40:55,954][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:40:55,954][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:40:56,294][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_3_step_139_loss_1.8758646249771118/model.pt
[2024-11-13 07:40:56,298][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:40:56,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:56,607][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 2.005300998687744, acc: 0.5714285969734192)
[2024-11-13 07:40:56,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:56,886][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 2.1593618392944336, acc: 0.42307692766189575)
[2024-11-13 07:40:56,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:57,190][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 2.7879092693328857, acc: 0.19354838132858276)
[2024-11-13 07:40:57,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:57,482][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 2.159273624420166, acc: 0.45945945382118225)
[2024-11-13 07:40:57,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:57,902][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 2.1765644550323486, acc: 0.3947368562221527)
[2024-11-13 07:40:57,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:58,203][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.7732152938842773, acc: 0.5373134613037109)
[2024-11-13 07:40:58,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:58,558][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 2.318176746368408, acc: 0.3877550959587097)
[2024-11-13 07:40:58,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:58,925][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 2.149984836578369, acc: 0.3404255211353302)
[2024-11-13 07:40:59,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:59,238][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.9478827714920044, acc: 0.4714285731315613)
[2024-11-13 07:40:59,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:59,504][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 2.3267099857330322, acc: 0.4285714328289032)
[2024-11-13 07:40:59,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:40:59,797][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.547376036643982, acc: 0.52173912525177)
[2024-11-13 07:40:59,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:00,084][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 1.955931305885315, acc: 0.3103448152542114)
[2024-11-13 07:41:00,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:00,364][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 2.086555004119873, acc: 0.52173912525177)
[2024-11-13 07:41:00,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:00,688][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 2.077969789505005, acc: 0.4067796468734741)
[2024-11-13 07:41:00,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:00,970][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 2.2886171340942383, acc: 0.4385964870452881)
[2024-11-13 07:41:01,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:01,335][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.9062796831130981, acc: 0.5)
[2024-11-13 07:41:01,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:01,654][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 1.760443091392517, acc: 0.5)
[2024-11-13 07:41:01,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:01,907][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 1.3104318380355835, acc: 0.6086956262588501)
[2024-11-13 07:41:01,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:02,258][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 1.8463939428329468, acc: 0.3684210479259491)
[2024-11-13 07:41:02,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:03,121][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 1.6836086511611938, acc: 0.5675675868988037)
[2024-11-13 07:41:03,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:03,470][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 1.9033156633377075, acc: 0.4444444477558136)
[2024-11-13 07:41:03,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:03,833][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 1.720165729522705, acc: 0.5348837375640869)
[2024-11-13 07:41:03,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:04,280][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 1.6500028371810913, acc: 0.4941176474094391)
[2024-11-13 07:41:04,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:04,722][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 2.035820484161377, acc: 0.4606741666793823)
[2024-11-13 07:41:04,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:05,056][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 1.6867047548294067, acc: 0.5909090638160706)
[2024-11-13 07:41:05,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:05,292][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 1.4905979633331299, acc: 0.523809552192688)
[2024-11-13 07:41:05,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:05,623][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.6059620380401611, acc: 0.4482758641242981)
[2024-11-13 07:41:05,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:05,955][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 1.4451355934143066, acc: 0.5918367505073547)
[2024-11-13 07:41:06,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:06,238][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 1.7305749654769897, acc: 0.46000000834465027)
[2024-11-13 07:41:06,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:06,586][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 1.651992917060852, acc: 0.5416666865348816)
[2024-11-13 07:41:06,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:06,926][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 2.0378315448760986, acc: 0.47058823704719543)
[2024-11-13 07:41:07,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:07,640][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.3954482078552246, acc: 0.4178082048892975)
[2024-11-13 07:41:07,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:07,962][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 1.0121738910675049, acc: 0.7083333134651184)
[2024-11-13 07:41:08,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:08,246][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 0.9090098142623901, acc: 0.7037037014961243)
[2024-11-13 07:41:08,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:08,567][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.4112732410430908, acc: 0.7142857313156128)
[2024-11-13 07:41:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:08,994][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.7898154258728027, acc: 0.5486725568771362)
[2024-11-13 07:41:09,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:09,286][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.6458051204681396, acc: 0.5362318754196167)
[2024-11-13 07:41:09,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:09,598][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 1.7639378309249878, acc: 0.5)
[2024-11-13 07:41:09,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:10,241][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.3409955501556396, acc: 0.40458014607429504)
[2024-11-13 07:41:10,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:10,740][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 2.206153631210327, acc: 0.40740740299224854)
[2024-11-13 07:41:10,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:10,992][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 1.6437757015228271, acc: 0.5737704634666443)
[2024-11-13 07:41:11,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:11,320][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.9555444121360779, acc: 0.7083333134651184)
[2024-11-13 07:41:11,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:11,649][root][INFO] - Training Epoch: 3/10, step 181/574 completed (loss: 1.4412487745285034, acc: 0.5600000023841858)
[2024-11-13 07:41:11,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:11,948][root][INFO] - Training Epoch: 3/10, step 182/574 completed (loss: 1.2190862894058228, acc: 0.6428571343421936)
[2024-11-13 07:41:12,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:12,308][root][INFO] - Training Epoch: 3/10, step 183/574 completed (loss: 2.09721040725708, acc: 0.4146341383457184)
[2024-11-13 07:41:12,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:12,708][root][INFO] - Training Epoch: 3/10, step 184/574 completed (loss: 2.233433723449707, acc: 0.39274924993515015)
[2024-11-13 07:41:12,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:13,014][root][INFO] - Training Epoch: 3/10, step 185/574 completed (loss: 2.27750563621521, acc: 0.3890489935874939)
[2024-11-13 07:41:13,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:13,424][root][INFO] - Training Epoch: 3/10, step 186/574 completed (loss: 2.3106765747070312, acc: 0.4156250059604645)
[2024-11-13 07:41:13,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:13,866][root][INFO] - Training Epoch: 3/10, step 187/574 completed (loss: 2.148455858230591, acc: 0.4127579629421234)
[2024-11-13 07:41:13,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:14,253][root][INFO] - Training Epoch: 3/10, step 188/574 completed (loss: 2.082315444946289, acc: 0.44128113985061646)
[2024-11-13 07:41:14,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:14,622][root][INFO] - Training Epoch: 3/10, step 189/574 completed (loss: 2.2408077716827393, acc: 0.5199999809265137)
[2024-11-13 07:41:14,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:15,092][root][INFO] - Training Epoch: 3/10, step 190/574 completed (loss: 2.292480707168579, acc: 0.43023255467414856)
[2024-11-13 07:41:15,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:15,663][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 1.9792027473449707, acc: 0.5634920597076416)
[2024-11-13 07:41:15,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:16,290][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 2.062502861022949, acc: 0.4469696879386902)
[2024-11-13 07:41:16,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:16,828][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 1.7873378992080688, acc: 0.5764706134796143)
[2024-11-13 07:41:17,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:17,557][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 1.7207144498825073, acc: 0.5308641791343689)
[2024-11-13 07:41:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:18,208][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 1.3882027864456177, acc: 0.5806451439857483)
[2024-11-13 07:41:18,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:18,471][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.7303041815757751, acc: 0.8214285969734192)
[2024-11-13 07:41:18,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:18,736][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 1.7059608697891235, acc: 0.550000011920929)
[2024-11-13 07:41:18,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:18,983][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 1.9930460453033447, acc: 0.45588234066963196)
[2024-11-13 07:41:19,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:19,249][root][INFO] - Training Epoch: 3/10, step 199/574 completed (loss: 1.9910067319869995, acc: 0.4632352888584137)
[2024-11-13 07:41:19,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:19,588][root][INFO] - Training Epoch: 3/10, step 200/574 completed (loss: 2.0957655906677246, acc: 0.4661017060279846)
[2024-11-13 07:41:19,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:19,897][root][INFO] - Training Epoch: 3/10, step 201/574 completed (loss: 2.206544876098633, acc: 0.4253731369972229)
[2024-11-13 07:41:19,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:20,237][root][INFO] - Training Epoch: 3/10, step 202/574 completed (loss: 2.2051491737365723, acc: 0.41747573018074036)
[2024-11-13 07:41:20,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:20,564][root][INFO] - Training Epoch: 3/10, step 203/574 completed (loss: 1.8966425657272339, acc: 0.4761904776096344)
[2024-11-13 07:41:20,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:20,852][root][INFO] - Training Epoch: 3/10, step 204/574 completed (loss: 1.9010155200958252, acc: 0.49450549483299255)
[2024-11-13 07:41:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:21,135][root][INFO] - Training Epoch: 3/10, step 205/574 completed (loss: 2.1162943840026855, acc: 0.42152467370033264)
[2024-11-13 07:41:21,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:21,522][root][INFO] - Training Epoch: 3/10, step 206/574 completed (loss: 2.113710880279541, acc: 0.4488188922405243)
[2024-11-13 07:41:21,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:21,883][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 2.040616512298584, acc: 0.45258620381355286)
[2024-11-13 07:41:21,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:22,225][root][INFO] - Training Epoch: 3/10, step 208/574 completed (loss: 2.020915985107422, acc: 0.45652174949645996)
[2024-11-13 07:41:22,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:22,592][root][INFO] - Training Epoch: 3/10, step 209/574 completed (loss: 2.216383218765259, acc: 0.3774318993091583)
[2024-11-13 07:41:22,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:22,927][root][INFO] - Training Epoch: 3/10, step 210/574 completed (loss: 2.2176690101623535, acc: 0.41304346919059753)
[2024-11-13 07:41:22,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:23,287][root][INFO] - Training Epoch: 3/10, step 211/574 completed (loss: 1.3719178438186646, acc: 0.6521739363670349)
[2024-11-13 07:41:23,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:23,646][root][INFO] - Training Epoch: 3/10, step 212/574 completed (loss: 1.6156599521636963, acc: 0.5714285969734192)
[2024-11-13 07:41:23,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:23,960][root][INFO] - Training Epoch: 3/10, step 213/574 completed (loss: 1.3494482040405273, acc: 0.5531914830207825)
[2024-11-13 07:41:24,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:24,460][root][INFO] - Training Epoch: 3/10, step 214/574 completed (loss: 1.7088937759399414, acc: 0.5076923370361328)
[2024-11-13 07:41:24,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:24,842][root][INFO] - Training Epoch: 3/10, step 215/574 completed (loss: 1.5296329259872437, acc: 0.6081081032752991)
[2024-11-13 07:41:24,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:25,171][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 1.4925540685653687, acc: 0.6279069781303406)
[2024-11-13 07:41:25,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:25,621][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 1.6907802820205688, acc: 0.5585585832595825)
[2024-11-13 07:41:25,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:25,966][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 1.6923487186431885, acc: 0.5111111402511597)
[2024-11-13 07:41:26,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:26,233][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.890241801738739, acc: 0.6969696879386902)
[2024-11-13 07:41:26,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:26,508][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.433510959148407, acc: 0.8518518805503845)
[2024-11-13 07:41:26,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:26,753][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.6445557475090027, acc: 0.7200000286102295)
[2024-11-13 07:41:26,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:27,105][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 1.9360171556472778, acc: 0.42307692766189575)
[2024-11-13 07:41:27,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:27,657][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 1.643924355506897, acc: 0.5597826242446899)
[2024-11-13 07:41:27,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:28,089][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 1.9701308012008667, acc: 0.4545454680919647)
[2024-11-13 07:41:28,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:28,450][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 2.198091745376587, acc: 0.40425533056259155)
[2024-11-13 07:41:28,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:28,774][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 1.5544278621673584, acc: 0.5660377144813538)
[2024-11-13 07:41:28,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:29,065][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 1.74240243434906, acc: 0.5166666507720947)
[2024-11-13 07:41:29,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:29,401][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 1.0732743740081787, acc: 0.7209302186965942)
[2024-11-13 07:41:29,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:29,671][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 0.964061975479126, acc: 0.7666666507720947)
[2024-11-13 07:41:29,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:29,972][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 2.291166067123413, acc: 0.35789474844932556)
[2024-11-13 07:41:30,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:30,279][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 1.7648617029190063, acc: 0.5444444417953491)
[2024-11-13 07:41:30,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:30,645][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 1.4824669361114502, acc: 0.605555534362793)
[2024-11-13 07:41:30,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:31,051][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 1.6765636205673218, acc: 0.6009174585342407)
[2024-11-13 07:41:31,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:31,431][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 1.5929938554763794, acc: 0.5846154093742371)
[2024-11-13 07:41:31,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:31,760][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 1.4707192182540894, acc: 0.6315789222717285)
[2024-11-13 07:41:31,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:32,101][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 1.1424587965011597, acc: 0.6666666865348816)
[2024-11-13 07:41:32,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:32,455][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 2.4921205043792725, acc: 0.27272728085517883)
[2024-11-13 07:41:32,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:32,740][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.812678575515747, acc: 0.37037035822868347)
[2024-11-13 07:41:32,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:33,080][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 1.4388232231140137, acc: 0.6857143044471741)
[2024-11-13 07:41:33,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:33,389][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.390899658203125, acc: 0.5681818127632141)
[2024-11-13 07:41:33,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:33,687][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.9177323579788208, acc: 0.4545454680919647)
[2024-11-13 07:41:33,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:34,127][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 2.038390874862671, acc: 0.4354838728904724)
[2024-11-13 07:41:34,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:34,529][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.5429831743240356, acc: 0.5909090638160706)
[2024-11-13 07:41:34,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:34,840][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.5443505048751831, acc: 0.8571428656578064)
[2024-11-13 07:41:34,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:35,175][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.3297032117843628, acc: 0.692307710647583)
[2024-11-13 07:41:35,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:35,526][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.2844971418380737, acc: 0.6774193644523621)
[2024-11-13 07:41:35,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:35,852][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 1.0904918909072876, acc: 0.6499999761581421)
[2024-11-13 07:41:35,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:36,180][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 1.2173194885253906, acc: 0.6756756901741028)
[2024-11-13 07:41:36,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:36,452][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 1.4923322200775146, acc: 0.5135135054588318)
[2024-11-13 07:41:36,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:36,781][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 1.2980595827102661, acc: 0.6486486196517944)
[2024-11-13 07:41:36,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:37,107][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 1.6637991666793823, acc: 0.4852941036224365)
[2024-11-13 07:41:37,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:37,465][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.785005509853363, acc: 0.707317054271698)
[2024-11-13 07:41:37,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:37,767][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.3978709876537323, acc: 0.8799999952316284)
[2024-11-13 07:41:37,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:38,087][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.49989110231399536, acc: 0.8799999952316284)
[2024-11-13 07:41:38,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:38,419][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.5480169653892517, acc: 0.8709677457809448)
[2024-11-13 07:41:38,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:38,725][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 1.4813851118087769, acc: 0.5789473652839661)
[2024-11-13 07:41:38,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:39,005][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 1.5285431146621704, acc: 0.5857142806053162)
[2024-11-13 07:41:39,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:39,300][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 1.391487956047058, acc: 0.5921052694320679)
[2024-11-13 07:41:39,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:39,753][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.6845299005508423, acc: 0.5094339847564697)
[2024-11-13 07:41:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:40,201][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 1.7450412511825562, acc: 0.5166666507720947)
[2024-11-13 07:41:40,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:40,575][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 1.1928869485855103, acc: 0.6388888955116272)
[2024-11-13 07:41:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:40,799][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 1.7554489374160767, acc: 0.5483871102333069)
[2024-11-13 07:41:40,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:41,085][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 2.713912010192871, acc: 0.3199999928474426)
[2024-11-13 07:41:41,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:41,420][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 2.213239908218384, acc: 0.4166666567325592)
[2024-11-13 07:41:41,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:41,999][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 2.435250759124756, acc: 0.37599998712539673)
[2024-11-13 07:41:42,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:42,253][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 2.1224565505981445, acc: 0.42696627974510193)
[2024-11-13 07:41:42,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:42,567][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 2.190549373626709, acc: 0.47297295928001404)
[2024-11-13 07:41:42,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:42,959][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.53058922290802, acc: 0.5862069129943848)
[2024-11-13 07:41:43,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:43,290][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 1.283589243888855, acc: 0.6363636255264282)
[2024-11-13 07:41:43,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:43,621][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 1.360572099685669, acc: 0.5909090638160706)
[2024-11-13 07:41:43,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:43,905][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.9130070209503174, acc: 0.78125)
[2024-11-13 07:41:43,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:44,227][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 1.0673840045928955, acc: 0.699999988079071)
[2024-11-13 07:41:44,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:44,565][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 1.7932180166244507, acc: 0.46666666865348816)
[2024-11-13 07:41:44,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:44,920][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 1.4101779460906982, acc: 0.59375)
[2024-11-13 07:41:45,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:45,257][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.9096677303314209, acc: 0.7333333492279053)
[2024-11-13 07:41:45,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:45,595][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 1.3593848943710327, acc: 0.6206896305084229)
[2024-11-13 07:41:45,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:45,913][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 1.31453275680542, acc: 0.6399999856948853)
[2024-11-13 07:41:45,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:46,213][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 2.189708709716797, acc: 0.42553192377090454)
[2024-11-13 07:41:46,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:46,513][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 1.884694218635559, acc: 0.5416666865348816)
[2024-11-13 07:41:46,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:46,841][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 1.6581214666366577, acc: 0.6590909361839294)
[2024-11-13 07:41:46,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:47,200][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 2.114868402481079, acc: 0.45783132314682007)
[2024-11-13 07:41:47,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:48,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:48,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:48,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:48,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:49,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:49,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:49,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:50,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:50,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:50,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:50,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:51,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:51,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:51,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:52,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:52,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:52,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:52,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:53,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:53,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:53,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:53,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:54,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:54,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:54,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:54,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:55,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:55,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:55,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:55,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:56,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:56,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:56,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:56,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:57,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:57,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:57,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:57,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:58,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:58,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:58,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:58,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:59,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:59,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:59,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:41:59,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:00,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:00,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:00,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:00,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:01,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:01,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:01,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:01,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:02,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:02,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:02,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:02,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:03,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:03,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:03,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:03,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:04,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:04,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:04,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:04,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:05,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:05,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:05,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:06,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:06,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:06,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:06,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:06,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:07,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:07,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:07,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:07,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:08,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:08,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:08,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:09,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:09,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:10,337][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.5113, device='cuda:0') eval_epoch_loss=tensor(1.8735, device='cuda:0') eval_epoch_acc=tensor(0.5151, device='cuda:0')
[2024-11-13 07:42:10,339][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:42:10,339][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:42:10,651][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_3_step_282_loss_1.8735408782958984/model.pt
[2024-11-13 07:42:10,655][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:42:10,655][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.8735408782958984
[2024-11-13 07:42:10,656][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5151148438453674
[2024-11-13 07:42:10,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:11,020][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 2.012454032897949, acc: 0.49074074625968933)
[2024-11-13 07:42:11,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:11,311][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 2.089154005050659, acc: 0.42105263471603394)
[2024-11-13 07:42:11,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:11,596][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 2.253309726715088, acc: 0.47058823704719543)
[2024-11-13 07:42:11,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:11,911][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 1.897815465927124, acc: 0.42500001192092896)
[2024-11-13 07:42:11,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:12,209][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 2.066270112991333, acc: 0.4453125)
[2024-11-13 07:42:12,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:12,566][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 2.2969741821289062, acc: 0.4000000059604645)
[2024-11-13 07:42:12,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:12,887][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 1.8319091796875, acc: 0.5054945349693298)
[2024-11-13 07:42:12,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:13,188][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 2.23738694190979, acc: 0.4409937858581543)
[2024-11-13 07:42:13,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:13,498][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 2.3626179695129395, acc: 0.3659793734550476)
[2024-11-13 07:42:13,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:13,778][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 1.0319708585739136, acc: 0.6363636255264282)
[2024-11-13 07:42:13,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:14,071][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 1.8985790014266968, acc: 0.5)
[2024-11-13 07:42:14,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:14,399][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 1.4418189525604248, acc: 0.6206896305084229)
[2024-11-13 07:42:14,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:14,765][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 1.2881684303283691, acc: 0.6727272868156433)
[2024-11-13 07:42:14,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:15,201][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.7702735662460327, acc: 0.5515463948249817)
[2024-11-13 07:42:15,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:15,472][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 1.975469946861267, acc: 0.48275861144065857)
[2024-11-13 07:42:15,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:15,752][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 1.7306747436523438, acc: 0.5555555820465088)
[2024-11-13 07:42:15,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:16,048][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 1.8170366287231445, acc: 0.44736841320991516)
[2024-11-13 07:42:16,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:16,372][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 1.5807240009307861, acc: 0.5892857313156128)
[2024-11-13 07:42:16,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:16,688][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 1.5189672708511353, acc: 0.5)
[2024-11-13 07:42:16,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:16,979][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 1.7218115329742432, acc: 0.5471698045730591)
[2024-11-13 07:42:17,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:17,269][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 1.0426527261734009, acc: 0.698113203048706)
[2024-11-13 07:42:17,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:17,551][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 1.0949758291244507, acc: 0.7058823704719543)
[2024-11-13 07:42:17,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:17,832][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 1.673307180404663, acc: 0.625)
[2024-11-13 07:42:17,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:18,132][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.3029673099517822, acc: 0.6393442749977112)
[2024-11-13 07:42:18,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:18,454][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.8003338575363159, acc: 0.800000011920929)
[2024-11-13 07:42:18,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:18,769][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.6186817288398743, acc: 0.7894737124443054)
[2024-11-13 07:42:18,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:19,063][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 1.8370527029037476, acc: 0.49275362491607666)
[2024-11-13 07:42:19,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:19,416][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 1.6545319557189941, acc: 0.5833333134651184)
[2024-11-13 07:42:19,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:19,712][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 1.4689143896102905, acc: 0.5180723071098328)
[2024-11-13 07:42:19,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:20,009][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 2.124406337738037, acc: 0.4743589758872986)
[2024-11-13 07:42:20,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:20,315][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 2.1526472568511963, acc: 0.4183673560619354)
[2024-11-13 07:42:20,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:20,584][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.2867409884929657, acc: 0.9166666865348816)
[2024-11-13 07:42:20,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:20,880][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 1.1998167037963867, acc: 0.625)
[2024-11-13 07:42:20,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:21,195][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 1.0266623497009277, acc: 0.7096773982048035)
[2024-11-13 07:42:21,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:21,505][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 0.9871129393577576, acc: 0.6774193644523621)
[2024-11-13 07:42:21,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:21,817][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 1.3559848070144653, acc: 0.6268656849861145)
[2024-11-13 07:42:21,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:22,114][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 1.3558672666549683, acc: 0.6538461446762085)
[2024-11-13 07:42:22,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:22,419][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 1.808875560760498, acc: 0.46666666865348816)
[2024-11-13 07:42:22,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:22,705][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 1.519465446472168, acc: 0.5483871102333069)
[2024-11-13 07:42:22,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:23,002][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.9832755923271179, acc: 0.7200000286102295)
[2024-11-13 07:42:23,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:23,303][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 2.0099196434020996, acc: 0.4444444477558136)
[2024-11-13 07:42:23,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:23,627][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.841170072555542, acc: 0.22857142984867096)
[2024-11-13 07:42:23,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:23,930][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 2.17850661277771, acc: 0.3333333432674408)
[2024-11-13 07:42:24,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:24,273][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.3722116947174072, acc: 0.39024388790130615)
[2024-11-13 07:42:24,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:24,585][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 1.958096981048584, acc: 0.4736842215061188)
[2024-11-13 07:42:24,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:24,903][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 1.1278001070022583, acc: 0.6842105388641357)
[2024-11-13 07:42:24,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:25,182][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.7498493194580078, acc: 0.8214285969734192)
[2024-11-13 07:42:25,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:25,473][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 1.6611512899398804, acc: 0.5185185074806213)
[2024-11-13 07:42:25,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:25,774][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.8246538639068604, acc: 0.78125)
[2024-11-13 07:42:25,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:26,083][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 1.721060872077942, acc: 0.5322580933570862)
[2024-11-13 07:42:26,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:26,406][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 1.600740671157837, acc: 0.5263158082962036)
[2024-11-13 07:42:26,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:26,693][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 2.1052162647247314, acc: 0.34375)
[2024-11-13 07:42:26,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:27,002][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 1.1073486804962158, acc: 0.7333333492279053)
[2024-11-13 07:42:27,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:27,278][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 1.8127212524414062, acc: 0.3684210479259491)
[2024-11-13 07:42:27,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:27,620][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 2.206202268600464, acc: 0.3799999952316284)
[2024-11-13 07:42:27,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:27,930][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 2.178819179534912, acc: 0.4252873659133911)
[2024-11-13 07:42:28,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:28,255][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 2.26716947555542, acc: 0.39361703395843506)
[2024-11-13 07:42:28,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:28,541][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 2.371731758117676, acc: 0.3855421543121338)
[2024-11-13 07:42:28,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:28,845][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.9662028551101685, acc: 0.739130437374115)
[2024-11-13 07:42:28,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:29,154][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 1.962001919746399, acc: 0.4871794879436493)
[2024-11-13 07:42:29,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:29,451][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 2.3745949268341064, acc: 0.3614457845687866)
[2024-11-13 07:42:29,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:29,740][root][INFO] - Training Epoch: 3/10, step 343/574 completed (loss: 1.7054086923599243, acc: 0.5660377144813538)
[2024-11-13 07:42:29,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:30,056][root][INFO] - Training Epoch: 3/10, step 344/574 completed (loss: 1.8575187921524048, acc: 0.5063291192054749)
[2024-11-13 07:42:30,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:30,365][root][INFO] - Training Epoch: 3/10, step 345/574 completed (loss: 1.7661001682281494, acc: 0.5098039507865906)
[2024-11-13 07:42:30,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:30,673][root][INFO] - Training Epoch: 3/10, step 346/574 completed (loss: 2.237786054611206, acc: 0.38805970549583435)
[2024-11-13 07:42:30,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:30,970][root][INFO] - Training Epoch: 3/10, step 347/574 completed (loss: 0.8685336112976074, acc: 0.75)
[2024-11-13 07:42:31,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:31,331][root][INFO] - Training Epoch: 3/10, step 348/574 completed (loss: 1.3171032667160034, acc: 0.6000000238418579)
[2024-11-13 07:42:31,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:31,672][root][INFO] - Training Epoch: 3/10, step 349/574 completed (loss: 1.333140254020691, acc: 0.6666666865348816)
[2024-11-13 07:42:31,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:31,973][root][INFO] - Training Epoch: 3/10, step 350/574 completed (loss: 1.728933334350586, acc: 0.5581395626068115)
[2024-11-13 07:42:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:32,269][root][INFO] - Training Epoch: 3/10, step 351/574 completed (loss: 1.6307790279388428, acc: 0.5384615659713745)
[2024-11-13 07:42:32,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:32,578][root][INFO] - Training Epoch: 3/10, step 352/574 completed (loss: 1.7315348386764526, acc: 0.5333333611488342)
[2024-11-13 07:42:32,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:32,884][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.8133248090744019, acc: 0.739130437374115)
[2024-11-13 07:42:32,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:33,195][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 1.8339507579803467, acc: 0.5384615659713745)
[2024-11-13 07:42:33,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:33,519][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 2.360275983810425, acc: 0.4175824224948883)
[2024-11-13 07:42:33,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:33,920][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.8857084512710571, acc: 0.539130449295044)
[2024-11-13 07:42:33,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:34,211][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 1.8829833269119263, acc: 0.532608687877655)
[2024-11-13 07:42:34,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:34,503][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 2.0133397579193115, acc: 0.40816327929496765)
[2024-11-13 07:42:34,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:34,810][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.397708922624588, acc: 0.9166666865348816)
[2024-11-13 07:42:34,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:35,116][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.8985968828201294, acc: 0.7692307829856873)
[2024-11-13 07:42:35,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:35,413][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.3779367208480835, acc: 0.6829268336296082)
[2024-11-13 07:42:35,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:35,724][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 1.6929633617401123, acc: 0.5555555820465088)
[2024-11-13 07:42:35,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:36,039][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 1.797684669494629, acc: 0.5131579041481018)
[2024-11-13 07:42:36,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:36,364][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 1.7325260639190674, acc: 0.5365853905677795)
[2024-11-13 07:42:36,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:36,661][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 1.7836042642593384, acc: 0.4545454680919647)
[2024-11-13 07:42:36,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:36,953][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.6592966914176941, acc: 0.7916666865348816)
[2024-11-13 07:42:37,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:37,243][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.4529004693031311, acc: 0.8695651888847351)
[2024-11-13 07:42:37,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:37,536][root][INFO] - Training Epoch: 3/10, step 368/574 completed (loss: 0.6793401837348938, acc: 0.8214285969734192)
[2024-11-13 07:42:37,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:37,843][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 1.0980137586593628, acc: 0.65625)
[2024-11-13 07:42:37,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:38,306][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 1.7574111223220825, acc: 0.5333333611488342)
[2024-11-13 07:42:38,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:38,886][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 1.4289265871047974, acc: 0.6226415038108826)
[2024-11-13 07:42:38,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:39,168][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 1.5696855783462524, acc: 0.5777778029441833)
[2024-11-13 07:42:39,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:39,440][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 1.579072117805481, acc: 0.6071428656578064)
[2024-11-13 07:42:39,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:39,733][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.9734079837799072, acc: 0.7142857313156128)
[2024-11-13 07:42:39,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:40,011][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.4537017047405243, acc: 0.8399999737739563)
[2024-11-13 07:42:40,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:40,297][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.6217858195304871, acc: 0.739130437374115)
[2024-11-13 07:42:40,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:40,599][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 1.8624296188354492, acc: 0.5)
[2024-11-13 07:42:40,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:40,907][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 1.6904730796813965, acc: 0.5263158082962036)
[2024-11-13 07:42:41,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:41,351][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 1.7382410764694214, acc: 0.5868263244628906)
[2024-11-13 07:42:41,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:41,670][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 1.571304202079773, acc: 0.548872172832489)
[2024-11-13 07:42:41,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:42,412][root][INFO] - Training Epoch: 3/10, step 381/574 completed (loss: 1.6227959394454956, acc: 0.5614973306655884)
[2024-11-13 07:42:42,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:42,850][root][INFO] - Training Epoch: 3/10, step 382/574 completed (loss: 1.4143409729003906, acc: 0.6126126050949097)
[2024-11-13 07:42:42,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:43,135][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 0.7216739058494568, acc: 0.8214285969734192)
[2024-11-13 07:42:43,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:43,445][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.6615079641342163, acc: 0.8214285969734192)
[2024-11-13 07:42:43,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:43,748][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 1.1292109489440918, acc: 0.75)
[2024-11-13 07:42:43,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:44,041][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 0.944380521774292, acc: 0.6944444179534912)
[2024-11-13 07:42:44,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:44,335][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 1.0440295934677124, acc: 0.7894737124443054)
[2024-11-13 07:42:44,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:44,619][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.6189504265785217, acc: 0.8181818127632141)
[2024-11-13 07:42:44,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:44,893][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 1.1065007448196411, acc: 0.6000000238418579)
[2024-11-13 07:42:44,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:45,193][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 1.161766529083252, acc: 0.6666666865348816)
[2024-11-13 07:42:45,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:45,471][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 2.4325077533721924, acc: 0.40740740299224854)
[2024-11-13 07:42:45,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:45,770][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 2.2553956508636475, acc: 0.42718446254730225)
[2024-11-13 07:42:45,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:46,183][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 1.883190393447876, acc: 0.5514705777168274)
[2024-11-13 07:42:46,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:46,510][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 2.1509666442871094, acc: 0.4933333396911621)
[2024-11-13 07:42:46,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:46,847][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 2.1424167156219482, acc: 0.4652777910232544)
[2024-11-13 07:42:46,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:47,178][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 1.881852626800537, acc: 0.5348837375640869)
[2024-11-13 07:42:47,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:47,486][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 1.0610464811325073, acc: 0.75)
[2024-11-13 07:42:47,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:47,782][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 1.399990439414978, acc: 0.6744186282157898)
[2024-11-13 07:42:47,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:48,086][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 1.5385801792144775, acc: 0.5600000023841858)
[2024-11-13 07:42:48,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:48,520][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 1.8102141618728638, acc: 0.5588235259056091)
[2024-11-13 07:42:48,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:48,853][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 1.6849133968353271, acc: 0.5066666603088379)
[2024-11-13 07:42:48,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:49,140][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 1.1828670501708984, acc: 0.6363636255264282)
[2024-11-13 07:42:49,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:49,441][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 1.3266927003860474, acc: 0.6666666865348816)
[2024-11-13 07:42:49,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:49,743][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.7352120876312256, acc: 0.8064516186714172)
[2024-11-13 07:42:49,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:50,068][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 1.100889801979065, acc: 0.6296296119689941)
[2024-11-13 07:42:50,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:50,382][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.6229550838470459, acc: 0.8799999952316284)
[2024-11-13 07:42:50,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:50,695][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.7686512470245361, acc: 0.75)
[2024-11-13 07:42:50,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:50,990][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.9107552170753479, acc: 0.7777777910232544)
[2024-11-13 07:42:51,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:51,309][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.8086045384407043, acc: 0.807692289352417)
[2024-11-13 07:42:51,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:51,606][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 1.1814926862716675, acc: 0.6551724076271057)
[2024-11-13 07:42:51,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:51,891][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.6656219363212585, acc: 0.8571428656578064)
[2024-11-13 07:42:51,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:52,160][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.9694961905479431, acc: 0.7333333492279053)
[2024-11-13 07:42:52,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:52,459][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 1.0174142122268677, acc: 0.7272727489471436)
[2024-11-13 07:42:52,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:52,730][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.7202244400978088, acc: 0.7272727489471436)
[2024-11-13 07:42:52,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:53,028][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 1.801037311553955, acc: 0.529411792755127)
[2024-11-13 07:42:53,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:53,322][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 1.5847784280776978, acc: 0.6153846383094788)
[2024-11-13 07:42:53,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:53,636][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 1.5522358417510986, acc: 0.5555555820465088)
[2024-11-13 07:42:53,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:53,946][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 1.4583979845046997, acc: 0.625)
[2024-11-13 07:42:53,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:54,215][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 1.3254801034927368, acc: 0.6499999761581421)
[2024-11-13 07:42:54,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:54,490][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.5532353520393372, acc: 0.8095238208770752)
[2024-11-13 07:42:54,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:54,781][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 1.0160820484161377, acc: 0.7333333492279053)
[2024-11-13 07:42:54,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:55,080][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 1.4392281770706177, acc: 0.65625)
[2024-11-13 07:42:55,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:55,394][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.989003300666809, acc: 0.5833333134651184)
[2024-11-13 07:42:55,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:55,692][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 1.1446783542633057, acc: 0.7037037014961243)
[2024-11-13 07:42:56,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:56,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:56,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:57,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:57,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:57,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:57,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:58,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:58,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:58,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:58,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:59,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:59,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:59,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:42:59,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:00,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:00,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:00,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:01,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:01,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:01,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:02,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:02,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:02,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:02,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:03,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:03,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:03,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:04,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:04,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:04,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:04,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:05,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:05,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:05,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:05,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:06,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:06,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:06,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:07,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:07,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:07,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:07,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:08,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:08,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:08,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:09,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:09,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:09,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:09,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:10,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:10,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:10,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:11,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:11,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:11,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:11,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:12,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:12,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:13,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:13,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:13,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:13,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:14,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:14,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:14,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:14,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:15,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:15,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:15,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:15,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:16,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:16,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:16,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:16,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:17,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:17,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:17,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:18,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:18,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:18,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:19,182][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.4625, device='cuda:0') eval_epoch_loss=tensor(2.1356, device='cuda:0') eval_epoch_acc=tensor(0.4829, device='cuda:0')
[2024-11-13 07:43:19,183][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:43:19,184][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:43:19,447][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_3_step_425_loss_2.1356418132781982/model.pt
[2024-11-13 07:43:19,451][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:43:19,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:19,858][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 1.9227122068405151, acc: 0.6666666865348816)
[2024-11-13 07:43:19,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:20,214][root][INFO] - Training Epoch: 3/10, step 426/574 completed (loss: 1.7974742650985718, acc: 0.6521739363670349)
[2024-11-13 07:43:20,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:20,540][root][INFO] - Training Epoch: 3/10, step 427/574 completed (loss: 1.3814949989318848, acc: 0.6216216087341309)
[2024-11-13 07:43:20,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:20,871][root][INFO] - Training Epoch: 3/10, step 428/574 completed (loss: 0.8805263042449951, acc: 0.7777777910232544)
[2024-11-13 07:43:20,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:21,214][root][INFO] - Training Epoch: 3/10, step 429/574 completed (loss: 1.9051814079284668, acc: 0.43478259444236755)
[2024-11-13 07:43:21,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:21,547][root][INFO] - Training Epoch: 3/10, step 430/574 completed (loss: 1.0815900564193726, acc: 0.6296296119689941)
[2024-11-13 07:43:21,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:21,847][root][INFO] - Training Epoch: 3/10, step 431/574 completed (loss: 1.0533121824264526, acc: 0.7037037014961243)
[2024-11-13 07:43:21,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:22,160][root][INFO] - Training Epoch: 3/10, step 432/574 completed (loss: 1.2921700477600098, acc: 0.5652173757553101)
[2024-11-13 07:43:22,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:22,485][root][INFO] - Training Epoch: 3/10, step 433/574 completed (loss: 1.2352997064590454, acc: 0.7222222089767456)
[2024-11-13 07:43:22,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:22,829][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.6676118969917297, acc: 0.8799999952316284)
[2024-11-13 07:43:22,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:23,146][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 1.149238109588623, acc: 0.6969696879386902)
[2024-11-13 07:43:23,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:23,454][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 1.4199693202972412, acc: 0.5277777910232544)
[2024-11-13 07:43:23,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:23,735][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 1.4769760370254517, acc: 0.5909090638160706)
[2024-11-13 07:43:23,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:24,063][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.7141488194465637, acc: 0.761904776096344)
[2024-11-13 07:43:24,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:24,363][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 1.8502893447875977, acc: 0.5384615659713745)
[2024-11-13 07:43:24,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:24,810][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 2.1111958026885986, acc: 0.5)
[2024-11-13 07:43:24,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:25,328][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 2.416724443435669, acc: 0.335999995470047)
[2024-11-13 07:43:25,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:25,668][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 2.2883453369140625, acc: 0.39516130089759827)
[2024-11-13 07:43:25,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:26,163][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 2.1910507678985596, acc: 0.4378109574317932)
[2024-11-13 07:43:26,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:26,444][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 1.9586842060089111, acc: 0.5094339847564697)
[2024-11-13 07:43:26,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:26,798][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 1.0056477785110474, acc: 0.6590909361839294)
[2024-11-13 07:43:26,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:27,061][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 1.4209849834442139, acc: 0.6086956262588501)
[2024-11-13 07:43:27,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:27,390][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 1.4739134311676025, acc: 0.5769230723381042)
[2024-11-13 07:43:27,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:27,753][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.9675685167312622, acc: 0.7142857313156128)
[2024-11-13 07:43:27,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:28,055][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 1.8848329782485962, acc: 0.5223880410194397)
[2024-11-13 07:43:28,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:28,415][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 1.6090526580810547, acc: 0.5833333134651184)
[2024-11-13 07:43:28,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:28,737][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 1.6492677927017212, acc: 0.532608687877655)
[2024-11-13 07:43:28,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:29,080][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 1.8317902088165283, acc: 0.4743589758872986)
[2024-11-13 07:43:29,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:29,404][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 2.0025858879089355, acc: 0.4736842215061188)
[2024-11-13 07:43:29,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:29,780][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 1.8490647077560425, acc: 0.5714285969734192)
[2024-11-13 07:43:29,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:30,074][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 1.2052969932556152, acc: 0.6363636255264282)
[2024-11-13 07:43:30,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:30,440][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 1.9928462505340576, acc: 0.4536082446575165)
[2024-11-13 07:43:30,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:30,756][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 1.6346209049224854, acc: 0.5571428537368774)
[2024-11-13 07:43:30,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:31,136][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.9212852716445923, acc: 0.4651162922382355)
[2024-11-13 07:43:31,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:31,459][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 2.1401073932647705, acc: 0.4285714328289032)
[2024-11-13 07:43:31,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:31,714][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 1.9400173425674438, acc: 0.48148149251937866)
[2024-11-13 07:43:31,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:32,034][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 1.7623496055603027, acc: 0.5277777910232544)
[2024-11-13 07:43:32,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:32,315][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 1.241139531135559, acc: 0.75)
[2024-11-13 07:43:32,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:32,669][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 1.4130995273590088, acc: 0.5769230723381042)
[2024-11-13 07:43:32,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:33,029][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 1.596413016319275, acc: 0.5869565010070801)
[2024-11-13 07:43:33,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:33,368][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 1.8964358568191528, acc: 0.3928571343421936)
[2024-11-13 07:43:33,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:33,716][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 1.9009422063827515, acc: 0.46987950801849365)
[2024-11-13 07:43:33,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:34,067][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 1.5900384187698364, acc: 0.5405405163764954)
[2024-11-13 07:43:34,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:34,398][root][INFO] - Training Epoch: 3/10, step 468/574 completed (loss: 1.7536436319351196, acc: 0.5339806079864502)
[2024-11-13 07:43:34,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:34,746][root][INFO] - Training Epoch: 3/10, step 469/574 completed (loss: 1.561242699623108, acc: 0.5853658318519592)
[2024-11-13 07:43:34,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:35,075][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 1.3400602340698242, acc: 0.625)
[2024-11-13 07:43:35,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:35,418][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 1.8346954584121704, acc: 0.4285714328289032)
[2024-11-13 07:43:35,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:35,783][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 2.084890365600586, acc: 0.3921568691730499)
[2024-11-13 07:43:35,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:36,148][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 2.2267370223999023, acc: 0.4192139804363251)
[2024-11-13 07:43:36,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:36,519][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 2.1065256595611572, acc: 0.4583333432674408)
[2024-11-13 07:43:36,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:36,806][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 2.124267816543579, acc: 0.38650307059288025)
[2024-11-13 07:43:36,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:37,037][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 2.1966259479522705, acc: 0.41726619005203247)
[2024-11-13 07:43:37,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:37,391][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 2.2548513412475586, acc: 0.39698493480682373)
[2024-11-13 07:43:37,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:37,703][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 1.2962578535079956, acc: 0.6388888955116272)
[2024-11-13 07:43:37,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:37,986][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 1.3879281282424927, acc: 0.6060606241226196)
[2024-11-13 07:43:38,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:38,276][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 1.0211716890335083, acc: 0.6296296119689941)
[2024-11-13 07:43:38,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:38,601][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 1.307004690170288, acc: 0.6000000238418579)
[2024-11-13 07:43:38,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:38,921][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 0.7794915437698364, acc: 0.75)
[2024-11-13 07:43:39,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:39,278][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 1.4646514654159546, acc: 0.568965494632721)
[2024-11-13 07:43:39,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:39,637][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 1.242557406425476, acc: 0.7419354915618896)
[2024-11-13 07:43:39,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:39,976][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.5912841558456421, acc: 0.8421052694320679)
[2024-11-13 07:43:40,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:40,301][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 1.7790801525115967, acc: 0.5185185074806213)
[2024-11-13 07:43:40,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:40,612][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 1.9756433963775635, acc: 0.380952388048172)
[2024-11-13 07:43:40,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:40,958][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 1.4737051725387573, acc: 0.5454545617103577)
[2024-11-13 07:43:41,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:41,321][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.7940922975540161, acc: 0.5230769515037537)
[2024-11-13 07:43:41,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:41,657][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 1.4335672855377197, acc: 0.5666666626930237)
[2024-11-13 07:43:41,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:42,026][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 1.389758825302124, acc: 0.5517241358757019)
[2024-11-13 07:43:42,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:42,350][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 1.8000378608703613, acc: 0.47058823704719543)
[2024-11-13 07:43:42,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:42,691][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 1.500343680381775, acc: 0.517241358757019)
[2024-11-13 07:43:42,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:43,027][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.6396928429603577, acc: 0.8421052694320679)
[2024-11-13 07:43:43,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:43,398][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 2.036733627319336, acc: 0.42105263471603394)
[2024-11-13 07:43:43,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:43,744][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.7043497562408447, acc: 0.5)
[2024-11-13 07:43:43,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:44,072][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 1.8559468984603882, acc: 0.5056179761886597)
[2024-11-13 07:43:44,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:44,424][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 2.1771907806396484, acc: 0.4157303273677826)
[2024-11-13 07:43:44,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:44,777][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.300132989883423, acc: 0.3758865296840668)
[2024-11-13 07:43:44,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:45,135][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 2.3486037254333496, acc: 0.33695653080940247)
[2024-11-13 07:43:45,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:45,499][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.803885281085968, acc: 0.8799999952316284)
[2024-11-13 07:43:45,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:45,830][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.7734328508377075, acc: 0.7692307829856873)
[2024-11-13 07:43:45,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:46,146][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.7389061450958252, acc: 0.7777777910232544)
[2024-11-13 07:43:46,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:46,430][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 1.6174598932266235, acc: 0.5185185074806213)
[2024-11-13 07:43:46,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:46,801][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 1.406945824623108, acc: 0.6037735939025879)
[2024-11-13 07:43:46,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:47,140][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 1.1092400550842285, acc: 0.6551724076271057)
[2024-11-13 07:43:47,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:47,593][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.7740581035614014, acc: 0.5135135054588318)
[2024-11-13 07:43:47,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:47,971][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.5690888166427612, acc: 0.577464759349823)
[2024-11-13 07:43:48,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:48,312][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.48794618248939514, acc: 0.800000011920929)
[2024-11-13 07:43:48,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:48,656][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.650078535079956, acc: 0.8333333134651184)
[2024-11-13 07:43:48,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:48,957][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 1.0546046495437622, acc: 0.692307710647583)
[2024-11-13 07:43:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:50,155][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 1.9662470817565918, acc: 0.47857141494750977)
[2024-11-13 07:43:50,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:50,710][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 1.838200330734253, acc: 0.523809552192688)
[2024-11-13 07:43:50,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:51,006][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 1.211382508277893, acc: 0.6428571343421936)
[2024-11-13 07:43:51,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:51,325][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 1.4472302198410034, acc: 0.6000000238418579)
[2024-11-13 07:43:51,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:51,852][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 1.480485439300537, acc: 0.6111111044883728)
[2024-11-13 07:43:51,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:52,127][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.5623801946640015, acc: 0.7307692170143127)
[2024-11-13 07:43:52,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:52,413][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 1.281550407409668, acc: 0.6451612710952759)
[2024-11-13 07:43:52,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:52,722][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 1.4743067026138306, acc: 0.6000000238418579)
[2024-11-13 07:43:52,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:52,987][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 1.5195579528808594, acc: 0.5925925970077515)
[2024-11-13 07:43:53,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:53,675][root][INFO] - Training Epoch: 3/10, step 521/574 completed (loss: 2.076129198074341, acc: 0.43644067645072937)
[2024-11-13 07:43:53,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:54,022][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 2.049309492111206, acc: 0.4701492488384247)
[2024-11-13 07:43:54,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:54,343][root][INFO] - Training Epoch: 3/10, step 523/574 completed (loss: 2.067474126815796, acc: 0.43065693974494934)
[2024-11-13 07:43:54,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:54,781][root][INFO] - Training Epoch: 3/10, step 524/574 completed (loss: 1.9078364372253418, acc: 0.4950000047683716)
[2024-11-13 07:43:54,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:55,072][root][INFO] - Training Epoch: 3/10, step 525/574 completed (loss: 1.8143178224563599, acc: 0.5)
[2024-11-13 07:43:55,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:55,403][root][INFO] - Training Epoch: 3/10, step 526/574 completed (loss: 1.648978352546692, acc: 0.5384615659713745)
[2024-11-13 07:43:55,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:55,759][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 2.183037519454956, acc: 0.2380952388048172)
[2024-11-13 07:43:55,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:56,115][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 2.641467571258545, acc: 0.2786885201931)
[2024-11-13 07:43:56,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:56,481][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 1.7022390365600586, acc: 0.5762711763381958)
[2024-11-13 07:43:56,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:56,801][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 2.249943494796753, acc: 0.4883720874786377)
[2024-11-13 07:43:56,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:57,104][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 2.036480188369751, acc: 0.5)
[2024-11-13 07:43:57,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:57,384][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 2.350179672241211, acc: 0.4150943458080292)
[2024-11-13 07:43:57,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:57,734][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 1.5889655351638794, acc: 0.5909090638160706)
[2024-11-13 07:43:57,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:58,074][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 1.4827176332473755, acc: 0.6000000238418579)
[2024-11-13 07:43:58,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:58,425][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 1.2117242813110352, acc: 0.699999988079071)
[2024-11-13 07:43:58,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:58,773][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 1.0476324558258057, acc: 0.7272727489471436)
[2024-11-13 07:43:58,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:59,129][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.6509228944778442, acc: 0.6000000238418579)
[2024-11-13 07:43:59,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:59,485][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 1.6262485980987549, acc: 0.625)
[2024-11-13 07:43:59,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:43:59,833][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 1.0759388208389282, acc: 0.71875)
[2024-11-13 07:43:59,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:00,148][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.5065721273422241, acc: 0.6060606241226196)
[2024-11-13 07:44:00,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:00,480][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.7977764010429382, acc: 0.8125)
[2024-11-13 07:44:00,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:00,811][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.7491593360900879, acc: 0.774193525314331)
[2024-11-13 07:44:00,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:01,140][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.5387805104255676, acc: 0.8260869383811951)
[2024-11-13 07:44:01,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:01,440][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 1.5599333047866821, acc: 0.5333333611488342)
[2024-11-13 07:44:01,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:01,738][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 1.5498292446136475, acc: 0.46341463923454285)
[2024-11-13 07:44:01,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:02,001][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 1.059255838394165, acc: 0.7428571581840515)
[2024-11-13 07:44:02,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:02,283][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 1.0794001817703247, acc: 0.7105262875556946)
[2024-11-13 07:44:02,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:02,554][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 0.9652823805809021, acc: 0.7419354915618896)
[2024-11-13 07:44:02,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:02,875][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.5762040615081787, acc: 0.8399999737739563)
[2024-11-13 07:44:02,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:03,204][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 1.0179427862167358, acc: 0.6969696879386902)
[2024-11-13 07:44:03,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:03,568][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.9845309257507324, acc: 0.699999988079071)
[2024-11-13 07:44:03,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:03,902][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 1.257054090499878, acc: 0.6571428775787354)
[2024-11-13 07:44:03,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:04,202][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 2.113813877105713, acc: 0.41605839133262634)
[2024-11-13 07:44:04,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:04,508][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 1.6615216732025146, acc: 0.5448275804519653)
[2024-11-13 07:44:04,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:04,846][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 2.328610420227051, acc: 0.37857142090797424)
[2024-11-13 07:44:04,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:05,195][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 2.1145899295806885, acc: 0.38410595059394836)
[2024-11-13 07:44:05,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:05,507][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 1.6847262382507324, acc: 0.5811966061592102)
[2024-11-13 07:44:05,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:05,840][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.6258949041366577, acc: 0.8399999737739563)
[2024-11-13 07:44:05,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:06,210][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.9949705600738525, acc: 0.6538461446762085)
[2024-11-13 07:44:06,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:06,547][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.5742102861404419, acc: 0.8461538553237915)
[2024-11-13 07:44:06,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:06,853][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 1.5196326971054077, acc: 0.5641025900840759)
[2024-11-13 07:44:06,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:07,140][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 1.5603481531143188, acc: 0.5888888835906982)
[2024-11-13 07:44:07,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:07,462][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 1.4913320541381836, acc: 0.6233766078948975)
[2024-11-13 07:44:07,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:07,774][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 1.390406608581543, acc: 0.5833333134651184)
[2024-11-13 07:44:07,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:08,101][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 1.274834394454956, acc: 0.6724137663841248)
[2024-11-13 07:44:08,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:08,477][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 1.536346197128296, acc: 0.523809552192688)
[2024-11-13 07:44:08,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:08,786][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 1.387259840965271, acc: 0.5526315569877625)
[2024-11-13 07:44:09,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:09,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:09,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:10,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:10,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:10,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:10,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:11,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:11,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:11,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:11,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:12,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:12,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:12,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:13,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:13,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:13,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:13,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:13,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:14,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:14,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:14,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:14,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:15,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:15,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:16,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:16,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:16,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:16,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:17,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:17,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:17,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:17,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:18,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:18,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:18,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:18,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:19,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:19,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:19,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:20,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:20,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:20,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:21,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:21,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:21,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:21,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:22,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:22,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:22,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:23,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:23,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:23,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:24,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:24,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:24,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:24,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:25,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:25,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:25,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:25,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:26,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:26,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:26,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:27,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:27,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:27,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:27,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:28,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:28,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:28,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:28,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:29,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:29,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:29,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:29,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:30,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:30,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:30,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:30,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:31,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:31,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:31,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:32,270][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.5244, device='cuda:0') eval_epoch_loss=tensor(1.8755, device='cuda:0') eval_epoch_acc=tensor(0.5254, device='cuda:0')
[2024-11-13 07:44:32,271][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:44:32,272][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:44:32,539][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_3_step_568_loss_1.875544548034668/model.pt
[2024-11-13 07:44:32,546][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:44:32,547][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5254340171813965
[2024-11-13 07:44:32,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:32,864][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 1.0775647163391113, acc: 0.7037037014961243)
[2024-11-13 07:44:32,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:33,258][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 1.8294446468353271, acc: 0.49197861552238464)
[2024-11-13 07:44:33,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:33,581][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 1.232080340385437, acc: 0.6612903475761414)
[2024-11-13 07:44:33,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:33,907][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 1.592008113861084, acc: 0.5384615659713745)
[2024-11-13 07:44:33,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:34,218][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 2.1332848072052, acc: 0.41326531767845154)
[2024-11-13 07:44:34,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:34,534][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 2.055361747741699, acc: 0.42138364911079407)
[2024-11-13 07:44:34,957][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=4.9642, train_epoch_loss=1.6023, epoch time 293.3632634729147s
[2024-11-13 07:44:34,957][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 07:44:34,957][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 07:44:34,957][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 07:44:34,957][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 07:44:34,957][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 07:44:35,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:35,699][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 1.3270494937896729, acc: 0.5185185074806213)
[2024-11-13 07:44:35,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:35,972][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 1.6046541929244995, acc: 0.5199999809265137)
[2024-11-13 07:44:36,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:36,280][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 2.31278920173645, acc: 0.3513513505458832)
[2024-11-13 07:44:36,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:36,656][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 2.0308244228363037, acc: 0.31578946113586426)
[2024-11-13 07:44:36,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:37,004][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 1.9242985248565674, acc: 0.4864864945411682)
[2024-11-13 07:44:37,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:37,295][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 1.801073431968689, acc: 0.3571428656578064)
[2024-11-13 07:44:37,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:37,548][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 2.0100438594818115, acc: 0.4897959232330322)
[2024-11-13 07:44:37,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:37,836][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 1.441244125366211, acc: 0.5666666626930237)
[2024-11-13 07:44:37,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:38,163][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.38778820633888245, acc: 0.9090909361839294)
[2024-11-13 07:44:38,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:38,449][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.6251424551010132, acc: 0.8846153616905212)
[2024-11-13 07:44:38,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:38,762][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 1.0928258895874023, acc: 0.7407407164573669)
[2024-11-13 07:44:38,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:39,114][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 1.4808623790740967, acc: 0.6410256624221802)
[2024-11-13 07:44:39,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:39,430][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 1.2205617427825928, acc: 0.6363636255264282)
[2024-11-13 07:44:39,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:39,752][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 1.4624316692352295, acc: 0.5869565010070801)
[2024-11-13 07:44:39,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:40,043][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 1.910223126411438, acc: 0.5098039507865906)
[2024-11-13 07:44:40,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:40,349][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 1.5940622091293335, acc: 0.44897958636283875)
[2024-11-13 07:44:40,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:40,675][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.6789576411247253, acc: 0.8947368264198303)
[2024-11-13 07:44:40,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:40,988][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 1.1524574756622314, acc: 0.5833333134651184)
[2024-11-13 07:44:41,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:41,317][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.4860243797302246, acc: 0.6388888955116272)
[2024-11-13 07:44:41,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:41,613][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 1.4646787643432617, acc: 0.5789473652839661)
[2024-11-13 07:44:41,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:41,949][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 1.2932401895523071, acc: 0.6153846383094788)
[2024-11-13 07:44:42,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:42,278][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 1.2662646770477295, acc: 0.6551724076271057)
[2024-11-13 07:44:42,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:42,588][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 1.1919658184051514, acc: 0.6000000238418579)
[2024-11-13 07:44:42,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:42,890][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.7184790372848511, acc: 0.7142857313156128)
[2024-11-13 07:44:42,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:43,199][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 1.3958433866500854, acc: 0.625)
[2024-11-13 07:44:43,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:43,547][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 2.31701922416687, acc: 0.4150943458080292)
[2024-11-13 07:44:43,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:43,883][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 2.1148812770843506, acc: 0.4383561611175537)
[2024-11-13 07:44:44,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:44,608][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 2.1259851455688477, acc: 0.4229249060153961)
[2024-11-13 07:44:44,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:44,817][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 1.8382655382156372, acc: 0.4651162922382355)
[2024-11-13 07:44:44,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:45,170][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 2.051079034805298, acc: 0.4819277226924896)
[2024-11-13 07:44:45,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:45,535][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 1.877528190612793, acc: 0.45679011940956116)
[2024-11-13 07:44:45,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:45,871][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 1.7168811559677124, acc: 0.5)
[2024-11-13 07:44:45,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:46,234][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 1.3601778745651245, acc: 0.6666666865348816)
[2024-11-13 07:44:46,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:46,569][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.9015936851501465, acc: 0.6521739363670349)
[2024-11-13 07:44:46,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:46,859][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 2.005096673965454, acc: 0.462184876203537)
[2024-11-13 07:44:46,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:47,208][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 1.4639822244644165, acc: 0.6065573692321777)
[2024-11-13 07:44:47,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:47,575][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 1.9515116214752197, acc: 0.460317462682724)
[2024-11-13 07:44:47,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:47,855][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 1.9303433895111084, acc: 0.4576271176338196)
[2024-11-13 07:44:47,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:48,199][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 1.4313830137252808, acc: 0.5517241358757019)
[2024-11-13 07:44:48,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:48,501][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.7810488343238831, acc: 0.7142857313156128)
[2024-11-13 07:44:48,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:48,790][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 1.3796197175979614, acc: 0.6153846383094788)
[2024-11-13 07:44:48,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:49,151][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 2.274167537689209, acc: 0.3918918967247009)
[2024-11-13 07:44:49,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:49,467][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 1.860076665878296, acc: 0.4923076927661896)
[2024-11-13 07:44:49,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:49,858][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 2.078350067138672, acc: 0.46464645862579346)
[2024-11-13 07:44:49,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:50,229][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 1.6547054052352905, acc: 0.5360824465751648)
[2024-11-13 07:44:50,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:50,573][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 2.0593810081481934, acc: 0.49264705181121826)
[2024-11-13 07:44:50,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:50,881][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.8379172682762146, acc: 0.7307692170143127)
[2024-11-13 07:44:50,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:51,219][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.6341996788978577, acc: 0.8148148059844971)
[2024-11-13 07:44:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:51,484][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 1.0338088274002075, acc: 0.6785714030265808)
[2024-11-13 07:44:51,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:51,822][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.783280611038208, acc: 0.7777777910232544)
[2024-11-13 07:44:51,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:52,172][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 1.3019800186157227, acc: 0.6140350699424744)
[2024-11-13 07:44:52,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:52,537][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.1969009637832642, acc: 0.6666666865348816)
[2024-11-13 07:44:52,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:52,858][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.964391827583313, acc: 0.4507042169570923)
[2024-11-13 07:44:52,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:53,228][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.1827948093414307, acc: 0.4933333396911621)
[2024-11-13 07:44:53,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:53,486][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 1.106648564338684, acc: 0.6486486196517944)
[2024-11-13 07:44:53,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:53,784][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.6551307439804077, acc: 0.7307692170143127)
[2024-11-13 07:44:54,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:55,085][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.830939531326294, acc: 0.5187713503837585)
[2024-11-13 07:44:55,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:55,898][root][INFO] - Training Epoch: 4/10, step 57/574 completed (loss: 2.3674306869506836, acc: 0.42265796661376953)
[2024-11-13 07:44:56,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:56,382][root][INFO] - Training Epoch: 4/10, step 58/574 completed (loss: 1.9206959009170532, acc: 0.5113636255264282)
[2024-11-13 07:44:56,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:56,842][root][INFO] - Training Epoch: 4/10, step 59/574 completed (loss: 2.0154857635498047, acc: 0.5367646813392639)
[2024-11-13 07:44:56,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:57,284][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 2.2949557304382324, acc: 0.41304346919059753)
[2024-11-13 07:44:57,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:57,666][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 1.7103509902954102, acc: 0.5874999761581421)
[2024-11-13 07:44:57,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:57,986][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 1.3315528631210327, acc: 0.6176470518112183)
[2024-11-13 07:44:58,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:58,308][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 1.5216482877731323, acc: 0.5833333134651184)
[2024-11-13 07:44:58,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:58,639][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 1.4506216049194336, acc: 0.609375)
[2024-11-13 07:44:58,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:58,934][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.7812245488166809, acc: 0.7931034564971924)
[2024-11-13 07:44:59,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:59,268][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 2.0319101810455322, acc: 0.4642857015132904)
[2024-11-13 07:44:59,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:59,620][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 1.825782299041748, acc: 0.5)
[2024-11-13 07:44:59,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:44:59,941][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.5670781135559082, acc: 0.7599999904632568)
[2024-11-13 07:45:00,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:00,336][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 1.1505206823349, acc: 0.6666666865348816)
[2024-11-13 07:45:00,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:00,698][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 1.4391497373580933, acc: 0.5757575631141663)
[2024-11-13 07:45:00,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:01,009][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 2.013031244277954, acc: 0.47058823704719543)
[2024-11-13 07:45:01,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:01,306][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 1.7604671716690063, acc: 0.5)
[2024-11-13 07:45:01,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:01,636][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 2.1035783290863037, acc: 0.41025641560554504)
[2024-11-13 07:45:01,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:01,896][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 1.8339331150054932, acc: 0.4897959232330322)
[2024-11-13 07:45:01,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:02,204][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 2.3582072257995605, acc: 0.34328359365463257)
[2024-11-13 07:45:02,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:02,555][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 2.1589720249176025, acc: 0.4197080433368683)
[2024-11-13 07:45:02,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:02,908][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.6300182342529297, acc: 0.8571428656578064)
[2024-11-13 07:45:02,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:03,194][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.5045525431632996, acc: 0.8333333134651184)
[2024-11-13 07:45:03,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:03,499][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.8968199491500854, acc: 0.6666666865348816)
[2024-11-13 07:45:03,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:03,870][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.6139832139015198, acc: 0.7307692170143127)
[2024-11-13 07:45:03,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:04,193][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 1.5675855875015259, acc: 0.5)
[2024-11-13 07:45:04,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:04,491][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 1.9264895915985107, acc: 0.5961538553237915)
[2024-11-13 07:45:04,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:04,810][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 1.3679966926574707, acc: 0.5625)
[2024-11-13 07:45:04,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:05,159][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 1.822547435760498, acc: 0.49275362491607666)
[2024-11-13 07:45:05,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:05,528][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 1.4226700067520142, acc: 0.5799999833106995)
[2024-11-13 07:45:05,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:05,865][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 1.406928300857544, acc: 0.5652173757553101)
[2024-11-13 07:45:05,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:06,292][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.9788868427276611, acc: 0.41999998688697815)
[2024-11-13 07:45:06,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:06,647][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.79441237449646, acc: 0.5145630836486816)
[2024-11-13 07:45:06,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:07,369][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.8098572492599487, acc: 0.5291262269020081)
[2024-11-13 07:45:07,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:07,983][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.947293996810913, acc: 0.4462365508079529)
[2024-11-13 07:45:08,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:08,580][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.782238245010376, acc: 0.5517241358757019)
[2024-11-13 07:45:08,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:09,151][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.4431166648864746, acc: 0.5789473652839661)
[2024-11-13 07:45:09,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:09,845][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 2.2010462284088135, acc: 0.3861386179924011)
[2024-11-13 07:45:09,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:10,118][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 2.147733688354492, acc: 0.3870967626571655)
[2024-11-13 07:45:10,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:10,411][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 2.040116310119629, acc: 0.4637681245803833)
[2024-11-13 07:45:10,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:10,734][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 2.087381601333618, acc: 0.36974790692329407)
[2024-11-13 07:45:10,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:11,059][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 2.3474812507629395, acc: 0.32692307233810425)
[2024-11-13 07:45:11,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:11,412][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 2.1860618591308594, acc: 0.40875911712646484)
[2024-11-13 07:45:11,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:11,720][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 2.2634737491607666, acc: 0.34328359365463257)
[2024-11-13 07:45:11,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:12,094][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.9362756609916687, acc: 0.75)
[2024-11-13 07:45:12,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:12,434][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.8234487175941467, acc: 0.7727272510528564)
[2024-11-13 07:45:12,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:12,791][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.8266849517822266, acc: 0.739130437374115)
[2024-11-13 07:45:12,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:13,117][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 1.1962494850158691, acc: 0.6136363744735718)
[2024-11-13 07:45:13,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:13,460][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 1.7805205583572388, acc: 0.5517241358757019)
[2024-11-13 07:45:13,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:13,814][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 1.4074466228485107, acc: 0.5348837375640869)
[2024-11-13 07:45:13,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:14,142][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 1.2623027563095093, acc: 0.5600000023841858)
[2024-11-13 07:45:14,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:14,458][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.5404506325721741, acc: 0.8235294222831726)
[2024-11-13 07:45:14,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:14,759][root][INFO] - Training Epoch: 4/10, step 108/574 completed (loss: 0.4641028046607971, acc: 0.8846153616905212)
[2024-11-13 07:45:14,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:15,103][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 1.3643786907196045, acc: 0.5714285969734192)
[2024-11-13 07:45:15,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:15,452][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 1.6829986572265625, acc: 0.5846154093742371)
[2024-11-13 07:45:15,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:15,848][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 1.620802402496338, acc: 0.6140350699424744)
[2024-11-13 07:45:15,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:16,209][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 1.3694770336151123, acc: 0.6491228342056274)
[2024-11-13 07:45:16,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:16,557][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 1.6400971412658691, acc: 0.5641025900840759)
[2024-11-13 07:45:16,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:16,922][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 1.2506730556488037, acc: 0.7142857313156128)
[2024-11-13 07:45:16,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:17,268][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.39776790142059326, acc: 0.8636363744735718)
[2024-11-13 07:45:17,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:17,634][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 1.8082497119903564, acc: 0.4920634925365448)
[2024-11-13 07:45:17,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:17,997][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 1.8509222269058228, acc: 0.5447154641151428)
[2024-11-13 07:45:18,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:18,336][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 1.4658159017562866, acc: 0.5967742204666138)
[2024-11-13 07:45:18,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:18,961][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.9422506093978882, acc: 0.49809885025024414)
[2024-11-13 07:45:19,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:19,259][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 1.5025311708450317, acc: 0.6133333444595337)
[2024-11-13 07:45:19,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:19,580][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 1.34529447555542, acc: 0.6346153616905212)
[2024-11-13 07:45:19,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:19,964][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.7251866459846497, acc: 0.8333333134651184)
[2024-11-13 07:45:20,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:20,284][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.9670440554618835, acc: 0.7368420958518982)
[2024-11-13 07:45:20,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:20,645][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 1.9933277368545532, acc: 0.47852760553359985)
[2024-11-13 07:45:20,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:20,969][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.6707242727279663, acc: 0.5486111044883728)
[2024-11-13 07:45:21,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:21,219][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 2.0188989639282227, acc: 0.4416666626930237)
[2024-11-13 07:45:21,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:21,520][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 1.9578837156295776, acc: 0.4107142984867096)
[2024-11-13 07:45:21,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:21,841][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.8449780941009521, acc: 0.5179487466812134)
[2024-11-13 07:45:21,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:22,220][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.7434377670288086, acc: 0.5220588445663452)
[2024-11-13 07:45:22,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:22,549][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 0.9106766581535339, acc: 0.807692289352417)
[2024-11-13 07:45:22,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:22,851][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.4733256995677948, acc: 0.8260869383811951)
[2024-11-13 07:45:22,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:23,201][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 1.0233147144317627, acc: 0.6875)
[2024-11-13 07:45:23,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:23,518][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 1.5512046813964844, acc: 0.5652173757553101)
[2024-11-13 07:45:23,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:23,850][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 1.2612963914871216, acc: 0.6000000238418579)
[2024-11-13 07:45:23,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:24,164][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.9383535385131836, acc: 0.6538461446762085)
[2024-11-13 07:45:24,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:24,434][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 1.8089826107025146, acc: 0.4285714328289032)
[2024-11-13 07:45:25,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:25,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:25,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:25,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:26,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:26,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:26,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:27,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:27,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:27,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:27,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:28,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:28,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:28,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:29,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:29,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:29,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:29,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:29,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:30,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:30,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:30,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:31,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:31,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:31,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:31,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:32,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:32,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:32,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:33,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:33,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:33,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:33,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:34,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:34,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:34,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:35,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:35,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:35,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:35,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:36,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:36,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:36,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:36,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:37,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:37,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:38,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:38,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:38,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:38,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:39,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:39,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:39,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:39,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:40,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:40,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:40,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:40,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:41,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:41,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:41,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:41,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:42,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:42,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:42,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:43,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:43,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:44,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:44,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:44,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:45,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:45,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:45,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:45,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:46,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:46,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:46,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:46,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:47,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:47,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:47,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:48,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:48,774][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.2270, device='cuda:0') eval_epoch_loss=tensor(1.8289, device='cuda:0') eval_epoch_acc=tensor(0.5183, device='cuda:0')
[2024-11-13 07:45:48,775][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:45:48,776][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:45:49,045][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_4_step_137_loss_1.82888925075531/model.pt
[2024-11-13 07:45:49,048][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:45:49,049][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.82888925075531
[2024-11-13 07:45:49,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:49,454][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 1.4894627332687378, acc: 0.5)
[2024-11-13 07:45:49,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:49,750][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 1.100977897644043, acc: 0.6521739363670349)
[2024-11-13 07:45:49,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:50,044][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 1.432478904724121, acc: 0.7142857313156128)
[2024-11-13 07:45:50,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:50,356][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 1.751479983329773, acc: 0.5)
[2024-11-13 07:45:50,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:50,690][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 2.3652710914611816, acc: 0.35483869910240173)
[2024-11-13 07:45:50,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:51,024][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 2.0019707679748535, acc: 0.4054054021835327)
[2024-11-13 07:45:51,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:51,457][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 2.0253307819366455, acc: 0.37719297409057617)
[2024-11-13 07:45:51,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:51,754][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 1.6629003286361694, acc: 0.5671641826629639)
[2024-11-13 07:45:51,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:52,095][root][INFO] - Training Epoch: 4/10, step 145/574 completed (loss: 2.259622097015381, acc: 0.36734694242477417)
[2024-11-13 07:45:52,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:52,503][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 2.00655198097229, acc: 0.3510638177394867)
[2024-11-13 07:45:52,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:52,851][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 1.8218191862106323, acc: 0.5)
[2024-11-13 07:45:52,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:53,195][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 2.0334975719451904, acc: 0.5)
[2024-11-13 07:45:53,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:53,537][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 1.52947998046875, acc: 0.47826087474823)
[2024-11-13 07:45:53,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:53,855][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 1.8986852169036865, acc: 0.3103448152542114)
[2024-11-13 07:45:53,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:54,122][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 2.0813705921173096, acc: 0.5)
[2024-11-13 07:45:54,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:54,453][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 2.0752251148223877, acc: 0.4237288236618042)
[2024-11-13 07:45:54,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:54,770][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 2.2221333980560303, acc: 0.4035087823867798)
[2024-11-13 07:45:54,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:55,121][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 1.935807704925537, acc: 0.5135135054588318)
[2024-11-13 07:45:55,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:55,453][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 1.548529863357544, acc: 0.5714285969734192)
[2024-11-13 07:45:55,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:55,793][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 1.39714777469635, acc: 0.6086956262588501)
[2024-11-13 07:45:55,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:56,127][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 1.5413204431533813, acc: 0.5263158082962036)
[2024-11-13 07:45:56,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:57,001][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.5032169818878174, acc: 0.5945945978164673)
[2024-11-13 07:45:57,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:57,305][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 1.9356330633163452, acc: 0.4444444477558136)
[2024-11-13 07:45:57,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:57,652][root][INFO] - Training Epoch: 4/10, step 160/574 completed (loss: 1.4722665548324585, acc: 0.5581395626068115)
[2024-11-13 07:45:57,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:58,119][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 1.400307059288025, acc: 0.5882353186607361)
[2024-11-13 07:45:58,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:58,557][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 1.8677171468734741, acc: 0.49438202381134033)
[2024-11-13 07:45:58,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:58,903][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 1.4478729963302612, acc: 0.6136363744735718)
[2024-11-13 07:45:58,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:59,239][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 1.1655890941619873, acc: 0.6190476417541504)
[2024-11-13 07:45:59,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:59,573][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 1.2645691633224487, acc: 0.6896551847457886)
[2024-11-13 07:45:59,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:45:59,904][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 1.1661558151245117, acc: 0.6122449040412903)
[2024-11-13 07:45:59,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:00,260][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 1.5465909242630005, acc: 0.5199999809265137)
[2024-11-13 07:46:00,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:00,629][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 1.4251596927642822, acc: 0.5555555820465088)
[2024-11-13 07:46:00,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:00,976][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 1.877511978149414, acc: 0.529411792755127)
[2024-11-13 07:46:01,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:01,684][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 2.2539210319519043, acc: 0.4452054798603058)
[2024-11-13 07:46:01,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:01,950][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.9257776737213135, acc: 0.6666666865348816)
[2024-11-13 07:46:02,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:02,279][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.6232803463935852, acc: 0.8148148059844971)
[2024-11-13 07:46:02,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:02,598][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 1.1413987874984741, acc: 0.7857142686843872)
[2024-11-13 07:46:02,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:03,031][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.6331701278686523, acc: 0.5663716793060303)
[2024-11-13 07:46:03,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:03,259][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 1.5675570964813232, acc: 0.5652173757553101)
[2024-11-13 07:46:03,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:03,575][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 1.6901493072509766, acc: 0.5227272510528564)
[2024-11-13 07:46:03,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:04,218][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 2.160578489303589, acc: 0.442748099565506)
[2024-11-13 07:46:04,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:04,719][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 2.00685715675354, acc: 0.43703705072402954)
[2024-11-13 07:46:04,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:05,005][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 1.4758573770523071, acc: 0.6557376980781555)
[2024-11-13 07:46:05,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:05,330][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.8110487461090088, acc: 0.8333333134651184)
[2024-11-13 07:46:05,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:05,664][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 1.3620998859405518, acc: 0.5600000023841858)
[2024-11-13 07:46:05,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:05,935][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.930721640586853, acc: 0.7142857313156128)
[2024-11-13 07:46:06,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:06,255][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 1.87107515335083, acc: 0.4878048896789551)
[2024-11-13 07:46:06,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:06,594][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 2.129300355911255, acc: 0.42598187923431396)
[2024-11-13 07:46:06,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:06,887][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 2.193112850189209, acc: 0.4005763828754425)
[2024-11-13 07:46:06,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:07,280][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 2.2269864082336426, acc: 0.421875)
[2024-11-13 07:46:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:07,731][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 2.10347580909729, acc: 0.41651031374931335)
[2024-11-13 07:46:07,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:08,112][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 1.9978861808776855, acc: 0.4483985900878906)
[2024-11-13 07:46:08,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:08,420][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 1.7738505601882935, acc: 0.47999998927116394)
[2024-11-13 07:46:08,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:08,856][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 2.107224464416504, acc: 0.44186046719551086)
[2024-11-13 07:46:09,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:09,434][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.8046573400497437, acc: 0.5158730149269104)
[2024-11-13 07:46:09,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:10,063][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.9435181617736816, acc: 0.46212121844291687)
[2024-11-13 07:46:10,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:10,602][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 1.6556793451309204, acc: 0.5647059082984924)
[2024-11-13 07:46:10,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:11,329][root][INFO] - Training Epoch: 4/10, step 194/574 completed (loss: 1.5816874504089355, acc: 0.5555555820465088)
[2024-11-13 07:46:11,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:11,986][root][INFO] - Training Epoch: 4/10, step 195/574 completed (loss: 1.2642513513565063, acc: 0.6129032373428345)
[2024-11-13 07:46:12,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:12,258][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.6608390808105469, acc: 0.8214285969734192)
[2024-11-13 07:46:12,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:12,485][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 1.1853326559066772, acc: 0.699999988079071)
[2024-11-13 07:46:12,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:12,756][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 1.6726242303848267, acc: 0.529411792755127)
[2024-11-13 07:46:12,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:13,114][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 1.8482494354248047, acc: 0.5073529481887817)
[2024-11-13 07:46:13,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:13,480][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 1.9009952545166016, acc: 0.4830508530139923)
[2024-11-13 07:46:13,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:13,826][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 2.0941882133483887, acc: 0.4701492488384247)
[2024-11-13 07:46:13,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:14,169][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 2.0536906719207764, acc: 0.4563106894493103)
[2024-11-13 07:46:14,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:14,506][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 1.6758571863174438, acc: 0.4920634925365448)
[2024-11-13 07:46:14,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:14,855][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 1.708937644958496, acc: 0.5384615659713745)
[2024-11-13 07:46:14,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:15,179][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 2.0011096000671387, acc: 0.4439461827278137)
[2024-11-13 07:46:15,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:15,557][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 2.0634288787841797, acc: 0.4724409580230713)
[2024-11-13 07:46:15,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:15,913][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 1.9259759187698364, acc: 0.4655172526836395)
[2024-11-13 07:46:15,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:16,267][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 1.9552803039550781, acc: 0.47826087474823)
[2024-11-13 07:46:16,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:16,601][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 2.1071629524230957, acc: 0.3852140009403229)
[2024-11-13 07:46:16,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:16,937][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 2.0847761631011963, acc: 0.45652174949645996)
[2024-11-13 07:46:16,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:17,193][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 1.0002113580703735, acc: 0.6521739363670349)
[2024-11-13 07:46:17,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:17,554][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 1.2908872365951538, acc: 0.6428571343421936)
[2024-11-13 07:46:17,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:17,893][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 1.0849488973617554, acc: 0.5957446694374084)
[2024-11-13 07:46:18,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:18,409][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 1.6139655113220215, acc: 0.5461538434028625)
[2024-11-13 07:46:18,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:18,765][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 1.4269344806671143, acc: 0.5945945978164673)
[2024-11-13 07:46:18,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:19,069][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 1.382097601890564, acc: 0.6395348906517029)
[2024-11-13 07:46:19,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:19,492][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 1.515005111694336, acc: 0.6036036014556885)
[2024-11-13 07:46:19,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:19,859][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 1.5778206586837769, acc: 0.5444444417953491)
[2024-11-13 07:46:19,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:20,127][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.7634536623954773, acc: 0.7575757503509521)
[2024-11-13 07:46:20,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:20,459][root][INFO] - Training Epoch: 4/10, step 220/574 completed (loss: 0.410380095243454, acc: 0.8518518805503845)
[2024-11-13 07:46:20,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:20,741][root][INFO] - Training Epoch: 4/10, step 221/574 completed (loss: 0.5767284631729126, acc: 0.8399999737739563)
[2024-11-13 07:46:20,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:21,081][root][INFO] - Training Epoch: 4/10, step 222/574 completed (loss: 1.7602185010910034, acc: 0.48076921701431274)
[2024-11-13 07:46:21,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:21,635][root][INFO] - Training Epoch: 4/10, step 223/574 completed (loss: 1.444894552230835, acc: 0.614130437374115)
[2024-11-13 07:46:21,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:22,062][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 1.8386573791503906, acc: 0.5)
[2024-11-13 07:46:22,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:22,423][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 2.01680064201355, acc: 0.43617022037506104)
[2024-11-13 07:46:22,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:22,778][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 1.3506697416305542, acc: 0.5849056839942932)
[2024-11-13 07:46:22,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:23,099][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 1.478450059890747, acc: 0.5333333611488342)
[2024-11-13 07:46:23,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:23,458][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.8333898186683655, acc: 0.7674418687820435)
[2024-11-13 07:46:23,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:23,768][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 0.853736937046051, acc: 0.800000011920929)
[2024-11-13 07:46:23,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:24,147][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 2.0578975677490234, acc: 0.42105263471603394)
[2024-11-13 07:46:24,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:24,492][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 1.5966225862503052, acc: 0.5777778029441833)
[2024-11-13 07:46:24,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:24,832][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 1.3435591459274292, acc: 0.6555555462837219)
[2024-11-13 07:46:24,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:25,232][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 1.620855450630188, acc: 0.5779816508293152)
[2024-11-13 07:46:25,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:25,627][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 1.427699089050293, acc: 0.5923076868057251)
[2024-11-13 07:46:25,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:25,972][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 1.3023334741592407, acc: 0.6315789222717285)
[2024-11-13 07:46:26,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:26,273][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.7964019179344177, acc: 0.7083333134651184)
[2024-11-13 07:46:26,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:26,611][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 1.8270388841629028, acc: 0.40909090638160706)
[2024-11-13 07:46:26,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:26,921][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 1.64402174949646, acc: 0.5185185074806213)
[2024-11-13 07:46:26,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:27,229][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 1.0277360677719116, acc: 0.7142857313156128)
[2024-11-13 07:46:27,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:27,591][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 1.1900445222854614, acc: 0.5681818127632141)
[2024-11-13 07:46:27,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:27,903][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 1.57176673412323, acc: 0.5681818127632141)
[2024-11-13 07:46:28,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:28,355][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.9546704292297363, acc: 0.4516128897666931)
[2024-11-13 07:46:28,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:28,759][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 1.38463294506073, acc: 0.6590909361839294)
[2024-11-13 07:46:28,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:29,068][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.46556535363197327, acc: 0.8571428656578064)
[2024-11-13 07:46:29,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:29,371][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 1.0489648580551147, acc: 0.7307692170143127)
[2024-11-13 07:46:29,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:29,719][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.9749987721443176, acc: 0.774193525314331)
[2024-11-13 07:46:29,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:30,012][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.7981936931610107, acc: 0.699999988079071)
[2024-11-13 07:46:30,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:30,292][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 1.106269121170044, acc: 0.6216216087341309)
[2024-11-13 07:46:30,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:30,593][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 1.3219332695007324, acc: 0.5675675868988037)
[2024-11-13 07:46:30,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:30,913][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 1.2443592548370361, acc: 0.6486486196517944)
[2024-11-13 07:46:30,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:31,221][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 1.6671667098999023, acc: 0.529411792755127)
[2024-11-13 07:46:31,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:31,548][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.7671968340873718, acc: 0.7317073345184326)
[2024-11-13 07:46:31,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:31,867][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.37342125177383423, acc: 0.8799999952316284)
[2024-11-13 07:46:31,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:32,229][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.5099713802337646, acc: 0.800000011920929)
[2024-11-13 07:46:32,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:32,587][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.5455148816108704, acc: 0.8387096524238586)
[2024-11-13 07:46:32,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:32,918][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 1.4230141639709473, acc: 0.5789473652839661)
[2024-11-13 07:46:32,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:33,255][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 1.4754425287246704, acc: 0.5714285969734192)
[2024-11-13 07:46:33,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:33,590][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 1.3077352046966553, acc: 0.6447368264198303)
[2024-11-13 07:46:33,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:34,041][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 1.538989782333374, acc: 0.5566037893295288)
[2024-11-13 07:46:34,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:34,500][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 1.6646910905838013, acc: 0.5333333611488342)
[2024-11-13 07:46:34,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:34,759][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 1.0544164180755615, acc: 0.6388888955116272)
[2024-11-13 07:46:34,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:35,039][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 1.5391415357589722, acc: 0.5161290168762207)
[2024-11-13 07:46:35,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:35,367][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 2.4447264671325684, acc: 0.4000000059604645)
[2024-11-13 07:46:35,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:35,714][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 1.9211808443069458, acc: 0.4791666567325592)
[2024-11-13 07:46:35,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:36,294][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 2.313887119293213, acc: 0.37599998712539673)
[2024-11-13 07:46:36,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:36,604][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 2.079953193664551, acc: 0.4157303273677826)
[2024-11-13 07:46:36,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:36,954][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 1.9960038661956787, acc: 0.4864864945411682)
[2024-11-13 07:46:37,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:37,342][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 1.4961413145065308, acc: 0.5862069129943848)
[2024-11-13 07:46:37,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:37,704][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.8807839751243591, acc: 0.7727272510528564)
[2024-11-13 07:46:37,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:38,047][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.9993047714233398, acc: 0.5909090638160706)
[2024-11-13 07:46:38,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:38,380][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.9159644842147827, acc: 0.71875)
[2024-11-13 07:46:38,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:38,703][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 1.0580310821533203, acc: 0.7333333492279053)
[2024-11-13 07:46:38,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:39,051][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 1.5983455181121826, acc: 0.5166666507720947)
[2024-11-13 07:46:39,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:39,373][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 1.1703765392303467, acc: 0.65625)
[2024-11-13 07:46:39,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:39,703][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.8371641039848328, acc: 0.7666666507720947)
[2024-11-13 07:46:39,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:40,068][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 1.2534314393997192, acc: 0.6206896305084229)
[2024-11-13 07:46:40,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:40,378][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 1.2773795127868652, acc: 0.6800000071525574)
[2024-11-13 07:46:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:40,728][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 1.798444390296936, acc: 0.5106382966041565)
[2024-11-13 07:46:40,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:41,046][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 1.7217718362808228, acc: 0.5625)
[2024-11-13 07:46:41,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:42,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:42,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:42,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:42,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:42,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:43,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:43,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:43,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:44,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:44,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:44,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:44,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:45,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:45,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:45,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:45,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:46,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:46,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:46,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:46,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:47,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:47,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:47,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:48,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:48,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:48,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:48,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:49,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:49,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:49,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:49,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:49,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:50,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:50,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:51,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:51,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:51,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:52,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:52,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:52,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:53,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:53,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:53,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:54,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:54,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:54,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:54,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:55,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:55,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:55,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:56,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:56,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:56,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:56,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:57,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:57,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:57,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:58,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:58,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:58,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:59,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:59,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:59,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:46:59,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:00,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:00,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:00,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:00,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:01,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:01,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:01,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:02,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:02,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:02,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:02,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:03,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:03,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:03,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:03,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:04,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:04,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:04,995][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.9375, device='cuda:0') eval_epoch_loss=tensor(1.9369, device='cuda:0') eval_epoch_acc=tensor(0.5309, device='cuda:0')
[2024-11-13 07:47:04,997][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:47:04,997][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:47:05,302][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_4_step_280_loss_1.9369474649429321/model.pt
[2024-11-13 07:47:05,306][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:47:05,306][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.5309207439422607
[2024-11-13 07:47:05,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:05,609][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 1.613582730293274, acc: 0.5909090638160706)
[2024-11-13 07:47:05,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:05,966][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 2.008964776992798, acc: 0.4939759075641632)
[2024-11-13 07:47:06,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:06,280][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 1.9253861904144287, acc: 0.49074074625968933)
[2024-11-13 07:47:06,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:06,624][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 1.640405535697937, acc: 0.5526315569877625)
[2024-11-13 07:47:06,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:06,932][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 1.8671599626541138, acc: 0.529411792755127)
[2024-11-13 07:47:07,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:07,238][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 1.3815511465072632, acc: 0.5249999761581421)
[2024-11-13 07:47:07,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:07,545][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 1.9622474908828735, acc: 0.453125)
[2024-11-13 07:47:07,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:07,874][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 2.0918593406677246, acc: 0.4480000138282776)
[2024-11-13 07:47:07,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:08,169][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 1.624880075454712, acc: 0.5164835453033447)
[2024-11-13 07:47:08,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:08,469][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 2.161839485168457, acc: 0.4409937858581543)
[2024-11-13 07:47:08,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:08,782][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 2.302203416824341, acc: 0.34536081552505493)
[2024-11-13 07:47:08,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:09,055][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.7021649479866028, acc: 0.7727272510528564)
[2024-11-13 07:47:09,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:09,355][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 1.8163076639175415, acc: 0.4523809552192688)
[2024-11-13 07:47:09,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:09,652][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 1.2926456928253174, acc: 0.6379310488700867)
[2024-11-13 07:47:09,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:10,013][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 1.2796001434326172, acc: 0.6545454263687134)
[2024-11-13 07:47:10,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:10,452][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.714191198348999, acc: 0.5360824465751648)
[2024-11-13 07:47:10,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:10,778][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 1.7283028364181519, acc: 0.4655172526836395)
[2024-11-13 07:47:10,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:11,086][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 1.4132378101348877, acc: 0.6296296119689941)
[2024-11-13 07:47:11,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:11,401][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 1.4791091680526733, acc: 0.6052631735801697)
[2024-11-13 07:47:11,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:11,697][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 1.110925555229187, acc: 0.6607142686843872)
[2024-11-13 07:47:11,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:11,997][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 1.189947485923767, acc: 0.59375)
[2024-11-13 07:47:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:12,318][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 1.2759370803833008, acc: 0.6603773832321167)
[2024-11-13 07:47:12,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:12,637][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.8060740232467651, acc: 0.7169811129570007)
[2024-11-13 07:47:12,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:12,918][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 1.0581562519073486, acc: 0.7647058963775635)
[2024-11-13 07:47:13,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:13,256][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 1.3378496170043945, acc: 0.625)
[2024-11-13 07:47:13,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:13,565][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 1.2949062585830688, acc: 0.6065573692321777)
[2024-11-13 07:47:13,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:13,852][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.6422989368438721, acc: 0.800000011920929)
[2024-11-13 07:47:13,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:14,158][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.4620191156864166, acc: 0.8421052694320679)
[2024-11-13 07:47:14,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:14,444][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 1.664261817932129, acc: 0.5362318754196167)
[2024-11-13 07:47:14,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:14,786][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 1.526182770729065, acc: 0.5555555820465088)
[2024-11-13 07:47:14,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:15,067][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 1.2792696952819824, acc: 0.6024096608161926)
[2024-11-13 07:47:15,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:15,352][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 1.8599594831466675, acc: 0.4871794879436493)
[2024-11-13 07:47:15,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:15,661][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 1.879470705986023, acc: 0.5204081535339355)
[2024-11-13 07:47:15,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:15,941][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.24438725411891937, acc: 0.9583333134651184)
[2024-11-13 07:47:15,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:16,213][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.8578023314476013, acc: 0.8333333134651184)
[2024-11-13 07:47:16,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:16,495][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.7206382155418396, acc: 0.8064516186714172)
[2024-11-13 07:47:16,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:16,787][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 0.81955885887146, acc: 0.7096773982048035)
[2024-11-13 07:47:16,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:17,099][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 1.308741569519043, acc: 0.641791045665741)
[2024-11-13 07:47:17,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:17,413][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 1.2645652294158936, acc: 0.625)
[2024-11-13 07:47:17,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:17,725][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 1.4293169975280762, acc: 0.5333333611488342)
[2024-11-13 07:47:17,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:18,072][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 1.3179010152816772, acc: 0.6129032373428345)
[2024-11-13 07:47:18,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:18,379][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.9543091058731079, acc: 0.7400000095367432)
[2024-11-13 07:47:18,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:18,683][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 1.9028947353363037, acc: 0.37037035822868347)
[2024-11-13 07:47:18,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:18,992][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 2.2253966331481934, acc: 0.37142857909202576)
[2024-11-13 07:47:19,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:19,328][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.8137972354888916, acc: 0.4615384638309479)
[2024-11-13 07:47:19,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:19,644][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 2.075178861618042, acc: 0.5609756112098694)
[2024-11-13 07:47:19,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:19,939][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.6033058166503906, acc: 0.6052631735801697)
[2024-11-13 07:47:20,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:20,243][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.88640958070755, acc: 0.7368420958518982)
[2024-11-13 07:47:20,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:20,542][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.699227511882782, acc: 0.8214285969734192)
[2024-11-13 07:47:20,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:20,851][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 1.431915521621704, acc: 0.6296296119689941)
[2024-11-13 07:47:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:21,151][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.7799459099769592, acc: 0.78125)
[2024-11-13 07:47:21,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:21,465][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 1.6899995803833008, acc: 0.5645161271095276)
[2024-11-13 07:47:21,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:21,800][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 1.4552379846572876, acc: 0.5614035129547119)
[2024-11-13 07:47:21,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:22,110][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 1.8280054330825806, acc: 0.46875)
[2024-11-13 07:47:22,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:22,444][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 0.9703238606452942, acc: 0.699999988079071)
[2024-11-13 07:47:22,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:22,738][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 1.2696481943130493, acc: 0.5789473652839661)
[2024-11-13 07:47:22,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:23,064][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 2.084103584289551, acc: 0.4399999976158142)
[2024-11-13 07:47:23,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:23,367][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 2.250534772872925, acc: 0.39080458879470825)
[2024-11-13 07:47:23,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:23,671][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 2.197561502456665, acc: 0.42553192377090454)
[2024-11-13 07:47:23,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:23,959][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 2.2992441654205322, acc: 0.3855421543121338)
[2024-11-13 07:47:24,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:24,194][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.8314524292945862, acc: 0.739130437374115)
[2024-11-13 07:47:24,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:24,432][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 1.6134012937545776, acc: 0.5384615659713745)
[2024-11-13 07:47:24,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:24,724][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 2.204543352127075, acc: 0.3855421543121338)
[2024-11-13 07:47:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:25,000][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 1.6089880466461182, acc: 0.6226415038108826)
[2024-11-13 07:47:25,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:25,308][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 1.7203658819198608, acc: 0.5189873576164246)
[2024-11-13 07:47:25,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:25,610][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 1.7422363758087158, acc: 0.529411792755127)
[2024-11-13 07:47:25,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:25,913][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 2.2993762493133545, acc: 0.4029850661754608)
[2024-11-13 07:47:25,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:26,228][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.6958574056625366, acc: 0.800000011920929)
[2024-11-13 07:47:26,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:26,507][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 1.0322535037994385, acc: 0.6000000238418579)
[2024-11-13 07:47:26,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:26,857][root][INFO] - Training Epoch: 4/10, step 349/574 completed (loss: 1.352217197418213, acc: 0.6944444179534912)
[2024-11-13 07:47:26,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:27,172][root][INFO] - Training Epoch: 4/10, step 350/574 completed (loss: 1.648679494857788, acc: 0.5581395626068115)
[2024-11-13 07:47:27,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:27,478][root][INFO] - Training Epoch: 4/10, step 351/574 completed (loss: 1.4800705909729004, acc: 0.5384615659713745)
[2024-11-13 07:47:27,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:27,787][root][INFO] - Training Epoch: 4/10, step 352/574 completed (loss: 1.5658529996871948, acc: 0.5555555820465088)
[2024-11-13 07:47:27,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:28,056][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.788175642490387, acc: 0.695652186870575)
[2024-11-13 07:47:28,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:28,344][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 1.477647304534912, acc: 0.5384615659713745)
[2024-11-13 07:47:28,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:28,659][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 2.2887825965881348, acc: 0.4065934121608734)
[2024-11-13 07:47:28,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:29,055][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 1.934851884841919, acc: 0.5478261113166809)
[2024-11-13 07:47:29,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:29,345][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 1.8859905004501343, acc: 0.510869562625885)
[2024-11-13 07:47:29,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:29,636][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 2.0821566581726074, acc: 0.4693877696990967)
[2024-11-13 07:47:29,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:29,911][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.4108695983886719, acc: 0.875)
[2024-11-13 07:47:29,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:30,192][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.7422444820404053, acc: 0.7692307829856873)
[2024-11-13 07:47:30,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:30,470][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 1.172572135925293, acc: 0.7317073345184326)
[2024-11-13 07:47:30,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:30,792][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 1.4047075510025024, acc: 0.6222222447395325)
[2024-11-13 07:47:30,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:31,085][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 1.7124654054641724, acc: 0.5131579041481018)
[2024-11-13 07:47:31,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:31,371][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 1.5888725519180298, acc: 0.5609756112098694)
[2024-11-13 07:47:31,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:31,633][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 1.502431869506836, acc: 0.5757575631141663)
[2024-11-13 07:47:31,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:31,905][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.6302199959754944, acc: 0.8333333134651184)
[2024-11-13 07:47:31,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:32,179][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.4290437400341034, acc: 0.9130434989929199)
[2024-11-13 07:47:32,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:32,484][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.5932073593139648, acc: 0.8571428656578064)
[2024-11-13 07:47:32,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:32,788][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 0.9865943789482117, acc: 0.65625)
[2024-11-13 07:47:32,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:33,251][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 1.6304223537445068, acc: 0.5696969628334045)
[2024-11-13 07:47:33,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:33,842][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 1.3167953491210938, acc: 0.698113203048706)
[2024-11-13 07:47:33,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:34,134][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 1.3976764678955078, acc: 0.6222222447395325)
[2024-11-13 07:47:34,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:34,423][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 1.335190773010254, acc: 0.5892857313156128)
[2024-11-13 07:47:34,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:34,746][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.8739927411079407, acc: 0.7142857313156128)
[2024-11-13 07:47:34,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:35,043][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.42541760206222534, acc: 0.8799999952316284)
[2024-11-13 07:47:35,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:35,347][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.6189759969711304, acc: 0.782608687877655)
[2024-11-13 07:47:35,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:35,627][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 1.3129905462265015, acc: 0.6458333134651184)
[2024-11-13 07:47:35,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:35,922][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 1.432982087135315, acc: 0.6315789222717285)
[2024-11-13 07:47:36,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:36,366][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 1.6431045532226562, acc: 0.6167664527893066)
[2024-11-13 07:47:36,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:36,699][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 1.406219482421875, acc: 0.5864661931991577)
[2024-11-13 07:47:36,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:37,442][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 1.5968728065490723, acc: 0.5508021116256714)
[2024-11-13 07:47:37,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:37,879][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 1.236997365951538, acc: 0.6576576828956604)
[2024-11-13 07:47:37,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:38,106][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.7128759622573853, acc: 0.7857142686843872)
[2024-11-13 07:47:38,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:38,365][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.5797837972640991, acc: 0.8214285969734192)
[2024-11-13 07:47:38,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:38,627][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 0.9392741322517395, acc: 0.71875)
[2024-11-13 07:47:38,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:38,933][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.8804650902748108, acc: 0.75)
[2024-11-13 07:47:39,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:39,239][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.94781494140625, acc: 0.7894737124443054)
[2024-11-13 07:47:39,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:39,547][root][INFO] - Training Epoch: 4/10, step 388/574 completed (loss: 0.4875643849372864, acc: 0.8181818127632141)
[2024-11-13 07:47:39,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:39,840][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.9328414797782898, acc: 0.6499999761581421)
[2024-11-13 07:47:39,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:40,142][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.86961829662323, acc: 0.6666666865348816)
[2024-11-13 07:47:40,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:40,443][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 2.3246991634368896, acc: 0.40740740299224854)
[2024-11-13 07:47:40,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:40,742][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 2.1462626457214355, acc: 0.446601927280426)
[2024-11-13 07:47:40,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:41,154][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 1.8612533807754517, acc: 0.5588235259056091)
[2024-11-13 07:47:41,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:41,465][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 2.0777151584625244, acc: 0.47999998927116394)
[2024-11-13 07:47:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:41,781][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 2.137985944747925, acc: 0.4722222089767456)
[2024-11-13 07:47:41,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:42,119][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 1.581597089767456, acc: 0.5813953280448914)
[2024-11-13 07:47:42,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:42,424][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.8440960049629211, acc: 0.7083333134651184)
[2024-11-13 07:47:42,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:42,736][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 1.097397804260254, acc: 0.7441860437393188)
[2024-11-13 07:47:42,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:43,004][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 1.3292007446289062, acc: 0.6800000071525574)
[2024-11-13 07:47:43,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:43,444][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 1.6450388431549072, acc: 0.5441176295280457)
[2024-11-13 07:47:43,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:43,793][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 1.540055751800537, acc: 0.54666668176651)
[2024-11-13 07:47:43,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:44,146][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 1.0471869707107544, acc: 0.6969696879386902)
[2024-11-13 07:47:44,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:44,500][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 1.3012700080871582, acc: 0.7272727489471436)
[2024-11-13 07:47:44,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:44,861][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.7446625828742981, acc: 0.8064516186714172)
[2024-11-13 07:47:44,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:45,184][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.7889017462730408, acc: 0.8148148059844971)
[2024-11-13 07:47:45,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:45,527][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.7243120670318604, acc: 0.7599999904632568)
[2024-11-13 07:47:45,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:45,851][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.6997387409210205, acc: 0.7777777910232544)
[2024-11-13 07:47:45,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:46,182][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.9081417918205261, acc: 0.7407407164573669)
[2024-11-13 07:47:46,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:46,468][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.8007090091705322, acc: 0.692307710647583)
[2024-11-13 07:47:46,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:46,798][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 1.1410586833953857, acc: 0.6896551847457886)
[2024-11-13 07:47:46,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:47,116][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.686805784702301, acc: 0.75)
[2024-11-13 07:47:47,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:47,475][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.9177600741386414, acc: 0.7333333492279053)
[2024-11-13 07:47:47,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:47,741][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 1.0078688859939575, acc: 0.6666666865348816)
[2024-11-13 07:47:47,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:48,017][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.6575192809104919, acc: 0.7727272510528564)
[2024-11-13 07:47:48,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:48,382][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 1.6068764925003052, acc: 0.5686274766921997)
[2024-11-13 07:47:48,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:48,738][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 1.4124089479446411, acc: 0.6153846383094788)
[2024-11-13 07:47:48,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:49,054][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 1.2740771770477295, acc: 0.5555555820465088)
[2024-11-13 07:47:49,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:49,414][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 1.2020548582077026, acc: 0.675000011920929)
[2024-11-13 07:47:49,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:49,779][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 1.0809710025787354, acc: 0.6499999761581421)
[2024-11-13 07:47:49,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:50,101][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.5491165518760681, acc: 0.761904776096344)
[2024-11-13 07:47:50,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:50,385][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.7770546078681946, acc: 0.7666666507720947)
[2024-11-13 07:47:50,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:50,648][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.8496369123458862, acc: 0.75)
[2024-11-13 07:47:51,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:51,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:52,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:52,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:52,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:52,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:52,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:53,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:53,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:54,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:54,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:54,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:55,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:55,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:55,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:55,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:55,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:56,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:56,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:56,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:56,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:57,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:57,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:57,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:58,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:58,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:58,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:58,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:59,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:59,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:59,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:47:59,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:00,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:00,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:00,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:01,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:01,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:01,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:01,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:02,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:02,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:02,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:02,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:03,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:03,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:03,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:03,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:04,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:04,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:04,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:04,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:05,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:05,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:05,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:06,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:06,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:06,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:06,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:06,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:07,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:07,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:07,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:08,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:08,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:08,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:08,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:09,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:09,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:09,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:09,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:10,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:10,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:10,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:10,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:11,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:11,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:11,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:11,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:12,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:12,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:12,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:12,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:13,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:13,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:14,012][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(15.3900, device='cuda:0') eval_epoch_loss=tensor(2.7337, device='cuda:0') eval_epoch_acc=tensor(0.4615, device='cuda:0')
[2024-11-13 07:48:14,014][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:48:14,014][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:48:14,333][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_4_step_423_loss_2.733720541000366/model.pt
[2024-11-13 07:48:14,336][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:48:14,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:14,734][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 0.8775050640106201, acc: 0.7222222089767456)
[2024-11-13 07:48:14,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:15,037][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 1.1112474203109741, acc: 0.6666666865348816)
[2024-11-13 07:48:15,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:15,382][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 1.5223140716552734, acc: 0.7575757503509521)
[2024-11-13 07:48:15,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:15,691][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 2.3444976806640625, acc: 0.6521739363670349)
[2024-11-13 07:48:15,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:16,038][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 1.4974384307861328, acc: 0.6756756901741028)
[2024-11-13 07:48:16,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:16,312][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 1.239066243171692, acc: 0.6666666865348816)
[2024-11-13 07:48:16,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:16,600][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 1.1662328243255615, acc: 0.6086956262588501)
[2024-11-13 07:48:16,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:16,916][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.5130177140235901, acc: 0.7777777910232544)
[2024-11-13 07:48:16,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:17,270][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.6778576374053955, acc: 0.7777777910232544)
[2024-11-13 07:48:17,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:17,580][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.7265318036079407, acc: 0.782608687877655)
[2024-11-13 07:48:17,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:17,931][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 1.0357869863510132, acc: 0.75)
[2024-11-13 07:48:18,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:18,239][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.6707860827445984, acc: 0.8399999737739563)
[2024-11-13 07:48:18,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:18,582][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 1.1554853916168213, acc: 0.6969696879386902)
[2024-11-13 07:48:18,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:18,921][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 1.3355138301849365, acc: 0.6388888955116272)
[2024-11-13 07:48:18,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:19,183][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 1.1595852375030518, acc: 0.75)
[2024-11-13 07:48:19,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:19,428][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.7908243536949158, acc: 0.761904776096344)
[2024-11-13 07:48:19,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:19,707][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 1.5929746627807617, acc: 0.5897436141967773)
[2024-11-13 07:48:19,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:20,075][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 1.7309223413467407, acc: 0.5454545617103577)
[2024-11-13 07:48:20,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:20,599][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 2.158261775970459, acc: 0.3919999897480011)
[2024-11-13 07:48:20,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:20,977][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 2.117826461791992, acc: 0.41129031777381897)
[2024-11-13 07:48:21,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:21,483][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 2.068978786468506, acc: 0.45771142840385437)
[2024-11-13 07:48:21,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:21,835][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 1.5354082584381104, acc: 0.6226415038108826)
[2024-11-13 07:48:21,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:22,199][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 0.9163520932197571, acc: 0.6590909361839294)
[2024-11-13 07:48:22,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:22,528][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 1.1065655946731567, acc: 0.6521739363670349)
[2024-11-13 07:48:22,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:22,880][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 1.2036566734313965, acc: 0.6538461446762085)
[2024-11-13 07:48:22,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:23,196][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.9694738388061523, acc: 0.7142857313156128)
[2024-11-13 07:48:23,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:23,481][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 1.7535151243209839, acc: 0.5223880410194397)
[2024-11-13 07:48:23,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:23,811][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 1.4910286664962769, acc: 0.6666666865348816)
[2024-11-13 07:48:23,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:24,149][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 1.4283263683319092, acc: 0.5760869383811951)
[2024-11-13 07:48:24,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:24,461][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 1.7097742557525635, acc: 0.5641025900840759)
[2024-11-13 07:48:24,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:24,786][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 1.8820879459381104, acc: 0.5)
[2024-11-13 07:48:24,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:25,115][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 1.5987926721572876, acc: 0.5714285969734192)
[2024-11-13 07:48:25,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:25,476][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 0.9832631945610046, acc: 0.6969696879386902)
[2024-11-13 07:48:25,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:25,846][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 1.9393601417541504, acc: 0.47422680258750916)
[2024-11-13 07:48:25,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:26,157][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 1.4583773612976074, acc: 0.6000000238418579)
[2024-11-13 07:48:26,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:26,481][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 1.8420432806015015, acc: 0.4883720874786377)
[2024-11-13 07:48:26,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:26,758][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 2.0017683506011963, acc: 0.375)
[2024-11-13 07:48:26,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:27,073][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 1.791632056236267, acc: 0.4938271641731262)
[2024-11-13 07:48:27,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:27,391][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 1.5319194793701172, acc: 0.5)
[2024-11-13 07:48:27,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:27,706][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 1.0701755285263062, acc: 0.6875)
[2024-11-13 07:48:27,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:28,001][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 1.120703935623169, acc: 0.6538461446762085)
[2024-11-13 07:48:28,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:28,302][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 1.285021185874939, acc: 0.739130437374115)
[2024-11-13 07:48:28,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:28,609][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 1.7078012228012085, acc: 0.4523809552192688)
[2024-11-13 07:48:28,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:28,883][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.8295786380767822, acc: 0.4457831382751465)
[2024-11-13 07:48:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:29,199][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 1.4506205320358276, acc: 0.5495495200157166)
[2024-11-13 07:48:29,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:29,495][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.6929253339767456, acc: 0.5728155374526978)
[2024-11-13 07:48:29,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:29,811][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 1.447632074356079, acc: 0.5934959053993225)
[2024-11-13 07:48:29,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:30,059][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 1.0918853282928467, acc: 0.6666666865348816)
[2024-11-13 07:48:30,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:30,324][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 1.4089909791946411, acc: 0.7142857313156128)
[2024-11-13 07:48:30,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:30,660][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 1.9222558736801147, acc: 0.47058823704719543)
[2024-11-13 07:48:30,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:30,967][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 2.095399856567383, acc: 0.4410480260848999)
[2024-11-13 07:48:31,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:31,242][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 1.8876127004623413, acc: 0.5)
[2024-11-13 07:48:31,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:31,562][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 1.9878360033035278, acc: 0.4110429584980011)
[2024-11-13 07:48:31,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:31,858][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 2.0620858669281006, acc: 0.4316546618938446)
[2024-11-13 07:48:31,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:32,212][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 2.2266781330108643, acc: 0.37688443064689636)
[2024-11-13 07:48:32,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:32,528][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 1.0899358987808228, acc: 0.6944444179534912)
[2024-11-13 07:48:32,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:32,835][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 1.2228317260742188, acc: 0.5151515007019043)
[2024-11-13 07:48:32,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:33,137][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.9161599278450012, acc: 0.7037037014961243)
[2024-11-13 07:48:33,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:33,439][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 1.3402612209320068, acc: 0.550000011920929)
[2024-11-13 07:48:33,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:33,736][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 0.743472695350647, acc: 0.75)
[2024-11-13 07:48:33,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:34,062][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 1.3411389589309692, acc: 0.568965494632721)
[2024-11-13 07:48:34,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:34,358][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 1.0672962665557861, acc: 0.7419354915618896)
[2024-11-13 07:48:34,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:34,649][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.753515362739563, acc: 0.8947368264198303)
[2024-11-13 07:48:34,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:34,933][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 1.4706755876541138, acc: 0.5925925970077515)
[2024-11-13 07:48:34,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:35,227][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 1.7849713563919067, acc: 0.380952388048172)
[2024-11-13 07:48:35,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:35,536][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 1.2922171354293823, acc: 0.4545454680919647)
[2024-11-13 07:48:35,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:35,849][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.7360533475875854, acc: 0.5692307949066162)
[2024-11-13 07:48:35,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:36,126][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 1.5799957513809204, acc: 0.5333333611488342)
[2024-11-13 07:48:36,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:36,423][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 1.3715568780899048, acc: 0.6206896305084229)
[2024-11-13 07:48:36,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:36,727][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 1.764919638633728, acc: 0.4901960790157318)
[2024-11-13 07:48:36,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:37,022][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 1.458646297454834, acc: 0.5517241358757019)
[2024-11-13 07:48:37,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:37,296][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.6177130341529846, acc: 0.8421052694320679)
[2024-11-13 07:48:37,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:37,567][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 1.4693293571472168, acc: 0.5789473652839661)
[2024-11-13 07:48:37,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:37,849][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 1.5529526472091675, acc: 0.5535714030265808)
[2024-11-13 07:48:37,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:38,176][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 1.7274041175842285, acc: 0.5056179761886597)
[2024-11-13 07:48:38,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:38,452][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 2.0240492820739746, acc: 0.483146071434021)
[2024-11-13 07:48:38,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:38,771][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 2.217585563659668, acc: 0.39716312289237976)
[2024-11-13 07:48:38,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:39,077][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 2.2738711833953857, acc: 0.3804347813129425)
[2024-11-13 07:48:39,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:39,356][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.7246527671813965, acc: 0.8399999737739563)
[2024-11-13 07:48:39,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:39,689][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.708389163017273, acc: 0.807692289352417)
[2024-11-13 07:48:39,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:39,969][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.6960743069648743, acc: 0.7777777910232544)
[2024-11-13 07:48:40,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:40,234][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 1.6690099239349365, acc: 0.48148149251937866)
[2024-11-13 07:48:40,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:40,511][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 1.1719374656677246, acc: 0.6226415038108826)
[2024-11-13 07:48:40,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:40,824][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 0.8241086006164551, acc: 0.8275862336158752)
[2024-11-13 07:48:40,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:41,271][root][INFO] - Training Epoch: 4/10, step 507/574 completed (loss: 1.6287108659744263, acc: 0.522522509098053)
[2024-11-13 07:48:41,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:41,628][root][INFO] - Training Epoch: 4/10, step 508/574 completed (loss: 1.4045958518981934, acc: 0.6338028311729431)
[2024-11-13 07:48:41,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:41,941][root][INFO] - Training Epoch: 4/10, step 509/574 completed (loss: 0.48368510603904724, acc: 0.8500000238418579)
[2024-11-13 07:48:42,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:42,248][root][INFO] - Training Epoch: 4/10, step 510/574 completed (loss: 0.6517685055732727, acc: 0.800000011920929)
[2024-11-13 07:48:42,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:42,542][root][INFO] - Training Epoch: 4/10, step 511/574 completed (loss: 0.7774401903152466, acc: 0.8461538553237915)
[2024-11-13 07:48:42,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:43,741][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 1.8683874607086182, acc: 0.4928571283817291)
[2024-11-13 07:48:43,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:44,294][root][INFO] - Training Epoch: 4/10, step 513/574 completed (loss: 1.687646508216858, acc: 0.5714285969734192)
[2024-11-13 07:48:44,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:44,573][root][INFO] - Training Epoch: 4/10, step 514/574 completed (loss: 1.023878574371338, acc: 0.6785714030265808)
[2024-11-13 07:48:44,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:44,927][root][INFO] - Training Epoch: 4/10, step 515/574 completed (loss: 1.4921413660049438, acc: 0.550000011920929)
[2024-11-13 07:48:45,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:45,454][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 1.4077168703079224, acc: 0.6388888955116272)
[2024-11-13 07:48:45,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:45,706][root][INFO] - Training Epoch: 4/10, step 517/574 completed (loss: 0.4565518796443939, acc: 0.7692307829856873)
[2024-11-13 07:48:45,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:45,976][root][INFO] - Training Epoch: 4/10, step 518/574 completed (loss: 1.3733114004135132, acc: 0.4838709533214569)
[2024-11-13 07:48:46,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:46,260][root][INFO] - Training Epoch: 4/10, step 519/574 completed (loss: 1.3334102630615234, acc: 0.699999988079071)
[2024-11-13 07:48:46,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:46,553][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 1.1469112634658813, acc: 0.7037037014961243)
[2024-11-13 07:48:46,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:47,252][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 2.0921106338500977, acc: 0.47457626461982727)
[2024-11-13 07:48:47,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:47,570][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 2.026874542236328, acc: 0.4701492488384247)
[2024-11-13 07:48:47,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:47,905][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 1.9059929847717285, acc: 0.46715328097343445)
[2024-11-13 07:48:48,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:48,343][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 1.8414117097854614, acc: 0.47999998927116394)
[2024-11-13 07:48:48,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:48,605][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 1.6569023132324219, acc: 0.6111111044883728)
[2024-11-13 07:48:48,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:48,872][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 1.5383524894714355, acc: 0.5769230723381042)
[2024-11-13 07:48:48,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:49,141][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 1.7569513320922852, acc: 0.3333333432674408)
[2024-11-13 07:48:49,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:49,444][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 2.3849639892578125, acc: 0.32786884903907776)
[2024-11-13 07:48:49,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:49,713][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 1.6495685577392578, acc: 0.5932203531265259)
[2024-11-13 07:48:49,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:50,007][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.9654769897460938, acc: 0.4883720874786377)
[2024-11-13 07:48:50,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:50,319][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 1.7140758037567139, acc: 0.5681818127632141)
[2024-11-13 07:48:50,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:50,627][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 2.090165853500366, acc: 0.4528301954269409)
[2024-11-13 07:48:50,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:50,926][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 1.6245346069335938, acc: 0.5681818127632141)
[2024-11-13 07:48:50,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:51,204][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 1.157292366027832, acc: 0.7200000286102295)
[2024-11-13 07:48:51,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:51,450][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.8507897257804871, acc: 0.800000011920929)
[2024-11-13 07:48:51,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:51,719][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.8209386467933655, acc: 0.7727272510528564)
[2024-11-13 07:48:51,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:52,039][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 1.5342967510223389, acc: 0.6000000238418579)
[2024-11-13 07:48:52,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:52,349][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 1.397737741470337, acc: 0.65625)
[2024-11-13 07:48:52,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:52,673][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 0.9092465043067932, acc: 0.75)
[2024-11-13 07:48:52,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:52,950][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 1.217947006225586, acc: 0.6666666865348816)
[2024-11-13 07:48:53,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:53,228][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.8029819130897522, acc: 0.6875)
[2024-11-13 07:48:53,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:53,511][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.5865736603736877, acc: 0.8387096524238586)
[2024-11-13 07:48:53,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:53,820][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.48744773864746094, acc: 0.8260869383811951)
[2024-11-13 07:48:53,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:54,094][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 1.341704249382019, acc: 0.6000000238418579)
[2024-11-13 07:48:54,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:54,394][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 1.364195704460144, acc: 0.5609756112098694)
[2024-11-13 07:48:54,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:54,651][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 1.139885663986206, acc: 0.6857143044471741)
[2024-11-13 07:48:54,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:54,964][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 1.0045908689498901, acc: 0.7105262875556946)
[2024-11-13 07:48:55,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:55,272][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.9172695875167847, acc: 0.7419354915618896)
[2024-11-13 07:48:55,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:55,564][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.6719197630882263, acc: 0.7599999904632568)
[2024-11-13 07:48:55,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:55,833][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.7646884918212891, acc: 0.7575757503509521)
[2024-11-13 07:48:55,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:56,123][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 1.1080032587051392, acc: 0.699999988079071)
[2024-11-13 07:48:56,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:56,417][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 1.1003755331039429, acc: 0.6857143044471741)
[2024-11-13 07:48:56,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:56,715][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 2.0517847537994385, acc: 0.43065693974494934)
[2024-11-13 07:48:56,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:57,063][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 1.5379054546356201, acc: 0.5724138021469116)
[2024-11-13 07:48:57,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:57,381][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 2.281496286392212, acc: 0.4714285731315613)
[2024-11-13 07:48:57,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:57,667][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 2.0390820503234863, acc: 0.4370861053466797)
[2024-11-13 07:48:57,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:57,978][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 1.637147307395935, acc: 0.5470085740089417)
[2024-11-13 07:48:58,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:58,222][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.5582011938095093, acc: 0.8399999737739563)
[2024-11-13 07:48:58,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:58,500][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.9734474420547485, acc: 0.7307692170143127)
[2024-11-13 07:48:58,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:58,829][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.6052116751670837, acc: 0.807692289352417)
[2024-11-13 07:48:58,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:59,138][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 1.2333807945251465, acc: 0.6666666865348816)
[2024-11-13 07:48:59,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:59,499][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 1.3906750679016113, acc: 0.5555555820465088)
[2024-11-13 07:48:59,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:48:59,815][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 1.2549631595611572, acc: 0.6623376607894897)
[2024-11-13 07:48:59,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:00,167][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 1.0623034238815308, acc: 0.7083333134651184)
[2024-11-13 07:49:00,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:00,487][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 0.979403555393219, acc: 0.6896551847457886)
[2024-11-13 07:49:01,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:01,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:01,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:01,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:02,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:02,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:02,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:03,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:03,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:03,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:03,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:04,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:04,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:04,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:05,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:05,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:05,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:05,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:05,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:06,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:06,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:06,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:06,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:07,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:07,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:07,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:07,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:08,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:08,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:08,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:08,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:09,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:09,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:09,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:09,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:10,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:10,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:10,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:11,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:11,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:11,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:11,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:12,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:12,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:12,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:13,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:13,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:13,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:14,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:14,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:14,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:14,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:15,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:15,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:15,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:16,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:16,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:16,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:16,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:17,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:17,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:17,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:18,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:18,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:18,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:18,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:19,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:19,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:19,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:20,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:20,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:21,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:21,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:21,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:21,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:21,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:22,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:22,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:22,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:22,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:23,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:23,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:23,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:23,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:24,451][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.0178, device='cuda:0') eval_epoch_loss=tensor(1.9484, device='cuda:0') eval_epoch_acc=tensor(0.5273, device='cuda:0')
[2024-11-13 07:49:24,453][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:49:24,454][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:49:24,779][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_4_step_566_loss_1.9484436511993408/model.pt
[2024-11-13 07:49:24,789][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:49:24,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:25,196][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 1.363281011581421, acc: 0.5595238208770752)
[2024-11-13 07:49:25,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:25,539][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 1.2928270101547241, acc: 0.6052631735801697)
[2024-11-13 07:49:25,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:25,860][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.7249871492385864, acc: 0.7407407164573669)
[2024-11-13 07:49:25,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:26,251][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 1.7110153436660767, acc: 0.5133689641952515)
[2024-11-13 07:49:26,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:26,565][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 1.1875507831573486, acc: 0.6612903475761414)
[2024-11-13 07:49:26,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:26,865][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 1.3226381540298462, acc: 0.632478654384613)
[2024-11-13 07:49:26,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:27,163][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 2.093261957168579, acc: 0.4183673560619354)
[2024-11-13 07:49:27,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:27,484][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 1.9226106405258179, acc: 0.4779874086380005)
[2024-11-13 07:49:27,995][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=4.2108, train_epoch_loss=1.4376, epoch time 293.03554234839976s
[2024-11-13 07:49:27,995][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 07:49:27,995][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 07:49:27,996][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 07:49:27,996][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 07:49:27,996][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 07:49:28,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:28,813][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 1.191014051437378, acc: 0.5925925970077515)
[2024-11-13 07:49:28,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:29,069][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 1.2161643505096436, acc: 0.6399999856948853)
[2024-11-13 07:49:29,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:29,296][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 1.9921306371688843, acc: 0.45945945382118225)
[2024-11-13 07:49:29,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:29,635][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 1.630885124206543, acc: 0.5263158082962036)
[2024-11-13 07:49:29,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:30,002][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 1.66399347782135, acc: 0.5675675868988037)
[2024-11-13 07:49:30,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:30,278][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 1.3874759674072266, acc: 0.5357142686843872)
[2024-11-13 07:49:30,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:30,593][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 1.981041431427002, acc: 0.44897958636283875)
[2024-11-13 07:49:30,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:30,918][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 1.4743402004241943, acc: 0.5666666626930237)
[2024-11-13 07:49:30,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:31,246][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.37758922576904297, acc: 0.9090909361839294)
[2024-11-13 07:49:31,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:31,579][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.6778799891471863, acc: 0.807692289352417)
[2024-11-13 07:49:31,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:31,909][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.8387507200241089, acc: 0.7777777910232544)
[2024-11-13 07:49:31,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:32,248][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 1.4722378253936768, acc: 0.5897436141967773)
[2024-11-13 07:49:32,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:32,582][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 1.0157166719436646, acc: 0.7272727489471436)
[2024-11-13 07:49:32,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:32,952][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 1.5000042915344238, acc: 0.54347825050354)
[2024-11-13 07:49:33,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:33,221][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 1.7588225603103638, acc: 0.5490196347236633)
[2024-11-13 07:49:33,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:33,519][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 1.513102650642395, acc: 0.4897959232330322)
[2024-11-13 07:49:33,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:33,819][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.4561226963996887, acc: 0.8947368264198303)
[2024-11-13 07:49:33,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:34,147][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 1.229404330253601, acc: 0.5833333134651184)
[2024-11-13 07:49:34,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:34,458][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 1.1592320203781128, acc: 0.7222222089767456)
[2024-11-13 07:49:34,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:34,758][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.942492663860321, acc: 0.6842105388641357)
[2024-11-13 07:49:34,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:35,097][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 1.037447452545166, acc: 0.692307710647583)
[2024-11-13 07:49:35,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:35,428][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 1.0723803043365479, acc: 0.6896551847457886)
[2024-11-13 07:49:35,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:35,725][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.9337623715400696, acc: 0.7200000286102295)
[2024-11-13 07:49:35,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:36,032][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.839736819267273, acc: 0.7142857313156128)
[2024-11-13 07:49:36,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:36,362][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 1.089341163635254, acc: 0.75)
[2024-11-13 07:49:36,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:36,656][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 1.9517706632614136, acc: 0.4150943458080292)
[2024-11-13 07:49:36,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:36,996][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 1.914696216583252, acc: 0.465753436088562)
[2024-11-13 07:49:37,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:37,728][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 2.204221487045288, acc: 0.4545454680919647)
[2024-11-13 07:49:37,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:38,073][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 1.7334343194961548, acc: 0.5813953280448914)
[2024-11-13 07:49:38,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:38,446][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 1.8302568197250366, acc: 0.5060241222381592)
[2024-11-13 07:49:38,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:38,753][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 1.6854170560836792, acc: 0.5061728358268738)
[2024-11-13 07:49:38,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:39,028][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 1.212685227394104, acc: 0.6785714030265808)
[2024-11-13 07:49:39,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:39,363][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.8792309165000916, acc: 0.7407407164573669)
[2024-11-13 07:49:39,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:39,702][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.6549234390258789, acc: 0.8260869383811951)
[2024-11-13 07:49:39,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:40,057][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 1.9108806848526, acc: 0.462184876203537)
[2024-11-13 07:49:40,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:40,392][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 1.455916404724121, acc: 0.6229507923126221)
[2024-11-13 07:49:40,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:40,718][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 1.8322820663452148, acc: 0.460317462682724)
[2024-11-13 07:49:40,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:41,056][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 1.7109955549240112, acc: 0.4237288236618042)
[2024-11-13 07:49:41,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:41,378][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 1.2955597639083862, acc: 0.5977011322975159)
[2024-11-13 07:49:41,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:41,629][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.7392215728759766, acc: 0.7142857313156128)
[2024-11-13 07:49:41,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:41,889][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 1.180200457572937, acc: 0.6153846383094788)
[2024-11-13 07:49:41,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:42,261][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 2.038067579269409, acc: 0.47297295928001404)
[2024-11-13 07:49:42,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:42,592][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 1.8468921184539795, acc: 0.4923076927661896)
[2024-11-13 07:49:42,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:42,953][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 1.9830360412597656, acc: 0.5252525210380554)
[2024-11-13 07:49:43,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:43,352][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 1.5406945943832397, acc: 0.6185566782951355)
[2024-11-13 07:49:43,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:43,696][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 1.9419769048690796, acc: 0.4779411852359772)
[2024-11-13 07:49:43,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:44,016][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.7343951463699341, acc: 0.7692307829856873)
[2024-11-13 07:49:44,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:44,338][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.5377615690231323, acc: 0.8148148059844971)
[2024-11-13 07:49:44,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:44,654][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.8583427667617798, acc: 0.75)
[2024-11-13 07:49:44,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:44,977][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.5392420291900635, acc: 0.8888888955116272)
[2024-11-13 07:49:45,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:45,291][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 1.0820434093475342, acc: 0.6666666865348816)
[2024-11-13 07:49:45,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:45,571][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 1.1455711126327515, acc: 0.6666666865348816)
[2024-11-13 07:49:45,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:45,899][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 1.7837541103363037, acc: 0.5352112650871277)
[2024-11-13 07:49:45,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:46,279][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 2.072317361831665, acc: 0.47999998927116394)
[2024-11-13 07:49:46,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:46,618][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 1.0830714702606201, acc: 0.7027027010917664)
[2024-11-13 07:49:46,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:46,964][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.5134886503219604, acc: 0.8846153616905212)
[2024-11-13 07:49:47,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:48,275][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 1.722373604774475, acc: 0.5563139915466309)
[2024-11-13 07:49:48,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:49,101][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 2.3948793411254883, acc: 0.4248366057872772)
[2024-11-13 07:49:49,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:49,583][root][INFO] - Training Epoch: 5/10, step 58/574 completed (loss: 1.8522552251815796, acc: 0.5340909361839294)
[2024-11-13 07:49:49,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:50,038][root][INFO] - Training Epoch: 5/10, step 59/574 completed (loss: 1.9533251523971558, acc: 0.5)
[2024-11-13 07:49:50,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:50,482][root][INFO] - Training Epoch: 5/10, step 60/574 completed (loss: 2.1067123413085938, acc: 0.4420289993286133)
[2024-11-13 07:49:50,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:50,847][root][INFO] - Training Epoch: 5/10, step 61/574 completed (loss: 1.5907375812530518, acc: 0.574999988079071)
[2024-11-13 07:49:50,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:51,195][root][INFO] - Training Epoch: 5/10, step 62/574 completed (loss: 0.8777564764022827, acc: 0.7647058963775635)
[2024-11-13 07:49:51,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:51,537][root][INFO] - Training Epoch: 5/10, step 63/574 completed (loss: 1.288999080657959, acc: 0.6111111044883728)
[2024-11-13 07:49:51,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:51,883][root][INFO] - Training Epoch: 5/10, step 64/574 completed (loss: 1.2553678750991821, acc: 0.65625)
[2024-11-13 07:49:51,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:52,127][root][INFO] - Training Epoch: 5/10, step 65/574 completed (loss: 0.6564794182777405, acc: 0.7586206793785095)
[2024-11-13 07:49:52,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:52,490][root][INFO] - Training Epoch: 5/10, step 66/574 completed (loss: 1.8767856359481812, acc: 0.5535714030265808)
[2024-11-13 07:49:52,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:52,812][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 1.703502893447876, acc: 0.5)
[2024-11-13 07:49:52,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:53,154][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.46310749650001526, acc: 0.800000011920929)
[2024-11-13 07:49:53,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:53,536][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 1.0725696086883545, acc: 0.6111111044883728)
[2024-11-13 07:49:53,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:53,839][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 1.1703743934631348, acc: 0.6363636255264282)
[2024-11-13 07:49:53,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:54,165][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 1.9410842657089233, acc: 0.5220588445663452)
[2024-11-13 07:49:54,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:54,491][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 1.7341969013214111, acc: 0.4841269850730896)
[2024-11-13 07:49:54,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:54,828][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 1.977833867073059, acc: 0.44102564454078674)
[2024-11-13 07:49:54,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:55,176][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.6416434049606323, acc: 0.5510203838348389)
[2024-11-13 07:49:55,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:55,526][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 2.348785638809204, acc: 0.3507462739944458)
[2024-11-13 07:49:55,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:55,906][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 2.168916702270508, acc: 0.43795621395111084)
[2024-11-13 07:49:55,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:56,239][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.5022020936012268, acc: 0.8571428656578064)
[2024-11-13 07:49:56,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:56,578][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.4620020389556885, acc: 0.8333333134651184)
[2024-11-13 07:49:56,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:56,936][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 1.0301270484924316, acc: 0.7272727489471436)
[2024-11-13 07:49:57,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:57,293][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.5562193989753723, acc: 0.7307692170143127)
[2024-11-13 07:49:57,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:57,602][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 1.392785906791687, acc: 0.5961538553237915)
[2024-11-13 07:49:57,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:57,855][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 1.7999207973480225, acc: 0.5192307829856873)
[2024-11-13 07:49:57,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:58,100][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 1.0872423648834229, acc: 0.59375)
[2024-11-13 07:49:58,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:58,430][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 1.5732094049453735, acc: 0.5362318754196167)
[2024-11-13 07:49:58,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:58,770][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 1.2054237127304077, acc: 0.6800000071525574)
[2024-11-13 07:49:58,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:59,074][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 1.2330267429351807, acc: 0.6086956262588501)
[2024-11-13 07:49:59,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:59,438][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 1.6338545083999634, acc: 0.5199999809265137)
[2024-11-13 07:49:59,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:49:59,704][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 1.574421763420105, acc: 0.582524299621582)
[2024-11-13 07:49:59,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:00,426][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 1.8368810415267944, acc: 0.5145630836486816)
[2024-11-13 07:50:00,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:01,046][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 1.9193940162658691, acc: 0.45698925852775574)
[2024-11-13 07:50:01,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:01,639][root][INFO] - Training Epoch: 5/10, step 91/574 completed (loss: 1.7199032306671143, acc: 0.556034505367279)
[2024-11-13 07:50:01,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:02,202][root][INFO] - Training Epoch: 5/10, step 92/574 completed (loss: 1.3428758382797241, acc: 0.5789473652839661)
[2024-11-13 07:50:02,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:02,889][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 2.11885666847229, acc: 0.39603960514068604)
[2024-11-13 07:50:02,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:03,222][root][INFO] - Training Epoch: 5/10, step 94/574 completed (loss: 1.9051530361175537, acc: 0.4677419364452362)
[2024-11-13 07:50:03,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:03,559][root][INFO] - Training Epoch: 5/10, step 95/574 completed (loss: 1.8639274835586548, acc: 0.4637681245803833)
[2024-11-13 07:50:03,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:03,833][root][INFO] - Training Epoch: 5/10, step 96/574 completed (loss: 2.0169057846069336, acc: 0.3949579894542694)
[2024-11-13 07:50:03,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:04,187][root][INFO] - Training Epoch: 5/10, step 97/574 completed (loss: 2.159156084060669, acc: 0.36538460850715637)
[2024-11-13 07:50:04,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:04,497][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 2.0675065517425537, acc: 0.43795621395111084)
[2024-11-13 07:50:04,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:04,759][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 1.9768776893615723, acc: 0.4029850661754608)
[2024-11-13 07:50:04,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:05,135][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.7578858733177185, acc: 0.699999988079071)
[2024-11-13 07:50:05,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:05,481][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.7149778008460999, acc: 0.7727272510528564)
[2024-11-13 07:50:05,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:05,833][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.6775106191635132, acc: 0.782608687877655)
[2024-11-13 07:50:05,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:06,176][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 1.12440824508667, acc: 0.6363636255264282)
[2024-11-13 07:50:06,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:06,511][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 1.6491862535476685, acc: 0.517241358757019)
[2024-11-13 07:50:06,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:06,825][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 1.112056016921997, acc: 0.6744186282157898)
[2024-11-13 07:50:06,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:07,124][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 1.1532524824142456, acc: 0.5600000023841858)
[2024-11-13 07:50:07,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:07,463][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.42122599482536316, acc: 0.8235294222831726)
[2024-11-13 07:50:07,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:07,782][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.3503459692001343, acc: 0.8846153616905212)
[2024-11-13 07:50:07,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:08,135][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 0.9514625072479248, acc: 0.738095223903656)
[2024-11-13 07:50:08,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:08,545][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 1.463439702987671, acc: 0.6153846383094788)
[2024-11-13 07:50:08,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:08,951][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 1.4494075775146484, acc: 0.5964912176132202)
[2024-11-13 07:50:09,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:09,300][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 1.194403886795044, acc: 0.6666666865348816)
[2024-11-13 07:50:09,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:09,641][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 1.5023292303085327, acc: 0.5641025900840759)
[2024-11-13 07:50:09,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:10,011][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 1.246434211730957, acc: 0.6734693646430969)
[2024-11-13 07:50:10,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:10,397][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.5526153445243835, acc: 0.8636363744735718)
[2024-11-13 07:50:10,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:10,711][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 1.514315128326416, acc: 0.5714285969734192)
[2024-11-13 07:50:10,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:10,998][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 1.7278419733047485, acc: 0.5528455376625061)
[2024-11-13 07:50:11,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:11,323][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 1.2970761060714722, acc: 0.6129032373428345)
[2024-11-13 07:50:11,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:11,955][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.9567081928253174, acc: 0.4790874421596527)
[2024-11-13 07:50:12,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:12,272][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 1.4971776008605957, acc: 0.5866666436195374)
[2024-11-13 07:50:12,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:12,661][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 1.1662163734436035, acc: 0.6346153616905212)
[2024-11-13 07:50:12,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:12,986][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.5795661807060242, acc: 0.875)
[2024-11-13 07:50:13,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:13,255][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.8703761696815491, acc: 0.7368420958518982)
[2024-11-13 07:50:13,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:13,561][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 1.9098190069198608, acc: 0.47239264845848083)
[2024-11-13 07:50:13,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:13,926][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.5734180212020874, acc: 0.5763888955116272)
[2024-11-13 07:50:14,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:14,284][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 1.834171175956726, acc: 0.49166667461395264)
[2024-11-13 07:50:14,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:14,656][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 1.875334620475769, acc: 0.4702380895614624)
[2024-11-13 07:50:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:14,996][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 1.7601649761199951, acc: 0.5128205418586731)
[2024-11-13 07:50:15,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:15,357][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 1.6974785327911377, acc: 0.529411792755127)
[2024-11-13 07:50:15,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:15,674][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.7960984110832214, acc: 0.807692289352417)
[2024-11-13 07:50:15,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:16,024][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.49094340205192566, acc: 0.782608687877655)
[2024-11-13 07:50:16,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:16,385][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.9142597317695618, acc: 0.65625)
[2024-11-13 07:50:16,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:16,688][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 1.1933635473251343, acc: 0.739130437374115)
[2024-11-13 07:50:16,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:16,979][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 1.049306869506836, acc: 0.7142857313156128)
[2024-11-13 07:50:17,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:17,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:18,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:18,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:18,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:19,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:19,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:19,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:20,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:20,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:20,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:20,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:21,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:21,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:21,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:21,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:22,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:22,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:22,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:23,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:23,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:23,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:23,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:24,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:24,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:24,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:25,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:25,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:25,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:26,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:26,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:26,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:26,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:27,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:27,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:27,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:27,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:28,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:28,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:28,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:29,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:29,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:29,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:29,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:30,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:30,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:30,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:31,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:31,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:31,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:32,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:32,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:32,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:32,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:33,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:33,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:33,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:34,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:34,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:34,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:35,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:35,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:35,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:35,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:36,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:36,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:36,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:37,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:37,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:37,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:37,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:38,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:38,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:38,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:39,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:39,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:39,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:39,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:40,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:40,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:40,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:40,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:41,484][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.2695, device='cuda:0') eval_epoch_loss=tensor(1.8357, device='cuda:0') eval_epoch_acc=tensor(0.5382, device='cuda:0')
[2024-11-13 07:50:41,485][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:50:41,485][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:50:41,784][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_5_step_135_loss_1.8357003927230835/model.pt
[2024-11-13 07:50:41,787][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:50:41,788][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.538173496723175
[2024-11-13 07:50:41,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:42,173][root][INFO] - Training Epoch: 5/10, step 135/574 completed (loss: 0.6271304488182068, acc: 0.692307710647583)
[2024-11-13 07:50:42,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:42,487][root][INFO] - Training Epoch: 5/10, step 136/574 completed (loss: 1.4452550411224365, acc: 0.5476190447807312)
[2024-11-13 07:50:42,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:42,762][root][INFO] - Training Epoch: 5/10, step 137/574 completed (loss: 1.179541826248169, acc: 0.5333333611488342)
[2024-11-13 07:50:42,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:43,055][root][INFO] - Training Epoch: 5/10, step 138/574 completed (loss: 0.8545452356338501, acc: 0.695652186870575)
[2024-11-13 07:50:43,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:43,403][root][INFO] - Training Epoch: 5/10, step 139/574 completed (loss: 0.9980564117431641, acc: 0.761904776096344)
[2024-11-13 07:50:43,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:43,736][root][INFO] - Training Epoch: 5/10, step 140/574 completed (loss: 1.353522777557373, acc: 0.5769230723381042)
[2024-11-13 07:50:43,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:44,074][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 1.8166208267211914, acc: 0.5161290168762207)
[2024-11-13 07:50:44,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:44,444][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 1.6465046405792236, acc: 0.5135135054588318)
[2024-11-13 07:50:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:44,874][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 1.8289567232131958, acc: 0.4385964870452881)
[2024-11-13 07:50:44,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:45,206][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 1.5473685264587402, acc: 0.5970149040222168)
[2024-11-13 07:50:45,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:45,554][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 2.1590516567230225, acc: 0.3571428656578064)
[2024-11-13 07:50:45,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:45,916][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 1.9984869956970215, acc: 0.3510638177394867)
[2024-11-13 07:50:45,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:46,203][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 1.7479431629180908, acc: 0.5285714268684387)
[2024-11-13 07:50:46,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:46,538][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 1.514190912246704, acc: 0.4642857015132904)
[2024-11-13 07:50:46,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:46,866][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 1.290093183517456, acc: 0.6521739363670349)
[2024-11-13 07:50:46,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:47,214][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 1.4660931825637817, acc: 0.5517241358757019)
[2024-11-13 07:50:47,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:47,583][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 1.848403811454773, acc: 0.5869565010070801)
[2024-11-13 07:50:47,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:47,945][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 1.863144040107727, acc: 0.49152541160583496)
[2024-11-13 07:50:48,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:48,279][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 2.0396907329559326, acc: 0.4912280738353729)
[2024-11-13 07:50:48,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:48,615][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 1.9002357721328735, acc: 0.4864864945411682)
[2024-11-13 07:50:48,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:48,934][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 1.2434704303741455, acc: 0.6785714030265808)
[2024-11-13 07:50:48,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:49,276][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 1.131853461265564, acc: 0.8260869383811951)
[2024-11-13 07:50:49,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:49,550][root][INFO] - Training Epoch: 5/10, step 157/574 completed (loss: 0.9246582388877869, acc: 0.7368420958518982)
[2024-11-13 07:50:49,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:50,417][root][INFO] - Training Epoch: 5/10, step 158/574 completed (loss: 1.392321228981018, acc: 0.6486486196517944)
[2024-11-13 07:50:50,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:50,756][root][INFO] - Training Epoch: 5/10, step 159/574 completed (loss: 1.6236717700958252, acc: 0.5370370149612427)
[2024-11-13 07:50:50,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:51,125][root][INFO] - Training Epoch: 5/10, step 160/574 completed (loss: 1.30716872215271, acc: 0.6162790656089783)
[2024-11-13 07:50:51,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:51,580][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 1.2223985195159912, acc: 0.6352941393852234)
[2024-11-13 07:50:51,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:52,022][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 1.7539916038513184, acc: 0.5056179761886597)
[2024-11-13 07:50:52,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:52,340][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 1.14766263961792, acc: 0.7272727489471436)
[2024-11-13 07:50:52,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:52,645][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 1.0899549722671509, acc: 0.761904776096344)
[2024-11-13 07:50:52,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:52,988][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 1.2185016870498657, acc: 0.6206896305084229)
[2024-11-13 07:50:53,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:53,280][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 1.0951242446899414, acc: 0.6530612111091614)
[2024-11-13 07:50:53,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:53,602][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 1.2448105812072754, acc: 0.6399999856948853)
[2024-11-13 07:50:53,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:53,943][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 1.3611611127853394, acc: 0.5972222089767456)
[2024-11-13 07:50:54,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:54,276][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.7972077131271362, acc: 0.5392156839370728)
[2024-11-13 07:50:54,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:54,983][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 2.1220641136169434, acc: 0.4931506812572479)
[2024-11-13 07:50:55,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:55,241][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.6925783753395081, acc: 0.8333333134651184)
[2024-11-13 07:50:55,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:55,584][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.57857745885849, acc: 0.8148148059844971)
[2024-11-13 07:50:55,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:55,903][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.567313551902771, acc: 0.8571428656578064)
[2024-11-13 07:50:56,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:56,338][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.5508311986923218, acc: 0.5752212405204773)
[2024-11-13 07:50:56,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:56,634][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 1.3946021795272827, acc: 0.5797101259231567)
[2024-11-13 07:50:56,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:56,967][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 1.5062522888183594, acc: 0.6022727489471436)
[2024-11-13 07:50:57,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:57,610][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 2.123096227645874, acc: 0.442748099565506)
[2024-11-13 07:50:57,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:58,109][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 1.95606529712677, acc: 0.48148149251937866)
[2024-11-13 07:50:58,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:58,440][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 1.3828985691070557, acc: 0.6393442749977112)
[2024-11-13 07:50:58,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:58,748][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.6517211198806763, acc: 0.7916666865348816)
[2024-11-13 07:50:58,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:59,004][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 1.056317925453186, acc: 0.6399999856948853)
[2024-11-13 07:50:59,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:59,223][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.6160618662834167, acc: 0.7857142686843872)
[2024-11-13 07:50:59,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:59,488][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 1.7375218868255615, acc: 0.47560974955558777)
[2024-11-13 07:50:59,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:50:59,798][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 2.0420844554901123, acc: 0.46525681018829346)
[2024-11-13 07:50:59,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:00,149][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 2.1124629974365234, acc: 0.44668588042259216)
[2024-11-13 07:51:00,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:00,546][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 2.1965959072113037, acc: 0.44062501192092896)
[2024-11-13 07:51:00,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:00,998][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 2.0810458660125732, acc: 0.4333958625793457)
[2024-11-13 07:51:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:01,385][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 1.9339560270309448, acc: 0.43772241473197937)
[2024-11-13 07:51:01,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:01,722][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 1.1161402463912964, acc: 0.6800000071525574)
[2024-11-13 07:51:01,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:02,149][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 2.0183510780334473, acc: 0.4651162922382355)
[2024-11-13 07:51:02,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:02,722][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 1.780725359916687, acc: 0.523809552192688)
[2024-11-13 07:51:02,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:03,352][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 1.8384406566619873, acc: 0.469696968793869)
[2024-11-13 07:51:03,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:03,895][root][INFO] - Training Epoch: 5/10, step 193/574 completed (loss: 1.5861098766326904, acc: 0.6000000238418579)
[2024-11-13 07:51:04,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:04,626][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 1.5544745922088623, acc: 0.5740740895271301)
[2024-11-13 07:51:04,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:05,276][root][INFO] - Training Epoch: 5/10, step 195/574 completed (loss: 1.2464183568954468, acc: 0.6774193644523621)
[2024-11-13 07:51:05,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:05,527][root][INFO] - Training Epoch: 5/10, step 196/574 completed (loss: 0.5960005521774292, acc: 0.8928571343421936)
[2024-11-13 07:51:05,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:05,859][root][INFO] - Training Epoch: 5/10, step 197/574 completed (loss: 0.8656572103500366, acc: 0.800000011920929)
[2024-11-13 07:51:05,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:06,225][root][INFO] - Training Epoch: 5/10, step 198/574 completed (loss: 1.3938648700714111, acc: 0.6176470518112183)
[2024-11-13 07:51:06,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:06,527][root][INFO] - Training Epoch: 5/10, step 199/574 completed (loss: 1.717543601989746, acc: 0.5220588445663452)
[2024-11-13 07:51:06,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:06,909][root][INFO] - Training Epoch: 5/10, step 200/574 completed (loss: 1.8325637578964233, acc: 0.5169491767883301)
[2024-11-13 07:51:06,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:07,242][root][INFO] - Training Epoch: 5/10, step 201/574 completed (loss: 1.957410216331482, acc: 0.48507463932037354)
[2024-11-13 07:51:07,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:07,569][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 1.9011179208755493, acc: 0.4757281541824341)
[2024-11-13 07:51:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:07,838][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 1.5172648429870605, acc: 0.5555555820465088)
[2024-11-13 07:51:07,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:08,146][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 1.573243498802185, acc: 0.5714285969734192)
[2024-11-13 07:51:08,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:08,452][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 1.9192698001861572, acc: 0.48430493474006653)
[2024-11-13 07:51:08,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:08,807][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 1.9731266498565674, acc: 0.4724409580230713)
[2024-11-13 07:51:08,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:09,155][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 1.8428484201431274, acc: 0.49568966031074524)
[2024-11-13 07:51:09,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:09,516][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 1.8409264087677002, acc: 0.5)
[2024-11-13 07:51:09,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:09,857][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 2.020751953125, acc: 0.443579763174057)
[2024-11-13 07:51:09,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:10,168][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 1.957371711730957, acc: 0.510869562625885)
[2024-11-13 07:51:10,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:10,445][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.8577961921691895, acc: 0.782608687877655)
[2024-11-13 07:51:10,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:10,735][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 1.0012773275375366, acc: 0.6785714030265808)
[2024-11-13 07:51:10,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:11,117][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.9555992484092712, acc: 0.6808510422706604)
[2024-11-13 07:51:11,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:11,620][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 1.5336500406265259, acc: 0.5307692289352417)
[2024-11-13 07:51:11,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:11,935][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 1.2682002782821655, acc: 0.6756756901741028)
[2024-11-13 07:51:12,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:12,292][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 1.2393492460250854, acc: 0.6511628031730652)
[2024-11-13 07:51:12,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:12,711][root][INFO] - Training Epoch: 5/10, step 217/574 completed (loss: 1.397415280342102, acc: 0.6216216087341309)
[2024-11-13 07:51:12,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:13,100][root][INFO] - Training Epoch: 5/10, step 218/574 completed (loss: 1.3023039102554321, acc: 0.6555555462837219)
[2024-11-13 07:51:13,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:13,439][root][INFO] - Training Epoch: 5/10, step 219/574 completed (loss: 0.7259416580200195, acc: 0.7878788113594055)
[2024-11-13 07:51:13,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:13,764][root][INFO] - Training Epoch: 5/10, step 220/574 completed (loss: 0.4313022792339325, acc: 0.8148148059844971)
[2024-11-13 07:51:13,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:14,071][root][INFO] - Training Epoch: 5/10, step 221/574 completed (loss: 0.6232826113700867, acc: 0.800000011920929)
[2024-11-13 07:51:14,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:14,419][root][INFO] - Training Epoch: 5/10, step 222/574 completed (loss: 1.3844544887542725, acc: 0.557692289352417)
[2024-11-13 07:51:14,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:14,971][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 1.4329888820648193, acc: 0.5760869383811951)
[2024-11-13 07:51:15,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:15,395][root][INFO] - Training Epoch: 5/10, step 224/574 completed (loss: 1.7033889293670654, acc: 0.5284090638160706)
[2024-11-13 07:51:15,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:15,749][root][INFO] - Training Epoch: 5/10, step 225/574 completed (loss: 1.854891061782837, acc: 0.4680851101875305)
[2024-11-13 07:51:15,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:16,071][root][INFO] - Training Epoch: 5/10, step 226/574 completed (loss: 1.1397608518600464, acc: 0.6792452931404114)
[2024-11-13 07:51:16,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:16,414][root][INFO] - Training Epoch: 5/10, step 227/574 completed (loss: 1.3448574542999268, acc: 0.6499999761581421)
[2024-11-13 07:51:16,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:16,724][root][INFO] - Training Epoch: 5/10, step 228/574 completed (loss: 0.64115309715271, acc: 0.7906976938247681)
[2024-11-13 07:51:16,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:17,047][root][INFO] - Training Epoch: 5/10, step 229/574 completed (loss: 0.6941272616386414, acc: 0.7666666507720947)
[2024-11-13 07:51:17,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:17,436][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 1.9486786127090454, acc: 0.5052631497383118)
[2024-11-13 07:51:17,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:17,763][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 1.4666337966918945, acc: 0.5888888835906982)
[2024-11-13 07:51:17,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:18,165][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 1.2159423828125, acc: 0.6499999761581421)
[2024-11-13 07:51:18,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:18,570][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 1.5883240699768066, acc: 0.6009174585342407)
[2024-11-13 07:51:18,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:18,942][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 1.336245059967041, acc: 0.6153846383094788)
[2024-11-13 07:51:18,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:19,247][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 1.1064298152923584, acc: 0.6842105388641357)
[2024-11-13 07:51:19,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:19,550][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.6810365319252014, acc: 0.7916666865348816)
[2024-11-13 07:51:19,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:19,877][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 1.455895185470581, acc: 0.5454545617103577)
[2024-11-13 07:51:19,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:20,185][root][INFO] - Training Epoch: 5/10, step 238/574 completed (loss: 1.3026248216629028, acc: 0.5185185074806213)
[2024-11-13 07:51:20,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:20,507][root][INFO] - Training Epoch: 5/10, step 239/574 completed (loss: 0.8327227234840393, acc: 0.7428571581840515)
[2024-11-13 07:51:20,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:20,883][root][INFO] - Training Epoch: 5/10, step 240/574 completed (loss: 1.0391007661819458, acc: 0.6136363744735718)
[2024-11-13 07:51:20,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:21,185][root][INFO] - Training Epoch: 5/10, step 241/574 completed (loss: 1.1437318325042725, acc: 0.6818181872367859)
[2024-11-13 07:51:21,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:21,624][root][INFO] - Training Epoch: 5/10, step 242/574 completed (loss: 1.6811630725860596, acc: 0.5322580933570862)
[2024-11-13 07:51:21,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:22,031][root][INFO] - Training Epoch: 5/10, step 243/574 completed (loss: 1.2260171175003052, acc: 0.6818181872367859)
[2024-11-13 07:51:22,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:22,383][root][INFO] - Training Epoch: 5/10, step 244/574 completed (loss: 0.5521863102912903, acc: 0.8571428656578064)
[2024-11-13 07:51:22,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:22,733][root][INFO] - Training Epoch: 5/10, step 245/574 completed (loss: 1.106784462928772, acc: 0.7307692170143127)
[2024-11-13 07:51:22,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:23,060][root][INFO] - Training Epoch: 5/10, step 246/574 completed (loss: 1.166398286819458, acc: 0.7419354915618896)
[2024-11-13 07:51:23,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:23,387][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.8572245836257935, acc: 0.6499999761581421)
[2024-11-13 07:51:23,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:23,709][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 0.9076688885688782, acc: 0.7027027010917664)
[2024-11-13 07:51:23,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:23,979][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 1.1384464502334595, acc: 0.6216216087341309)
[2024-11-13 07:51:24,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:24,235][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 0.9779401421546936, acc: 0.6486486196517944)
[2024-11-13 07:51:24,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:24,545][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 1.620876669883728, acc: 0.5147058963775635)
[2024-11-13 07:51:24,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:24,841][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.7515785694122314, acc: 0.7317073345184326)
[2024-11-13 07:51:24,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:25,108][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.3207920491695404, acc: 0.8799999952316284)
[2024-11-13 07:51:25,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:25,370][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.4336109161376953, acc: 0.800000011920929)
[2024-11-13 07:51:25,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:25,655][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.4485914409160614, acc: 0.8387096524238586)
[2024-11-13 07:51:25,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:25,975][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 1.4075400829315186, acc: 0.5789473652839661)
[2024-11-13 07:51:26,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:26,268][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 1.3609578609466553, acc: 0.6142857074737549)
[2024-11-13 07:51:26,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:26,582][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 1.1570991277694702, acc: 0.6315789222717285)
[2024-11-13 07:51:26,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:27,042][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 1.52634859085083, acc: 0.5283018946647644)
[2024-11-13 07:51:27,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:27,497][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 1.6023516654968262, acc: 0.550000011920929)
[2024-11-13 07:51:27,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:27,777][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.9701526165008545, acc: 0.7222222089767456)
[2024-11-13 07:51:27,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:28,076][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 1.2830859422683716, acc: 0.6774193644523621)
[2024-11-13 07:51:28,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:28,385][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 2.302455186843872, acc: 0.4266666769981384)
[2024-11-13 07:51:28,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:28,680][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 1.7232385873794556, acc: 0.5208333134651184)
[2024-11-13 07:51:28,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:29,266][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 2.3078978061676025, acc: 0.3919999897480011)
[2024-11-13 07:51:29,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:29,613][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 1.9870258569717407, acc: 0.449438214302063)
[2024-11-13 07:51:29,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:29,938][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 1.9204556941986084, acc: 0.5135135054588318)
[2024-11-13 07:51:30,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:30,310][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 1.3539631366729736, acc: 0.6206896305084229)
[2024-11-13 07:51:30,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:30,593][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.7555336356163025, acc: 0.8181818127632141)
[2024-11-13 07:51:30,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:30,949][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.8488706946372986, acc: 0.7272727489471436)
[2024-11-13 07:51:31,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:31,243][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.6698474884033203, acc: 0.8125)
[2024-11-13 07:51:31,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:31,525][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.9297693967819214, acc: 0.7333333492279053)
[2024-11-13 07:51:31,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:31,884][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 1.3755323886871338, acc: 0.6333333253860474)
[2024-11-13 07:51:31,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:32,238][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.954043447971344, acc: 0.78125)
[2024-11-13 07:51:32,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:32,562][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.7453301548957825, acc: 0.7666666507720947)
[2024-11-13 07:51:32,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:32,878][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 1.0960866212844849, acc: 0.7241379022598267)
[2024-11-13 07:51:32,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:33,153][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.9978123307228088, acc: 0.7200000286102295)
[2024-11-13 07:51:33,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:34,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:34,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:34,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:35,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:35,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:35,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:36,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:36,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:36,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:36,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:37,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:37,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:37,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:37,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:38,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:38,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:38,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:38,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:39,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:39,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:39,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:40,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:40,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:40,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:40,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:41,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:41,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:41,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:42,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:42,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:42,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:43,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:43,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:43,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:43,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:44,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:44,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:44,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:44,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:45,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:45,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:45,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:45,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:46,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:46,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:46,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:47,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:47,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:47,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:47,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:48,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:48,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:48,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:49,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:49,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:49,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:49,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:49,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:50,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:50,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:50,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:51,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:51,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:51,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:51,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:52,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:52,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:52,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:53,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:53,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:53,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:53,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:54,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:54,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:54,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:55,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:55,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:55,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:55,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:56,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:56,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:56,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:56,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:57,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:57,873][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.6299, device='cuda:0') eval_epoch_loss=tensor(1.8916, device='cuda:0') eval_epoch_acc=tensor(0.5349, device='cuda:0')
[2024-11-13 07:51:57,874][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:51:57,874][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:51:58,204][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_5_step_278_loss_1.8915884494781494/model.pt
[2024-11-13 07:51:58,207][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:51:58,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:58,597][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 1.5344300270080566, acc: 0.5106382966041565)
[2024-11-13 07:51:58,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:58,920][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 1.4664368629455566, acc: 0.6041666865348816)
[2024-11-13 07:51:59,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:59,256][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 1.2993639707565308, acc: 0.7045454382896423)
[2024-11-13 07:51:59,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:59,594][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 1.8502980470657349, acc: 0.4939759075641632)
[2024-11-13 07:51:59,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:51:59,913][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 1.7272530794143677, acc: 0.5092592835426331)
[2024-11-13 07:51:59,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:00,182][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 1.4786087274551392, acc: 0.5)
[2024-11-13 07:52:00,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:00,399][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 1.3188689947128296, acc: 0.5588235259056091)
[2024-11-13 07:52:00,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:00,672][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 0.9923778772354126, acc: 0.675000011920929)
[2024-11-13 07:52:00,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:00,975][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 1.8547518253326416, acc: 0.46875)
[2024-11-13 07:52:01,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:01,316][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 1.9009658098220825, acc: 0.4399999976158142)
[2024-11-13 07:52:01,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:01,710][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 1.4373196363449097, acc: 0.5714285969734192)
[2024-11-13 07:52:01,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:02,019][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 2.125765562057495, acc: 0.4658385217189789)
[2024-11-13 07:52:02,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:02,376][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 2.1423323154449463, acc: 0.3865979313850403)
[2024-11-13 07:52:02,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:02,752][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.6405357718467712, acc: 0.7727272510528564)
[2024-11-13 07:52:02,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:03,063][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 1.4293028116226196, acc: 0.5714285969734192)
[2024-11-13 07:52:03,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:03,380][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 1.0995714664459229, acc: 0.6551724076271057)
[2024-11-13 07:52:03,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:03,773][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 1.0804898738861084, acc: 0.6727272868156433)
[2024-11-13 07:52:03,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:04,209][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.6570079326629639, acc: 0.5567010045051575)
[2024-11-13 07:52:04,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:04,494][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 1.5577620267868042, acc: 0.568965494632721)
[2024-11-13 07:52:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:04,865][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 1.0904465913772583, acc: 0.6666666865348816)
[2024-11-13 07:52:04,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:05,186][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 1.3465220928192139, acc: 0.5526315569877625)
[2024-11-13 07:52:05,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:05,472][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 0.852419912815094, acc: 0.7857142686843872)
[2024-11-13 07:52:05,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:05,814][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 1.0290513038635254, acc: 0.65625)
[2024-11-13 07:52:05,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:06,161][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 1.1025201082229614, acc: 0.698113203048706)
[2024-11-13 07:52:06,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:06,527][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.6514865159988403, acc: 0.8301886916160583)
[2024-11-13 07:52:06,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:06,854][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.7866976261138916, acc: 0.8529411554336548)
[2024-11-13 07:52:06,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:07,184][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 0.9687895774841309, acc: 0.75)
[2024-11-13 07:52:07,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:07,490][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 1.3259220123291016, acc: 0.6065573692321777)
[2024-11-13 07:52:07,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:07,820][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.5132133364677429, acc: 0.8333333134651184)
[2024-11-13 07:52:07,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:08,120][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.40949344635009766, acc: 0.8947368264198303)
[2024-11-13 07:52:08,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:08,481][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 1.4663952589035034, acc: 0.6376811861991882)
[2024-11-13 07:52:08,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:08,857][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 1.4517226219177246, acc: 0.6388888955116272)
[2024-11-13 07:52:08,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:09,147][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 1.2143206596374512, acc: 0.6144578456878662)
[2024-11-13 07:52:09,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:09,451][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 1.7076146602630615, acc: 0.5384615659713745)
[2024-11-13 07:52:09,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:09,763][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 1.7382210493087769, acc: 0.5510203838348389)
[2024-11-13 07:52:09,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:10,042][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.22588686645030975, acc: 0.9583333134651184)
[2024-11-13 07:52:10,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:10,356][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.7010307312011719, acc: 0.7916666865348816)
[2024-11-13 07:52:10,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:10,657][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.6224913001060486, acc: 0.8064516186714172)
[2024-11-13 07:52:10,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:10,940][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 0.5852571725845337, acc: 0.8387096524238586)
[2024-11-13 07:52:11,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:11,255][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 1.1126515865325928, acc: 0.6567164063453674)
[2024-11-13 07:52:11,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:11,565][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 1.2358965873718262, acc: 0.6538461446762085)
[2024-11-13 07:52:11,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:11,890][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 0.9720889329910278, acc: 0.7333333492279053)
[2024-11-13 07:52:11,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:12,198][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 1.191051721572876, acc: 0.6451612710952759)
[2024-11-13 07:52:12,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:12,487][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.7637861371040344, acc: 0.7799999713897705)
[2024-11-13 07:52:12,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:12,832][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 1.2885323762893677, acc: 0.5925925970077515)
[2024-11-13 07:52:12,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:13,134][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 1.5056108236312866, acc: 0.6000000238418579)
[2024-11-13 07:52:13,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:13,421][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 1.40077543258667, acc: 0.5128205418586731)
[2024-11-13 07:52:13,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:13,711][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 1.7325810194015503, acc: 0.5609756112098694)
[2024-11-13 07:52:13,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:14,048][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 1.4110616445541382, acc: 0.6315789222717285)
[2024-11-13 07:52:14,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:14,396][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.5777665972709656, acc: 0.8947368264198303)
[2024-11-13 07:52:14,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:14,714][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.5197398066520691, acc: 0.8214285969734192)
[2024-11-13 07:52:14,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:15,006][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 1.119201421737671, acc: 0.6666666865348816)
[2024-11-13 07:52:15,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:15,349][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.8177438378334045, acc: 0.8125)
[2024-11-13 07:52:15,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:15,735][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 1.3651800155639648, acc: 0.6612903475761414)
[2024-11-13 07:52:15,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:16,096][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 1.290057897567749, acc: 0.5964912176132202)
[2024-11-13 07:52:16,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:16,423][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 1.6335757970809937, acc: 0.46875)
[2024-11-13 07:52:16,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:16,740][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.8701237440109253, acc: 0.699999988079071)
[2024-11-13 07:52:16,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:17,021][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 1.2049707174301147, acc: 0.6842105388641357)
[2024-11-13 07:52:17,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:17,382][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 1.866187572479248, acc: 0.4399999976158142)
[2024-11-13 07:52:17,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:17,750][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 2.2194466590881348, acc: 0.4252873659133911)
[2024-11-13 07:52:17,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:18,109][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 2.2432384490966797, acc: 0.41489362716674805)
[2024-11-13 07:52:18,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:18,428][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 2.2100439071655273, acc: 0.40963855385780334)
[2024-11-13 07:52:18,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:18,768][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 0.7059203386306763, acc: 0.782608687877655)
[2024-11-13 07:52:18,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:19,080][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 1.4106571674346924, acc: 0.5128205418586731)
[2024-11-13 07:52:19,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:19,402][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 2.1012191772460938, acc: 0.3855421543121338)
[2024-11-13 07:52:19,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:19,733][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 1.459979772567749, acc: 0.6415094137191772)
[2024-11-13 07:52:19,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:20,084][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 1.5752278566360474, acc: 0.5822784900665283)
[2024-11-13 07:52:20,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:20,414][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 1.367854118347168, acc: 0.5686274766921997)
[2024-11-13 07:52:20,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:20,760][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 2.0685477256774902, acc: 0.46268656849861145)
[2024-11-13 07:52:20,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:21,088][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.6179646253585815, acc: 0.8500000238418579)
[2024-11-13 07:52:21,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:21,448][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 1.0061049461364746, acc: 0.6800000071525574)
[2024-11-13 07:52:21,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:21,782][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 1.193950891494751, acc: 0.6944444179534912)
[2024-11-13 07:52:21,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:22,162][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 1.4912123680114746, acc: 0.5581395626068115)
[2024-11-13 07:52:22,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:22,530][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 1.1782450675964355, acc: 0.6153846383094788)
[2024-11-13 07:52:22,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:22,870][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 1.458276391029358, acc: 0.6000000238418579)
[2024-11-13 07:52:22,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:23,168][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.5540224313735962, acc: 0.782608687877655)
[2024-11-13 07:52:23,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:23,527][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.9921777248382568, acc: 0.7692307829856873)
[2024-11-13 07:52:23,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:23,867][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 2.145822286605835, acc: 0.4285714328289032)
[2024-11-13 07:52:23,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:24,269][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 1.7832708358764648, acc: 0.5130434632301331)
[2024-11-13 07:52:24,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:24,603][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 1.7047301530838013, acc: 0.554347813129425)
[2024-11-13 07:52:24,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:24,949][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 1.4964497089385986, acc: 0.5714285969734192)
[2024-11-13 07:52:25,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:25,271][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.22925256192684174, acc: 0.9583333134651184)
[2024-11-13 07:52:25,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:25,609][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.5881777405738831, acc: 0.8846153616905212)
[2024-11-13 07:52:25,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:25,981][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 1.144775629043579, acc: 0.6585366129875183)
[2024-11-13 07:52:26,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:26,359][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 1.118122935295105, acc: 0.6666666865348816)
[2024-11-13 07:52:26,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:26,703][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 1.5850785970687866, acc: 0.5657894611358643)
[2024-11-13 07:52:26,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:27,032][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 1.4191519021987915, acc: 0.5609756112098694)
[2024-11-13 07:52:27,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:27,359][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 1.1927547454833984, acc: 0.5757575631141663)
[2024-11-13 07:52:27,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:27,667][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.483805775642395, acc: 0.8333333134651184)
[2024-11-13 07:52:27,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:28,007][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.33094948530197144, acc: 0.9130434989929199)
[2024-11-13 07:52:28,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:28,423][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.593560516834259, acc: 0.8571428656578064)
[2024-11-13 07:52:28,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:28,755][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.8779627680778503, acc: 0.6875)
[2024-11-13 07:52:28,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:29,234][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 1.6381081342697144, acc: 0.539393961429596)
[2024-11-13 07:52:29,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:29,830][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 1.2713005542755127, acc: 0.698113203048706)
[2024-11-13 07:52:29,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:30,139][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 1.3889961242675781, acc: 0.6333333253860474)
[2024-11-13 07:52:30,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:30,449][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 1.3206250667572021, acc: 0.6428571343421936)
[2024-11-13 07:52:30,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:30,749][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.7910545468330383, acc: 0.7714285850524902)
[2024-11-13 07:52:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:31,007][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.4506334960460663, acc: 0.8399999737739563)
[2024-11-13 07:52:31,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:31,362][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.5155177116394043, acc: 0.8260869383811951)
[2024-11-13 07:52:31,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:31,660][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 1.3647375106811523, acc: 0.5833333134651184)
[2024-11-13 07:52:31,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:31,955][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 1.3695734739303589, acc: 0.6631578803062439)
[2024-11-13 07:52:32,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:32,410][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 1.5522795915603638, acc: 0.6107784509658813)
[2024-11-13 07:52:32,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:32,758][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 1.2518845796585083, acc: 0.6315789222717285)
[2024-11-13 07:52:32,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:33,500][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 1.4789507389068604, acc: 0.5935828685760498)
[2024-11-13 07:52:33,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:33,952][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 1.1192206144332886, acc: 0.7027027010917664)
[2024-11-13 07:52:34,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:34,277][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.6533414125442505, acc: 0.8214285969734192)
[2024-11-13 07:52:34,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:34,595][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.5178683996200562, acc: 0.8571428656578064)
[2024-11-13 07:52:34,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:34,851][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 0.6992775201797485, acc: 0.8125)
[2024-11-13 07:52:34,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:35,159][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.7006465196609497, acc: 0.8333333134651184)
[2024-11-13 07:52:35,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:35,488][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.8965961337089539, acc: 0.7894737124443054)
[2024-11-13 07:52:35,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:35,822][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.4188013970851898, acc: 0.8181818127632141)
[2024-11-13 07:52:35,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:36,174][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.8735741376876831, acc: 0.6499999761581421)
[2024-11-13 07:52:36,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:36,550][root][INFO] - Training Epoch: 5/10, step 390/574 completed (loss: 0.5316634178161621, acc: 0.8095238208770752)
[2024-11-13 07:52:36,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:36,878][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 1.7537941932678223, acc: 0.42592594027519226)
[2024-11-13 07:52:36,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:37,213][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 2.0927348136901855, acc: 0.48543688654899597)
[2024-11-13 07:52:37,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:37,678][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 1.7905958890914917, acc: 0.5441176295280457)
[2024-11-13 07:52:37,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:38,049][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 1.9420719146728516, acc: 0.46666666865348816)
[2024-11-13 07:52:38,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:38,383][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 2.069706439971924, acc: 0.4583333432674408)
[2024-11-13 07:52:38,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:38,758][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 1.214221715927124, acc: 0.6511628031730652)
[2024-11-13 07:52:38,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:39,069][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.9083390831947327, acc: 0.7083333134651184)
[2024-11-13 07:52:39,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:39,373][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 1.056527018547058, acc: 0.6744186282157898)
[2024-11-13 07:52:39,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:39,646][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 0.9200853109359741, acc: 0.7599999904632568)
[2024-11-13 07:52:39,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:40,090][root][INFO] - Training Epoch: 5/10, step 400/574 completed (loss: 1.63960599899292, acc: 0.5882353186607361)
[2024-11-13 07:52:40,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:40,441][root][INFO] - Training Epoch: 5/10, step 401/574 completed (loss: 1.5772426128387451, acc: 0.5333333611488342)
[2024-11-13 07:52:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:40,783][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 0.8837190866470337, acc: 0.6969696879386902)
[2024-11-13 07:52:40,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:41,093][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 1.0237464904785156, acc: 0.7575757503509521)
[2024-11-13 07:52:41,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:41,383][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.6958606243133545, acc: 0.8064516186714172)
[2024-11-13 07:52:41,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:41,704][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 1.0369864702224731, acc: 0.6666666865348816)
[2024-11-13 07:52:41,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:42,028][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.6994906067848206, acc: 0.7599999904632568)
[2024-11-13 07:52:42,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:42,383][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.7011722326278687, acc: 0.7777777910232544)
[2024-11-13 07:52:42,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:42,733][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.6455613374710083, acc: 0.8888888955116272)
[2024-11-13 07:52:42,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:42,999][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.5711896419525146, acc: 0.8461538553237915)
[2024-11-13 07:52:43,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:43,288][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 1.1708307266235352, acc: 0.6379310488700867)
[2024-11-13 07:52:43,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:43,532][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.5808314085006714, acc: 0.8214285969734192)
[2024-11-13 07:52:43,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:43,873][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 1.0727512836456299, acc: 0.699999988079071)
[2024-11-13 07:52:43,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:44,227][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.8632426261901855, acc: 0.8181818127632141)
[2024-11-13 07:52:44,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:44,518][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.6784975528717041, acc: 0.7727272510528564)
[2024-11-13 07:52:44,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:44,860][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 1.6271158456802368, acc: 0.5490196347236633)
[2024-11-13 07:52:44,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:45,201][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 1.655698299407959, acc: 0.692307710647583)
[2024-11-13 07:52:45,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:45,528][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 1.60501229763031, acc: 0.6111111044883728)
[2024-11-13 07:52:45,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:45,847][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 1.1132842302322388, acc: 0.699999988079071)
[2024-11-13 07:52:45,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:46,153][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 1.1527544260025024, acc: 0.699999988079071)
[2024-11-13 07:52:46,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:46,492][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.5296605229377747, acc: 0.8571428656578064)
[2024-11-13 07:52:47,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:47,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:47,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:47,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:48,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:48,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:48,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:49,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:49,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:49,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:49,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:50,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:50,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:50,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:51,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:51,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:51,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:51,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:52,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:52,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:52,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:52,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:53,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:53,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:53,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:53,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:54,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:54,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:54,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:54,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:54,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:55,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:55,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:55,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:55,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:56,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:56,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:56,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:56,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:57,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:57,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:57,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:58,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:58,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:58,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:58,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:59,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:59,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:59,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:52:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:00,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:00,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:00,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:00,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:01,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:01,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:01,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:01,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:02,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:02,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:02,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:03,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:03,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:03,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:03,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:04,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:04,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:04,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:05,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:05,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:05,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:05,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:05,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:06,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:06,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:06,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:07,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:07,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:07,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:07,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:08,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:08,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:08,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:08,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:09,462][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.0771, device='cuda:0') eval_epoch_loss=tensor(2.2058, device='cuda:0') eval_epoch_acc=tensor(0.5018, device='cuda:0')
[2024-11-13 07:53:09,463][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:53:09,463][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:53:09,797][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_5_step_421_loss_2.205759286880493/model.pt
[2024-11-13 07:53:09,807][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:53:09,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:10,196][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.7637208700180054, acc: 0.7666666507720947)
[2024-11-13 07:53:10,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:10,499][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.6002055406570435, acc: 0.84375)
[2024-11-13 07:53:10,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:10,838][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.6674026846885681, acc: 0.8333333134651184)
[2024-11-13 07:53:10,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:11,157][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.7108367085456848, acc: 0.7407407164573669)
[2024-11-13 07:53:11,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:11,495][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 1.0032942295074463, acc: 0.7575757503509521)
[2024-11-13 07:53:11,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:11,803][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 1.369604468345642, acc: 0.695652186870575)
[2024-11-13 07:53:11,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:12,118][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 1.1496747732162476, acc: 0.7837837934494019)
[2024-11-13 07:53:12,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:12,398][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.9516803622245789, acc: 0.7407407164573669)
[2024-11-13 07:53:12,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:12,735][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.8405598998069763, acc: 0.782608687877655)
[2024-11-13 07:53:12,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:13,077][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.9727569222450256, acc: 0.7407407164573669)
[2024-11-13 07:53:13,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:13,423][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.47251877188682556, acc: 0.8518518805503845)
[2024-11-13 07:53:13,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:13,738][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.7248675227165222, acc: 0.739130437374115)
[2024-11-13 07:53:13,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:14,059][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 1.0456546545028687, acc: 0.6944444179534912)
[2024-11-13 07:53:14,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:14,372][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.7264404296875, acc: 0.8399999737739563)
[2024-11-13 07:53:14,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:14,682][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.9944872856140137, acc: 0.7272727489471436)
[2024-11-13 07:53:14,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:14,994][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 2.4189186096191406, acc: 0.5)
[2024-11-13 07:53:15,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:15,357][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 1.0957144498825073, acc: 0.75)
[2024-11-13 07:53:15,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:15,640][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.7189768552780151, acc: 0.7142857313156128)
[2024-11-13 07:53:15,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:15,975][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 1.536507487297058, acc: 0.6153846383094788)
[2024-11-13 07:53:16,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:16,401][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 1.7328346967697144, acc: 0.5454545617103577)
[2024-11-13 07:53:16,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:16,916][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 2.0575461387634277, acc: 0.41600000858306885)
[2024-11-13 07:53:16,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:17,306][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 2.0468549728393555, acc: 0.4516128897666931)
[2024-11-13 07:53:17,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:17,813][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 1.9853699207305908, acc: 0.43283581733703613)
[2024-11-13 07:53:17,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:18,117][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 1.440841555595398, acc: 0.6226415038108826)
[2024-11-13 07:53:18,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:18,508][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 1.1050734519958496, acc: 0.6363636255264282)
[2024-11-13 07:53:18,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:18,836][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 1.0436221361160278, acc: 0.695652186870575)
[2024-11-13 07:53:18,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:19,120][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 1.0414320230484009, acc: 0.7692307829856873)
[2024-11-13 07:53:19,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:19,458][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.9542525410652161, acc: 0.7142857313156128)
[2024-11-13 07:53:19,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:19,791][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 1.4650167226791382, acc: 0.641791045665741)
[2024-11-13 07:53:19,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:20,100][root][INFO] - Training Epoch: 5/10, step 450/574 completed (loss: 1.447043538093567, acc: 0.625)
[2024-11-13 07:53:20,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:20,437][root][INFO] - Training Epoch: 5/10, step 451/574 completed (loss: 1.3964539766311646, acc: 0.5869565010070801)
[2024-11-13 07:53:20,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:20,745][root][INFO] - Training Epoch: 5/10, step 452/574 completed (loss: 1.5589239597320557, acc: 0.5641025900840759)
[2024-11-13 07:53:20,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:21,047][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 1.7197321653366089, acc: 0.5131579041481018)
[2024-11-13 07:53:21,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:21,303][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 1.4224096536636353, acc: 0.5918367505073547)
[2024-11-13 07:53:21,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:21,596][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 1.081098198890686, acc: 0.6969696879386902)
[2024-11-13 07:53:21,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:21,889][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 1.9110275506973267, acc: 0.49484536051750183)
[2024-11-13 07:53:21,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:22,219][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 1.3256373405456543, acc: 0.6142857074737549)
[2024-11-13 07:53:22,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:22,553][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 1.770331621170044, acc: 0.5116279125213623)
[2024-11-13 07:53:22,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:22,851][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 1.57718026638031, acc: 0.4642857015132904)
[2024-11-13 07:53:22,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:23,184][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 1.6742559671401978, acc: 0.5061728358268738)
[2024-11-13 07:53:23,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:23,502][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 1.361757755279541, acc: 0.5555555820465088)
[2024-11-13 07:53:23,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:23,829][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.9187109470367432, acc: 0.71875)
[2024-11-13 07:53:23,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:24,178][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.8257991075515747, acc: 0.7307692170143127)
[2024-11-13 07:53:24,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:24,530][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 1.0412516593933105, acc: 0.739130437374115)
[2024-11-13 07:53:24,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:24,873][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 1.5959105491638184, acc: 0.5)
[2024-11-13 07:53:24,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:25,220][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 1.6028738021850586, acc: 0.5542168617248535)
[2024-11-13 07:53:25,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:25,552][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 1.3873302936553955, acc: 0.5585585832595825)
[2024-11-13 07:53:25,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:25,884][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 1.5906883478164673, acc: 0.582524299621582)
[2024-11-13 07:53:25,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:26,209][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 1.3217824697494507, acc: 0.6260162591934204)
[2024-11-13 07:53:26,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:26,554][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 1.0228441953659058, acc: 0.7083333134651184)
[2024-11-13 07:53:26,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:26,840][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.9870510101318359, acc: 0.7857142686843872)
[2024-11-13 07:53:26,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:27,178][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 1.8828948736190796, acc: 0.46078431606292725)
[2024-11-13 07:53:27,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:27,496][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 2.1273410320281982, acc: 0.42794761061668396)
[2024-11-13 07:53:27,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:27,803][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 1.876298427581787, acc: 0.4895833432674408)
[2024-11-13 07:53:27,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:28,099][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 1.8688483238220215, acc: 0.44171780347824097)
[2024-11-13 07:53:28,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:28,460][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 2.06943941116333, acc: 0.4460431635379791)
[2024-11-13 07:53:28,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:28,810][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 2.148510694503784, acc: 0.39698493480682373)
[2024-11-13 07:53:28,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:29,092][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 1.0055307149887085, acc: 0.75)
[2024-11-13 07:53:29,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:29,425][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.9811050891876221, acc: 0.6666666865348816)
[2024-11-13 07:53:29,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:29,704][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.7492896318435669, acc: 0.8148148059844971)
[2024-11-13 07:53:29,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:30,014][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 1.0112990140914917, acc: 0.699999988079071)
[2024-11-13 07:53:30,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:30,356][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 0.8313692808151245, acc: 0.800000011920929)
[2024-11-13 07:53:30,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:30,720][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 1.2835359573364258, acc: 0.6034482717514038)
[2024-11-13 07:53:30,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:31,052][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.8968332409858704, acc: 0.7096773982048035)
[2024-11-13 07:53:31,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:31,358][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.649507999420166, acc: 0.8947368264198303)
[2024-11-13 07:53:31,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:31,685][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 1.4690287113189697, acc: 0.5555555820465088)
[2024-11-13 07:53:31,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:31,976][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 1.344145655632019, acc: 0.5714285969734192)
[2024-11-13 07:53:32,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:32,326][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 1.218315839767456, acc: 0.5)
[2024-11-13 07:53:32,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:32,635][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 1.6568865776062012, acc: 0.5692307949066162)
[2024-11-13 07:53:32,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:32,872][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 1.250644326210022, acc: 0.6000000238418579)
[2024-11-13 07:53:32,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:33,197][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 1.1877028942108154, acc: 0.6206896305084229)
[2024-11-13 07:53:33,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:33,520][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 1.5180315971374512, acc: 0.5490196347236633)
[2024-11-13 07:53:33,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:33,843][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 1.3977974653244019, acc: 0.517241358757019)
[2024-11-13 07:53:33,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:34,097][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.5610139966011047, acc: 0.7894737124443054)
[2024-11-13 07:53:34,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:34,389][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 1.350490689277649, acc: 0.5789473652839661)
[2024-11-13 07:53:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:34,749][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 1.4107354879379272, acc: 0.625)
[2024-11-13 07:53:34,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:35,133][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 1.6165310144424438, acc: 0.5617977380752563)
[2024-11-13 07:53:35,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:35,474][root][INFO] - Training Epoch: 5/10, step 498/574 completed (loss: 1.8460978269577026, acc: 0.5056179761886597)
[2024-11-13 07:53:35,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:35,807][root][INFO] - Training Epoch: 5/10, step 499/574 completed (loss: 2.2101564407348633, acc: 0.38297873735427856)
[2024-11-13 07:53:35,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:36,146][root][INFO] - Training Epoch: 5/10, step 500/574 completed (loss: 2.010671615600586, acc: 0.41304346919059753)
[2024-11-13 07:53:36,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:36,437][root][INFO] - Training Epoch: 5/10, step 501/574 completed (loss: 0.846844494342804, acc: 0.800000011920929)
[2024-11-13 07:53:36,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:36,769][root][INFO] - Training Epoch: 5/10, step 502/574 completed (loss: 0.7105575203895569, acc: 0.7307692170143127)
[2024-11-13 07:53:36,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:37,093][root][INFO] - Training Epoch: 5/10, step 503/574 completed (loss: 0.6334296464920044, acc: 0.7777777910232544)
[2024-11-13 07:53:37,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:37,422][root][INFO] - Training Epoch: 5/10, step 504/574 completed (loss: 1.2728080749511719, acc: 0.5925925970077515)
[2024-11-13 07:53:37,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:37,747][root][INFO] - Training Epoch: 5/10, step 505/574 completed (loss: 1.1068352460861206, acc: 0.6415094137191772)
[2024-11-13 07:53:37,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:38,085][root][INFO] - Training Epoch: 5/10, step 506/574 completed (loss: 0.7746545076370239, acc: 0.8275862336158752)
[2024-11-13 07:53:38,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:38,540][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 1.610416293144226, acc: 0.5675675868988037)
[2024-11-13 07:53:38,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:38,921][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 1.2836275100708008, acc: 0.6338028311729431)
[2024-11-13 07:53:38,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:39,246][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.47870883345603943, acc: 0.800000011920929)
[2024-11-13 07:53:39,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:39,558][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.5783290863037109, acc: 0.800000011920929)
[2024-11-13 07:53:39,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:39,883][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.7281694412231445, acc: 0.8461538553237915)
[2024-11-13 07:53:40,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:41,078][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.8543161153793335, acc: 0.47857141494750977)
[2024-11-13 07:53:41,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:41,630][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 1.567652940750122, acc: 0.5555555820465088)
[2024-11-13 07:53:41,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:41,901][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.7857416868209839, acc: 0.7142857313156128)
[2024-11-13 07:53:41,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:42,194][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 1.1037538051605225, acc: 0.6666666865348816)
[2024-11-13 07:53:42,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:42,724][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 1.3354640007019043, acc: 0.6527777910232544)
[2024-11-13 07:53:42,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:43,055][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.5068452954292297, acc: 0.7692307829856873)
[2024-11-13 07:53:43,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:43,378][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 1.0700860023498535, acc: 0.6774193644523621)
[2024-11-13 07:53:43,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:43,681][root][INFO] - Training Epoch: 5/10, step 519/574 completed (loss: 1.1945314407348633, acc: 0.6499999761581421)
[2024-11-13 07:53:43,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:43,962][root][INFO] - Training Epoch: 5/10, step 520/574 completed (loss: 1.0559347867965698, acc: 0.6296296119689941)
[2024-11-13 07:53:44,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:44,653][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 1.9746119976043701, acc: 0.4661017060279846)
[2024-11-13 07:53:44,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:44,936][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 1.821925163269043, acc: 0.5)
[2024-11-13 07:53:45,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:45,262][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 1.7920082807540894, acc: 0.510948896408081)
[2024-11-13 07:53:45,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:45,737][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 1.871861457824707, acc: 0.5)
[2024-11-13 07:53:45,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:46,036][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 1.628039836883545, acc: 0.6481481194496155)
[2024-11-13 07:53:46,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:46,334][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 1.4008252620697021, acc: 0.5384615659713745)
[2024-11-13 07:53:46,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:46,627][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 1.3547148704528809, acc: 0.6666666865348816)
[2024-11-13 07:53:46,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:46,929][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 2.133882999420166, acc: 0.3606557250022888)
[2024-11-13 07:53:46,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:47,222][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 1.5156877040863037, acc: 0.6271186470985413)
[2024-11-13 07:53:47,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:47,530][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 1.812157392501831, acc: 0.5581395626068115)
[2024-11-13 07:53:47,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:47,834][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 1.3930602073669434, acc: 0.6136363744735718)
[2024-11-13 07:53:47,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:48,144][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.9463131427764893, acc: 0.43396225571632385)
[2024-11-13 07:53:48,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:48,454][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 1.359835147857666, acc: 0.6590909361839294)
[2024-11-13 07:53:48,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:48,748][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 1.025031328201294, acc: 0.7200000286102295)
[2024-11-13 07:53:48,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:49,039][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.5317775011062622, acc: 0.8999999761581421)
[2024-11-13 07:53:49,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:49,323][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.6847239136695862, acc: 0.7727272510528564)
[2024-11-13 07:53:49,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:49,657][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 1.4384537935256958, acc: 0.6615384817123413)
[2024-11-13 07:53:49,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:49,936][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 1.3454375267028809, acc: 0.640625)
[2024-11-13 07:53:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:50,264][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.9601467251777649, acc: 0.71875)
[2024-11-13 07:53:50,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:50,536][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 1.0516371726989746, acc: 0.7272727489471436)
[2024-11-13 07:53:50,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:50,835][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.7989405989646912, acc: 0.75)
[2024-11-13 07:53:50,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:51,130][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.5341994166374207, acc: 0.8387096524238586)
[2024-11-13 07:53:51,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:51,457][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.4256904423236847, acc: 0.8695651888847351)
[2024-11-13 07:53:51,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:51,795][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.9469664692878723, acc: 0.6333333253860474)
[2024-11-13 07:53:51,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:52,115][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 1.4270771741867065, acc: 0.5853658318519592)
[2024-11-13 07:53:52,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:52,393][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.8579652905464172, acc: 0.6857143044471741)
[2024-11-13 07:53:52,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:52,646][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.839226484298706, acc: 0.7631579041481018)
[2024-11-13 07:53:52,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:52,966][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.7702431678771973, acc: 0.774193525314331)
[2024-11-13 07:53:53,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:53,278][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.4186539053916931, acc: 0.8799999952316284)
[2024-11-13 07:53:53,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:53,566][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.5105025768280029, acc: 0.8181818127632141)
[2024-11-13 07:53:53,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:53,860][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.8535457849502563, acc: 0.7250000238418579)
[2024-11-13 07:53:53,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:54,092][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 0.9567043781280518, acc: 0.7428571581840515)
[2024-11-13 07:53:54,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:54,382][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 1.9176974296569824, acc: 0.47445255517959595)
[2024-11-13 07:53:54,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:54,715][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 1.4035207033157349, acc: 0.6137930750846863)
[2024-11-13 07:53:54,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:55,082][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 2.154529094696045, acc: 0.4357142746448517)
[2024-11-13 07:53:55,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:55,458][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 1.9608172178268433, acc: 0.4768211841583252)
[2024-11-13 07:53:55,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:55,774][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 1.607651710510254, acc: 0.5555555820465088)
[2024-11-13 07:53:55,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:56,091][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.4791167378425598, acc: 0.8799999952316284)
[2024-11-13 07:53:56,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:56,399][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.591108500957489, acc: 0.7307692170143127)
[2024-11-13 07:53:56,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:56,681][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.5798177123069763, acc: 0.807692289352417)
[2024-11-13 07:53:56,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:56,977][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 1.1083399057388306, acc: 0.6666666865348816)
[2024-11-13 07:53:57,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:57,306][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 1.3832964897155762, acc: 0.5555555820465088)
[2024-11-13 07:53:57,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:57,579][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 1.2226731777191162, acc: 0.649350643157959)
[2024-11-13 07:53:58,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:58,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:58,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:59,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:59,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:53:59,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:00,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:00,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:00,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:00,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:01,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:01,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:01,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:01,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:02,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:02,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:02,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:03,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:03,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:03,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:03,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:04,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:04,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:04,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:04,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:05,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:05,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:05,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:06,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:06,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:06,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:06,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:07,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:07,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:07,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:08,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:08,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:08,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:08,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:09,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:09,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:09,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:09,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:10,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:10,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:10,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:10,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:11,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:11,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:11,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:12,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:12,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:12,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:13,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:13,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:13,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:13,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:14,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:14,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:14,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:15,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:15,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:15,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:15,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:16,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:16,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:16,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:17,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:17,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:17,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:17,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:17,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:18,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:18,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:18,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:19,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:19,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:19,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:19,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:20,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:20,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:20,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:21,350][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.9924, device='cuda:0') eval_epoch_loss=tensor(2.0785, device='cuda:0') eval_epoch_acc=tensor(0.5008, device='cuda:0')
[2024-11-13 07:54:21,352][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:54:21,352][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:54:21,680][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_5_step_564_loss_2.078495502471924/model.pt
[2024-11-13 07:54:21,683][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:54:21,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:21,996][root][INFO] - Training Epoch: 5/10, step 564/574 completed (loss: 0.9874110817909241, acc: 0.7291666865348816)
[2024-11-13 07:54:22,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:22,283][root][INFO] - Training Epoch: 5/10, step 565/574 completed (loss: 0.9207040071487427, acc: 0.7068965435028076)
[2024-11-13 07:54:22,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:22,580][root][INFO] - Training Epoch: 5/10, step 566/574 completed (loss: 1.3473306894302368, acc: 0.5595238208770752)
[2024-11-13 07:54:22,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:22,908][root][INFO] - Training Epoch: 5/10, step 567/574 completed (loss: 0.7987194061279297, acc: 0.7105262875556946)
[2024-11-13 07:54:22,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:23,202][root][INFO] - Training Epoch: 5/10, step 568/574 completed (loss: 0.6240875124931335, acc: 0.8148148059844971)
[2024-11-13 07:54:23,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:23,551][root][INFO] - Training Epoch: 5/10, step 569/574 completed (loss: 1.655035138130188, acc: 0.5401069521903992)
[2024-11-13 07:54:23,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:23,863][root][INFO] - Training Epoch: 5/10, step 570/574 completed (loss: 1.1991767883300781, acc: 0.6774193644523621)
[2024-11-13 07:54:23,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:24,181][root][INFO] - Training Epoch: 5/10, step 571/574 completed (loss: 1.327797532081604, acc: 0.6495726704597473)
[2024-11-13 07:54:24,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:24,486][root][INFO] - Training Epoch: 5/10, step 572/574 completed (loss: 1.9900786876678467, acc: 0.4591836631298065)
[2024-11-13 07:54:24,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:24,809][root][INFO] - Training Epoch: 5/10, step 573/574 completed (loss: 1.8857475519180298, acc: 0.48427674174308777)
[2024-11-13 07:54:25,195][slam_llm.utils.train_utils][INFO] - Epoch 5: train_perplexity=3.6413, train_epoch_loss=1.2923, epoch time 297.19824761897326s
[2024-11-13 07:54:25,196][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 07:54:25,196][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-11-13 07:54:25,196][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 07:54:25,196][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 07:54:25,196][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 07:54:25,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:26,043][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 0.9738759398460388, acc: 0.6296296119689941)
[2024-11-13 07:54:26,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:26,355][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.9885647296905518, acc: 0.800000011920929)
[2024-11-13 07:54:26,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:26,661][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 1.336832046508789, acc: 0.5945945978164673)
[2024-11-13 07:54:26,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:26,953][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 1.2704945802688599, acc: 0.5789473652839661)
[2024-11-13 07:54:27,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:27,246][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 1.3933645486831665, acc: 0.6216216087341309)
[2024-11-13 07:54:27,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:27,536][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 1.1003957986831665, acc: 0.6785714030265808)
[2024-11-13 07:54:27,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:27,871][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 1.777059555053711, acc: 0.4693877696990967)
[2024-11-13 07:54:27,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:28,188][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 1.0728932619094849, acc: 0.699999988079071)
[2024-11-13 07:54:28,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:28,512][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.44251710176467896, acc: 0.8181818127632141)
[2024-11-13 07:54:28,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:28,852][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.5818414092063904, acc: 0.8461538553237915)
[2024-11-13 07:54:28,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:29,204][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.6761105060577393, acc: 0.8148148059844971)
[2024-11-13 07:54:29,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:29,520][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 1.0969572067260742, acc: 0.6666666865348816)
[2024-11-13 07:54:29,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:29,845][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.8618298768997192, acc: 0.7272727489471436)
[2024-11-13 07:54:29,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:30,166][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 1.1688263416290283, acc: 0.6521739363670349)
[2024-11-13 07:54:30,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:30,472][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 1.3076173067092896, acc: 0.6078431606292725)
[2024-11-13 07:54:30,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:30,790][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 1.2241791486740112, acc: 0.6122449040412903)
[2024-11-13 07:54:30,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:31,089][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.5602132081985474, acc: 0.8421052694320679)
[2024-11-13 07:54:31,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:31,382][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.9665655493736267, acc: 0.6666666865348816)
[2024-11-13 07:54:31,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:31,670][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 1.2611327171325684, acc: 0.6666666865348816)
[2024-11-13 07:54:31,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:32,016][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 0.8524132966995239, acc: 0.6315789222717285)
[2024-11-13 07:54:32,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:32,318][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 1.0362250804901123, acc: 0.692307710647583)
[2024-11-13 07:54:32,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:32,662][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.7599804401397705, acc: 0.8275862336158752)
[2024-11-13 07:54:32,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:32,996][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.7236764430999756, acc: 0.800000011920929)
[2024-11-13 07:54:33,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:33,311][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.6712883114814758, acc: 0.7142857313156128)
[2024-11-13 07:54:33,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:33,598][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 0.7303276658058167, acc: 0.75)
[2024-11-13 07:54:33,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:33,920][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 1.6629432439804077, acc: 0.43396225571632385)
[2024-11-13 07:54:33,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:34,216][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 1.825573444366455, acc: 0.4383561611175537)
[2024-11-13 07:54:34,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:34,943][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 2.2178399562835693, acc: 0.4229249060153961)
[2024-11-13 07:54:34,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:35,214][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 1.3839068412780762, acc: 0.5581395626068115)
[2024-11-13 07:54:35,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:35,514][root][INFO] - Training Epoch: 6/10, step 29/574 completed (loss: 1.7392727136611938, acc: 0.5301204919815063)
[2024-11-13 07:54:35,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:35,826][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 1.6570931673049927, acc: 0.5679012537002563)
[2024-11-13 07:54:35,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:36,170][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 1.0196155309677124, acc: 0.6785714030265808)
[2024-11-13 07:54:36,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:36,491][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 1.0140092372894287, acc: 0.6666666865348816)
[2024-11-13 07:54:36,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:36,805][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.5491901636123657, acc: 0.8695651888847351)
[2024-11-13 07:54:36,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:37,162][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 1.8538908958435059, acc: 0.4957983195781708)
[2024-11-13 07:54:37,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:37,455][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 1.35085129737854, acc: 0.6229507923126221)
[2024-11-13 07:54:37,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:37,813][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 1.7018667459487915, acc: 0.460317462682724)
[2024-11-13 07:54:37,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:38,120][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 1.6039578914642334, acc: 0.5423728823661804)
[2024-11-13 07:54:38,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:38,434][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 1.385404109954834, acc: 0.5862069129943848)
[2024-11-13 07:54:38,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:38,719][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.7124783396720886, acc: 0.761904776096344)
[2024-11-13 07:54:38,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:39,056][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 1.0150974988937378, acc: 0.692307710647583)
[2024-11-13 07:54:39,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:39,393][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 1.9628617763519287, acc: 0.5)
[2024-11-13 07:54:39,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:39,715][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 1.6739177703857422, acc: 0.446153849363327)
[2024-11-13 07:54:39,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:40,030][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 1.9373136758804321, acc: 0.4747474789619446)
[2024-11-13 07:54:40,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:40,399][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 1.5752887725830078, acc: 0.5773195624351501)
[2024-11-13 07:54:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:40,748][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 1.904496192932129, acc: 0.5220588445663452)
[2024-11-13 07:54:40,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:41,031][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.8568848967552185, acc: 0.6538461446762085)
[2024-11-13 07:54:41,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:41,332][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.4109179973602295, acc: 0.8518518805503845)
[2024-11-13 07:54:41,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:41,697][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.9464864730834961, acc: 0.75)
[2024-11-13 07:54:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:42,001][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.5768017768859863, acc: 0.8888888955116272)
[2024-11-13 07:54:42,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:42,288][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 1.0228924751281738, acc: 0.719298243522644)
[2024-11-13 07:54:42,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:42,593][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 1.0979177951812744, acc: 0.6666666865348816)
[2024-11-13 07:54:42,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:42,858][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 1.4872573614120483, acc: 0.591549277305603)
[2024-11-13 07:54:42,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:43,237][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.8356974124908447, acc: 0.5533333420753479)
[2024-11-13 07:54:43,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:43,558][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.8653568625450134, acc: 0.7567567825317383)
[2024-11-13 07:54:43,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:43,883][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.46377894282341003, acc: 0.8846153616905212)
[2024-11-13 07:54:44,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:45,191][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 1.7361446619033813, acc: 0.5255972743034363)
[2024-11-13 07:54:45,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:46,008][root][INFO] - Training Epoch: 6/10, step 57/574 completed (loss: 2.4093496799468994, acc: 0.413943350315094)
[2024-11-13 07:54:46,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:46,492][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 1.8100361824035645, acc: 0.5625)
[2024-11-13 07:54:46,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:46,956][root][INFO] - Training Epoch: 6/10, step 59/574 completed (loss: 1.8629862070083618, acc: 0.5441176295280457)
[2024-11-13 07:54:47,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:47,401][root][INFO] - Training Epoch: 6/10, step 60/574 completed (loss: 2.0710113048553467, acc: 0.4202898442745209)
[2024-11-13 07:54:47,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:47,740][root][INFO] - Training Epoch: 6/10, step 61/574 completed (loss: 1.5190250873565674, acc: 0.612500011920929)
[2024-11-13 07:54:47,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:48,026][root][INFO] - Training Epoch: 6/10, step 62/574 completed (loss: 0.8909440040588379, acc: 0.7647058963775635)
[2024-11-13 07:54:48,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:48,399][root][INFO] - Training Epoch: 6/10, step 63/574 completed (loss: 1.1267895698547363, acc: 0.6666666865348816)
[2024-11-13 07:54:48,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:48,731][root][INFO] - Training Epoch: 6/10, step 64/574 completed (loss: 1.084702730178833, acc: 0.6875)
[2024-11-13 07:54:48,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:49,069][root][INFO] - Training Epoch: 6/10, step 65/574 completed (loss: 0.5821737051010132, acc: 0.8275862336158752)
[2024-11-13 07:54:49,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:49,400][root][INFO] - Training Epoch: 6/10, step 66/574 completed (loss: 1.638724684715271, acc: 0.5357142686843872)
[2024-11-13 07:54:49,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:49,716][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 1.6526707410812378, acc: 0.5666666626930237)
[2024-11-13 07:54:49,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:50,011][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.5451546907424927, acc: 0.800000011920929)
[2024-11-13 07:54:50,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:50,306][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.9238027930259705, acc: 0.7777777910232544)
[2024-11-13 07:54:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:50,602][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 1.1651569604873657, acc: 0.6969696879386902)
[2024-11-13 07:54:50,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:50,915][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 1.8571802377700806, acc: 0.529411792755127)
[2024-11-13 07:54:50,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:51,220][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 1.5532816648483276, acc: 0.5476190447807312)
[2024-11-13 07:54:51,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:51,528][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 1.9312422275543213, acc: 0.46666666865348816)
[2024-11-13 07:54:51,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:51,843][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 1.5266097784042358, acc: 0.581632673740387)
[2024-11-13 07:54:51,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:52,172][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 2.1228249073028564, acc: 0.3507462739944458)
[2024-11-13 07:54:52,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:52,524][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 2.119055986404419, acc: 0.45985400676727295)
[2024-11-13 07:54:52,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:52,842][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.3657200336456299, acc: 0.9047619104385376)
[2024-11-13 07:54:52,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:53,146][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.34279462695121765, acc: 0.875)
[2024-11-13 07:54:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:53,440][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.7332143783569336, acc: 0.7272727489471436)
[2024-11-13 07:54:53,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:53,712][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.484857439994812, acc: 0.807692289352417)
[2024-11-13 07:54:53,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:54,007][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 1.3057492971420288, acc: 0.6346153616905212)
[2024-11-13 07:54:54,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:54,331][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 1.4727981090545654, acc: 0.6538461446762085)
[2024-11-13 07:54:54,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:54,612][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.7270890474319458, acc: 0.78125)
[2024-11-13 07:54:54,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:54,937][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 1.551395297050476, acc: 0.52173912525177)
[2024-11-13 07:54:55,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:55,252][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 1.1134907007217407, acc: 0.6399999856948853)
[2024-11-13 07:54:55,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:55,546][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 0.9676954746246338, acc: 0.739130437374115)
[2024-11-13 07:54:55,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:55,923][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 1.5072230100631714, acc: 0.5600000023841858)
[2024-11-13 07:54:55,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:56,235][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 1.4244871139526367, acc: 0.5728155374526978)
[2024-11-13 07:54:56,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:56,955][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 1.7719762325286865, acc: 0.5485436916351318)
[2024-11-13 07:54:57,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:57,568][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.8561960458755493, acc: 0.48924732208251953)
[2024-11-13 07:54:57,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:58,158][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 1.697156310081482, acc: 0.5732758641242981)
[2024-11-13 07:54:58,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:58,719][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 1.291226863861084, acc: 0.5684210658073425)
[2024-11-13 07:54:58,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:59,412][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 1.8945260047912598, acc: 0.4554455578327179)
[2024-11-13 07:54:59,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:59,679][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 1.679967999458313, acc: 0.5161290168762207)
[2024-11-13 07:54:59,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:54:59,979][root][INFO] - Training Epoch: 6/10, step 95/574 completed (loss: 1.4276114702224731, acc: 0.5362318754196167)
[2024-11-13 07:55:00,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:00,295][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 1.8875324726104736, acc: 0.42016807198524475)
[2024-11-13 07:55:00,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:00,603][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 2.023890256881714, acc: 0.4326923191547394)
[2024-11-13 07:55:00,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:00,956][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 2.0597643852233887, acc: 0.48175182938575745)
[2024-11-13 07:55:01,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:01,246][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 1.9948915243148804, acc: 0.34328359365463257)
[2024-11-13 07:55:01,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:01,538][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.6184263229370117, acc: 0.8500000238418579)
[2024-11-13 07:55:01,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:01,857][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.529941737651825, acc: 0.8181818127632141)
[2024-11-13 07:55:01,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:02,172][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.5878632664680481, acc: 0.8260869383811951)
[2024-11-13 07:55:02,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:02,488][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.9450611472129822, acc: 0.7045454382896423)
[2024-11-13 07:55:02,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:02,798][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 1.5536065101623535, acc: 0.5517241358757019)
[2024-11-13 07:55:02,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:03,134][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.8287562131881714, acc: 0.7674418687820435)
[2024-11-13 07:55:03,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:03,447][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 1.0309021472930908, acc: 0.7200000286102295)
[2024-11-13 07:55:03,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:03,743][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.280281126499176, acc: 1.0)
[2024-11-13 07:55:03,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:04,042][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.31159350275993347, acc: 0.9230769276618958)
[2024-11-13 07:55:04,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:04,342][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.8345045447349548, acc: 0.761904776096344)
[2024-11-13 07:55:04,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:04,652][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 1.2884392738342285, acc: 0.6769230961799622)
[2024-11-13 07:55:04,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:05,035][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 1.3404098749160767, acc: 0.6842105388641357)
[2024-11-13 07:55:05,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:05,370][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 1.044284462928772, acc: 0.7368420958518982)
[2024-11-13 07:55:05,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:05,686][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 1.2719870805740356, acc: 0.5897436141967773)
[2024-11-13 07:55:05,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:06,011][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 1.1364448070526123, acc: 0.6734693646430969)
[2024-11-13 07:55:06,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:06,313][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.27496132254600525, acc: 0.9090909361839294)
[2024-11-13 07:55:06,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:06,629][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 1.4086321592330933, acc: 0.5714285969734192)
[2024-11-13 07:55:06,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:06,949][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 1.6094948053359985, acc: 0.6016260385513306)
[2024-11-13 07:55:07,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:07,244][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 1.1610655784606934, acc: 0.6451612710952759)
[2024-11-13 07:55:07,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:07,873][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 1.9775089025497437, acc: 0.48669201135635376)
[2024-11-13 07:55:07,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:08,189][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 1.2307788133621216, acc: 0.6133333444595337)
[2024-11-13 07:55:08,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:08,530][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 1.0708715915679932, acc: 0.692307710647583)
[2024-11-13 07:55:08,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:08,810][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.548755943775177, acc: 0.875)
[2024-11-13 07:55:08,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:09,093][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.8105668425559998, acc: 0.6842105388641357)
[2024-11-13 07:55:09,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:09,405][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 1.7854735851287842, acc: 0.4969325065612793)
[2024-11-13 07:55:09,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:09,737][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.5505454540252686, acc: 0.5833333134651184)
[2024-11-13 07:55:09,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:10,029][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 1.802688479423523, acc: 0.5083333253860474)
[2024-11-13 07:55:10,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:10,364][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 1.7887792587280273, acc: 0.4761904776096344)
[2024-11-13 07:55:10,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:10,684][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 1.689845323562622, acc: 0.528205156326294)
[2024-11-13 07:55:10,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:11,055][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 1.6136884689331055, acc: 0.5220588445663452)
[2024-11-13 07:55:11,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:11,395][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.9020043015480042, acc: 0.807692289352417)
[2024-11-13 07:55:11,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:11,705][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.39376258850097656, acc: 0.9130434989929199)
[2024-11-13 07:55:11,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:12,016][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.8699931502342224, acc: 0.65625)
[2024-11-13 07:55:12,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:13,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:13,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:13,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:14,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:14,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:14,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:14,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:15,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:15,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:15,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:15,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:16,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:16,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:16,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:17,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:17,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:17,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:17,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:18,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:18,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:18,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:18,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:19,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:19,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:19,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:20,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:20,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:20,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:20,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:21,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:21,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:21,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:21,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:22,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:22,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:22,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:22,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:23,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:23,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:23,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:24,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:24,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:24,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:24,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:25,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:25,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:25,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:25,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:26,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:26,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:26,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:27,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:27,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:27,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:27,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:28,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:28,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:28,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:29,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:29,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:29,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:30,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:30,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:30,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:31,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:31,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:31,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:31,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:32,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:32,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:32,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:32,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:33,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:33,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:33,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:33,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:33,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:34,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:34,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:34,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:35,680][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.8899, device='cuda:0') eval_epoch_loss=tensor(1.9301, device='cuda:0') eval_epoch_acc=tensor(0.5189, device='cuda:0')
[2024-11-13 07:55:35,683][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:55:35,683][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:55:36,030][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_6_step_133_loss_1.9300593137741089/model.pt
[2024-11-13 07:55:36,034][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:55:36,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:36,392][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.9670619964599609, acc: 0.6086956262588501)
[2024-11-13 07:55:36,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:36,704][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 1.0488901138305664, acc: 0.6857143044471741)
[2024-11-13 07:55:36,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:37,021][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.5104830861091614, acc: 0.8461538553237915)
[2024-11-13 07:55:37,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:37,331][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 1.0604466199874878, acc: 0.7142857313156128)
[2024-11-13 07:55:37,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:37,628][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 1.0358474254608154, acc: 0.6333333253860474)
[2024-11-13 07:55:37,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:37,944][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.8570651412010193, acc: 0.695652186870575)
[2024-11-13 07:55:38,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:38,239][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 1.0984388589859009, acc: 0.761904776096344)
[2024-11-13 07:55:38,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:38,547][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 1.1944103240966797, acc: 0.5769230723381042)
[2024-11-13 07:55:38,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:38,844][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 1.5043927431106567, acc: 0.5806451439857483)
[2024-11-13 07:55:38,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:39,157][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 1.3877516984939575, acc: 0.4864864945411682)
[2024-11-13 07:55:39,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:39,574][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 1.6576261520385742, acc: 0.45614033937454224)
[2024-11-13 07:55:39,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:39,880][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 1.526087760925293, acc: 0.60447758436203)
[2024-11-13 07:55:39,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:40,181][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 2.1199405193328857, acc: 0.3469387888908386)
[2024-11-13 07:55:40,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:40,548][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 1.852272391319275, acc: 0.40425533056259155)
[2024-11-13 07:55:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:40,860][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 1.577455997467041, acc: 0.5285714268684387)
[2024-11-13 07:55:40,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:41,149][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 0.8270202279090881, acc: 0.8214285969734192)
[2024-11-13 07:55:41,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:41,449][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.943179190158844, acc: 0.695652186870575)
[2024-11-13 07:55:41,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:41,739][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.8853174448013306, acc: 0.6896551847457886)
[2024-11-13 07:55:41,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:42,046][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 1.54087233543396, acc: 0.5869565010070801)
[2024-11-13 07:55:42,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:42,372][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 1.5719777345657349, acc: 0.5423728823661804)
[2024-11-13 07:55:42,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:42,686][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 1.7273890972137451, acc: 0.5263158082962036)
[2024-11-13 07:55:42,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:42,997][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 1.5673458576202393, acc: 0.5405405163764954)
[2024-11-13 07:55:43,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:43,304][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.9400378465652466, acc: 0.7857142686843872)
[2024-11-13 07:55:43,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:43,617][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.9762914776802063, acc: 0.739130437374115)
[2024-11-13 07:55:43,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:43,899][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 0.6492228507995605, acc: 0.7894737124443054)
[2024-11-13 07:55:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:44,769][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 1.3914884328842163, acc: 0.5945945978164673)
[2024-11-13 07:55:44,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:45,044][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 1.4355459213256836, acc: 0.5925925970077515)
[2024-11-13 07:55:45,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:45,375][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 1.2158234119415283, acc: 0.6511628031730652)
[2024-11-13 07:55:45,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:45,824][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 1.1730097532272339, acc: 0.6352941393852234)
[2024-11-13 07:55:45,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:46,284][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 1.6728042364120483, acc: 0.5280898809432983)
[2024-11-13 07:55:46,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:46,586][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.9913001656532288, acc: 0.7272727489471436)
[2024-11-13 07:55:46,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:46,857][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 1.0320686101913452, acc: 0.761904776096344)
[2024-11-13 07:55:46,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:47,196][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 0.9718166589736938, acc: 0.6551724076271057)
[2024-11-13 07:55:47,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:47,523][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 1.0369064807891846, acc: 0.6734693646430969)
[2024-11-13 07:55:47,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:47,841][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 1.0993573665618896, acc: 0.6399999856948853)
[2024-11-13 07:55:47,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:48,176][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 1.2141815423965454, acc: 0.6388888955116272)
[2024-11-13 07:55:48,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:48,469][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.5448858737945557, acc: 0.5882353186607361)
[2024-11-13 07:55:48,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:49,190][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 2.1031243801116943, acc: 0.42465752363204956)
[2024-11-13 07:55:49,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:49,470][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.6744317412376404, acc: 0.7916666865348816)
[2024-11-13 07:55:49,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:49,722][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.597674548625946, acc: 0.7777777910232544)
[2024-11-13 07:55:49,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:50,024][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.6746693253517151, acc: 0.8214285969734192)
[2024-11-13 07:55:50,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:50,450][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.402299404144287, acc: 0.6460176706314087)
[2024-11-13 07:55:50,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:50,736][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 1.1233251094818115, acc: 0.7101449370384216)
[2024-11-13 07:55:50,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:51,065][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 1.5853393077850342, acc: 0.5340909361839294)
[2024-11-13 07:55:51,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:51,702][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 1.9497679471969604, acc: 0.49618321657180786)
[2024-11-13 07:55:51,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:52,209][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 1.8809255361557007, acc: 0.4592592716217041)
[2024-11-13 07:55:52,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:52,485][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 1.222500205039978, acc: 0.6721311211585999)
[2024-11-13 07:55:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:52,741][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.6352015137672424, acc: 0.875)
[2024-11-13 07:55:52,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:53,011][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.8372946977615356, acc: 0.7599999904632568)
[2024-11-13 07:55:53,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:53,291][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.7209469676017761, acc: 0.75)
[2024-11-13 07:55:53,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:53,617][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 1.6201221942901611, acc: 0.5121951103210449)
[2024-11-13 07:55:53,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:53,976][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 1.9956345558166504, acc: 0.4622356593608856)
[2024-11-13 07:55:54,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:54,299][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 2.158923864364624, acc: 0.46109509468078613)
[2024-11-13 07:55:54,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:54,700][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 2.175647020339966, acc: 0.42500001192092896)
[2024-11-13 07:55:54,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:55,155][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 2.067836284637451, acc: 0.454033762216568)
[2024-11-13 07:55:55,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:55,499][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 1.8845103979110718, acc: 0.47330960631370544)
[2024-11-13 07:55:55,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:55,789][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.783354640007019, acc: 0.800000011920929)
[2024-11-13 07:55:55,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:56,212][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 1.9897518157958984, acc: 0.45348837971687317)
[2024-11-13 07:55:56,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:56,777][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.7182824611663818, acc: 0.5555555820465088)
[2024-11-13 07:55:56,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:57,403][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 1.770087480545044, acc: 0.5)
[2024-11-13 07:55:57,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:57,955][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 1.5119489431381226, acc: 0.6235294342041016)
[2024-11-13 07:55:58,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:58,678][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 1.5433673858642578, acc: 0.5740740895271301)
[2024-11-13 07:55:58,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:59,329][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 1.1664762496948242, acc: 0.6774193644523621)
[2024-11-13 07:55:59,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:59,602][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.6992038488388062, acc: 0.7857142686843872)
[2024-11-13 07:55:59,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:55:59,984][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.9301060438156128, acc: 0.7749999761581421)
[2024-11-13 07:56:00,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:00,316][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 1.2997910976409912, acc: 0.6470588445663452)
[2024-11-13 07:56:00,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:00,695][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 1.6371736526489258, acc: 0.5220588445663452)
[2024-11-13 07:56:00,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:01,081][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 1.6861380338668823, acc: 0.5254237055778503)
[2024-11-13 07:56:01,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:01,414][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 1.8785691261291504, acc: 0.4701492488384247)
[2024-11-13 07:56:01,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:01,760][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 1.73274827003479, acc: 0.5048543810844421)
[2024-11-13 07:56:01,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:02,115][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 1.3699955940246582, acc: 0.6190476417541504)
[2024-11-13 07:56:02,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:02,460][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 1.4604555368423462, acc: 0.593406617641449)
[2024-11-13 07:56:02,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:02,791][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 1.8323365449905396, acc: 0.48430493474006653)
[2024-11-13 07:56:02,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:03,147][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 1.8643171787261963, acc: 0.4881889820098877)
[2024-11-13 07:56:03,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:03,489][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 1.7746518850326538, acc: 0.5086206793785095)
[2024-11-13 07:56:03,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:03,878][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 1.743133544921875, acc: 0.5362318754196167)
[2024-11-13 07:56:03,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:04,215][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 1.9939755201339722, acc: 0.40856030583381653)
[2024-11-13 07:56:04,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:04,554][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 1.8295774459838867, acc: 0.5760869383811951)
[2024-11-13 07:56:04,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:04,883][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 1.0795869827270508, acc: 0.695652186870575)
[2024-11-13 07:56:04,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:05,206][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.7502008676528931, acc: 0.7857142686843872)
[2024-11-13 07:56:05,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:05,461][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.8135594129562378, acc: 0.7446808218955994)
[2024-11-13 07:56:05,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:05,966][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 1.4442453384399414, acc: 0.5692307949066162)
[2024-11-13 07:56:06,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:06,285][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 1.2157549858093262, acc: 0.662162184715271)
[2024-11-13 07:56:06,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:06,626][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 1.0736654996871948, acc: 0.6860465407371521)
[2024-11-13 07:56:06,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:07,052][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 1.3221641778945923, acc: 0.6756756901741028)
[2024-11-13 07:56:07,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:07,384][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 1.2893965244293213, acc: 0.6222222447395325)
[2024-11-13 07:56:07,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:07,741][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.6904973387718201, acc: 0.8484848737716675)
[2024-11-13 07:56:07,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:08,068][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.3078943192958832, acc: 0.9259259104728699)
[2024-11-13 07:56:08,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:08,388][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.5327090620994568, acc: 0.8399999737739563)
[2024-11-13 07:56:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:08,737][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 0.9592319130897522, acc: 0.7307692170143127)
[2024-11-13 07:56:08,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:09,293][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 1.3872779607772827, acc: 0.6195651888847351)
[2024-11-13 07:56:09,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:09,727][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 1.6908618211746216, acc: 0.5227272510528564)
[2024-11-13 07:56:09,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:10,099][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 1.6272741556167603, acc: 0.5)
[2024-11-13 07:56:10,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:10,430][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.9029150009155273, acc: 0.7547169923782349)
[2024-11-13 07:56:10,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:10,685][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 1.1630446910858154, acc: 0.7166666388511658)
[2024-11-13 07:56:10,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:11,033][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.6195864081382751, acc: 0.8372092843055725)
[2024-11-13 07:56:11,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:11,398][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.7629424929618835, acc: 0.7666666507720947)
[2024-11-13 07:56:11,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:11,747][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 1.7207330465316772, acc: 0.49473685026168823)
[2024-11-13 07:56:11,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:12,101][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 1.267177700996399, acc: 0.6555555462837219)
[2024-11-13 07:56:12,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:12,498][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 1.1351851224899292, acc: 0.6888889074325562)
[2024-11-13 07:56:12,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:12,914][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 1.5484853982925415, acc: 0.6009174585342407)
[2024-11-13 07:56:13,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:13,306][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 1.095660924911499, acc: 0.6769230961799622)
[2024-11-13 07:56:13,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:13,625][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.7726840376853943, acc: 0.7368420958518982)
[2024-11-13 07:56:13,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:13,964][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.5225755572319031, acc: 0.875)
[2024-11-13 07:56:14,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:14,276][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 1.2847697734832764, acc: 0.6818181872367859)
[2024-11-13 07:56:14,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:14,538][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.9452552795410156, acc: 0.7037037014961243)
[2024-11-13 07:56:14,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:14,843][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.7128790616989136, acc: 0.7714285850524902)
[2024-11-13 07:56:14,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:15,149][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.9867438673973083, acc: 0.6818181872367859)
[2024-11-13 07:56:15,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:15,428][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.9672417044639587, acc: 0.7727272510528564)
[2024-11-13 07:56:15,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:15,871][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 1.4819529056549072, acc: 0.5967742204666138)
[2024-11-13 07:56:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:16,289][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 1.1547304391860962, acc: 0.6590909361839294)
[2024-11-13 07:56:16,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:16,579][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.4159129858016968, acc: 0.8571428656578064)
[2024-11-13 07:56:16,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:16,865][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.6874971985816956, acc: 0.807692289352417)
[2024-11-13 07:56:16,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:17,186][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.6106810569763184, acc: 0.8709677457809448)
[2024-11-13 07:56:17,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:17,522][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.7131906747817993, acc: 0.699999988079071)
[2024-11-13 07:56:17,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:17,851][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.9208296537399292, acc: 0.7567567825317383)
[2024-11-13 07:56:17,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:18,195][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 1.0862021446228027, acc: 0.6756756901741028)
[2024-11-13 07:56:18,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:18,548][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.9174990057945251, acc: 0.7297297120094299)
[2024-11-13 07:56:18,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:18,898][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 1.4345393180847168, acc: 0.5882353186607361)
[2024-11-13 07:56:18,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:19,176][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.6295775771141052, acc: 0.7560975551605225)
[2024-11-13 07:56:19,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:19,469][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.21447141468524933, acc: 0.9599999785423279)
[2024-11-13 07:56:19,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:19,736][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.27195295691490173, acc: 0.9200000166893005)
[2024-11-13 07:56:19,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:19,957][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.4404725134372711, acc: 0.9032257795333862)
[2024-11-13 07:56:20,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:20,260][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.9424464106559753, acc: 0.7017543911933899)
[2024-11-13 07:56:20,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:20,576][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 1.2388925552368164, acc: 0.6714285612106323)
[2024-11-13 07:56:20,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:20,812][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 1.1062736511230469, acc: 0.6315789222717285)
[2024-11-13 07:56:20,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:21,274][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 1.2596770524978638, acc: 0.5849056839942932)
[2024-11-13 07:56:21,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:21,724][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 1.543908715248108, acc: 0.5833333134651184)
[2024-11-13 07:56:21,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:22,059][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.8774667978286743, acc: 0.75)
[2024-11-13 07:56:22,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:22,345][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.9475524425506592, acc: 0.7419354915618896)
[2024-11-13 07:56:22,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:22,665][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 2.1000113487243652, acc: 0.5066666603088379)
[2024-11-13 07:56:22,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:22,940][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 1.5337162017822266, acc: 0.5208333134651184)
[2024-11-13 07:56:23,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:23,528][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 2.154240131378174, acc: 0.4320000112056732)
[2024-11-13 07:56:23,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:23,868][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 1.8790968656539917, acc: 0.449438214302063)
[2024-11-13 07:56:23,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:24,215][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 1.6664949655532837, acc: 0.6351351141929626)
[2024-11-13 07:56:24,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:24,594][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 1.2836377620697021, acc: 0.6206896305084229)
[2024-11-13 07:56:24,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:24,941][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.6826766729354858, acc: 0.7727272510528564)
[2024-11-13 07:56:25,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:25,258][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.6446910500526428, acc: 0.7727272510528564)
[2024-11-13 07:56:25,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:25,590][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.6761338710784912, acc: 0.78125)
[2024-11-13 07:56:25,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:25,936][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.9945629239082336, acc: 0.7666666507720947)
[2024-11-13 07:56:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:26,283][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 1.3979436159133911, acc: 0.6000000238418579)
[2024-11-13 07:56:26,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:26,625][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.6587778329849243, acc: 0.84375)
[2024-11-13 07:56:26,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:26,959][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.6092987060546875, acc: 0.800000011920929)
[2024-11-13 07:56:27,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:27,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:28,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:28,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:28,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:28,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:29,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:29,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:29,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:30,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:30,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:30,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:30,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:31,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:31,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:31,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:31,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:32,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:32,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:32,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:33,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:33,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:33,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:34,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:34,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:34,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:34,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:35,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:35,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:35,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:36,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:36,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:36,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:36,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:37,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:37,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:37,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:38,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:38,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:38,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:38,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:39,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:39,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:39,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:39,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:40,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:40,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:40,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:41,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:41,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:41,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:41,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:42,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:42,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:42,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:42,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:43,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:43,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:43,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:43,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:44,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:44,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:44,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:45,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:45,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:45,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:46,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:46,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:46,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:46,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:47,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:47,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:47,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:48,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:48,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:48,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:49,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:49,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:49,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:49,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:50,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:50,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:50,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:51,242][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.0081, device='cuda:0') eval_epoch_loss=tensor(1.9471, device='cuda:0') eval_epoch_acc=tensor(0.5360, device='cuda:0')
[2024-11-13 07:56:51,244][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:56:51,245][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:56:51,605][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_6_step_276_loss_1.9470633268356323/model.pt
[2024-11-13 07:56:51,608][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:56:51,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:51,918][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 1.0553494691848755, acc: 0.7241379022598267)
[2024-11-13 07:56:51,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:52,195][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 1.219404697418213, acc: 0.6800000071525574)
[2024-11-13 07:56:52,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:52,462][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 1.1529438495635986, acc: 0.6595744490623474)
[2024-11-13 07:56:52,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:52,753][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 1.328192949295044, acc: 0.6458333134651184)
[2024-11-13 07:56:52,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:53,053][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 1.1536732912063599, acc: 0.7272727489471436)
[2024-11-13 07:56:53,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:53,415][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 1.6621172428131104, acc: 0.5301204919815063)
[2024-11-13 07:56:53,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:53,751][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 1.7491357326507568, acc: 0.5277777910232544)
[2024-11-13 07:56:53,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:54,030][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 1.0742902755737305, acc: 0.6842105388641357)
[2024-11-13 07:56:54,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:54,309][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 1.2164599895477295, acc: 0.5588235259056091)
[2024-11-13 07:56:54,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:54,637][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.9716750979423523, acc: 0.6499999761581421)
[2024-11-13 07:56:54,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:54,952][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 1.8090850114822388, acc: 0.46875)
[2024-11-13 07:56:55,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:55,301][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 1.7498319149017334, acc: 0.4560000002384186)
[2024-11-13 07:56:55,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:55,603][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 1.3844085931777954, acc: 0.6263736486434937)
[2024-11-13 07:56:55,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:55,911][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 1.9912285804748535, acc: 0.4658385217189789)
[2024-11-13 07:56:55,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:56,219][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 2.0188467502593994, acc: 0.438144326210022)
[2024-11-13 07:56:56,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:56,492][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.5334808826446533, acc: 0.7727272510528564)
[2024-11-13 07:56:56,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:56,807][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 1.3135111331939697, acc: 0.5952380895614624)
[2024-11-13 07:56:56,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:57,180][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 1.0555750131607056, acc: 0.6896551847457886)
[2024-11-13 07:56:57,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:57,620][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.7917641997337341, acc: 0.7818182110786438)
[2024-11-13 07:56:57,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:58,071][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 1.5764622688293457, acc: 0.5824742317199707)
[2024-11-13 07:56:58,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:58,345][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 1.4515953063964844, acc: 0.5862069129943848)
[2024-11-13 07:56:58,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:58,573][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.8091289401054382, acc: 0.8148148059844971)
[2024-11-13 07:56:58,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:58,875][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 1.0743869543075562, acc: 0.7368420958518982)
[2024-11-13 07:56:58,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:59,219][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.983695387840271, acc: 0.7678571343421936)
[2024-11-13 07:56:59,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:59,496][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 1.1507673263549805, acc: 0.625)
[2024-11-13 07:56:59,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:56:59,809][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 1.1476832628250122, acc: 0.698113203048706)
[2024-11-13 07:56:59,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:00,117][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.5526453256607056, acc: 0.8301886916160583)
[2024-11-13 07:57:00,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:00,416][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.864274263381958, acc: 0.7941176295280457)
[2024-11-13 07:57:00,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:00,765][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 1.1169270277023315, acc: 0.75)
[2024-11-13 07:57:00,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:01,117][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 1.006923794746399, acc: 0.6557376980781555)
[2024-11-13 07:57:01,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:01,446][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.4774969518184662, acc: 0.800000011920929)
[2024-11-13 07:57:01,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:01,765][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.4688214659690857, acc: 0.8947368264198303)
[2024-11-13 07:57:01,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:02,122][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 1.252505898475647, acc: 0.5797101259231567)
[2024-11-13 07:57:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:02,488][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 1.4082133769989014, acc: 0.625)
[2024-11-13 07:57:02,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:02,735][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 1.1418629884719849, acc: 0.6385542154312134)
[2024-11-13 07:57:02,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:03,041][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 1.7004519701004028, acc: 0.5)
[2024-11-13 07:57:03,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:03,420][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 1.6885159015655518, acc: 0.5306122303009033)
[2024-11-13 07:57:03,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:03,712][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.1987582892179489, acc: 0.9583333134651184)
[2024-11-13 07:57:03,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:04,035][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.7356278300285339, acc: 0.75)
[2024-11-13 07:57:04,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:04,360][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.5848209261894226, acc: 0.8387096524238586)
[2024-11-13 07:57:04,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:04,649][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 0.6050727367401123, acc: 0.8387096524238586)
[2024-11-13 07:57:04,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:04,961][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 1.1685900688171387, acc: 0.611940324306488)
[2024-11-13 07:57:05,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:05,279][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 1.2998961210250854, acc: 0.6442307829856873)
[2024-11-13 07:57:05,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:05,571][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 1.0232049226760864, acc: 0.6888889074325562)
[2024-11-13 07:57:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:05,907][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 1.3153197765350342, acc: 0.6290322542190552)
[2024-11-13 07:57:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:06,207][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.9096612334251404, acc: 0.7400000095367432)
[2024-11-13 07:57:06,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:06,529][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 1.2615530490875244, acc: 0.6296296119689941)
[2024-11-13 07:57:06,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:06,816][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 1.9634917974472046, acc: 0.4571428596973419)
[2024-11-13 07:57:06,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:07,092][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 1.2878822088241577, acc: 0.6410256624221802)
[2024-11-13 07:57:07,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:07,381][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.5678578615188599, acc: 0.6097561120986938)
[2024-11-13 07:57:07,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:07,674][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 1.2441825866699219, acc: 0.7105262875556946)
[2024-11-13 07:57:07,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:07,966][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.6152563095092773, acc: 0.7894737124443054)
[2024-11-13 07:57:08,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:08,240][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.42934635281562805, acc: 0.8928571343421936)
[2024-11-13 07:57:08,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:08,540][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 1.2458949089050293, acc: 0.7037037014961243)
[2024-11-13 07:57:08,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:08,893][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.5027930736541748, acc: 0.84375)
[2024-11-13 07:57:08,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:09,213][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 1.0843167304992676, acc: 0.7419354915618896)
[2024-11-13 07:57:09,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:09,546][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 1.0997278690338135, acc: 0.7017543911933899)
[2024-11-13 07:57:09,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:09,832][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 1.4524166584014893, acc: 0.625)
[2024-11-13 07:57:09,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:10,125][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.7059784531593323, acc: 0.7333333492279053)
[2024-11-13 07:57:10,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:10,437][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 1.0066274404525757, acc: 0.7368420958518982)
[2024-11-13 07:57:10,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:10,745][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 1.5772709846496582, acc: 0.5199999809265137)
[2024-11-13 07:57:10,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:11,048][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 1.9541667699813843, acc: 0.4597701132297516)
[2024-11-13 07:57:11,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:11,370][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 2.0888681411743164, acc: 0.478723406791687)
[2024-11-13 07:57:11,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:11,716][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 2.149860143661499, acc: 0.3855421543121338)
[2024-11-13 07:57:11,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:12,030][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.6526364684104919, acc: 0.8260869383811951)
[2024-11-13 07:57:12,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:12,311][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 1.1324492692947388, acc: 0.6410256624221802)
[2024-11-13 07:57:12,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:12,579][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 1.985060214996338, acc: 0.4337349534034729)
[2024-11-13 07:57:12,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:12,860][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 1.3996309041976929, acc: 0.6603773832321167)
[2024-11-13 07:57:12,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:13,136][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 1.401513934135437, acc: 0.6329113841056824)
[2024-11-13 07:57:13,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:13,452][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 1.1290581226348877, acc: 0.6470588445663452)
[2024-11-13 07:57:13,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:13,765][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 2.095878839492798, acc: 0.3731343150138855)
[2024-11-13 07:57:13,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:14,083][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.5301470756530762, acc: 0.8500000238418579)
[2024-11-13 07:57:14,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:14,414][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 1.056350588798523, acc: 0.6399999856948853)
[2024-11-13 07:57:14,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:14,745][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 1.1742368936538696, acc: 0.6944444179534912)
[2024-11-13 07:57:14,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:15,128][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 1.3962247371673584, acc: 0.5116279125213623)
[2024-11-13 07:57:15,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:15,493][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 1.0895087718963623, acc: 0.692307710647583)
[2024-11-13 07:57:15,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:15,848][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 1.3660860061645508, acc: 0.5777778029441833)
[2024-11-13 07:57:15,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:16,164][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.685691773891449, acc: 0.695652186870575)
[2024-11-13 07:57:16,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:16,502][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.9454236626625061, acc: 0.7307692170143127)
[2024-11-13 07:57:16,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:16,835][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 1.911146879196167, acc: 0.49450549483299255)
[2024-11-13 07:57:16,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:17,270][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 1.629401445388794, acc: 0.573913037776947)
[2024-11-13 07:57:17,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:17,593][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 1.504055380821228, acc: 0.554347813129425)
[2024-11-13 07:57:17,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:17,916][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 1.2686694860458374, acc: 0.6122449040412903)
[2024-11-13 07:57:17,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:18,152][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.1758643537759781, acc: 0.9583333134651184)
[2024-11-13 07:57:18,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:18,433][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.6094321012496948, acc: 0.692307710647583)
[2024-11-13 07:57:18,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:18,755][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.6131715774536133, acc: 0.7804877758026123)
[2024-11-13 07:57:18,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:19,098][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 1.055677890777588, acc: 0.7111111283302307)
[2024-11-13 07:57:19,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:19,469][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 1.3572142124176025, acc: 0.6447368264198303)
[2024-11-13 07:57:19,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:19,765][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 1.138419270515442, acc: 0.707317054271698)
[2024-11-13 07:57:19,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:20,056][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 1.1522990465164185, acc: 0.6363636255264282)
[2024-11-13 07:57:20,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:20,378][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.4261554181575775, acc: 0.8333333134651184)
[2024-11-13 07:57:20,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:20,679][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.17481468617916107, acc: 1.0)
[2024-11-13 07:57:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:21,010][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.5306786298751831, acc: 0.8214285969734192)
[2024-11-13 07:57:21,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:21,287][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.6866457462310791, acc: 0.78125)
[2024-11-13 07:57:21,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:21,762][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 1.4674274921417236, acc: 0.5939394235610962)
[2024-11-13 07:57:21,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:22,351][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 1.1994647979736328, acc: 0.7169811129570007)
[2024-11-13 07:57:22,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:22,696][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 1.1975339651107788, acc: 0.6222222447395325)
[2024-11-13 07:57:22,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:23,036][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 1.1839958429336548, acc: 0.6607142686843872)
[2024-11-13 07:57:23,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:23,333][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.6332012414932251, acc: 0.7428571581840515)
[2024-11-13 07:57:23,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:23,661][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.3416644036769867, acc: 0.8399999737739563)
[2024-11-13 07:57:23,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:23,979][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.5020149946212769, acc: 0.9130434989929199)
[2024-11-13 07:57:24,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:24,270][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 1.1108355522155762, acc: 0.7291666865348816)
[2024-11-13 07:57:24,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:24,561][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 1.256043553352356, acc: 0.7157894968986511)
[2024-11-13 07:57:24,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:25,014][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 1.4738445281982422, acc: 0.6467065811157227)
[2024-11-13 07:57:25,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:25,355][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 1.050942301750183, acc: 0.6842105388641357)
[2024-11-13 07:57:25,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:26,099][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 1.3759677410125732, acc: 0.5882353186607361)
[2024-11-13 07:57:26,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:26,538][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 1.0331557989120483, acc: 0.7297297120094299)
[2024-11-13 07:57:26,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:26,818][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.6955336928367615, acc: 0.8214285969734192)
[2024-11-13 07:57:26,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:27,121][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.39426562190055847, acc: 0.8571428656578064)
[2024-11-13 07:57:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:27,433][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 1.0250227451324463, acc: 0.8125)
[2024-11-13 07:57:27,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:27,742][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.7187016606330872, acc: 0.8333333134651184)
[2024-11-13 07:57:27,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:28,089][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.7823202013969421, acc: 0.7631579041481018)
[2024-11-13 07:57:28,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:28,459][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.3702253997325897, acc: 0.8636363744735718)
[2024-11-13 07:57:28,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:28,734][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.9848864674568176, acc: 0.6000000238418579)
[2024-11-13 07:57:28,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:29,081][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.5595871210098267, acc: 0.8095238208770752)
[2024-11-13 07:57:29,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:29,431][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 1.4720207452774048, acc: 0.6111111044883728)
[2024-11-13 07:57:29,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:29,815][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 1.8974790573120117, acc: 0.5436893105506897)
[2024-11-13 07:57:29,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:30,236][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 1.7723357677459717, acc: 0.5514705777168274)
[2024-11-13 07:57:30,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:30,640][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 1.8222938776016235, acc: 0.5)
[2024-11-13 07:57:30,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:31,026][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 1.99699068069458, acc: 0.4722222089767456)
[2024-11-13 07:57:31,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:31,330][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 1.0360356569290161, acc: 0.7209302186965942)
[2024-11-13 07:57:31,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:31,668][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.6267160773277283, acc: 0.8333333134651184)
[2024-11-13 07:57:31,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:31,993][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.8915706276893616, acc: 0.7674418687820435)
[2024-11-13 07:57:32,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:32,270][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.5589502453804016, acc: 0.800000011920929)
[2024-11-13 07:57:32,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:32,705][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 1.4185882806777954, acc: 0.6029411554336548)
[2024-11-13 07:57:32,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:33,012][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 1.3875116109848022, acc: 0.54666668176651)
[2024-11-13 07:57:33,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:33,342][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.8778761625289917, acc: 0.7272727489471436)
[2024-11-13 07:57:33,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:33,658][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.7116960883140564, acc: 0.8484848737716675)
[2024-11-13 07:57:33,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:34,003][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.5698651075363159, acc: 0.8387096524238586)
[2024-11-13 07:57:34,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:34,309][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.9681636095046997, acc: 0.7037037014961243)
[2024-11-13 07:57:34,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:34,542][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.5265253186225891, acc: 0.8799999952316284)
[2024-11-13 07:57:34,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:34,805][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.5583788156509399, acc: 0.8611111044883728)
[2024-11-13 07:57:34,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:35,185][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.5734331607818604, acc: 0.8518518805503845)
[2024-11-13 07:57:35,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:35,515][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.6182835102081299, acc: 0.807692289352417)
[2024-11-13 07:57:35,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:35,880][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.9718500375747681, acc: 0.7068965435028076)
[2024-11-13 07:57:35,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:36,196][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.4923742711544037, acc: 0.8214285969734192)
[2024-11-13 07:57:36,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:36,500][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.49251773953437805, acc: 0.8666666746139526)
[2024-11-13 07:57:36,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:36,831][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.7251254320144653, acc: 0.7878788113594055)
[2024-11-13 07:57:36,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:37,147][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.48152729868888855, acc: 0.8181818127632141)
[2024-11-13 07:57:37,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:37,519][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 1.4737670421600342, acc: 0.5882353186607361)
[2024-11-13 07:57:37,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:37,875][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 1.2399942874908447, acc: 0.6538461446762085)
[2024-11-13 07:57:37,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:38,208][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 1.420863389968872, acc: 0.6666666865348816)
[2024-11-13 07:57:38,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:38,551][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.9606369733810425, acc: 0.7250000238418579)
[2024-11-13 07:57:39,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:39,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:40,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:40,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:40,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:40,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:40,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:41,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:41,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:42,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:42,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:42,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:42,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:43,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:43,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:43,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:43,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:44,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:44,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:44,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:45,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:45,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:45,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:45,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:46,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:46,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:46,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:46,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:47,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:47,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:47,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:47,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:48,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:48,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:48,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:48,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:49,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:49,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:49,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:50,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:50,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:50,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:50,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:51,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:51,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:51,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:51,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:52,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:52,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:52,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:52,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:53,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:53,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:53,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:53,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:54,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:54,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:54,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:55,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:55,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:55,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:56,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:56,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:56,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:56,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:57,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:57,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:57,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:58,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:58,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:58,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:58,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:59,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:59,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:59,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:57:59,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:00,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:00,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:00,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:00,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:01,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:01,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:01,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:02,224][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.0184, device='cuda:0') eval_epoch_loss=tensor(2.0817, device='cuda:0') eval_epoch_acc=tensor(0.5299, device='cuda:0')
[2024-11-13 07:58:02,226][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:58:02,226][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:58:02,532][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_6_step_419_loss_2.081737518310547/model.pt
[2024-11-13 07:58:02,535][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:58:02,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:02,901][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.8786090612411499, acc: 0.75)
[2024-11-13 07:58:02,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:03,251][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.399238646030426, acc: 0.8571428656578064)
[2024-11-13 07:58:03,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:03,561][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.5968068838119507, acc: 0.8666666746139526)
[2024-11-13 07:58:03,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:03,888][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.4829925000667572, acc: 0.875)
[2024-11-13 07:58:03,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:04,249][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.6285269856452942, acc: 0.8333333134651184)
[2024-11-13 07:58:04,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:04,582][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.690070629119873, acc: 0.7777777910232544)
[2024-11-13 07:58:04,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:04,924][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.8379688858985901, acc: 0.8181818127632141)
[2024-11-13 07:58:05,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:05,261][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 1.3450937271118164, acc: 0.782608687877655)
[2024-11-13 07:58:05,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:05,580][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.7971116900444031, acc: 0.7297297120094299)
[2024-11-13 07:58:05,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:05,883][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.6100102066993713, acc: 0.7777777910232544)
[2024-11-13 07:58:05,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:06,198][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.5026189684867859, acc: 0.8260869383811951)
[2024-11-13 07:58:06,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:06,485][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.41433143615722656, acc: 0.8518518805503845)
[2024-11-13 07:58:06,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:06,788][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.5859380960464478, acc: 0.7777777910232544)
[2024-11-13 07:58:06,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:07,108][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.48190173506736755, acc: 0.8695651888847351)
[2024-11-13 07:58:07,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:07,463][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.7944387197494507, acc: 0.7222222089767456)
[2024-11-13 07:58:07,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:07,804][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.6976675391197205, acc: 0.8399999737739563)
[2024-11-13 07:58:07,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:08,119][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.791258692741394, acc: 0.7878788113594055)
[2024-11-13 07:58:08,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:08,490][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 1.1112505197525024, acc: 0.6666666865348816)
[2024-11-13 07:58:08,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:08,846][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.8025121092796326, acc: 0.7954545617103577)
[2024-11-13 07:58:08,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:09,220][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.3793577551841736, acc: 0.8095238208770752)
[2024-11-13 07:58:09,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:09,512][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 0.9443047642707825, acc: 0.692307710647583)
[2024-11-13 07:58:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:09,895][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 1.6072564125061035, acc: 0.5757575631141663)
[2024-11-13 07:58:10,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:10,402][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 2.178025245666504, acc: 0.4560000002384186)
[2024-11-13 07:58:10,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:10,789][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 2.126147508621216, acc: 0.5)
[2024-11-13 07:58:10,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:11,297][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 1.9219578504562378, acc: 0.5074626803398132)
[2024-11-13 07:58:11,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:11,610][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 1.3306574821472168, acc: 0.6415094137191772)
[2024-11-13 07:58:11,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:11,960][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.9596703052520752, acc: 0.6590909361839294)
[2024-11-13 07:58:12,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:12,229][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.7409990429878235, acc: 0.739130437374115)
[2024-11-13 07:58:12,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:12,516][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.8817952275276184, acc: 0.7307692170143127)
[2024-11-13 07:58:12,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:12,826][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.775927722454071, acc: 0.75)
[2024-11-13 07:58:12,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:13,141][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 1.501668095588684, acc: 0.611940324306488)
[2024-11-13 07:58:13,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:13,502][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 1.2542496919631958, acc: 0.6666666865348816)
[2024-11-13 07:58:13,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:13,865][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 1.3493645191192627, acc: 0.6086956262588501)
[2024-11-13 07:58:13,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:14,179][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 1.36329984664917, acc: 0.6025640964508057)
[2024-11-13 07:58:14,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:14,486][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 1.635337233543396, acc: 0.5)
[2024-11-13 07:58:14,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:14,818][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 1.2204456329345703, acc: 0.6734693646430969)
[2024-11-13 07:58:14,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:15,099][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.6717099547386169, acc: 0.8484848737716675)
[2024-11-13 07:58:15,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:15,419][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 1.7817243337631226, acc: 0.5051546096801758)
[2024-11-13 07:58:15,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:15,729][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 1.2287660837173462, acc: 0.6857143044471741)
[2024-11-13 07:58:15,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:16,053][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 1.6264160871505737, acc: 0.5465116500854492)
[2024-11-13 07:58:16,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:16,342][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 1.47687828540802, acc: 0.5535714030265808)
[2024-11-13 07:58:16,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:16,631][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 1.5909212827682495, acc: 0.5432098507881165)
[2024-11-13 07:58:16,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:16,951][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 1.1061291694641113, acc: 0.6388888955116272)
[2024-11-13 07:58:17,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:17,256][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.5705702900886536, acc: 0.90625)
[2024-11-13 07:58:17,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:17,547][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.7085946798324585, acc: 0.692307710647583)
[2024-11-13 07:58:17,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:17,846][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.9201212525367737, acc: 0.760869562625885)
[2024-11-13 07:58:17,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:18,133][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 1.4869104623794556, acc: 0.523809552192688)
[2024-11-13 07:58:18,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:18,456][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 1.3399744033813477, acc: 0.6144578456878662)
[2024-11-13 07:58:18,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:18,769][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 1.1788519620895386, acc: 0.630630612373352)
[2024-11-13 07:58:18,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:19,094][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 1.4343786239624023, acc: 0.6116504669189453)
[2024-11-13 07:58:19,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:19,416][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 1.2055145502090454, acc: 0.6585366129875183)
[2024-11-13 07:58:19,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:19,712][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.8131084442138672, acc: 0.7916666865348816)
[2024-11-13 07:58:19,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:20,013][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.7321538329124451, acc: 0.8214285969734192)
[2024-11-13 07:58:20,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:20,406][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 1.7134222984313965, acc: 0.4901960790157318)
[2024-11-13 07:58:20,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:20,738][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 2.0186123847961426, acc: 0.4585152864456177)
[2024-11-13 07:58:20,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:21,116][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 1.608019232749939, acc: 0.5729166865348816)
[2024-11-13 07:58:21,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:21,426][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 1.7552490234375, acc: 0.4907975494861603)
[2024-11-13 07:58:21,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:21,776][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 1.8639925718307495, acc: 0.4676258862018585)
[2024-11-13 07:58:21,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:22,102][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 2.0217185020446777, acc: 0.4422110617160797)
[2024-11-13 07:58:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:22,359][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.9045107364654541, acc: 0.6388888955116272)
[2024-11-13 07:58:22,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:22,685][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.9065714478492737, acc: 0.6363636255264282)
[2024-11-13 07:58:22,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:22,993][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.8332184553146362, acc: 0.7407407164573669)
[2024-11-13 07:58:23,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:23,333][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 1.0206187963485718, acc: 0.6499999761581421)
[2024-11-13 07:58:23,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:23,660][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.6451306343078613, acc: 0.800000011920929)
[2024-11-13 07:58:23,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:24,043][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 1.058611273765564, acc: 0.6551724076271057)
[2024-11-13 07:58:24,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:24,351][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.6148515939712524, acc: 0.8387096524238586)
[2024-11-13 07:58:24,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:24,635][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.6089522838592529, acc: 0.8947368264198303)
[2024-11-13 07:58:24,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:24,915][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 1.358096957206726, acc: 0.5185185074806213)
[2024-11-13 07:58:24,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:25,213][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 1.195050597190857, acc: 0.6190476417541504)
[2024-11-13 07:58:25,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:25,517][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 1.0152456760406494, acc: 0.5909090638160706)
[2024-11-13 07:58:25,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:25,847][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 1.578101396560669, acc: 0.5846154093742371)
[2024-11-13 07:58:25,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:26,140][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 1.048851490020752, acc: 0.699999988079071)
[2024-11-13 07:58:26,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:26,431][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 1.0005533695220947, acc: 0.6551724076271057)
[2024-11-13 07:58:26,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:26,736][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 1.5170820951461792, acc: 0.5686274766921997)
[2024-11-13 07:58:26,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:27,044][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 1.203792929649353, acc: 0.517241358757019)
[2024-11-13 07:58:27,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:27,324][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.5724925398826599, acc: 0.8421052694320679)
[2024-11-13 07:58:27,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:27,626][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 1.3570990562438965, acc: 0.5263158082962036)
[2024-11-13 07:58:27,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:27,977][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 1.3070274591445923, acc: 0.6517857313156128)
[2024-11-13 07:58:28,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:28,305][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 1.3324633836746216, acc: 0.6404494643211365)
[2024-11-13 07:58:28,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:28,597][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 1.6393696069717407, acc: 0.5393258333206177)
[2024-11-13 07:58:28,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:28,906][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 1.990405559539795, acc: 0.45390069484710693)
[2024-11-13 07:58:28,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:29,196][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 1.7412567138671875, acc: 0.489130437374115)
[2024-11-13 07:58:29,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:29,479][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.6300757527351379, acc: 0.7599999904632568)
[2024-11-13 07:58:29,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:29,752][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.551045298576355, acc: 0.7307692170143127)
[2024-11-13 07:58:29,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:30,037][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.6463030576705933, acc: 0.7407407164573669)
[2024-11-13 07:58:30,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:30,316][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 1.187121868133545, acc: 0.5925925970077515)
[2024-11-13 07:58:30,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:30,638][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.9917151927947998, acc: 0.6415094137191772)
[2024-11-13 07:58:30,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:30,928][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.8544617295265198, acc: 0.7586206793785095)
[2024-11-13 07:58:31,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:31,387][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.4650787115097046, acc: 0.6036036014556885)
[2024-11-13 07:58:31,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:31,744][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 1.242280125617981, acc: 0.7042253613471985)
[2024-11-13 07:58:31,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:32,011][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.687774658203125, acc: 0.75)
[2024-11-13 07:58:32,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:32,302][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.6000238656997681, acc: 0.8333333134651184)
[2024-11-13 07:58:32,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:32,613][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.5527923107147217, acc: 0.8461538553237915)
[2024-11-13 07:58:32,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:33,808][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 1.8248621225357056, acc: 0.5142857432365417)
[2024-11-13 07:58:33,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:34,359][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 1.498543620109558, acc: 0.5634920597076416)
[2024-11-13 07:58:34,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:34,630][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.75719153881073, acc: 0.75)
[2024-11-13 07:58:34,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:34,968][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 1.108376145362854, acc: 0.6666666865348816)
[2024-11-13 07:58:35,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:35,498][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 1.0744681358337402, acc: 0.7222222089767456)
[2024-11-13 07:58:35,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:35,759][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.3823760449886322, acc: 0.8461538553237915)
[2024-11-13 07:58:35,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:36,035][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.7929787039756775, acc: 0.8064516186714172)
[2024-11-13 07:58:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:36,333][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.8882116079330444, acc: 0.75)
[2024-11-13 07:58:36,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:36,619][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.8288043737411499, acc: 0.6296296119689941)
[2024-11-13 07:58:36,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:37,310][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 1.98241126537323, acc: 0.47033897042274475)
[2024-11-13 07:58:37,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:37,627][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 1.7137620449066162, acc: 0.5)
[2024-11-13 07:58:37,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:37,969][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 1.6479517221450806, acc: 0.5328466892242432)
[2024-11-13 07:58:38,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:38,406][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 1.897089958190918, acc: 0.5049999952316284)
[2024-11-13 07:58:38,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:38,688][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 1.6422951221466064, acc: 0.5740740895271301)
[2024-11-13 07:58:38,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:38,983][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 1.4207077026367188, acc: 0.5961538553237915)
[2024-11-13 07:58:39,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:39,263][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.9491377472877502, acc: 0.7142857313156128)
[2024-11-13 07:58:39,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:39,562][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 1.7482614517211914, acc: 0.49180328845977783)
[2024-11-13 07:58:39,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:39,837][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 1.4007630348205566, acc: 0.6610169410705566)
[2024-11-13 07:58:39,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:40,110][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 1.685989499092102, acc: 0.5581395626068115)
[2024-11-13 07:58:40,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:40,410][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 1.0355490446090698, acc: 0.7045454382896423)
[2024-11-13 07:58:40,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:40,706][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 1.541931390762329, acc: 0.5660377144813538)
[2024-11-13 07:58:40,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:41,001][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 1.1038775444030762, acc: 0.6590909361839294)
[2024-11-13 07:58:41,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:41,282][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.7464653253555298, acc: 0.8399999737739563)
[2024-11-13 07:58:41,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:41,600][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.6120397448539734, acc: 0.8500000238418579)
[2024-11-13 07:58:41,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:41,913][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.49686527252197266, acc: 0.8181818127632141)
[2024-11-13 07:58:42,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:42,248][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 1.318084716796875, acc: 0.6769230961799622)
[2024-11-13 07:58:42,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:42,536][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 1.2300056219100952, acc: 0.65625)
[2024-11-13 07:58:42,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:42,868][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.9469579458236694, acc: 0.75)
[2024-11-13 07:58:42,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:43,150][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.8925465941429138, acc: 0.7272727489471436)
[2024-11-13 07:58:43,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:43,427][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.658537745475769, acc: 0.8125)
[2024-11-13 07:58:43,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:43,709][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.5050786733627319, acc: 0.8387096524238586)
[2024-11-13 07:58:43,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:44,001][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.3003091812133789, acc: 0.9130434989929199)
[2024-11-13 07:58:44,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:44,300][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.9555334448814392, acc: 0.699999988079071)
[2024-11-13 07:58:44,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:44,660][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 1.0143479108810425, acc: 0.6341463327407837)
[2024-11-13 07:58:44,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:44,962][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.565832793712616, acc: 0.800000011920929)
[2024-11-13 07:58:45,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:45,260][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.6976633667945862, acc: 0.8421052694320679)
[2024-11-13 07:58:45,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:45,568][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.675845742225647, acc: 0.7419354915618896)
[2024-11-13 07:58:45,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:45,875][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.40382906794548035, acc: 0.8399999737739563)
[2024-11-13 07:58:45,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:46,169][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.561401903629303, acc: 0.8484848737716675)
[2024-11-13 07:58:46,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:46,457][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.6048673987388611, acc: 0.824999988079071)
[2024-11-13 07:58:46,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:46,756][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.9341844916343689, acc: 0.7142857313156128)
[2024-11-13 07:58:46,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:47,065][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 1.7181228399276733, acc: 0.5328466892242432)
[2024-11-13 07:58:47,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:47,358][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 1.456247329711914, acc: 0.5931034684181213)
[2024-11-13 07:58:47,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:47,655][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 2.0055553913116455, acc: 0.4714285731315613)
[2024-11-13 07:58:47,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:47,954][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 1.7459336519241333, acc: 0.443708598613739)
[2024-11-13 07:58:48,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:48,243][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 1.301187515258789, acc: 0.6153846383094788)
[2024-11-13 07:58:48,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:48,525][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.30183884501457214, acc: 0.9200000166893005)
[2024-11-13 07:58:48,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:48,795][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.472200870513916, acc: 0.8461538553237915)
[2024-11-13 07:58:48,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:49,076][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.46084749698638916, acc: 0.807692289352417)
[2024-11-13 07:58:49,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:49,364][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.784547746181488, acc: 0.7948718070983887)
[2024-11-13 07:58:50,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:50,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:50,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:50,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:51,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:51,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:51,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:51,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:52,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:52,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:52,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:53,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:53,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:53,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:53,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:54,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:54,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:54,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:54,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:55,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:55,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:55,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:55,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:56,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:56,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:56,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:56,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:57,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:57,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:57,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:57,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:58,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:58,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:58,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:59,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:59,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:59,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:58:59,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:00,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:00,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:00,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:00,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:01,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:01,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:01,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:01,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:02,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:02,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:02,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:02,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:03,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:03,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:03,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:03,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:04,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:04,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:04,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:04,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:05,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:05,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:05,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:05,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:06,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:06,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:06,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:07,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:07,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:07,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:08,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:08,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:08,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:08,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:09,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:09,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:09,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:09,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:10,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:10,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:10,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:10,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:11,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:11,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:11,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:12,253][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.8587, device='cuda:0') eval_epoch_loss=tensor(2.0616, device='cuda:0') eval_epoch_acc=tensor(0.5179, device='cuda:0')
[2024-11-13 07:59:12,255][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 07:59:12,255][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 07:59:12,565][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_6_step_562_loss_2.061615467071533/model.pt
[2024-11-13 07:59:12,568][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 07:59:12,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:12,910][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 1.0903490781784058, acc: 0.6555555462837219)
[2024-11-13 07:59:12,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:13,187][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.9511916637420654, acc: 0.7142857313156128)
[2024-11-13 07:59:13,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:13,461][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.7604146003723145, acc: 0.8125)
[2024-11-13 07:59:13,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:13,755][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.7305271029472351, acc: 0.7758620977401733)
[2024-11-13 07:59:13,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:14,061][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 1.0229822397232056, acc: 0.7023809552192688)
[2024-11-13 07:59:14,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:14,376][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.5843535661697388, acc: 0.7894737124443054)
[2024-11-13 07:59:14,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:14,663][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.47220495343208313, acc: 0.8148148059844971)
[2024-11-13 07:59:14,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:14,990][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 1.5408480167388916, acc: 0.5668449401855469)
[2024-11-13 07:59:15,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:15,262][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.9865129590034485, acc: 0.6935483813285828)
[2024-11-13 07:59:15,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:15,543][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 1.140076994895935, acc: 0.6752136945724487)
[2024-11-13 07:59:15,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:15,833][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 2.0023903846740723, acc: 0.4591836631298065)
[2024-11-13 07:59:15,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:16,147][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 1.8179161548614502, acc: 0.49056604504585266)
[2024-11-13 07:59:16,498][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=3.1915, train_epoch_loss=1.1605, epoch time 291.30129263177514s
[2024-11-13 07:59:16,499][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 07:59:16,499][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 07:59:16,499][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 07:59:16,499][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 07:59:16,499][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 07:59:16,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:17,316][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.6834172010421753, acc: 0.7777777910232544)
[2024-11-13 07:59:17,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:17,604][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.7351238131523132, acc: 0.8399999737739563)
[2024-11-13 07:59:17,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:17,922][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 1.326402187347412, acc: 0.5945945978164673)
[2024-11-13 07:59:17,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:18,220][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 1.203904151916504, acc: 0.5789473652839661)
[2024-11-13 07:59:18,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:18,519][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 1.0315788984298706, acc: 0.6756756901741028)
[2024-11-13 07:59:18,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:18,828][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 1.141861081123352, acc: 0.5714285969734192)
[2024-11-13 07:59:18,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:19,140][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 1.4626035690307617, acc: 0.5918367505073547)
[2024-11-13 07:59:19,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:19,427][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.8455639481544495, acc: 0.7666666507720947)
[2024-11-13 07:59:19,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:19,738][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.30177855491638184, acc: 0.9090909361839294)
[2024-11-13 07:59:19,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:20,044][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.2916921377182007, acc: 0.9230769276618958)
[2024-11-13 07:59:20,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:20,374][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.5576380491256714, acc: 0.7407407164573669)
[2024-11-13 07:59:20,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:20,606][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 1.0294502973556519, acc: 0.692307710647583)
[2024-11-13 07:59:20,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:20,896][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.9226601123809814, acc: 0.7878788113594055)
[2024-11-13 07:59:20,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:21,194][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.9909440875053406, acc: 0.695652186870575)
[2024-11-13 07:59:21,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:21,528][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 1.233361005783081, acc: 0.6078431606292725)
[2024-11-13 07:59:21,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:21,848][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 1.0725117921829224, acc: 0.6326530575752258)
[2024-11-13 07:59:21,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:22,151][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.36581671237945557, acc: 0.8421052694320679)
[2024-11-13 07:59:22,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:22,508][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.731480598449707, acc: 0.75)
[2024-11-13 07:59:22,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:22,820][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 1.0325114727020264, acc: 0.7222222089767456)
[2024-11-13 07:59:22,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:23,113][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.6735994815826416, acc: 0.7368420958518982)
[2024-11-13 07:59:23,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:23,431][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.7503109574317932, acc: 0.807692289352417)
[2024-11-13 07:59:23,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:23,740][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.9543457627296448, acc: 0.7241379022598267)
[2024-11-13 07:59:23,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:24,061][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.8821063041687012, acc: 0.800000011920929)
[2024-11-13 07:59:24,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:24,372][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.3868514597415924, acc: 0.8571428656578064)
[2024-11-13 07:59:24,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:24,675][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.5400042533874512, acc: 0.75)
[2024-11-13 07:59:24,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:24,983][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 1.2716319561004639, acc: 0.6415094137191772)
[2024-11-13 07:59:25,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:25,296][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 1.5701467990875244, acc: 0.5205479264259338)
[2024-11-13 07:59:25,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:26,027][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 2.087347984313965, acc: 0.4584980309009552)
[2024-11-13 07:59:26,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:26,333][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.8884997963905334, acc: 0.6744186282157898)
[2024-11-13 07:59:26,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:26,654][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 1.4158257246017456, acc: 0.5783132314682007)
[2024-11-13 07:59:26,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:26,892][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 1.3930463790893555, acc: 0.5679012537002563)
[2024-11-13 07:59:26,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:27,177][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.5918444395065308, acc: 0.8214285969734192)
[2024-11-13 07:59:27,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:27,463][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.5584984421730042, acc: 0.7777777910232544)
[2024-11-13 07:59:27,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:27,742][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.5535568594932556, acc: 0.8695651888847351)
[2024-11-13 07:59:27,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:28,046][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 1.9127899408340454, acc: 0.4957983195781708)
[2024-11-13 07:59:28,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:28,365][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 1.3279597759246826, acc: 0.6721311211585999)
[2024-11-13 07:59:28,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:28,682][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 1.5416821241378784, acc: 0.5396825671195984)
[2024-11-13 07:59:28,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:28,985][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 1.6276787519454956, acc: 0.49152541160583496)
[2024-11-13 07:59:29,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:29,321][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 1.2351092100143433, acc: 0.5862069129943848)
[2024-11-13 07:59:29,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:29,622][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.6434612274169922, acc: 0.761904776096344)
[2024-11-13 07:59:29,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:29,925][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.7538080811500549, acc: 0.7692307829856873)
[2024-11-13 07:59:30,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:30,289][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 1.7864755392074585, acc: 0.5135135054588318)
[2024-11-13 07:59:30,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:30,610][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 1.4524939060211182, acc: 0.5538461804389954)
[2024-11-13 07:59:30,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:30,954][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 1.8022233247756958, acc: 0.5252525210380554)
[2024-11-13 07:59:31,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:31,317][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 1.4224029779434204, acc: 0.5876288414001465)
[2024-11-13 07:59:31,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:31,669][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 1.8270111083984375, acc: 0.4779411852359772)
[2024-11-13 07:59:31,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:31,969][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.6481974124908447, acc: 0.7307692170143127)
[2024-11-13 07:59:32,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:32,304][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.45812132954597473, acc: 0.8518518805503845)
[2024-11-13 07:59:32,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:32,599][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.9863496422767639, acc: 0.7142857313156128)
[2024-11-13 07:59:32,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:32,912][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.6303048133850098, acc: 0.8055555820465088)
[2024-11-13 07:59:32,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:33,210][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 1.0699108839035034, acc: 0.7368420958518982)
[2024-11-13 07:59:33,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:33,564][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.9955088496208191, acc: 0.682539701461792)
[2024-11-13 07:59:33,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:33,915][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 1.5257930755615234, acc: 0.5492957830429077)
[2024-11-13 07:59:34,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:34,294][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.7964109182357788, acc: 0.5266666412353516)
[2024-11-13 07:59:34,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:34,612][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.7479454278945923, acc: 0.8108108043670654)
[2024-11-13 07:59:34,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:34,932][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.5210300087928772, acc: 0.8846153616905212)
[2024-11-13 07:59:35,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:36,235][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 1.6504396200180054, acc: 0.5870307087898254)
[2024-11-13 07:59:36,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:37,046][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 2.2081267833709717, acc: 0.4313725531101227)
[2024-11-13 07:59:37,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:37,566][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 1.7408363819122314, acc: 0.5625)
[2024-11-13 07:59:37,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:38,015][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 1.7101718187332153, acc: 0.5514705777168274)
[2024-11-13 07:59:38,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:38,461][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 1.8460054397583008, acc: 0.4492753744125366)
[2024-11-13 07:59:38,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:38,824][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 1.3812475204467773, acc: 0.675000011920929)
[2024-11-13 07:59:38,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:39,171][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.5532775521278381, acc: 0.7941176295280457)
[2024-11-13 07:59:39,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:39,515][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 1.2386177778244019, acc: 0.6388888955116272)
[2024-11-13 07:59:39,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:39,894][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.8540735840797424, acc: 0.734375)
[2024-11-13 07:59:39,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:40,219][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.5890032649040222, acc: 0.7931034564971924)
[2024-11-13 07:59:40,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:40,571][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 1.278859257698059, acc: 0.6071428656578064)
[2024-11-13 07:59:40,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:40,933][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 1.5236594676971436, acc: 0.5666666626930237)
[2024-11-13 07:59:41,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:41,281][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.5215676426887512, acc: 0.7599999904632568)
[2024-11-13 07:59:41,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:41,592][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.8148545026779175, acc: 0.7222222089767456)
[2024-11-13 07:59:41,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:41,928][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.9037041068077087, acc: 0.7272727489471436)
[2024-11-13 07:59:41,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:42,232][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 1.8061801195144653, acc: 0.5441176295280457)
[2024-11-13 07:59:42,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:42,588][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 1.574486494064331, acc: 0.5476190447807312)
[2024-11-13 07:59:42,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:42,978][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 1.9030841588974, acc: 0.46666666865348816)
[2024-11-13 07:59:43,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:43,338][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 1.3668116331100464, acc: 0.6020408272743225)
[2024-11-13 07:59:43,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:43,657][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 2.025362730026245, acc: 0.4776119291782379)
[2024-11-13 07:59:43,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:44,002][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 2.0124549865722656, acc: 0.4562043845653534)
[2024-11-13 07:59:44,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:44,319][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.36801794171333313, acc: 0.8571428656578064)
[2024-11-13 07:59:44,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:44,640][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.30660274624824524, acc: 0.9166666865348816)
[2024-11-13 07:59:44,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:44,949][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.5854739546775818, acc: 0.7878788113594055)
[2024-11-13 07:59:45,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:45,326][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.5374363660812378, acc: 0.8461538553237915)
[2024-11-13 07:59:45,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:45,676][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 1.0843042135238647, acc: 0.6730769276618958)
[2024-11-13 07:59:45,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:46,041][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 1.3251622915267944, acc: 0.6153846383094788)
[2024-11-13 07:59:46,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:46,387][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.7692165374755859, acc: 0.71875)
[2024-11-13 07:59:46,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:46,710][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 1.2349740266799927, acc: 0.5797101259231567)
[2024-11-13 07:59:46,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:47,005][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.9662342667579651, acc: 0.699999988079071)
[2024-11-13 07:59:47,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:47,360][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.8429983258247375, acc: 0.8260869383811951)
[2024-11-13 07:59:47,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:47,766][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 1.17500901222229, acc: 0.6000000238418579)
[2024-11-13 07:59:47,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:48,166][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 1.298277497291565, acc: 0.6213592290878296)
[2024-11-13 07:59:48,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:48,891][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 1.7230260372161865, acc: 0.5631067752838135)
[2024-11-13 07:59:49,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:49,507][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.7443480491638184, acc: 0.5)
[2024-11-13 07:59:49,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:50,097][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 1.7044553756713867, acc: 0.5818965435028076)
[2024-11-13 07:59:50,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:50,666][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 1.1388911008834839, acc: 0.6105263233184814)
[2024-11-13 07:59:50,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:51,360][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 1.7173643112182617, acc: 0.5643564462661743)
[2024-11-13 07:59:51,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:51,725][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 1.339206576347351, acc: 0.5806451439857483)
[2024-11-13 07:59:51,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:52,082][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 1.1571460962295532, acc: 0.6521739363670349)
[2024-11-13 07:59:52,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:52,442][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 1.7230745553970337, acc: 0.4789915978908539)
[2024-11-13 07:59:52,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:52,818][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 1.729175090789795, acc: 0.5096153616905212)
[2024-11-13 07:59:52,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:53,205][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 1.7683448791503906, acc: 0.48905110359191895)
[2024-11-13 07:59:53,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:53,505][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 1.3548805713653564, acc: 0.5373134613037109)
[2024-11-13 07:59:53,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:53,829][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.3697482943534851, acc: 0.949999988079071)
[2024-11-13 07:59:53,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:54,195][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.31463873386383057, acc: 0.9545454382896423)
[2024-11-13 07:59:54,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:54,586][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.32549285888671875, acc: 0.8695651888847351)
[2024-11-13 07:59:54,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:54,888][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.7268084287643433, acc: 0.7727272510528564)
[2024-11-13 07:59:54,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:55,204][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 1.3327391147613525, acc: 0.5862069129943848)
[2024-11-13 07:59:55,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:55,543][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.5815656781196594, acc: 0.7906976938247681)
[2024-11-13 07:59:55,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:55,876][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.6581403613090515, acc: 0.8399999737739563)
[2024-11-13 07:59:55,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:56,203][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.08213020861148834, acc: 1.0)
[2024-11-13 07:59:56,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:56,539][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.15391424298286438, acc: 0.9615384340286255)
[2024-11-13 07:59:56,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:56,857][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.5967473983764648, acc: 0.8095238208770752)
[2024-11-13 07:59:56,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:57,168][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 1.0850449800491333, acc: 0.7230769395828247)
[2024-11-13 07:59:57,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:57,541][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 1.2471106052398682, acc: 0.6140350699424744)
[2024-11-13 07:59:57,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:57,906][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.9730235934257507, acc: 0.7017543911933899)
[2024-11-13 07:59:57,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:58,255][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 1.0977205038070679, acc: 0.6666666865348816)
[2024-11-13 07:59:58,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:58,600][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 1.0014351606369019, acc: 0.7142857313156128)
[2024-11-13 07:59:58,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:58,905][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.25234124064445496, acc: 0.9090909361839294)
[2024-11-13 07:59:58,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:59,258][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 1.283789038658142, acc: 0.60317462682724)
[2024-11-13 07:59:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:59,621][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 1.5215932130813599, acc: 0.6016260385513306)
[2024-11-13 07:59:59,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 07:59:59,955][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.9565129280090332, acc: 0.7419354915618896)
[2024-11-13 08:00:00,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:00,579][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 1.8813817501068115, acc: 0.5019011497497559)
[2024-11-13 08:00:00,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:00,896][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 1.126530408859253, acc: 0.6399999856948853)
[2024-11-13 08:00:00,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:01,231][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.9322182536125183, acc: 0.75)
[2024-11-13 08:00:01,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:01,535][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.4797404110431671, acc: 0.8333333134651184)
[2024-11-13 08:00:01,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:01,808][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.7403733730316162, acc: 0.7894737124443054)
[2024-11-13 08:00:01,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:02,179][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 1.7666068077087402, acc: 0.5214723944664001)
[2024-11-13 08:00:02,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:02,580][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 1.5622928142547607, acc: 0.5972222089767456)
[2024-11-13 08:00:02,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:02,896][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 1.7492097616195679, acc: 0.4833333194255829)
[2024-11-13 08:00:02,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:03,264][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 1.8082081079483032, acc: 0.4702380895614624)
[2024-11-13 08:00:03,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:03,617][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 1.634290337562561, acc: 0.5128205418586731)
[2024-11-13 08:00:03,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:03,998][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 1.4611520767211914, acc: 0.6029411554336548)
[2024-11-13 08:00:04,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:04,369][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.8960925340652466, acc: 0.7692307829856873)
[2024-11-13 08:00:05,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:05,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:05,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:05,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:06,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:06,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:06,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:07,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:07,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:07,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:07,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:08,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:08,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:08,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:08,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:09,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:09,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:09,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:09,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:10,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:10,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:10,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:11,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:11,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:11,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:11,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:12,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:12,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:12,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:12,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:13,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:13,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:13,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:13,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:14,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:14,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:14,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:14,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:15,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:15,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:15,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:16,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:16,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:16,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:16,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:17,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:17,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:17,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:18,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:18,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:18,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:18,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:19,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:19,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:19,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:19,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:20,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:20,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:20,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:20,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:21,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:21,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:21,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:21,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:22,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:22,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:22,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:22,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:23,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:23,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:23,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:24,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:24,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:24,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:24,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:25,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:25,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:25,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:25,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:26,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:26,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:26,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:26,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:27,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:27,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:28,259][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.0375, device='cuda:0') eval_epoch_loss=tensor(1.9513, device='cuda:0') eval_epoch_acc=tensor(0.5184, device='cuda:0')
[2024-11-13 08:00:28,261][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:00:28,261][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:00:28,592][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_7_step_131_loss_1.9512584209442139/model.pt
[2024-11-13 08:00:28,595][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:00:28,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:28,911][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.34574493765830994, acc: 0.9130434989929199)
[2024-11-13 08:00:28,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:29,208][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.5779808163642883, acc: 0.84375)
[2024-11-13 08:00:29,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:29,484][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.8548744320869446, acc: 0.739130437374115)
[2024-11-13 08:00:29,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:29,822][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 1.0174897909164429, acc: 0.6571428775787354)
[2024-11-13 08:00:29,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:30,114][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.4382839798927307, acc: 0.807692289352417)
[2024-11-13 08:00:30,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:30,406][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 1.0809767246246338, acc: 0.6904761791229248)
[2024-11-13 08:00:30,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:30,755][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 1.049392819404602, acc: 0.6333333253860474)
[2024-11-13 08:00:30,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:31,073][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.7102918028831482, acc: 0.739130437374115)
[2024-11-13 08:00:31,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:31,385][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.7551038265228271, acc: 0.761904776096344)
[2024-11-13 08:00:31,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:31,709][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.839237630367279, acc: 0.7692307829856873)
[2024-11-13 08:00:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:32,026][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 1.0318564176559448, acc: 0.7096773982048035)
[2024-11-13 08:00:32,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:32,325][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 1.254024863243103, acc: 0.5945945978164673)
[2024-11-13 08:00:32,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:32,753][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 1.6267002820968628, acc: 0.5)
[2024-11-13 08:00:32,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:33,068][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 1.508441686630249, acc: 0.5597015023231506)
[2024-11-13 08:00:33,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:33,382][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 1.99700129032135, acc: 0.4591836631298065)
[2024-11-13 08:00:33,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:33,747][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 1.8372483253479004, acc: 0.40425533056259155)
[2024-11-13 08:00:33,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:34,029][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 1.446703314781189, acc: 0.6000000238418579)
[2024-11-13 08:00:34,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:34,309][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 1.6357543468475342, acc: 0.6071428656578064)
[2024-11-13 08:00:34,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:34,582][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.8456260561943054, acc: 0.6086956262588501)
[2024-11-13 08:00:34,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:34,866][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.8468105792999268, acc: 0.6896551847457886)
[2024-11-13 08:00:34,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:35,165][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 1.4608967304229736, acc: 0.5652173757553101)
[2024-11-13 08:00:35,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:35,472][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 1.7206284999847412, acc: 0.4406779706478119)
[2024-11-13 08:00:35,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:35,749][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 1.743445634841919, acc: 0.5087719559669495)
[2024-11-13 08:00:35,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:36,050][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 1.377887487411499, acc: 0.6486486196517944)
[2024-11-13 08:00:36,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:36,335][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 1.014700174331665, acc: 0.6428571343421936)
[2024-11-13 08:00:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:36,682][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 1.0349433422088623, acc: 0.6521739363670349)
[2024-11-13 08:00:36,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:37,007][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.5551989078521729, acc: 0.8421052694320679)
[2024-11-13 08:00:37,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:37,864][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 1.1039568185806274, acc: 0.6351351141929626)
[2024-11-13 08:00:37,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:38,125][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 1.4055145978927612, acc: 0.5925925970077515)
[2024-11-13 08:00:38,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:38,463][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 1.1252115964889526, acc: 0.6279069781303406)
[2024-11-13 08:00:38,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:38,906][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 1.0045644044876099, acc: 0.6941176652908325)
[2024-11-13 08:00:39,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:39,342][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 1.647705078125, acc: 0.584269642829895)
[2024-11-13 08:00:39,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:39,663][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.8431901931762695, acc: 0.8181818127632141)
[2024-11-13 08:00:39,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:39,966][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.7008967995643616, acc: 0.8095238208770752)
[2024-11-13 08:00:40,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:40,303][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 1.122490406036377, acc: 0.7241379022598267)
[2024-11-13 08:00:40,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:40,601][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 1.0318732261657715, acc: 0.6326530575752258)
[2024-11-13 08:00:40,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:40,891][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 1.0661221742630005, acc: 0.699999988079071)
[2024-11-13 08:00:40,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:41,202][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 1.260040283203125, acc: 0.6527777910232544)
[2024-11-13 08:00:41,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:41,543][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 1.4443670511245728, acc: 0.6176470518112183)
[2024-11-13 08:00:41,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:42,259][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 2.0727663040161133, acc: 0.4726027250289917)
[2024-11-13 08:00:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:42,536][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.6489079594612122, acc: 0.7916666865348816)
[2024-11-13 08:00:42,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:42,791][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.9594517946243286, acc: 0.7777777910232544)
[2024-11-13 08:00:42,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:43,067][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.8461286425590515, acc: 0.6785714030265808)
[2024-11-13 08:00:43,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:43,502][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 1.409335732460022, acc: 0.6017699241638184)
[2024-11-13 08:00:43,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:43,779][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 1.0796962976455688, acc: 0.6811594367027283)
[2024-11-13 08:00:43,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:44,042][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 1.3641620874404907, acc: 0.625)
[2024-11-13 08:00:44,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:44,678][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 1.9891481399536133, acc: 0.47328245639801025)
[2024-11-13 08:00:44,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:45,176][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 1.8038345575332642, acc: 0.5037037134170532)
[2024-11-13 08:00:45,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:45,454][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 1.0715692043304443, acc: 0.6721311211585999)
[2024-11-13 08:00:45,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:45,728][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.39034509658813477, acc: 0.875)
[2024-11-13 08:00:45,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:45,974][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.8420560956001282, acc: 0.7599999904632568)
[2024-11-13 08:00:46,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:46,243][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.7851074934005737, acc: 0.75)
[2024-11-13 08:00:46,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:46,531][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 1.4536250829696655, acc: 0.5487805008888245)
[2024-11-13 08:00:46,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:46,869][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 1.963057518005371, acc: 0.47129908204078674)
[2024-11-13 08:00:46,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:47,170][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 2.10386061668396, acc: 0.4495677351951599)
[2024-11-13 08:00:47,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:47,564][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 2.1649508476257324, acc: 0.4281249940395355)
[2024-11-13 08:00:47,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:48,009][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 2.088557481765747, acc: 0.4333958625793457)
[2024-11-13 08:00:48,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:48,354][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 1.955029010772705, acc: 0.4483985900878906)
[2024-11-13 08:00:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:48,658][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.6504952311515808, acc: 0.8399999737739563)
[2024-11-13 08:00:48,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:49,084][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 1.9456379413604736, acc: 0.4651162922382355)
[2024-11-13 08:00:49,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:49,649][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.6176470518112183, acc: 0.5555555820465088)
[2024-11-13 08:00:49,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:50,275][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 1.673202395439148, acc: 0.5075757503509521)
[2024-11-13 08:00:50,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:50,811][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 1.3778953552246094, acc: 0.6235294342041016)
[2024-11-13 08:00:50,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:51,532][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 1.4320640563964844, acc: 0.5925925970077515)
[2024-11-13 08:00:51,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:52,182][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 1.1140265464782715, acc: 0.725806474685669)
[2024-11-13 08:00:52,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:52,449][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.554128110408783, acc: 0.8571428656578064)
[2024-11-13 08:00:52,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:52,721][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.8396776914596558, acc: 0.7749999761581421)
[2024-11-13 08:00:52,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:53,013][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 1.2147101163864136, acc: 0.6470588445663452)
[2024-11-13 08:00:53,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:53,303][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 1.5468193292617798, acc: 0.5220588445663452)
[2024-11-13 08:00:53,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:53,605][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 1.6059867143630981, acc: 0.5677965879440308)
[2024-11-13 08:00:53,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:53,922][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 1.8348520994186401, acc: 0.49253731966018677)
[2024-11-13 08:00:54,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:54,293][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 1.653958797454834, acc: 0.5436893105506897)
[2024-11-13 08:00:54,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:54,590][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 1.2397844791412354, acc: 0.6349206566810608)
[2024-11-13 08:00:54,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:54,902][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 1.352745771408081, acc: 0.6483516693115234)
[2024-11-13 08:00:54,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:55,225][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 1.8041075468063354, acc: 0.5067264437675476)
[2024-11-13 08:00:55,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:55,570][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 1.7890397310256958, acc: 0.5314960479736328)
[2024-11-13 08:00:55,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:55,907][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 1.6725844144821167, acc: 0.49568966031074524)
[2024-11-13 08:00:55,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:56,221][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 1.7043476104736328, acc: 0.5398550629615784)
[2024-11-13 08:00:56,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:56,599][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 1.9129167795181274, acc: 0.4280155599117279)
[2024-11-13 08:00:56,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:56,934][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 1.6702007055282593, acc: 0.510869562625885)
[2024-11-13 08:00:56,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:57,216][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.8631190657615662, acc: 0.739130437374115)
[2024-11-13 08:00:57,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:57,542][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.6600707173347473, acc: 0.7857142686843872)
[2024-11-13 08:00:57,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:57,851][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.6891456246376038, acc: 0.7872340679168701)
[2024-11-13 08:00:57,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:58,348][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 1.3260396718978882, acc: 0.6153846383094788)
[2024-11-13 08:00:58,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:58,632][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 1.1461189985275269, acc: 0.6891891956329346)
[2024-11-13 08:00:58,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:58,927][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 1.066330909729004, acc: 0.6627907156944275)
[2024-11-13 08:00:59,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:59,338][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 1.2165240049362183, acc: 0.6756756901741028)
[2024-11-13 08:00:59,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:59,638][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 1.1362054347991943, acc: 0.6333333253860474)
[2024-11-13 08:00:59,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:00:59,922][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.46738964319229126, acc: 0.8787878751754761)
[2024-11-13 08:00:59,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:00,189][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.3699814975261688, acc: 0.8518518805503845)
[2024-11-13 08:01:00,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:00,502][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.3927517235279083, acc: 0.8399999737739563)
[2024-11-13 08:01:00,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:00,837][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 0.9104207158088684, acc: 0.692307710647583)
[2024-11-13 08:01:00,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:01,389][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 1.3764007091522217, acc: 0.592391312122345)
[2024-11-13 08:01:01,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:01,814][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 1.5805816650390625, acc: 0.5795454382896423)
[2024-11-13 08:01:01,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:02,180][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 1.4139786958694458, acc: 0.542553186416626)
[2024-11-13 08:01:02,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:02,498][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.7696999311447144, acc: 0.7735849022865295)
[2024-11-13 08:01:02,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:02,795][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.956925630569458, acc: 0.699999988079071)
[2024-11-13 08:01:02,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:03,097][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.459989458322525, acc: 0.8372092843055725)
[2024-11-13 08:01:03,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:03,413][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 0.5703935027122498, acc: 0.8666666746139526)
[2024-11-13 08:01:03,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:03,742][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 1.4301462173461914, acc: 0.557894766330719)
[2024-11-13 08:01:03,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:04,062][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 0.989764928817749, acc: 0.6777777671813965)
[2024-11-13 08:01:04,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:04,404][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 0.9891331195831299, acc: 0.7222222089767456)
[2024-11-13 08:01:04,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:04,801][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 1.552605152130127, acc: 0.6009174585342407)
[2024-11-13 08:01:04,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:05,174][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 0.9300839304924011, acc: 0.7230769395828247)
[2024-11-13 08:01:05,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:05,439][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.8214383721351624, acc: 0.6842105388641357)
[2024-11-13 08:01:05,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:05,708][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.6128301620483398, acc: 0.8333333134651184)
[2024-11-13 08:01:05,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:05,993][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.9994552135467529, acc: 0.7727272510528564)
[2024-11-13 08:01:06,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:06,277][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.9066406488418579, acc: 0.7777777910232544)
[2024-11-13 08:01:06,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:06,591][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.556114912033081, acc: 0.800000011920929)
[2024-11-13 08:01:06,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:06,946][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.8456227779388428, acc: 0.7045454382896423)
[2024-11-13 08:01:07,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:07,298][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.7131885886192322, acc: 0.7954545617103577)
[2024-11-13 08:01:07,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:07,748][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 1.2937260866165161, acc: 0.5483871102333069)
[2024-11-13 08:01:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:08,153][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.9211137294769287, acc: 0.6818181872367859)
[2024-11-13 08:01:08,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:08,422][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.17945387959480286, acc: 0.9523809552192688)
[2024-11-13 08:01:08,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:08,699][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.49981430172920227, acc: 0.7692307829856873)
[2024-11-13 08:01:08,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:08,996][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.49557942152023315, acc: 0.8709677457809448)
[2024-11-13 08:01:09,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:09,298][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.557294487953186, acc: 0.800000011920929)
[2024-11-13 08:01:09,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:09,649][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.6007677316665649, acc: 0.7837837934494019)
[2024-11-13 08:01:09,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:09,959][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.7785840034484863, acc: 0.7837837934494019)
[2024-11-13 08:01:10,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:10,277][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.6185855865478516, acc: 0.7837837934494019)
[2024-11-13 08:01:10,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:10,592][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 1.0446069240570068, acc: 0.6764705777168274)
[2024-11-13 08:01:10,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:10,914][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.42587414383888245, acc: 0.8780487775802612)
[2024-11-13 08:01:10,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:11,174][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.17595629394054413, acc: 0.9200000166893005)
[2024-11-13 08:01:11,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:11,504][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.10494980216026306, acc: 1.0)
[2024-11-13 08:01:11,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:11,806][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.33913248777389526, acc: 0.9032257795333862)
[2024-11-13 08:01:11,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:12,142][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.7999333739280701, acc: 0.7368420958518982)
[2024-11-13 08:01:12,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:12,516][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.978350043296814, acc: 0.7142857313156128)
[2024-11-13 08:01:12,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:12,820][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.9661860466003418, acc: 0.7105262875556946)
[2024-11-13 08:01:12,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:13,280][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 1.3286397457122803, acc: 0.5849056839942932)
[2024-11-13 08:01:13,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:13,736][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 1.5351760387420654, acc: 0.5583333373069763)
[2024-11-13 08:01:13,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:14,072][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.6153409481048584, acc: 0.8055555820465088)
[2024-11-13 08:01:14,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:14,409][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.6005234122276306, acc: 0.8387096524238586)
[2024-11-13 08:01:14,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:14,765][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 1.7344800233840942, acc: 0.5199999809265137)
[2024-11-13 08:01:14,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:15,132][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 1.0528959035873413, acc: 0.6875)
[2024-11-13 08:01:15,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:15,717][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 2.1062912940979004, acc: 0.3840000033378601)
[2024-11-13 08:01:15,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:16,075][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 1.5642417669296265, acc: 0.584269642829895)
[2024-11-13 08:01:16,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:16,401][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 1.5052051544189453, acc: 0.6081081032752991)
[2024-11-13 08:01:16,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:16,773][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 1.1592302322387695, acc: 0.6206896305084229)
[2024-11-13 08:01:16,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:17,110][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.5408784747123718, acc: 0.8181818127632141)
[2024-11-13 08:01:17,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:17,440][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.7478125095367432, acc: 0.7272727489471436)
[2024-11-13 08:01:17,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:17,734][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.5170427560806274, acc: 0.8125)
[2024-11-13 08:01:17,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:17,948][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.6847162246704102, acc: 0.8666666746139526)
[2024-11-13 08:01:18,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:18,235][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 1.339159607887268, acc: 0.6000000238418579)
[2024-11-13 08:01:18,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:19,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:19,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:19,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:19,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:20,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:20,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:20,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:20,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:21,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:21,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:21,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:22,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:22,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:22,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:22,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:23,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:23,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:23,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:23,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:24,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:24,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:24,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:24,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:25,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:25,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:25,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:26,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:26,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:26,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:26,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:27,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:27,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:27,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:28,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:28,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:28,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:29,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:29,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:29,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:29,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:30,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:30,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:30,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:31,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:31,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:31,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:31,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:32,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:32,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:32,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:32,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:33,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:33,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:33,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:33,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:34,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:34,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:34,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:34,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:35,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:35,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:35,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:36,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:36,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:36,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:36,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:37,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:37,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:37,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:38,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:38,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:38,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:39,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:39,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:39,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:39,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:39,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:40,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:40,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:40,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:40,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:41,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:41,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:42,160][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.5504, device='cuda:0') eval_epoch_loss=tensor(2.0216, device='cuda:0') eval_epoch_acc=tensor(0.5379, device='cuda:0')
[2024-11-13 08:01:42,161][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:01:42,161][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:01:42,589][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_7_step_274_loss_2.0216057300567627/model.pt
[2024-11-13 08:01:42,598][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:01:42,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:43,044][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.4391183853149414, acc: 0.90625)
[2024-11-13 08:01:43,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:43,408][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.48524898290634155, acc: 0.800000011920929)
[2024-11-13 08:01:43,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:43,776][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.7710449695587158, acc: 0.7586206793785095)
[2024-11-13 08:01:43,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:44,139][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 1.2022976875305176, acc: 0.6399999856948853)
[2024-11-13 08:01:44,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:44,459][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.9017693400382996, acc: 0.7446808218955994)
[2024-11-13 08:01:44,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:44,791][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 1.0796570777893066, acc: 0.75)
[2024-11-13 08:01:44,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:45,136][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.8644605875015259, acc: 0.75)
[2024-11-13 08:01:45,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:45,563][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 1.5352613925933838, acc: 0.5662650465965271)
[2024-11-13 08:01:45,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:45,938][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 1.6615104675292969, acc: 0.5833333134651184)
[2024-11-13 08:01:46,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:46,276][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 1.104136347770691, acc: 0.6315789222717285)
[2024-11-13 08:01:46,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:46,619][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.9180406928062439, acc: 0.6764705777168274)
[2024-11-13 08:01:46,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:46,991][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.47783684730529785, acc: 0.8500000238418579)
[2024-11-13 08:01:47,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:47,313][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 1.6497629880905151, acc: 0.515625)
[2024-11-13 08:01:47,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:47,640][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 1.6080080270767212, acc: 0.5360000133514404)
[2024-11-13 08:01:47,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:47,918][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 1.2224043607711792, acc: 0.6483516693115234)
[2024-11-13 08:01:47,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:48,238][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 1.936713695526123, acc: 0.45962733030319214)
[2024-11-13 08:01:48,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:48,596][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 1.8990802764892578, acc: 0.4793814420700073)
[2024-11-13 08:01:48,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:48,933][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.44163820147514343, acc: 0.8636363744735718)
[2024-11-13 08:01:48,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:49,216][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 1.2567362785339355, acc: 0.6666666865348816)
[2024-11-13 08:01:49,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:49,631][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.9312619566917419, acc: 0.7413793206214905)
[2024-11-13 08:01:49,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:50,022][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.6921395659446716, acc: 0.800000011920929)
[2024-11-13 08:01:50,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:50,459][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 1.5409294366836548, acc: 0.6030927896499634)
[2024-11-13 08:01:50,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:50,694][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 1.2532161474227905, acc: 0.5862069129943848)
[2024-11-13 08:01:50,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:51,027][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.9618656635284424, acc: 0.7407407164573669)
[2024-11-13 08:01:51,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:51,369][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 1.0689598321914673, acc: 0.7368420958518982)
[2024-11-13 08:01:51,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:51,704][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.5833293199539185, acc: 0.8571428656578064)
[2024-11-13 08:01:51,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:52,071][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.591022253036499, acc: 0.75)
[2024-11-13 08:01:52,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:52,455][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.8819928169250488, acc: 0.7358490824699402)
[2024-11-13 08:01:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:52,846][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.44293212890625, acc: 0.8867924809455872)
[2024-11-13 08:01:52,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:53,165][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.6370900869369507, acc: 0.7941176295280457)
[2024-11-13 08:01:53,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:53,460][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.7329651713371277, acc: 0.84375)
[2024-11-13 08:01:53,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:53,815][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.8968248963356018, acc: 0.7377049326896667)
[2024-11-13 08:01:53,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:54,142][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.32875463366508484, acc: 0.8333333134651184)
[2024-11-13 08:01:54,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:54,453][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.22816342115402222, acc: 1.0)
[2024-11-13 08:01:54,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:54,731][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 1.1914314031600952, acc: 0.6086956262588501)
[2024-11-13 08:01:54,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:55,078][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 1.2213070392608643, acc: 0.6388888955116272)
[2024-11-13 08:01:55,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:55,367][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 1.0159366130828857, acc: 0.650602400302887)
[2024-11-13 08:01:55,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:55,657][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 1.4009668827056885, acc: 0.5897436141967773)
[2024-11-13 08:01:55,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:55,964][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 1.4556691646575928, acc: 0.6020408272743225)
[2024-11-13 08:01:56,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:56,238][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.12537449598312378, acc: 1.0)
[2024-11-13 08:01:56,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:56,529][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.3813006579875946, acc: 0.9166666865348816)
[2024-11-13 08:01:56,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:56,836][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.6061438918113708, acc: 0.8387096524238586)
[2024-11-13 08:01:56,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:57,136][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.3112657964229584, acc: 0.9032257795333862)
[2024-11-13 08:01:57,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:57,445][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.8352250456809998, acc: 0.7014925479888916)
[2024-11-13 08:01:57,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:57,747][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 1.0996679067611694, acc: 0.6442307829856873)
[2024-11-13 08:01:57,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:58,039][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.7266929745674133, acc: 0.7777777910232544)
[2024-11-13 08:01:58,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:58,327][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.9261041879653931, acc: 0.725806474685669)
[2024-11-13 08:01:58,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:58,630][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.5542944669723511, acc: 0.7799999713897705)
[2024-11-13 08:01:58,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:58,952][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.8686747550964355, acc: 0.7777777910232544)
[2024-11-13 08:01:59,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:59,256][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 1.2510825395584106, acc: 0.6571428775787354)
[2024-11-13 08:01:59,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:59,552][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.9220579266548157, acc: 0.7435897588729858)
[2024-11-13 08:01:59,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:01:59,869][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 1.4047329425811768, acc: 0.5853658318519592)
[2024-11-13 08:01:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:00,176][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.9424147605895996, acc: 0.7894737124443054)
[2024-11-13 08:02:00,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:00,469][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.4009877145290375, acc: 0.8947368264198303)
[2024-11-13 08:02:00,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:00,752][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.31226611137390137, acc: 0.9642857313156128)
[2024-11-13 08:02:00,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:01,067][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.820843517780304, acc: 0.7037037014961243)
[2024-11-13 08:02:01,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:01,376][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.38934141397476196, acc: 0.9375)
[2024-11-13 08:02:01,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:01,676][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 1.0746686458587646, acc: 0.6935483813285828)
[2024-11-13 08:02:01,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:01,997][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 0.9679844975471497, acc: 0.7017543911933899)
[2024-11-13 08:02:02,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:02,317][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 1.1682919263839722, acc: 0.65625)
[2024-11-13 08:02:02,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:02,624][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.7431451678276062, acc: 0.6666666865348816)
[2024-11-13 08:02:02,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:02,925][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.9413078427314758, acc: 0.6315789222717285)
[2024-11-13 08:02:02,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:03,220][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 1.2952170372009277, acc: 0.6000000238418579)
[2024-11-13 08:02:03,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:03,521][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 1.7203748226165771, acc: 0.49425286054611206)
[2024-11-13 08:02:03,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:03,849][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 1.876400113105774, acc: 0.4893617033958435)
[2024-11-13 08:02:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:04,140][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 1.8785319328308105, acc: 0.40963855385780334)
[2024-11-13 08:02:04,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:04,380][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.5272185206413269, acc: 0.8260869383811951)
[2024-11-13 08:02:04,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:04,681][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.7526137232780457, acc: 0.7435897588729858)
[2024-11-13 08:02:04,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:04,983][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 1.7246710062026978, acc: 0.5542168617248535)
[2024-11-13 08:02:05,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:05,287][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 1.070014476776123, acc: 0.7169811129570007)
[2024-11-13 08:02:05,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:05,593][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 1.0810366868972778, acc: 0.6455696225166321)
[2024-11-13 08:02:05,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:05,907][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 1.059347152709961, acc: 0.686274528503418)
[2024-11-13 08:02:05,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:06,209][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 1.7384532690048218, acc: 0.5074626803398132)
[2024-11-13 08:02:06,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:06,512][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.6056195497512817, acc: 0.800000011920929)
[2024-11-13 08:02:06,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:06,814][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.5925360321998596, acc: 0.7599999904632568)
[2024-11-13 08:02:06,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:07,152][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.9984459280967712, acc: 0.7222222089767456)
[2024-11-13 08:02:07,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:07,434][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 1.2010878324508667, acc: 0.5581395626068115)
[2024-11-13 08:02:07,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:07,754][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.9675024747848511, acc: 0.6666666865348816)
[2024-11-13 08:02:07,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:08,075][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 1.137325406074524, acc: 0.6888889074325562)
[2024-11-13 08:02:08,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:08,359][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.6193735003471375, acc: 0.739130437374115)
[2024-11-13 08:02:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:08,675][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.864611029624939, acc: 0.692307710647583)
[2024-11-13 08:02:08,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:09,002][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 1.787381649017334, acc: 0.5384615659713745)
[2024-11-13 08:02:09,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:09,402][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 1.564474105834961, acc: 0.6173912882804871)
[2024-11-13 08:02:09,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:09,705][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 1.3888338804244995, acc: 0.6304348111152649)
[2024-11-13 08:02:09,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:09,988][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 1.3301748037338257, acc: 0.6122449040412903)
[2024-11-13 08:02:10,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:10,255][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.23210233449935913, acc: 0.9166666865348816)
[2024-11-13 08:02:10,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:10,584][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.4971940815448761, acc: 0.8461538553237915)
[2024-11-13 08:02:10,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:10,883][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.5550807118415833, acc: 0.8048780560493469)
[2024-11-13 08:02:10,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:11,163][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.6570944786071777, acc: 0.7555555701255798)
[2024-11-13 08:02:11,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:11,465][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 0.9931018948554993, acc: 0.6842105388641357)
[2024-11-13 08:02:11,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:11,776][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.7928435206413269, acc: 0.7804877758026123)
[2024-11-13 08:02:11,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:12,064][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.9535306692123413, acc: 0.6969696879386902)
[2024-11-13 08:02:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:12,332][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.4623471796512604, acc: 0.875)
[2024-11-13 08:02:12,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:12,618][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.05098087340593338, acc: 1.0)
[2024-11-13 08:02:12,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:12,886][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.37095627188682556, acc: 0.9285714030265808)
[2024-11-13 08:02:12,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:13,186][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.8109440803527832, acc: 0.65625)
[2024-11-13 08:02:13,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:13,661][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 1.5838760137557983, acc: 0.5272727012634277)
[2024-11-13 08:02:13,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:14,243][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 1.1406954526901245, acc: 0.6792452931404114)
[2024-11-13 08:02:14,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:14,526][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 1.27776300907135, acc: 0.6222222447395325)
[2024-11-13 08:02:14,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:14,802][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 1.0110883712768555, acc: 0.6071428656578064)
[2024-11-13 08:02:14,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:15,104][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.6026450395584106, acc: 0.8285714387893677)
[2024-11-13 08:02:15,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:15,412][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.2563522458076477, acc: 0.8799999952316284)
[2024-11-13 08:02:15,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:15,716][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.27246376872062683, acc: 0.9130434989929199)
[2024-11-13 08:02:15,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:16,022][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.9096779823303223, acc: 0.75)
[2024-11-13 08:02:16,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:16,320][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 1.1435143947601318, acc: 0.6631578803062439)
[2024-11-13 08:02:16,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:16,773][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 1.3928580284118652, acc: 0.6047903895378113)
[2024-11-13 08:02:16,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:17,112][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 0.9886815547943115, acc: 0.7142857313156128)
[2024-11-13 08:02:17,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:17,851][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 1.3283283710479736, acc: 0.614973247051239)
[2024-11-13 08:02:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:18,288][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.8704801201820374, acc: 0.7567567825317383)
[2024-11-13 08:02:18,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:18,560][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.4830159842967987, acc: 0.8571428656578064)
[2024-11-13 08:02:18,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:18,861][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.3034859597682953, acc: 0.8928571343421936)
[2024-11-13 08:02:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:19,184][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.5865833759307861, acc: 0.78125)
[2024-11-13 08:02:19,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:19,487][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.5490672588348389, acc: 0.8055555820465088)
[2024-11-13 08:02:19,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:19,780][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.5565748810768127, acc: 0.8157894611358643)
[2024-11-13 08:02:19,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:20,075][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.2682766616344452, acc: 0.9545454382896423)
[2024-11-13 08:02:20,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:20,363][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.6121233105659485, acc: 0.75)
[2024-11-13 08:02:20,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:20,653][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.29089370369911194, acc: 0.9047619104385376)
[2024-11-13 08:02:20,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:20,935][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 1.3493497371673584, acc: 0.6481481194496155)
[2024-11-13 08:02:21,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:21,237][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 1.8936291933059692, acc: 0.49514561891555786)
[2024-11-13 08:02:21,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:21,650][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 1.6817243099212646, acc: 0.5735294222831726)
[2024-11-13 08:02:21,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:21,975][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 1.8169918060302734, acc: 0.5199999809265137)
[2024-11-13 08:02:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:22,292][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 2.0328168869018555, acc: 0.5069444179534912)
[2024-11-13 08:02:22,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:22,628][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.886480450630188, acc: 0.7209302186965942)
[2024-11-13 08:02:22,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:22,946][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.48171254992485046, acc: 0.875)
[2024-11-13 08:02:23,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:23,257][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.6799435615539551, acc: 0.8139534592628479)
[2024-11-13 08:02:23,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:23,545][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.5403584837913513, acc: 0.800000011920929)
[2024-11-13 08:02:23,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:23,981][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 1.2605019807815552, acc: 0.6029411554336548)
[2024-11-13 08:02:24,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:24,272][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 1.438910722732544, acc: 0.6133333444595337)
[2024-11-13 08:02:24,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:24,549][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.7388572692871094, acc: 0.7272727489471436)
[2024-11-13 08:02:24,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:24,873][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.8492377996444702, acc: 0.7878788113594055)
[2024-11-13 08:02:24,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:25,167][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.4000541567802429, acc: 0.8387096524238586)
[2024-11-13 08:02:25,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:25,477][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.6062791347503662, acc: 0.7777777910232544)
[2024-11-13 08:02:25,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:25,769][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.45401039719581604, acc: 0.8799999952316284)
[2024-11-13 08:02:25,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:26,088][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.5528417229652405, acc: 0.8333333134651184)
[2024-11-13 08:02:26,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:26,406][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.5291568040847778, acc: 0.8518518805503845)
[2024-11-13 08:02:26,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:26,699][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.40964677929878235, acc: 0.8461538553237915)
[2024-11-13 08:02:26,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:27,006][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.9570878744125366, acc: 0.7068965435028076)
[2024-11-13 08:02:27,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:27,328][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.4397939145565033, acc: 0.8571428656578064)
[2024-11-13 08:02:27,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:27,633][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.40189826488494873, acc: 0.8999999761581421)
[2024-11-13 08:02:27,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:27,929][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.4833467900753021, acc: 0.8484848737716675)
[2024-11-13 08:02:27,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:28,231][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.5291045308113098, acc: 0.8181818127632141)
[2024-11-13 08:02:28,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:28,542][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 1.3412339687347412, acc: 0.6470588445663452)
[2024-11-13 08:02:28,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:28,843][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 1.1108978986740112, acc: 0.692307710647583)
[2024-11-13 08:02:29,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:30,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:30,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:30,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:30,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:30,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:31,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:31,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:31,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:31,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:32,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:32,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:32,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:33,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:33,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:33,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:33,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:33,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:34,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:34,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:34,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:35,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:35,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:35,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:35,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:36,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:36,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:36,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:36,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:37,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:37,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:37,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:37,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:38,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:38,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:38,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:39,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:39,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:39,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:39,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:40,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:40,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:40,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:40,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:41,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:41,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:41,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:41,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:42,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:42,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:43,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:43,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:43,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:43,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:44,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:44,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:44,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:45,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:45,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:45,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:46,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:46,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:46,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:46,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:47,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:47,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:47,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:48,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:48,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:48,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:48,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:49,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:49,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:49,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:49,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:50,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:50,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:50,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:50,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:51,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:51,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:51,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:52,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:52,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:53,046][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.3206, device='cuda:0') eval_epoch_loss=tensor(1.9907, device='cuda:0') eval_epoch_acc=tensor(0.5493, device='cuda:0')
[2024-11-13 08:02:53,047][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:02:53,047][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:02:53,407][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_7_step_417_loss_1.9906867742538452/model.pt
[2024-11-13 08:02:53,416][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:02:53,417][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.5492717027664185
[2024-11-13 08:02:53,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:53,820][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 1.3836846351623535, acc: 0.6111111044883728)
[2024-11-13 08:02:53,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:54,126][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 1.059908390045166, acc: 0.699999988079071)
[2024-11-13 08:02:54,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:54,441][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.7151080369949341, acc: 0.800000011920929)
[2024-11-13 08:02:54,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:54,760][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.3905550539493561, acc: 0.8571428656578064)
[2024-11-13 08:02:54,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:55,039][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.4434538185596466, acc: 0.8666666746139526)
[2024-11-13 08:02:55,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:55,368][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.4868090748786926, acc: 0.875)
[2024-11-13 08:02:55,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:55,764][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.5775645971298218, acc: 0.8333333134651184)
[2024-11-13 08:02:55,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:56,103][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.8224304914474487, acc: 0.8518518805503845)
[2024-11-13 08:02:56,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:56,454][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.6718429923057556, acc: 0.8181818127632141)
[2024-11-13 08:02:56,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:56,810][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.9108577370643616, acc: 0.8260869383811951)
[2024-11-13 08:02:56,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:57,101][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 0.5699325203895569, acc: 0.7567567825317383)
[2024-11-13 08:02:57,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:57,366][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.7027596235275269, acc: 0.7777777910232544)
[2024-11-13 08:02:57,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:57,689][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.386580228805542, acc: 0.8260869383811951)
[2024-11-13 08:02:57,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:57,946][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.2513921558856964, acc: 0.9629629850387573)
[2024-11-13 08:02:58,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:58,250][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.15832415223121643, acc: 0.9629629850387573)
[2024-11-13 08:02:58,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:58,568][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.4633549451828003, acc: 0.9130434989929199)
[2024-11-13 08:02:58,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:58,925][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.4586281180381775, acc: 0.8611111044883728)
[2024-11-13 08:02:59,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:59,233][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.6196960806846619, acc: 0.800000011920929)
[2024-11-13 08:02:59,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:59,587][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.7043803930282593, acc: 0.7575757503509521)
[2024-11-13 08:02:59,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:02:59,919][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.8656197786331177, acc: 0.75)
[2024-11-13 08:02:59,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:00,207][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.7342043519020081, acc: 0.8409090638160706)
[2024-11-13 08:03:00,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:00,543][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.40852999687194824, acc: 0.9047619104385376)
[2024-11-13 08:03:00,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:00,885][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.7282264232635498, acc: 0.7435897588729858)
[2024-11-13 08:03:00,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:01,295][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 1.2965706586837769, acc: 0.6363636255264282)
[2024-11-13 08:03:01,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:01,804][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 2.0062193870544434, acc: 0.47200000286102295)
[2024-11-13 08:03:01,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:02,183][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 1.698251485824585, acc: 0.5564516186714172)
[2024-11-13 08:03:02,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:02,678][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 1.852286696434021, acc: 0.5273631811141968)
[2024-11-13 08:03:02,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:02,953][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 1.082853078842163, acc: 0.7169811129570007)
[2024-11-13 08:03:03,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:03,309][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.7480705380439758, acc: 0.8181818127632141)
[2024-11-13 08:03:03,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:03,632][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.5125936269760132, acc: 0.8695651888847351)
[2024-11-13 08:03:03,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:03,969][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.6293672919273376, acc: 0.7307692170143127)
[2024-11-13 08:03:04,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:04,248][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.6389203667640686, acc: 0.75)
[2024-11-13 08:03:04,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:04,549][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 1.1978943347930908, acc: 0.6865671873092651)
[2024-11-13 08:03:04,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:04,920][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 1.0488213300704956, acc: 0.7361111044883728)
[2024-11-13 08:03:04,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:05,189][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 1.2304422855377197, acc: 0.6847826242446899)
[2024-11-13 08:03:05,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:05,469][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 1.2810574769973755, acc: 0.6025640964508057)
[2024-11-13 08:03:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:05,819][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 1.4283729791641235, acc: 0.5789473652839661)
[2024-11-13 08:03:05,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:06,112][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 1.1150000095367432, acc: 0.6530612111091614)
[2024-11-13 08:03:06,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:06,408][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.5864429473876953, acc: 0.8484848737716675)
[2024-11-13 08:03:06,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:06,711][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 1.7918827533721924, acc: 0.4845360815525055)
[2024-11-13 08:03:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:06,999][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 1.0314204692840576, acc: 0.7285714149475098)
[2024-11-13 08:03:07,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:07,318][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 1.4864833354949951, acc: 0.6279069781303406)
[2024-11-13 08:03:07,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:07,642][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 1.2623026371002197, acc: 0.5892857313156128)
[2024-11-13 08:03:07,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:07,987][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 1.5998775959014893, acc: 0.5555555820465088)
[2024-11-13 08:03:08,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:08,335][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.7240583896636963, acc: 0.7777777910232544)
[2024-11-13 08:03:08,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:08,684][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.5159509778022766, acc: 0.875)
[2024-11-13 08:03:08,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:08,975][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.4231891930103302, acc: 0.9230769276618958)
[2024-11-13 08:03:09,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:09,233][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.9483144879341125, acc: 0.695652186870575)
[2024-11-13 08:03:09,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:09,438][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 1.241319179534912, acc: 0.6428571343421936)
[2024-11-13 08:03:09,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:09,774][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 1.2784475088119507, acc: 0.6385542154312134)
[2024-11-13 08:03:09,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:10,154][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 1.1135152578353882, acc: 0.6666666865348816)
[2024-11-13 08:03:10,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:10,510][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 1.223312497138977, acc: 0.6990291476249695)
[2024-11-13 08:03:10,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:10,847][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 1.054240107536316, acc: 0.707317054271698)
[2024-11-13 08:03:10,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:11,191][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.7961384654045105, acc: 0.7083333134651184)
[2024-11-13 08:03:11,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:11,563][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.6382130980491638, acc: 0.8571428656578064)
[2024-11-13 08:03:11,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:11,945][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 1.463236927986145, acc: 0.5490196347236633)
[2024-11-13 08:03:12,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:12,317][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 1.8389320373535156, acc: 0.5109170079231262)
[2024-11-13 08:03:12,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:12,591][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 1.4693211317062378, acc: 0.625)
[2024-11-13 08:03:12,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:12,907][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 1.6290959119796753, acc: 0.558282196521759)
[2024-11-13 08:03:12,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:13,152][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 1.723419189453125, acc: 0.5539568066596985)
[2024-11-13 08:03:13,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:13,469][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 1.912914752960205, acc: 0.48241207003593445)
[2024-11-13 08:03:13,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:13,813][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.6064069867134094, acc: 0.7777777910232544)
[2024-11-13 08:03:13,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:14,131][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.683691680431366, acc: 0.8484848737716675)
[2024-11-13 08:03:14,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:14,456][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.6730160713195801, acc: 0.8518518805503845)
[2024-11-13 08:03:14,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:14,797][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.6843323707580566, acc: 0.75)
[2024-11-13 08:03:14,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:15,134][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.5873795747756958, acc: 0.8500000238418579)
[2024-11-13 08:03:15,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:15,482][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.7957677245140076, acc: 0.7758620977401733)
[2024-11-13 08:03:15,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:15,788][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.4271361529827118, acc: 0.8709677457809448)
[2024-11-13 08:03:15,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:16,142][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.5918657183647156, acc: 0.7368420958518982)
[2024-11-13 08:03:16,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:16,432][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.7847869396209717, acc: 0.6666666865348816)
[2024-11-13 08:03:16,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:16,703][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.7003257274627686, acc: 0.8095238208770752)
[2024-11-13 08:03:16,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:16,983][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.8273427486419678, acc: 0.7272727489471436)
[2024-11-13 08:03:17,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:17,330][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 1.37026846408844, acc: 0.6461538672447205)
[2024-11-13 08:03:17,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:17,628][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.7518352270126343, acc: 0.7666666507720947)
[2024-11-13 08:03:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:17,869][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.7440812587738037, acc: 0.7586206793785095)
[2024-11-13 08:03:17,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:18,158][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 1.1720876693725586, acc: 0.6470588445663452)
[2024-11-13 08:03:18,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:18,496][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.9639756679534912, acc: 0.6206896305084229)
[2024-11-13 08:03:18,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:18,783][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.44841107726097107, acc: 0.8947368264198303)
[2024-11-13 08:03:18,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:19,129][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.6337165236473083, acc: 0.7894737124443054)
[2024-11-13 08:03:19,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:19,424][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 1.2263844013214111, acc: 0.6428571343421936)
[2024-11-13 08:03:19,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:19,744][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 1.1738475561141968, acc: 0.6966292262077332)
[2024-11-13 08:03:19,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:20,067][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 1.5224326848983765, acc: 0.5617977380752563)
[2024-11-13 08:03:20,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:20,352][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.8829432725906372, acc: 0.43971630930900574)
[2024-11-13 08:03:20,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:20,662][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 1.6346954107284546, acc: 0.54347825050354)
[2024-11-13 08:03:20,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:21,026][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.3766034245491028, acc: 0.8799999952316284)
[2024-11-13 08:03:21,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:21,352][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.6398482918739319, acc: 0.807692289352417)
[2024-11-13 08:03:21,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:21,707][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.5729531049728394, acc: 0.8148148059844971)
[2024-11-13 08:03:21,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:22,056][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 1.202026128768921, acc: 0.7037037014961243)
[2024-11-13 08:03:22,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:22,374][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.6716905832290649, acc: 0.7169811129570007)
[2024-11-13 08:03:22,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:22,673][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.5576713681221008, acc: 0.8275862336158752)
[2024-11-13 08:03:22,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:23,131][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 1.4116092920303345, acc: 0.5675675868988037)
[2024-11-13 08:03:23,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:23,509][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 1.2249903678894043, acc: 0.6901408433914185)
[2024-11-13 08:03:23,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:23,793][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.6146683692932129, acc: 0.699999988079071)
[2024-11-13 08:03:23,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:24,091][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.6312233805656433, acc: 0.7333333492279053)
[2024-11-13 08:03:24,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:24,352][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.710828423500061, acc: 0.807692289352417)
[2024-11-13 08:03:24,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:25,558][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 1.7133840322494507, acc: 0.5357142686843872)
[2024-11-13 08:03:25,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:26,121][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 1.4439634084701538, acc: 0.60317462682724)
[2024-11-13 08:03:26,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:26,404][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.7139063477516174, acc: 0.7857142686843872)
[2024-11-13 08:03:26,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:26,718][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 1.1521985530853271, acc: 0.6666666865348816)
[2024-11-13 08:03:26,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:27,243][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.8932206630706787, acc: 0.7916666865348816)
[2024-11-13 08:03:27,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:27,510][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.18071940541267395, acc: 0.9615384340286255)
[2024-11-13 08:03:27,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:27,807][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.8768423199653625, acc: 0.8064516186714172)
[2024-11-13 08:03:27,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:28,110][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.8453298807144165, acc: 0.800000011920929)
[2024-11-13 08:03:28,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:28,421][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.5921522974967957, acc: 0.7777777910232544)
[2024-11-13 08:03:28,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:29,115][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 1.8197733163833618, acc: 0.5)
[2024-11-13 08:03:29,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:29,411][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 1.5252963304519653, acc: 0.5298507213592529)
[2024-11-13 08:03:29,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:29,736][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 1.4797230958938599, acc: 0.5766423344612122)
[2024-11-13 08:03:29,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:30,175][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 1.7725616693496704, acc: 0.5350000262260437)
[2024-11-13 08:03:30,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:30,454][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 1.0407798290252686, acc: 0.7037037014961243)
[2024-11-13 08:03:30,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:30,746][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.8957639336585999, acc: 0.7692307829856873)
[2024-11-13 08:03:30,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:31,030][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.8560838103294373, acc: 0.6666666865348816)
[2024-11-13 08:03:31,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:31,335][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 1.24517023563385, acc: 0.6229507923126221)
[2024-11-13 08:03:31,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:31,623][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 1.102547287940979, acc: 0.7118644118309021)
[2024-11-13 08:03:31,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:31,917][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 1.2992076873779297, acc: 0.6279069781303406)
[2024-11-13 08:03:31,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:32,178][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.9231805205345154, acc: 0.7727272510528564)
[2024-11-13 08:03:32,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:32,443][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 1.1953935623168945, acc: 0.6603773832321167)
[2024-11-13 08:03:32,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:32,730][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.9681190252304077, acc: 0.7727272510528564)
[2024-11-13 08:03:32,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:33,033][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.714091956615448, acc: 0.7599999904632568)
[2024-11-13 08:03:33,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:33,339][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.35395383834838867, acc: 0.8999999761581421)
[2024-11-13 08:03:33,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:33,625][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.4763501286506653, acc: 0.8636363744735718)
[2024-11-13 08:03:33,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:33,964][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 1.2274906635284424, acc: 0.692307710647583)
[2024-11-13 08:03:34,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:34,283][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 1.132737636566162, acc: 0.65625)
[2024-11-13 08:03:34,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:34,604][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.7984095811843872, acc: 0.8125)
[2024-11-13 08:03:34,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:34,876][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.7678032517433167, acc: 0.7272727489471436)
[2024-11-13 08:03:34,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:35,189][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.5466917753219604, acc: 0.8125)
[2024-11-13 08:03:35,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:35,477][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.5362885594367981, acc: 0.8709677457809448)
[2024-11-13 08:03:35,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:35,773][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.21847862005233765, acc: 0.95652174949646)
[2024-11-13 08:03:35,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:36,066][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.8327734470367432, acc: 0.7666666507720947)
[2024-11-13 08:03:36,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:36,367][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.7705103754997253, acc: 0.7317073345184326)
[2024-11-13 08:03:36,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:36,688][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.5060095191001892, acc: 0.800000011920929)
[2024-11-13 08:03:36,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:36,975][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.578413188457489, acc: 0.8421052694320679)
[2024-11-13 08:03:37,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:37,271][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.5427401661872864, acc: 0.8064516186714172)
[2024-11-13 08:03:37,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:37,574][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.48525241017341614, acc: 0.8399999737739563)
[2024-11-13 08:03:37,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:37,863][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.32757267355918884, acc: 0.8787878751754761)
[2024-11-13 08:03:37,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:38,155][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.39817875623703003, acc: 0.8999999761581421)
[2024-11-13 08:03:38,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:38,442][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.7571633458137512, acc: 0.800000011920929)
[2024-11-13 08:03:38,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:38,735][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 1.6725447177886963, acc: 0.49635037779808044)
[2024-11-13 08:03:38,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:39,027][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 1.2507222890853882, acc: 0.6000000238418579)
[2024-11-13 08:03:39,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:39,321][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 1.7941430807113647, acc: 0.4714285731315613)
[2024-11-13 08:03:39,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:39,644][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 1.6608772277832031, acc: 0.45695364475250244)
[2024-11-13 08:03:39,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:39,929][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 1.1139965057373047, acc: 0.6666666865348816)
[2024-11-13 08:03:39,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:40,224][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.20646966993808746, acc: 0.9200000166893005)
[2024-11-13 08:03:40,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:40,529][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.4026455879211426, acc: 0.8461538553237915)
[2024-11-13 08:03:41,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:41,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:41,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:41,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:42,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:42,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:43,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:43,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:43,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:43,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:44,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:44,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:44,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:45,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:45,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:45,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:46,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:46,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:46,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:46,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:47,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:47,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:47,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:47,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:48,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:48,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:48,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:49,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:49,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:49,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:49,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:50,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:50,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:50,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:51,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:51,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:51,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:51,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:52,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:52,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:52,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:52,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:53,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:53,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:53,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:53,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:54,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:54,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:54,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:55,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:55,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:55,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:55,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:56,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:56,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:56,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:57,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:57,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:57,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:58,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:58,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:58,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:58,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:58,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:59,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:59,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:03:59,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:00,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:00,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:00,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:00,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:00,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:01,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:01,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:01,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:01,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:02,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:02,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:02,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:03,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:03,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:03,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:04,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:04,685][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.4713, device='cuda:0') eval_epoch_loss=tensor(2.0111, device='cuda:0') eval_epoch_acc=tensor(0.5386, device='cuda:0')
[2024-11-13 08:04:04,686][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:04:04,687][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:04:05,061][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_7_step_560_loss_2.0110626220703125/model.pt
[2024-11-13 08:04:05,064][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:04:05,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:05,393][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.29995396733283997, acc: 0.9230769276618958)
[2024-11-13 08:04:05,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:05,665][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.7023965716362, acc: 0.7948718070983887)
[2024-11-13 08:04:05,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:05,914][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 0.9331396222114563, acc: 0.6888889074325562)
[2024-11-13 08:04:05,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:06,151][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.8939940929412842, acc: 0.7272727489471436)
[2024-11-13 08:04:06,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:06,443][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.691863477230072, acc: 0.75)
[2024-11-13 08:04:06,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:06,736][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.6173883676528931, acc: 0.8103448152542114)
[2024-11-13 08:04:06,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:07,045][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 0.9852849245071411, acc: 0.7023809552192688)
[2024-11-13 08:04:07,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:07,355][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.6625353097915649, acc: 0.8157894611358643)
[2024-11-13 08:04:07,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:07,665][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.564717173576355, acc: 0.7777777910232544)
[2024-11-13 08:04:07,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:08,003][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 1.4178416728973389, acc: 0.5828877091407776)
[2024-11-13 08:04:08,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:08,277][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.9559810161590576, acc: 0.6935483813285828)
[2024-11-13 08:04:08,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:08,599][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 1.082031488418579, acc: 0.7094017267227173)
[2024-11-13 08:04:08,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:08,913][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 1.732304334640503, acc: 0.4948979616165161)
[2024-11-13 08:04:08,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:09,242][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 1.66972017288208, acc: 0.5408805012702942)
[2024-11-13 08:04:09,728][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=2.7712, train_epoch_loss=1.0193, epoch time 293.2285580150783s
[2024-11-13 08:04:09,729][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 08:04:09,729][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 08:04:09,729][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 08:04:09,729][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 08:04:09,729][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 08:04:10,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:10,628][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.44762688875198364, acc: 0.8148148059844971)
[2024-11-13 08:04:10,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:10,931][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.5149230360984802, acc: 0.8399999737739563)
[2024-11-13 08:04:11,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:11,258][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.625718891620636, acc: 0.837837815284729)
[2024-11-13 08:04:11,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:11,632][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.6092281937599182, acc: 0.7894737124443054)
[2024-11-13 08:04:11,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:11,968][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.6015328764915466, acc: 0.8108108043670654)
[2024-11-13 08:04:12,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:12,328][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.5613526701927185, acc: 0.8571428656578064)
[2024-11-13 08:04:12,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:12,679][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 1.1890634298324585, acc: 0.6530612111091614)
[2024-11-13 08:04:12,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:13,030][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.6715148687362671, acc: 0.8333333134651184)
[2024-11-13 08:04:13,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:13,401][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.1364320069551468, acc: 0.9090909361839294)
[2024-11-13 08:04:13,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:13,719][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.1602461040019989, acc: 0.9615384340286255)
[2024-11-13 08:04:13,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:14,116][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.40414729714393616, acc: 0.8888888955116272)
[2024-11-13 08:04:14,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:14,444][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 1.1022837162017822, acc: 0.7179487347602844)
[2024-11-13 08:04:14,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:14,729][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.5397304892539978, acc: 0.8484848737716675)
[2024-11-13 08:04:14,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:15,120][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.8758827447891235, acc: 0.804347813129425)
[2024-11-13 08:04:15,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:15,437][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.8594949245452881, acc: 0.6470588445663452)
[2024-11-13 08:04:15,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:15,698][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.6461396813392639, acc: 0.8163265585899353)
[2024-11-13 08:04:15,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:16,041][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.2740246057510376, acc: 0.9473684430122375)
[2024-11-13 08:04:16,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:16,384][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.7988004088401794, acc: 0.7916666865348816)
[2024-11-13 08:04:16,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:16,758][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.6531996726989746, acc: 0.8055555820465088)
[2024-11-13 08:04:16,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:17,094][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.816950798034668, acc: 0.6315789222717285)
[2024-11-13 08:04:17,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:17,449][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.5639730095863342, acc: 0.8461538553237915)
[2024-11-13 08:04:17,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:17,746][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.749015212059021, acc: 0.7241379022598267)
[2024-11-13 08:04:17,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:18,061][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.5230730772018433, acc: 0.800000011920929)
[2024-11-13 08:04:18,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:18,334][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.45842084288597107, acc: 0.8571428656578064)
[2024-11-13 08:04:18,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:18,664][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.4067428708076477, acc: 0.875)
[2024-11-13 08:04:18,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:18,989][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 0.9925432801246643, acc: 0.7358490824699402)
[2024-11-13 08:04:19,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:19,360][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 1.327802062034607, acc: 0.6164383292198181)
[2024-11-13 08:04:19,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:20,107][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 1.9024847745895386, acc: 0.5375494360923767)
[2024-11-13 08:04:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:20,378][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.7664377689361572, acc: 0.7209302186965942)
[2024-11-13 08:04:20,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:20,736][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 1.1714621782302856, acc: 0.6144578456878662)
[2024-11-13 08:04:20,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:21,046][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 1.1248455047607422, acc: 0.6296296119689941)
[2024-11-13 08:04:21,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:21,319][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.5298349261283875, acc: 0.8928571343421936)
[2024-11-13 08:04:21,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:21,640][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.7134094834327698, acc: 0.8148148059844971)
[2024-11-13 08:04:21,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:22,009][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.20544402301311493, acc: 0.95652174949646)
[2024-11-13 08:04:22,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:22,347][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 1.5914199352264404, acc: 0.5378151535987854)
[2024-11-13 08:04:22,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:22,671][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.9153481125831604, acc: 0.7868852615356445)
[2024-11-13 08:04:22,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:23,002][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 1.196918249130249, acc: 0.60317462682724)
[2024-11-13 08:04:23,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:23,388][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 1.2063349485397339, acc: 0.5593220591545105)
[2024-11-13 08:04:23,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:23,746][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 1.1471983194351196, acc: 0.6321839094161987)
[2024-11-13 08:04:23,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:24,122][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.3022725582122803, acc: 0.9523809552192688)
[2024-11-13 08:04:24,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:24,419][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.4369668960571289, acc: 0.8846153616905212)
[2024-11-13 08:04:24,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:24,798][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 1.4505631923675537, acc: 0.6351351141929626)
[2024-11-13 08:04:24,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:25,194][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 1.3980958461761475, acc: 0.6615384817123413)
[2024-11-13 08:04:25,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:25,538][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 1.6857980489730835, acc: 0.49494948983192444)
[2024-11-13 08:04:25,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:25,901][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 1.2584106922149658, acc: 0.5979381203651428)
[2024-11-13 08:04:25,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:26,291][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 1.6811619997024536, acc: 0.5147058963775635)
[2024-11-13 08:04:26,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:26,660][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.4224572479724884, acc: 0.8461538553237915)
[2024-11-13 08:04:26,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:26,998][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.14222119748592377, acc: 0.9629629850387573)
[2024-11-13 08:04:27,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:27,313][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.6140302419662476, acc: 0.8571428656578064)
[2024-11-13 08:04:27,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:27,657][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.42415904998779297, acc: 0.8611111044883728)
[2024-11-13 08:04:27,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:28,048][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.9375606775283813, acc: 0.7017543911933899)
[2024-11-13 08:04:28,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:28,363][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.8810487985610962, acc: 0.7777777910232544)
[2024-11-13 08:04:28,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:28,622][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 1.0740699768066406, acc: 0.6619718074798584)
[2024-11-13 08:04:28,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:28,990][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 1.7079228162765503, acc: 0.5666666626930237)
[2024-11-13 08:04:29,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:29,292][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.7412611842155457, acc: 0.8108108043670654)
[2024-11-13 08:04:29,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:29,596][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.37422749400138855, acc: 0.8461538553237915)
[2024-11-13 08:04:29,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:30,899][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.6335073709487915, acc: 0.5563139915466309)
[2024-11-13 08:04:31,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:31,710][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 2.2224032878875732, acc: 0.40740740299224854)
[2024-11-13 08:04:31,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:32,242][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 1.701398491859436, acc: 0.5852272510528564)
[2024-11-13 08:04:32,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:32,708][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 1.641230583190918, acc: 0.5661764740943909)
[2024-11-13 08:04:32,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:33,172][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 1.734910011291504, acc: 0.4855072498321533)
[2024-11-13 08:04:33,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:33,531][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 1.3789756298065186, acc: 0.637499988079071)
[2024-11-13 08:04:33,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:33,876][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.3605569899082184, acc: 0.8529411554336548)
[2024-11-13 08:04:33,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:34,145][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 1.028260588645935, acc: 0.6666666865348816)
[2024-11-13 08:04:34,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:34,471][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.786754846572876, acc: 0.71875)
[2024-11-13 08:04:34,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:34,793][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.2337115854024887, acc: 0.931034505367279)
[2024-11-13 08:04:34,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:35,166][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 1.1537611484527588, acc: 0.7142857313156128)
[2024-11-13 08:04:35,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:35,493][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 1.1721069812774658, acc: 0.6499999761581421)
[2024-11-13 08:04:35,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:35,815][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.25734570622444153, acc: 0.9200000166893005)
[2024-11-13 08:04:35,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:36,117][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.4957880973815918, acc: 0.8333333134651184)
[2024-11-13 08:04:36,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:36,510][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.7261561155319214, acc: 0.8484848737716675)
[2024-11-13 08:04:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:36,878][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 1.6328692436218262, acc: 0.5588235259056091)
[2024-11-13 08:04:36,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:37,202][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 1.3427256345748901, acc: 0.658730149269104)
[2024-11-13 08:04:37,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:37,493][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 1.867552399635315, acc: 0.47179487347602844)
[2024-11-13 08:04:37,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:37,750][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 1.2941949367523193, acc: 0.6122449040412903)
[2024-11-13 08:04:37,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:38,118][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 1.861310601234436, acc: 0.5)
[2024-11-13 08:04:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:38,523][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.9756736755371094, acc: 0.485401451587677)
[2024-11-13 08:04:38,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:38,890][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.4686276912689209, acc: 0.9047619104385376)
[2024-11-13 08:04:38,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:39,253][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.19145546853542328, acc: 0.9166666865348816)
[2024-11-13 08:04:39,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:39,582][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.48241934180259705, acc: 0.7878788113594055)
[2024-11-13 08:04:39,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:39,880][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.46665728092193604, acc: 0.807692289352417)
[2024-11-13 08:04:39,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:40,198][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.8542721271514893, acc: 0.7307692170143127)
[2024-11-13 08:04:40,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:40,514][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 1.1270127296447754, acc: 0.6346153616905212)
[2024-11-13 08:04:40,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:40,810][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.4385211765766144, acc: 0.84375)
[2024-11-13 08:04:40,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:41,091][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 1.018795132637024, acc: 0.6811594367027283)
[2024-11-13 08:04:41,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:41,403][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.763496458530426, acc: 0.7400000095367432)
[2024-11-13 08:04:41,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:41,728][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.8155818581581116, acc: 0.739130437374115)
[2024-11-13 08:04:41,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:42,110][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 1.0034807920455933, acc: 0.7200000286102295)
[2024-11-13 08:04:42,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:42,436][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 1.0441985130310059, acc: 0.6990291476249695)
[2024-11-13 08:04:42,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:43,158][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 1.691429853439331, acc: 0.5582524538040161)
[2024-11-13 08:04:43,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:43,774][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 1.737318754196167, acc: 0.5107526779174805)
[2024-11-13 08:04:43,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:44,367][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 1.5782999992370605, acc: 0.6034482717514038)
[2024-11-13 08:04:44,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:44,932][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 1.0449011325836182, acc: 0.6105263233184814)
[2024-11-13 08:04:45,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:45,626][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 1.4287517070770264, acc: 0.5742574334144592)
[2024-11-13 08:04:45,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:45,964][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 1.2019819021224976, acc: 0.6935483813285828)
[2024-11-13 08:04:46,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:46,274][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 1.0298219919204712, acc: 0.6376811861991882)
[2024-11-13 08:04:46,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:46,596][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 1.5865447521209717, acc: 0.529411792755127)
[2024-11-13 08:04:46,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:46,955][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 1.5759739875793457, acc: 0.5288461446762085)
[2024-11-13 08:04:47,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:47,338][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 1.6366126537322998, acc: 0.510948896408081)
[2024-11-13 08:04:47,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:47,660][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 1.026443362236023, acc: 0.7014925479888916)
[2024-11-13 08:04:47,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:47,998][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.2880884110927582, acc: 0.949999988079071)
[2024-11-13 08:04:48,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:48,311][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.17475691437721252, acc: 0.9545454382896423)
[2024-11-13 08:04:48,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:48,673][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.2308373600244522, acc: 0.95652174949646)
[2024-11-13 08:04:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:48,959][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.6424590945243835, acc: 0.8181818127632141)
[2024-11-13 08:04:49,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:49,240][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.937301754951477, acc: 0.7413793206214905)
[2024-11-13 08:04:49,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:49,541][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.2865433990955353, acc: 0.9069767594337463)
[2024-11-13 08:04:49,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:49,838][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.6180254220962524, acc: 0.800000011920929)
[2024-11-13 08:04:49,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:50,121][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.06275670230388641, acc: 1.0)
[2024-11-13 08:04:50,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:50,423][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.07840677350759506, acc: 1.0)
[2024-11-13 08:04:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:50,719][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.2779507040977478, acc: 0.9047619104385376)
[2024-11-13 08:04:50,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:51,059][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.8559470772743225, acc: 0.7230769395828247)
[2024-11-13 08:04:51,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:51,465][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.9174450635910034, acc: 0.7543859481811523)
[2024-11-13 08:04:51,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:51,790][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.7243801355361938, acc: 0.7719298005104065)
[2024-11-13 08:04:51,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:52,108][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.7091640830039978, acc: 0.7435897588729858)
[2024-11-13 08:04:52,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:52,443][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.680345892906189, acc: 0.7551020383834839)
[2024-11-13 08:04:52,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:52,768][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.08354844152927399, acc: 0.9545454382896423)
[2024-11-13 08:04:52,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:53,098][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.9733489751815796, acc: 0.6984127163887024)
[2024-11-13 08:04:53,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:53,469][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 1.2548104524612427, acc: 0.642276406288147)
[2024-11-13 08:04:53,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:53,836][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.7209884524345398, acc: 0.8064516186714172)
[2024-11-13 08:04:53,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:54,465][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 1.8228850364685059, acc: 0.5019011497497559)
[2024-11-13 08:04:54,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:54,757][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.8614948391914368, acc: 0.7200000286102295)
[2024-11-13 08:04:54,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:55,098][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.6713847517967224, acc: 0.807692289352417)
[2024-11-13 08:04:55,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:55,371][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.510422945022583, acc: 0.8333333134651184)
[2024-11-13 08:04:55,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:55,647][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.4510425627231598, acc: 0.8421052694320679)
[2024-11-13 08:04:55,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:55,950][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.5712254047393799, acc: 0.5705521702766418)
[2024-11-13 08:04:56,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:56,266][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 1.577996850013733, acc: 0.5833333134651184)
[2024-11-13 08:04:56,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:56,563][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 1.4855530261993408, acc: 0.574999988079071)
[2024-11-13 08:04:56,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:56,894][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.678492784500122, acc: 0.494047611951828)
[2024-11-13 08:04:56,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:57,193][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 1.6157490015029907, acc: 0.5538461804389954)
[2024-11-13 08:04:58,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:58,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:58,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:58,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:59,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:59,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:59,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:04:59,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:00,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:00,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:00,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:01,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:01,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:01,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:01,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:02,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:02,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:02,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:02,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:03,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:03,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:03,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:03,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:04,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:04,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:04,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:04,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:05,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:05,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:05,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:05,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:06,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:06,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:06,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:06,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:07,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:07,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:07,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:08,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:08,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:08,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:08,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:09,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:09,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:09,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:09,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:09,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:10,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:10,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:10,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:10,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:11,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:11,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:11,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:11,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:12,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:12,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:12,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:13,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:13,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:13,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:13,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:14,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:14,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:14,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:15,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:15,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:15,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:16,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:16,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:16,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:16,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:17,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:17,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:17,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:17,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:18,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:18,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:18,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:18,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:19,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:19,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:19,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:19,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:20,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:20,917][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.2496, device='cuda:0') eval_epoch_loss=tensor(1.9809, device='cuda:0') eval_epoch_acc=tensor(0.5495, device='cuda:0')
[2024-11-13 08:05:20,918][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:05:20,918][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:05:21,343][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_8_step_129_loss_1.9809460639953613/model.pt
[2024-11-13 08:05:21,346][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:05:21,347][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.549534022808075
[2024-11-13 08:05:21,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:21,740][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 1.3220306634902954, acc: 0.6397058963775635)
[2024-11-13 08:05:21,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:22,090][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.6816637516021729, acc: 0.8461538553237915)
[2024-11-13 08:05:22,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:22,387][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.45885565876960754, acc: 0.8695651888847351)
[2024-11-13 08:05:22,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:22,692][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.5538183450698853, acc: 0.78125)
[2024-11-13 08:05:22,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:22,982][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.4019528329372406, acc: 0.8260869383811951)
[2024-11-13 08:05:23,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:23,301][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.8077536821365356, acc: 0.7142857313156128)
[2024-11-13 08:05:23,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:23,613][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.268198162317276, acc: 0.9615384340286255)
[2024-11-13 08:05:23,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:23,896][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.6836047172546387, acc: 0.8095238208770752)
[2024-11-13 08:05:23,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:24,184][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.893833339214325, acc: 0.6666666865348816)
[2024-11-13 08:05:24,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:24,456][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.5856567621231079, acc: 0.8260869383811951)
[2024-11-13 08:05:24,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:24,762][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.9229410290718079, acc: 0.761904776096344)
[2024-11-13 08:05:24,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:25,017][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 1.135511040687561, acc: 0.692307710647583)
[2024-11-13 08:05:25,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:25,288][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 1.0052802562713623, acc: 0.6451612710952759)
[2024-11-13 08:05:25,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:25,602][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 1.104262113571167, acc: 0.6486486196517944)
[2024-11-13 08:05:25,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:26,021][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 1.6258254051208496, acc: 0.5350877046585083)
[2024-11-13 08:05:26,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:26,323][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 1.449532389640808, acc: 0.611940324306488)
[2024-11-13 08:05:26,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:26,628][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 1.8452805280685425, acc: 0.4591836631298065)
[2024-11-13 08:05:26,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:26,982][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 1.652927041053772, acc: 0.4893617033958435)
[2024-11-13 08:05:27,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:27,256][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 1.3910071849822998, acc: 0.5857142806053162)
[2024-11-13 08:05:27,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:27,542][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.7472285032272339, acc: 0.7142857313156128)
[2024-11-13 08:05:27,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:27,845][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 1.0260447263717651, acc: 0.739130437374115)
[2024-11-13 08:05:27,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:28,132][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.9237216711044312, acc: 0.6551724076271057)
[2024-11-13 08:05:28,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:28,443][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 1.0967886447906494, acc: 0.739130437374115)
[2024-11-13 08:05:28,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:28,755][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 1.4281784296035767, acc: 0.6271186470985413)
[2024-11-13 08:05:28,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:29,025][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 1.5260870456695557, acc: 0.6315789222717285)
[2024-11-13 08:05:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:29,346][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 1.4055681228637695, acc: 0.5675675868988037)
[2024-11-13 08:05:29,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:29,639][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.8773800134658813, acc: 0.7857142686843872)
[2024-11-13 08:05:29,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:29,931][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.6099282503128052, acc: 0.8695651888847351)
[2024-11-13 08:05:30,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:30,236][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.77315753698349, acc: 0.7368420958518982)
[2024-11-13 08:05:30,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:31,091][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 1.485460877418518, acc: 0.5810810923576355)
[2024-11-13 08:05:31,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:31,459][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 1.2744489908218384, acc: 0.5185185074806213)
[2024-11-13 08:05:31,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:31,844][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 1.0709558725357056, acc: 0.6627907156944275)
[2024-11-13 08:05:31,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:32,290][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 0.9824864268302917, acc: 0.6941176652908325)
[2024-11-13 08:05:32,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:32,717][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 1.426340937614441, acc: 0.6404494643211365)
[2024-11-13 08:05:32,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:32,985][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.46339473128318787, acc: 0.8409090638160706)
[2024-11-13 08:05:33,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:33,273][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.5389124155044556, acc: 0.761904776096344)
[2024-11-13 08:05:33,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:33,590][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.8402278423309326, acc: 0.7241379022598267)
[2024-11-13 08:05:33,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:33,887][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.7647808790206909, acc: 0.795918345451355)
[2024-11-13 08:05:33,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:34,187][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.8220913410186768, acc: 0.7200000286102295)
[2024-11-13 08:05:34,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:34,526][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 1.118627667427063, acc: 0.6944444179534912)
[2024-11-13 08:05:34,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:34,838][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.2083839178085327, acc: 0.6666666865348816)
[2024-11-13 08:05:35,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:35,545][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.9143942594528198, acc: 0.48630136251449585)
[2024-11-13 08:05:35,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:35,873][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.3397144377231598, acc: 0.9166666865348816)
[2024-11-13 08:05:35,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:36,197][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.4757026433944702, acc: 0.8518518805503845)
[2024-11-13 08:05:36,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:36,530][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.47991031408309937, acc: 0.8214285969734192)
[2024-11-13 08:05:36,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:36,985][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 1.3470914363861084, acc: 0.5929203629493713)
[2024-11-13 08:05:37,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:37,298][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 1.1186654567718506, acc: 0.6811594367027283)
[2024-11-13 08:05:37,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:37,634][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 1.312538981437683, acc: 0.6363636255264282)
[2024-11-13 08:05:37,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:38,271][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 1.8951021432876587, acc: 0.4885496199131012)
[2024-11-13 08:05:38,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:38,776][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 1.8405684232711792, acc: 0.4740740656852722)
[2024-11-13 08:05:38,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:39,112][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 1.0274922847747803, acc: 0.7377049326896667)
[2024-11-13 08:05:39,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:39,430][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.4543968141078949, acc: 0.875)
[2024-11-13 08:05:39,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:39,769][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.8889890909194946, acc: 0.7200000286102295)
[2024-11-13 08:05:39,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:40,159][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.5395954251289368, acc: 0.7857142686843872)
[2024-11-13 08:05:40,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:40,453][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 1.2292394638061523, acc: 0.5853658318519592)
[2024-11-13 08:05:40,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:40,801][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 1.9040507078170776, acc: 0.4743202328681946)
[2024-11-13 08:05:40,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:41,146][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 2.0034236907958984, acc: 0.4985590875148773)
[2024-11-13 08:05:41,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:41,550][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 2.0475826263427734, acc: 0.4375)
[2024-11-13 08:05:41,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:41,996][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 2.0228934288024902, acc: 0.48217636346817017)
[2024-11-13 08:05:42,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:42,339][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 1.8921910524368286, acc: 0.4483985900878906)
[2024-11-13 08:05:42,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:42,652][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.5449373722076416, acc: 0.8799999952316284)
[2024-11-13 08:05:42,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:43,081][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 1.7364850044250488, acc: 0.5465116500854492)
[2024-11-13 08:05:43,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:43,647][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 1.5264102220535278, acc: 0.60317462682724)
[2024-11-13 08:05:43,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:44,273][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 1.5958659648895264, acc: 0.560606062412262)
[2024-11-13 08:05:44,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:44,812][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 1.3126246929168701, acc: 0.6352941393852234)
[2024-11-13 08:05:44,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:45,535][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 1.3749208450317383, acc: 0.6111111044883728)
[2024-11-13 08:05:45,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:46,187][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 1.0272761583328247, acc: 0.725806474685669)
[2024-11-13 08:05:46,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:46,443][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.5168810486793518, acc: 0.7857142686843872)
[2024-11-13 08:05:46,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:46,795][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.6437254548072815, acc: 0.824999988079071)
[2024-11-13 08:05:46,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:47,121][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 1.081820011138916, acc: 0.6470588445663452)
[2024-11-13 08:05:47,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:47,450][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 1.522015929222107, acc: 0.5588235259056091)
[2024-11-13 08:05:47,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:47,738][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 1.4526551961898804, acc: 0.5762711763381958)
[2024-11-13 08:05:47,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:48,030][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 1.7026194334030151, acc: 0.5)
[2024-11-13 08:05:48,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:48,359][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 1.4142096042633057, acc: 0.5728155374526978)
[2024-11-13 08:05:48,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:48,683][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 0.9564113020896912, acc: 0.6984127163887024)
[2024-11-13 08:05:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:48,966][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 1.1081485748291016, acc: 0.6593406796455383)
[2024-11-13 08:05:49,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:49,316][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 1.7186310291290283, acc: 0.5381165742874146)
[2024-11-13 08:05:49,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:49,699][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 1.7081018686294556, acc: 0.5354330539703369)
[2024-11-13 08:05:49,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:50,030][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 1.6036659479141235, acc: 0.517241358757019)
[2024-11-13 08:05:50,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:50,366][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 1.6366339921951294, acc: 0.5579710006713867)
[2024-11-13 08:05:50,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:50,667][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 1.816161870956421, acc: 0.5097275972366333)
[2024-11-13 08:05:50,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:51,026][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 1.387597918510437, acc: 0.6195651888847351)
[2024-11-13 08:05:51,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:51,348][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.6882766485214233, acc: 0.782608687877655)
[2024-11-13 08:05:51,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:51,654][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.6036492586135864, acc: 0.8571428656578064)
[2024-11-13 08:05:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:51,956][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.6270990371704102, acc: 0.7872340679168701)
[2024-11-13 08:05:52,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:52,455][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 1.1924318075180054, acc: 0.6692307591438293)
[2024-11-13 08:05:52,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:52,736][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.9824197292327881, acc: 0.7702702879905701)
[2024-11-13 08:05:52,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:53,090][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.9953704476356506, acc: 0.6860465407371521)
[2024-11-13 08:05:53,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:53,550][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 1.1650630235671997, acc: 0.6486486196517944)
[2024-11-13 08:05:53,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:53,916][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.9876638650894165, acc: 0.699999988079071)
[2024-11-13 08:05:53,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:54,226][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.371378093957901, acc: 0.9090909361839294)
[2024-11-13 08:05:54,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:54,521][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.3075489103794098, acc: 0.8518518805503845)
[2024-11-13 08:05:54,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:54,825][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.2413858026266098, acc: 0.8799999952316284)
[2024-11-13 08:05:54,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:55,215][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.6818344593048096, acc: 0.8269230723381042)
[2024-11-13 08:05:55,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:55,777][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 1.1828683614730835, acc: 0.657608687877655)
[2024-11-13 08:05:55,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:56,227][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 1.3844400644302368, acc: 0.5965909361839294)
[2024-11-13 08:05:56,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:56,603][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 1.031447172164917, acc: 0.6702127456665039)
[2024-11-13 08:05:56,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:56,872][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.5125604867935181, acc: 0.849056601524353)
[2024-11-13 08:05:56,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:57,238][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.900579035282135, acc: 0.75)
[2024-11-13 08:05:57,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:57,549][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.4265345633029938, acc: 0.8837209343910217)
[2024-11-13 08:05:57,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:57,876][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 0.6990140080451965, acc: 0.800000011920929)
[2024-11-13 08:05:57,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:58,255][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 1.1313756704330444, acc: 0.7052631378173828)
[2024-11-13 08:05:58,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:58,568][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 0.893611490726471, acc: 0.7222222089767456)
[2024-11-13 08:05:58,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:58,944][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 1.0206429958343506, acc: 0.7111111283302307)
[2024-11-13 08:05:59,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:59,381][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.3958468437194824, acc: 0.6376146674156189)
[2024-11-13 08:05:59,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:05:59,767][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 0.9102516770362854, acc: 0.7230769395828247)
[2024-11-13 08:05:59,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:00,036][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.3423471450805664, acc: 0.8947368264198303)
[2024-11-13 08:06:00,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:00,331][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.5500863194465637, acc: 0.875)
[2024-11-13 08:06:00,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:00,632][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.8277075290679932, acc: 0.6818181872367859)
[2024-11-13 08:06:00,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:00,922][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.6617233753204346, acc: 0.7407407164573669)
[2024-11-13 08:06:01,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:01,267][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.36490294337272644, acc: 0.8857142925262451)
[2024-11-13 08:06:01,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:01,592][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.5248098373413086, acc: 0.8636363744735718)
[2024-11-13 08:06:01,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:01,925][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.7036554217338562, acc: 0.8409090638160706)
[2024-11-13 08:06:02,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:02,383][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.9415197968482971, acc: 0.7580645084381104)
[2024-11-13 08:06:02,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:02,829][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.4776405990123749, acc: 0.8409090638160706)
[2024-11-13 08:06:02,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:03,109][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.05491047725081444, acc: 1.0)
[2024-11-13 08:06:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:03,471][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.380218505859375, acc: 0.8846153616905212)
[2024-11-13 08:06:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:03,790][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.39275529980659485, acc: 0.8709677457809448)
[2024-11-13 08:06:03,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:04,171][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.5814695954322815, acc: 0.800000011920929)
[2024-11-13 08:06:04,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:04,537][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.4684932827949524, acc: 0.8648648858070374)
[2024-11-13 08:06:04,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:04,914][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.5981866717338562, acc: 0.7837837934494019)
[2024-11-13 08:06:04,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:05,270][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.42219775915145874, acc: 0.837837815284729)
[2024-11-13 08:06:05,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:05,592][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.9005479216575623, acc: 0.6911764740943909)
[2024-11-13 08:06:05,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:05,965][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.40566959977149963, acc: 0.8292682766914368)
[2024-11-13 08:06:06,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:06,316][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.22965501248836517, acc: 0.9200000166893005)
[2024-11-13 08:06:06,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:06,701][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.07574494183063507, acc: 1.0)
[2024-11-13 08:06:06,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:07,010][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.2538187503814697, acc: 0.9032257795333862)
[2024-11-13 08:06:07,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:07,288][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.6090059280395508, acc: 0.7719298005104065)
[2024-11-13 08:06:07,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:07,561][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.7971161603927612, acc: 0.7285714149475098)
[2024-11-13 08:06:07,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:07,867][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.7266308665275574, acc: 0.7105262875556946)
[2024-11-13 08:06:08,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:08,329][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 1.184348464012146, acc: 0.650943398475647)
[2024-11-13 08:06:08,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:08,792][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 1.2160428762435913, acc: 0.6499999761581421)
[2024-11-13 08:06:08,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:09,117][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.5376883149147034, acc: 0.8611111044883728)
[2024-11-13 08:06:09,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:09,429][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.6445096135139465, acc: 0.8064516186714172)
[2024-11-13 08:06:09,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:09,820][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 1.4830412864685059, acc: 0.6000000238418579)
[2024-11-13 08:06:09,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:10,168][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.6988744735717773, acc: 0.875)
[2024-11-13 08:06:10,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:10,763][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 1.899383306503296, acc: 0.47200000286102295)
[2024-11-13 08:06:10,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:11,017][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 1.2838984727859497, acc: 0.6292135119438171)
[2024-11-13 08:06:11,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:11,291][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 1.2633922100067139, acc: 0.6486486196517944)
[2024-11-13 08:06:11,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:11,644][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.9175851345062256, acc: 0.6896551847457886)
[2024-11-13 08:06:11,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:11,913][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.48292991518974304, acc: 0.8181818127632141)
[2024-11-13 08:06:11,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:12,226][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.42944660782814026, acc: 0.8181818127632141)
[2024-11-13 08:06:12,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:12,461][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.34329038858413696, acc: 0.90625)
[2024-11-13 08:06:13,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:13,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:13,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:13,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:14,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:14,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:14,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:14,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:15,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:15,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:15,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:16,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:16,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:16,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:17,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:17,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:17,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:17,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:18,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:18,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:18,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:18,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:19,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:19,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:19,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:20,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:20,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:20,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:21,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:21,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:21,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:21,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:21,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:22,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:22,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:22,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:23,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:23,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:23,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:24,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:24,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:24,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:25,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:25,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:25,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:25,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:26,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:26,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:27,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:27,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:27,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:27,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:28,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:28,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:28,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:28,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:29,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:29,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:29,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:30,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:30,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:30,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:30,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:31,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:31,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:31,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:31,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:32,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:32,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:32,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:33,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:33,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:33,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:33,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:34,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:34,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:34,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:34,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:35,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:35,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:35,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:36,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:36,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:36,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:37,365][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.4585, device='cuda:0') eval_epoch_loss=tensor(2.0094, device='cuda:0') eval_epoch_acc=tensor(0.5387, device='cuda:0')
[2024-11-13 08:06:37,366][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:06:37,366][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:06:37,851][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_8_step_272_loss_2.009357452392578/model.pt
[2024-11-13 08:06:37,862][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:06:37,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:38,221][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.49796196818351746, acc: 0.8333333134651184)
[2024-11-13 08:06:38,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:38,541][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.6838359832763672, acc: 0.8333333134651184)
[2024-11-13 08:06:38,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:38,836][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.323403924703598, acc: 0.9375)
[2024-11-13 08:06:38,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:39,161][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.26446202397346497, acc: 0.9333333373069763)
[2024-11-13 08:06:39,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:39,442][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.5358073711395264, acc: 0.8620689511299133)
[2024-11-13 08:06:39,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:39,808][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.8213340044021606, acc: 0.6800000071525574)
[2024-11-13 08:06:39,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:40,084][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.9562680125236511, acc: 0.7021276354789734)
[2024-11-13 08:06:40,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:40,386][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.8220425248146057, acc: 0.7916666865348816)
[2024-11-13 08:06:40,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:40,685][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.6536900997161865, acc: 0.8409090638160706)
[2024-11-13 08:06:40,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:41,036][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 1.336628794670105, acc: 0.6144578456878662)
[2024-11-13 08:06:41,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:41,339][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 1.4791529178619385, acc: 0.6203703880310059)
[2024-11-13 08:06:41,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:41,652][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.5627655982971191, acc: 0.8684210777282715)
[2024-11-13 08:06:41,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:41,916][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.5160899758338928, acc: 0.8235294222831726)
[2024-11-13 08:06:42,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:42,266][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.6397904753684998, acc: 0.800000011920929)
[2024-11-13 08:06:42,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:42,564][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 1.5373255014419556, acc: 0.578125)
[2024-11-13 08:06:42,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:42,882][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 1.5372415781021118, acc: 0.5759999752044678)
[2024-11-13 08:06:42,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:43,242][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 1.1471036672592163, acc: 0.6813187003135681)
[2024-11-13 08:06:43,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:43,576][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 1.8124499320983887, acc: 0.5465838313102722)
[2024-11-13 08:06:43,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:43,895][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 1.8886581659317017, acc: 0.469072163105011)
[2024-11-13 08:06:43,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:44,120][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.3997522294521332, acc: 0.9090909361839294)
[2024-11-13 08:06:44,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:44,391][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.8090985417366028, acc: 0.738095223903656)
[2024-11-13 08:06:44,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:44,659][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.837725818157196, acc: 0.7413793206214905)
[2024-11-13 08:06:44,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:45,024][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.613711416721344, acc: 0.7818182110786438)
[2024-11-13 08:06:45,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:45,456][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 1.5351167917251587, acc: 0.5876288414001465)
[2024-11-13 08:06:45,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:45,817][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.9860181212425232, acc: 0.7241379022598267)
[2024-11-13 08:06:45,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:46,192][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.6579679846763611, acc: 0.8148148059844971)
[2024-11-13 08:06:46,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:46,515][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.8794382214546204, acc: 0.7631579041481018)
[2024-11-13 08:06:46,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:46,854][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.7465170621871948, acc: 0.8392857313156128)
[2024-11-13 08:06:46,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:47,200][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.480736643075943, acc: 0.84375)
[2024-11-13 08:06:47,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:47,536][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.7086203694343567, acc: 0.8113207817077637)
[2024-11-13 08:06:47,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:47,858][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.42932286858558655, acc: 0.849056601524353)
[2024-11-13 08:06:47,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:48,150][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.6028097867965698, acc: 0.8529411554336548)
[2024-11-13 08:06:48,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:48,436][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.48698922991752625, acc: 0.84375)
[2024-11-13 08:06:48,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:48,800][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.7411083579063416, acc: 0.7868852615356445)
[2024-11-13 08:06:48,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:49,192][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.21354195475578308, acc: 1.0)
[2024-11-13 08:06:49,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:49,488][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.12472373247146606, acc: 1.0)
[2024-11-13 08:06:49,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:49,839][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.9432637095451355, acc: 0.739130437374115)
[2024-11-13 08:06:49,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:50,249][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 1.1526939868927002, acc: 0.6111111044883728)
[2024-11-13 08:06:50,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:50,552][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.8148757815361023, acc: 0.759036123752594)
[2024-11-13 08:06:50,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:50,879][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 1.183361291885376, acc: 0.6282051205635071)
[2024-11-13 08:06:50,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:51,176][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 1.3216508626937866, acc: 0.6224489808082581)
[2024-11-13 08:06:51,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:51,504][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.07559948414564133, acc: 1.0)
[2024-11-13 08:06:51,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:51,838][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.215476393699646, acc: 0.9166666865348816)
[2024-11-13 08:06:51,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:52,186][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.28752607107162476, acc: 0.9032257795333862)
[2024-11-13 08:06:52,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:52,535][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.22124098241329193, acc: 0.9032257795333862)
[2024-11-13 08:06:52,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:52,911][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.7324927449226379, acc: 0.7910447716712952)
[2024-11-13 08:06:53,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:53,270][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.9298487901687622, acc: 0.7307692170143127)
[2024-11-13 08:06:53,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:53,577][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.41980740427970886, acc: 0.8666666746139526)
[2024-11-13 08:06:53,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:53,872][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.7752842307090759, acc: 0.7580645084381104)
[2024-11-13 08:06:53,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:54,223][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.41869479417800903, acc: 0.8799999952316284)
[2024-11-13 08:06:54,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:54,531][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 1.026006817817688, acc: 0.5925925970077515)
[2024-11-13 08:06:54,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:54,858][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 0.8408295512199402, acc: 0.800000011920929)
[2024-11-13 08:06:54,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:55,129][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.9832549691200256, acc: 0.6666666865348816)
[2024-11-13 08:06:55,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:55,423][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 1.1193047761917114, acc: 0.707317054271698)
[2024-11-13 08:06:55,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:55,721][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.7692916989326477, acc: 0.8157894611358643)
[2024-11-13 08:06:55,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:56,008][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.16572818160057068, acc: 0.9473684430122375)
[2024-11-13 08:06:56,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:56,351][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.38344302773475647, acc: 0.8928571343421936)
[2024-11-13 08:06:56,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:56,703][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.5604881644248962, acc: 0.7777777910232544)
[2024-11-13 08:06:56,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:57,034][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.3457879424095154, acc: 0.9375)
[2024-11-13 08:06:57,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:57,343][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.8972766995429993, acc: 0.7419354915618896)
[2024-11-13 08:06:57,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:57,737][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.8346641659736633, acc: 0.7543859481811523)
[2024-11-13 08:06:57,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:58,111][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.7991625070571899, acc: 0.84375)
[2024-11-13 08:06:58,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:58,462][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.40518322587013245, acc: 0.8666666746139526)
[2024-11-13 08:06:58,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:58,779][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.43665143847465515, acc: 0.8421052694320679)
[2024-11-13 08:06:58,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:59,049][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.8366026878356934, acc: 0.7599999904632568)
[2024-11-13 08:06:59,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:59,351][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 1.4348492622375488, acc: 0.5862069129943848)
[2024-11-13 08:06:59,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:59,685][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 1.4796913862228394, acc: 0.6063829660415649)
[2024-11-13 08:06:59,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:06:59,965][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 1.578308343887329, acc: 0.5542168617248535)
[2024-11-13 08:07:00,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:00,255][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.29929107427597046, acc: 0.9130434989929199)
[2024-11-13 08:07:00,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:00,612][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.680602490901947, acc: 0.8205128312110901)
[2024-11-13 08:07:00,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:00,867][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 1.1057822704315186, acc: 0.6385542154312134)
[2024-11-13 08:07:00,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:01,252][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.6276275515556335, acc: 0.8301886916160583)
[2024-11-13 08:07:01,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:01,585][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.658164918422699, acc: 0.797468364238739)
[2024-11-13 08:07:01,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:01,907][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.5356212854385376, acc: 0.843137264251709)
[2024-11-13 08:07:01,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:02,196][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 1.5678296089172363, acc: 0.5671641826629639)
[2024-11-13 08:07:02,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:02,470][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.3846181631088257, acc: 0.8500000238418579)
[2024-11-13 08:07:02,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:02,819][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.3446381092071533, acc: 0.9200000166893005)
[2024-11-13 08:07:02,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:03,164][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.8125898241996765, acc: 0.7777777910232544)
[2024-11-13 08:07:03,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:03,455][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 1.1170523166656494, acc: 0.604651153087616)
[2024-11-13 08:07:03,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:03,739][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 1.1242246627807617, acc: 0.7179487347602844)
[2024-11-13 08:07:03,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:04,075][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 1.035521388053894, acc: 0.6666666865348816)
[2024-11-13 08:07:04,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:04,414][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.48416051268577576, acc: 0.782608687877655)
[2024-11-13 08:07:04,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:04,762][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.4059807360172272, acc: 0.9230769276618958)
[2024-11-13 08:07:04,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:05,064][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 1.6634879112243652, acc: 0.5714285969734192)
[2024-11-13 08:07:05,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:05,473][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 1.5056480169296265, acc: 0.573913037776947)
[2024-11-13 08:07:05,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:05,817][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 1.3420536518096924, acc: 0.5978260636329651)
[2024-11-13 08:07:05,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:06,146][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.8836077451705933, acc: 0.7755101919174194)
[2024-11-13 08:07:06,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:06,448][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.12615126371383667, acc: 1.0)
[2024-11-13 08:07:06,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:06,820][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.3506248891353607, acc: 0.9230769276618958)
[2024-11-13 08:07:06,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:07,096][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.4021092355251312, acc: 0.9024389982223511)
[2024-11-13 08:07:07,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:07,428][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.7257821559906006, acc: 0.7333333492279053)
[2024-11-13 08:07:07,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:07,768][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 0.8788231015205383, acc: 0.7105262875556946)
[2024-11-13 08:07:07,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:08,100][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.5623968243598938, acc: 0.8292682766914368)
[2024-11-13 08:07:08,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:08,446][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.9520565867424011, acc: 0.6666666865348816)
[2024-11-13 08:07:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:08,766][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.19640447199344635, acc: 0.9583333134651184)
[2024-11-13 08:07:08,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:09,049][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.03466382622718811, acc: 1.0)
[2024-11-13 08:07:09,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:09,342][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.1906656175851822, acc: 0.9642857313156128)
[2024-11-13 08:07:09,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:09,648][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.4785548448562622, acc: 0.875)
[2024-11-13 08:07:09,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:10,118][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 1.3924779891967773, acc: 0.6424242258071899)
[2024-11-13 08:07:10,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:10,698][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 1.0211098194122314, acc: 0.6792452931404114)
[2024-11-13 08:07:10,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:11,055][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 1.021511435508728, acc: 0.7555555701255798)
[2024-11-13 08:07:11,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:11,380][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.8295570611953735, acc: 0.6964285969734192)
[2024-11-13 08:07:11,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:11,705][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.34879541397094727, acc: 0.9142857193946838)
[2024-11-13 08:07:11,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:12,002][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.1846814602613449, acc: 0.9599999785423279)
[2024-11-13 08:07:12,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:12,301][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.29876843094825745, acc: 0.9130434989929199)
[2024-11-13 08:07:12,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:12,628][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.6993840336799622, acc: 0.7708333134651184)
[2024-11-13 08:07:12,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:12,958][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 1.0916221141815186, acc: 0.7052631378173828)
[2024-11-13 08:07:13,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:13,415][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 1.349568486213684, acc: 0.5928143858909607)
[2024-11-13 08:07:13,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:13,827][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.9280158877372742, acc: 0.7142857313156128)
[2024-11-13 08:07:14,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:14,569][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 1.3466343879699707, acc: 0.6310160160064697)
[2024-11-13 08:07:14,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:15,016][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.7912513017654419, acc: 0.7657657861709595)
[2024-11-13 08:07:15,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:15,294][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.3306160569190979, acc: 0.9285714030265808)
[2024-11-13 08:07:15,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:15,593][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.09693054109811783, acc: 1.0)
[2024-11-13 08:07:15,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:15,940][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.4658074676990509, acc: 0.875)
[2024-11-13 08:07:16,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:16,257][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.49779924750328064, acc: 0.8333333134651184)
[2024-11-13 08:07:16,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:16,570][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.44965341687202454, acc: 0.9210526347160339)
[2024-11-13 08:07:16,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:16,896][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.11310689896345139, acc: 1.0)
[2024-11-13 08:07:16,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:17,216][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.3583182692527771, acc: 0.8500000238418579)
[2024-11-13 08:07:17,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:17,555][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.4215308129787445, acc: 0.9047619104385376)
[2024-11-13 08:07:17,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:17,926][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.9510608911514282, acc: 0.7407407164573669)
[2024-11-13 08:07:18,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:18,255][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 1.4613512754440308, acc: 0.5922330021858215)
[2024-11-13 08:07:18,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:18,678][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 1.4807615280151367, acc: 0.5882353186607361)
[2024-11-13 08:07:18,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:19,002][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 1.565423846244812, acc: 0.5400000214576721)
[2024-11-13 08:07:19,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:19,361][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 1.7015962600708008, acc: 0.5138888955116272)
[2024-11-13 08:07:19,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:19,666][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.8004150986671448, acc: 0.7906976938247681)
[2024-11-13 08:07:19,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:20,020][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.21469151973724365, acc: 0.9583333134651184)
[2024-11-13 08:07:20,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:20,359][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.5510123372077942, acc: 0.8372092843055725)
[2024-11-13 08:07:20,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:20,662][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.24098634719848633, acc: 0.9200000166893005)
[2024-11-13 08:07:20,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:21,094][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.9316174983978271, acc: 0.75)
[2024-11-13 08:07:21,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:21,434][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.9599581956863403, acc: 0.6933333277702332)
[2024-11-13 08:07:21,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:21,780][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.7382558584213257, acc: 0.7272727489471436)
[2024-11-13 08:07:21,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:22,140][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.39426541328430176, acc: 0.8787878751754761)
[2024-11-13 08:07:22,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:22,420][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.458957701921463, acc: 0.8709677457809448)
[2024-11-13 08:07:22,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:22,736][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.5408100485801697, acc: 0.8148148059844971)
[2024-11-13 08:07:22,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:23,098][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.18941713869571686, acc: 0.9599999785423279)
[2024-11-13 08:07:23,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:23,427][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.39794209599494934, acc: 0.8611111044883728)
[2024-11-13 08:07:23,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:23,783][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.3855619728565216, acc: 0.8888888955116272)
[2024-11-13 08:07:23,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:24,134][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.1694873720407486, acc: 0.9230769276618958)
[2024-11-13 08:07:24,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:24,435][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.8640890717506409, acc: 0.7413793206214905)
[2024-11-13 08:07:24,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:24,813][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.46238917112350464, acc: 0.8214285969734192)
[2024-11-13 08:07:24,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:25,174][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.3204433023929596, acc: 0.8999999761581421)
[2024-11-13 08:07:25,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:25,489][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.3405608534812927, acc: 0.8484848737716675)
[2024-11-13 08:07:25,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:25,799][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.5878987312316895, acc: 0.7727272510528564)
[2024-11-13 08:07:26,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:26,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:27,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:27,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:27,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:27,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:28,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:28,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:28,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:29,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:29,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:29,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:29,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:30,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:30,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:30,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:31,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:31,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:31,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:32,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:32,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:32,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:32,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:33,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:33,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:33,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:33,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:34,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:34,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:34,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:35,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:35,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:35,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:35,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:36,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:36,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:36,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:36,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:37,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:37,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:38,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:38,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:38,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:38,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:39,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:39,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:39,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:39,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:40,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:40,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:40,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:40,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:41,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:41,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:41,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:41,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:42,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:42,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:42,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:43,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:43,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:43,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:44,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:44,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:44,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:44,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:45,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:45,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:45,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:46,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:46,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:46,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:46,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:47,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:47,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:47,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:47,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:47,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:48,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:48,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:48,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:48,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:49,410][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.9140, device='cuda:0') eval_epoch_loss=tensor(2.0686, device='cuda:0') eval_epoch_acc=tensor(0.5580, device='cuda:0')
[2024-11-13 08:07:49,411][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:07:49,411][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:07:49,745][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_8_step_415_loss_2.0686309337615967/model.pt
[2024-11-13 08:07:49,750][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:07:49,750][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.5579565763473511
[2024-11-13 08:07:49,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:50,118][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.9493249654769897, acc: 0.7450980544090271)
[2024-11-13 08:07:50,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:50,461][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.7112535238265991, acc: 0.807692289352417)
[2024-11-13 08:07:50,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:50,778][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.7836257815361023, acc: 0.7222222089767456)
[2024-11-13 08:07:50,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:51,137][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.8252789378166199, acc: 0.699999988079071)
[2024-11-13 08:07:51,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:51,454][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.7584415674209595, acc: 0.800000011920929)
[2024-11-13 08:07:51,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:51,742][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.2755873501300812, acc: 0.8571428656578064)
[2024-11-13 08:07:51,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:52,067][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.36378464102745056, acc: 0.8999999761581421)
[2024-11-13 08:07:52,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:52,390][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.3252451717853546, acc: 0.875)
[2024-11-13 08:07:52,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:52,683][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.5698046088218689, acc: 0.8888888955116272)
[2024-11-13 08:07:52,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:52,973][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.33228403329849243, acc: 0.9259259104728699)
[2024-11-13 08:07:53,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:53,250][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.6916590929031372, acc: 0.8181818127632141)
[2024-11-13 08:07:53,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:53,541][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 0.9106093645095825, acc: 0.782608687877655)
[2024-11-13 08:07:53,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:53,868][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.4406486749649048, acc: 0.837837815284729)
[2024-11-13 08:07:53,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:54,190][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.5458773374557495, acc: 0.8148148059844971)
[2024-11-13 08:07:54,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:54,482][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.3003556728363037, acc: 0.8260869383811951)
[2024-11-13 08:07:54,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:54,765][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.08032399415969849, acc: 1.0)
[2024-11-13 08:07:54,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:55,050][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.13160032033920288, acc: 0.9629629850387573)
[2024-11-13 08:07:55,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:55,337][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.1157592386007309, acc: 1.0)
[2024-11-13 08:07:55,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:55,657][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.5537614226341248, acc: 0.8333333134651184)
[2024-11-13 08:07:55,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:55,948][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.34324634075164795, acc: 0.800000011920929)
[2024-11-13 08:07:56,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:56,257][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.49399879574775696, acc: 0.8181818127632141)
[2024-11-13 08:07:56,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:56,558][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.7247021794319153, acc: 0.7777777910232544)
[2024-11-13 08:07:56,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:56,856][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.5779481530189514, acc: 0.8181818127632141)
[2024-11-13 08:07:56,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:57,157][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.13227394223213196, acc: 0.9523809552192688)
[2024-11-13 08:07:57,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:57,459][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.8604472279548645, acc: 0.7435897588729858)
[2024-11-13 08:07:57,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:57,831][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 1.0628453493118286, acc: 0.7272727489471436)
[2024-11-13 08:07:57,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:58,336][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 1.8933137655258179, acc: 0.47999998927116394)
[2024-11-13 08:07:58,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:58,699][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 1.5943301916122437, acc: 0.5483871102333069)
[2024-11-13 08:07:58,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:59,202][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 1.7120412588119507, acc: 0.5572139024734497)
[2024-11-13 08:07:59,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:59,512][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.9879319071769714, acc: 0.7358490824699402)
[2024-11-13 08:07:59,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:07:59,865][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.6014333367347717, acc: 0.8636363744735718)
[2024-11-13 08:07:59,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:00,170][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.339537650346756, acc: 0.8695651888847351)
[2024-11-13 08:08:00,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:00,480][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.560944676399231, acc: 0.7692307829856873)
[2024-11-13 08:08:00,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:00,778][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.3737618923187256, acc: 0.8928571343421936)
[2024-11-13 08:08:00,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:01,079][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.7551153302192688, acc: 0.746268630027771)
[2024-11-13 08:08:01,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:01,377][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.8185234665870667, acc: 0.7361111044883728)
[2024-11-13 08:08:01,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:01,663][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.9192752838134766, acc: 0.739130437374115)
[2024-11-13 08:08:01,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:01,957][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.9684120416641235, acc: 0.692307710647583)
[2024-11-13 08:08:02,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:02,246][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.9373048543930054, acc: 0.6842105388641357)
[2024-11-13 08:08:02,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:02,547][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.8129831552505493, acc: 0.7346938848495483)
[2024-11-13 08:08:02,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:02,830][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.44125574827194214, acc: 0.8181818127632141)
[2024-11-13 08:08:02,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:03,135][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 1.6075212955474854, acc: 0.5463917255401611)
[2024-11-13 08:08:03,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:03,399][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.7391480207443237, acc: 0.7714285850524902)
[2024-11-13 08:08:03,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:03,728][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 1.4407778978347778, acc: 0.6104651093482971)
[2024-11-13 08:08:03,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:03,999][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.8552708029747009, acc: 0.6428571343421936)
[2024-11-13 08:08:04,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:04,298][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 1.403959035873413, acc: 0.6419752836227417)
[2024-11-13 08:08:04,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:04,592][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.6697627902030945, acc: 0.8333333134651184)
[2024-11-13 08:08:04,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:04,880][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.3675309121608734, acc: 0.9375)
[2024-11-13 08:08:04,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:05,160][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.24809648096561432, acc: 0.9230769276618958)
[2024-11-13 08:08:05,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:05,451][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.483417809009552, acc: 0.8695651888847351)
[2024-11-13 08:08:05,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:05,756][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 1.157126784324646, acc: 0.6428571343421936)
[2024-11-13 08:08:05,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:06,062][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 1.0917414426803589, acc: 0.6987951993942261)
[2024-11-13 08:08:06,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:06,375][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.9807798266410828, acc: 0.7297297120094299)
[2024-11-13 08:08:06,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:06,669][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 1.0985673666000366, acc: 0.6699029207229614)
[2024-11-13 08:08:06,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:06,985][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 1.0271244049072266, acc: 0.7560975551605225)
[2024-11-13 08:08:07,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:07,296][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.6072195172309875, acc: 0.8333333134651184)
[2024-11-13 08:08:07,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:07,579][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.4455186724662781, acc: 0.8928571343421936)
[2024-11-13 08:08:07,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:07,926][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 1.4267573356628418, acc: 0.5882353186607361)
[2024-11-13 08:08:08,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:08,254][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 1.8340144157409668, acc: 0.47598254680633545)
[2024-11-13 08:08:08,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:08,546][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 1.238996148109436, acc: 0.6875)
[2024-11-13 08:08:08,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:08,851][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 1.5603957176208496, acc: 0.558282196521759)
[2024-11-13 08:08:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:09,146][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 1.527204990386963, acc: 0.5395683646202087)
[2024-11-13 08:08:09,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:09,442][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 1.7749708890914917, acc: 0.45728641748428345)
[2024-11-13 08:08:09,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:09,721][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.4573066532611847, acc: 0.8333333134651184)
[2024-11-13 08:08:09,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:10,022][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.5681230425834656, acc: 0.8787878751754761)
[2024-11-13 08:08:10,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:10,318][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.5973184108734131, acc: 0.8888888955116272)
[2024-11-13 08:08:10,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:10,631][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.4176814556121826, acc: 0.8500000238418579)
[2024-11-13 08:08:10,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:10,939][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.6691914796829224, acc: 0.75)
[2024-11-13 08:08:11,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:11,276][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.7039539217948914, acc: 0.7413793206214905)
[2024-11-13 08:08:11,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:11,566][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.2814674377441406, acc: 0.9354838728904724)
[2024-11-13 08:08:11,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:11,892][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.43200522661209106, acc: 0.8947368264198303)
[2024-11-13 08:08:11,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:12,187][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.7117104530334473, acc: 0.7407407164573669)
[2024-11-13 08:08:12,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:12,482][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.5423862338066101, acc: 0.8571428656578064)
[2024-11-13 08:08:12,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:12,788][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.46085119247436523, acc: 0.7272727489471436)
[2024-11-13 08:08:12,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:13,145][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.8909845352172852, acc: 0.7692307829856873)
[2024-11-13 08:08:13,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:13,456][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.45017772912979126, acc: 0.8666666746139526)
[2024-11-13 08:08:13,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:13,758][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.4651663601398468, acc: 0.8275862336158752)
[2024-11-13 08:08:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:14,069][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.7462663650512695, acc: 0.7450980544090271)
[2024-11-13 08:08:14,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:14,366][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.9773383736610413, acc: 0.6206896305084229)
[2024-11-13 08:08:14,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:14,666][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.256440132856369, acc: 0.9473684430122375)
[2024-11-13 08:08:14,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:14,956][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.6918465495109558, acc: 0.7368420958518982)
[2024-11-13 08:08:15,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:15,275][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 1.1029561758041382, acc: 0.625)
[2024-11-13 08:08:15,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:15,616][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 1.0000029802322388, acc: 0.7078651785850525)
[2024-11-13 08:08:15,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:15,911][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 1.2771873474121094, acc: 0.617977499961853)
[2024-11-13 08:08:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:16,203][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 1.7005891799926758, acc: 0.5106382966041565)
[2024-11-13 08:08:16,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:16,497][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 1.2627201080322266, acc: 0.5760869383811951)
[2024-11-13 08:08:16,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:16,788][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.21062633395195007, acc: 0.9200000166893005)
[2024-11-13 08:08:16,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:17,076][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.43614381551742554, acc: 0.807692289352417)
[2024-11-13 08:08:17,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:17,348][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.6781418323516846, acc: 0.7777777910232544)
[2024-11-13 08:08:17,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:17,673][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 1.099890947341919, acc: 0.7037037014961243)
[2024-11-13 08:08:17,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:17,968][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.7728159427642822, acc: 0.7169811129570007)
[2024-11-13 08:08:18,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:18,272][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.6181173920631409, acc: 0.7931034564971924)
[2024-11-13 08:08:18,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:18,717][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 1.3797850608825684, acc: 0.5945945978164673)
[2024-11-13 08:08:18,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:19,065][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 1.0567207336425781, acc: 0.7746478915214539)
[2024-11-13 08:08:19,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:19,344][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.536955714225769, acc: 0.8500000238418579)
[2024-11-13 08:08:19,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:19,640][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.5652583241462708, acc: 0.8333333134651184)
[2024-11-13 08:08:19,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:19,952][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.4521900713443756, acc: 0.9230769276618958)
[2024-11-13 08:08:20,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:21,145][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 1.6129896640777588, acc: 0.5642856955528259)
[2024-11-13 08:08:21,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:21,696][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 1.4001777172088623, acc: 0.5634920597076416)
[2024-11-13 08:08:21,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:21,962][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.6222184896469116, acc: 0.8214285969734192)
[2024-11-13 08:08:22,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:22,239][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.904071033000946, acc: 0.7166666388511658)
[2024-11-13 08:08:22,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:22,764][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.8935454487800598, acc: 0.7777777910232544)
[2024-11-13 08:08:22,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:23,031][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.21049128472805023, acc: 0.8846153616905212)
[2024-11-13 08:08:23,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:23,306][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.8445427417755127, acc: 0.774193525314331)
[2024-11-13 08:08:23,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:23,587][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.6937901973724365, acc: 0.75)
[2024-11-13 08:08:23,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:23,896][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.9285873174667358, acc: 0.7037037014961243)
[2024-11-13 08:08:24,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:24,594][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 1.8026050329208374, acc: 0.4830508530139923)
[2024-11-13 08:08:24,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:24,900][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 1.448270320892334, acc: 0.5746268630027771)
[2024-11-13 08:08:24,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:25,222][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 1.28922700881958, acc: 0.6058394312858582)
[2024-11-13 08:08:25,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:25,659][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 1.681026577949524, acc: 0.5550000071525574)
[2024-11-13 08:08:25,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:25,934][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.7157793641090393, acc: 0.7777777910232544)
[2024-11-13 08:08:25,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:26,212][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.7175620794296265, acc: 0.7307692170143127)
[2024-11-13 08:08:26,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:26,463][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.7148670554161072, acc: 0.7142857313156128)
[2024-11-13 08:08:26,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:26,783][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 1.2175517082214355, acc: 0.6065573692321777)
[2024-11-13 08:08:26,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:27,060][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.8622189164161682, acc: 0.7966101765632629)
[2024-11-13 08:08:27,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:27,338][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 1.01565682888031, acc: 0.7209302186965942)
[2024-11-13 08:08:27,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:27,630][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.48627516627311707, acc: 0.9090909361839294)
[2024-11-13 08:08:27,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:27,927][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.8225156664848328, acc: 0.7547169923782349)
[2024-11-13 08:08:28,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:28,246][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.6686937212944031, acc: 0.7727272510528564)
[2024-11-13 08:08:28,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:28,544][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.5147339105606079, acc: 0.8399999737739563)
[2024-11-13 08:08:28,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:28,868][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.5323299765586853, acc: 0.8500000238418579)
[2024-11-13 08:08:28,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:29,162][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.6793848276138306, acc: 0.8636363744735718)
[2024-11-13 08:08:29,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:29,503][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 1.0780025720596313, acc: 0.7230769395828247)
[2024-11-13 08:08:29,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:29,797][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.8059390783309937, acc: 0.796875)
[2024-11-13 08:08:29,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:30,128][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.5184810757637024, acc: 0.90625)
[2024-11-13 08:08:30,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:30,398][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.7031993269920349, acc: 0.6969696879386902)
[2024-11-13 08:08:30,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:30,696][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.375432550907135, acc: 0.875)
[2024-11-13 08:08:30,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:30,989][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.4480588734149933, acc: 0.8387096524238586)
[2024-11-13 08:08:31,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:31,304][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.12264572083950043, acc: 1.0)
[2024-11-13 08:08:31,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:31,600][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.5436472296714783, acc: 0.800000011920929)
[2024-11-13 08:08:31,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:31,911][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.559683620929718, acc: 0.8048780560493469)
[2024-11-13 08:08:31,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:32,200][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.39736947417259216, acc: 0.8571428656578064)
[2024-11-13 08:08:32,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:32,489][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.5175005793571472, acc: 0.8157894611358643)
[2024-11-13 08:08:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:32,764][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.531272828578949, acc: 0.8064516186714172)
[2024-11-13 08:08:32,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:33,059][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.25846078991889954, acc: 0.9200000166893005)
[2024-11-13 08:08:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:33,357][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.3468230664730072, acc: 0.9090909361839294)
[2024-11-13 08:08:33,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:33,649][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.36579757928848267, acc: 0.925000011920929)
[2024-11-13 08:08:33,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:33,935][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.6597009301185608, acc: 0.8428571224212646)
[2024-11-13 08:08:34,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:34,239][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 1.6494736671447754, acc: 0.49635037779808044)
[2024-11-13 08:08:34,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:34,551][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 1.2443561553955078, acc: 0.6000000238418579)
[2024-11-13 08:08:34,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:34,864][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 1.703884482383728, acc: 0.550000011920929)
[2024-11-13 08:08:34,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:35,176][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 1.5175296068191528, acc: 0.49668875336647034)
[2024-11-13 08:08:35,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:35,500][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 1.0975784063339233, acc: 0.6410256624221802)
[2024-11-13 08:08:36,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:36,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:36,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:37,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:37,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:37,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:37,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:38,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:38,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:38,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:39,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:39,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:39,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:39,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:40,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:40,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:40,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:41,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:41,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:41,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:41,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:42,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:42,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:42,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:43,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:43,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:43,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:43,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:44,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:44,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:44,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:45,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:45,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:45,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:45,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:46,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:46,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:46,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:46,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:47,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:47,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:47,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:47,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:48,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:48,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:48,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:48,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:49,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:49,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:49,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:50,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:50,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:50,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:51,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:51,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:51,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:51,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:52,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:52,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:52,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:52,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:53,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:53,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:53,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:54,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:54,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:54,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:54,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:55,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:55,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:55,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:55,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:56,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:56,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:56,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:57,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:57,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:57,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:57,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:58,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:58,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:58,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:58,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:59,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:08:59,707][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.1275, device='cuda:0') eval_epoch_loss=tensor(1.9640, device='cuda:0') eval_epoch_acc=tensor(0.5519, device='cuda:0')
[2024-11-13 08:08:59,708][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:08:59,708][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:09:00,043][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_8_step_558_loss_1.9639612436294556/model.pt
[2024-11-13 08:09:00,047][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:09:00,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:00,399][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.19806917011737823, acc: 0.9200000166893005)
[2024-11-13 08:09:00,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:00,706][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.3089652359485626, acc: 0.9615384340286255)
[2024-11-13 08:09:00,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:01,069][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.28787124156951904, acc: 0.8846153616905212)
[2024-11-13 08:09:01,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:01,425][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.653593897819519, acc: 0.7948718070983887)
[2024-11-13 08:09:01,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:01,798][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.8688400387763977, acc: 0.7666666507720947)
[2024-11-13 08:09:01,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:02,097][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.6035102009773254, acc: 0.8311688303947449)
[2024-11-13 08:09:02,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:02,431][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.5413431525230408, acc: 0.8333333134651184)
[2024-11-13 08:09:02,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:02,766][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.5220038294792175, acc: 0.8275862336158752)
[2024-11-13 08:09:02,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:03,099][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 0.8600248694419861, acc: 0.7023809552192688)
[2024-11-13 08:09:03,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:03,439][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.39598986506462097, acc: 0.9210526347160339)
[2024-11-13 08:09:03,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:03,789][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.45039287209510803, acc: 0.8888888955116272)
[2024-11-13 08:09:03,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:04,148][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 1.46589994430542, acc: 0.614973247051239)
[2024-11-13 08:09:04,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:04,447][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.9018070697784424, acc: 0.725806474685669)
[2024-11-13 08:09:04,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:04,778][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.8723472952842712, acc: 0.7179487347602844)
[2024-11-13 08:09:04,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:05,092][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 1.5474234819412231, acc: 0.581632673740387)
[2024-11-13 08:09:05,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:05,410][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 1.5677845478057861, acc: 0.5786163806915283)
[2024-11-13 08:09:05,800][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=2.3548, train_epoch_loss=0.8565, epoch time 296.0694391261786s
[2024-11-13 08:09:05,800][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 08:09:05,800][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 08:09:05,800][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 08:09:05,800][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 08:09:05,800][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 08:09:06,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:06,635][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.3718778192996979, acc: 0.8518518805503845)
[2024-11-13 08:09:06,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:06,905][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.27281519770622253, acc: 0.9599999785423279)
[2024-11-13 08:09:06,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:07,231][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.7452341318130493, acc: 0.7837837934494019)
[2024-11-13 08:09:07,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:07,591][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.6250817775726318, acc: 0.8157894611358643)
[2024-11-13 08:09:07,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:07,877][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.6730598211288452, acc: 0.837837815284729)
[2024-11-13 08:09:07,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:08,195][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.42395028471946716, acc: 0.8571428656578064)
[2024-11-13 08:09:08,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:08,539][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.6469443440437317, acc: 0.795918345451355)
[2024-11-13 08:09:08,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:08,871][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.5753622055053711, acc: 0.800000011920929)
[2024-11-13 08:09:08,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:09,243][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.12891584634780884, acc: 0.9545454382896423)
[2024-11-13 08:09:09,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:09,598][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.13627487421035767, acc: 0.9615384340286255)
[2024-11-13 08:09:09,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:09,940][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.16793248057365417, acc: 0.9629629850387573)
[2024-11-13 08:09:10,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:10,222][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.5506266355514526, acc: 0.8461538553237915)
[2024-11-13 08:09:10,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:10,487][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.46336686611175537, acc: 0.8787878751754761)
[2024-11-13 08:09:10,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:10,867][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.6717828512191772, acc: 0.8478260636329651)
[2024-11-13 08:09:10,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:11,214][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.8299337029457092, acc: 0.6666666865348816)
[2024-11-13 08:09:11,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:11,544][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.6664935350418091, acc: 0.8163265585899353)
[2024-11-13 08:09:11,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:11,910][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.246689572930336, acc: 0.9473684430122375)
[2024-11-13 08:09:11,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:12,263][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.7134745717048645, acc: 0.7916666865348816)
[2024-11-13 08:09:12,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:12,576][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.5287497043609619, acc: 0.8333333134651184)
[2024-11-13 08:09:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:12,892][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.3984459340572357, acc: 0.8421052694320679)
[2024-11-13 08:09:12,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:13,266][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.46205008029937744, acc: 0.7692307829856873)
[2024-11-13 08:09:13,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:13,621][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.43426817655563354, acc: 0.8275862336158752)
[2024-11-13 08:09:13,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:13,942][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.8880909085273743, acc: 0.8399999737739563)
[2024-11-13 08:09:14,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:14,247][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.35870710015296936, acc: 0.8571428656578064)
[2024-11-13 08:09:14,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:14,543][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.30340272188186646, acc: 0.875)
[2024-11-13 08:09:14,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:14,869][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.7565204501152039, acc: 0.7547169923782349)
[2024-11-13 08:09:14,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:15,208][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.9403099417686462, acc: 0.7260273694992065)
[2024-11-13 08:09:15,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:15,939][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 1.8233665227890015, acc: 0.5375494360923767)
[2024-11-13 08:09:15,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:16,208][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.5058209896087646, acc: 0.8372092843055725)
[2024-11-13 08:09:16,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:16,548][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.9069658517837524, acc: 0.6867470145225525)
[2024-11-13 08:09:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:16,911][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.941341757774353, acc: 0.7037037014961243)
[2024-11-13 08:09:16,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:17,234][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.5434352159500122, acc: 0.8214285969734192)
[2024-11-13 08:09:17,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:17,532][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.3249124586582184, acc: 0.8888888955116272)
[2024-11-13 08:09:17,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:17,859][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.20136092603206635, acc: 0.9130434989929199)
[2024-11-13 08:09:17,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:18,205][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 1.5305883884429932, acc: 0.5630252361297607)
[2024-11-13 08:09:18,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:18,594][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.8095375895500183, acc: 0.7540983557701111)
[2024-11-13 08:09:18,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:18,939][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.8301822543144226, acc: 0.7460317611694336)
[2024-11-13 08:09:19,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:19,250][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.8635947108268738, acc: 0.6779661178588867)
[2024-11-13 08:09:19,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:19,550][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.8680697679519653, acc: 0.7586206793785095)
[2024-11-13 08:09:19,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:19,831][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.33282220363616943, acc: 0.8571428656578064)
[2024-11-13 08:09:19,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:20,155][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.42323967814445496, acc: 0.8846153616905212)
[2024-11-13 08:09:20,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:20,505][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 1.1324342489242554, acc: 0.6216216087341309)
[2024-11-13 08:09:20,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:20,821][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 1.105020523071289, acc: 0.6769230961799622)
[2024-11-13 08:09:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:21,173][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 1.5346779823303223, acc: 0.5151515007019043)
[2024-11-13 08:09:21,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:21,572][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 1.0881577730178833, acc: 0.6804123520851135)
[2024-11-13 08:09:21,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:21,976][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 1.4444985389709473, acc: 0.6029411554336548)
[2024-11-13 08:09:22,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:22,285][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.3305053412914276, acc: 0.9615384340286255)
[2024-11-13 08:09:22,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:22,601][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.15046392381191254, acc: 0.9629629850387573)
[2024-11-13 08:09:22,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:22,899][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.5708566904067993, acc: 0.8571428656578064)
[2024-11-13 08:09:22,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:23,241][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.3566950559616089, acc: 0.9166666865348816)
[2024-11-13 08:09:23,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:23,613][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.8674522638320923, acc: 0.7543859481811523)
[2024-11-13 08:09:23,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:23,997][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.9788889288902283, acc: 0.682539701461792)
[2024-11-13 08:09:24,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:24,313][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.8306535482406616, acc: 0.7323943376541138)
[2024-11-13 08:09:24,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:24,690][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 1.5791432857513428, acc: 0.5666666626930237)
[2024-11-13 08:09:24,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:25,011][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.40130800008773804, acc: 0.8648648858070374)
[2024-11-13 08:09:25,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:25,371][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.3127662241458893, acc: 0.8846153616905212)
[2024-11-13 08:09:25,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:26,682][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.6340938806533813, acc: 0.5494880676269531)
[2024-11-13 08:09:26,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:27,499][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 2.128115653991699, acc: 0.43572986125946045)
[2024-11-13 08:09:27,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:28,011][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 1.5798611640930176, acc: 0.5568181872367859)
[2024-11-13 08:09:28,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:28,463][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 1.3791686296463013, acc: 0.625)
[2024-11-13 08:09:28,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:28,907][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 1.7333265542984009, acc: 0.47826087474823)
[2024-11-13 08:09:28,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:29,251][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 1.2355901002883911, acc: 0.6875)
[2024-11-13 08:09:29,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:29,558][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.1763339787721634, acc: 0.970588207244873)
[2024-11-13 08:09:29,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:29,915][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.8642100691795349, acc: 0.7777777910232544)
[2024-11-13 08:09:29,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:30,280][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.6442195177078247, acc: 0.78125)
[2024-11-13 08:09:30,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:30,619][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.29279062151908875, acc: 0.931034505367279)
[2024-11-13 08:09:30,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:30,952][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.8305252194404602, acc: 0.7321428656578064)
[2024-11-13 08:09:31,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:31,275][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.979705274105072, acc: 0.699999988079071)
[2024-11-13 08:09:31,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:31,569][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.17486274242401123, acc: 0.9599999785423279)
[2024-11-13 08:09:31,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:31,905][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.3778289258480072, acc: 0.8611111044883728)
[2024-11-13 08:09:31,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:32,204][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.5030978918075562, acc: 0.8181818127632141)
[2024-11-13 08:09:32,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:32,580][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 1.504685640335083, acc: 0.5882353186607361)
[2024-11-13 08:09:32,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:32,959][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 1.3057630062103271, acc: 0.6428571343421936)
[2024-11-13 08:09:33,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:33,253][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 1.7520074844360352, acc: 0.5076923370361328)
[2024-11-13 08:09:33,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:33,562][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 1.0798879861831665, acc: 0.6734693646430969)
[2024-11-13 08:09:33,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:33,883][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 1.5601757764816284, acc: 0.5447761416435242)
[2024-11-13 08:09:33,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:34,216][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 1.8201290369033813, acc: 0.510948896408081)
[2024-11-13 08:09:34,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:34,566][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.1712133288383484, acc: 0.9523809552192688)
[2024-11-13 08:09:34,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:34,920][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.21485698223114014, acc: 0.9583333134651184)
[2024-11-13 08:09:34,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:35,210][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.41309383511543274, acc: 0.8484848737716675)
[2024-11-13 08:09:35,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:35,590][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.30582496523857117, acc: 0.8461538553237915)
[2024-11-13 08:09:35,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:35,948][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.6255330443382263, acc: 0.8653846383094788)
[2024-11-13 08:09:36,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:36,320][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.8915132284164429, acc: 0.6538461446762085)
[2024-11-13 08:09:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:36,682][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.40103843808174133, acc: 0.875)
[2024-11-13 08:09:36,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:37,017][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.8423408269882202, acc: 0.782608687877655)
[2024-11-13 08:09:37,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:37,328][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.6491206884384155, acc: 0.8199999928474426)
[2024-11-13 08:09:37,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:37,706][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.33715611696243286, acc: 0.9130434989929199)
[2024-11-13 08:09:37,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:38,063][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.852779746055603, acc: 0.699999988079071)
[2024-11-13 08:09:38,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:38,427][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 1.052808403968811, acc: 0.708737850189209)
[2024-11-13 08:09:38,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:39,157][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 1.5657293796539307, acc: 0.5631067752838135)
[2024-11-13 08:09:39,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:39,771][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 1.6544098854064941, acc: 0.5053763389587402)
[2024-11-13 08:09:39,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:40,365][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 1.5537384748458862, acc: 0.568965494632721)
[2024-11-13 08:09:40,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:40,926][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.9527974128723145, acc: 0.6736842393875122)
[2024-11-13 08:09:41,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:41,621][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 1.3604828119277954, acc: 0.6237623691558838)
[2024-11-13 08:09:41,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:41,969][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 1.0154863595962524, acc: 0.7096773982048035)
[2024-11-13 08:09:42,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:42,312][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.9654548764228821, acc: 0.7101449370384216)
[2024-11-13 08:09:42,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:42,675][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 1.3579609394073486, acc: 0.5546218752861023)
[2024-11-13 08:09:42,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:43,039][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 1.5103284120559692, acc: 0.5288461446762085)
[2024-11-13 08:09:43,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:43,418][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 1.5124841928482056, acc: 0.569343090057373)
[2024-11-13 08:09:43,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:43,759][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.6738049983978271, acc: 0.7611940503120422)
[2024-11-13 08:09:43,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:44,080][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.32278552651405334, acc: 0.949999988079071)
[2024-11-13 08:09:44,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:44,400][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.10485813021659851, acc: 0.9545454382896423)
[2024-11-13 08:09:44,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:44,758][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.25016266107559204, acc: 0.95652174949646)
[2024-11-13 08:09:44,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:45,116][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.4119638502597809, acc: 0.8409090638160706)
[2024-11-13 08:09:45,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:45,493][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.7576524019241333, acc: 0.7931034564971924)
[2024-11-13 08:09:45,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:45,851][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.25541412830352783, acc: 0.930232584476471)
[2024-11-13 08:09:45,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:46,162][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.5754795670509338, acc: 0.7599999904632568)
[2024-11-13 08:09:46,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:46,488][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.013563437387347221, acc: 1.0)
[2024-11-13 08:09:46,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:46,778][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.052890367805957794, acc: 1.0)
[2024-11-13 08:09:46,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:47,107][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.2785640060901642, acc: 0.9047619104385376)
[2024-11-13 08:09:47,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:47,451][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.6022875905036926, acc: 0.8307692408561707)
[2024-11-13 08:09:47,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:47,796][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.7457832098007202, acc: 0.7894737124443054)
[2024-11-13 08:09:47,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:48,163][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.5480868816375732, acc: 0.8947368264198303)
[2024-11-13 08:09:48,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:48,495][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.5647369623184204, acc: 0.7692307829856873)
[2024-11-13 08:09:48,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:48,827][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.48377999663352966, acc: 0.8571428656578064)
[2024-11-13 08:09:48,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:49,126][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.0473875030875206, acc: 0.9545454382896423)
[2024-11-13 08:09:49,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:49,493][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 0.7422527074813843, acc: 0.8253968358039856)
[2024-11-13 08:09:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:49,803][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 0.9468951225280762, acc: 0.7235772609710693)
[2024-11-13 08:09:49,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:50,188][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.4667227268218994, acc: 0.8548387289047241)
[2024-11-13 08:09:50,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:50,817][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 1.6691445112228394, acc: 0.49809885025024414)
[2024-11-13 08:09:50,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:51,116][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.5919783711433411, acc: 0.8133333325386047)
[2024-11-13 08:09:51,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:51,480][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.49553579092025757, acc: 0.8653846383094788)
[2024-11-13 08:09:51,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:51,815][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.26376065611839294, acc: 0.875)
[2024-11-13 08:09:51,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:52,180][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.2471173256635666, acc: 1.0)
[2024-11-13 08:09:52,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:52,546][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 1.5000123977661133, acc: 0.5766870975494385)
[2024-11-13 08:09:52,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:52,922][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 1.4106472730636597, acc: 0.6111111044883728)
[2024-11-13 08:09:53,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:53,276][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 1.3606791496276855, acc: 0.6083333492279053)
[2024-11-13 08:09:54,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:54,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:54,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:54,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:54,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:55,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:55,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:55,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:56,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:56,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:56,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:57,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:57,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:57,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:58,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:58,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:58,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:58,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:59,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:59,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:59,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:59,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:09:59,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:00,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:00,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:00,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:01,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:01,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:01,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:02,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:02,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:02,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:02,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:02,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:03,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:03,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:03,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:03,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:04,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:04,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:04,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:04,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:05,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:05,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:05,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:06,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:06,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:06,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:06,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:07,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:07,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:07,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:08,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:08,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:08,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:08,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:09,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:09,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:09,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:09,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:10,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:10,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:10,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:10,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:11,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:11,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:11,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:11,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:12,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:12,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:12,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:12,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:13,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:13,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:14,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:14,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:14,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:14,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:15,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:15,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:15,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:15,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:16,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:16,770][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.3568, device='cuda:0') eval_epoch_loss=tensor(2.1231, device='cuda:0') eval_epoch_acc=tensor(0.5631, device='cuda:0')
[2024-11-13 08:10:16,771][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:10:16,772][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:10:17,314][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_9_step_127_loss_2.123077869415283/model.pt
[2024-11-13 08:10:17,319][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:10:17,319][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 9 is 0.5631462931632996
[2024-11-13 08:10:17,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:17,676][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 1.6114072799682617, acc: 0.5416666865348816)
[2024-11-13 08:10:17,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:17,989][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 1.5836294889450073, acc: 0.5589743852615356)
[2024-11-13 08:10:18,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:18,345][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 1.2131537199020386, acc: 0.6323529481887817)
[2024-11-13 08:10:18,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:18,626][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.5218527913093567, acc: 0.8461538553237915)
[2024-11-13 08:10:18,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:18,927][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.16108419001102448, acc: 0.95652174949646)
[2024-11-13 08:10:18,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:19,234][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.44309407472610474, acc: 0.875)
[2024-11-13 08:10:19,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:19,541][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.6252956986427307, acc: 0.8260869383811951)
[2024-11-13 08:10:19,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:19,850][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.7320050597190857, acc: 0.6857143044471741)
[2024-11-13 08:10:19,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:20,161][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.3464687168598175, acc: 0.9230769276618958)
[2024-11-13 08:10:20,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:20,468][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.6074640154838562, acc: 0.8095238208770752)
[2024-11-13 08:10:20,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:20,763][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.6980377435684204, acc: 0.7666666507720947)
[2024-11-13 08:10:20,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:21,061][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.6743658185005188, acc: 0.8695651888847351)
[2024-11-13 08:10:21,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:21,343][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.3292037844657898, acc: 0.9523809552192688)
[2024-11-13 08:10:21,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:21,636][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.7413793206214905, acc: 0.7307692170143127)
[2024-11-13 08:10:21,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:21,935][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.47419506311416626, acc: 0.8709677457809448)
[2024-11-13 08:10:22,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:22,236][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.7494614720344543, acc: 0.8108108043670654)
[2024-11-13 08:10:22,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:22,655][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 1.3558140993118286, acc: 0.5701754093170166)
[2024-11-13 08:10:22,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:22,956][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 1.2853361368179321, acc: 0.6343283653259277)
[2024-11-13 08:10:23,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:23,259][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 1.4900331497192383, acc: 0.5102040767669678)
[2024-11-13 08:10:23,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:23,650][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 1.429577112197876, acc: 0.5957446694374084)
[2024-11-13 08:10:23,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:23,945][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 1.0273022651672363, acc: 0.6285714507102966)
[2024-11-13 08:10:24,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:24,242][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.7459403276443481, acc: 0.8214285969734192)
[2024-11-13 08:10:24,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:24,552][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.7434074282646179, acc: 0.695652186870575)
[2024-11-13 08:10:24,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:24,853][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.46210619807243347, acc: 0.8275862336158752)
[2024-11-13 08:10:24,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:25,169][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.5577905774116516, acc: 0.804347813129425)
[2024-11-13 08:10:25,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:25,474][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 1.0803509950637817, acc: 0.7118644118309021)
[2024-11-13 08:10:25,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:25,777][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 1.2924724817276, acc: 0.6140350699424744)
[2024-11-13 08:10:25,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:26,097][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 1.2963824272155762, acc: 0.6216216087341309)
[2024-11-13 08:10:26,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:26,379][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.5463853478431702, acc: 0.8214285969734192)
[2024-11-13 08:10:26,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:26,694][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.5669853091239929, acc: 0.9130434989929199)
[2024-11-13 08:10:26,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:26,977][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.25334206223487854, acc: 0.9473684430122375)
[2024-11-13 08:10:27,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:27,829][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 1.0588282346725464, acc: 0.662162184715271)
[2024-11-13 08:10:27,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:28,099][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 1.0545920133590698, acc: 0.6666666865348816)
[2024-11-13 08:10:28,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:28,419][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 1.0017060041427612, acc: 0.7093023061752319)
[2024-11-13 08:10:28,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:28,862][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.8666238188743591, acc: 0.7058823704719543)
[2024-11-13 08:10:28,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:29,291][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 1.2062675952911377, acc: 0.6741573214530945)
[2024-11-13 08:10:29,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:29,577][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.5356336832046509, acc: 0.8409090638160706)
[2024-11-13 08:10:29,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:29,849][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.6896666288375854, acc: 0.761904776096344)
[2024-11-13 08:10:29,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:30,163][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.4566231071949005, acc: 0.8620689511299133)
[2024-11-13 08:10:30,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:30,461][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.5963273048400879, acc: 0.8367347121238708)
[2024-11-13 08:10:30,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:30,749][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.6954593658447266, acc: 0.7400000095367432)
[2024-11-13 08:10:30,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:31,059][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.825637936592102, acc: 0.7638888955116272)
[2024-11-13 08:10:31,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:31,375][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 0.9358804821968079, acc: 0.7352941036224365)
[2024-11-13 08:10:31,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:32,078][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 1.8661116361618042, acc: 0.48630136251449585)
[2024-11-13 08:10:32,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:32,337][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.26605433225631714, acc: 0.9166666865348816)
[2024-11-13 08:10:32,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:32,605][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.4392704367637634, acc: 0.8518518805503845)
[2024-11-13 08:10:32,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:32,894][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.463393896818161, acc: 0.9285714030265808)
[2024-11-13 08:10:32,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:33,321][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 1.0349786281585693, acc: 0.7345132827758789)
[2024-11-13 08:10:33,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:33,594][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.8164666295051575, acc: 0.7536231875419617)
[2024-11-13 08:10:33,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:33,901][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 1.013755202293396, acc: 0.75)
[2024-11-13 08:10:34,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:34,543][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 1.8696869611740112, acc: 0.4656488597393036)
[2024-11-13 08:10:34,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:35,042][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 1.6153496503829956, acc: 0.5481481552124023)
[2024-11-13 08:10:35,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:35,306][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.7585920095443726, acc: 0.7540983557701111)
[2024-11-13 08:10:35,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:35,577][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.21544413268566132, acc: 0.875)
[2024-11-13 08:10:35,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:35,862][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.5417760610580444, acc: 0.8399999737739563)
[2024-11-13 08:10:35,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:36,153][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.4232313930988312, acc: 0.8214285969734192)
[2024-11-13 08:10:36,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:36,468][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 1.0603623390197754, acc: 0.6463414430618286)
[2024-11-13 08:10:36,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:36,790][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 1.8860639333724976, acc: 0.4864048361778259)
[2024-11-13 08:10:36,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:37,108][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 2.077619791030884, acc: 0.46685880422592163)
[2024-11-13 08:10:37,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:37,501][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 2.0633816719055176, acc: 0.453125)
[2024-11-13 08:10:37,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:37,941][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 2.057814359664917, acc: 0.4671669900417328)
[2024-11-13 08:10:38,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:38,271][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 1.8814777135849, acc: 0.46975088119506836)
[2024-11-13 08:10:38,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:38,550][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.6130734086036682, acc: 0.7599999904632568)
[2024-11-13 08:10:38,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:39,004][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 1.8111598491668701, acc: 0.4883720874786377)
[2024-11-13 08:10:39,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:39,570][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 1.5267705917358398, acc: 0.60317462682724)
[2024-11-13 08:10:39,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:40,195][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 1.642775297164917, acc: 0.5757575631141663)
[2024-11-13 08:10:40,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:40,730][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 1.308112382888794, acc: 0.6705882549285889)
[2024-11-13 08:10:40,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:41,454][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 1.3965669870376587, acc: 0.5987654328346252)
[2024-11-13 08:10:41,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:42,103][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.9739648699760437, acc: 0.8064516186714172)
[2024-11-13 08:10:42,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:42,366][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.3181052803993225, acc: 0.9285714030265808)
[2024-11-13 08:10:42,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:42,682][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.6451326608657837, acc: 0.7749999761581421)
[2024-11-13 08:10:42,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:42,993][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.9304189085960388, acc: 0.7352941036224365)
[2024-11-13 08:10:43,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:43,312][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 1.4294713735580444, acc: 0.5661764740943909)
[2024-11-13 08:10:43,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:43,625][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 1.3894171714782715, acc: 0.5508474707603455)
[2024-11-13 08:10:43,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:43,916][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 1.5311920642852783, acc: 0.5447761416435242)
[2024-11-13 08:10:43,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:44,247][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 1.3717082738876343, acc: 0.5631067752838135)
[2024-11-13 08:10:44,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:44,528][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.855099618434906, acc: 0.761904776096344)
[2024-11-13 08:10:44,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:44,804][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 1.0124999284744263, acc: 0.7032967209815979)
[2024-11-13 08:10:44,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:45,111][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 1.5863304138183594, acc: 0.5560538172721863)
[2024-11-13 08:10:45,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:45,454][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 1.6335753202438354, acc: 0.5669291615486145)
[2024-11-13 08:10:45,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:45,750][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 1.5948983430862427, acc: 0.5862069129943848)
[2024-11-13 08:10:45,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:46,054][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 1.6008291244506836, acc: 0.554347813129425)
[2024-11-13 08:10:46,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:46,404][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 1.7679530382156372, acc: 0.48638132214546204)
[2024-11-13 08:10:46,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:46,734][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 1.1748480796813965, acc: 0.6739130616188049)
[2024-11-13 08:10:46,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:47,002][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.4610362946987152, acc: 0.782608687877655)
[2024-11-13 08:10:47,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:47,321][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.3505531847476959, acc: 0.8928571343421936)
[2024-11-13 08:10:47,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:47,686][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.530026376247406, acc: 0.8297872543334961)
[2024-11-13 08:10:47,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:48,193][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 1.1186810731887817, acc: 0.6846153736114502)
[2024-11-13 08:10:48,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:48,500][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.7767558097839355, acc: 0.7972972989082336)
[2024-11-13 08:10:48,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:48,810][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.8602340817451477, acc: 0.7558139562606812)
[2024-11-13 08:10:48,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:49,224][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 1.023532509803772, acc: 0.7027027010917664)
[2024-11-13 08:10:49,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:49,533][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.895689845085144, acc: 0.7333333492279053)
[2024-11-13 08:10:49,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:49,796][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.2444387525320053, acc: 0.939393937587738)
[2024-11-13 08:10:49,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:50,044][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.23472614586353302, acc: 0.9259259104728699)
[2024-11-13 08:10:50,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:50,282][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.12324237078428268, acc: 0.9599999785423279)
[2024-11-13 08:10:50,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:50,611][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.36064809560775757, acc: 0.942307710647583)
[2024-11-13 08:10:50,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:51,167][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 1.0683517456054688, acc: 0.6630434989929199)
[2024-11-13 08:10:51,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:51,596][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 1.2176170349121094, acc: 0.6306818127632141)
[2024-11-13 08:10:51,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:51,981][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 0.915992259979248, acc: 0.7021276354789734)
[2024-11-13 08:10:52,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:52,299][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.5194682478904724, acc: 0.8301886916160583)
[2024-11-13 08:10:52,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:52,648][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.6204850673675537, acc: 0.8166666626930237)
[2024-11-13 08:10:52,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:53,017][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.2167813926935196, acc: 0.930232584476471)
[2024-11-13 08:10:53,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:53,317][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.3073769509792328, acc: 0.8999999761581421)
[2024-11-13 08:10:53,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:53,630][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 0.890394926071167, acc: 0.7789473533630371)
[2024-11-13 08:10:53,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:53,944][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 0.7362859845161438, acc: 0.7777777910232544)
[2024-11-13 08:10:54,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:54,313][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 0.8667864203453064, acc: 0.7777777910232544)
[2024-11-13 08:10:54,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:54,747][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 1.303534746170044, acc: 0.6605504751205444)
[2024-11-13 08:10:54,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:55,177][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 0.7470662593841553, acc: 0.7769230604171753)
[2024-11-13 08:10:55,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:55,496][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.23669525980949402, acc: 0.8947368264198303)
[2024-11-13 08:10:55,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:55,852][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.28100499510765076, acc: 0.9166666865348816)
[2024-11-13 08:10:55,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:56,217][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.37400105595588684, acc: 0.8181818127632141)
[2024-11-13 08:10:56,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:56,534][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.45074155926704407, acc: 0.8518518805503845)
[2024-11-13 08:10:56,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:56,800][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.5165286064147949, acc: 0.8285714387893677)
[2024-11-13 08:10:56,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:57,121][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.6065585613250732, acc: 0.75)
[2024-11-13 08:10:57,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:57,474][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.731747567653656, acc: 0.7954545617103577)
[2024-11-13 08:10:57,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:57,919][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.6878402829170227, acc: 0.7580645084381104)
[2024-11-13 08:10:58,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:58,355][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.4464501440525055, acc: 0.8409090638160706)
[2024-11-13 08:10:58,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:58,691][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.011557037942111492, acc: 1.0)
[2024-11-13 08:10:58,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:59,061][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.22885765135288239, acc: 0.9230769276618958)
[2024-11-13 08:10:59,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:59,343][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.2646019756793976, acc: 0.9677419066429138)
[2024-11-13 08:10:59,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:59,565][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.2940429449081421, acc: 0.8500000238418579)
[2024-11-13 08:10:59,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:10:59,879][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.4504004716873169, acc: 0.8648648858070374)
[2024-11-13 08:10:59,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:00,168][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.601762592792511, acc: 0.837837815284729)
[2024-11-13 08:11:00,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:00,434][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.3056347370147705, acc: 0.8918918967247009)
[2024-11-13 08:11:00,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:00,800][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.8258839845657349, acc: 0.75)
[2024-11-13 08:11:00,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:01,163][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.36323410272598267, acc: 0.8780487775802612)
[2024-11-13 08:11:01,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:01,517][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.09806819260120392, acc: 1.0)
[2024-11-13 08:11:01,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:01,878][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.03729667514562607, acc: 1.0)
[2024-11-13 08:11:01,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:02,217][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.10862186551094055, acc: 0.9677419066429138)
[2024-11-13 08:11:02,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:02,533][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.4538046419620514, acc: 0.8771929740905762)
[2024-11-13 08:11:02,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:02,767][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.5529260039329529, acc: 0.8714285492897034)
[2024-11-13 08:11:02,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:03,120][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.5920014381408691, acc: 0.8289473652839661)
[2024-11-13 08:11:03,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:03,572][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 1.0354777574539185, acc: 0.7075471878051758)
[2024-11-13 08:11:03,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:04,027][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 1.295102834701538, acc: 0.6583333611488342)
[2024-11-13 08:11:04,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:04,355][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.41352641582489014, acc: 0.8611111044883728)
[2024-11-13 08:11:04,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:04,657][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.5195788741111755, acc: 0.8709677457809448)
[2024-11-13 08:11:04,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:04,993][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 1.332234263420105, acc: 0.6133333444595337)
[2024-11-13 08:11:05,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:05,318][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.7747349143028259, acc: 0.7708333134651184)
[2024-11-13 08:11:05,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:05,905][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 1.5828195810317993, acc: 0.5199999809265137)
[2024-11-13 08:11:05,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:06,207][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 1.0895329713821411, acc: 0.617977499961853)
[2024-11-13 08:11:06,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:06,543][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.9905598759651184, acc: 0.7162162065505981)
[2024-11-13 08:11:06,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:06,920][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.6160498261451721, acc: 0.8275862336158752)
[2024-11-13 08:11:06,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:07,217][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.2653937041759491, acc: 0.9090909361839294)
[2024-11-13 08:11:07,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:08,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:08,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:09,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:09,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:09,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:09,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:10,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:10,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:10,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:10,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:11,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:11,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:11,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:12,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:12,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:12,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:12,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:13,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:13,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:13,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:14,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:14,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:14,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:14,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:15,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:15,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:16,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:16,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:16,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:16,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:17,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:17,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:17,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:17,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:18,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:18,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:18,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:19,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:19,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:19,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:20,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:20,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:20,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:20,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:21,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:21,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:21,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:22,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:22,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:22,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:22,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:23,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:23,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:23,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:23,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:24,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:24,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:24,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:25,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:25,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:25,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:25,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:26,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:26,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:26,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:27,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:27,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:27,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:28,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:28,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:28,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:28,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:29,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:29,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:29,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:29,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:30,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:30,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:30,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:31,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:31,767][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.0399, device='cuda:0') eval_epoch_loss=tensor(2.0844, device='cuda:0') eval_epoch_acc=tensor(0.5277, device='cuda:0')
[2024-11-13 08:11:31,768][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:11:31,768][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:11:32,121][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_9_step_270_loss_2.0844223499298096/model.pt
[2024-11-13 08:11:32,126][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:11:32,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:32,516][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.31695735454559326, acc: 0.9090909361839294)
[2024-11-13 08:11:32,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:32,846][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.26225483417510986, acc: 0.9375)
[2024-11-13 08:11:32,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:33,187][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.4352911710739136, acc: 0.8333333134651184)
[2024-11-13 08:11:33,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:33,517][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.7996371388435364, acc: 0.7166666388511658)
[2024-11-13 08:11:33,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:33,835][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.21788780391216278, acc: 0.9375)
[2024-11-13 08:11:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:34,172][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.30035144090652466, acc: 0.8999999761581421)
[2024-11-13 08:11:34,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:34,478][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.46552935242652893, acc: 0.8965517282485962)
[2024-11-13 08:11:34,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:34,844][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.43739259243011475, acc: 0.800000011920929)
[2024-11-13 08:11:34,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:35,188][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.764423668384552, acc: 0.8297872543334961)
[2024-11-13 08:11:35,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:35,516][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.7981954216957092, acc: 0.75)
[2024-11-13 08:11:35,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:35,833][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.6396887302398682, acc: 0.7954545617103577)
[2024-11-13 08:11:35,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:36,192][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.8898629546165466, acc: 0.7469879388809204)
[2024-11-13 08:11:36,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:36,544][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 1.2951421737670898, acc: 0.6851851940155029)
[2024-11-13 08:11:36,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:36,865][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.5275288820266724, acc: 0.8947368264198303)
[2024-11-13 08:11:36,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:37,201][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.5113821029663086, acc: 0.8235294222831726)
[2024-11-13 08:11:37,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:37,550][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.25020867586135864, acc: 0.925000011920929)
[2024-11-13 08:11:37,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:37,886][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 1.259657382965088, acc: 0.6015625)
[2024-11-13 08:11:37,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:38,192][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 1.1606113910675049, acc: 0.6800000071525574)
[2024-11-13 08:11:38,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:38,497][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.9435903429985046, acc: 0.7362637519836426)
[2024-11-13 08:11:38,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:38,791][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 1.645177960395813, acc: 0.5590062141418457)
[2024-11-13 08:11:38,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:39,127][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 1.6664941310882568, acc: 0.530927836894989)
[2024-11-13 08:11:39,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:39,432][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.21487011015415192, acc: 0.9090909361839294)
[2024-11-13 08:11:39,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:39,704][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.5106694102287292, acc: 0.8571428656578064)
[2024-11-13 08:11:39,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:40,058][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.6391726136207581, acc: 0.7758620977401733)
[2024-11-13 08:11:40,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:40,493][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.46164998412132263, acc: 0.8181818127632141)
[2024-11-13 08:11:40,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:40,932][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 1.5561941862106323, acc: 0.5773195624351501)
[2024-11-13 08:11:40,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:41,190][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.9202332496643066, acc: 0.7413793206214905)
[2024-11-13 08:11:41,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:41,520][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.6586110591888428, acc: 0.7407407164573669)
[2024-11-13 08:11:41,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:41,817][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.5797402262687683, acc: 0.8157894611358643)
[2024-11-13 08:11:41,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:42,128][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.35667064785957336, acc: 0.9107142686843872)
[2024-11-13 08:11:42,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:42,376][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.2713233530521393, acc: 0.90625)
[2024-11-13 08:11:42,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:42,635][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.5747537016868591, acc: 0.849056601524353)
[2024-11-13 08:11:42,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:42,900][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.29826048016548157, acc: 0.9245283007621765)
[2024-11-13 08:11:42,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:43,185][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.45583197474479675, acc: 0.8529411554336548)
[2024-11-13 08:11:43,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:43,479][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.40754422545433044, acc: 0.875)
[2024-11-13 08:11:43,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:43,797][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.7233828902244568, acc: 0.7540983557701111)
[2024-11-13 08:11:43,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:44,013][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.15149837732315063, acc: 0.9666666388511658)
[2024-11-13 08:11:44,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:44,304][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.1393832564353943, acc: 0.9473684430122375)
[2024-11-13 08:11:44,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:44,660][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.7318462133407593, acc: 0.7971014380455017)
[2024-11-13 08:11:44,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:45,073][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.9190329313278198, acc: 0.7638888955116272)
[2024-11-13 08:11:45,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:45,359][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.5608386993408203, acc: 0.8554216623306274)
[2024-11-13 08:11:45,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:45,586][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 1.0991432666778564, acc: 0.6538461446762085)
[2024-11-13 08:11:45,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:45,902][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 1.086530327796936, acc: 0.6734693646430969)
[2024-11-13 08:11:45,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:46,228][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.04810425639152527, acc: 1.0)
[2024-11-13 08:11:46,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:46,563][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.07679581642150879, acc: 1.0)
[2024-11-13 08:11:46,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:46,943][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.5329990386962891, acc: 0.8709677457809448)
[2024-11-13 08:11:47,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:47,277][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.14720340073108673, acc: 0.9354838728904724)
[2024-11-13 08:11:47,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:47,659][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.49919161200523376, acc: 0.8507462739944458)
[2024-11-13 08:11:47,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:47,975][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.8148185014724731, acc: 0.7307692170143127)
[2024-11-13 08:11:48,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:48,311][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.4965537488460541, acc: 0.8888888955116272)
[2024-11-13 08:11:48,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:48,629][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.4896617531776428, acc: 0.8387096524238586)
[2024-11-13 08:11:48,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:49,001][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.28301069140434265, acc: 0.8999999761581421)
[2024-11-13 08:11:49,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:49,326][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.7509103417396545, acc: 0.7407407164573669)
[2024-11-13 08:11:49,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:49,659][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.710577666759491, acc: 0.7714285850524902)
[2024-11-13 08:11:49,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:49,990][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.718939483165741, acc: 0.7692307829856873)
[2024-11-13 08:11:50,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:50,229][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 0.6356788277626038, acc: 0.8292682766914368)
[2024-11-13 08:11:50,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:50,493][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.567169725894928, acc: 0.8421052694320679)
[2024-11-13 08:11:50,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:50,798][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.14085161685943604, acc: 0.9473684430122375)
[2024-11-13 08:11:50,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:51,140][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.11932031810283661, acc: 0.9642857313156128)
[2024-11-13 08:11:51,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:51,437][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.212303027510643, acc: 0.8888888955116272)
[2024-11-13 08:11:51,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:51,776][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.32793059945106506, acc: 0.9375)
[2024-11-13 08:11:51,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:52,158][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.7452126145362854, acc: 0.774193525314331)
[2024-11-13 08:11:52,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:52,497][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.7355743050575256, acc: 0.7719298005104065)
[2024-11-13 08:11:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:52,822][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.7302380204200745, acc: 0.6875)
[2024-11-13 08:11:52,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:53,126][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.49420005083084106, acc: 0.8333333134651184)
[2024-11-13 08:11:53,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:53,470][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.377567857503891, acc: 0.8421052694320679)
[2024-11-13 08:11:53,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:53,756][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 1.0283410549163818, acc: 0.6200000047683716)
[2024-11-13 08:11:53,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:54,120][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 1.3863093852996826, acc: 0.6206896305084229)
[2024-11-13 08:11:54,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:54,487][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 1.3213492631912231, acc: 0.6489361524581909)
[2024-11-13 08:11:54,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:54,813][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 1.4659359455108643, acc: 0.5301204919815063)
[2024-11-13 08:11:54,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:55,176][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.11851642280817032, acc: 0.95652174949646)
[2024-11-13 08:11:55,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:55,514][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.2698538303375244, acc: 0.9487179517745972)
[2024-11-13 08:11:55,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:55,851][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.9740635752677917, acc: 0.7349397540092468)
[2024-11-13 08:11:55,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:56,191][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.6240812540054321, acc: 0.849056601524353)
[2024-11-13 08:11:56,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:56,503][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.47196492552757263, acc: 0.8607594966888428)
[2024-11-13 08:11:56,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:56,810][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.44311079382896423, acc: 0.843137264251709)
[2024-11-13 08:11:56,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:57,134][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.9227532744407654, acc: 0.6567164063453674)
[2024-11-13 08:11:57,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:57,428][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.12927690148353577, acc: 1.0)
[2024-11-13 08:11:57,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:57,744][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.2075340449810028, acc: 0.9200000166893005)
[2024-11-13 08:11:57,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:58,073][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.44558465480804443, acc: 0.8611111044883728)
[2024-11-13 08:11:58,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:58,403][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.6605961322784424, acc: 0.7441860437393188)
[2024-11-13 08:11:58,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:58,750][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.5522700548171997, acc: 0.8205128312110901)
[2024-11-13 08:11:58,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:59,097][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 1.1260637044906616, acc: 0.644444465637207)
[2024-11-13 08:11:59,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:59,381][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.2946813702583313, acc: 0.9130434989929199)
[2024-11-13 08:11:59,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:11:59,728][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.28775256872177124, acc: 0.9230769276618958)
[2024-11-13 08:11:59,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:00,049][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 1.4356330633163452, acc: 0.5824176073074341)
[2024-11-13 08:12:00,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:00,468][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 1.2788480520248413, acc: 0.6000000238418579)
[2024-11-13 08:12:00,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:00,819][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 1.15218186378479, acc: 0.70652174949646)
[2024-11-13 08:12:00,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:01,159][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.9177915453910828, acc: 0.7755101919174194)
[2024-11-13 08:12:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:01,538][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.031495071947574615, acc: 1.0)
[2024-11-13 08:12:01,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:01,867][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.3292045295238495, acc: 0.8846153616905212)
[2024-11-13 08:12:01,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:02,184][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.39038917422294617, acc: 0.8536585569381714)
[2024-11-13 08:12:02,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:02,515][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.341130793094635, acc: 0.8666666746139526)
[2024-11-13 08:12:02,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:02,830][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.6645960807800293, acc: 0.8026315569877625)
[2024-11-13 08:12:02,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:03,155][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.4649026393890381, acc: 0.8292682766914368)
[2024-11-13 08:12:03,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:03,457][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.5584477782249451, acc: 0.8484848737716675)
[2024-11-13 08:12:03,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:03,771][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.1704559475183487, acc: 0.875)
[2024-11-13 08:12:03,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:04,124][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.02749873697757721, acc: 1.0)
[2024-11-13 08:12:04,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:04,435][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.5210937857627869, acc: 0.9285714030265808)
[2024-11-13 08:12:04,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:04,729][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.35889026522636414, acc: 0.875)
[2024-11-13 08:12:04,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:05,215][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 1.315753698348999, acc: 0.6484848260879517)
[2024-11-13 08:12:05,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:05,798][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 0.935526430606842, acc: 0.7452830076217651)
[2024-11-13 08:12:05,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:06,082][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.7928593754768372, acc: 0.7777777910232544)
[2024-11-13 08:12:06,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:06,428][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.8733597993850708, acc: 0.7321428656578064)
[2024-11-13 08:12:06,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:06,759][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.30887144804000854, acc: 0.9428571462631226)
[2024-11-13 08:12:06,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:07,062][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.10273007303476334, acc: 0.9599999785423279)
[2024-11-13 08:12:07,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:07,347][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.3381909132003784, acc: 0.9130434989929199)
[2024-11-13 08:12:07,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:07,633][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.5092986226081848, acc: 0.8333333134651184)
[2024-11-13 08:12:07,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:07,914][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.9871114492416382, acc: 0.75789475440979)
[2024-11-13 08:12:08,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:08,361][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 1.1877715587615967, acc: 0.688622772693634)
[2024-11-13 08:12:08,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:08,745][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.8938244581222534, acc: 0.7443609237670898)
[2024-11-13 08:12:08,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:09,482][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 1.2662456035614014, acc: 0.6524063944816589)
[2024-11-13 08:12:09,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:09,922][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.715644121170044, acc: 0.7657657861709595)
[2024-11-13 08:12:09,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:10,221][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.13796603679656982, acc: 0.9285714030265808)
[2024-11-13 08:12:10,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:10,548][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.047504134476184845, acc: 1.0)
[2024-11-13 08:12:10,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:10,869][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.2750931978225708, acc: 0.875)
[2024-11-13 08:12:10,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:11,198][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.3522105813026428, acc: 0.9166666865348816)
[2024-11-13 08:12:11,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:11,487][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.30818966031074524, acc: 0.9473684430122375)
[2024-11-13 08:12:11,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:11,733][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.2307881861925125, acc: 0.9545454382896423)
[2024-11-13 08:12:11,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:11,997][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.36232322454452515, acc: 0.800000011920929)
[2024-11-13 08:12:12,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:12,213][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.3372311592102051, acc: 0.9047619104385376)
[2024-11-13 08:12:12,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:12,514][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 1.1349058151245117, acc: 0.6851851940155029)
[2024-11-13 08:12:12,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:12,805][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 1.3873857259750366, acc: 0.5922330021858215)
[2024-11-13 08:12:12,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:13,229][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 1.36025869846344, acc: 0.6176470518112183)
[2024-11-13 08:12:13,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:13,583][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 1.4199810028076172, acc: 0.5600000023841858)
[2024-11-13 08:12:13,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:13,906][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 1.5866918563842773, acc: 0.5763888955116272)
[2024-11-13 08:12:13,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:14,199][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.5061835646629333, acc: 0.9069767594337463)
[2024-11-13 08:12:14,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:14,493][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.2666279971599579, acc: 0.9583333134651184)
[2024-11-13 08:12:14,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:14,794][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.519681990146637, acc: 0.8372092843055725)
[2024-11-13 08:12:14,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:15,096][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.5099054574966431, acc: 0.8399999737739563)
[2024-11-13 08:12:15,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:15,566][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.9172257781028748, acc: 0.720588207244873)
[2024-11-13 08:12:15,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:15,937][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.9191172122955322, acc: 0.6933333277702332)
[2024-11-13 08:12:16,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:16,293][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.4967145621776581, acc: 0.8181818127632141)
[2024-11-13 08:12:16,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:16,631][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.273785799741745, acc: 0.9090909361839294)
[2024-11-13 08:12:16,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:16,920][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.10761527717113495, acc: 1.0)
[2024-11-13 08:12:16,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:17,234][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.22980555891990662, acc: 0.9259259104728699)
[2024-11-13 08:12:17,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:17,584][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.23080042004585266, acc: 1.0)
[2024-11-13 08:12:17,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:17,912][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.3618360757827759, acc: 0.8611111044883728)
[2024-11-13 08:12:17,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:18,234][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.42527374625205994, acc: 0.8888888955116272)
[2024-11-13 08:12:18,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:18,547][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.1506691575050354, acc: 0.9615384340286255)
[2024-11-13 08:12:18,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:18,845][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.6223006844520569, acc: 0.7931034564971924)
[2024-11-13 08:12:18,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:19,090][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.4122067987918854, acc: 0.8571428656578064)
[2024-11-13 08:12:19,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:19,362][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.4517892599105835, acc: 0.8999999761581421)
[2024-11-13 08:12:20,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:20,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:20,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:20,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:21,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:21,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:21,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:22,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:22,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:22,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:23,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:23,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:23,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:24,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:24,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:24,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:24,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:25,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:25,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:25,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:25,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:26,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:26,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:26,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:27,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:27,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:27,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:28,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:28,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:28,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:28,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:29,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:29,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:29,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:29,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:30,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:30,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:30,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:30,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:31,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:31,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:31,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:31,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:32,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:32,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:32,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:32,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:33,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:33,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:33,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:34,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:34,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:34,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:34,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:35,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:35,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:35,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:35,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:35,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:36,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:36,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:36,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:37,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:37,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:37,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:37,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:38,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:38,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:39,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:39,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:39,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:39,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:40,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:40,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:40,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:41,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:41,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:41,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:42,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:42,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:42,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:42,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:43,348][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.4906, device='cuda:0') eval_epoch_loss=tensor(2.1390, device='cuda:0') eval_epoch_acc=tensor(0.5542, device='cuda:0')
[2024-11-13 08:12:43,349][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:12:43,350][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:12:43,715][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_9_step_413_loss_2.138960123062134/model.pt
[2024-11-13 08:12:43,719][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:12:43,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:44,035][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.37324583530426025, acc: 0.9090909361839294)
[2024-11-13 08:12:44,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:44,301][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.24438758194446564, acc: 0.9090909361839294)
[2024-11-13 08:12:44,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:44,597][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.9017956852912903, acc: 0.7647058963775635)
[2024-11-13 08:12:44,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:44,881][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.49685221910476685, acc: 0.8461538553237915)
[2024-11-13 08:12:44,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:45,175][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.5292274951934814, acc: 0.8333333134651184)
[2024-11-13 08:12:45,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:45,482][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.5399399995803833, acc: 0.824999988079071)
[2024-11-13 08:12:45,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:45,754][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.5960816144943237, acc: 0.8500000238418579)
[2024-11-13 08:12:45,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:46,055][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.07696729898452759, acc: 1.0)
[2024-11-13 08:12:46,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:46,356][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.24415500462055206, acc: 0.8999999761581421)
[2024-11-13 08:12:46,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:46,647][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.21378330886363983, acc: 0.90625)
[2024-11-13 08:12:46,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:46,933][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.3452703654766083, acc: 0.8333333134651184)
[2024-11-13 08:12:46,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:47,223][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.23349449038505554, acc: 0.9629629850387573)
[2024-11-13 08:12:47,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:47,528][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.46233922243118286, acc: 0.8484848737716675)
[2024-11-13 08:12:47,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:47,860][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.3694813847541809, acc: 0.8260869383811951)
[2024-11-13 08:12:47,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:48,183][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.32394930720329285, acc: 0.9189189076423645)
[2024-11-13 08:12:48,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:48,474][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.3293950855731964, acc: 0.8148148059844971)
[2024-11-13 08:12:48,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:48,774][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.19126546382904053, acc: 0.9130434989929199)
[2024-11-13 08:12:48,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:49,060][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.055932193994522095, acc: 0.9629629850387573)
[2024-11-13 08:12:49,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:49,361][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.07045316696166992, acc: 1.0)
[2024-11-13 08:12:49,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:49,696][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.44003865122795105, acc: 0.8695651888847351)
[2024-11-13 08:12:49,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:50,035][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.5146282911300659, acc: 0.8055555820465088)
[2024-11-13 08:12:50,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:50,327][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.3771510422229767, acc: 0.9200000166893005)
[2024-11-13 08:12:50,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:50,621][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.46589818596839905, acc: 0.8787878751754761)
[2024-11-13 08:12:50,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:50,923][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.4456022083759308, acc: 0.8611111044883728)
[2024-11-13 08:12:50,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:51,220][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.6413218975067139, acc: 0.8181818127632141)
[2024-11-13 08:12:51,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:51,525][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.10890010744333267, acc: 0.9523809552192688)
[2024-11-13 08:12:51,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:51,835][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.5260728001594543, acc: 0.8461538553237915)
[2024-11-13 08:12:51,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:52,194][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 1.0696485042572021, acc: 0.7121211886405945)
[2024-11-13 08:12:52,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:52,703][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 1.5743577480316162, acc: 0.5120000243186951)
[2024-11-13 08:12:52,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:53,019][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 1.3758991956710815, acc: 0.5806451439857483)
[2024-11-13 08:12:53,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:53,511][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 1.6473373174667358, acc: 0.5671641826629639)
[2024-11-13 08:12:53,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:53,767][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.6536698341369629, acc: 0.8113207817077637)
[2024-11-13 08:12:53,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:54,095][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.4682995676994324, acc: 0.8636363744735718)
[2024-11-13 08:12:54,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:54,361][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.05853382498025894, acc: 1.0)
[2024-11-13 08:12:54,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:54,646][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.37172621488571167, acc: 0.9230769276618958)
[2024-11-13 08:12:54,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:54,957][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.43250009417533875, acc: 0.8928571343421936)
[2024-11-13 08:12:55,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:55,313][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.7913875579833984, acc: 0.746268630027771)
[2024-11-13 08:12:55,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:55,627][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.6020315885543823, acc: 0.7638888955116272)
[2024-11-13 08:12:55,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:55,922][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.9459437727928162, acc: 0.6847826242446899)
[2024-11-13 08:12:55,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:56,205][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.7549020648002625, acc: 0.7307692170143127)
[2024-11-13 08:12:56,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:56,523][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.7899388670921326, acc: 0.75)
[2024-11-13 08:12:56,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:56,831][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.6415612101554871, acc: 0.8367347121238708)
[2024-11-13 08:12:56,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:57,112][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.12729525566101074, acc: 0.9696969985961914)
[2024-11-13 08:12:57,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:57,421][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 1.2810498476028442, acc: 0.6288659572601318)
[2024-11-13 08:12:57,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:57,726][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.6079579591751099, acc: 0.8428571224212646)
[2024-11-13 08:12:57,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:58,050][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 1.273672342300415, acc: 0.645348846912384)
[2024-11-13 08:12:58,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:58,337][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.7392721176147461, acc: 0.7678571343421936)
[2024-11-13 08:12:58,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:58,635][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 1.2218937873840332, acc: 0.6666666865348816)
[2024-11-13 08:12:58,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:58,895][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.36688485741615295, acc: 0.9444444179534912)
[2024-11-13 08:12:58,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:59,210][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.1874755322933197, acc: 0.9375)
[2024-11-13 08:12:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:59,534][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.34400543570518494, acc: 0.8846153616905212)
[2024-11-13 08:12:59,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:12:59,855][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.31283968687057495, acc: 0.9130434989929199)
[2024-11-13 08:12:59,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:00,161][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.9012740254402161, acc: 0.7142857313156128)
[2024-11-13 08:13:00,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:00,465][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.9793960452079773, acc: 0.7108433842658997)
[2024-11-13 08:13:00,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:00,814][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.8823075890541077, acc: 0.7477477192878723)
[2024-11-13 08:13:00,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:01,140][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 1.0512568950653076, acc: 0.6990291476249695)
[2024-11-13 08:13:01,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:01,475][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.816990077495575, acc: 0.7804877758026123)
[2024-11-13 08:13:01,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:01,771][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.5503473877906799, acc: 0.8333333134651184)
[2024-11-13 08:13:01,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:02,063][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.25189217925071716, acc: 0.8928571343421936)
[2024-11-13 08:13:02,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:02,421][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 1.307673692703247, acc: 0.5980392098426819)
[2024-11-13 08:13:02,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:02,743][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 1.7859656810760498, acc: 0.5021833777427673)
[2024-11-13 08:13:02,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:03,039][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 1.1974347829818726, acc: 0.6770833134651184)
[2024-11-13 08:13:03,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:03,348][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 1.3766275644302368, acc: 0.6073619723320007)
[2024-11-13 08:13:03,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:03,679][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 1.4024351835250854, acc: 0.6474820375442505)
[2024-11-13 08:13:03,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:03,980][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 1.6006296873092651, acc: 0.5025125741958618)
[2024-11-13 08:13:04,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:04,269][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.40797531604766846, acc: 0.9166666865348816)
[2024-11-13 08:13:04,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:04,576][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.42566975951194763, acc: 0.8787878751754761)
[2024-11-13 08:13:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:04,882][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.4777989089488983, acc: 0.8518518805503845)
[2024-11-13 08:13:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:05,165][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.20026902854442596, acc: 0.949999988079071)
[2024-11-13 08:13:05,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:05,448][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.310669869184494, acc: 0.8500000238418579)
[2024-11-13 08:13:05,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:05,777][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.5538989901542664, acc: 0.8448275923728943)
[2024-11-13 08:13:05,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:06,010][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.21770240366458893, acc: 0.9032257795333862)
[2024-11-13 08:13:06,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:06,269][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.268265962600708, acc: 0.9473684430122375)
[2024-11-13 08:13:06,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:06,554][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.4649229347705841, acc: 0.8518518805503845)
[2024-11-13 08:13:06,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:06,886][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.4033176898956299, acc: 0.9523809552192688)
[2024-11-13 08:13:06,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:07,200][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.3718559443950653, acc: 0.8636363744735718)
[2024-11-13 08:13:07,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:07,545][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.6979175806045532, acc: 0.800000011920929)
[2024-11-13 08:13:07,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:07,848][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.45077624917030334, acc: 0.8666666746139526)
[2024-11-13 08:13:07,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:08,158][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.2886069416999817, acc: 0.931034505367279)
[2024-11-13 08:13:08,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:08,464][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.6331678628921509, acc: 0.8039215803146362)
[2024-11-13 08:13:08,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:08,760][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.40903937816619873, acc: 0.8965517282485962)
[2024-11-13 08:13:08,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:08,992][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.14245693385601044, acc: 0.9473684430122375)
[2024-11-13 08:13:09,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:09,272][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.28268036246299744, acc: 0.9473684430122375)
[2024-11-13 08:13:09,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:09,568][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 1.0410242080688477, acc: 0.6517857313156128)
[2024-11-13 08:13:09,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:09,880][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.9101840853691101, acc: 0.7078651785850525)
[2024-11-13 08:13:09,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:10,256][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 1.1330173015594482, acc: 0.6516854166984558)
[2024-11-13 08:13:10,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:10,578][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 1.5484200716018677, acc: 0.5390070676803589)
[2024-11-13 08:13:10,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:10,889][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 1.0705311298370361, acc: 0.6739130616188049)
[2024-11-13 08:13:10,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:11,210][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.6202341318130493, acc: 0.9599999785423279)
[2024-11-13 08:13:11,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:11,571][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.2020796835422516, acc: 0.9230769276618958)
[2024-11-13 08:13:11,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:11,904][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.2572024166584015, acc: 0.8518518805503845)
[2024-11-13 08:13:11,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:12,218][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.7010985612869263, acc: 0.7777777910232544)
[2024-11-13 08:13:12,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:12,526][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.566857099533081, acc: 0.8113207817077637)
[2024-11-13 08:13:12,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:12,829][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.3632177412509918, acc: 0.8620689511299133)
[2024-11-13 08:13:12,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:13,276][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 1.2339996099472046, acc: 0.6126126050949097)
[2024-11-13 08:13:13,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:13,701][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.9355676174163818, acc: 0.7746478915214539)
[2024-11-13 08:13:13,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:14,043][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.40606531500816345, acc: 0.8999999761581421)
[2024-11-13 08:13:14,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:14,382][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.628412127494812, acc: 0.8333333134651184)
[2024-11-13 08:13:14,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:14,725][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.28561869263648987, acc: 0.9615384340286255)
[2024-11-13 08:13:15,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:15,919][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 1.4881842136383057, acc: 0.5714285969734192)
[2024-11-13 08:13:16,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:16,471][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 1.2636871337890625, acc: 0.60317462682724)
[2024-11-13 08:13:16,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:16,774][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.4283449649810791, acc: 0.8571428656578064)
[2024-11-13 08:13:16,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:17,117][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.8963614702224731, acc: 0.7666666507720947)
[2024-11-13 08:13:17,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:17,647][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.6529896259307861, acc: 0.8055555820465088)
[2024-11-13 08:13:17,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:17,977][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.23882342875003815, acc: 0.9230769276618958)
[2024-11-13 08:13:18,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:18,315][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.634499728679657, acc: 0.8064516186714172)
[2024-11-13 08:13:18,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:18,647][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.544680118560791, acc: 0.75)
[2024-11-13 08:13:18,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:18,978][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.6487628817558289, acc: 0.8148148059844971)
[2024-11-13 08:13:19,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:19,672][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 1.822324275970459, acc: 0.508474588394165)
[2024-11-13 08:13:19,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:20,069][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 1.5944721698760986, acc: 0.5373134613037109)
[2024-11-13 08:13:20,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:20,411][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 1.420837640762329, acc: 0.569343090057373)
[2024-11-13 08:13:20,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:20,848][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 1.6951206922531128, acc: 0.550000011920929)
[2024-11-13 08:13:20,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:21,160][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.8459396958351135, acc: 0.6481481194496155)
[2024-11-13 08:13:21,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:21,422][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.769562840461731, acc: 0.75)
[2024-11-13 08:13:21,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:21,765][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.6759065985679626, acc: 0.8095238208770752)
[2024-11-13 08:13:21,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:22,098][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.8755269646644592, acc: 0.7704917788505554)
[2024-11-13 08:13:22,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:22,383][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.613036036491394, acc: 0.7966101765632629)
[2024-11-13 08:13:22,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:22,672][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.9757247567176819, acc: 0.7209302186965942)
[2024-11-13 08:13:22,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:22,931][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.6847220063209534, acc: 0.8181818127632141)
[2024-11-13 08:13:22,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:23,161][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.5801398754119873, acc: 0.8301886916160583)
[2024-11-13 08:13:23,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:23,461][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.3090556859970093, acc: 0.9318181872367859)
[2024-11-13 08:13:23,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:23,823][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.4609946310520172, acc: 0.8799999952316284)
[2024-11-13 08:13:23,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:24,118][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.20490296185016632, acc: 1.0)
[2024-11-13 08:13:24,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:24,443][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.2215316891670227, acc: 0.9545454382896423)
[2024-11-13 08:13:24,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:24,810][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.7915173172950745, acc: 0.7230769395828247)
[2024-11-13 08:13:24,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:25,172][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.6898409128189087, acc: 0.796875)
[2024-11-13 08:13:25,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:25,537][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.4548482596874237, acc: 0.8125)
[2024-11-13 08:13:25,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:25,916][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.5017526745796204, acc: 0.8181818127632141)
[2024-11-13 08:13:25,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:26,266][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.1448148787021637, acc: 0.9375)
[2024-11-13 08:13:26,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:26,603][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.3081739842891693, acc: 0.8709677457809448)
[2024-11-13 08:13:26,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:26,884][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.08432821929454803, acc: 1.0)
[2024-11-13 08:13:26,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:27,183][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.5017440319061279, acc: 0.800000011920929)
[2024-11-13 08:13:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:27,544][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.4129461348056793, acc: 0.8292682766914368)
[2024-11-13 08:13:27,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:27,891][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.23911939561367035, acc: 0.9142857193946838)
[2024-11-13 08:13:27,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:28,209][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.28403621912002563, acc: 0.8947368264198303)
[2024-11-13 08:13:28,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:28,514][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.5778937339782715, acc: 0.774193525314331)
[2024-11-13 08:13:28,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:28,848][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.25248217582702637, acc: 0.9200000166893005)
[2024-11-13 08:13:28,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:29,205][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.13134349882602692, acc: 0.939393937587738)
[2024-11-13 08:13:29,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:29,474][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.40178099274635315, acc: 0.824999988079071)
[2024-11-13 08:13:29,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:29,804][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.3683341145515442, acc: 0.8714285492897034)
[2024-11-13 08:13:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:30,107][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 1.460609793663025, acc: 0.5839415788650513)
[2024-11-13 08:13:30,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:30,471][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 1.2492733001708984, acc: 0.634482741355896)
[2024-11-13 08:13:30,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:30,778][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 1.6405186653137207, acc: 0.5714285969734192)
[2024-11-13 08:13:31,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:31,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:32,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:32,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:32,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:32,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:33,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:33,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:33,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:34,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:34,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:34,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:34,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:35,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:35,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:35,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:36,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:36,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:36,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:36,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:37,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:37,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:37,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:38,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:38,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:38,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:38,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:39,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:39,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:40,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:40,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:40,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:40,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:40,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:41,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:41,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:42,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:42,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:42,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:42,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:43,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:43,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:43,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:43,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:44,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:44,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:44,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:44,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:45,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:45,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:45,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:46,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:46,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:46,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:46,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:47,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:47,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:47,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:47,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:48,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:48,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:48,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:49,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:49,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:49,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:49,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:50,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:50,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:50,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:51,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:51,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:51,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:51,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:52,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:52,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:52,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:52,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:53,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:53,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:53,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:53,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:54,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:54,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:54,987][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.6356, device='cuda:0') eval_epoch_loss=tensor(2.0328, device='cuda:0') eval_epoch_acc=tensor(0.5592, device='cuda:0')
[2024-11-13 08:13:54,989][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:13:54,989][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:13:55,303][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_9_step_556_loss_2.0328211784362793/model.pt
[2024-11-13 08:13:55,313][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:13:55,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:55,720][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 1.4320001602172852, acc: 0.556291401386261)
[2024-11-13 08:13:55,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:56,063][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 1.0300673246383667, acc: 0.6837607026100159)
[2024-11-13 08:13:56,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:56,385][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.14175723493099213, acc: 0.9599999785423279)
[2024-11-13 08:13:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:56,682][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.42222675681114197, acc: 0.8461538553237915)
[2024-11-13 08:13:56,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:57,029][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.16849085688591003, acc: 0.9615384340286255)
[2024-11-13 08:13:57,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:57,379][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.5072632431983948, acc: 0.7948718070983887)
[2024-11-13 08:13:57,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:57,755][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.792423665523529, acc: 0.7333333492279053)
[2024-11-13 08:13:57,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:58,088][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.6385510563850403, acc: 0.8181818127632141)
[2024-11-13 08:13:58,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:58,412][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.36911311745643616, acc: 0.9583333134651184)
[2024-11-13 08:13:58,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:58,758][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.5501300096511841, acc: 0.7931034564971924)
[2024-11-13 08:13:58,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:59,070][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.7548340559005737, acc: 0.7857142686843872)
[2024-11-13 08:13:59,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:59,369][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.19764858484268188, acc: 0.9473684430122375)
[2024-11-13 08:13:59,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:13:59,669][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.17570611834526062, acc: 0.9259259104728699)
[2024-11-13 08:13:59,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:00,010][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 1.3590962886810303, acc: 0.6203208565711975)
[2024-11-13 08:14:00,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:00,304][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.6264364719390869, acc: 0.8064516186714172)
[2024-11-13 08:14:00,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:00,610][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 1.0107802152633667, acc: 0.7435897588729858)
[2024-11-13 08:14:00,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:00,909][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 1.4850701093673706, acc: 0.5510203838348389)
[2024-11-13 08:14:00,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:01,216][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 1.4398469924926758, acc: 0.5408805012702942)
[2024-11-13 08:14:01,598][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=2.0534, train_epoch_loss=0.7195, epoch time 295.79717591032386s
[2024-11-13 08:14:01,599][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 08:14:01,599][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 08:14:01,599][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 08:14:01,599][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 08:14:01,599][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 08:14:02,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:02,436][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.3794943392276764, acc: 0.8518518805503845)
[2024-11-13 08:14:02,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:02,718][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.18249846994876862, acc: 0.9599999785423279)
[2024-11-13 08:14:02,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:02,998][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.7030153274536133, acc: 0.7567567825317383)
[2024-11-13 08:14:03,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:03,317][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.4039113521575928, acc: 0.8947368264198303)
[2024-11-13 08:14:03,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:03,612][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.5014336109161377, acc: 0.8108108043670654)
[2024-11-13 08:14:03,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:03,941][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.6243423819541931, acc: 0.75)
[2024-11-13 08:14:04,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:04,313][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.6063500642776489, acc: 0.8163265585899353)
[2024-11-13 08:14:04,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:04,640][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.49962118268013, acc: 0.800000011920929)
[2024-11-13 08:14:04,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:04,956][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.0909634605050087, acc: 0.9545454382896423)
[2024-11-13 08:14:05,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:05,254][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.057408928871154785, acc: 1.0)
[2024-11-13 08:14:05,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:05,582][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.20386077463626862, acc: 0.9259259104728699)
[2024-11-13 08:14:05,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:05,896][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.45946401357650757, acc: 0.8717948794364929)
[2024-11-13 08:14:05,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:06,263][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.44087275862693787, acc: 0.8787878751754761)
[2024-11-13 08:14:06,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:06,604][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.5123459696769714, acc: 0.8260869383811951)
[2024-11-13 08:14:06,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:06,908][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.4884662628173828, acc: 0.8235294222831726)
[2024-11-13 08:14:06,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:07,272][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.4540909230709076, acc: 0.8571428656578064)
[2024-11-13 08:14:07,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:07,620][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.3235275447368622, acc: 0.8947368264198303)
[2024-11-13 08:14:07,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:07,963][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.5003491044044495, acc: 0.8333333134651184)
[2024-11-13 08:14:08,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:08,344][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.5116990804672241, acc: 0.8611111044883728)
[2024-11-13 08:14:08,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:08,668][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.3269440531730652, acc: 0.8947368264198303)
[2024-11-13 08:14:08,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:08,978][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.5160056948661804, acc: 0.7307692170143127)
[2024-11-13 08:14:09,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:09,289][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.4714805781841278, acc: 0.7586206793785095)
[2024-11-13 08:14:09,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:09,621][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.5936421751976013, acc: 0.800000011920929)
[2024-11-13 08:14:09,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:09,923][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.37192803621292114, acc: 0.8571428656578064)
[2024-11-13 08:14:09,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:10,214][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.8867553472518921, acc: 0.6875)
[2024-11-13 08:14:10,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:10,528][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.7067793607711792, acc: 0.7735849022865295)
[2024-11-13 08:14:10,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:10,861][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.9626907706260681, acc: 0.7397260069847107)
[2024-11-13 08:14:11,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:11,597][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 1.7784394025802612, acc: 0.5335968136787415)
[2024-11-13 08:14:11,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:11,885][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.47090858221054077, acc: 0.8372092843055725)
[2024-11-13 08:14:11,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:12,199][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.7962259650230408, acc: 0.7469879388809204)
[2024-11-13 08:14:12,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:12,508][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.8537690043449402, acc: 0.6666666865348816)
[2024-11-13 08:14:12,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:12,866][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.3381330966949463, acc: 0.8928571343421936)
[2024-11-13 08:14:12,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:13,210][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.5245276689529419, acc: 0.8148148059844971)
[2024-11-13 08:14:13,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:13,573][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.18088479340076447, acc: 0.95652174949646)
[2024-11-13 08:14:13,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:13,952][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 1.3119529485702515, acc: 0.6638655662536621)
[2024-11-13 08:14:14,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:14,321][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.6058412790298462, acc: 0.7868852615356445)
[2024-11-13 08:14:14,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:14,661][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.9033693671226501, acc: 0.761904776096344)
[2024-11-13 08:14:14,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:14,983][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.6894135475158691, acc: 0.7966101765632629)
[2024-11-13 08:14:15,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:15,334][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.8103330135345459, acc: 0.7701149582862854)
[2024-11-13 08:14:15,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:15,601][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.5423396229743958, acc: 0.8095238208770752)
[2024-11-13 08:14:15,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:15,965][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.37301504611968994, acc: 0.8461538553237915)
[2024-11-13 08:14:16,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:16,303][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.9680418968200684, acc: 0.7567567825317383)
[2024-11-13 08:14:16,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:16,597][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.8591213226318359, acc: 0.7384615540504456)
[2024-11-13 08:14:16,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:16,922][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 1.0510330200195312, acc: 0.6767676472663879)
[2024-11-13 08:14:16,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:17,247][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.8482125401496887, acc: 0.7422680258750916)
[2024-11-13 08:14:17,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:17,592][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 1.2771271467208862, acc: 0.5882353186607361)
[2024-11-13 08:14:17,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:17,874][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.389670729637146, acc: 0.8461538553237915)
[2024-11-13 08:14:17,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:18,166][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.06056780740618706, acc: 1.0)
[2024-11-13 08:14:18,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:18,458][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.6259164214134216, acc: 0.8571428656578064)
[2024-11-13 08:14:18,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:18,776][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.1990736424922943, acc: 0.9444444179534912)
[2024-11-13 08:14:18,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:19,076][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.6784569025039673, acc: 0.7719298005104065)
[2024-11-13 08:14:19,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:19,387][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.602121889591217, acc: 0.8253968358039856)
[2024-11-13 08:14:19,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:19,692][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.6744365692138672, acc: 0.7746478915214539)
[2024-11-13 08:14:19,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:20,071][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.6801769733428955, acc: 0.5533333420753479)
[2024-11-13 08:14:20,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:20,352][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.466155081987381, acc: 0.7837837934494019)
[2024-11-13 08:14:20,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:20,641][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.27947309613227844, acc: 0.9230769276618958)
[2024-11-13 08:14:20,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:21,949][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.6170357465744019, acc: 0.5938566327095032)
[2024-11-13 08:14:22,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:22,763][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 2.207706928253174, acc: 0.44008713960647583)
[2024-11-13 08:14:22,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:23,249][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 1.6219115257263184, acc: 0.5454545617103577)
[2024-11-13 08:14:23,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:23,691][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 1.4392575025558472, acc: 0.5882353186607361)
[2024-11-13 08:14:23,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:24,146][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 1.5602089166641235, acc: 0.5072463750839233)
[2024-11-13 08:14:24,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:24,490][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 1.1306265592575073, acc: 0.6499999761581421)
[2024-11-13 08:14:24,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:24,765][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.20646359026432037, acc: 0.9117646813392639)
[2024-11-13 08:14:24,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:25,052][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.6376497745513916, acc: 0.7777777910232544)
[2024-11-13 08:14:25,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:25,372][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.5912330746650696, acc: 0.828125)
[2024-11-13 08:14:25,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:25,665][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.258587509393692, acc: 0.8620689511299133)
[2024-11-13 08:14:25,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:25,974][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.8058021664619446, acc: 0.7678571343421936)
[2024-11-13 08:14:26,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:26,282][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.8610910177230835, acc: 0.7666666507720947)
[2024-11-13 08:14:26,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:26,597][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.18195225298404694, acc: 0.9200000166893005)
[2024-11-13 08:14:26,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:26,921][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.3801911175251007, acc: 0.8611111044883728)
[2024-11-13 08:14:26,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:27,235][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.4356681704521179, acc: 0.8484848737716675)
[2024-11-13 08:14:27,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:27,562][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 1.3742951154708862, acc: 0.6102941036224365)
[2024-11-13 08:14:27,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:27,895][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 1.302155613899231, acc: 0.6349206566810608)
[2024-11-13 08:14:27,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:28,216][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 1.6617252826690674, acc: 0.5128205418586731)
[2024-11-13 08:14:28,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:28,518][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 1.0409471988677979, acc: 0.7142857313156128)
[2024-11-13 08:14:28,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:28,841][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 1.5566402673721313, acc: 0.5746268630027771)
[2024-11-13 08:14:28,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:29,191][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 1.8044617176055908, acc: 0.4927007257938385)
[2024-11-13 08:14:29,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:29,510][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.41083213686943054, acc: 0.8571428656578064)
[2024-11-13 08:14:29,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:29,828][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.12459411472082138, acc: 0.9583333134651184)
[2024-11-13 08:14:29,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:30,158][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.3806467056274414, acc: 0.8787878751754761)
[2024-11-13 08:14:30,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:30,450][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.2096993774175644, acc: 0.8846153616905212)
[2024-11-13 08:14:30,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:30,715][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.5505065321922302, acc: 0.8269230723381042)
[2024-11-13 08:14:30,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:31,004][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.5979431867599487, acc: 0.8461538553237915)
[2024-11-13 08:14:31,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:31,314][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.25443190336227417, acc: 0.9375)
[2024-11-13 08:14:31,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:31,647][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.7298277616500854, acc: 0.739130437374115)
[2024-11-13 08:14:31,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:31,967][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.6031209230422974, acc: 0.8399999737739563)
[2024-11-13 08:14:32,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:32,276][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.39103299379348755, acc: 0.9130434989929199)
[2024-11-13 08:14:32,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:32,635][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.7855158448219299, acc: 0.7400000095367432)
[2024-11-13 08:14:32,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:32,939][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.8210524320602417, acc: 0.737864077091217)
[2024-11-13 08:14:33,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:33,655][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 1.4186125993728638, acc: 0.6262136101722717)
[2024-11-13 08:14:33,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:34,270][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 1.4402153491973877, acc: 0.5913978219032288)
[2024-11-13 08:14:34,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:34,862][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 1.33403480052948, acc: 0.625)
[2024-11-13 08:14:34,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:35,431][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.8887414932250977, acc: 0.6842105388641357)
[2024-11-13 08:14:35,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:36,127][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 1.1079137325286865, acc: 0.6732673048973083)
[2024-11-13 08:14:36,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:36,410][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.7395761013031006, acc: 0.8225806355476379)
[2024-11-13 08:14:36,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:36,701][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.816373348236084, acc: 0.7536231875419617)
[2024-11-13 08:14:36,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:37,048][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 1.1592973470687866, acc: 0.6134454011917114)
[2024-11-13 08:14:37,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:37,368][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 1.3777936697006226, acc: 0.5865384340286255)
[2024-11-13 08:14:37,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:37,703][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 1.2967216968536377, acc: 0.5985401272773743)
[2024-11-13 08:14:37,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:37,993][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.5403086543083191, acc: 0.8507462739944458)
[2024-11-13 08:14:38,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:38,313][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.6925622224807739, acc: 0.8500000238418579)
[2024-11-13 08:14:38,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:38,619][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.13715027272701263, acc: 1.0)
[2024-11-13 08:14:38,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:38,920][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.2725915014743805, acc: 0.9130434989929199)
[2024-11-13 08:14:38,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:39,244][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.4071347117424011, acc: 0.8409090638160706)
[2024-11-13 08:14:39,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:39,570][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.7562860250473022, acc: 0.7931034564971924)
[2024-11-13 08:14:39,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:39,904][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.2976449131965637, acc: 0.9069767594337463)
[2024-11-13 08:14:39,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:40,211][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.4138140082359314, acc: 0.8799999952316284)
[2024-11-13 08:14:40,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:40,506][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.010454883798956871, acc: 1.0)
[2024-11-13 08:14:40,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:40,812][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.06401403993368149, acc: 0.9615384340286255)
[2024-11-13 08:14:40,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:41,107][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.30428576469421387, acc: 0.8571428656578064)
[2024-11-13 08:14:41,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:41,414][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.5836606621742249, acc: 0.800000011920929)
[2024-11-13 08:14:41,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:41,759][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 1.0300556421279907, acc: 0.7719298005104065)
[2024-11-13 08:14:41,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:42,069][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.6285043954849243, acc: 0.8245614171028137)
[2024-11-13 08:14:42,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:42,377][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.5857699513435364, acc: 0.8461538553237915)
[2024-11-13 08:14:42,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:42,706][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.3644214868545532, acc: 0.918367326259613)
[2024-11-13 08:14:42,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:42,985][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.03235064074397087, acc: 1.0)
[2024-11-13 08:14:43,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:43,296][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.500029981136322, acc: 0.8095238208770752)
[2024-11-13 08:14:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:43,585][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.8943188786506653, acc: 0.7560975551605225)
[2024-11-13 08:14:43,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:43,922][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.5551932454109192, acc: 0.8548387289047241)
[2024-11-13 08:14:44,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:44,544][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 1.539157509803772, acc: 0.5703421831130981)
[2024-11-13 08:14:44,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:44,852][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.438155859708786, acc: 0.8799999952316284)
[2024-11-13 08:14:44,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:45,203][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.3535768389701843, acc: 0.9038461446762085)
[2024-11-13 08:14:45,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:45,496][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.2579677999019623, acc: 0.9583333134651184)
[2024-11-13 08:14:45,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:45,791][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.12247907370328903, acc: 1.0)
[2024-11-13 08:14:45,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:46,145][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 1.113960862159729, acc: 0.6625766754150391)
[2024-11-13 08:14:46,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:47,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:47,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:47,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:48,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:48,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:48,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:48,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:49,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:49,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:49,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:49,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:50,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:50,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:50,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:51,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:51,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:51,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:51,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:52,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:52,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:52,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:52,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:53,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:53,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:53,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:53,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:54,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:54,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:54,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:54,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:55,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:55,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:55,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:55,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:56,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:56,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:56,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:57,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:57,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:57,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:58,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:58,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:58,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:58,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:59,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:59,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:14:59,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:00,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:00,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:00,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:00,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:01,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:01,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:01,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:01,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:02,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:02,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:02,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:03,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:03,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:03,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:03,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:04,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:04,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:04,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:04,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:05,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:06,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:06,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:06,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:06,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:07,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:07,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:07,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:07,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:07,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:08,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:08,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:08,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:08,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:09,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:09,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:10,010][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.0706, device='cuda:0') eval_epoch_loss=tensor(2.2050, device='cuda:0') eval_epoch_acc=tensor(0.5613, device='cuda:0')
[2024-11-13 08:15:10,011][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:15:10,012][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:15:10,344][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_10_step_125_loss_2.2050347328186035/model.pt
[2024-11-13 08:15:10,352][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:15:10,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:10,741][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 1.1773046255111694, acc: 0.6597222089767456)
[2024-11-13 08:15:10,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:11,018][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 1.0155845880508423, acc: 0.7166666388511658)
[2024-11-13 08:15:11,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:11,311][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 1.3466697931289673, acc: 0.6071428656578064)
[2024-11-13 08:15:11,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:11,650][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 1.3980343341827393, acc: 0.6153846383094788)
[2024-11-13 08:15:11,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:12,004][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 0.9810938835144043, acc: 0.6838235259056091)
[2024-11-13 08:15:12,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:12,313][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.5674270391464233, acc: 0.807692289352417)
[2024-11-13 08:15:12,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:12,581][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.10882759094238281, acc: 0.95652174949646)
[2024-11-13 08:15:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:12,884][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.23127850890159607, acc: 0.96875)
[2024-11-13 08:15:12,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:13,172][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.09943988174200058, acc: 0.95652174949646)
[2024-11-13 08:15:13,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:13,461][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.5229666829109192, acc: 0.8285714387893677)
[2024-11-13 08:15:13,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:13,752][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.1899637132883072, acc: 0.9230769276618958)
[2024-11-13 08:15:13,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:14,043][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.5986353754997253, acc: 0.8333333134651184)
[2024-11-13 08:15:14,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:14,340][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.6155436038970947, acc: 0.800000011920929)
[2024-11-13 08:15:14,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:14,628][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.3441838026046753, acc: 0.8695651888847351)
[2024-11-13 08:15:14,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:14,940][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.4971289336681366, acc: 0.8095238208770752)
[2024-11-13 08:15:14,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:15,224][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.6332845687866211, acc: 0.7692307829856873)
[2024-11-13 08:15:15,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:15,507][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.4630247950553894, acc: 0.8387096524238586)
[2024-11-13 08:15:15,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:15,795][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.8526297211647034, acc: 0.6756756901741028)
[2024-11-13 08:15:15,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:16,214][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 1.1182489395141602, acc: 0.6228070259094238)
[2024-11-13 08:15:16,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:16,512][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 1.1344106197357178, acc: 0.6716417670249939)
[2024-11-13 08:15:16,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:16,823][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 1.2728079557418823, acc: 0.6122449040412903)
[2024-11-13 08:15:16,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:17,190][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 1.1186347007751465, acc: 0.6595744490623474)
[2024-11-13 08:15:17,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:17,511][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.7379780411720276, acc: 0.7571428418159485)
[2024-11-13 08:15:17,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:17,820][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.7483033537864685, acc: 0.8214285969734192)
[2024-11-13 08:15:17,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:18,131][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.37958401441574097, acc: 0.8695651888847351)
[2024-11-13 08:15:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:18,421][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.4726676940917969, acc: 0.8275862336158752)
[2024-11-13 08:15:18,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:18,726][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.4780336320400238, acc: 0.8478260636329651)
[2024-11-13 08:15:18,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:19,040][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.5906402468681335, acc: 0.8305084705352783)
[2024-11-13 08:15:19,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:19,366][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.7720685005187988, acc: 0.7543859481811523)
[2024-11-13 08:15:19,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:19,690][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 1.2067843675613403, acc: 0.6351351141929626)
[2024-11-13 08:15:19,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:19,981][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.8912806510925293, acc: 0.8214285969734192)
[2024-11-13 08:15:20,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:20,281][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.47240859270095825, acc: 0.8695651888847351)
[2024-11-13 08:15:20,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:20,607][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.27185678482055664, acc: 0.8947368264198303)
[2024-11-13 08:15:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:21,472][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 1.2196605205535889, acc: 0.662162184715271)
[2024-11-13 08:15:21,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:21,740][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 1.0168708562850952, acc: 0.6851851940155029)
[2024-11-13 08:15:21,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:22,096][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 1.1882573366165161, acc: 0.6511628031730652)
[2024-11-13 08:15:22,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:22,547][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 0.9048287868499756, acc: 0.7764706015586853)
[2024-11-13 08:15:22,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:22,986][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 1.333145260810852, acc: 0.6067415475845337)
[2024-11-13 08:15:23,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:23,306][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.5327117443084717, acc: 0.8863636255264282)
[2024-11-13 08:15:23,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:23,653][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.8688634037971497, acc: 0.6666666865348816)
[2024-11-13 08:15:23,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:23,956][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 0.5684351325035095, acc: 0.7586206793785095)
[2024-11-13 08:15:24,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:24,235][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.4616113007068634, acc: 0.8775510191917419)
[2024-11-13 08:15:24,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:24,543][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.6784684062004089, acc: 0.8199999928474426)
[2024-11-13 08:15:24,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:24,931][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.8775500059127808, acc: 0.7361111044883728)
[2024-11-13 08:15:25,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:25,228][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 1.05223548412323, acc: 0.6666666865348816)
[2024-11-13 08:15:25,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:25,932][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 1.5724166631698608, acc: 0.5616438388824463)
[2024-11-13 08:15:25,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:26,190][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.20482726395130157, acc: 1.0)
[2024-11-13 08:15:26,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:26,545][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.18913306295871735, acc: 0.9259259104728699)
[2024-11-13 08:15:26,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:26,872][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.348686158657074, acc: 0.8571428656578064)
[2024-11-13 08:15:26,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:27,300][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 0.8779616355895996, acc: 0.76106196641922)
[2024-11-13 08:15:27,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:27,562][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.5413674116134644, acc: 0.8115941882133484)
[2024-11-13 08:15:27,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:27,823][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.8570427298545837, acc: 0.7840909361839294)
[2024-11-13 08:15:28,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:28,462][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 1.6315888166427612, acc: 0.48091602325439453)
[2024-11-13 08:15:28,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:28,961][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 1.3328968286514282, acc: 0.6000000238418579)
[2024-11-13 08:15:29,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:29,243][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.5157291293144226, acc: 0.8524590134620667)
[2024-11-13 08:15:29,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:29,561][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.15965379774570465, acc: 0.9166666865348816)
[2024-11-13 08:15:29,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:29,914][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.4389352798461914, acc: 0.9200000166893005)
[2024-11-13 08:15:29,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:30,248][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.23241427540779114, acc: 0.9285714030265808)
[2024-11-13 08:15:30,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:30,583][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.8925507664680481, acc: 0.6951219439506531)
[2024-11-13 08:15:30,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:30,968][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 1.8050978183746338, acc: 0.5075528621673584)
[2024-11-13 08:15:31,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:31,354][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 2.070899248123169, acc: 0.48414984345436096)
[2024-11-13 08:15:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:31,751][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 2.030595302581787, acc: 0.4625000059604645)
[2024-11-13 08:15:31,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:32,202][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 2.0498440265655518, acc: 0.454033762216568)
[2024-11-13 08:15:32,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:32,596][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 1.8417041301727295, acc: 0.5017793774604797)
[2024-11-13 08:15:32,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:32,970][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.4786275029182434, acc: 0.8399999737739563)
[2024-11-13 08:15:33,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:33,400][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 1.546222448348999, acc: 0.5465116500854492)
[2024-11-13 08:15:33,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:33,966][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 1.5525871515274048, acc: 0.5634920597076416)
[2024-11-13 08:15:34,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:34,592][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 1.56313157081604, acc: 0.5909090638160706)
[2024-11-13 08:15:34,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:35,140][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 1.249743103981018, acc: 0.6470588445663452)
[2024-11-13 08:15:35,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:35,863][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 1.4113001823425293, acc: 0.6172839403152466)
[2024-11-13 08:15:36,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:36,513][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.968457818031311, acc: 0.7903226017951965)
[2024-11-13 08:15:36,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:36,805][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.39705634117126465, acc: 0.8928571343421936)
[2024-11-13 08:15:36,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:37,063][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.5285820960998535, acc: 0.7749999761581421)
[2024-11-13 08:15:37,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:37,391][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.9227499961853027, acc: 0.7647058963775635)
[2024-11-13 08:15:37,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:37,727][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 1.3540103435516357, acc: 0.625)
[2024-11-13 08:15:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:38,076][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 1.3238513469696045, acc: 0.6016949415206909)
[2024-11-13 08:15:38,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:38,373][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 1.499351143836975, acc: 0.5447761416435242)
[2024-11-13 08:15:38,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:38,693][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 1.2794389724731445, acc: 0.6213592290878296)
[2024-11-13 08:15:38,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:39,040][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.6916555166244507, acc: 0.7936508059501648)
[2024-11-13 08:15:39,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:39,368][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.8808587789535522, acc: 0.7362637519836426)
[2024-11-13 08:15:39,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:39,721][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 1.5369168519973755, acc: 0.573991060256958)
[2024-11-13 08:15:39,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:40,116][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 1.650212287902832, acc: 0.5708661675453186)
[2024-11-13 08:15:40,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:40,486][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 1.4977530241012573, acc: 0.568965494632721)
[2024-11-13 08:15:40,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:40,829][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 1.5238722562789917, acc: 0.5652173757553101)
[2024-11-13 08:15:40,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:41,171][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 1.7002484798431396, acc: 0.49805447459220886)
[2024-11-13 08:15:41,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:41,492][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 1.0182005167007446, acc: 0.6739130616188049)
[2024-11-13 08:15:41,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:41,805][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.22888343036174774, acc: 0.9130434989929199)
[2024-11-13 08:15:41,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:42,158][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.2604622542858124, acc: 0.9285714030265808)
[2024-11-13 08:15:42,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:42,513][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.46055835485458374, acc: 0.8297872543334961)
[2024-11-13 08:15:42,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:43,015][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 1.004427194595337, acc: 0.7307692170143127)
[2024-11-13 08:15:43,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:43,311][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.5665077567100525, acc: 0.8108108043670654)
[2024-11-13 08:15:43,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:43,678][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.7898127436637878, acc: 0.7558139562606812)
[2024-11-13 08:15:43,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:44,116][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.8548862338066101, acc: 0.7297297120094299)
[2024-11-13 08:15:44,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:44,454][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.7299893498420715, acc: 0.7888888716697693)
[2024-11-13 08:15:44,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:44,768][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.3338676989078522, acc: 0.8787878751754761)
[2024-11-13 08:15:44,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:45,093][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.13383589684963226, acc: 0.9629629850387573)
[2024-11-13 08:15:45,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:45,364][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.29930809140205383, acc: 0.9200000166893005)
[2024-11-13 08:15:45,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:45,669][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.5665333271026611, acc: 0.7884615659713745)
[2024-11-13 08:15:45,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:46,222][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 1.0145760774612427, acc: 0.7119565010070801)
[2024-11-13 08:15:46,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:46,648][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 1.2034159898757935, acc: 0.6477272510528564)
[2024-11-13 08:15:46,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:47,020][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.6616774797439575, acc: 0.8085106611251831)
[2024-11-13 08:15:47,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:47,384][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.3516235649585724, acc: 0.9245283007621765)
[2024-11-13 08:15:47,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:47,722][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.6754536032676697, acc: 0.7666666507720947)
[2024-11-13 08:15:47,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:48,065][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.32354918122291565, acc: 0.9069767594337463)
[2024-11-13 08:15:48,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:48,395][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.49037468433380127, acc: 0.8333333134651184)
[2024-11-13 08:15:48,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:48,735][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 0.6590405702590942, acc: 0.8315789699554443)
[2024-11-13 08:15:48,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:49,059][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.6549573540687561, acc: 0.7777777910232544)
[2024-11-13 08:15:49,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:49,418][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 0.8372557163238525, acc: 0.7666666507720947)
[2024-11-13 08:15:49,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:49,814][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 1.2541041374206543, acc: 0.6513761281967163)
[2024-11-13 08:15:49,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:50,236][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 0.7044823169708252, acc: 0.8153846263885498)
[2024-11-13 08:15:50,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:50,550][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.20875711739063263, acc: 0.8947368264198303)
[2024-11-13 08:15:50,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:50,884][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.09959352016448975, acc: 0.9583333134651184)
[2024-11-13 08:15:50,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:51,230][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.6014163494110107, acc: 0.6363636255264282)
[2024-11-13 08:15:51,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:51,561][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.3720881938934326, acc: 0.8888888955116272)
[2024-11-13 08:15:51,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:51,827][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.3012026846408844, acc: 0.8857142925262451)
[2024-11-13 08:15:51,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:52,099][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.27037513256073, acc: 0.9090909361839294)
[2024-11-13 08:15:52,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:52,425][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.4553118646144867, acc: 0.8863636255264282)
[2024-11-13 08:15:52,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:52,867][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 0.7436368465423584, acc: 0.7419354915618896)
[2024-11-13 08:15:52,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:53,275][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.3902340829372406, acc: 0.9318181872367859)
[2024-11-13 08:15:53,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:53,569][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.22278015315532684, acc: 0.9523809552192688)
[2024-11-13 08:15:53,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:53,875][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.2238778918981552, acc: 0.9230769276618958)
[2024-11-13 08:15:53,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:54,177][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.24084322154521942, acc: 0.9677419066429138)
[2024-11-13 08:15:54,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:54,539][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.39774414896965027, acc: 0.8500000238418579)
[2024-11-13 08:15:54,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:54,900][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.4648962914943695, acc: 0.837837815284729)
[2024-11-13 08:15:54,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:55,253][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.367249995470047, acc: 0.8648648858070374)
[2024-11-13 08:15:55,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:55,562][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.24229755997657776, acc: 0.9459459185600281)
[2024-11-13 08:15:55,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:55,870][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.7159113883972168, acc: 0.8088235259056091)
[2024-11-13 08:15:55,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:56,216][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.24363961815834045, acc: 0.9756097793579102)
[2024-11-13 08:15:56,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:56,551][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.04425142705440521, acc: 1.0)
[2024-11-13 08:15:56,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:56,905][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.04093113914132118, acc: 1.0)
[2024-11-13 08:15:56,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:57,187][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.15004974603652954, acc: 0.9354838728904724)
[2024-11-13 08:15:57,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:57,543][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.5779865980148315, acc: 0.8070175647735596)
[2024-11-13 08:15:57,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:57,878][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.4660252630710602, acc: 0.8571428656578064)
[2024-11-13 08:15:57,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:58,188][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.5058022141456604, acc: 0.8289473652839661)
[2024-11-13 08:15:58,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:58,639][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.8445104360580444, acc: 0.7075471878051758)
[2024-11-13 08:15:58,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:59,087][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 1.1026058197021484, acc: 0.6916666626930237)
[2024-11-13 08:15:59,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:59,363][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.46389850974082947, acc: 0.8333333134651184)
[2024-11-13 08:15:59,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:15:59,690][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.30559399724006653, acc: 0.8709677457809448)
[2024-11-13 08:15:59,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:00,019][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.9755454659461975, acc: 0.7599999904632568)
[2024-11-13 08:16:00,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:00,349][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.4953314960002899, acc: 0.8125)
[2024-11-13 08:16:00,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:00,929][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 1.4898196458816528, acc: 0.5519999861717224)
[2024-11-13 08:16:00,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:01,278][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.8991765975952148, acc: 0.7191011309623718)
[2024-11-13 08:16:01,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:01,590][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.815650999546051, acc: 0.7162162065505981)
[2024-11-13 08:16:02,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:02,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:02,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:03,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:03,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:03,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:03,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:04,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:04,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:04,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:04,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:05,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:05,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:05,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:06,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:06,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:06,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:06,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:06,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:07,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:07,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:07,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:07,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:08,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:08,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:08,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:09,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:09,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:09,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:09,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:10,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:10,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:10,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:10,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:11,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:11,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:11,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:11,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:12,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:12,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:12,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:12,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:13,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:13,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:13,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:13,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:14,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:14,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:14,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:15,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:15,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:15,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:15,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:15,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:16,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:16,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:16,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:16,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:17,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:17,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:17,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:17,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:18,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:18,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:19,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:19,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:19,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:19,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:20,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:20,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:20,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:20,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:21,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:21,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:21,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:22,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:22,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:22,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:23,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:23,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:23,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:24,165][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.2677, device='cuda:0') eval_epoch_loss=tensor(2.1124, device='cuda:0') eval_epoch_acc=tensor(0.5613, device='cuda:0')
[2024-11-13 08:16:24,166][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:16:24,167][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:16:24,500][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_10_step_268_loss_2.112354040145874/model.pt
[2024-11-13 08:16:24,511][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:16:24,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:24,961][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.5082492828369141, acc: 0.8620689511299133)
[2024-11-13 08:16:25,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:25,265][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.10562565922737122, acc: 0.9545454382896423)
[2024-11-13 08:16:25,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:25,584][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.33173930644989014, acc: 0.8181818127632141)
[2024-11-13 08:16:25,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:25,880][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.2935498058795929, acc: 0.90625)
[2024-11-13 08:16:25,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:26,186][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.285500705242157, acc: 0.9333333373069763)
[2024-11-13 08:16:26,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:26,524][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.4790093004703522, acc: 0.8666666746139526)
[2024-11-13 08:16:26,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:26,820][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.44699543714523315, acc: 0.8125)
[2024-11-13 08:16:26,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:27,132][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.27216431498527527, acc: 1.0)
[2024-11-13 08:16:27,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:27,451][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.30870872735977173, acc: 0.8965517282485962)
[2024-11-13 08:16:27,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:27,737][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.22638121247291565, acc: 0.9200000166893005)
[2024-11-13 08:16:27,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:28,020][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.5260105729103088, acc: 0.8723404407501221)
[2024-11-13 08:16:28,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:28,322][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.5506356358528137, acc: 0.8125)
[2024-11-13 08:16:28,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:28,600][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.2288038730621338, acc: 0.9545454382896423)
[2024-11-13 08:16:28,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:28,968][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.7380995750427246, acc: 0.7831325531005859)
[2024-11-13 08:16:29,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:29,289][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 1.2106430530548096, acc: 0.6481481194496155)
[2024-11-13 08:16:29,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:29,575][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.4414641857147217, acc: 0.8684210777282715)
[2024-11-13 08:16:29,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:29,872][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.44996753334999084, acc: 0.8823529481887817)
[2024-11-13 08:16:29,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:30,095][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.28237539529800415, acc: 0.8999999761581421)
[2024-11-13 08:16:30,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:30,372][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 1.0633149147033691, acc: 0.6796875)
[2024-11-13 08:16:30,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:30,668][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 1.1259886026382446, acc: 0.6800000071525574)
[2024-11-13 08:16:30,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:30,962][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.7249251008033752, acc: 0.7692307829856873)
[2024-11-13 08:16:31,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:31,320][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 1.3205333948135376, acc: 0.6521739363670349)
[2024-11-13 08:16:31,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:31,656][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 1.5350390672683716, acc: 0.5773195624351501)
[2024-11-13 08:16:31,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:31,944][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.11852890998125076, acc: 1.0)
[2024-11-13 08:16:32,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:32,217][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.4724043905735016, acc: 0.8095238208770752)
[2024-11-13 08:16:32,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:32,521][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.5361456871032715, acc: 0.8275862336158752)
[2024-11-13 08:16:32,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:32,894][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.31389474868774414, acc: 0.9454545378684998)
[2024-11-13 08:16:32,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:33,333][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 1.4055736064910889, acc: 0.6134020686149597)
[2024-11-13 08:16:33,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:33,652][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.6124567985534668, acc: 0.7758620977401733)
[2024-11-13 08:16:33,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:33,984][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.45955392718315125, acc: 0.8888888955116272)
[2024-11-13 08:16:34,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:34,296][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.6319769620895386, acc: 0.8421052694320679)
[2024-11-13 08:16:34,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:34,592][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.47467735409736633, acc: 0.875)
[2024-11-13 08:16:34,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:34,884][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.3845035135746002, acc: 0.84375)
[2024-11-13 08:16:34,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:35,179][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.44954538345336914, acc: 0.8679245114326477)
[2024-11-13 08:16:35,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:35,479][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.34389546513557434, acc: 0.8867924809455872)
[2024-11-13 08:16:35,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:35,758][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.19989845156669617, acc: 0.970588207244873)
[2024-11-13 08:16:35,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:36,007][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.44461339712142944, acc: 0.84375)
[2024-11-13 08:16:36,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:36,290][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.5119802951812744, acc: 0.8524590134620667)
[2024-11-13 08:16:36,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:36,565][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.23926766216754913, acc: 0.8999999761581421)
[2024-11-13 08:16:36,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:36,873][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.05871988460421562, acc: 0.9473684430122375)
[2024-11-13 08:16:36,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:37,187][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.660728394985199, acc: 0.8405796885490417)
[2024-11-13 08:16:37,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:37,522][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.7918418645858765, acc: 0.7083333134651184)
[2024-11-13 08:16:37,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:37,748][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.6844976544380188, acc: 0.7831325531005859)
[2024-11-13 08:16:37,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:38,076][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.8435778617858887, acc: 0.7435897588729858)
[2024-11-13 08:16:38,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:38,417][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.9218825697898865, acc: 0.704081654548645)
[2024-11-13 08:16:38,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:38,701][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.01712336577475071, acc: 1.0)
[2024-11-13 08:16:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:38,980][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.27079829573631287, acc: 0.9583333134651184)
[2024-11-13 08:16:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:39,269][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.20722320675849915, acc: 0.9354838728904724)
[2024-11-13 08:16:39,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:39,539][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.13283054530620575, acc: 0.9354838728904724)
[2024-11-13 08:16:39,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:39,870][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.41545483469963074, acc: 0.89552241563797)
[2024-11-13 08:16:39,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:40,183][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.6486203074455261, acc: 0.7980769276618958)
[2024-11-13 08:16:40,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:40,472][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.3979438245296478, acc: 0.8888888955116272)
[2024-11-13 08:16:40,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:40,743][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.47755032777786255, acc: 0.8548387289047241)
[2024-11-13 08:16:40,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:41,033][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.2601003646850586, acc: 0.9399999976158142)
[2024-11-13 08:16:41,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:41,294][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.8931076526641846, acc: 0.7037037014961243)
[2024-11-13 08:16:41,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:41,577][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.6343336701393127, acc: 0.8285714387893677)
[2024-11-13 08:16:41,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:41,845][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.4791887700557709, acc: 0.8974359035491943)
[2024-11-13 08:16:41,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:42,123][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.7488610148429871, acc: 0.7317073345184326)
[2024-11-13 08:16:42,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:42,410][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.3557373881340027, acc: 0.9210526347160339)
[2024-11-13 08:16:42,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:42,694][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.051348913460969925, acc: 1.0)
[2024-11-13 08:16:42,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:42,965][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.09795605391263962, acc: 0.9642857313156128)
[2024-11-13 08:16:43,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:43,312][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.271294504404068, acc: 0.8888888955116272)
[2024-11-13 08:16:43,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:43,637][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.11565783619880676, acc: 1.0)
[2024-11-13 08:16:43,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:43,943][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.4004814028739929, acc: 0.9032257795333862)
[2024-11-13 08:16:44,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:44,275][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.6436268091201782, acc: 0.7894737124443054)
[2024-11-13 08:16:44,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:44,604][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.47020813822746277, acc: 0.8125)
[2024-11-13 08:16:44,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:44,906][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.2781420946121216, acc: 0.9666666388511658)
[2024-11-13 08:16:44,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:45,228][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.24261023104190826, acc: 0.9473684430122375)
[2024-11-13 08:16:45,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:45,546][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.6938708424568176, acc: 0.7799999713897705)
[2024-11-13 08:16:45,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:45,870][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 1.0738179683685303, acc: 0.6666666865348816)
[2024-11-13 08:16:45,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:46,204][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 1.140128493309021, acc: 0.6702127456665039)
[2024-11-13 08:16:46,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:46,521][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 1.4133740663528442, acc: 0.6024096608161926)
[2024-11-13 08:16:46,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:46,809][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.16657865047454834, acc: 0.9130434989929199)
[2024-11-13 08:16:46,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:47,106][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.3238828182220459, acc: 0.9230769276618958)
[2024-11-13 08:16:47,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:47,394][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.8203305006027222, acc: 0.7469879388809204)
[2024-11-13 08:16:47,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:47,701][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.4613313376903534, acc: 0.9056603908538818)
[2024-11-13 08:16:47,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:48,008][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.44347870349884033, acc: 0.8354430198669434)
[2024-11-13 08:16:48,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:48,318][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.367773175239563, acc: 0.8823529481887817)
[2024-11-13 08:16:48,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:48,614][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.7213852405548096, acc: 0.7761194109916687)
[2024-11-13 08:16:48,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:48,930][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.1822148859500885, acc: 0.949999988079071)
[2024-11-13 08:16:49,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:49,233][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.12027224898338318, acc: 0.9599999785423279)
[2024-11-13 08:16:49,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:49,563][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.29181361198425293, acc: 0.9166666865348816)
[2024-11-13 08:16:49,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:49,913][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.5848384499549866, acc: 0.7674418687820435)
[2024-11-13 08:16:49,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:50,258][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.45729860663414, acc: 0.8461538553237915)
[2024-11-13 08:16:50,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:50,625][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.7100189924240112, acc: 0.800000011920929)
[2024-11-13 08:16:50,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:50,951][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.3459155261516571, acc: 0.782608687877655)
[2024-11-13 08:16:51,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:51,263][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.41295182704925537, acc: 0.8461538553237915)
[2024-11-13 08:16:51,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:51,613][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 1.016226053237915, acc: 0.7362637519836426)
[2024-11-13 08:16:51,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:52,009][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 1.2108339071273804, acc: 0.678260862827301)
[2024-11-13 08:16:52,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:52,340][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.7365105748176575, acc: 0.804347813129425)
[2024-11-13 08:16:52,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:52,689][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.6957915425300598, acc: 0.8367347121238708)
[2024-11-13 08:16:52,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:53,032][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.14799346029758453, acc: 0.9166666865348816)
[2024-11-13 08:16:53,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:53,353][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.1773889809846878, acc: 0.9230769276618958)
[2024-11-13 08:16:53,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:53,666][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.16265827417373657, acc: 0.9512194991111755)
[2024-11-13 08:16:53,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:53,991][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.3714993894100189, acc: 0.8888888955116272)
[2024-11-13 08:16:54,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:54,273][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.5135806202888489, acc: 0.8289473652839661)
[2024-11-13 08:16:54,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:54,598][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.38842856884002686, acc: 0.8536585569381714)
[2024-11-13 08:16:54,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:54,945][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.5618746876716614, acc: 0.8181818127632141)
[2024-11-13 08:16:55,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:55,260][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.19004817306995392, acc: 0.9166666865348816)
[2024-11-13 08:16:55,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:55,598][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.011453664861619473, acc: 1.0)
[2024-11-13 08:16:55,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:55,952][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.1526622325181961, acc: 0.9642857313156128)
[2024-11-13 08:16:56,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:56,254][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.1727922558784485, acc: 0.96875)
[2024-11-13 08:16:56,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:56,726][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 1.410354733467102, acc: 0.6060606241226196)
[2024-11-13 08:16:56,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:57,308][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.9272254109382629, acc: 0.7358490824699402)
[2024-11-13 08:16:57,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:57,651][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.645042896270752, acc: 0.8333333134651184)
[2024-11-13 08:16:57,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:57,978][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.6381699442863464, acc: 0.7678571343421936)
[2024-11-13 08:16:58,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:58,300][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.3004246652126312, acc: 0.9428571462631226)
[2024-11-13 08:16:58,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:58,609][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.03598126024007797, acc: 1.0)
[2024-11-13 08:16:58,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:58,940][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.24898815155029297, acc: 0.95652174949646)
[2024-11-13 08:16:59,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:59,305][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.4804031550884247, acc: 0.8541666865348816)
[2024-11-13 08:16:59,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:16:59,659][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.7443708777427673, acc: 0.7684210538864136)
[2024-11-13 08:16:59,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:00,109][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 1.1276570558547974, acc: 0.6706587076187134)
[2024-11-13 08:17:00,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:00,434][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.6461700797080994, acc: 0.8045112490653992)
[2024-11-13 08:17:00,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:01,170][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 1.1336115598678589, acc: 0.6791443824768066)
[2024-11-13 08:17:01,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:01,617][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.5300315022468567, acc: 0.8198198080062866)
[2024-11-13 08:17:01,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:01,946][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.23081877827644348, acc: 0.9642857313156128)
[2024-11-13 08:17:02,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:02,292][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.0717763900756836, acc: 0.9642857313156128)
[2024-11-13 08:17:02,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:02,611][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.200840026140213, acc: 0.875)
[2024-11-13 08:17:02,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:02,898][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.3626546263694763, acc: 0.9166666865348816)
[2024-11-13 08:17:02,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:03,246][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.18315108120441437, acc: 0.9736841917037964)
[2024-11-13 08:17:03,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:03,591][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.036822423338890076, acc: 1.0)
[2024-11-13 08:17:03,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:03,951][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.11712899059057236, acc: 1.0)
[2024-11-13 08:17:04,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:04,293][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.040660031139850616, acc: 1.0)
[2024-11-13 08:17:04,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:04,624][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.41931477189064026, acc: 0.9444444179534912)
[2024-11-13 08:17:04,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:04,969][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 1.1216713190078735, acc: 0.6796116232872009)
[2024-11-13 08:17:05,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:05,405][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 1.0961531400680542, acc: 0.6911764740943909)
[2024-11-13 08:17:05,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:05,785][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 1.1351659297943115, acc: 0.6399999856948853)
[2024-11-13 08:17:05,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:06,160][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 1.4385771751403809, acc: 0.5347222089767456)
[2024-11-13 08:17:06,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:06,442][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.5528267025947571, acc: 0.8372092843055725)
[2024-11-13 08:17:06,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:06,733][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.3204308748245239, acc: 0.875)
[2024-11-13 08:17:06,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:07,062][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.5229324698448181, acc: 0.8604651093482971)
[2024-11-13 08:17:07,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:07,357][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.20175741612911224, acc: 0.9200000166893005)
[2024-11-13 08:17:07,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:07,787][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.7915825843811035, acc: 0.779411792755127)
[2024-11-13 08:17:07,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:08,139][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.40666842460632324, acc: 0.8666666746139526)
[2024-11-13 08:17:08,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:08,452][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.20240303874015808, acc: 0.939393937587738)
[2024-11-13 08:17:08,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:08,794][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.4966983199119568, acc: 0.8787878751754761)
[2024-11-13 08:17:08,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:09,100][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.12347642332315445, acc: 0.9677419066429138)
[2024-11-13 08:17:09,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:09,385][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.23602300882339478, acc: 0.9259259104728699)
[2024-11-13 08:17:09,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:09,694][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.05863092094659805, acc: 1.0)
[2024-11-13 08:17:09,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:10,010][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.2019978165626526, acc: 0.9444444179534912)
[2024-11-13 08:17:10,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:10,316][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.21856962144374847, acc: 0.9629629850387573)
[2024-11-13 08:17:10,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:10,577][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.1422891914844513, acc: 0.9615384340286255)
[2024-11-13 08:17:10,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:10,875][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.4107992947101593, acc: 0.8965517282485962)
[2024-11-13 08:17:11,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:11,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:12,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:12,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:12,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:13,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:13,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:13,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:13,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:14,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:14,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:14,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:15,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:15,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:15,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:16,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:16,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:16,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:16,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:17,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:17,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:17,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:18,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:18,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:18,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:19,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:19,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:19,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:19,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:20,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:20,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:20,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:20,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:21,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:21,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:21,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:21,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:22,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:22,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:22,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:22,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:23,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:23,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:23,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:24,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:24,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:24,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:24,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:25,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:25,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:25,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:26,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:26,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:26,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:26,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:27,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:27,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:27,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:27,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:28,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:28,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:28,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:29,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:29,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:29,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:29,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:30,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:30,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:30,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:31,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:31,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:31,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:31,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:32,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:32,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:32,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:32,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:33,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:33,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:33,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:34,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:34,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:34,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:34,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:35,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:35,855][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.5213, device='cuda:0') eval_epoch_loss=tensor(2.2535, device='cuda:0') eval_epoch_acc=tensor(0.5437, device='cuda:0')
[2024-11-13 08:17:35,856][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:17:35,857][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:17:36,183][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_10_step_411_loss_2.2535266876220703/model.pt
[2024-11-13 08:17:36,187][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:17:36,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:36,532][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.32618218660354614, acc: 0.8928571343421936)
[2024-11-13 08:17:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:36,825][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.4661395251750946, acc: 0.8999999761581421)
[2024-11-13 08:17:36,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:37,104][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.42743757367134094, acc: 0.8484848737716675)
[2024-11-13 08:17:37,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:37,458][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.21742844581604004, acc: 0.9090909361839294)
[2024-11-13 08:17:37,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:37,773][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.8099311590194702, acc: 0.7647058963775635)
[2024-11-13 08:17:37,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:38,071][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.4813954532146454, acc: 0.7692307829856873)
[2024-11-13 08:17:38,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:38,380][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.7000420689582825, acc: 0.7777777910232544)
[2024-11-13 08:17:38,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:38,682][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.440155565738678, acc: 0.8500000238418579)
[2024-11-13 08:17:38,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:38,966][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.4087677597999573, acc: 0.8500000238418579)
[2024-11-13 08:17:39,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:39,237][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.06980186700820923, acc: 1.0)
[2024-11-13 08:17:39,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:39,500][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.3590518832206726, acc: 0.8666666746139526)
[2024-11-13 08:17:39,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:39,825][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.40204519033432007, acc: 0.875)
[2024-11-13 08:17:39,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:40,134][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.460835337638855, acc: 0.8333333134651184)
[2024-11-13 08:17:40,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:40,410][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.18262450397014618, acc: 0.9629629850387573)
[2024-11-13 08:17:40,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:40,685][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.5664030909538269, acc: 0.8181818127632141)
[2024-11-13 08:17:40,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:40,952][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.6828535199165344, acc: 0.8260869383811951)
[2024-11-13 08:17:41,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:41,244][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.3073231279850006, acc: 0.837837815284729)
[2024-11-13 08:17:41,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:41,585][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.2644226849079132, acc: 0.8888888955116272)
[2024-11-13 08:17:41,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:41,888][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.11603609472513199, acc: 0.95652174949646)
[2024-11-13 08:17:41,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:42,152][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.07780814915895462, acc: 1.0)
[2024-11-13 08:17:42,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:42,445][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.06179966777563095, acc: 1.0)
[2024-11-13 08:17:42,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:42,731][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.23115485906600952, acc: 0.9130434989929199)
[2024-11-13 08:17:42,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:43,085][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.26462188363075256, acc: 0.9166666865348816)
[2024-11-13 08:17:43,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:43,388][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.13285399973392487, acc: 0.9200000166893005)
[2024-11-13 08:17:43,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:43,680][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.3931899070739746, acc: 0.8787878751754761)
[2024-11-13 08:17:43,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:43,991][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.42994245886802673, acc: 0.8611111044883728)
[2024-11-13 08:17:44,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:44,304][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.28641006350517273, acc: 0.9090909361839294)
[2024-11-13 08:17:44,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:44,600][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.09018818289041519, acc: 0.9523809552192688)
[2024-11-13 08:17:44,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:44,914][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.2654290199279785, acc: 0.8974359035491943)
[2024-11-13 08:17:45,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:45,285][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.7732700705528259, acc: 0.7424242496490479)
[2024-11-13 08:17:45,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:45,793][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 1.3452234268188477, acc: 0.6240000128746033)
[2024-11-13 08:17:45,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:46,132][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 1.1466422080993652, acc: 0.6048387289047241)
[2024-11-13 08:17:46,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:46,626][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 1.4413563013076782, acc: 0.606965184211731)
[2024-11-13 08:17:46,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:46,908][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.28571996092796326, acc: 0.9433962106704712)
[2024-11-13 08:17:46,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:47,267][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.3488982915878296, acc: 0.9090909361839294)
[2024-11-13 08:17:47,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:47,580][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.10052639245986938, acc: 1.0)
[2024-11-13 08:17:47,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:47,874][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.3091943860054016, acc: 0.9230769276618958)
[2024-11-13 08:17:47,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:48,171][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.3214862048625946, acc: 0.8571428656578064)
[2024-11-13 08:17:48,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:48,486][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.519585132598877, acc: 0.8656716346740723)
[2024-11-13 08:17:48,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:48,785][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.3641318380832672, acc: 0.9027777910232544)
[2024-11-13 08:17:48,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:49,070][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.585439920425415, acc: 0.79347825050354)
[2024-11-13 08:17:49,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:49,372][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.6321521401405334, acc: 0.807692289352417)
[2024-11-13 08:17:49,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:49,659][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.5797256231307983, acc: 0.7631579041481018)
[2024-11-13 08:17:49,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:49,958][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.5404006242752075, acc: 0.8367347121238708)
[2024-11-13 08:17:50,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:50,240][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.1131901890039444, acc: 0.939393937587738)
[2024-11-13 08:17:50,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:50,547][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 1.0724356174468994, acc: 0.6804123520851135)
[2024-11-13 08:17:50,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:50,849][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.5897344350814819, acc: 0.8571428656578064)
[2024-11-13 08:17:50,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:51,173][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 1.1834864616394043, acc: 0.6627907156944275)
[2024-11-13 08:17:51,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:51,503][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.4631653130054474, acc: 0.8392857313156128)
[2024-11-13 08:17:51,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:51,814][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.9145504236221313, acc: 0.7407407164573669)
[2024-11-13 08:17:51,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:52,115][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.2916233539581299, acc: 0.9166666865348816)
[2024-11-13 08:17:52,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:52,411][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.17644348740577698, acc: 0.9375)
[2024-11-13 08:17:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:52,708][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.11824250221252441, acc: 0.9615384340286255)
[2024-11-13 08:17:52,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:53,015][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.2480330616235733, acc: 0.9347826242446899)
[2024-11-13 08:17:53,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:53,305][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.718362033367157, acc: 0.75)
[2024-11-13 08:17:53,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:53,638][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.7913663983345032, acc: 0.759036123752594)
[2024-11-13 08:17:53,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:53,956][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.835384726524353, acc: 0.7297297120094299)
[2024-11-13 08:17:54,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:54,244][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.872684895992279, acc: 0.7669903039932251)
[2024-11-13 08:17:54,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:54,551][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.8455118536949158, acc: 0.7886179089546204)
[2024-11-13 08:17:54,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:54,858][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.3109784424304962, acc: 0.875)
[2024-11-13 08:17:54,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:55,161][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.6024516224861145, acc: 0.7857142686843872)
[2024-11-13 08:17:55,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:55,528][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 1.077081561088562, acc: 0.6470588445663452)
[2024-11-13 08:17:55,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:55,866][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 1.6776539087295532, acc: 0.4890829622745514)
[2024-11-13 08:17:55,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:56,168][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.9842705726623535, acc: 0.71875)
[2024-11-13 08:17:56,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:56,468][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 1.2554432153701782, acc: 0.6380367875099182)
[2024-11-13 08:17:56,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:56,779][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 1.1559923887252808, acc: 0.6906474828720093)
[2024-11-13 08:17:56,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:57,090][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 1.411920189857483, acc: 0.5678392052650452)
[2024-11-13 08:17:57,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:57,370][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.3460468351840973, acc: 0.9166666865348816)
[2024-11-13 08:17:57,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:57,706][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.6766157746315002, acc: 0.8181818127632141)
[2024-11-13 08:17:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:58,012][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.28979164361953735, acc: 0.9259259104728699)
[2024-11-13 08:17:58,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:58,314][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.1842847317457199, acc: 0.949999988079071)
[2024-11-13 08:17:58,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:58,623][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.5554711222648621, acc: 0.8500000238418579)
[2024-11-13 08:17:58,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:58,954][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.6499868631362915, acc: 0.7931034564971924)
[2024-11-13 08:17:59,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:59,249][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.189581036567688, acc: 1.0)
[2024-11-13 08:17:59,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:59,500][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.1650378406047821, acc: 0.9473684430122375)
[2024-11-13 08:17:59,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:17:59,766][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.4604445993900299, acc: 0.8888888955116272)
[2024-11-13 08:17:59,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:00,063][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.14312328398227692, acc: 0.9523809552192688)
[2024-11-13 08:18:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:00,379][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.23140345513820648, acc: 0.9090909361839294)
[2024-11-13 08:18:00,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:00,693][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.7530423998832703, acc: 0.7692307829856873)
[2024-11-13 08:18:00,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:00,969][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.4149952530860901, acc: 0.8999999761581421)
[2024-11-13 08:18:01,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:01,269][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.2846606373786926, acc: 0.931034505367279)
[2024-11-13 08:18:01,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:01,565][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.6812508702278137, acc: 0.8235294222831726)
[2024-11-13 08:18:01,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:01,850][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.2636498808860779, acc: 0.8965517282485962)
[2024-11-13 08:18:01,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:02,164][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.1768563985824585, acc: 0.8947368264198303)
[2024-11-13 08:18:02,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:02,476][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.34468820691108704, acc: 0.8421052694320679)
[2024-11-13 08:18:02,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:02,791][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.940610408782959, acc: 0.6517857313156128)
[2024-11-13 08:18:02,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:03,121][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.6433936357498169, acc: 0.8202247023582458)
[2024-11-13 08:18:03,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:03,446][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.9132976531982422, acc: 0.7191011309623718)
[2024-11-13 08:18:03,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:03,752][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 1.284967064857483, acc: 0.6241135001182556)
[2024-11-13 08:18:03,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:04,050][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 1.0248535871505737, acc: 0.6086956262588501)
[2024-11-13 08:18:04,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:04,324][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.2717539668083191, acc: 0.9599999785423279)
[2024-11-13 08:18:04,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:04,612][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.33310186862945557, acc: 0.8461538553237915)
[2024-11-13 08:18:04,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:04,885][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.14694076776504517, acc: 0.9629629850387573)
[2024-11-13 08:18:04,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:05,173][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.45865821838378906, acc: 0.8518518805503845)
[2024-11-13 08:18:05,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:05,458][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.3570631146430969, acc: 0.9245283007621765)
[2024-11-13 08:18:05,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:05,748][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.10320574790239334, acc: 0.9655172228813171)
[2024-11-13 08:18:05,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:06,194][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 1.1154321432113647, acc: 0.6936936974525452)
[2024-11-13 08:18:06,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:06,575][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.9820022583007812, acc: 0.7605633735656738)
[2024-11-13 08:18:06,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:06,893][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.3303220868110657, acc: 0.949999988079071)
[2024-11-13 08:18:06,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:07,204][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.29015448689460754, acc: 0.8666666746139526)
[2024-11-13 08:18:07,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:07,508][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.24652031064033508, acc: 0.9230769276618958)
[2024-11-13 08:18:07,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:08,706][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 1.2093576192855835, acc: 0.6214285492897034)
[2024-11-13 08:18:08,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:09,260][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 1.0961596965789795, acc: 0.682539701461792)
[2024-11-13 08:18:09,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:09,537][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.22178955376148224, acc: 0.9642857313156128)
[2024-11-13 08:18:09,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:09,857][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.5457512736320496, acc: 0.800000011920929)
[2024-11-13 08:18:10,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:10,394][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.6104816794395447, acc: 0.7916666865348816)
[2024-11-13 08:18:10,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:10,685][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.1799561232328415, acc: 0.9230769276618958)
[2024-11-13 08:18:10,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:11,014][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.6249127984046936, acc: 0.8709677457809448)
[2024-11-13 08:18:11,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:11,320][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.4616371989250183, acc: 0.800000011920929)
[2024-11-13 08:18:11,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:11,569][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.5390239357948303, acc: 0.8518518805503845)
[2024-11-13 08:18:11,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:12,257][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 1.6679307222366333, acc: 0.5508474707603455)
[2024-11-13 08:18:12,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:12,557][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 1.3030576705932617, acc: 0.5970149040222168)
[2024-11-13 08:18:12,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:12,937][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 1.1734060049057007, acc: 0.6204379796981812)
[2024-11-13 08:18:13,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:13,377][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 1.6191308498382568, acc: 0.6000000238418579)
[2024-11-13 08:18:13,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:13,663][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.6820152401924133, acc: 0.7777777910232544)
[2024-11-13 08:18:13,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:13,946][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.644778311252594, acc: 0.807692289352417)
[2024-11-13 08:18:14,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:14,231][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.4390552043914795, acc: 0.8095238208770752)
[2024-11-13 08:18:14,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:14,530][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.7974614500999451, acc: 0.7377049326896667)
[2024-11-13 08:18:14,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:14,831][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.5860841274261475, acc: 0.8305084705352783)
[2024-11-13 08:18:14,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:15,137][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.9425041079521179, acc: 0.7674418687820435)
[2024-11-13 08:18:15,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:15,446][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.5863295197486877, acc: 0.8409090638160706)
[2024-11-13 08:18:15,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:15,759][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.7524846196174622, acc: 0.7924528121948242)
[2024-11-13 08:18:15,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:16,055][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.49538689851760864, acc: 0.8863636255264282)
[2024-11-13 08:18:16,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:16,356][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.6407653093338013, acc: 0.8399999737739563)
[2024-11-13 08:18:16,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:16,643][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.40234270691871643, acc: 0.8999999761581421)
[2024-11-13 08:18:16,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:16,927][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.10468757152557373, acc: 1.0)
[2024-11-13 08:18:17,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:17,266][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.9679693579673767, acc: 0.692307710647583)
[2024-11-13 08:18:17,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:17,550][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.7919261455535889, acc: 0.796875)
[2024-11-13 08:18:17,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:17,888][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.28489986062049866, acc: 0.9375)
[2024-11-13 08:18:17,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:18,163][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.43833795189857483, acc: 0.8484848737716675)
[2024-11-13 08:18:18,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:18,447][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.22388118505477905, acc: 0.9375)
[2024-11-13 08:18:18,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:18,737][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.26627635955810547, acc: 0.8709677457809448)
[2024-11-13 08:18:18,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:19,056][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.08354401588439941, acc: 0.95652174949646)
[2024-11-13 08:18:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:19,404][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.468659371137619, acc: 0.800000011920929)
[2024-11-13 08:18:19,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:19,749][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.4274274408817291, acc: 0.8536585569381714)
[2024-11-13 08:18:19,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:20,088][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.16089563071727753, acc: 0.9428571462631226)
[2024-11-13 08:18:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:20,384][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.2977053225040436, acc: 0.8684210777282715)
[2024-11-13 08:18:20,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:20,692][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.26753008365631104, acc: 0.9032257795333862)
[2024-11-13 08:18:20,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:21,015][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.17881391942501068, acc: 0.9200000166893005)
[2024-11-13 08:18:21,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:21,334][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.15177848935127258, acc: 0.939393937587738)
[2024-11-13 08:18:21,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:21,661][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.3595578968524933, acc: 0.875)
[2024-11-13 08:18:21,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:22,016][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.35319599509239197, acc: 0.8571428656578064)
[2024-11-13 08:18:22,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:22,346][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 1.2146631479263306, acc: 0.6204379796981812)
[2024-11-13 08:18:22,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:23,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:23,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:23,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:24,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:24,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:24,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:24,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:25,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:25,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:25,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:25,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:26,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:26,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:27,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:27,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:27,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:27,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:28,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:28,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:28,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:29,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:29,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:29,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:29,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:30,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:30,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:30,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:30,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:31,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:31,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:31,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:31,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:32,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:32,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:32,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:33,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:33,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:33,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:33,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:34,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:34,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:34,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:34,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:35,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:35,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:35,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:35,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:36,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:36,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:36,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:37,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:37,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:37,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:37,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:38,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:38,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:38,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:38,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:39,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:39,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:39,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:40,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:40,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:40,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:40,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:41,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:41,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:41,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:42,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:42,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:42,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:42,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:43,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:43,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:43,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:43,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:44,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:44,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:44,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:44,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:45,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:45,812][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.8289, device='cuda:0') eval_epoch_loss=tensor(2.1780, device='cuda:0') eval_epoch_acc=tensor(0.5678, device='cuda:0')
[2024-11-13 08:18:45,813][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:18:45,814][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:18:46,214][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft/asr_epoch_10_step_554_loss_2.1780314445495605/model.pt
[2024-11-13 08:18:46,226][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_w2v2_llama32_1b_linear_peft directory
[2024-11-13 08:18:46,227][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 10 is 0.5678411722183228
[2024-11-13 08:18:46,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:46,637][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 1.0065631866455078, acc: 0.6965517401695251)
[2024-11-13 08:18:46,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:46,984][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 1.4963513612747192, acc: 0.5714285969734192)
[2024-11-13 08:18:47,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:47,303][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 1.19434654712677, acc: 0.6026490330696106)
[2024-11-13 08:18:47,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:47,656][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.9546229839324951, acc: 0.6581196784973145)
[2024-11-13 08:18:47,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:48,001][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.08874648809432983, acc: 1.0)
[2024-11-13 08:18:48,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:48,313][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.23820196092128754, acc: 0.9230769276618958)
[2024-11-13 08:18:48,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:48,636][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.13108707964420319, acc: 0.9615384340286255)
[2024-11-13 08:18:48,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:48,980][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.29785439372062683, acc: 0.8717948794364929)
[2024-11-13 08:18:49,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:49,333][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.5996519923210144, acc: 0.8333333134651184)
[2024-11-13 08:18:49,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:49,636][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.46203696727752686, acc: 0.8441558480262756)
[2024-11-13 08:18:49,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:49,879][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.46309101581573486, acc: 0.8333333134651184)
[2024-11-13 08:18:49,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:50,162][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.4231533110141754, acc: 0.8448275923728943)
[2024-11-13 08:18:50,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:50,402][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.7090832591056824, acc: 0.738095223903656)
[2024-11-13 08:18:50,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:50,642][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.4262210428714752, acc: 0.8684210777282715)
[2024-11-13 08:18:50,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:50,966][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.10419368743896484, acc: 0.9629629850387573)
[2024-11-13 08:18:51,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:51,315][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 1.2577531337738037, acc: 0.6417112350463867)
[2024-11-13 08:18:51,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:51,643][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.6618848443031311, acc: 0.725806474685669)
[2024-11-13 08:18:51,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:52,017][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.7665483355522156, acc: 0.8034188151359558)
[2024-11-13 08:18:52,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:52,327][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 1.309495449066162, acc: 0.6020408272743225)
[2024-11-13 08:18:52,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:18:52,656][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 1.186572551727295, acc: 0.6415094137191772)
[2024-11-13 08:18:53,097][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.8749, train_epoch_loss=0.6286, epoch time 291.49612000770867s
[2024-11-13 08:18:53,097][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 08:18:53,097][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-11-13 08:18:53,097][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 08:18:53,097][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 08:18:53,098][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 4 GB
[2024-11-13 08:18:53,102][root][INFO] - Key: avg_train_prep, Value: 5.049324989318848
[2024-11-13 08:18:53,103][root][INFO] - Key: avg_train_loss, Value: 1.349377989768982
[2024-11-13 08:18:53,103][root][INFO] - Key: avg_train_acc, Value: 0.6384252905845642
[2024-11-13 08:18:53,103][root][INFO] - Key: avg_eval_prep, Value: 8.270528793334961
[2024-11-13 08:18:53,104][root][INFO] - Key: avg_eval_loss, Value: 2.0807461738586426
[2024-11-13 08:18:53,104][root][INFO] - Key: avg_eval_acc, Value: 0.5097729563713074
[2024-11-13 08:18:53,104][root][INFO] - Key: avg_epoch_time, Value: 295.0191398726776
[2024-11-13 08:18:53,104][root][INFO] - Key: avg_checkpoint_time, Value: 0.3580201810225844
