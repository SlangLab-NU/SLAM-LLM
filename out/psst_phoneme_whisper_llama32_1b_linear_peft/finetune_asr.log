[2024-11-13 08:31:44,856][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-13 08:31:44,856][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-13 08:31:44,857][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-13 08:31:44,857][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_whisper_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-13_08-31-44.txt', 'log_interval': 5}
[2024-11-13 08:33:38,743][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-13 08:33:38,747][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2024-11-13 08:33:38,750][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-13 08:33:38,751][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2024-11-13 08:33:48,750][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 08:33:48,751][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-13 08:33:48,752][slam_llm.models.slam_model][INFO] - setup peft...
[2024-11-13 08:33:48,881][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 08:33:48,883][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-11-13 08:33:49,021][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-13 08:33:49,022][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2024-11-13 08:33:49,022][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-13 08:33:49,026][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2024-11-13 08:33:51,272][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2024-11-13 08:33:53,295][root][INFO] - --> Training Set Length = 2298
[2024-11-13 08:33:53,299][root][INFO] - --> Validation Set Length = 341
[2024-11-13 08:33:53,300][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 08:33:53,300][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 08:33:56,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:33:58,975][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-13 08:34:02,221][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 12.394572257995605, acc: 0.0)
[2024-11-13 08:34:02,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:02,897][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 11.706838607788086, acc: 0.0)
[2024-11-13 08:34:03,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:03,568][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 10.572463989257812, acc: 0.0)
[2024-11-13 08:34:03,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:04,243][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 11.022500991821289, acc: 0.0)
[2024-11-13 08:34:04,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:05,084][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 10.60308837890625, acc: 0.027027027681469917)
[2024-11-13 08:34:05,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:05,764][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 11.859227180480957, acc: 0.0)
[2024-11-13 08:34:05,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:06,459][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 10.498894691467285, acc: 0.0)
[2024-11-13 08:34:06,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:07,151][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 10.93868350982666, acc: 0.0)
[2024-11-13 08:34:07,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:07,820][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 11.790008544921875, acc: 0.0)
[2024-11-13 08:34:07,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:08,514][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 10.029322624206543, acc: 0.0)
[2024-11-13 08:34:08,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:09,213][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 10.476609230041504, acc: 0.0)
[2024-11-13 08:34:09,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:09,899][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 8.910332679748535, acc: 0.0)
[2024-11-13 08:34:09,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:10,595][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 9.918071746826172, acc: 0.0)
[2024-11-13 08:34:10,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:11,288][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 8.599881172180176, acc: 0.0)
[2024-11-13 08:34:11,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:11,976][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 8.4296293258667, acc: 0.019607843831181526)
[2024-11-13 08:34:12,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:12,667][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 7.770975112915039, acc: 0.020408162847161293)
[2024-11-13 08:34:12,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:13,354][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.615270614624023, acc: 0.0)
[2024-11-13 08:34:13,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:14,041][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.270832061767578, acc: 0.0)
[2024-11-13 08:34:14,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:14,728][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.684284210205078, acc: 0.02777777798473835)
[2024-11-13 08:34:14,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:15,410][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 7.7030534744262695, acc: 0.05263157933950424)
[2024-11-13 08:34:15,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:16,097][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 7.8768839836120605, acc: 0.0)
[2024-11-13 08:34:16,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:16,778][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 6.821001052856445, acc: 0.0)
[2024-11-13 08:34:16,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:17,464][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.698126792907715, acc: 0.03999999910593033)
[2024-11-13 08:34:17,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:18,144][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 7.981227397918701, acc: 0.0)
[2024-11-13 08:34:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:18,824][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 7.737274646759033, acc: 0.0)
[2024-11-13 08:34:18,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:19,545][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 6.57164192199707, acc: 0.0)
[2024-11-13 08:34:19,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:20,234][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 6.072365760803223, acc: 0.027397260069847107)
[2024-11-13 08:34:20,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:21,042][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 4.6239914894104, acc: 0.1660079061985016)
[2024-11-13 08:34:21,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:21,742][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.240330219268799, acc: 0.0)
[2024-11-13 08:34:21,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:22,438][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.559394359588623, acc: 0.08433734625577927)
[2024-11-13 08:34:22,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:23,148][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.168545246124268, acc: 0.06172839552164078)
[2024-11-13 08:34:23,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:23,846][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 6.547085285186768, acc: 0.0)
[2024-11-13 08:34:23,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:24,562][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 6.423638343811035, acc: 0.0)
[2024-11-13 08:34:24,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:25,252][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 7.40676736831665, acc: 0.0)
[2024-11-13 08:34:25,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:25,951][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 4.936147689819336, acc: 0.09243697673082352)
[2024-11-13 08:34:26,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:26,638][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.471550464630127, acc: 0.08196721225976944)
[2024-11-13 08:34:26,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:27,334][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 4.854384422302246, acc: 0.1111111119389534)
[2024-11-13 08:34:27,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:28,016][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 5.923442363739014, acc: 0.016949152573943138)
[2024-11-13 08:34:28,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:28,707][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 4.854127883911133, acc: 0.13793103396892548)
[2024-11-13 08:34:28,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:29,394][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 5.9270429611206055, acc: 0.0)
[2024-11-13 08:34:29,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:30,079][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 5.755702018737793, acc: 0.07692307978868484)
[2024-11-13 08:34:30,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:30,778][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 4.849081993103027, acc: 0.1621621549129486)
[2024-11-13 08:34:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:31,468][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.148584842681885, acc: 0.0923076942563057)
[2024-11-13 08:34:31,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:32,162][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 4.824063301086426, acc: 0.1111111119389534)
[2024-11-13 08:34:32,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:32,873][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.744139671325684, acc: 0.19587628543376923)
[2024-11-13 08:34:32,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:33,575][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 5.168036460876465, acc: 0.11029411852359772)
[2024-11-13 08:34:33,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:34,258][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 6.093310832977295, acc: 0.0)
[2024-11-13 08:34:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:34,945][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 5.317307472229004, acc: 0.0)
[2024-11-13 08:34:35,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:35,630][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 5.5573344230651855, acc: 0.0357142873108387)
[2024-11-13 08:34:35,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:36,316][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 4.9489359855651855, acc: 0.1111111119389534)
[2024-11-13 08:34:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:37,012][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.10790491104126, acc: 0.15789473056793213)
[2024-11-13 08:34:37,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:37,706][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 4.913177013397217, acc: 0.1111111119389534)
[2024-11-13 08:34:37,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:38,408][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.465190887451172, acc: 0.0845070406794548)
[2024-11-13 08:34:38,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:39,161][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.840435981750488, acc: 0.18666666746139526)
[2024-11-13 08:34:39,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:39,861][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 5.405772686004639, acc: 0.054054055362939835)
[2024-11-13 08:34:39,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:40,544][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 5.1480712890625, acc: 0.11538461595773697)
[2024-11-13 08:34:40,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:41,398][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.360668182373047, acc: 0.3890784978866577)
[2024-11-13 08:34:41,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:42,181][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 4.050142765045166, acc: 0.24618735909461975)
[2024-11-13 08:34:42,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:42,902][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 4.517250061035156, acc: 0.15909090638160706)
[2024-11-13 08:34:42,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:43,599][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.152794361114502, acc: 0.20588235557079315)
[2024-11-13 08:34:43,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:44,336][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 4.130310535430908, acc: 0.18115942180156708)
[2024-11-13 08:34:44,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:45,056][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.2781171798706055, acc: 0.20000000298023224)
[2024-11-13 08:34:45,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:45,741][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 4.534732818603516, acc: 0.029411764815449715)
[2024-11-13 08:34:45,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:46,428][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 4.943709373474121, acc: 0.02777777798473835)
[2024-11-13 08:34:46,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:47,133][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 3.801398754119873, acc: 0.203125)
[2024-11-13 08:34:47,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:47,817][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 3.760018825531006, acc: 0.2068965584039688)
[2024-11-13 08:34:47,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:48,516][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 4.683164119720459, acc: 0.125)
[2024-11-13 08:34:48,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:49,206][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 4.439032554626465, acc: 0.06666667014360428)
[2024-11-13 08:34:49,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:49,888][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 4.31978178024292, acc: 0.11999999731779099)
[2024-11-13 08:34:49,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:50,582][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 4.555300712585449, acc: 0.0555555559694767)
[2024-11-13 08:34:50,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:51,272][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 5.3406982421875, acc: 0.09090909361839294)
[2024-11-13 08:34:51,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:52,001][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 4.334432601928711, acc: 0.20588235557079315)
[2024-11-13 08:34:52,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:52,757][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 3.7306265830993652, acc: 0.1825396865606308)
[2024-11-13 08:34:52,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:53,491][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.127286911010742, acc: 0.25128206610679626)
[2024-11-13 08:34:53,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:54,182][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 4.869626998901367, acc: 0.09183673560619354)
[2024-11-13 08:34:54,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:54,891][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.189821243286133, acc: 0.1492537260055542)
[2024-11-13 08:34:54,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:55,636][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 3.935800790786743, acc: 0.23722627758979797)
[2024-11-13 08:34:55,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:56,317][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 4.813138484954834, acc: 0.0476190485060215)
[2024-11-13 08:34:56,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:57,001][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 4.618185997009277, acc: 0.0833333358168602)
[2024-11-13 08:34:57,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:57,682][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 4.254122257232666, acc: 0.12121212482452393)
[2024-11-13 08:34:57,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:58,365][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 4.017731666564941, acc: 0.1538461595773697)
[2024-11-13 08:34:58,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:59,054][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 4.590313911437988, acc: 0.07692307978868484)
[2024-11-13 08:34:59,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:34:59,741][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 4.478152275085449, acc: 0.1538461595773697)
[2024-11-13 08:34:59,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:00,436][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 3.645829439163208, acc: 0.15625)
[2024-11-13 08:35:00,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:01,127][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 4.271387100219727, acc: 0.1304347813129425)
[2024-11-13 08:35:01,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:01,822][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 3.8701653480529785, acc: 0.23999999463558197)
[2024-11-13 08:35:01,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:02,509][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 4.526214122772217, acc: 0.08695652335882187)
[2024-11-13 08:35:02,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:03,211][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 4.234397888183594, acc: 0.20000000298023224)
[2024-11-13 08:35:03,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:03,918][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 3.778198719024658, acc: 0.27184465527534485)
[2024-11-13 08:35:04,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:04,654][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 3.778002977371216, acc: 0.3252427279949188)
[2024-11-13 08:35:04,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:05,380][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 4.003814220428467, acc: 0.23118279874324799)
[2024-11-13 08:35:05,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:06,115][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.5219757556915283, acc: 0.3405172526836395)
[2024-11-13 08:35:06,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:06,811][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 3.8573532104492188, acc: 0.2526315748691559)
[2024-11-13 08:35:06,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:07,531][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 4.067664623260498, acc: 0.20792078971862793)
[2024-11-13 08:35:07,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:08,220][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 3.844564437866211, acc: 0.24193547666072845)
[2024-11-13 08:35:08,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:08,928][root][INFO] - Training Epoch: 1/10, step 95/574 completed (loss: 3.7484090328216553, acc: 0.23188406229019165)
[2024-11-13 08:35:09,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:09,630][root][INFO] - Training Epoch: 1/10, step 96/574 completed (loss: 4.148977279663086, acc: 0.1260504275560379)
[2024-11-13 08:35:09,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:10,329][root][INFO] - Training Epoch: 1/10, step 97/574 completed (loss: 3.642894983291626, acc: 0.19230769574642181)
[2024-11-13 08:35:10,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:11,040][root][INFO] - Training Epoch: 1/10, step 98/574 completed (loss: 3.7493839263916016, acc: 0.24087591469287872)
[2024-11-13 08:35:11,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:11,730][root][INFO] - Training Epoch: 1/10, step 99/574 completed (loss: 4.365454196929932, acc: 0.11940298229455948)
[2024-11-13 08:35:11,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:12,423][root][INFO] - Training Epoch: 1/10, step 100/574 completed (loss: 4.100234508514404, acc: 0.15000000596046448)
[2024-11-13 08:35:12,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:13,104][root][INFO] - Training Epoch: 1/10, step 101/574 completed (loss: 3.1258010864257812, acc: 0.22727273404598236)
[2024-11-13 08:35:13,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:13,798][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 2.8397133350372314, acc: 0.21739129722118378)
[2024-11-13 08:35:13,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:14,484][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 3.3661890029907227, acc: 0.22727273404598236)
[2024-11-13 08:35:14,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:15,179][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 3.677802085876465, acc: 0.2068965584039688)
[2024-11-13 08:35:15,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:15,866][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 3.7599852085113525, acc: 0.11627907305955887)
[2024-11-13 08:35:15,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:16,546][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 3.2119245529174805, acc: 0.2800000011920929)
[2024-11-13 08:35:16,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:17,229][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 3.5072216987609863, acc: 0.23529411852359772)
[2024-11-13 08:35:17,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:17,910][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 3.4888343811035156, acc: 0.19230769574642181)
[2024-11-13 08:35:17,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:18,597][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 3.7335026264190674, acc: 0.1666666716337204)
[2024-11-13 08:35:18,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:19,310][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 4.02474308013916, acc: 0.2153846174478531)
[2024-11-13 08:35:19,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:20,001][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 3.7697811126708984, acc: 0.21052631735801697)
[2024-11-13 08:35:20,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:20,688][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 3.8230743408203125, acc: 0.22807016968727112)
[2024-11-13 08:35:20,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:21,371][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 3.5252246856689453, acc: 0.1794871836900711)
[2024-11-13 08:35:21,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:22,061][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 3.158634662628174, acc: 0.30612245202064514)
[2024-11-13 08:35:22,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:22,752][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 3.7332205772399902, acc: 0.22727273404598236)
[2024-11-13 08:35:22,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:23,490][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.107461929321289, acc: 0.2698412835597992)
[2024-11-13 08:35:23,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:24,194][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.115715503692627, acc: 0.31707316637039185)
[2024-11-13 08:35:24,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:24,896][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 3.451754570007324, acc: 0.24193547666072845)
[2024-11-13 08:35:24,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:25,674][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.1492724418640137, acc: 0.31178706884384155)
[2024-11-13 08:35:25,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:26,376][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 3.0616543292999268, acc: 0.30666667222976685)
[2024-11-13 08:35:26,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:27,071][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 3.413092613220215, acc: 0.2884615361690521)
[2024-11-13 08:35:27,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:27,756][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 3.6242244243621826, acc: 0.0833333358168602)
[2024-11-13 08:35:27,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:28,441][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 2.831709384918213, acc: 0.31578946113586426)
[2024-11-13 08:35:28,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:29,143][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.645742893218994, acc: 0.2269938588142395)
[2024-11-13 08:35:29,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:29,863][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 2.913271903991699, acc: 0.3333333432674408)
[2024-11-13 08:35:29,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:30,575][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.240321397781372, acc: 0.25)
[2024-11-13 08:35:30,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:31,320][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.239217519760132, acc: 0.2023809552192688)
[2024-11-13 08:35:31,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:32,040][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.280460834503174, acc: 0.22564102709293365)
[2024-11-13 08:35:32,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:32,777][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 2.6233673095703125, acc: 0.44117647409439087)
[2024-11-13 08:35:32,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:33,461][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.508420467376709, acc: 0.11538461595773697)
[2024-11-13 08:35:33,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:34,151][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 2.854030132293701, acc: 0.3478260934352875)
[2024-11-13 08:35:34,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:34,835][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.7056596279144287, acc: 0.15625)
[2024-11-13 08:35:34,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:35,525][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 2.8380813598632812, acc: 0.17391304671764374)
[2024-11-13 08:35:35,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:36,207][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 2.8866729736328125, acc: 0.22857142984867096)
[2024-11-13 08:35:36,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:36,904][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 2.7177042961120605, acc: 0.3076923191547394)
[2024-11-13 08:35:36,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:37,601][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.071988105773926, acc: 0.2857142984867096)
[2024-11-13 08:35:37,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:38,283][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 2.5571014881134033, acc: 0.36666667461395264)
[2024-11-13 08:35:38,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:38,963][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 2.464247941970825, acc: 0.3913043439388275)
[2024-11-13 08:35:39,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:39,646][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 3.895541191101074, acc: 0.2380952388048172)
[2024-11-13 08:35:39,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:40,337][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 3.2008450031280518, acc: 0.3076923191547394)
[2024-11-13 08:35:40,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:41,033][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 3.3036816120147705, acc: 0.29032257199287415)
[2024-11-13 08:35:41,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:41,720][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.514998197555542, acc: 0.10810811072587967)
[2024-11-13 08:35:43,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:43,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:44,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:44,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:45,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:45,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:46,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:47,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:47,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:48,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:48,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:49,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:49,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:50,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:51,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:51,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:52,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:52,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:53,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:54,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:54,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:55,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:55,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:56,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:57,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:57,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:58,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:58,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:59,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:35:59,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:00,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:00,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:01,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:01,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:02,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:03,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:03,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:04,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:04,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:05,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:06,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:06,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:07,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:07,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:08,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:08,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:09,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:10,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:10,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:11,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:11,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:12,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:13,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:13,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:14,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:14,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:15,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:16,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:16,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:17,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:17,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:18,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:19,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:20,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:21,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:22,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:23,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:23,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:24,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:24,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:25,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:26,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:26,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:27,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:28,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:29,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:30,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:30,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:31,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:31,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:33,198][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(20.7914, device='cuda:0') eval_epoch_loss=tensor(3.0345, device='cuda:0') eval_epoch_acc=tensor(0.2554, device='cuda:0')
[2024-11-13 08:36:33,200][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:36:33,200][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:36:33,653][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_1_step_143_loss_3.0345370769500732/model.pt
[2024-11-13 08:36:33,658][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:36:33,659][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.0345370769500732
[2024-11-13 08:36:33,659][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.25540658831596375
[2024-11-13 08:36:33,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:34,399][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 2.602451801300049, acc: 0.3245614171028137)
[2024-11-13 08:36:34,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:35,090][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 2.5922389030456543, acc: 0.3208955228328705)
[2024-11-13 08:36:35,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:35,782][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 2.9781932830810547, acc: 0.23469388484954834)
[2024-11-13 08:36:35,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:36,484][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 2.927395820617676, acc: 0.3085106313228607)
[2024-11-13 08:36:36,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:37,180][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 2.728290319442749, acc: 0.37142857909202576)
[2024-11-13 08:36:37,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:37,857][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 3.4783897399902344, acc: 0.2142857164144516)
[2024-11-13 08:36:37,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:38,537][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 2.8469796180725098, acc: 0.30434781312942505)
[2024-11-13 08:36:38,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:39,211][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 3.206637144088745, acc: 0.2068965584039688)
[2024-11-13 08:36:39,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:39,886][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 2.771458625793457, acc: 0.3478260934352875)
[2024-11-13 08:36:39,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:40,572][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 2.4149391651153564, acc: 0.32203391194343567)
[2024-11-13 08:36:40,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:41,254][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 3.195275068283081, acc: 0.22807016968727112)
[2024-11-13 08:36:41,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:41,937][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 2.937206268310547, acc: 0.3243243098258972)
[2024-11-13 08:36:42,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:42,608][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 2.5500986576080322, acc: 0.4285714328289032)
[2024-11-13 08:36:42,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:43,324][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.2694079875946045, acc: 0.47826087474823)
[2024-11-13 08:36:43,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:43,997][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 3.0439982414245605, acc: 0.2631579041481018)
[2024-11-13 08:36:44,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:44,677][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 3.1577887535095215, acc: 0.3918918967247009)
[2024-11-13 08:36:44,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:45,366][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 2.881561279296875, acc: 0.3333333432674408)
[2024-11-13 08:36:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:46,052][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 2.7286322116851807, acc: 0.3604651093482971)
[2024-11-13 08:36:46,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:46,735][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 2.6258904933929443, acc: 0.38823530077934265)
[2024-11-13 08:36:46,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:47,419][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 3.1712284088134766, acc: 0.30337077379226685)
[2024-11-13 08:36:47,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:48,097][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 2.41032075881958, acc: 0.3636363744735718)
[2024-11-13 08:36:48,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:48,767][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 2.6644575595855713, acc: 0.4285714328289032)
[2024-11-13 08:36:48,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:49,440][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 2.905315637588501, acc: 0.17241379618644714)
[2024-11-13 08:36:49,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:50,121][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 2.2052106857299805, acc: 0.4897959232330322)
[2024-11-13 08:36:50,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:50,795][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 2.7132625579833984, acc: 0.3199999928474426)
[2024-11-13 08:36:50,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:51,477][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 2.8436574935913086, acc: 0.3888888955116272)
[2024-11-13 08:36:51,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:52,165][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 2.740302085876465, acc: 0.3137255012989044)
[2024-11-13 08:36:52,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:52,887][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 3.3126583099365234, acc: 0.28082191944122314)
[2024-11-13 08:36:53,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:53,561][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 2.514765739440918, acc: 0.375)
[2024-11-13 08:36:53,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:54,240][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 3.3390181064605713, acc: 0.14814814925193787)
[2024-11-13 08:36:54,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:54,913][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 3.0639472007751465, acc: 0.2142857164144516)
[2024-11-13 08:36:54,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:55,629][root][INFO] - Training Epoch: 1/10, step 174/574 completed (loss: 2.831890821456909, acc: 0.3185840845108032)
[2024-11-13 08:36:55,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:56,309][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 3.1380419731140137, acc: 0.28985506296157837)
[2024-11-13 08:36:56,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:56,989][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 2.997455596923828, acc: 0.22727273404598236)
[2024-11-13 08:36:57,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:57,710][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 3.041076898574829, acc: 0.23664122819900513)
[2024-11-13 08:36:57,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:58,423][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 3.277989625930786, acc: 0.20000000298023224)
[2024-11-13 08:36:58,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:59,104][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 2.9057791233062744, acc: 0.3442623019218445)
[2024-11-13 08:36:59,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:36:59,778][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 2.5707151889801025, acc: 0.375)
[2024-11-13 08:36:59,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:00,449][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 2.7504754066467285, acc: 0.2800000011920929)
[2024-11-13 08:37:00,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:01,120][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 3.110327959060669, acc: 0.2142857164144516)
[2024-11-13 08:37:01,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:01,803][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 3.2095277309417725, acc: 0.2073170691728592)
[2024-11-13 08:37:01,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:02,554][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 3.155170202255249, acc: 0.2386706918478012)
[2024-11-13 08:37:02,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:03,282][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 3.064899444580078, acc: 0.26224783062934875)
[2024-11-13 08:37:03,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:04,004][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.1557278633117676, acc: 0.24062499403953552)
[2024-11-13 08:37:04,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:04,768][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 2.969015598297119, acc: 0.2476547807455063)
[2024-11-13 08:37:04,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:05,507][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 2.89914608001709, acc: 0.24199287593364716)
[2024-11-13 08:37:05,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:06,181][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 3.4493517875671387, acc: 0.11999999731779099)
[2024-11-13 08:37:06,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:06,877][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 2.825090169906616, acc: 0.3139534890651703)
[2024-11-13 08:37:06,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:07,578][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 2.7052624225616455, acc: 0.3492063581943512)
[2024-11-13 08:37:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:08,269][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 2.672276020050049, acc: 0.35606059432029724)
[2024-11-13 08:37:08,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:08,952][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 2.4242422580718994, acc: 0.43529412150382996)
[2024-11-13 08:37:09,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:09,662][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 2.4375829696655273, acc: 0.40740740299224854)
[2024-11-13 08:37:09,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:10,347][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 2.5363504886627197, acc: 0.4032258093357086)
[2024-11-13 08:37:10,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:11,020][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 2.4691734313964844, acc: 0.3928571343421936)
[2024-11-13 08:37:11,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:11,694][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 3.0331308841705322, acc: 0.2750000059604645)
[2024-11-13 08:37:11,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:12,372][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 3.287271499633789, acc: 0.22058823704719543)
[2024-11-13 08:37:12,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:13,057][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 2.9374241828918457, acc: 0.3382352888584137)
[2024-11-13 08:37:13,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:13,743][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 2.96435809135437, acc: 0.3050847351551056)
[2024-11-13 08:37:13,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:14,432][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 2.838456630706787, acc: 0.3507462739944458)
[2024-11-13 08:37:14,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:15,120][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 3.124457597732544, acc: 0.27184465527534485)
[2024-11-13 08:37:15,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:15,808][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 2.786637306213379, acc: 0.3968254029750824)
[2024-11-13 08:37:15,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:16,491][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 2.868114709854126, acc: 0.20879121124744415)
[2024-11-13 08:37:16,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:17,214][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 2.8366804122924805, acc: 0.27802690863609314)
[2024-11-13 08:37:17,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:17,940][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 2.790215015411377, acc: 0.27559053897857666)
[2024-11-13 08:37:18,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:18,652][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 2.76588773727417, acc: 0.2844827473163605)
[2024-11-13 08:37:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:19,362][root][INFO] - Training Epoch: 1/10, step 208/574 completed (loss: 2.6743698120117188, acc: 0.3115941882133484)
[2024-11-13 08:37:19,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:20,078][root][INFO] - Training Epoch: 1/10, step 209/574 completed (loss: 2.8607468605041504, acc: 0.24513618648052216)
[2024-11-13 08:37:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:20,790][root][INFO] - Training Epoch: 1/10, step 210/574 completed (loss: 3.0826659202575684, acc: 0.21739129722118378)
[2024-11-13 08:37:20,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:21,469][root][INFO] - Training Epoch: 1/10, step 211/574 completed (loss: 2.6450302600860596, acc: 0.260869562625885)
[2024-11-13 08:37:21,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:22,141][root][INFO] - Training Epoch: 1/10, step 212/574 completed (loss: 3.136070728302002, acc: 0.1071428582072258)
[2024-11-13 08:37:22,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:22,821][root][INFO] - Training Epoch: 1/10, step 213/574 completed (loss: 2.510122776031494, acc: 0.2978723347187042)
[2024-11-13 08:37:22,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:23,521][root][INFO] - Training Epoch: 1/10, step 214/574 completed (loss: 2.5497496128082275, acc: 0.3076923191547394)
[2024-11-13 08:37:23,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:24,211][root][INFO] - Training Epoch: 1/10, step 215/574 completed (loss: 2.4047067165374756, acc: 0.36486485600471497)
[2024-11-13 08:37:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:24,901][root][INFO] - Training Epoch: 1/10, step 216/574 completed (loss: 2.6308341026306152, acc: 0.39534884691238403)
[2024-11-13 08:37:24,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:25,593][root][INFO] - Training Epoch: 1/10, step 217/574 completed (loss: 2.4296655654907227, acc: 0.4144144058227539)
[2024-11-13 08:37:25,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:26,280][root][INFO] - Training Epoch: 1/10, step 218/574 completed (loss: 2.438950538635254, acc: 0.3777777850627899)
[2024-11-13 08:37:26,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:26,981][root][INFO] - Training Epoch: 1/10, step 219/574 completed (loss: 2.0410051345825195, acc: 0.4848484992980957)
[2024-11-13 08:37:27,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:27,657][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 2.1289031505584717, acc: 0.48148149251937866)
[2024-11-13 08:37:27,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:28,328][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 2.1752309799194336, acc: 0.3199999928474426)
[2024-11-13 08:37:28,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:29,023][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 2.704695701599121, acc: 0.2884615361690521)
[2024-11-13 08:37:29,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:29,732][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 2.430079698562622, acc: 0.3695652186870575)
[2024-11-13 08:37:29,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:30,436][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 2.616842269897461, acc: 0.33522728085517883)
[2024-11-13 08:37:30,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:31,142][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 2.809943675994873, acc: 0.26595744490623474)
[2024-11-13 08:37:31,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:31,816][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 2.6307265758514404, acc: 0.3207547068595886)
[2024-11-13 08:37:31,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:32,496][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 2.154939889907837, acc: 0.4333333373069763)
[2024-11-13 08:37:32,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:33,203][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 2.2770934104919434, acc: 0.5116279125213623)
[2024-11-13 08:37:33,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:33,876][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 2.6056971549987793, acc: 0.36666667461395264)
[2024-11-13 08:37:33,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:34,568][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 3.017441511154175, acc: 0.2526315748691559)
[2024-11-13 08:37:34,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:35,258][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 2.342024087905884, acc: 0.36666667461395264)
[2024-11-13 08:37:35,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:35,968][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 2.2348430156707764, acc: 0.4444444477558136)
[2024-11-13 08:37:36,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:36,683][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 2.254028797149658, acc: 0.43119266629219055)
[2024-11-13 08:37:36,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:37,390][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 2.245990037918091, acc: 0.4307692348957062)
[2024-11-13 08:37:37,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:38,063][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 2.106513500213623, acc: 0.4736842215061188)
[2024-11-13 08:37:38,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:38,733][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 2.070345640182495, acc: 0.3333333432674408)
[2024-11-13 08:37:38,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:39,403][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 2.55098819732666, acc: 0.27272728085517883)
[2024-11-13 08:37:39,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:40,086][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 1.8902016878128052, acc: 0.48148149251937866)
[2024-11-13 08:37:40,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:40,766][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.5384950637817383, acc: 0.22857142984867096)
[2024-11-13 08:37:40,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:41,441][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 2.146460771560669, acc: 0.4318181872367859)
[2024-11-13 08:37:41,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:42,128][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 2.3512637615203857, acc: 0.47727271914482117)
[2024-11-13 08:37:42,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:42,807][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 2.611532688140869, acc: 0.33870968222618103)
[2024-11-13 08:37:42,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:43,484][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 2.412931203842163, acc: 0.3863636255264282)
[2024-11-13 08:37:43,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:44,155][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 2.204590082168579, acc: 0.380952388048172)
[2024-11-13 08:37:44,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:44,834][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 2.561370849609375, acc: 0.3076923191547394)
[2024-11-13 08:37:44,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:45,515][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 2.9710757732391357, acc: 0.19354838132858276)
[2024-11-13 08:37:45,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:46,185][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.1219136714935303, acc: 0.30000001192092896)
[2024-11-13 08:37:46,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:46,864][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 2.3330178260803223, acc: 0.4324324429035187)
[2024-11-13 08:37:46,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:47,537][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 2.555476188659668, acc: 0.2432432472705841)
[2024-11-13 08:37:47,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:48,212][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 2.6952223777770996, acc: 0.4054054021835327)
[2024-11-13 08:37:48,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:48,895][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 2.871756076812744, acc: 0.27941176295280457)
[2024-11-13 08:37:48,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:49,574][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 1.6143171787261963, acc: 0.5365853905677795)
[2024-11-13 08:37:49,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:50,258][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 2.06562876701355, acc: 0.4000000059604645)
[2024-11-13 08:37:50,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:50,939][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 2.1883347034454346, acc: 0.2800000011920929)
[2024-11-13 08:37:51,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:51,626][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 2.9281229972839355, acc: 0.25806450843811035)
[2024-11-13 08:37:51,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:52,305][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 2.7121667861938477, acc: 0.24561403691768646)
[2024-11-13 08:37:52,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:52,980][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 2.6630654335021973, acc: 0.3142857253551483)
[2024-11-13 08:37:53,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:53,680][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 2.5626437664031982, acc: 0.3815789520740509)
[2024-11-13 08:37:53,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:54,385][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 2.5512402057647705, acc: 0.27358490228652954)
[2024-11-13 08:37:54,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:55,097][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 2.4393088817596436, acc: 0.375)
[2024-11-13 08:37:55,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:55,770][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 2.3121838569641113, acc: 0.3888888955116272)
[2024-11-13 08:37:55,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:56,446][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 2.5829017162323, acc: 0.4193548262119293)
[2024-11-13 08:37:56,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:57,130][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 2.9309024810791016, acc: 0.2800000011920929)
[2024-11-13 08:37:57,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:57,820][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 2.6698246002197266, acc: 0.2708333432674408)
[2024-11-13 08:37:57,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:58,538][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 2.746258020401001, acc: 0.29600000381469727)
[2024-11-13 08:37:58,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:59,220][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 2.6039998531341553, acc: 0.3483146131038666)
[2024-11-13 08:37:59,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:37:59,914][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 2.597508430480957, acc: 0.4189189076423645)
[2024-11-13 08:38:00,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:00,599][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 2.295966863632202, acc: 0.36206895112991333)
[2024-11-13 08:38:00,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:01,275][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 2.6553921699523926, acc: 0.3181818127632141)
[2024-11-13 08:38:01,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:01,957][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 1.925010323524475, acc: 0.40909090638160706)
[2024-11-13 08:38:02,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:02,632][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 1.9563919305801392, acc: 0.46875)
[2024-11-13 08:38:02,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:03,305][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 1.997193694114685, acc: 0.5333333611488342)
[2024-11-13 08:38:03,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:03,985][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 2.4914093017578125, acc: 0.4000000059604645)
[2024-11-13 08:38:04,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:04,658][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.1700754165649414, acc: 0.46875)
[2024-11-13 08:38:04,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:05,331][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 1.9541751146316528, acc: 0.5)
[2024-11-13 08:38:05,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:06,009][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 2.52496600151062, acc: 0.37931033968925476)
[2024-11-13 08:38:06,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:06,689][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 2.1889188289642334, acc: 0.3199999928474426)
[2024-11-13 08:38:06,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:07,370][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 2.805349111557007, acc: 0.3191489279270172)
[2024-11-13 08:38:07,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:08,047][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 2.2545838356018066, acc: 0.4375)
[2024-11-13 08:38:08,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:08,721][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.235483169555664, acc: 0.4545454680919647)
[2024-11-13 08:38:08,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:09,414][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 2.678783655166626, acc: 0.3132530152797699)
[2024-11-13 08:38:09,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:10,103][root][INFO] - Training Epoch: 1/10, step 282/574 completed (loss: 2.5655229091644287, acc: 0.37037035822868347)
[2024-11-13 08:38:10,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:10,781][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 2.8507819175720215, acc: 0.10526315867900848)
[2024-11-13 08:38:10,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:11,454][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 2.6047539710998535, acc: 0.20588235557079315)
[2024-11-13 08:38:11,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:12,129][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 2.541001796722412, acc: 0.2750000059604645)
[2024-11-13 08:38:13,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:13,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:14,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:14,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:15,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:16,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:16,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:17,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:17,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:18,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:19,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:19,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:20,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:20,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:21,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:22,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:22,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:23,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:23,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:24,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:24,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:25,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:26,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:26,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:27,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:27,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:28,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:28,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:29,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:30,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:30,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:31,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:31,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:32,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:33,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:33,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:34,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:34,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:35,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:35,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:36,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:36,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:37,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:38,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:38,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:39,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:39,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:40,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:41,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:41,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:42,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:42,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:43,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:43,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:44,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:45,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:45,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:46,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:46,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:47,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:48,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:48,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:49,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:49,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:51,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:51,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:52,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:52,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:53,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:53,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:54,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:55,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:55,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:56,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:56,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:57,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:58,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:58,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:59,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:38:59,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:00,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:01,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:01,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:02,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:03,146][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(12.6017, device='cuda:0') eval_epoch_loss=tensor(2.5338, device='cuda:0') eval_epoch_acc=tensor(0.3456, device='cuda:0')
[2024-11-13 08:39:03,148][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:39:03,148][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:39:03,619][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_1_step_286_loss_2.533834457397461/model.pt
[2024-11-13 08:39:03,624][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:39:03,626][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.533834457397461
[2024-11-13 08:39:03,626][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.3455546498298645
[2024-11-13 08:39:03,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:04,329][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 2.5147199630737305, acc: 0.296875)
[2024-11-13 08:39:04,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:05,034][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 2.8625147342681885, acc: 0.2160000056028366)
[2024-11-13 08:39:05,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:05,728][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 2.4358201026916504, acc: 0.38461539149284363)
[2024-11-13 08:39:05,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:06,419][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 2.7661213874816895, acc: 0.260869562625885)
[2024-11-13 08:39:06,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:07,139][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 2.7304224967956543, acc: 0.2835051417350769)
[2024-11-13 08:39:07,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:07,815][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 2.2221086025238037, acc: 0.3636363744735718)
[2024-11-13 08:39:07,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:08,492][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.5509700775146484, acc: 0.3333333432674408)
[2024-11-13 08:39:08,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:09,175][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 2.192549228668213, acc: 0.4482758641242981)
[2024-11-13 08:39:09,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:09,862][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 1.8456767797470093, acc: 0.5272727012634277)
[2024-11-13 08:39:09,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:10,583][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.1876261234283447, acc: 0.4020618498325348)
[2024-11-13 08:39:10,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:11,265][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 2.4985790252685547, acc: 0.37931033968925476)
[2024-11-13 08:39:11,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:11,937][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 2.0451908111572266, acc: 0.48148149251937866)
[2024-11-13 08:39:12,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:12,620][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 2.557328224182129, acc: 0.2631579041481018)
[2024-11-13 08:39:12,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:13,308][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 2.699949264526367, acc: 0.3392857015132904)
[2024-11-13 08:39:13,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:13,992][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 2.540496826171875, acc: 0.21875)
[2024-11-13 08:39:14,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:14,681][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 2.656268358230591, acc: 0.37735849618911743)
[2024-11-13 08:39:14,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:15,360][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 1.8092021942138672, acc: 0.5660377144813538)
[2024-11-13 08:39:15,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:16,079][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 1.9679327011108398, acc: 0.5)
[2024-11-13 08:39:16,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:16,750][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 2.9141650199890137, acc: 0.21875)
[2024-11-13 08:39:16,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:17,435][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 2.0813519954681396, acc: 0.5245901346206665)
[2024-11-13 08:39:17,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:18,109][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 1.7205941677093506, acc: 0.5666666626930237)
[2024-11-13 08:39:18,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:18,784][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 2.044844150543213, acc: 0.3684210479259491)
[2024-11-13 08:39:18,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:19,469][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 2.5552420616149902, acc: 0.3478260934352875)
[2024-11-13 08:39:19,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:20,159][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.290421962738037, acc: 0.375)
[2024-11-13 08:39:20,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:20,840][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 2.6027512550354004, acc: 0.3132530152797699)
[2024-11-13 08:39:20,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:21,538][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 2.7183499336242676, acc: 0.25641027092933655)
[2024-11-13 08:39:21,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:22,242][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 2.774376630783081, acc: 0.27551019191741943)
[2024-11-13 08:39:22,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:22,915][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 1.615129828453064, acc: 0.6666666865348816)
[2024-11-13 08:39:23,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:23,603][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 2.213601589202881, acc: 0.375)
[2024-11-13 08:39:23,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:24,312][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 2.373782157897949, acc: 0.22580644488334656)
[2024-11-13 08:39:24,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:25,010][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 2.438452959060669, acc: 0.32258063554763794)
[2024-11-13 08:39:25,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:25,694][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 2.0866730213165283, acc: 0.46268656849861145)
[2024-11-13 08:39:25,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:26,381][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 2.014061689376831, acc: 0.4615384638309479)
[2024-11-13 08:39:26,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:27,056][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 2.791585683822632, acc: 0.24444444477558136)
[2024-11-13 08:39:27,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:27,736][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 2.273491144180298, acc: 0.3870967626571655)
[2024-11-13 08:39:27,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:28,414][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 1.6549304723739624, acc: 0.6200000047683716)
[2024-11-13 08:39:28,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:29,087][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 2.858386516571045, acc: 0.3333333432674408)
[2024-11-13 08:39:29,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:29,766][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 3.654689073562622, acc: 0.1428571492433548)
[2024-11-13 08:39:29,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:30,439][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 2.894780397415161, acc: 0.25641027092933655)
[2024-11-13 08:39:30,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:31,116][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 2.957993984222412, acc: 0.2926829159259796)
[2024-11-13 08:39:31,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:31,803][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 2.5243425369262695, acc: 0.3947368562221527)
[2024-11-13 08:39:31,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:32,480][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 2.2519543170928955, acc: 0.31578946113586426)
[2024-11-13 08:39:32,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:33,154][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 2.2591209411621094, acc: 0.3928571343421936)
[2024-11-13 08:39:33,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:33,828][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 2.6654586791992188, acc: 0.3333333432674408)
[2024-11-13 08:39:33,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:34,515][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 1.9031926393508911, acc: 0.5)
[2024-11-13 08:39:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:35,197][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 2.57403564453125, acc: 0.30645161867141724)
[2024-11-13 08:39:35,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:35,880][root][INFO] - Training Epoch: 1/10, step 332/574 completed (loss: 2.058199644088745, acc: 0.4385964870452881)
[2024-11-13 08:39:35,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:36,559][root][INFO] - Training Epoch: 1/10, step 333/574 completed (loss: 2.7933669090270996, acc: 0.1875)
[2024-11-13 08:39:36,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:37,264][root][INFO] - Training Epoch: 1/10, step 334/574 completed (loss: 2.2397313117980957, acc: 0.4000000059604645)
[2024-11-13 08:39:37,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:37,939][root][INFO] - Training Epoch: 1/10, step 335/574 completed (loss: 2.142225980758667, acc: 0.42105263471603394)
[2024-11-13 08:39:38,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:38,646][root][INFO] - Training Epoch: 1/10, step 336/574 completed (loss: 2.4700510501861572, acc: 0.30000001192092896)
[2024-11-13 08:39:38,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:39,333][root][INFO] - Training Epoch: 1/10, step 337/574 completed (loss: 2.491028070449829, acc: 0.3103448152542114)
[2024-11-13 08:39:39,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:40,015][root][INFO] - Training Epoch: 1/10, step 338/574 completed (loss: 2.6492271423339844, acc: 0.3191489279270172)
[2024-11-13 08:39:40,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:40,699][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 2.6977641582489014, acc: 0.3614457845687866)
[2024-11-13 08:39:40,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:41,373][root][INFO] - Training Epoch: 1/10, step 340/574 completed (loss: 2.201688766479492, acc: 0.47826087474823)
[2024-11-13 08:39:41,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:42,046][root][INFO] - Training Epoch: 1/10, step 341/574 completed (loss: 2.7969958782196045, acc: 0.25641027092933655)
[2024-11-13 08:39:42,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:42,726][root][INFO] - Training Epoch: 1/10, step 342/574 completed (loss: 2.9087393283843994, acc: 0.27710843086242676)
[2024-11-13 08:39:42,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:43,410][root][INFO] - Training Epoch: 1/10, step 343/574 completed (loss: 2.313519239425659, acc: 0.3396226465702057)
[2024-11-13 08:39:43,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:44,101][root][INFO] - Training Epoch: 1/10, step 344/574 completed (loss: 2.6780736446380615, acc: 0.3037974536418915)
[2024-11-13 08:39:44,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:44,782][root][INFO] - Training Epoch: 1/10, step 345/574 completed (loss: 2.398205280303955, acc: 0.3529411852359772)
[2024-11-13 08:39:44,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:45,464][root][INFO] - Training Epoch: 1/10, step 346/574 completed (loss: 2.9193923473358154, acc: 0.28358209133148193)
[2024-11-13 08:39:45,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:46,136][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 2.0832102298736572, acc: 0.550000011920929)
[2024-11-13 08:39:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:46,807][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 2.184455394744873, acc: 0.4399999976158142)
[2024-11-13 08:39:46,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:47,483][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 2.0488157272338867, acc: 0.4444444477558136)
[2024-11-13 08:39:47,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:48,165][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 2.499479293823242, acc: 0.3720930218696594)
[2024-11-13 08:39:48,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:48,840][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 2.303905963897705, acc: 0.41025641560554504)
[2024-11-13 08:39:48,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:49,517][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 2.2218947410583496, acc: 0.35555556416511536)
[2024-11-13 08:39:49,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:50,198][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 1.7051036357879639, acc: 0.52173912525177)
[2024-11-13 08:39:50,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:50,881][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 2.6505661010742188, acc: 0.26923078298568726)
[2024-11-13 08:39:50,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:51,572][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 2.7704482078552246, acc: 0.2857142984867096)
[2024-11-13 08:39:51,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:52,279][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.2086899280548096, acc: 0.4000000059604645)
[2024-11-13 08:39:52,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:52,956][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 2.4992763996124268, acc: 0.30434781312942505)
[2024-11-13 08:39:53,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:53,637][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 2.42423415184021, acc: 0.3469387888908386)
[2024-11-13 08:39:53,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:54,310][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 1.5237836837768555, acc: 0.625)
[2024-11-13 08:39:54,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:54,986][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 2.0597333908081055, acc: 0.38461539149284363)
[2024-11-13 08:39:55,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:55,661][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 2.5251638889312744, acc: 0.39024388790130615)
[2024-11-13 08:39:55,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:56,338][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 2.18442964553833, acc: 0.42222222685813904)
[2024-11-13 08:39:56,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:57,025][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 2.635443687438965, acc: 0.3815789520740509)
[2024-11-13 08:39:57,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:57,709][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 2.796485424041748, acc: 0.39024388790130615)
[2024-11-13 08:39:57,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:58,395][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 2.5655710697174072, acc: 0.42424243688583374)
[2024-11-13 08:39:58,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:59,066][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 1.3926329612731934, acc: 0.5833333134651184)
[2024-11-13 08:39:59,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:39:59,742][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 1.3056504726409912, acc: 0.6521739363670349)
[2024-11-13 08:39:59,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:00,413][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 2.108854293823242, acc: 0.3214285671710968)
[2024-11-13 08:40:00,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:01,090][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 2.0727572441101074, acc: 0.40625)
[2024-11-13 08:40:01,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:01,799][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 2.498274803161621, acc: 0.4000000059604645)
[2024-11-13 08:40:01,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:02,506][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 1.9340018033981323, acc: 0.5471698045730591)
[2024-11-13 08:40:02,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:03,186][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.284179210662842, acc: 0.3888888955116272)
[2024-11-13 08:40:03,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:03,865][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 2.4294044971466064, acc: 0.3928571343421936)
[2024-11-13 08:40:03,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:04,554][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 1.524251103401184, acc: 0.6000000238418579)
[2024-11-13 08:40:04,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:05,229][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 1.4200892448425293, acc: 0.6399999856948853)
[2024-11-13 08:40:05,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:05,908][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 1.498271107673645, acc: 0.47826087474823)
[2024-11-13 08:40:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:06,599][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 2.75581431388855, acc: 0.2708333432674408)
[2024-11-13 08:40:06,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:07,285][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 2.273404836654663, acc: 0.4000000059604645)
[2024-11-13 08:40:07,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:07,995][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.270810842514038, acc: 0.38922154903411865)
[2024-11-13 08:40:08,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:08,701][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 2.0390830039978027, acc: 0.451127827167511)
[2024-11-13 08:40:08,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:09,419][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 2.158869504928589, acc: 0.4224599003791809)
[2024-11-13 08:40:09,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:10,123][root][INFO] - Training Epoch: 1/10, step 382/574 completed (loss: 1.9524931907653809, acc: 0.5045045018196106)
[2024-11-13 08:40:10,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:10,797][root][INFO] - Training Epoch: 1/10, step 383/574 completed (loss: 1.5549280643463135, acc: 0.6071428656578064)
[2024-11-13 08:40:10,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:11,469][root][INFO] - Training Epoch: 1/10, step 384/574 completed (loss: 1.389833688735962, acc: 0.6071428656578064)
[2024-11-13 08:40:11,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:12,143][root][INFO] - Training Epoch: 1/10, step 385/574 completed (loss: 2.2561252117156982, acc: 0.375)
[2024-11-13 08:40:12,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:12,814][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 2.4029786586761475, acc: 0.25)
[2024-11-13 08:40:12,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:13,488][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 2.4576995372772217, acc: 0.34210526943206787)
[2024-11-13 08:40:13,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:14,159][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 2.0207180976867676, acc: 0.4545454680919647)
[2024-11-13 08:40:14,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:14,829][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 1.9110095500946045, acc: 0.5)
[2024-11-13 08:40:14,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:15,503][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 2.0839483737945557, acc: 0.4285714328289032)
[2024-11-13 08:40:15,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:16,184][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 2.5953290462493896, acc: 0.35185185074806213)
[2024-11-13 08:40:16,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:16,867][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 2.8423728942871094, acc: 0.3009708821773529)
[2024-11-13 08:40:16,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:17,586][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.4007768630981445, acc: 0.4264705777168274)
[2024-11-13 08:40:17,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:18,278][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 2.767030954360962, acc: 0.3266666531562805)
[2024-11-13 08:40:18,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:18,969][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.454862356185913, acc: 0.375)
[2024-11-13 08:40:19,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:19,661][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 2.706284999847412, acc: 0.41860464215278625)
[2024-11-13 08:40:19,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:20,336][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 2.030386209487915, acc: 0.4166666567325592)
[2024-11-13 08:40:20,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:21,051][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 2.051503896713257, acc: 0.44186046719551086)
[2024-11-13 08:40:21,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:21,783][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 2.284334897994995, acc: 0.4399999976158142)
[2024-11-13 08:40:21,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:22,474][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 2.484813928604126, acc: 0.47058823704719543)
[2024-11-13 08:40:22,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:23,171][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.3910982608795166, acc: 0.4000000059604645)
[2024-11-13 08:40:23,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:23,846][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 2.2037875652313232, acc: 0.39393940567970276)
[2024-11-13 08:40:23,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:24,520][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 2.376312732696533, acc: 0.27272728085517883)
[2024-11-13 08:40:24,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:25,192][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 2.5007519721984863, acc: 0.25806450843811035)
[2024-11-13 08:40:25,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:25,867][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 2.344752788543701, acc: 0.37037035822868347)
[2024-11-13 08:40:25,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:26,536][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 1.5279855728149414, acc: 0.6800000071525574)
[2024-11-13 08:40:26,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:27,213][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 1.7291561365127563, acc: 0.5277777910232544)
[2024-11-13 08:40:27,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:27,911][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.7893258333206177, acc: 0.48148149251937866)
[2024-11-13 08:40:28,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:28,593][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.8734376430511475, acc: 0.5)
[2024-11-13 08:40:28,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:29,283][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 1.9798697233200073, acc: 0.517241358757019)
[2024-11-13 08:40:29,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:29,954][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 1.825508713722229, acc: 0.5357142686843872)
[2024-11-13 08:40:30,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:30,628][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 1.8099384307861328, acc: 0.4333333373069763)
[2024-11-13 08:40:30,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:31,306][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 2.026952028274536, acc: 0.3636363744735718)
[2024-11-13 08:40:31,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:31,979][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 2.3109967708587646, acc: 0.3181818127632141)
[2024-11-13 08:40:32,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:32,658][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.422067165374756, acc: 0.45098039507865906)
[2024-11-13 08:40:32,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:33,336][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 2.3463215827941895, acc: 0.38461539149284363)
[2024-11-13 08:40:33,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:34,006][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 2.5990166664123535, acc: 0.3333333432674408)
[2024-11-13 08:40:34,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:34,699][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.048884391784668, acc: 0.4749999940395355)
[2024-11-13 08:40:34,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:35,372][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 2.522911548614502, acc: 0.3499999940395355)
[2024-11-13 08:40:35,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:36,046][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 1.4006757736206055, acc: 0.5714285969734192)
[2024-11-13 08:40:36,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:36,733][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 2.292743444442749, acc: 0.36666667461395264)
[2024-11-13 08:40:36,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:37,405][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 2.2737882137298584, acc: 0.34375)
[2024-11-13 08:40:37,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:38,079][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 2.1754658222198486, acc: 0.3611111044883728)
[2024-11-13 08:40:38,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:38,765][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 2.2911911010742188, acc: 0.3333333432674408)
[2024-11-13 08:40:38,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:39,439][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 1.7988002300262451, acc: 0.5151515007019043)
[2024-11-13 08:40:39,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:40,108][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.946895718574524, acc: 0.3913043439388275)
[2024-11-13 08:40:40,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:40,783][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.7504701614379883, acc: 0.4864864945411682)
[2024-11-13 08:40:40,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:41,458][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 1.3165864944458008, acc: 0.5925925970077515)
[2024-11-13 08:40:42,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:43,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:43,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:44,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:44,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:45,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:46,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:46,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:47,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:47,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:48,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:48,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:49,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:50,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:50,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:51,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:51,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:52,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:53,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:53,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:54,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:54,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:55,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:55,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:56,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:57,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:57,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:58,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:58,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:40:59,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:00,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:00,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:01,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:01,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:02,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:03,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:03,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:04,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:04,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:05,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:06,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:06,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:07,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:07,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:08,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:09,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:10,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:10,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:11,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:11,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:12,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:13,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:13,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:14,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:14,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:15,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:16,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:16,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:17,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:17,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:18,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:18,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:19,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:20,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:20,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:21,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:21,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:22,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:23,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:23,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:24,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:24,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:25,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:25,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:26,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:27,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:27,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:28,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:28,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:29,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:30,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:30,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:31,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:31,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:32,844][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(11.3725, device='cuda:0') eval_epoch_loss=tensor(2.4312, device='cuda:0') eval_epoch_acc=tensor(0.3603, device='cuda:0')
[2024-11-13 08:41:32,846][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:41:32,847][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:41:33,198][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_1_step_429_loss_2.43119478225708/model.pt
[2024-11-13 08:41:33,206][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:41:33,207][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.43119478225708
[2024-11-13 08:41:33,207][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.36028075218200684
[2024-11-13 08:41:33,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:33,909][root][INFO] - Training Epoch: 1/10, step 429/574 completed (loss: 1.8481420278549194, acc: 0.52173912525177)
[2024-11-13 08:41:34,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:34,600][root][INFO] - Training Epoch: 1/10, step 430/574 completed (loss: 1.7524223327636719, acc: 0.3333333432674408)
[2024-11-13 08:41:34,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:35,271][root][INFO] - Training Epoch: 1/10, step 431/574 completed (loss: 1.590516209602356, acc: 0.4444444477558136)
[2024-11-13 08:41:35,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:35,942][root][INFO] - Training Epoch: 1/10, step 432/574 completed (loss: 2.420884370803833, acc: 0.43478259444236755)
[2024-11-13 08:41:36,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:36,614][root][INFO] - Training Epoch: 1/10, step 433/574 completed (loss: 1.99739408493042, acc: 0.5833333134651184)
[2024-11-13 08:41:36,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:37,285][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 1.3384112119674683, acc: 0.5199999809265137)
[2024-11-13 08:41:37,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:37,957][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 2.055095911026001, acc: 0.4545454680919647)
[2024-11-13 08:41:38,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:38,642][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 1.7170778512954712, acc: 0.5555555820465088)
[2024-11-13 08:41:38,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:39,320][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 1.7599282264709473, acc: 0.5454545617103577)
[2024-11-13 08:41:39,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:39,992][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 1.0202895402908325, acc: 0.6666666865348816)
[2024-11-13 08:41:40,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:40,667][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 2.456956386566162, acc: 0.38461539149284363)
[2024-11-13 08:41:40,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:41,367][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.1830503940582275, acc: 0.40909090638160706)
[2024-11-13 08:41:41,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:42,076][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 2.974297285079956, acc: 0.2720000147819519)
[2024-11-13 08:41:42,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:42,764][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 2.6504862308502197, acc: 0.30645161867141724)
[2024-11-13 08:41:42,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:44,299][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 2.602792501449585, acc: 0.3283582031726837)
[2024-11-13 08:41:44,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:44,978][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.603945732116699, acc: 0.35849055647850037)
[2024-11-13 08:41:45,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:45,658][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 1.784722924232483, acc: 0.47727271914482117)
[2024-11-13 08:41:45,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:46,334][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.150317430496216, acc: 0.47826087474823)
[2024-11-13 08:41:46,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:47,020][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 1.9999476671218872, acc: 0.5)
[2024-11-13 08:41:47,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:47,697][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.963133692741394, acc: 0.5)
[2024-11-13 08:41:47,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:48,369][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.8674263954162598, acc: 0.3731343150138855)
[2024-11-13 08:41:48,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:49,061][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.4268481731414795, acc: 0.4444444477558136)
[2024-11-13 08:41:49,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:49,782][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 2.7148852348327637, acc: 0.32608696818351746)
[2024-11-13 08:41:49,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:50,462][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.784093141555786, acc: 0.28205129504203796)
[2024-11-13 08:41:50,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:51,152][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.7048499584198, acc: 0.32894736528396606)
[2024-11-13 08:41:51,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:51,828][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 2.1447010040283203, acc: 0.4897959232330322)
[2024-11-13 08:41:51,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:52,501][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 2.0771429538726807, acc: 0.4545454680919647)
[2024-11-13 08:41:52,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:53,187][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.3907575607299805, acc: 0.2989690601825714)
[2024-11-13 08:41:53,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:53,875][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.4299378395080566, acc: 0.3285714387893677)
[2024-11-13 08:41:53,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:54,594][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.47619891166687, acc: 0.26744186878204346)
[2024-11-13 08:41:54,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:55,266][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.7078614234924316, acc: 0.25)
[2024-11-13 08:41:55,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:55,959][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 2.4989285469055176, acc: 0.3086419701576233)
[2024-11-13 08:41:56,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:56,641][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 1.991441249847412, acc: 0.4722222089767456)
[2024-11-13 08:41:56,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:57,317][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 2.1606290340423584, acc: 0.4375)
[2024-11-13 08:41:57,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:57,987][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 2.035776138305664, acc: 0.4615384638309479)
[2024-11-13 08:41:58,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:58,675][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 2.277406692504883, acc: 0.3695652186870575)
[2024-11-13 08:41:58,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:41:59,356][root][INFO] - Training Epoch: 1/10, step 465/574 completed (loss: 2.4206111431121826, acc: 0.3095238208770752)
[2024-11-13 08:41:59,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:00,042][root][INFO] - Training Epoch: 1/10, step 466/574 completed (loss: 2.569096565246582, acc: 0.27710843086242676)
[2024-11-13 08:42:00,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:00,747][root][INFO] - Training Epoch: 1/10, step 467/574 completed (loss: 2.329859495162964, acc: 0.38738739490509033)
[2024-11-13 08:42:00,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:01,430][root][INFO] - Training Epoch: 1/10, step 468/574 completed (loss: 2.444507122039795, acc: 0.3980582654476166)
[2024-11-13 08:42:01,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:02,137][root][INFO] - Training Epoch: 1/10, step 469/574 completed (loss: 2.3378207683563232, acc: 0.35772356390953064)
[2024-11-13 08:42:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:02,810][root][INFO] - Training Epoch: 1/10, step 470/574 completed (loss: 1.8085490465164185, acc: 0.4583333432674408)
[2024-11-13 08:42:02,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:03,487][root][INFO] - Training Epoch: 1/10, step 471/574 completed (loss: 2.6592624187469482, acc: 0.3571428656578064)
[2024-11-13 08:42:03,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:04,197][root][INFO] - Training Epoch: 1/10, step 472/574 completed (loss: 2.374776840209961, acc: 0.38235294818878174)
[2024-11-13 08:42:04,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:04,908][root][INFO] - Training Epoch: 1/10, step 473/574 completed (loss: 2.5981125831604004, acc: 0.3624454140663147)
[2024-11-13 08:42:04,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:05,589][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 2.447143793106079, acc: 0.34375)
[2024-11-13 08:42:05,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:06,304][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.4104161262512207, acc: 0.34355828166007996)
[2024-11-13 08:42:06,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:07,001][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 2.6523654460906982, acc: 0.316546767950058)
[2024-11-13 08:42:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:07,715][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 2.5759599208831787, acc: 0.34170854091644287)
[2024-11-13 08:42:07,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:08,392][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 2.1285080909729004, acc: 0.3333333432674408)
[2024-11-13 08:42:08,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:09,067][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 2.0706372261047363, acc: 0.39393940567970276)
[2024-11-13 08:42:09,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:09,739][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 2.078684091567993, acc: 0.25925925374031067)
[2024-11-13 08:42:09,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:10,416][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 2.5226988792419434, acc: 0.30000001192092896)
[2024-11-13 08:42:10,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:11,086][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 1.466273307800293, acc: 0.550000011920929)
[2024-11-13 08:42:11,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:11,779][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 1.8574209213256836, acc: 0.5)
[2024-11-13 08:42:11,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:12,499][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 1.88835608959198, acc: 0.5161290168762207)
[2024-11-13 08:42:12,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:13,171][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.47169029712677, acc: 0.6315789222717285)
[2024-11-13 08:42:13,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:13,848][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.5342679023742676, acc: 0.3333333432674408)
[2024-11-13 08:42:13,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:14,520][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.778268814086914, acc: 0.3333333432674408)
[2024-11-13 08:42:14,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:15,191][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 1.9925079345703125, acc: 0.40909090638160706)
[2024-11-13 08:42:15,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:15,870][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.1991183757781982, acc: 0.4153846204280853)
[2024-11-13 08:42:15,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:16,545][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 1.7185019254684448, acc: 0.6666666865348816)
[2024-11-13 08:42:16,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:17,222][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 1.8459036350250244, acc: 0.5862069129943848)
[2024-11-13 08:42:17,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:17,911][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.1896755695343018, acc: 0.3529411852359772)
[2024-11-13 08:42:17,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:18,593][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 2.190730333328247, acc: 0.48275861144065857)
[2024-11-13 08:42:18,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:19,265][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 1.2407411336898804, acc: 0.5789473652839661)
[2024-11-13 08:42:19,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:19,945][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.0765740871429443, acc: 0.15789473056793213)
[2024-11-13 08:42:20,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:20,639][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.2666354179382324, acc: 0.3928571343421936)
[2024-11-13 08:42:20,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:21,328][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.179629325866699, acc: 0.4157303273677826)
[2024-11-13 08:42:21,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:22,013][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.548107624053955, acc: 0.3483146131038666)
[2024-11-13 08:42:22,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:22,715][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.6831135749816895, acc: 0.26241135597229004)
[2024-11-13 08:42:22,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:23,407][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.540456771850586, acc: 0.33695653080940247)
[2024-11-13 08:42:23,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:24,078][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 1.423506259918213, acc: 0.5600000023841858)
[2024-11-13 08:42:24,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:24,752][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 1.9131735563278198, acc: 0.4615384638309479)
[2024-11-13 08:42:24,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:25,439][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 1.5224313735961914, acc: 0.5185185074806213)
[2024-11-13 08:42:25,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:26,122][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 2.2116880416870117, acc: 0.3333333432674408)
[2024-11-13 08:42:26,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:26,813][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 1.8269047737121582, acc: 0.5094339847564697)
[2024-11-13 08:42:26,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:27,491][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 1.3454989194869995, acc: 0.6896551847457886)
[2024-11-13 08:42:27,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:28,178][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.295443058013916, acc: 0.4054054021835327)
[2024-11-13 08:42:28,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:28,863][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 2.156520366668701, acc: 0.4647887349128723)
[2024-11-13 08:42:28,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:29,546][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 0.5468872785568237, acc: 0.8500000238418579)
[2024-11-13 08:42:29,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:30,222][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 1.2862948179244995, acc: 0.699999988079071)
[2024-11-13 08:42:30,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:30,947][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 1.9036495685577393, acc: 0.5384615659713745)
[2024-11-13 08:42:31,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:31,684][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 2.3884828090667725, acc: 0.3928571343421936)
[2024-11-13 08:42:31,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:32,391][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 2.493067502975464, acc: 0.4047619104385376)
[2024-11-13 08:42:32,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:33,094][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 2.1456782817840576, acc: 0.6428571343421936)
[2024-11-13 08:42:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:33,777][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 2.2174179553985596, acc: 0.4166666567325592)
[2024-11-13 08:42:33,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:34,477][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.203958511352539, acc: 0.4583333432674408)
[2024-11-13 08:42:34,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:35,200][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 0.8741715550422668, acc: 0.7307692170143127)
[2024-11-13 08:42:35,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:35,886][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 2.2406857013702393, acc: 0.3870967626571655)
[2024-11-13 08:42:36,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:36,576][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 2.5345101356506348, acc: 0.44999998807907104)
[2024-11-13 08:42:36,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:37,253][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.423680543899536, acc: 0.18518517911434174)
[2024-11-13 08:42:37,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:38,189][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.460315465927124, acc: 0.3262711763381958)
[2024-11-13 08:42:38,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:38,893][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.4610936641693115, acc: 0.33582088351249695)
[2024-11-13 08:42:38,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:39,580][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.4556941986083984, acc: 0.34306567907333374)
[2024-11-13 08:42:39,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:40,305][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.2253923416137695, acc: 0.4000000059604645)
[2024-11-13 08:42:40,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:40,984][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.4762072563171387, acc: 0.29629629850387573)
[2024-11-13 08:42:41,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:41,663][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.0326013565063477, acc: 0.48076921701431274)
[2024-11-13 08:42:41,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:42,330][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.33768630027771, acc: 0.3333333432674408)
[2024-11-13 08:42:42,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:43,012][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 2.8607680797576904, acc: 0.2950819730758667)
[2024-11-13 08:42:43,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:43,689][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.272022008895874, acc: 0.35593220591545105)
[2024-11-13 08:42:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:44,370][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 2.789900064468384, acc: 0.27906978130340576)
[2024-11-13 08:42:44,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:45,054][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.582712173461914, acc: 0.3636363744735718)
[2024-11-13 08:42:45,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:45,746][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.5987331867218018, acc: 0.2830188572406769)
[2024-11-13 08:42:45,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:46,424][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.2692368030548096, acc: 0.5)
[2024-11-13 08:42:46,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:47,094][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 1.9203126430511475, acc: 0.47999998927116394)
[2024-11-13 08:42:47,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:47,814][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 1.7729606628417969, acc: 0.5)
[2024-11-13 08:42:47,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:48,484][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 1.8486946821212769, acc: 0.40909090638160706)
[2024-11-13 08:42:48,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:49,165][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 2.1520516872406006, acc: 0.446153849363327)
[2024-11-13 08:42:49,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:49,848][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 2.184309720993042, acc: 0.375)
[2024-11-13 08:42:49,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:50,531][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 1.5502777099609375, acc: 0.5)
[2024-11-13 08:42:50,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:51,206][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 2.2148447036743164, acc: 0.3333333432674408)
[2024-11-13 08:42:51,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:51,876][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 1.12062406539917, acc: 0.6875)
[2024-11-13 08:42:51,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:52,558][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 1.4046601057052612, acc: 0.5161290168762207)
[2024-11-13 08:42:52,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:53,232][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 0.8667627573013306, acc: 0.782608687877655)
[2024-11-13 08:42:53,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:53,904][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 2.2915432453155518, acc: 0.36666667461395264)
[2024-11-13 08:42:53,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:54,582][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 2.2287633419036865, acc: 0.3658536672592163)
[2024-11-13 08:42:54,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:55,263][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 1.577883243560791, acc: 0.6285714507102966)
[2024-11-13 08:42:55,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:55,940][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 1.8838802576065063, acc: 0.5263158082962036)
[2024-11-13 08:42:56,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:56,615][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 1.977668046951294, acc: 0.4193548262119293)
[2024-11-13 08:42:56,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:57,290][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 1.1728010177612305, acc: 0.7200000286102295)
[2024-11-13 08:42:57,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:57,967][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.8720142841339111, acc: 0.42424243688583374)
[2024-11-13 08:42:58,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:58,655][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 1.594758152961731, acc: 0.6000000238418579)
[2024-11-13 08:42:58,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:42:59,334][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.8532640933990479, acc: 0.4714285731315613)
[2024-11-13 08:42:59,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:00,039][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.796471118927002, acc: 0.2554744482040405)
[2024-11-13 08:43:00,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:00,742][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.288935661315918, acc: 0.3931034505367279)
[2024-11-13 08:43:00,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:01,440][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.922593116760254, acc: 0.23571428656578064)
[2024-11-13 08:43:01,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:02,126][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.881788969039917, acc: 0.1986754983663559)
[2024-11-13 08:43:02,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:02,806][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 2.4726996421813965, acc: 0.3333333432674408)
[2024-11-13 08:43:02,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:03,489][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 1.0181502103805542, acc: 0.800000011920929)
[2024-11-13 08:43:03,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:04,164][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.920341968536377, acc: 0.5384615659713745)
[2024-11-13 08:43:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:04,836][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.5828335285186768, acc: 0.5384615659713745)
[2024-11-13 08:43:04,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:05,514][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 2.064263343811035, acc: 0.41025641560554504)
[2024-11-13 08:43:05,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:06,218][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 2.152437448501587, acc: 0.46666666865348816)
[2024-11-13 08:43:06,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:06,898][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.5239052772521973, acc: 0.2857142984867096)
[2024-11-13 08:43:06,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:07,575][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.161342144012451, acc: 0.3541666567325592)
[2024-11-13 08:43:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:08,251][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.3900699615478516, acc: 0.36206895112991333)
[2024-11-13 08:43:08,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:08,939][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.3044886589050293, acc: 0.3452380895614624)
[2024-11-13 08:43:09,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:09,614][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.8210288286209106, acc: 0.4736842215061188)
[2024-11-13 08:43:09,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:10,286][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 2.306349039077759, acc: 0.29629629850387573)
[2024-11-13 08:43:10,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:11,018][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.34157395362854, acc: 0.34224599599838257)
[2024-11-13 08:43:11,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:11,697][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 1.9886904954910278, acc: 0.3870967626571655)
[2024-11-13 08:43:11,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:12,386][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 2.4473397731781006, acc: 0.3504273593425751)
[2024-11-13 08:43:13,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:13,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:14,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:15,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:15,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:16,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:16,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:17,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:17,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:18,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:19,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:19,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:20,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:20,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:21,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:22,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:23,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:23,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:24,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:25,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:25,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:26,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:27,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:27,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:28,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:29,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:30,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:30,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:31,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:31,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:32,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:32,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:33,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:34,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:34,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:35,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:35,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:36,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:37,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:37,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:38,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:38,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:39,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:39,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:40,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:41,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:41,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:42,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:42,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:43,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:44,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:44,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:45,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:45,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:46,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:47,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:47,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:48,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:48,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:49,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:49,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:50,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:51,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:52,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:52,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:53,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:54,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:54,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:55,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:55,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:56,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:57,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:57,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:58,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:58,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:59,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:43:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:00,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:01,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:01,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:02,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:02,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:03,814][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.1640, device='cuda:0') eval_epoch_loss=tensor(2.0997, device='cuda:0') eval_epoch_acc=tensor(0.4311, device='cuda:0')
[2024-11-13 08:44:03,815][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:44:03,815][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:44:04,169][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_1_step_572_loss_2.099738597869873/model.pt
[2024-11-13 08:44:04,172][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:44:04,173][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.099738597869873
[2024-11-13 08:44:04,173][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.43106696009635925
[2024-11-13 08:44:04,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:04,895][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 2.6186676025390625, acc: 0.2806122303009033)
[2024-11-13 08:44:04,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:05,612][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 2.457871913909912, acc: 0.276729553937912)
[2024-11-13 08:44:06,048][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=20.9640, train_epoch_loss=3.0428, epoch time 612.7393009345978s
[2024-11-13 08:44:06,049][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 08:44:06,049][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 08:44:06,049][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 08:44:06,049][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 1
[2024-11-13 08:44:06,049][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 08:44:06,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:07,418][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 1.755858063697815, acc: 0.5555555820465088)
[2024-11-13 08:44:07,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:08,101][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 2.095278263092041, acc: 0.4399999976158142)
[2024-11-13 08:44:08,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:08,795][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 2.8238394260406494, acc: 0.29729729890823364)
[2024-11-13 08:44:08,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:09,485][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 2.6077959537506104, acc: 0.2631579041481018)
[2024-11-13 08:44:09,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:10,172][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 2.042147636413574, acc: 0.3243243098258972)
[2024-11-13 08:44:10,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:10,864][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.4081273078918457, acc: 0.25)
[2024-11-13 08:44:10,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:11,553][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.6369056701660156, acc: 0.2448979616165161)
[2024-11-13 08:44:11,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:12,238][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 2.245086908340454, acc: 0.30000001192092896)
[2024-11-13 08:44:12,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:12,919][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 0.5867636203765869, acc: 0.9090909361839294)
[2024-11-13 08:44:13,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:13,599][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 1.220985770225525, acc: 0.692307710647583)
[2024-11-13 08:44:13,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:14,283][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 1.4052478075027466, acc: 0.5925925970077515)
[2024-11-13 08:44:14,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:14,970][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.2128450870513916, acc: 0.41025641560554504)
[2024-11-13 08:44:15,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:15,654][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.8685210943222046, acc: 0.42424243688583374)
[2024-11-13 08:44:15,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:16,340][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 2.069456100463867, acc: 0.3913043439388275)
[2024-11-13 08:44:16,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:17,023][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.519871234893799, acc: 0.3529411852359772)
[2024-11-13 08:44:17,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:17,709][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 1.9141271114349365, acc: 0.4693877696990967)
[2024-11-13 08:44:17,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:18,405][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.097280502319336, acc: 0.7894737124443054)
[2024-11-13 08:44:18,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:19,106][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 2.3582284450531006, acc: 0.375)
[2024-11-13 08:44:19,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:19,793][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.8062047958374023, acc: 0.3055555522441864)
[2024-11-13 08:44:19,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:20,472][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 1.5542993545532227, acc: 0.5789473652839661)
[2024-11-13 08:44:20,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:21,154][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 2.4651236534118652, acc: 0.38461539149284363)
[2024-11-13 08:44:21,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:21,838][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 2.400261878967285, acc: 0.4482758641242981)
[2024-11-13 08:44:21,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:22,521][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 2.2387006282806396, acc: 0.36000001430511475)
[2024-11-13 08:44:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:23,204][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 1.5739061832427979, acc: 0.5714285969734192)
[2024-11-13 08:44:23,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:23,900][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 2.5335655212402344, acc: 0.1875)
[2024-11-13 08:44:23,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:24,609][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 2.8164126873016357, acc: 0.18867924809455872)
[2024-11-13 08:44:24,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:25,301][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.5511720180511475, acc: 0.3287671208381653)
[2024-11-13 08:44:25,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:26,104][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 2.604295015335083, acc: 0.2964426875114441)
[2024-11-13 08:44:26,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:26,791][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 2.5856573581695557, acc: 0.23255814611911774)
[2024-11-13 08:44:26,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:27,487][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 2.409540891647339, acc: 0.3734939694404602)
[2024-11-13 08:44:27,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:28,197][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.3372511863708496, acc: 0.34567901492118835)
[2024-11-13 08:44:28,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:28,884][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 2.5408668518066406, acc: 0.3571428656578064)
[2024-11-13 08:44:28,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:29,564][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 1.9202567338943481, acc: 0.5185185074806213)
[2024-11-13 08:44:29,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:30,256][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 2.0007195472717285, acc: 0.3913043439388275)
[2024-11-13 08:44:30,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:30,957][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 2.283674716949463, acc: 0.3949579894542694)
[2024-11-13 08:44:31,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:31,651][root][INFO] - Training Epoch: 2/10, step 35/574 completed (loss: 1.9704447984695435, acc: 0.44262295961380005)
[2024-11-13 08:44:31,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:32,353][root][INFO] - Training Epoch: 2/10, step 36/574 completed (loss: 2.1011269092559814, acc: 0.4444444477558136)
[2024-11-13 08:44:32,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:33,040][root][INFO] - Training Epoch: 2/10, step 37/574 completed (loss: 2.444761037826538, acc: 0.38983049988746643)
[2024-11-13 08:44:33,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:33,747][root][INFO] - Training Epoch: 2/10, step 38/574 completed (loss: 1.7782361507415771, acc: 0.49425286054611206)
[2024-11-13 08:44:33,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:34,436][root][INFO] - Training Epoch: 2/10, step 39/574 completed (loss: 1.5121592283248901, acc: 0.6190476417541504)
[2024-11-13 08:44:34,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:35,136][root][INFO] - Training Epoch: 2/10, step 40/574 completed (loss: 2.8122715950012207, acc: 0.19230769574642181)
[2024-11-13 08:44:35,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:35,833][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 2.6702675819396973, acc: 0.3243243098258972)
[2024-11-13 08:44:35,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:36,529][root][INFO] - Training Epoch: 2/10, step 42/574 completed (loss: 2.1746206283569336, acc: 0.4615384638309479)
[2024-11-13 08:44:36,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:37,224][root][INFO] - Training Epoch: 2/10, step 43/574 completed (loss: 2.433405876159668, acc: 0.39393940567970276)
[2024-11-13 08:44:37,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:37,925][root][INFO] - Training Epoch: 2/10, step 44/574 completed (loss: 2.1853339672088623, acc: 0.42268040776252747)
[2024-11-13 08:44:38,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:38,637][root][INFO] - Training Epoch: 2/10, step 45/574 completed (loss: 2.3093101978302, acc: 0.44117647409439087)
[2024-11-13 08:44:38,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:39,327][root][INFO] - Training Epoch: 2/10, step 46/574 completed (loss: 1.2135868072509766, acc: 0.6153846383094788)
[2024-11-13 08:44:39,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:40,011][root][INFO] - Training Epoch: 2/10, step 47/574 completed (loss: 1.1581922769546509, acc: 0.7037037014961243)
[2024-11-13 08:44:40,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:40,697][root][INFO] - Training Epoch: 2/10, step 48/574 completed (loss: 1.4790112972259521, acc: 0.6785714030265808)
[2024-11-13 08:44:40,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:41,382][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 1.6158822774887085, acc: 0.5)
[2024-11-13 08:44:41,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:42,078][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 1.6607799530029297, acc: 0.5263158082962036)
[2024-11-13 08:44:42,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:42,776][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 1.91781747341156, acc: 0.5079365372657776)
[2024-11-13 08:44:42,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:43,471][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.3107895851135254, acc: 0.3661971688270569)
[2024-11-13 08:44:43,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:44,200][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 2.7006595134735107, acc: 0.41999998688697815)
[2024-11-13 08:44:44,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:44,885][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 1.5996441841125488, acc: 0.6216216087341309)
[2024-11-13 08:44:44,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:45,577][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 1.0333207845687866, acc: 0.692307710647583)
[2024-11-13 08:44:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:46,419][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 2.129796266555786, acc: 0.45392492413520813)
[2024-11-13 08:44:46,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:47,200][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 2.703681707382202, acc: 0.3616557717323303)
[2024-11-13 08:44:47,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:47,925][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.1904585361480713, acc: 0.4488636255264282)
[2024-11-13 08:44:48,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:48,639][root][INFO] - Training Epoch: 2/10, step 59/574 completed (loss: 2.4623031616210938, acc: 0.38235294818878174)
[2024-11-13 08:44:48,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:49,361][root][INFO] - Training Epoch: 2/10, step 60/574 completed (loss: 2.406742572784424, acc: 0.3550724685192108)
[2024-11-13 08:44:49,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:50,077][root][INFO] - Training Epoch: 2/10, step 61/574 completed (loss: 1.9617502689361572, acc: 0.5)
[2024-11-13 08:44:50,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:50,762][root][INFO] - Training Epoch: 2/10, step 62/574 completed (loss: 1.7571892738342285, acc: 0.47058823704719543)
[2024-11-13 08:44:50,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:51,457][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 2.3121213912963867, acc: 0.2777777910232544)
[2024-11-13 08:44:51,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:52,154][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 2.0699303150177, acc: 0.484375)
[2024-11-13 08:44:52,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:52,850][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 1.1372532844543457, acc: 0.7241379022598267)
[2024-11-13 08:44:52,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:53,542][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 2.405045986175537, acc: 0.4285714328289032)
[2024-11-13 08:44:53,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:54,231][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 2.337836503982544, acc: 0.3333333432674408)
[2024-11-13 08:44:54,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:54,924][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 1.3070456981658936, acc: 0.5199999809265137)
[2024-11-13 08:44:55,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:55,621][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 1.5892562866210938, acc: 0.6111111044883728)
[2024-11-13 08:44:55,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:56,321][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 1.8611449003219604, acc: 0.5454545617103577)
[2024-11-13 08:44:56,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:57,038][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 2.3383045196533203, acc: 0.4117647111415863)
[2024-11-13 08:44:57,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:57,740][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.2125327587127686, acc: 0.4047619104385376)
[2024-11-13 08:44:57,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:58,465][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.444129467010498, acc: 0.34358975291252136)
[2024-11-13 08:44:58,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:59,165][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.23317813873291, acc: 0.3571428656578064)
[2024-11-13 08:44:59,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:44:59,864][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.6956961154937744, acc: 0.2238806039094925)
[2024-11-13 08:44:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:00,611][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.4575018882751465, acc: 0.37226277589797974)
[2024-11-13 08:45:00,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:01,294][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.9559033513069153, acc: 0.8095238208770752)
[2024-11-13 08:45:01,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:01,988][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 1.1416306495666504, acc: 0.7083333134651184)
[2024-11-13 08:45:02,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:02,673][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.4281182289123535, acc: 0.5757575631141663)
[2024-11-13 08:45:02,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:03,371][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.6254321336746216, acc: 0.38461539149284363)
[2024-11-13 08:45:03,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:04,067][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 2.0952088832855225, acc: 0.4038461446762085)
[2024-11-13 08:45:04,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:04,759][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.414487361907959, acc: 0.38461539149284363)
[2024-11-13 08:45:04,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:05,449][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 1.9636129140853882, acc: 0.5)
[2024-11-13 08:45:05,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:06,139][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 2.391120433807373, acc: 0.3478260934352875)
[2024-11-13 08:45:06,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:06,831][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.9556878805160522, acc: 0.47999998927116394)
[2024-11-13 08:45:06,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:07,524][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 2.28486704826355, acc: 0.3913043439388275)
[2024-11-13 08:45:07,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:08,222][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.3672873973846436, acc: 0.3199999928474426)
[2024-11-13 08:45:08,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:08,920][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 2.0095107555389404, acc: 0.5339806079864502)
[2024-11-13 08:45:09,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:09,648][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 2.0338284969329834, acc: 0.5194174647331238)
[2024-11-13 08:45:09,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:10,374][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.2298085689544678, acc: 0.3870967626571655)
[2024-11-13 08:45:10,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:11,111][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 2.000227451324463, acc: 0.5129310488700867)
[2024-11-13 08:45:11,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:11,813][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 1.703916072845459, acc: 0.4736842215061188)
[2024-11-13 08:45:11,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:12,545][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 2.4031193256378174, acc: 0.31683167815208435)
[2024-11-13 08:45:12,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:13,253][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 2.491483449935913, acc: 0.35483869910240173)
[2024-11-13 08:45:13,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:13,951][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.5730948448181152, acc: 0.3188405930995941)
[2024-11-13 08:45:14,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:14,652][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 2.7300517559051514, acc: 0.2521008551120758)
[2024-11-13 08:45:14,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:15,352][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.7108519077301025, acc: 0.25)
[2024-11-13 08:45:15,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:16,053][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.5380303859710693, acc: 0.31386861205101013)
[2024-11-13 08:45:16,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:16,742][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 2.6836307048797607, acc: 0.17910447716712952)
[2024-11-13 08:45:16,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:17,430][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 1.703528642654419, acc: 0.550000011920929)
[2024-11-13 08:45:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:18,112][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 1.154557704925537, acc: 0.5909090638160706)
[2024-11-13 08:45:18,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:18,795][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.418045997619629, acc: 0.6086956262588501)
[2024-11-13 08:45:18,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:19,480][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 2.0409350395202637, acc: 0.3863636255264282)
[2024-11-13 08:45:19,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:20,172][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.3028550148010254, acc: 0.32758620381355286)
[2024-11-13 08:45:20,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:20,858][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 2.198834180831909, acc: 0.3720930218696594)
[2024-11-13 08:45:20,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:21,549][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.7078355550765991, acc: 0.5199999809265137)
[2024-11-13 08:45:21,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:22,232][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 1.2010387182235718, acc: 0.5882353186607361)
[2024-11-13 08:45:22,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:22,917][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.8389225006103516, acc: 0.7692307829856873)
[2024-11-13 08:45:22,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:23,614][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 2.1356914043426514, acc: 0.380952388048172)
[2024-11-13 08:45:23,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:24,306][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.1987414360046387, acc: 0.4923076927661896)
[2024-11-13 08:45:24,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:24,996][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.34191632270813, acc: 0.4385964870452881)
[2024-11-13 08:45:25,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:25,682][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 2.0354509353637695, acc: 0.45614033937454224)
[2024-11-13 08:45:25,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:26,370][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.294339418411255, acc: 0.41025641560554504)
[2024-11-13 08:45:26,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:27,059][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.617427945137024, acc: 0.6122449040412903)
[2024-11-13 08:45:27,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:27,742][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 0.7537727952003479, acc: 0.8636363744735718)
[2024-11-13 08:45:27,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:28,450][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.303304672241211, acc: 0.4444444477558136)
[2024-11-13 08:45:28,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:29,147][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.1167943477630615, acc: 0.4471544623374939)
[2024-11-13 08:45:29,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:29,838][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.8742375373840332, acc: 0.5322580933570862)
[2024-11-13 08:45:29,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:30,603][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.173004150390625, acc: 0.4030418395996094)
[2024-11-13 08:45:30,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:31,300][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.844885230064392, acc: 0.5066666603088379)
[2024-11-13 08:45:31,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:31,997][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.683335781097412, acc: 0.5769230723381042)
[2024-11-13 08:45:32,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:32,691][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 0.8846589922904968, acc: 0.7916666865348816)
[2024-11-13 08:45:32,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:33,372][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.8416069746017456, acc: 0.5263158082962036)
[2024-11-13 08:45:33,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:34,083][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.3423779010772705, acc: 0.349693238735199)
[2024-11-13 08:45:34,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:34,806][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 2.0642101764678955, acc: 0.4305555522441864)
[2024-11-13 08:45:34,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:35,511][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.3665316104888916, acc: 0.3583333194255829)
[2024-11-13 08:45:35,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:36,248][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.4887027740478516, acc: 0.2916666567325592)
[2024-11-13 08:45:36,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:36,974][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.227304220199585, acc: 0.4000000059604645)
[2024-11-13 08:45:37,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:37,710][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 1.9633160829544067, acc: 0.4852941036224365)
[2024-11-13 08:45:37,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:38,396][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.236801028251648, acc: 0.6153846383094788)
[2024-11-13 08:45:38,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:39,080][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 0.8928502202033997, acc: 0.695652186870575)
[2024-11-13 08:45:39,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:39,763][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 1.8786834478378296, acc: 0.46875)
[2024-11-13 08:45:39,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:40,447][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 2.1171953678131104, acc: 0.52173912525177)
[2024-11-13 08:45:40,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:41,131][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 1.677176594734192, acc: 0.4571428596973419)
[2024-11-13 08:45:41,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:41,812][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 1.6340241432189941, acc: 0.6153846383094788)
[2024-11-13 08:45:41,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:42,500][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 2.3436355590820312, acc: 0.3095238208770752)
[2024-11-13 08:45:42,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:43,182][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 1.7109373807907104, acc: 0.4333333373069763)
[2024-11-13 08:45:43,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:43,865][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.915528655052185, acc: 0.43478259444236755)
[2024-11-13 08:45:43,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:44,546][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 2.4039700031280518, acc: 0.523809552192688)
[2024-11-13 08:45:44,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:45,237][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 2.6017956733703613, acc: 0.38461539149284363)
[2024-11-13 08:45:46,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:46,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:47,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:48,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:48,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:49,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:49,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:50,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:51,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:51,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:52,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:53,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:53,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:54,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:54,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:55,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:55,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:56,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:57,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:57,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:58,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:45:59,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:00,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:00,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:01,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:01,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:02,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:03,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:03,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:04,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:04,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:05,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:06,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:06,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:07,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:07,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:08,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:09,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:10,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:10,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:11,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:11,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:12,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:13,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:13,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:14,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:14,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:15,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:16,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:16,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:17,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:17,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:18,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:18,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:19,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:20,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:21,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:22,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:23,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:23,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:24,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:24,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:25,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:26,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:27,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:27,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:28,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:28,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:29,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:30,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:30,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:31,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:32,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:32,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:33,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:33,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:34,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:35,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:35,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:36,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:37,188][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.9681, device='cuda:0') eval_epoch_loss=tensor(2.1937, device='cuda:0') eval_epoch_acc=tensor(0.4124, device='cuda:0')
[2024-11-13 08:46:37,189][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:46:37,190][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:46:37,532][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_2_step_141_loss_2.193673849105835/model.pt
[2024-11-13 08:46:37,536][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:46:37,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:38,228][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 3.201930522918701, acc: 0.19354838132858276)
[2024-11-13 08:46:38,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:38,906][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 2.8041725158691406, acc: 0.21621622145175934)
[2024-11-13 08:46:38,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:39,621][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.284461736679077, acc: 0.35087719559669495)
[2024-11-13 08:46:39,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:40,309][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 2.1968677043914795, acc: 0.44029849767684937)
[2024-11-13 08:46:40,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:40,998][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.3844053745269775, acc: 0.3571428656578064)
[2024-11-13 08:46:41,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:41,700][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.2414073944091797, acc: 0.3404255211353302)
[2024-11-13 08:46:41,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:42,384][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.109234571456909, acc: 0.48571428656578064)
[2024-11-13 08:46:42,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:43,060][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 2.262627124786377, acc: 0.3571428656578064)
[2024-11-13 08:46:43,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:43,731][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.7068177461624146, acc: 0.52173912525177)
[2024-11-13 08:46:43,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:44,406][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.428256034851074, acc: 0.27586206793785095)
[2024-11-13 08:46:44,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:45,081][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.1465048789978027, acc: 0.43478259444236755)
[2024-11-13 08:46:45,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:45,763][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.041715383529663, acc: 0.4576271176338196)
[2024-11-13 08:46:45,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:46,441][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.571443796157837, acc: 0.3684210479259491)
[2024-11-13 08:46:46,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:47,133][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.089797258377075, acc: 0.4324324429035187)
[2024-11-13 08:46:47,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:47,808][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.8405512571334839, acc: 0.5357142686843872)
[2024-11-13 08:46:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:48,480][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.5178099870681763, acc: 0.6521739363670349)
[2024-11-13 08:46:48,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:49,183][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 2.295438766479492, acc: 0.31578946113586426)
[2024-11-13 08:46:49,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:49,864][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 1.954102635383606, acc: 0.4864864945411682)
[2024-11-13 08:46:49,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:50,541][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.2341601848602295, acc: 0.46296295523643494)
[2024-11-13 08:46:50,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:51,220][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 2.075260639190674, acc: 0.41860464215278625)
[2024-11-13 08:46:51,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:51,899][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 1.963980793952942, acc: 0.48235294222831726)
[2024-11-13 08:46:51,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:52,586][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 2.314516067504883, acc: 0.40449437499046326)
[2024-11-13 08:46:52,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:53,266][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 2.026756525039673, acc: 0.5)
[2024-11-13 08:46:53,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:53,936][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 1.7038156986236572, acc: 0.5714285969734192)
[2024-11-13 08:46:54,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:54,612][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 2.04298734664917, acc: 0.3448275923728943)
[2024-11-13 08:46:54,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:55,291][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.5901340246200562, acc: 0.5714285969734192)
[2024-11-13 08:46:55,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:55,966][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 1.8685482740402222, acc: 0.47999998927116394)
[2024-11-13 08:46:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:56,649][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.948873519897461, acc: 0.4583333432674408)
[2024-11-13 08:46:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:57,338][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.1544158458709717, acc: 0.3921568691730499)
[2024-11-13 08:46:57,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:58,068][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.4793167114257812, acc: 0.4178082048892975)
[2024-11-13 08:46:58,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:58,742][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.4739179611206055, acc: 0.6666666865348816)
[2024-11-13 08:46:58,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:46:59,419][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 1.4227279424667358, acc: 0.5925925970077515)
[2024-11-13 08:46:59,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:00,094][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.9197568893432617, acc: 0.5)
[2024-11-13 08:47:00,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:00,799][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 2.0173134803771973, acc: 0.48672565817832947)
[2024-11-13 08:47:00,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:01,483][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 2.0666940212249756, acc: 0.4637681245803833)
[2024-11-13 08:47:01,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:02,169][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 2.2781381607055664, acc: 0.3636363744735718)
[2024-11-13 08:47:02,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:02,878][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 2.5475549697875977, acc: 0.290076345205307)
[2024-11-13 08:47:02,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:03,581][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 2.3992114067077637, acc: 0.3185185194015503)
[2024-11-13 08:47:03,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:04,269][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 1.87101411819458, acc: 0.5245901346206665)
[2024-11-13 08:47:04,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:04,953][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 0.9379429221153259, acc: 0.7083333134651184)
[2024-11-13 08:47:05,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:05,624][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 1.8418656587600708, acc: 0.4399999976158142)
[2024-11-13 08:47:05,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:06,301][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 1.4718574285507202, acc: 0.5357142686843872)
[2024-11-13 08:47:06,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:06,987][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 2.496361255645752, acc: 0.3414634168148041)
[2024-11-13 08:47:07,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:07,715][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 2.5974011421203613, acc: 0.3262839913368225)
[2024-11-13 08:47:07,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:08,444][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.6514055728912354, acc: 0.3285302519798279)
[2024-11-13 08:47:08,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:09,165][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.598170757293701, acc: 0.33125001192092896)
[2024-11-13 08:47:09,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:09,930][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.376157283782959, acc: 0.347091943025589)
[2024-11-13 08:47:10,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:10,674][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.30769944190979, acc: 0.3772242069244385)
[2024-11-13 08:47:10,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:11,346][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 2.6631412506103516, acc: 0.4000000059604645)
[2024-11-13 08:47:11,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:12,033][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.446878433227539, acc: 0.40697672963142395)
[2024-11-13 08:47:12,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:12,728][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.1713616847991943, acc: 0.4841269850730896)
[2024-11-13 08:47:12,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:13,421][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.274501085281372, acc: 0.4469696879386902)
[2024-11-13 08:47:13,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:14,105][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 2.025692939758301, acc: 0.48235294222831726)
[2024-11-13 08:47:14,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:14,813][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 1.9548059701919556, acc: 0.5123456716537476)
[2024-11-13 08:47:14,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:15,499][root][INFO] - Training Epoch: 2/10, step 195/574 completed (loss: 1.621028184890747, acc: 0.5483871102333069)
[2024-11-13 08:47:15,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:16,171][root][INFO] - Training Epoch: 2/10, step 196/574 completed (loss: 0.9651422500610352, acc: 0.75)
[2024-11-13 08:47:16,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:16,845][root][INFO] - Training Epoch: 2/10, step 197/574 completed (loss: 2.258513927459717, acc: 0.42500001192092896)
[2024-11-13 08:47:16,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:17,532][root][INFO] - Training Epoch: 2/10, step 198/574 completed (loss: 2.2550408840179443, acc: 0.3970588147640228)
[2024-11-13 08:47:17,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:18,222][root][INFO] - Training Epoch: 2/10, step 199/574 completed (loss: 2.2180233001708984, acc: 0.4485294222831726)
[2024-11-13 08:47:18,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:18,909][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 2.3932688236236572, acc: 0.3644067943096161)
[2024-11-13 08:47:19,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:19,601][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 2.387495994567871, acc: 0.43283581733703613)
[2024-11-13 08:47:19,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:20,300][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.336151361465454, acc: 0.3883495032787323)
[2024-11-13 08:47:20,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:20,985][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 2.1846444606781006, acc: 0.460317462682724)
[2024-11-13 08:47:21,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:21,669][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 2.1996374130249023, acc: 0.38461539149284363)
[2024-11-13 08:47:21,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:22,386][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.309178113937378, acc: 0.35874438285827637)
[2024-11-13 08:47:22,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:23,115][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.205254077911377, acc: 0.4448818862438202)
[2024-11-13 08:47:23,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:23,826][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 2.2312936782836914, acc: 0.40086206793785095)
[2024-11-13 08:47:23,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:24,539][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.206524133682251, acc: 0.44565218687057495)
[2024-11-13 08:47:24,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:25,256][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.336754083633423, acc: 0.34241244196891785)
[2024-11-13 08:47:25,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:25,965][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.5090928077697754, acc: 0.3804347813129425)
[2024-11-13 08:47:26,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:26,636][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.5092567205429077, acc: 0.6521739363670349)
[2024-11-13 08:47:26,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:27,309][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 2.018120288848877, acc: 0.5)
[2024-11-13 08:47:27,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:27,996][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.8492499589920044, acc: 0.5319148898124695)
[2024-11-13 08:47:28,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:28,697][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 2.028224229812622, acc: 0.4307692348957062)
[2024-11-13 08:47:28,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:29,374][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 1.8212125301361084, acc: 0.5540540814399719)
[2024-11-13 08:47:29,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:30,054][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 1.8658404350280762, acc: 0.43023255467414856)
[2024-11-13 08:47:30,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:30,747][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 1.9184932708740234, acc: 0.46846845746040344)
[2024-11-13 08:47:30,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:31,433][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 1.9601103067398071, acc: 0.4333333373069763)
[2024-11-13 08:47:31,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:32,108][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 1.0365124940872192, acc: 0.6969696879386902)
[2024-11-13 08:47:32,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:32,780][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.6115620732307434, acc: 0.8518518805503845)
[2024-11-13 08:47:32,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:33,457][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 1.124467372894287, acc: 0.5600000023841858)
[2024-11-13 08:47:33,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:34,141][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 2.122969150543213, acc: 0.4038461446762085)
[2024-11-13 08:47:34,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:34,852][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 1.9327069520950317, acc: 0.489130437374115)
[2024-11-13 08:47:34,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:35,556][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 2.0529913902282715, acc: 0.4431818127632141)
[2024-11-13 08:47:35,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:36,267][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 2.412217378616333, acc: 0.3617021143436432)
[2024-11-13 08:47:36,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:36,942][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 1.9668865203857422, acc: 0.49056604504585266)
[2024-11-13 08:47:37,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:37,631][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 2.086026191711426, acc: 0.4833333194255829)
[2024-11-13 08:47:37,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:38,314][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.5937435626983643, acc: 0.6511628031730652)
[2024-11-13 08:47:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:38,992][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 1.5839296579360962, acc: 0.6666666865348816)
[2024-11-13 08:47:39,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:39,684][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 2.488304853439331, acc: 0.3684210479259491)
[2024-11-13 08:47:39,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:40,365][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 1.9751951694488525, acc: 0.47777777910232544)
[2024-11-13 08:47:40,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:41,077][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 1.929411768913269, acc: 0.5055555701255798)
[2024-11-13 08:47:41,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:41,786][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 1.992051124572754, acc: 0.5045871734619141)
[2024-11-13 08:47:41,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:42,491][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 1.878360629081726, acc: 0.4692307710647583)
[2024-11-13 08:47:42,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:43,159][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 1.4392050504684448, acc: 0.5263158082962036)
[2024-11-13 08:47:43,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:43,829][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.356505036354065, acc: 0.5833333134651184)
[2024-11-13 08:47:43,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:44,501][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 2.3490405082702637, acc: 0.3181818127632141)
[2024-11-13 08:47:44,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:45,174][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.6961767673492432, acc: 0.40740740299224854)
[2024-11-13 08:47:45,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:45,849][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.7907377481460571, acc: 0.48571428656578064)
[2024-11-13 08:47:45,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:46,535][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.7877084016799927, acc: 0.5)
[2024-11-13 08:47:46,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:47,210][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 2.0351908206939697, acc: 0.4318181872367859)
[2024-11-13 08:47:47,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:47,888][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.124922752380371, acc: 0.4032258093357086)
[2024-11-13 08:47:47,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:48,577][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 1.8094371557235718, acc: 0.4545454680919647)
[2024-11-13 08:47:48,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:49,249][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 1.1138513088226318, acc: 0.7142857313156128)
[2024-11-13 08:47:49,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:49,921][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.7933714389801025, acc: 0.5384615659713745)
[2024-11-13 08:47:50,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:50,597][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.952373743057251, acc: 0.4193548262119293)
[2024-11-13 08:47:50,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:51,269][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.484636664390564, acc: 0.44999998807907104)
[2024-11-13 08:47:51,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:51,945][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.618424654006958, acc: 0.5405405163764954)
[2024-11-13 08:47:52,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:52,616][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.6979769468307495, acc: 0.4864864945411682)
[2024-11-13 08:47:52,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:53,299][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.7576754093170166, acc: 0.5405405163764954)
[2024-11-13 08:47:53,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:53,985][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 2.2803406715393066, acc: 0.4117647111415863)
[2024-11-13 08:47:54,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:54,663][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 1.3009229898452759, acc: 0.5853658318519592)
[2024-11-13 08:47:54,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:55,332][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 0.6232721209526062, acc: 0.8399999737739563)
[2024-11-13 08:47:55,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:56,003][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.693240225315094, acc: 0.800000011920929)
[2024-11-13 08:47:56,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:56,675][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 1.105743408203125, acc: 0.7096773982048035)
[2024-11-13 08:47:56,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:57,354][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 2.059366226196289, acc: 0.42105263471603394)
[2024-11-13 08:47:57,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:58,028][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 2.0920534133911133, acc: 0.4571428596973419)
[2024-11-13 08:47:58,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:58,708][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.88525390625, acc: 0.5131579041481018)
[2024-11-13 08:47:58,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:47:59,415][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 2.117709159851074, acc: 0.3962264060974121)
[2024-11-13 08:47:59,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:00,127][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 2.1613073348999023, acc: 0.4416666626930237)
[2024-11-13 08:48:00,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:00,800][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 1.7156338691711426, acc: 0.5277777910232544)
[2024-11-13 08:48:00,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:01,472][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 2.179049015045166, acc: 0.3870967626571655)
[2024-11-13 08:48:01,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:02,156][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 2.8006412982940674, acc: 0.36000001430511475)
[2024-11-13 08:48:02,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:02,831][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 2.4354701042175293, acc: 0.3333333432674408)
[2024-11-13 08:48:02,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:03,543][root][INFO] - Training Epoch: 2/10, step 265/574 completed (loss: 2.5144424438476562, acc: 0.328000009059906)
[2024-11-13 08:48:03,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:04,223][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 2.36794114112854, acc: 0.40449437499046326)
[2024-11-13 08:48:04,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:04,906][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 2.3703136444091797, acc: 0.4054054021835327)
[2024-11-13 08:48:04,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:05,588][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 1.6858909130096436, acc: 0.5)
[2024-11-13 08:48:05,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:06,270][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 1.6294595003128052, acc: 0.6363636255264282)
[2024-11-13 08:48:06,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:06,944][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 1.369801640510559, acc: 0.5454545617103577)
[2024-11-13 08:48:07,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:07,619][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 1.2662501335144043, acc: 0.625)
[2024-11-13 08:48:07,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:08,291][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 1.4802207946777344, acc: 0.5666666626930237)
[2024-11-13 08:48:08,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:08,972][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 2.1031224727630615, acc: 0.4166666567325592)
[2024-11-13 08:48:09,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:09,644][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 1.760511875152588, acc: 0.5)
[2024-11-13 08:48:09,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:10,318][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 1.3432445526123047, acc: 0.6333333253860474)
[2024-11-13 08:48:10,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:10,990][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 1.7000588178634644, acc: 0.6206896305084229)
[2024-11-13 08:48:11,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:11,663][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 1.547348976135254, acc: 0.6399999856948853)
[2024-11-13 08:48:11,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:12,343][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 2.3312506675720215, acc: 0.40425533056259155)
[2024-11-13 08:48:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:13,031][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.939794659614563, acc: 0.5208333134651184)
[2024-11-13 08:48:13,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:13,711][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 1.7815062999725342, acc: 0.5909090638160706)
[2024-11-13 08:48:13,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:14,407][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.3104310035705566, acc: 0.3855421543121338)
[2024-11-13 08:48:14,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:15,103][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 2.1226389408111572, acc: 0.46296295523643494)
[2024-11-13 08:48:15,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:15,778][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 2.9066720008850098, acc: 0.21052631735801697)
[2024-11-13 08:48:16,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:17,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:17,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:18,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:19,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:19,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:20,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:20,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:21,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:21,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:22,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:23,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:23,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:24,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:24,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:25,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:26,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:26,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:27,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:27,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:28,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:28,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:29,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:30,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:30,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:31,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:31,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:32,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:33,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:34,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:35,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:35,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:36,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:36,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:37,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:37,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:38,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:39,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:39,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:40,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:41,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:41,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:42,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:42,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:43,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:44,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:44,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:45,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:45,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:46,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:47,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:47,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:48,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:48,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:49,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:49,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:50,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:51,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:51,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:52,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:52,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:53,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:53,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:54,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:55,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:55,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:56,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:56,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:57,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:58,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:58,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:59,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:48:59,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:00,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:00,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:01,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:02,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:02,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:03,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:03,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:04,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:05,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:05,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:06,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:07,300][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.5800, device='cuda:0') eval_epoch_loss=tensor(2.0255, device='cuda:0') eval_epoch_acc=tensor(0.4634, device='cuda:0')
[2024-11-13 08:49:07,301][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:49:07,302][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:49:07,608][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_2_step_284_loss_2.0255095958709717/model.pt
[2024-11-13 08:49:07,611][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:49:07,612][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 2.0255095958709717
[2024-11-13 08:49:07,612][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.4634053409099579
[2024-11-13 08:49:07,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:08,301][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 2.626979112625122, acc: 0.29411765933036804)
[2024-11-13 08:49:08,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:08,975][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 2.1976840496063232, acc: 0.3499999940395355)
[2024-11-13 08:49:09,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:09,671][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.3026463985443115, acc: 0.359375)
[2024-11-13 08:49:09,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:10,375][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 2.5541205406188965, acc: 0.3199999928474426)
[2024-11-13 08:49:10,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:11,057][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 2.178241491317749, acc: 0.4175824224948883)
[2024-11-13 08:49:11,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:11,747][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 2.526992082595825, acc: 0.3478260934352875)
[2024-11-13 08:49:11,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:12,462][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.529951333999634, acc: 0.34536081552505493)
[2024-11-13 08:49:12,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:13,147][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.546043872833252, acc: 0.6363636255264282)
[2024-11-13 08:49:13,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:13,824][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 2.3024439811706543, acc: 0.4523809552192688)
[2024-11-13 08:49:13,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:14,504][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.7403196096420288, acc: 0.6034482717514038)
[2024-11-13 08:49:14,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:15,184][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.413235068321228, acc: 0.6181818246841431)
[2024-11-13 08:49:15,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:15,907][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 1.9586362838745117, acc: 0.5257731676101685)
[2024-11-13 08:49:15,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:16,585][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 2.25274920463562, acc: 0.4482758641242981)
[2024-11-13 08:49:16,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:17,269][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 2.03808856010437, acc: 0.48148149251937866)
[2024-11-13 08:49:17,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:17,946][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 2.1439900398254395, acc: 0.42105263471603394)
[2024-11-13 08:49:18,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:18,622][root][INFO] - Training Epoch: 2/10, step 299/574 completed (loss: 2.059394359588623, acc: 0.5357142686843872)
[2024-11-13 08:49:18,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:19,307][root][INFO] - Training Epoch: 2/10, step 300/574 completed (loss: 2.008018970489502, acc: 0.46875)
[2024-11-13 08:49:19,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:19,986][root][INFO] - Training Epoch: 2/10, step 301/574 completed (loss: 2.1922717094421387, acc: 0.49056604504585266)
[2024-11-13 08:49:20,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:20,661][root][INFO] - Training Epoch: 2/10, step 302/574 completed (loss: 1.4223361015319824, acc: 0.6226415038108826)
[2024-11-13 08:49:20,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:21,345][root][INFO] - Training Epoch: 2/10, step 303/574 completed (loss: 1.442494511604309, acc: 0.5882353186607361)
[2024-11-13 08:49:21,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:22,019][root][INFO] - Training Epoch: 2/10, step 304/574 completed (loss: 2.3906755447387695, acc: 0.375)
[2024-11-13 08:49:22,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:22,701][root][INFO] - Training Epoch: 2/10, step 305/574 completed (loss: 1.7267663478851318, acc: 0.5901639461517334)
[2024-11-13 08:49:22,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:23,372][root][INFO] - Training Epoch: 2/10, step 306/574 completed (loss: 1.0166069269180298, acc: 0.7666666507720947)
[2024-11-13 08:49:23,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:24,042][root][INFO] - Training Epoch: 2/10, step 307/574 completed (loss: 0.7062115669250488, acc: 0.7368420958518982)
[2024-11-13 08:49:24,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:24,735][root][INFO] - Training Epoch: 2/10, step 308/574 completed (loss: 2.2482025623321533, acc: 0.4492753744125366)
[2024-11-13 08:49:24,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:25,421][root][INFO] - Training Epoch: 2/10, step 309/574 completed (loss: 1.9895439147949219, acc: 0.5)
[2024-11-13 08:49:25,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:26,103][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 2.058518648147583, acc: 0.42168673872947693)
[2024-11-13 08:49:26,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:26,784][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 2.2826085090637207, acc: 0.3205128312110901)
[2024-11-13 08:49:26,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:27,493][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 2.4468724727630615, acc: 0.3571428656578064)
[2024-11-13 08:49:27,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:28,167][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.39944514632225037, acc: 0.9166666865348816)
[2024-11-13 08:49:28,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:28,882][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 1.4656094312667847, acc: 0.625)
[2024-11-13 08:49:28,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:29,555][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 1.119749665260315, acc: 0.6451612710952759)
[2024-11-13 08:49:29,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:30,226][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 1.542134165763855, acc: 0.5161290168762207)
[2024-11-13 08:49:30,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:30,910][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 1.6205880641937256, acc: 0.5820895433425903)
[2024-11-13 08:49:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:31,598][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 1.5624446868896484, acc: 0.5865384340286255)
[2024-11-13 08:49:31,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:32,271][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 2.1901001930236816, acc: 0.4000000059604645)
[2024-11-13 08:49:32,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:32,949][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 1.9173437356948853, acc: 0.4032258093357086)
[2024-11-13 08:49:33,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:33,634][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 1.1716220378875732, acc: 0.7200000286102295)
[2024-11-13 08:49:33,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:34,309][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.6157727241516113, acc: 0.40740740299224854)
[2024-11-13 08:49:34,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:34,987][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.733948230743408, acc: 0.17142857611179352)
[2024-11-13 08:49:35,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:35,659][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 2.7165768146514893, acc: 0.28205129504203796)
[2024-11-13 08:49:35,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:36,340][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 2.7149674892425537, acc: 0.39024388790130615)
[2024-11-13 08:49:36,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:37,016][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.27878999710083, acc: 0.44736841320991516)
[2024-11-13 08:49:37,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:37,687][root][INFO] - Training Epoch: 2/10, step 327/574 completed (loss: 1.539485216140747, acc: 0.5263158082962036)
[2024-11-13 08:49:37,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:38,357][root][INFO] - Training Epoch: 2/10, step 328/574 completed (loss: 1.0774801969528198, acc: 0.7142857313156128)
[2024-11-13 08:49:38,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:39,029][root][INFO] - Training Epoch: 2/10, step 329/574 completed (loss: 2.2275052070617676, acc: 0.40740740299224854)
[2024-11-13 08:49:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:39,701][root][INFO] - Training Epoch: 2/10, step 330/574 completed (loss: 1.1755008697509766, acc: 0.65625)
[2024-11-13 08:49:39,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:40,379][root][INFO] - Training Epoch: 2/10, step 331/574 completed (loss: 2.1600966453552246, acc: 0.35483869910240173)
[2024-11-13 08:49:40,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:41,060][root][INFO] - Training Epoch: 2/10, step 332/574 completed (loss: 1.795976996421814, acc: 0.5614035129547119)
[2024-11-13 08:49:41,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:41,731][root][INFO] - Training Epoch: 2/10, step 333/574 completed (loss: 2.465635061264038, acc: 0.34375)
[2024-11-13 08:49:41,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:42,403][root][INFO] - Training Epoch: 2/10, step 334/574 completed (loss: 1.6197562217712402, acc: 0.5666666626930237)
[2024-11-13 08:49:42,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:43,098][root][INFO] - Training Epoch: 2/10, step 335/574 completed (loss: 2.0676186084747314, acc: 0.42105263471603394)
[2024-11-13 08:49:43,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:43,782][root][INFO] - Training Epoch: 2/10, step 336/574 completed (loss: 2.2277517318725586, acc: 0.41999998688697815)
[2024-11-13 08:49:43,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:44,464][root][INFO] - Training Epoch: 2/10, step 337/574 completed (loss: 2.2340965270996094, acc: 0.36781609058380127)
[2024-11-13 08:49:44,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:45,146][root][INFO] - Training Epoch: 2/10, step 338/574 completed (loss: 2.342808246612549, acc: 0.38297873735427856)
[2024-11-13 08:49:45,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:45,833][root][INFO] - Training Epoch: 2/10, step 339/574 completed (loss: 2.3923850059509277, acc: 0.42168673872947693)
[2024-11-13 08:49:45,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:46,513][root][INFO] - Training Epoch: 2/10, step 340/574 completed (loss: 1.3208543062210083, acc: 0.5652173757553101)
[2024-11-13 08:49:46,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:47,187][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 2.28434681892395, acc: 0.43589743971824646)
[2024-11-13 08:49:47,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:47,865][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 2.530444860458374, acc: 0.34939759969711304)
[2024-11-13 08:49:47,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:48,546][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 1.8869725465774536, acc: 0.5094339847564697)
[2024-11-13 08:49:48,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:49,227][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 2.349393129348755, acc: 0.40506330132484436)
[2024-11-13 08:49:49,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:49,903][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 2.2664051055908203, acc: 0.3921568691730499)
[2024-11-13 08:49:49,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:50,588][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.582397937774658, acc: 0.2985074520111084)
[2024-11-13 08:49:50,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:51,261][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 1.399813175201416, acc: 0.6499999761581421)
[2024-11-13 08:49:51,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:51,933][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 1.6510008573532104, acc: 0.47999998927116394)
[2024-11-13 08:49:52,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:52,617][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.5693541765213013, acc: 0.6111111044883728)
[2024-11-13 08:49:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:53,305][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.9845433235168457, acc: 0.5348837375640869)
[2024-11-13 08:49:53,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:53,987][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 2.1340010166168213, acc: 0.4615384638309479)
[2024-11-13 08:49:54,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:54,667][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 1.951844573020935, acc: 0.42222222685813904)
[2024-11-13 08:49:54,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:55,341][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 1.021589994430542, acc: 0.695652186870575)
[2024-11-13 08:49:55,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:56,017][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.636012077331543, acc: 0.42307692766189575)
[2024-11-13 08:49:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:56,700][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.6268086433410645, acc: 0.3186813294887543)
[2024-11-13 08:49:56,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:57,403][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 2.0050947666168213, acc: 0.417391300201416)
[2024-11-13 08:49:57,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:58,083][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 2.155884027481079, acc: 0.41304346919059753)
[2024-11-13 08:49:58,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:58,772][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 2.1792819499969482, acc: 0.4285714328289032)
[2024-11-13 08:49:58,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:49:59,451][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.4419802725315094, acc: 0.875)
[2024-11-13 08:49:59,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:00,125][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 1.0978509187698364, acc: 0.6538461446762085)
[2024-11-13 08:50:00,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:00,801][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.8150501251220703, acc: 0.5853658318519592)
[2024-11-13 08:50:00,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:01,475][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 2.0672123432159424, acc: 0.46666666865348816)
[2024-11-13 08:50:01,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:02,157][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 2.180481195449829, acc: 0.3552631437778473)
[2024-11-13 08:50:02,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:02,836][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 2.0961122512817383, acc: 0.5121951103210449)
[2024-11-13 08:50:02,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:03,523][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 1.980556845664978, acc: 0.42424243688583374)
[2024-11-13 08:50:03,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:04,195][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.9260912537574768, acc: 0.75)
[2024-11-13 08:50:04,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:04,866][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.556974470615387, acc: 0.8695651888847351)
[2024-11-13 08:50:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:05,544][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.975455105304718, acc: 0.7142857313156128)
[2024-11-13 08:50:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:06,224][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.4949593544006348, acc: 0.5)
[2024-11-13 08:50:06,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:06,934][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 2.045590877532959, acc: 0.49696969985961914)
[2024-11-13 08:50:07,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:07,646][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.5745182037353516, acc: 0.6320754885673523)
[2024-11-13 08:50:07,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:08,332][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.876272439956665, acc: 0.5111111402511597)
[2024-11-13 08:50:08,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:09,020][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 1.980047583580017, acc: 0.5)
[2024-11-13 08:50:09,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:09,698][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 1.1062521934509277, acc: 0.6285714507102966)
[2024-11-13 08:50:09,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:10,367][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.4068286120891571, acc: 0.9200000166893005)
[2024-11-13 08:50:10,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:11,036][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.9121767282485962, acc: 0.695652186870575)
[2024-11-13 08:50:11,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:11,715][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 2.2409260272979736, acc: 0.3125)
[2024-11-13 08:50:11,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:12,397][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 1.8898892402648926, acc: 0.5684210658073425)
[2024-11-13 08:50:12,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:13,099][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 1.9102863073349, acc: 0.5029940009117126)
[2024-11-13 08:50:13,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:13,784][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.8210995197296143, acc: 0.49624061584472656)
[2024-11-13 08:50:13,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:14,502][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.8603408336639404, acc: 0.49197861552238464)
[2024-11-13 08:50:14,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:15,206][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 1.5851105451583862, acc: 0.5855855941772461)
[2024-11-13 08:50:15,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:15,878][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 1.1735498905181885, acc: 0.6071428656578064)
[2024-11-13 08:50:15,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:16,549][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 0.9407672882080078, acc: 0.7857142686843872)
[2024-11-13 08:50:16,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:17,224][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 1.5681281089782715, acc: 0.5625)
[2024-11-13 08:50:17,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:17,896][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 1.7469229698181152, acc: 0.4722222089767456)
[2024-11-13 08:50:17,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:18,579][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 1.5250275135040283, acc: 0.5526315569877625)
[2024-11-13 08:50:18,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:19,253][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.9732035994529724, acc: 0.6818181872367859)
[2024-11-13 08:50:19,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:19,936][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 1.4052202701568604, acc: 0.699999988079071)
[2024-11-13 08:50:20,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:20,608][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.1740095615386963, acc: 0.7142857313156128)
[2024-11-13 08:50:20,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:21,286][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 2.5096261501312256, acc: 0.42592594027519226)
[2024-11-13 08:50:21,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:21,969][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 2.5417959690093994, acc: 0.3980582654476166)
[2024-11-13 08:50:22,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:22,680][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 2.11736798286438, acc: 0.5147058963775635)
[2024-11-13 08:50:22,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:23,376][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 2.448819875717163, acc: 0.40666666626930237)
[2024-11-13 08:50:23,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:24,066][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 2.227313995361328, acc: 0.4652777910232544)
[2024-11-13 08:50:24,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:24,742][root][INFO] - Training Epoch: 2/10, step 396/574 completed (loss: 2.182304620742798, acc: 0.5581395626068115)
[2024-11-13 08:50:24,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:25,418][root][INFO] - Training Epoch: 2/10, step 397/574 completed (loss: 1.1823103427886963, acc: 0.75)
[2024-11-13 08:50:25,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:26,094][root][INFO] - Training Epoch: 2/10, step 398/574 completed (loss: 1.5706071853637695, acc: 0.604651153087616)
[2024-11-13 08:50:26,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:26,776][root][INFO] - Training Epoch: 2/10, step 399/574 completed (loss: 1.9319329261779785, acc: 0.4000000059604645)
[2024-11-13 08:50:26,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:27,463][root][INFO] - Training Epoch: 2/10, step 400/574 completed (loss: 2.0125107765197754, acc: 0.5)
[2024-11-13 08:50:27,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:28,144][root][INFO] - Training Epoch: 2/10, step 401/574 completed (loss: 1.8394067287445068, acc: 0.54666668176651)
[2024-11-13 08:50:28,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:28,823][root][INFO] - Training Epoch: 2/10, step 402/574 completed (loss: 1.353790044784546, acc: 0.6666666865348816)
[2024-11-13 08:50:28,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:29,504][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 1.6355059146881104, acc: 0.5757575631141663)
[2024-11-13 08:50:29,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:30,175][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 0.9447363615036011, acc: 0.7419354915618896)
[2024-11-13 08:50:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:30,847][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 1.609895944595337, acc: 0.5925925970077515)
[2024-11-13 08:50:30,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:31,525][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 1.0682024955749512, acc: 0.7200000286102295)
[2024-11-13 08:50:31,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:32,208][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 1.1081019639968872, acc: 0.6388888955116272)
[2024-11-13 08:50:32,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:32,883][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 1.034246563911438, acc: 0.7037037014961243)
[2024-11-13 08:50:32,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:33,561][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 1.2772297859191895, acc: 0.692307710647583)
[2024-11-13 08:50:33,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:34,239][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.4920274019241333, acc: 0.6379310488700867)
[2024-11-13 08:50:34,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:34,910][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 1.223204493522644, acc: 0.7142857313156128)
[2024-11-13 08:50:34,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:35,629][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 1.250662088394165, acc: 0.6666666865348816)
[2024-11-13 08:50:35,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:36,301][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.3316237926483154, acc: 0.6666666865348816)
[2024-11-13 08:50:36,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:36,972][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 1.5002732276916504, acc: 0.5454545617103577)
[2024-11-13 08:50:37,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:37,652][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 2.107110023498535, acc: 0.4901960790157318)
[2024-11-13 08:50:37,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:38,334][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 1.743398666381836, acc: 0.6153846383094788)
[2024-11-13 08:50:38,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:39,017][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 1.6679495573043823, acc: 0.6111111044883728)
[2024-11-13 08:50:39,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:39,699][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 1.6387608051300049, acc: 0.6000000238418579)
[2024-11-13 08:50:39,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:40,380][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 2.444211483001709, acc: 0.4000000059604645)
[2024-11-13 08:50:40,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:41,054][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.832333505153656, acc: 0.7142857313156128)
[2024-11-13 08:50:41,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:41,723][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.6639094352722168, acc: 0.4333333373069763)
[2024-11-13 08:50:41,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:42,398][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.2723504304885864, acc: 0.65625)
[2024-11-13 08:50:42,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:43,089][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 1.6462047100067139, acc: 0.5)
[2024-11-13 08:50:43,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:43,762][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 1.036508321762085, acc: 0.5925925970077515)
[2024-11-13 08:50:43,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:44,449][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 1.1613420248031616, acc: 0.7575757503509521)
[2024-11-13 08:50:44,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:45,121][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 0.8573044538497925, acc: 0.739130437374115)
[2024-11-13 08:50:46,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:46,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:47,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:47,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:48,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:49,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:49,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:50,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:50,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:51,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:51,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:52,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:53,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:53,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:54,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:54,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:55,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:56,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:56,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:57,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:57,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:58,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:58,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:50:59,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:00,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:00,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:01,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:02,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:03,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:04,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:04,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:05,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:06,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:06,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:07,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:07,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:08,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:09,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:09,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:10,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:10,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:11,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:12,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:12,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:13,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:13,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:14,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:15,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:15,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:16,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:16,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:17,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:18,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:18,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:19,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:19,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:20,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:20,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:21,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:22,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:22,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:23,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:23,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:24,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:25,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:25,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:26,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:26,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:27,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:28,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:28,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:29,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:29,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:30,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:31,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:31,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:32,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:32,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:33,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:34,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:34,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:35,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:35,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:36,779][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.9353, device='cuda:0') eval_epoch_loss=tensor(2.0713, device='cuda:0') eval_epoch_acc=tensor(0.4574, device='cuda:0')
[2024-11-13 08:51:36,780][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:51:36,780][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:51:37,226][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_2_step_427_loss_2.0713229179382324/model.pt
[2024-11-13 08:51:37,235][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:51:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:37,952][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 1.2033672332763672, acc: 0.6756756901741028)
[2024-11-13 08:51:38,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:38,637][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 0.8204880356788635, acc: 0.7777777910232544)
[2024-11-13 08:51:38,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:39,314][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 1.8695929050445557, acc: 0.52173912525177)
[2024-11-13 08:51:39,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:39,998][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.8173453211784363, acc: 0.7037037014961243)
[2024-11-13 08:51:40,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:40,674][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.720185399055481, acc: 0.7777777910232544)
[2024-11-13 08:51:40,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:41,355][root][INFO] - Training Epoch: 2/10, step 432/574 completed (loss: 1.7044674158096313, acc: 0.6086956262588501)
[2024-11-13 08:51:41,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:42,028][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 1.3479105234146118, acc: 0.6666666865348816)
[2024-11-13 08:51:42,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:42,700][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 0.6526356339454651, acc: 0.800000011920929)
[2024-11-13 08:51:42,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:43,374][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 1.2638089656829834, acc: 0.6969696879386902)
[2024-11-13 08:51:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:44,051][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 1.4782490730285645, acc: 0.6111111044883728)
[2024-11-13 08:51:44,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:44,732][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 1.3472057580947876, acc: 0.6818181872367859)
[2024-11-13 08:51:44,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:45,407][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.5644181370735168, acc: 0.8095238208770752)
[2024-11-13 08:51:45,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:46,088][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 2.1438581943511963, acc: 0.5384615659713745)
[2024-11-13 08:51:46,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:46,778][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 2.066833019256592, acc: 0.4545454680919647)
[2024-11-13 08:51:46,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:47,485][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.5683560371398926, acc: 0.35199999809265137)
[2024-11-13 08:51:47,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:48,182][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.337963342666626, acc: 0.3790322542190552)
[2024-11-13 08:51:48,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:48,893][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 2.333946466445923, acc: 0.4129353165626526)
[2024-11-13 08:51:48,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:49,587][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 2.2343533039093018, acc: 0.4528301954269409)
[2024-11-13 08:51:49,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:50,270][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.3786660432815552, acc: 0.6590909361839294)
[2024-11-13 08:51:50,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:50,947][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 1.6348466873168945, acc: 0.5652173757553101)
[2024-11-13 08:51:51,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:51,633][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.7126375436782837, acc: 0.5384615659713745)
[2024-11-13 08:51:51,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:52,308][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 1.152315378189087, acc: 0.7142857313156128)
[2024-11-13 08:51:52,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:52,987][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 2.128600835800171, acc: 0.49253731966018677)
[2024-11-13 08:51:53,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:53,666][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 1.9243414402008057, acc: 0.4722222089767456)
[2024-11-13 08:51:53,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:54,348][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 2.126730442047119, acc: 0.41304346919059753)
[2024-11-13 08:51:54,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:55,026][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 2.2171883583068848, acc: 0.42307692766189575)
[2024-11-13 08:51:55,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:55,708][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 2.2324633598327637, acc: 0.3684210479259491)
[2024-11-13 08:51:55,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:56,411][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.7985535860061646, acc: 0.5510203838348389)
[2024-11-13 08:51:56,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:57,090][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.74031400680542, acc: 0.5151515007019043)
[2024-11-13 08:51:57,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:57,776][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 2.1521031856536865, acc: 0.34020617604255676)
[2024-11-13 08:51:57,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:58,456][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.9850271940231323, acc: 0.4571428596973419)
[2024-11-13 08:51:58,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:59,184][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 2.18098521232605, acc: 0.4011628031730652)
[2024-11-13 08:51:59,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:51:59,865][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 2.3539884090423584, acc: 0.375)
[2024-11-13 08:51:59,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:00,556][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 2.1323444843292236, acc: 0.4197530746459961)
[2024-11-13 08:52:00,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:01,231][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.9312520027160645, acc: 0.5555555820465088)
[2024-11-13 08:52:01,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:01,902][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 1.6074872016906738, acc: 0.59375)
[2024-11-13 08:52:02,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:02,575][root][INFO] - Training Epoch: 2/10, step 463/574 completed (loss: 1.7652511596679688, acc: 0.5769230723381042)
[2024-11-13 08:52:02,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:03,254][root][INFO] - Training Epoch: 2/10, step 464/574 completed (loss: 1.9999648332595825, acc: 0.5)
[2024-11-13 08:52:03,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:03,942][root][INFO] - Training Epoch: 2/10, step 465/574 completed (loss: 2.0110743045806885, acc: 0.369047611951828)
[2024-11-13 08:52:04,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:04,625][root][INFO] - Training Epoch: 2/10, step 466/574 completed (loss: 2.194762945175171, acc: 0.4457831382751465)
[2024-11-13 08:52:04,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:05,331][root][INFO] - Training Epoch: 2/10, step 467/574 completed (loss: 1.9072829484939575, acc: 0.4864864945411682)
[2024-11-13 08:52:05,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:06,016][root][INFO] - Training Epoch: 2/10, step 468/574 completed (loss: 2.066779613494873, acc: 0.48543688654899597)
[2024-11-13 08:52:06,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:06,732][root][INFO] - Training Epoch: 2/10, step 469/574 completed (loss: 1.8635385036468506, acc: 0.5284552574157715)
[2024-11-13 08:52:06,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:07,407][root][INFO] - Training Epoch: 2/10, step 470/574 completed (loss: 1.5342212915420532, acc: 0.625)
[2024-11-13 08:52:07,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:08,081][root][INFO] - Training Epoch: 2/10, step 471/574 completed (loss: 2.635570764541626, acc: 0.4285714328289032)
[2024-11-13 08:52:08,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:08,790][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 2.3588085174560547, acc: 0.3529411852359772)
[2024-11-13 08:52:08,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:09,500][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 2.3797781467437744, acc: 0.4104803502559662)
[2024-11-13 08:52:09,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:10,191][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 2.203153371810913, acc: 0.4166666567325592)
[2024-11-13 08:52:10,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:10,882][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 2.2547035217285156, acc: 0.38650307059288025)
[2024-11-13 08:52:10,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:11,570][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 2.2635586261749268, acc: 0.40287768840789795)
[2024-11-13 08:52:11,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:12,275][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 2.327211618423462, acc: 0.3919597864151001)
[2024-11-13 08:52:12,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:12,950][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.6827566623687744, acc: 0.5555555820465088)
[2024-11-13 08:52:13,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:13,625][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.7712273597717285, acc: 0.4848484992980957)
[2024-11-13 08:52:13,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:14,298][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.4262677431106567, acc: 0.6296296119689941)
[2024-11-13 08:52:14,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:14,970][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.6225608587265015, acc: 0.6000000238418579)
[2024-11-13 08:52:15,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:15,659][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 0.8889912366867065, acc: 0.699999988079071)
[2024-11-13 08:52:15,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:16,346][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.7085257768630981, acc: 0.5517241358757019)
[2024-11-13 08:52:16,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:17,022][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 1.4394261837005615, acc: 0.6774193644523621)
[2024-11-13 08:52:17,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:17,697][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 0.9556275606155396, acc: 0.7894737124443054)
[2024-11-13 08:52:17,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:18,371][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 2.2003657817840576, acc: 0.4444444477558136)
[2024-11-13 08:52:18,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:19,045][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 2.24798583984375, acc: 0.380952388048172)
[2024-11-13 08:52:19,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:19,718][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 1.4880965948104858, acc: 0.4545454680919647)
[2024-11-13 08:52:19,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:20,402][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 2.033964157104492, acc: 0.4615384638309479)
[2024-11-13 08:52:20,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:21,078][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 1.3181177377700806, acc: 0.6333333253860474)
[2024-11-13 08:52:21,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:21,753][root][INFO] - Training Epoch: 2/10, step 491/574 completed (loss: 1.6174710988998413, acc: 0.5517241358757019)
[2024-11-13 08:52:21,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:22,430][root][INFO] - Training Epoch: 2/10, step 492/574 completed (loss: 2.066951036453247, acc: 0.4117647111415863)
[2024-11-13 08:52:22,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:23,103][root][INFO] - Training Epoch: 2/10, step 493/574 completed (loss: 1.7104368209838867, acc: 0.517241358757019)
[2024-11-13 08:52:23,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:23,777][root][INFO] - Training Epoch: 2/10, step 494/574 completed (loss: 0.835279643535614, acc: 0.7368420958518982)
[2024-11-13 08:52:23,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:24,452][root][INFO] - Training Epoch: 2/10, step 495/574 completed (loss: 2.786301851272583, acc: 0.2631579041481018)
[2024-11-13 08:52:24,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:25,142][root][INFO] - Training Epoch: 2/10, step 496/574 completed (loss: 1.866658329963684, acc: 0.4553571343421936)
[2024-11-13 08:52:25,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:25,829][root][INFO] - Training Epoch: 2/10, step 497/574 completed (loss: 1.9505587816238403, acc: 0.43820226192474365)
[2024-11-13 08:52:25,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:26,514][root][INFO] - Training Epoch: 2/10, step 498/574 completed (loss: 2.2055132389068604, acc: 0.4157303273677826)
[2024-11-13 08:52:26,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:27,221][root][INFO] - Training Epoch: 2/10, step 499/574 completed (loss: 2.350255250930786, acc: 0.3617021143436432)
[2024-11-13 08:52:27,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:27,919][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 2.259510040283203, acc: 0.3804347813129425)
[2024-11-13 08:52:28,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:28,595][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.6458601355552673, acc: 0.9200000166893005)
[2024-11-13 08:52:28,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:29,279][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 0.9990958571434021, acc: 0.692307710647583)
[2024-11-13 08:52:29,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:29,954][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 0.7149612307548523, acc: 0.7407407164573669)
[2024-11-13 08:52:30,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:30,626][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 1.5771287679672241, acc: 0.5555555820465088)
[2024-11-13 08:52:30,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:31,308][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.6093560457229614, acc: 0.5471698045730591)
[2024-11-13 08:52:31,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:31,982][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.254895806312561, acc: 0.7586206793785095)
[2024-11-13 08:52:32,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:32,684][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 2.0515153408050537, acc: 0.4324324429035187)
[2024-11-13 08:52:32,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:33,369][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.8401358127593994, acc: 0.5352112650871277)
[2024-11-13 08:52:33,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:34,040][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.33560025691986084, acc: 0.8999999761581421)
[2024-11-13 08:52:34,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:34,714][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.7545455694198608, acc: 0.800000011920929)
[2024-11-13 08:52:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:35,383][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 1.0199426412582397, acc: 0.7692307829856873)
[2024-11-13 08:52:35,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:36,118][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.034620523452759, acc: 0.44999998807907104)
[2024-11-13 08:52:36,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:36,831][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 2.0080976486206055, acc: 0.4920634925365448)
[2024-11-13 08:52:36,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:37,520][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.8092193603515625, acc: 0.5714285969734192)
[2024-11-13 08:52:37,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:38,205][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 1.7161345481872559, acc: 0.5333333611488342)
[2024-11-13 08:52:38,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:38,892][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.8244471549987793, acc: 0.5138888955116272)
[2024-11-13 08:52:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:39,563][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.42304691672325134, acc: 0.807692289352417)
[2024-11-13 08:52:39,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:40,236][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 1.6721282005310059, acc: 0.5806451439857483)
[2024-11-13 08:52:40,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:40,900][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 2.5078585147857666, acc: 0.3499999940395355)
[2024-11-13 08:52:40,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:41,572][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 2.309537887573242, acc: 0.40740740299224854)
[2024-11-13 08:52:41,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:42,477][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 2.168457269668579, acc: 0.4237288236618042)
[2024-11-13 08:52:42,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:43,186][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 2.412067174911499, acc: 0.38805970549583435)
[2024-11-13 08:52:43,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:43,874][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 2.2572596073150635, acc: 0.40145984292030334)
[2024-11-13 08:52:43,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:44,599][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 1.9678645133972168, acc: 0.4449999928474426)
[2024-11-13 08:52:44,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:45,284][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 2.113161325454712, acc: 0.5)
[2024-11-13 08:52:45,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:45,965][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 1.7690317630767822, acc: 0.5)
[2024-11-13 08:52:46,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:46,635][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 2.3060288429260254, acc: 0.2857142984867096)
[2024-11-13 08:52:46,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:47,319][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.7057907581329346, acc: 0.24590164422988892)
[2024-11-13 08:52:47,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:48,001][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 1.970915675163269, acc: 0.508474588394165)
[2024-11-13 08:52:48,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:48,678][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.282806634902954, acc: 0.41860464215278625)
[2024-11-13 08:52:48,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:49,353][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 2.2027204036712646, acc: 0.4318181872367859)
[2024-11-13 08:52:49,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:50,033][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.4564461708068848, acc: 0.37735849618911743)
[2024-11-13 08:52:50,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:50,711][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.9380682706832886, acc: 0.5454545617103577)
[2024-11-13 08:52:50,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:51,387][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.6736938953399658, acc: 0.6000000238418579)
[2024-11-13 08:52:51,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:52,062][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 1.6264652013778687, acc: 0.6000000238418579)
[2024-11-13 08:52:52,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:52,734][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 1.3915499448776245, acc: 0.5454545617103577)
[2024-11-13 08:52:52,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:53,416][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 1.8252745866775513, acc: 0.5692307949066162)
[2024-11-13 08:52:53,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:54,101][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 1.807051658630371, acc: 0.5625)
[2024-11-13 08:52:54,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:54,780][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 1.1121746301651, acc: 0.71875)
[2024-11-13 08:52:54,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:55,457][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 1.7736518383026123, acc: 0.4545454680919647)
[2024-11-13 08:52:55,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:56,127][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.7903206944465637, acc: 0.8125)
[2024-11-13 08:52:56,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:56,799][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 0.9557371735572815, acc: 0.6774193644523621)
[2024-11-13 08:52:56,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:57,468][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.6623938083648682, acc: 0.782608687877655)
[2024-11-13 08:52:57,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:58,140][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 2.0995047092437744, acc: 0.4000000059604645)
[2024-11-13 08:52:58,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:58,817][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 1.495753526687622, acc: 0.4878048896789551)
[2024-11-13 08:52:58,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:52:59,499][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 0.9229523539543152, acc: 0.7428571581840515)
[2024-11-13 08:52:59,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:00,180][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 1.4380409717559814, acc: 0.6315789222717285)
[2024-11-13 08:53:00,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:00,857][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 1.2754093408584595, acc: 0.6774193644523621)
[2024-11-13 08:53:00,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:01,529][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.6718530058860779, acc: 0.8399999737739563)
[2024-11-13 08:53:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:02,207][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 1.3545849323272705, acc: 0.6363636255264282)
[2024-11-13 08:53:02,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:02,885][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 1.1300101280212402, acc: 0.7250000238418579)
[2024-11-13 08:53:02,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:03,564][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 1.3684414625167847, acc: 0.5714285969734192)
[2024-11-13 08:53:03,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:04,266][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 2.430781126022339, acc: 0.37956205010414124)
[2024-11-13 08:53:04,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:04,971][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.953728199005127, acc: 0.4689655303955078)
[2024-11-13 08:53:05,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:05,663][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 2.691746950149536, acc: 0.3142857253551483)
[2024-11-13 08:53:05,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:06,357][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 2.390813112258911, acc: 0.3178808093070984)
[2024-11-13 08:53:06,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:07,043][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 2.0066585540771484, acc: 0.470085471868515)
[2024-11-13 08:53:07,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:07,725][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.5295072793960571, acc: 0.8799999952316284)
[2024-11-13 08:53:07,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:08,402][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 1.4197031259536743, acc: 0.6153846383094788)
[2024-11-13 08:53:08,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:09,073][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.8432687520980835, acc: 0.7692307829856873)
[2024-11-13 08:53:09,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:09,751][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.4186164140701294, acc: 0.6153846383094788)
[2024-11-13 08:53:09,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:10,453][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.7314870357513428, acc: 0.5111111402511597)
[2024-11-13 08:53:10,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:11,149][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.9179025888442993, acc: 0.4285714328289032)
[2024-11-13 08:53:11,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:11,825][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 1.629870057106018, acc: 0.5625)
[2024-11-13 08:53:11,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:12,509][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 1.6935441493988037, acc: 0.5517241358757019)
[2024-11-13 08:53:12,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:13,197][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.8617289066314697, acc: 0.488095223903656)
[2024-11-13 08:53:13,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:13,872][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 1.6050971746444702, acc: 0.5789473652839661)
[2024-11-13 08:53:13,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:14,547][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 1.6025718450546265, acc: 0.5185185074806213)
[2024-11-13 08:53:14,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:15,274][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 2.003769874572754, acc: 0.4385026693344116)
[2024-11-13 08:53:16,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:16,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:17,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:17,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:18,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:19,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:19,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:20,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:20,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:21,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:22,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:22,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:23,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:23,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:24,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:25,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:25,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:26,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:26,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:27,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:27,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:28,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:29,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:29,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:30,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:30,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:31,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:32,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:32,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:33,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:33,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:34,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:35,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:35,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:36,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:36,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:37,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:38,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:38,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:39,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:39,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:40,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:41,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:41,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:42,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:42,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:43,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:43,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:44,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:45,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:45,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:46,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:46,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:47,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:48,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:48,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:49,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:49,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:50,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:51,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:51,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:52,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:52,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:53,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:54,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:54,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:55,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:55,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:56,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:57,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:57,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:58,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:58,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:59,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:53:59,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:00,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:01,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:01,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:02,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:02,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:03,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:04,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:04,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:05,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:05,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:06,844][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.3098, device='cuda:0') eval_epoch_loss=tensor(1.8421, device='cuda:0') eval_epoch_acc=tensor(0.5204, device='cuda:0')
[2024-11-13 08:54:06,845][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:54:06,845][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:54:07,242][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_2_step_570_loss_1.8420990705490112/model.pt
[2024-11-13 08:54:07,245][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:54:07,246][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.8420990705490112
[2024-11-13 08:54:07,246][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.5204394459724426
[2024-11-13 08:54:07,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:07,946][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 1.4245946407318115, acc: 0.5967742204666138)
[2024-11-13 08:54:08,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:08,636][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 2.090207099914551, acc: 0.43589743971824646)
[2024-11-13 08:54:08,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:09,342][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 2.3731424808502197, acc: 0.36734694242477417)
[2024-11-13 08:54:09,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:10,049][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 2.319533586502075, acc: 0.3333333432674408)
[2024-11-13 08:54:10,458][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=6.5563, train_epoch_loss=1.8804, epoch time 604.4075053539127s
[2024-11-13 08:54:10,458][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 08:54:10,458][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 08:54:10,458][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 08:54:10,458][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 2
[2024-11-13 08:54:10,458][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 08:54:11,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:11,809][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.5704370737075806, acc: 0.4444444477558136)
[2024-11-13 08:54:11,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:12,499][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 2.048135757446289, acc: 0.47999998927116394)
[2024-11-13 08:54:12,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:13,184][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 2.656609535217285, acc: 0.3513513505458832)
[2024-11-13 08:54:13,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:13,870][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 2.1175010204315186, acc: 0.3684210479259491)
[2024-11-13 08:54:13,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:14,562][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 1.9301356077194214, acc: 0.5135135054588318)
[2024-11-13 08:54:14,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:15,248][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 1.8796768188476562, acc: 0.4285714328289032)
[2024-11-13 08:54:15,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:15,936][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 2.236454486846924, acc: 0.4285714328289032)
[2024-11-13 08:54:16,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:16,622][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 1.7398991584777832, acc: 0.6666666865348816)
[2024-11-13 08:54:16,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:17,308][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.4030175507068634, acc: 0.9090909361839294)
[2024-11-13 08:54:17,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:17,995][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.6896686553955078, acc: 0.8461538553237915)
[2024-11-13 08:54:18,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:18,681][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 0.961986780166626, acc: 0.6666666865348816)
[2024-11-13 08:54:18,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:19,368][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 1.9630212783813477, acc: 0.4615384638309479)
[2024-11-13 08:54:19,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:20,052][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 1.6398296356201172, acc: 0.4848484992980957)
[2024-11-13 08:54:20,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:20,746][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 1.7879525423049927, acc: 0.5)
[2024-11-13 08:54:20,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:21,445][root][INFO] - Training Epoch: 3/10, step 14/574 completed (loss: 2.1699862480163574, acc: 0.4901960790157318)
[2024-11-13 08:54:21,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:22,133][root][INFO] - Training Epoch: 3/10, step 15/574 completed (loss: 1.7052501440048218, acc: 0.5918367505073547)
[2024-11-13 08:54:22,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:22,818][root][INFO] - Training Epoch: 3/10, step 16/574 completed (loss: 0.7610344886779785, acc: 0.7894737124443054)
[2024-11-13 08:54:22,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:23,501][root][INFO] - Training Epoch: 3/10, step 17/574 completed (loss: 1.6349719762802124, acc: 0.5416666865348816)
[2024-11-13 08:54:23,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:24,193][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 1.9786016941070557, acc: 0.4722222089767456)
[2024-11-13 08:54:24,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:24,876][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 1.3063498735427856, acc: 0.6315789222717285)
[2024-11-13 08:54:24,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:25,567][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 1.5315169095993042, acc: 0.5769230723381042)
[2024-11-13 08:54:25,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:26,263][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 1.8150553703308105, acc: 0.5517241358757019)
[2024-11-13 08:54:26,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:26,957][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 1.7648526430130005, acc: 0.5199999809265137)
[2024-11-13 08:54:27,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:27,656][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 1.0421850681304932, acc: 0.7142857313156128)
[2024-11-13 08:54:27,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:28,339][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 1.770671010017395, acc: 0.5)
[2024-11-13 08:54:28,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:29,035][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 2.4996204376220703, acc: 0.30188679695129395)
[2024-11-13 08:54:29,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:29,728][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 2.2548561096191406, acc: 0.4383561611175537)
[2024-11-13 08:54:29,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:30,531][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.3471062183380127, acc: 0.36758893728256226)
[2024-11-13 08:54:30,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:31,217][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 2.1714696884155273, acc: 0.44186046719551086)
[2024-11-13 08:54:31,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:31,910][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 2.0771360397338867, acc: 0.46987950801849365)
[2024-11-13 08:54:31,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:32,618][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 2.013000249862671, acc: 0.40740740299224854)
[2024-11-13 08:54:32,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:33,303][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 2.1869709491729736, acc: 0.4642857015132904)
[2024-11-13 08:54:33,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:33,984][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 1.4807581901550293, acc: 0.5555555820465088)
[2024-11-13 08:54:34,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:34,667][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 1.4283545017242432, acc: 0.52173912525177)
[2024-11-13 08:54:34,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:35,369][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 2.0516018867492676, acc: 0.47058823704719543)
[2024-11-13 08:54:35,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:36,059][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 1.7337523698806763, acc: 0.4754098355770111)
[2024-11-13 08:54:36,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:36,755][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 2.046149492263794, acc: 0.4920634925365448)
[2024-11-13 08:54:36,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:37,445][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 2.101586103439331, acc: 0.38983049988746643)
[2024-11-13 08:54:37,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:38,139][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 1.4135980606079102, acc: 0.6436781883239746)
[2024-11-13 08:54:38,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:38,832][root][INFO] - Training Epoch: 3/10, step 39/574 completed (loss: 1.0715471506118774, acc: 0.6666666865348816)
[2024-11-13 08:54:38,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:39,526][root][INFO] - Training Epoch: 3/10, step 40/574 completed (loss: 2.053035259246826, acc: 0.42307692766189575)
[2024-11-13 08:54:39,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:40,223][root][INFO] - Training Epoch: 3/10, step 41/574 completed (loss: 2.4405908584594727, acc: 0.4189189076423645)
[2024-11-13 08:54:40,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:40,916][root][INFO] - Training Epoch: 3/10, step 42/574 completed (loss: 1.8307019472122192, acc: 0.5538461804389954)
[2024-11-13 08:54:40,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:41,608][root][INFO] - Training Epoch: 3/10, step 43/574 completed (loss: 2.094459056854248, acc: 0.5353535413742065)
[2024-11-13 08:54:41,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:42,314][root][INFO] - Training Epoch: 3/10, step 44/574 completed (loss: 1.9226865768432617, acc: 0.4845360815525055)
[2024-11-13 08:54:42,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:43,016][root][INFO] - Training Epoch: 3/10, step 45/574 completed (loss: 2.1269795894622803, acc: 0.47058823704719543)
[2024-11-13 08:54:43,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:43,696][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.5966120362281799, acc: 0.8846153616905212)
[2024-11-13 08:54:43,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:44,379][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.731810986995697, acc: 0.8888888955116272)
[2024-11-13 08:54:44,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:45,065][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 1.4099922180175781, acc: 0.6428571343421936)
[2024-11-13 08:54:45,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:45,754][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 0.9309808015823364, acc: 0.7222222089767456)
[2024-11-13 08:54:45,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:46,446][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.2929068803787231, acc: 0.6315789222717285)
[2024-11-13 08:54:46,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:47,150][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.4410815238952637, acc: 0.6666666865348816)
[2024-11-13 08:54:47,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:47,847][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 2.183290719985962, acc: 0.4225352108478546)
[2024-11-13 08:54:47,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:48,566][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 2.22163987159729, acc: 0.46000000834465027)
[2024-11-13 08:54:48,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:49,250][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.3758412599563599, acc: 0.6756756901741028)
[2024-11-13 08:54:49,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:49,933][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.7131276726722717, acc: 0.807692289352417)
[2024-11-13 08:54:50,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:50,775][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 1.899176001548767, acc: 0.49829351902008057)
[2024-11-13 08:54:50,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:51,552][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 2.4191582202911377, acc: 0.40522876381874084)
[2024-11-13 08:54:51,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:52,276][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 1.966030240058899, acc: 0.46590909361839294)
[2024-11-13 08:54:52,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:52,980][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 2.3194727897644043, acc: 0.41911765933036804)
[2024-11-13 08:54:53,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:53,702][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 2.2615163326263428, acc: 0.3840579688549042)
[2024-11-13 08:54:53,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:54,419][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.6911468505859375, acc: 0.5874999761581421)
[2024-11-13 08:54:54,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:55,103][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 1.353326439857483, acc: 0.6176470518112183)
[2024-11-13 08:54:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:55,799][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 1.6300287246704102, acc: 0.5555555820465088)
[2024-11-13 08:54:55,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:56,496][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 1.6969327926635742, acc: 0.5625)
[2024-11-13 08:54:56,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:57,180][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 0.7231784462928772, acc: 0.7931034564971924)
[2024-11-13 08:54:57,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:57,877][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 2.416761875152588, acc: 0.3928571343421936)
[2024-11-13 08:54:57,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:58,567][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 2.0228302478790283, acc: 0.4166666567325592)
[2024-11-13 08:54:58,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:59,253][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.6881536841392517, acc: 0.7599999904632568)
[2024-11-13 08:54:59,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:54:59,941][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.0802974700927734, acc: 0.6944444179534912)
[2024-11-13 08:55:00,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:00,627][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 1.5693987607955933, acc: 0.5454545617103577)
[2024-11-13 08:55:00,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:01,350][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 2.0575625896453857, acc: 0.49264705181121826)
[2024-11-13 08:55:01,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:02,058][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 1.921546459197998, acc: 0.4841269850730896)
[2024-11-13 08:55:02,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:02,788][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 2.1693222522735596, acc: 0.37948718667030334)
[2024-11-13 08:55:02,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:03,482][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 1.9590367078781128, acc: 0.4897959232330322)
[2024-11-13 08:55:03,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:04,179][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 2.4037322998046875, acc: 0.31343284249305725)
[2024-11-13 08:55:04,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:04,921][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.2387266159057617, acc: 0.41605839133262634)
[2024-11-13 08:55:05,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:05,603][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.3737888038158417, acc: 0.8571428656578064)
[2024-11-13 08:55:05,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:06,297][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.6375383138656616, acc: 0.8333333134651184)
[2024-11-13 08:55:06,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:06,994][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 1.1597299575805664, acc: 0.6666666865348816)
[2024-11-13 08:55:07,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:07,680][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.8751348257064819, acc: 0.6538461446762085)
[2024-11-13 08:55:07,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:08,373][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 1.7436254024505615, acc: 0.48076921701431274)
[2024-11-13 08:55:08,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:09,064][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 2.135605573654175, acc: 0.5384615659713745)
[2024-11-13 08:55:09,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:09,752][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 1.54936945438385, acc: 0.53125)
[2024-11-13 08:55:09,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:10,444][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 1.9558966159820557, acc: 0.52173912525177)
[2024-11-13 08:55:10,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:11,145][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.4584143161773682, acc: 0.5600000023841858)
[2024-11-13 08:55:11,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:11,828][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 1.7780425548553467, acc: 0.52173912525177)
[2024-11-13 08:55:11,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:12,523][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 2.2702159881591797, acc: 0.4000000059604645)
[2024-11-13 08:55:12,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:13,226][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.9146678447723389, acc: 0.5145630836486816)
[2024-11-13 08:55:13,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:13,948][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 1.8549107313156128, acc: 0.5194174647331238)
[2024-11-13 08:55:14,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:14,672][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 2.068679094314575, acc: 0.4139784872531891)
[2024-11-13 08:55:14,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:15,413][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 1.8019016981124878, acc: 0.5344827771186829)
[2024-11-13 08:55:15,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:16,113][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.5766193866729736, acc: 0.5473684072494507)
[2024-11-13 08:55:16,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:16,836][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 2.2348246574401855, acc: 0.3663366436958313)
[2024-11-13 08:55:16,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:17,524][root][INFO] - Training Epoch: 3/10, step 94/574 completed (loss: 2.2936127185821533, acc: 0.3870967626571655)
[2024-11-13 08:55:17,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:18,215][root][INFO] - Training Epoch: 3/10, step 95/574 completed (loss: 2.259830951690674, acc: 0.36231884360313416)
[2024-11-13 08:55:18,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:18,914][root][INFO] - Training Epoch: 3/10, step 96/574 completed (loss: 2.4621899127960205, acc: 0.3193277418613434)
[2024-11-13 08:55:18,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:19,613][root][INFO] - Training Epoch: 3/10, step 97/574 completed (loss: 2.3486201763153076, acc: 0.3076923191547394)
[2024-11-13 08:55:19,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:20,321][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 2.292454242706299, acc: 0.37956205010414124)
[2024-11-13 08:55:20,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:21,019][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 2.3548247814178467, acc: 0.3731343150138855)
[2024-11-13 08:55:21,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:21,704][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 0.9671090841293335, acc: 0.800000011920929)
[2024-11-13 08:55:21,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:22,385][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.5915783643722534, acc: 0.8636363744735718)
[2024-11-13 08:55:22,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:23,070][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 1.1039775609970093, acc: 0.739130437374115)
[2024-11-13 08:55:23,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:23,758][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 1.3952831029891968, acc: 0.5681818127632141)
[2024-11-13 08:55:23,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:24,448][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 2.033160448074341, acc: 0.4482758641242981)
[2024-11-13 08:55:24,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:25,134][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 1.6674565076828003, acc: 0.5813953280448914)
[2024-11-13 08:55:25,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:25,816][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 1.1305694580078125, acc: 0.6399999856948853)
[2024-11-13 08:55:25,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:26,498][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.420637845993042, acc: 0.8823529481887817)
[2024-11-13 08:55:26,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:27,183][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.38385647535324097, acc: 0.9230769276618958)
[2024-11-13 08:55:27,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:27,882][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 1.7282943725585938, acc: 0.5)
[2024-11-13 08:55:27,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:28,580][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 1.798229694366455, acc: 0.5384615659713745)
[2024-11-13 08:55:28,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:29,271][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.7998420000076294, acc: 0.5614035129547119)
[2024-11-13 08:55:29,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:29,957][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.5525944232940674, acc: 0.5789473652839661)
[2024-11-13 08:55:30,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:30,642][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.8866723775863647, acc: 0.4615384638309479)
[2024-11-13 08:55:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:31,331][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 1.2991321086883545, acc: 0.6938775777816772)
[2024-11-13 08:55:31,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:32,013][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.33860528469085693, acc: 0.9090909361839294)
[2024-11-13 08:55:32,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:32,712][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 2.1596505641937256, acc: 0.4444444477558136)
[2024-11-13 08:55:32,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:33,405][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 1.9251177310943604, acc: 0.43089431524276733)
[2024-11-13 08:55:33,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:34,096][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 1.6708168983459473, acc: 0.6129032373428345)
[2024-11-13 08:55:34,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:34,857][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 2.034843683242798, acc: 0.47148290276527405)
[2024-11-13 08:55:34,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:35,561][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 1.546485424041748, acc: 0.5866666436195374)
[2024-11-13 08:55:35,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:36,257][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 1.343429684638977, acc: 0.6538461446762085)
[2024-11-13 08:55:36,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:36,938][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.7254483103752136, acc: 0.9166666865348816)
[2024-11-13 08:55:37,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:37,632][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 1.0757468938827515, acc: 0.6842105388641357)
[2024-11-13 08:55:37,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:38,342][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 1.9881584644317627, acc: 0.46625766158103943)
[2024-11-13 08:55:38,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:39,069][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.8312888145446777, acc: 0.5486111044883728)
[2024-11-13 08:55:39,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:39,768][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 2.1250414848327637, acc: 0.375)
[2024-11-13 08:55:39,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:40,501][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.240232467651367, acc: 0.3988095223903656)
[2024-11-13 08:55:40,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:41,221][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.9613944292068481, acc: 0.4615384638309479)
[2024-11-13 08:55:41,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:41,957][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.833482265472412, acc: 0.5514705777168274)
[2024-11-13 08:55:42,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:42,641][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 0.788475751876831, acc: 0.7692307829856873)
[2024-11-13 08:55:42,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:43,340][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.44584769010543823, acc: 0.8695651888847351)
[2024-11-13 08:55:43,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:44,026][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 1.25950288772583, acc: 0.65625)
[2024-11-13 08:55:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:44,708][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.6877970695495605, acc: 0.47826087474823)
[2024-11-13 08:55:44,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:45,393][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.375295639038086, acc: 0.6285714507102966)
[2024-11-13 08:55:45,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:46,076][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.1292691230773926, acc: 0.6538461446762085)
[2024-11-13 08:55:46,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:46,766][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 1.8390398025512695, acc: 0.380952388048172)
[2024-11-13 08:55:46,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:47,449][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.3267771005630493, acc: 0.6000000238418579)
[2024-11-13 08:55:47,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:48,131][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 1.385230302810669, acc: 0.6086956262588501)
[2024-11-13 08:55:49,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:49,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:50,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:50,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:51,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:52,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:52,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:53,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:53,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:54,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:54,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:55,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:56,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:56,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:57,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:57,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:58,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:59,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:55:59,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:00,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:00,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:02,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:02,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:03,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:03,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:04,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:04,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:05,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:06,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:06,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:07,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:07,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:08,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:09,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:09,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:10,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:10,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:11,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:12,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:12,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:13,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:13,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:14,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:14,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:15,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:16,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:16,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:17,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:18,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:18,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:19,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:19,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:20,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:20,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:21,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:22,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:22,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:23,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:23,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:24,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:25,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:25,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:26,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:26,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:27,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:28,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:28,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:29,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:29,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:30,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:30,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:31,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:32,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:33,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:33,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:34,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:35,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:35,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:36,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:36,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:37,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:37,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:38,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:39,545][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.9650, device='cuda:0') eval_epoch_loss=tensor(1.7859, device='cuda:0') eval_epoch_acc=tensor(0.5146, device='cuda:0')
[2024-11-13 08:56:39,546][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:56:39,547][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:56:39,870][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_3_step_139_loss_1.785912036895752/model.pt
[2024-11-13 08:56:39,873][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:56:39,874][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.785912036895752
[2024-11-13 08:56:39,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:40,569][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.9541373252868652, acc: 0.523809552192688)
[2024-11-13 08:56:40,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:41,242][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 2.1236767768859863, acc: 0.3461538553237915)
[2024-11-13 08:56:41,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:41,914][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 2.923705816268921, acc: 0.29032257199287415)
[2024-11-13 08:56:42,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:42,599][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 2.1002683639526367, acc: 0.4054054021835327)
[2024-11-13 08:56:42,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:43,307][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 2.0472118854522705, acc: 0.38596490025520325)
[2024-11-13 08:56:43,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:44,003][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.8338370323181152, acc: 0.48507463932037354)
[2024-11-13 08:56:44,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:44,693][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 2.2559826374053955, acc: 0.37755101919174194)
[2024-11-13 08:56:44,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:45,394][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 2.136470317840576, acc: 0.3404255211353302)
[2024-11-13 08:56:45,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:46,075][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.9804579019546509, acc: 0.4571428596973419)
[2024-11-13 08:56:46,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:46,746][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 2.209221363067627, acc: 0.3928571343421936)
[2024-11-13 08:56:46,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:47,419][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.5265417098999023, acc: 0.6521739363670349)
[2024-11-13 08:56:47,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:48,106][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 2.2344954013824463, acc: 0.24137930572032928)
[2024-11-13 08:56:48,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:48,786][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 2.0027055740356445, acc: 0.5)
[2024-11-13 08:56:48,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:49,466][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 1.9331724643707275, acc: 0.508474588394165)
[2024-11-13 08:56:49,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:50,145][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 2.3019773960113525, acc: 0.4035087823867798)
[2024-11-13 08:56:50,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:50,827][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.8267279863357544, acc: 0.4864864945411682)
[2024-11-13 08:56:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:51,503][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 1.7977392673492432, acc: 0.5)
[2024-11-13 08:56:51,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:52,180][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 1.3238173723220825, acc: 0.6521739363670349)
[2024-11-13 08:56:52,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:52,850][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 2.071892499923706, acc: 0.42105263471603394)
[2024-11-13 08:56:52,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:53,531][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 1.6396769285202026, acc: 0.5405405163764954)
[2024-11-13 08:56:53,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:54,211][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 1.9896501302719116, acc: 0.46296295523643494)
[2024-11-13 08:56:54,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:54,905][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 1.808834195137024, acc: 0.43023255467414856)
[2024-11-13 08:56:55,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:55,595][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 1.723588466644287, acc: 0.48235294222831726)
[2024-11-13 08:56:55,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:56,280][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 2.149117946624756, acc: 0.4157303273677826)
[2024-11-13 08:56:56,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:56,956][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 1.7742406129837036, acc: 0.6136363744735718)
[2024-11-13 08:56:57,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:57,628][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 1.6319621801376343, acc: 0.5714285969734192)
[2024-11-13 08:56:57,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:58,299][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.6713024377822876, acc: 0.517241358757019)
[2024-11-13 08:56:58,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:58,991][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 1.4848511219024658, acc: 0.5918367505073547)
[2024-11-13 08:56:59,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:56:59,666][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 1.7321282625198364, acc: 0.47999998927116394)
[2024-11-13 08:56:59,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:00,350][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 1.6781189441680908, acc: 0.5416666865348816)
[2024-11-13 08:57:00,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:01,047][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 1.8887661695480347, acc: 0.5)
[2024-11-13 08:57:01,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:01,768][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.395796060562134, acc: 0.42465752363204956)
[2024-11-13 08:57:01,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:02,438][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 0.8480939865112305, acc: 0.75)
[2024-11-13 08:57:02,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:03,108][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 0.8358704447746277, acc: 0.7407407164573669)
[2024-11-13 08:57:03,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:03,781][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.3831465244293213, acc: 0.7142857313156128)
[2024-11-13 08:57:03,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:04,485][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.7708096504211426, acc: 0.5044247508049011)
[2024-11-13 08:57:04,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:05,163][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.7721928358078003, acc: 0.49275362491607666)
[2024-11-13 08:57:05,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:05,847][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 1.871147871017456, acc: 0.47727271914482117)
[2024-11-13 08:57:05,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:06,553][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.4232022762298584, acc: 0.35114502906799316)
[2024-11-13 08:57:06,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:07,257][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 2.1275763511657715, acc: 0.39259257912635803)
[2024-11-13 08:57:07,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:07,935][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 1.5530396699905396, acc: 0.6065573692321777)
[2024-11-13 08:57:08,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:08,616][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.7742850184440613, acc: 0.7916666865348816)
[2024-11-13 08:57:08,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:09,289][root][INFO] - Training Epoch: 3/10, step 181/574 completed (loss: 1.492080807685852, acc: 0.6000000238418579)
[2024-11-13 08:57:09,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:09,977][root][INFO] - Training Epoch: 3/10, step 182/574 completed (loss: 1.013503909111023, acc: 0.6785714030265808)
[2024-11-13 08:57:10,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:10,663][root][INFO] - Training Epoch: 3/10, step 183/574 completed (loss: 1.9607657194137573, acc: 0.46341463923454285)
[2024-11-13 08:57:10,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:11,388][root][INFO] - Training Epoch: 3/10, step 184/574 completed (loss: 2.2975387573242188, acc: 0.40181270241737366)
[2024-11-13 08:57:11,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:12,112][root][INFO] - Training Epoch: 3/10, step 185/574 completed (loss: 2.3537843227386475, acc: 0.3631123900413513)
[2024-11-13 08:57:12,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:12,831][root][INFO] - Training Epoch: 3/10, step 186/574 completed (loss: 2.388336658477783, acc: 0.4000000059604645)
[2024-11-13 08:57:12,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:13,603][root][INFO] - Training Epoch: 3/10, step 187/574 completed (loss: 2.1972038745880127, acc: 0.3939962387084961)
[2024-11-13 08:57:13,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:14,340][root][INFO] - Training Epoch: 3/10, step 188/574 completed (loss: 2.1451520919799805, acc: 0.41281139850616455)
[2024-11-13 08:57:14,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:15,012][root][INFO] - Training Epoch: 3/10, step 189/574 completed (loss: 2.181819438934326, acc: 0.4000000059604645)
[2024-11-13 08:57:15,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:15,695][root][INFO] - Training Epoch: 3/10, step 190/574 completed (loss: 2.1397409439086914, acc: 0.41860464215278625)
[2024-11-13 08:57:15,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:16,382][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 1.875321388244629, acc: 0.5317460298538208)
[2024-11-13 08:57:16,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:17,073][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 1.9923686981201172, acc: 0.47727271914482117)
[2024-11-13 08:57:17,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:17,754][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 1.7404135465621948, acc: 0.529411792755127)
[2024-11-13 08:57:17,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:18,461][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 1.695062279701233, acc: 0.5864197611808777)
[2024-11-13 08:57:18,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:19,161][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 1.423914909362793, acc: 0.5967742204666138)
[2024-11-13 08:57:19,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:19,833][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.5906491279602051, acc: 0.8571428656578064)
[2024-11-13 08:57:19,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:20,509][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 1.8151565790176392, acc: 0.5249999761581421)
[2024-11-13 08:57:20,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:21,191][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 1.7692809104919434, acc: 0.5)
[2024-11-13 08:57:21,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:21,879][root][INFO] - Training Epoch: 3/10, step 199/574 completed (loss: 1.9263023138046265, acc: 0.4852941036224365)
[2024-11-13 08:57:21,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:22,563][root][INFO] - Training Epoch: 3/10, step 200/574 completed (loss: 2.084738254547119, acc: 0.43220338225364685)
[2024-11-13 08:57:22,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:23,250][root][INFO] - Training Epoch: 3/10, step 201/574 completed (loss: 2.218390703201294, acc: 0.43283581733703613)
[2024-11-13 08:57:23,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:23,945][root][INFO] - Training Epoch: 3/10, step 202/574 completed (loss: 2.057957887649536, acc: 0.43689319491386414)
[2024-11-13 08:57:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:24,644][root][INFO] - Training Epoch: 3/10, step 203/574 completed (loss: 1.8059964179992676, acc: 0.5396825671195984)
[2024-11-13 08:57:24,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:25,328][root][INFO] - Training Epoch: 3/10, step 204/574 completed (loss: 1.865750789642334, acc: 0.5274725556373596)
[2024-11-13 08:57:25,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:26,044][root][INFO] - Training Epoch: 3/10, step 205/574 completed (loss: 2.0576164722442627, acc: 0.4304932653903961)
[2024-11-13 08:57:26,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:26,769][root][INFO] - Training Epoch: 3/10, step 206/574 completed (loss: 2.0669801235198975, acc: 0.4842519760131836)
[2024-11-13 08:57:26,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:27,478][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 1.9689409732818604, acc: 0.4612068831920624)
[2024-11-13 08:57:27,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:28,194][root][INFO] - Training Epoch: 3/10, step 208/574 completed (loss: 2.0575153827667236, acc: 0.4528985619544983)
[2024-11-13 08:57:28,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:28,915][root][INFO] - Training Epoch: 3/10, step 209/574 completed (loss: 2.180708169937134, acc: 0.3813229501247406)
[2024-11-13 08:57:28,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:29,630][root][INFO] - Training Epoch: 3/10, step 210/574 completed (loss: 2.275289297103882, acc: 0.45652174949645996)
[2024-11-13 08:57:29,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:30,314][root][INFO] - Training Epoch: 3/10, step 211/574 completed (loss: 1.0556178092956543, acc: 0.739130437374115)
[2024-11-13 08:57:30,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:30,997][root][INFO] - Training Epoch: 3/10, step 212/574 completed (loss: 1.5796940326690674, acc: 0.6071428656578064)
[2024-11-13 08:57:31,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:31,679][root][INFO] - Training Epoch: 3/10, step 213/574 completed (loss: 1.3038229942321777, acc: 0.6382978558540344)
[2024-11-13 08:57:31,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:32,381][root][INFO] - Training Epoch: 3/10, step 214/574 completed (loss: 1.7733021974563599, acc: 0.5230769515037537)
[2024-11-13 08:57:32,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:33,064][root][INFO] - Training Epoch: 3/10, step 215/574 completed (loss: 1.529935598373413, acc: 0.5405405163764954)
[2024-11-13 08:57:33,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:33,745][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 1.4628180265426636, acc: 0.6162790656089783)
[2024-11-13 08:57:33,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:34,432][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 1.7293219566345215, acc: 0.5495495200157166)
[2024-11-13 08:57:34,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:35,116][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 1.6642472743988037, acc: 0.47777777910232544)
[2024-11-13 08:57:35,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:35,791][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.7817069292068481, acc: 0.7272727489471436)
[2024-11-13 08:57:35,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:36,464][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.2011064887046814, acc: 0.9259259104728699)
[2024-11-13 08:57:36,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:37,135][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.4883606731891632, acc: 0.8399999737739563)
[2024-11-13 08:57:37,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:37,816][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 1.8454430103302002, acc: 0.5)
[2024-11-13 08:57:37,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:38,534][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 1.606594204902649, acc: 0.5652173757553101)
[2024-11-13 08:57:38,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:39,241][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 1.8424454927444458, acc: 0.4886363744735718)
[2024-11-13 08:57:39,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:39,949][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 2.1877524852752686, acc: 0.40425533056259155)
[2024-11-13 08:57:40,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:40,625][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 1.4230390787124634, acc: 0.6226415038108826)
[2024-11-13 08:57:40,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:41,301][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 1.756626844406128, acc: 0.5)
[2024-11-13 08:57:41,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:41,992][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 1.1101765632629395, acc: 0.7441860437393188)
[2024-11-13 08:57:42,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:42,666][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 1.1482126712799072, acc: 0.7333333492279053)
[2024-11-13 08:57:42,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:43,362][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 2.2247464656829834, acc: 0.4000000059604645)
[2024-11-13 08:57:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:44,042][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 1.6663509607315063, acc: 0.5555555820465088)
[2024-11-13 08:57:44,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:44,747][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 1.5804014205932617, acc: 0.5611110925674438)
[2024-11-13 08:57:44,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:45,458][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 1.6874340772628784, acc: 0.5871559381484985)
[2024-11-13 08:57:45,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:46,165][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 1.618963360786438, acc: 0.5461538434028625)
[2024-11-13 08:57:46,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:46,839][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 0.9291917085647583, acc: 0.7368420958518982)
[2024-11-13 08:57:46,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:47,520][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 0.9374889731407166, acc: 0.6666666865348816)
[2024-11-13 08:57:47,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:48,193][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 1.707870364189148, acc: 0.5)
[2024-11-13 08:57:48,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:48,868][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.4445382356643677, acc: 0.5185185074806213)
[2024-11-13 08:57:48,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:49,550][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 1.2912482023239136, acc: 0.7428571581840515)
[2024-11-13 08:57:49,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:50,226][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.4817321300506592, acc: 0.5454545617103577)
[2024-11-13 08:57:50,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:50,899][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.622551441192627, acc: 0.5454545617103577)
[2024-11-13 08:57:50,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:51,593][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 2.0077996253967285, acc: 0.4516128897666931)
[2024-11-13 08:57:51,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:52,275][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.5818747282028198, acc: 0.5454545617103577)
[2024-11-13 08:57:52,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:52,946][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.31060299277305603, acc: 0.9523809552192688)
[2024-11-13 08:57:53,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:53,626][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.0541934967041016, acc: 0.6538461446762085)
[2024-11-13 08:57:53,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:54,299][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.5575734376907349, acc: 0.6774193644523621)
[2024-11-13 08:57:54,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:54,968][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 0.7943904995918274, acc: 0.699999988079071)
[2024-11-13 08:57:55,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:55,647][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 1.352295994758606, acc: 0.6216216087341309)
[2024-11-13 08:57:55,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:56,323][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 1.2618262767791748, acc: 0.5405405163764954)
[2024-11-13 08:57:56,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:57,010][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 1.2987890243530273, acc: 0.5945945978164673)
[2024-11-13 08:57:57,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:57,697][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 1.819299340248108, acc: 0.529411792755127)
[2024-11-13 08:57:57,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:58,391][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.6033438444137573, acc: 0.8536585569381714)
[2024-11-13 08:57:58,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:59,065][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.3947222828865051, acc: 0.9200000166893005)
[2024-11-13 08:57:59,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:57:59,735][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.21000896394252777, acc: 1.0)
[2024-11-13 08:57:59,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:00,419][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.31182074546813965, acc: 0.9354838728904724)
[2024-11-13 08:58:00,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:01,098][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 1.457053780555725, acc: 0.6140350699424744)
[2024-11-13 08:58:01,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:01,773][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 1.5148087739944458, acc: 0.6428571343421936)
[2024-11-13 08:58:01,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:02,452][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 1.3193951845169067, acc: 0.6710526347160339)
[2024-11-13 08:58:02,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:03,166][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.6588079929351807, acc: 0.5188679099082947)
[2024-11-13 08:58:03,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:03,877][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 1.73013174533844, acc: 0.5333333611488342)
[2024-11-13 08:58:03,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:04,563][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 0.9000115990638733, acc: 0.8333333134651184)
[2024-11-13 08:58:04,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:05,239][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 1.654492735862732, acc: 0.5483871102333069)
[2024-11-13 08:58:05,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:05,923][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 2.815938711166382, acc: 0.3733333349227905)
[2024-11-13 08:58:06,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:06,602][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 2.1276636123657227, acc: 0.4166666567325592)
[2024-11-13 08:58:06,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:07,317][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 2.2543203830718994, acc: 0.42399999499320984)
[2024-11-13 08:58:07,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:08,006][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 2.1281282901763916, acc: 0.4157303273677826)
[2024-11-13 08:58:08,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:08,691][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 1.988284707069397, acc: 0.5135135054588318)
[2024-11-13 08:58:08,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:09,374][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.2524482011795044, acc: 0.6206896305084229)
[2024-11-13 08:58:09,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:10,045][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 1.0113205909729004, acc: 0.7727272510528564)
[2024-11-13 08:58:10,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:10,719][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 1.0504502058029175, acc: 0.6818181872367859)
[2024-11-13 08:58:10,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:11,391][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.8032599091529846, acc: 0.78125)
[2024-11-13 08:58:11,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:12,067][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 0.9193150997161865, acc: 0.800000011920929)
[2024-11-13 08:58:12,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:12,747][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 1.5785821676254272, acc: 0.550000011920929)
[2024-11-13 08:58:12,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:13,421][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 0.9149734377861023, acc: 0.6875)
[2024-11-13 08:58:13,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:14,095][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.7404164671897888, acc: 0.7666666507720947)
[2024-11-13 08:58:14,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:14,772][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 1.2476872205734253, acc: 0.7586206793785095)
[2024-11-13 08:58:14,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:15,453][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 1.0651273727416992, acc: 0.6800000071525574)
[2024-11-13 08:58:15,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:16,133][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 2.0607876777648926, acc: 0.44680851697921753)
[2024-11-13 08:58:16,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:16,811][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 1.4702540636062622, acc: 0.6041666865348816)
[2024-11-13 08:58:16,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:17,488][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 1.344239354133606, acc: 0.7272727489471436)
[2024-11-13 08:58:17,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:18,173][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 1.9669634103775024, acc: 0.4819277226924896)
[2024-11-13 08:58:19,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:19,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:20,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:21,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:22,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:22,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:23,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:23,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:24,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:24,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:25,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:26,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:26,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:27,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:28,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:28,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:29,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:30,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:31,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:31,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:32,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:33,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:34,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:34,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:35,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:36,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:36,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:37,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:37,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:38,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:38,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:39,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:40,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:40,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:41,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:41,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:42,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:43,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:43,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:44,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:44,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:45,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:46,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:46,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:47,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:47,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:48,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:48,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:49,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:50,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:50,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:51,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:51,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:52,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:52,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:53,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:54,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:54,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:55,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:55,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:56,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:57,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:57,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:58,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:58,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:58:59,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:00,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:01,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:01,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:02,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:02,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:03,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:04,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:04,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:05,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:05,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:06,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:06,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:07,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:08,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:08,999][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.2148, device='cuda:0') eval_epoch_loss=tensor(1.6515, device='cuda:0') eval_epoch_acc=tensor(0.5673, device='cuda:0')
[2024-11-13 08:59:09,001][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 08:59:09,001][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 08:59:09,329][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_3_step_282_loss_1.6515027284622192/model.pt
[2024-11-13 08:59:09,334][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 08:59:09,335][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.6515027284622192
[2024-11-13 08:59:09,335][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5672906041145325
[2024-11-13 08:59:09,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:10,034][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 1.982796311378479, acc: 0.45370370149612427)
[2024-11-13 08:59:10,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:10,708][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 2.035731077194214, acc: 0.31578946113586426)
[2024-11-13 08:59:10,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:11,381][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 1.9126126766204834, acc: 0.4117647111415863)
[2024-11-13 08:59:11,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:12,056][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 1.792593240737915, acc: 0.44999998807907104)
[2024-11-13 08:59:12,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:12,744][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 1.9670923948287964, acc: 0.4140625)
[2024-11-13 08:59:12,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:13,447][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 2.2301313877105713, acc: 0.37599998712539673)
[2024-11-13 08:59:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:14,131][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 1.674256682395935, acc: 0.5384615659713745)
[2024-11-13 08:59:14,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:14,819][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 2.2536492347717285, acc: 0.40993788838386536)
[2024-11-13 08:59:14,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:15,534][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 2.3461194038391113, acc: 0.3814432919025421)
[2024-11-13 08:59:15,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:16,209][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.31439435482025146, acc: 0.9090909361839294)
[2024-11-13 08:59:16,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:16,882][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 1.8616509437561035, acc: 0.523809552192688)
[2024-11-13 08:59:16,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:17,561][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 1.4196794033050537, acc: 0.6206896305084229)
[2024-11-13 08:59:17,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:18,243][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 1.1565704345703125, acc: 0.6909090876579285)
[2024-11-13 08:59:18,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:18,965][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.754408836364746, acc: 0.5360824465751648)
[2024-11-13 08:59:19,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:19,657][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 1.997642993927002, acc: 0.4482758641242981)
[2024-11-13 08:59:19,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:20,328][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 1.4797457456588745, acc: 0.5925925970077515)
[2024-11-13 08:59:20,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:21,003][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 1.3702061176300049, acc: 0.6052631735801697)
[2024-11-13 08:59:21,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:21,681][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 1.3378325700759888, acc: 0.6071428656578064)
[2024-11-13 08:59:21,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:22,353][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 1.5033798217773438, acc: 0.65625)
[2024-11-13 08:59:22,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:23,033][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 1.742671012878418, acc: 0.5660377144813538)
[2024-11-13 08:59:23,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:23,712][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 0.8911234736442566, acc: 0.7169811129570007)
[2024-11-13 08:59:23,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:24,383][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 0.9281298518180847, acc: 0.7941176295280457)
[2024-11-13 08:59:24,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:25,066][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 1.921822190284729, acc: 0.5)
[2024-11-13 08:59:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:25,751][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.2448396682739258, acc: 0.6065573692321777)
[2024-11-13 08:59:25,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:26,422][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.5611284375190735, acc: 0.8999999761581421)
[2024-11-13 08:59:26,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:27,092][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.12967908382415771, acc: 1.0)
[2024-11-13 08:59:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:27,773][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 1.87034010887146, acc: 0.47826087474823)
[2024-11-13 08:59:27,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:28,458][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 1.4905216693878174, acc: 0.625)
[2024-11-13 08:59:28,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:29,139][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 1.4465181827545166, acc: 0.5662650465965271)
[2024-11-13 08:59:29,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:29,824][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 1.852486491203308, acc: 0.44871795177459717)
[2024-11-13 08:59:29,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:30,535][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 1.9750194549560547, acc: 0.5102040767669678)
[2024-11-13 08:59:30,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:31,223][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.07519149035215378, acc: 1.0)
[2024-11-13 08:59:31,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:31,895][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 0.6189374327659607, acc: 0.8333333134651184)
[2024-11-13 08:59:31,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:32,568][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 0.49095481634140015, acc: 0.8064516186714172)
[2024-11-13 08:59:32,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:33,240][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 0.7294374108314514, acc: 0.8064516186714172)
[2024-11-13 08:59:33,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:33,921][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 1.175106406211853, acc: 0.6567164063453674)
[2024-11-13 08:59:34,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:34,615][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 1.2910889387130737, acc: 0.6442307829856873)
[2024-11-13 08:59:34,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:35,291][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 1.6899250745773315, acc: 0.6000000238418579)
[2024-11-13 08:59:35,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:35,970][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 1.1461974382400513, acc: 0.6774193644523621)
[2024-11-13 08:59:36,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:36,648][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.8108901977539062, acc: 0.8199999928474426)
[2024-11-13 08:59:36,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:37,321][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 1.579068660736084, acc: 0.5185185074806213)
[2024-11-13 08:59:37,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:37,999][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.4835124015808105, acc: 0.37142857909202576)
[2024-11-13 08:59:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:38,670][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 1.671152949333191, acc: 0.4871794879436493)
[2024-11-13 08:59:38,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:39,350][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.188288450241089, acc: 0.3658536672592163)
[2024-11-13 08:59:39,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:40,027][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 1.8549305200576782, acc: 0.5263158082962036)
[2024-11-13 08:59:40,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:40,697][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 0.729739248752594, acc: 0.7368420958518982)
[2024-11-13 08:59:40,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:41,369][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.22807979583740234, acc: 0.9642857313156128)
[2024-11-13 08:59:41,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:42,039][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 1.3552353382110596, acc: 0.7407407164573669)
[2024-11-13 08:59:42,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:42,711][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.41027116775512695, acc: 0.875)
[2024-11-13 08:59:42,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:43,391][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 1.5026538372039795, acc: 0.5645161271095276)
[2024-11-13 08:59:43,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:44,083][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 1.3146440982818604, acc: 0.6315789222717285)
[2024-11-13 08:59:44,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:44,763][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 1.8473467826843262, acc: 0.5)
[2024-11-13 08:59:44,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:45,439][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 0.7941561341285706, acc: 0.699999988079071)
[2024-11-13 08:59:45,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:46,111][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 1.4621673822402954, acc: 0.6842105388641357)
[2024-11-13 08:59:46,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:46,792][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 1.9307781457901, acc: 0.47999998927116394)
[2024-11-13 08:59:46,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:47,482][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 1.9802323579788208, acc: 0.4712643623352051)
[2024-11-13 08:59:47,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:48,163][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 2.201718807220459, acc: 0.42553192377090454)
[2024-11-13 08:59:48,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:48,850][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 2.225827693939209, acc: 0.3734939694404602)
[2024-11-13 08:59:48,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:49,522][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.5926408171653748, acc: 0.8695651888847351)
[2024-11-13 08:59:49,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:50,194][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 1.622679352760315, acc: 0.5384615659713745)
[2024-11-13 08:59:50,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:50,874][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 2.1639890670776367, acc: 0.42168673872947693)
[2024-11-13 08:59:50,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:51,558][root][INFO] - Training Epoch: 3/10, step 343/574 completed (loss: 1.5800065994262695, acc: 0.5283018946647644)
[2024-11-13 08:59:51,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:52,252][root][INFO] - Training Epoch: 3/10, step 344/574 completed (loss: 1.71052086353302, acc: 0.5443037748336792)
[2024-11-13 08:59:52,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:52,928][root][INFO] - Training Epoch: 3/10, step 345/574 completed (loss: 1.6489413976669312, acc: 0.529411792755127)
[2024-11-13 08:59:53,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:53,609][root][INFO] - Training Epoch: 3/10, step 346/574 completed (loss: 2.35937237739563, acc: 0.35820895433425903)
[2024-11-13 08:59:53,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:54,280][root][INFO] - Training Epoch: 3/10, step 347/574 completed (loss: 0.5025210380554199, acc: 0.8500000238418579)
[2024-11-13 08:59:54,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:54,949][root][INFO] - Training Epoch: 3/10, step 348/574 completed (loss: 1.0004733800888062, acc: 0.7200000286102295)
[2024-11-13 08:59:55,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:55,624][root][INFO] - Training Epoch: 3/10, step 349/574 completed (loss: 1.1589469909667969, acc: 0.6666666865348816)
[2024-11-13 08:59:55,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:56,300][root][INFO] - Training Epoch: 3/10, step 350/574 completed (loss: 1.5741912126541138, acc: 0.5348837375640869)
[2024-11-13 08:59:56,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:56,975][root][INFO] - Training Epoch: 3/10, step 351/574 completed (loss: 1.463944911956787, acc: 0.5641025900840759)
[2024-11-13 08:59:57,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:57,655][root][INFO] - Training Epoch: 3/10, step 352/574 completed (loss: 1.6376432180404663, acc: 0.5333333611488342)
[2024-11-13 08:59:57,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:58,337][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.35764482617378235, acc: 0.95652174949646)
[2024-11-13 08:59:58,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:59,010][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 1.8692631721496582, acc: 0.5769230723381042)
[2024-11-13 08:59:59,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 08:59:59,697][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 2.2223305702209473, acc: 0.36263737082481384)
[2024-11-13 08:59:59,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:00,405][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.763532042503357, acc: 0.530434787273407)
[2024-11-13 09:00:00,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:01,084][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 1.7724534273147583, acc: 0.47826087474823)
[2024-11-13 09:00:01,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:01,768][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 1.7691466808319092, acc: 0.4897959232330322)
[2024-11-13 09:00:01,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:02,440][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.1714845448732376, acc: 0.9583333134651184)
[2024-11-13 09:00:02,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:03,113][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.34320053458213806, acc: 0.9230769276618958)
[2024-11-13 09:00:03,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:03,787][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.2552412748336792, acc: 0.6341463327407837)
[2024-11-13 09:00:03,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:04,460][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 1.3107844591140747, acc: 0.644444465637207)
[2024-11-13 09:00:04,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:05,143][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 1.7986376285552979, acc: 0.46052631735801697)
[2024-11-13 09:00:05,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:05,818][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 1.4625734090805054, acc: 0.6341463327407837)
[2024-11-13 09:00:05,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:06,491][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 1.4324837923049927, acc: 0.4545454680919647)
[2024-11-13 09:00:06,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:07,203][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.2580108046531677, acc: 0.9166666865348816)
[2024-11-13 09:00:07,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:07,887][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.05557232350111008, acc: 1.0)
[2024-11-13 09:00:07,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:08,559][root][INFO] - Training Epoch: 3/10, step 368/574 completed (loss: 0.2783002555370331, acc: 0.9285714030265808)
[2024-11-13 09:00:08,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:09,245][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 0.75407475233078, acc: 0.78125)
[2024-11-13 09:00:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:09,956][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 1.810296654701233, acc: 0.5636363625526428)
[2024-11-13 09:00:10,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:10,674][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 1.3204911947250366, acc: 0.6415094137191772)
[2024-11-13 09:00:10,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:11,357][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 1.3871694803237915, acc: 0.6555555462837219)
[2024-11-13 09:00:11,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:12,035][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 1.274032711982727, acc: 0.7142857313156128)
[2024-11-13 09:00:12,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:12,724][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.6154191493988037, acc: 0.7714285850524902)
[2024-11-13 09:00:12,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:13,396][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.18197402358055115, acc: 0.9599999785423279)
[2024-11-13 09:00:13,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:14,069][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.25569626688957214, acc: 0.9130434989929199)
[2024-11-13 09:00:14,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:14,745][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 1.338122844696045, acc: 0.6666666865348816)
[2024-11-13 09:00:14,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:15,430][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 1.4945238828659058, acc: 0.6000000238418579)
[2024-11-13 09:00:15,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:16,135][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 1.7162249088287354, acc: 0.5928143858909607)
[2024-11-13 09:00:16,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:16,823][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 1.3623276948928833, acc: 0.5789473652839661)
[2024-11-13 09:00:16,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:17,541][root][INFO] - Training Epoch: 3/10, step 381/574 completed (loss: 1.527510404586792, acc: 0.5668449401855469)
[2024-11-13 09:00:17,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:18,249][root][INFO] - Training Epoch: 3/10, step 382/574 completed (loss: 1.1763246059417725, acc: 0.6936936974525452)
[2024-11-13 09:00:18,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:18,921][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 0.4226641058921814, acc: 0.8571428656578064)
[2024-11-13 09:00:19,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:19,592][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.11748749017715454, acc: 1.0)
[2024-11-13 09:00:19,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:20,268][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 0.4785946309566498, acc: 0.84375)
[2024-11-13 09:00:20,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:20,939][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 0.8395593762397766, acc: 0.7222222089767456)
[2024-11-13 09:00:21,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:21,623][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 0.5944730639457703, acc: 0.7631579041481018)
[2024-11-13 09:00:21,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:22,293][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.23176813125610352, acc: 0.9545454382896423)
[2024-11-13 09:00:22,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:22,964][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 0.30676260590553284, acc: 0.8500000238418579)
[2024-11-13 09:00:23,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:23,637][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 0.3360617756843567, acc: 0.9047619104385376)
[2024-11-13 09:00:23,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:24,314][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 2.2498066425323486, acc: 0.3888888955116272)
[2024-11-13 09:00:24,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:24,995][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 2.264906406402588, acc: 0.3980582654476166)
[2024-11-13 09:00:25,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:25,706][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 1.807291030883789, acc: 0.5735294222831726)
[2024-11-13 09:00:25,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:26,398][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 2.106748580932617, acc: 0.46666666865348816)
[2024-11-13 09:00:26,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:27,094][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 2.0107979774475098, acc: 0.4652777910232544)
[2024-11-13 09:00:27,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:27,773][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 1.5605849027633667, acc: 0.6511628031730652)
[2024-11-13 09:00:27,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:28,449][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 0.31549379229545593, acc: 0.9166666865348816)
[2024-11-13 09:00:28,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:29,130][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 1.0033512115478516, acc: 0.6976743936538696)
[2024-11-13 09:00:29,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:29,800][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 1.0446710586547852, acc: 0.7200000286102295)
[2024-11-13 09:00:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:30,485][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 1.529980182647705, acc: 0.6029411554336548)
[2024-11-13 09:00:30,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:31,176][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 1.5621767044067383, acc: 0.6266666650772095)
[2024-11-13 09:00:31,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:31,851][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 0.8841581344604492, acc: 0.7575757503509521)
[2024-11-13 09:00:31,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:32,522][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 0.9630836248397827, acc: 0.8181818127632141)
[2024-11-13 09:00:32,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:33,194][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.1439782977104187, acc: 1.0)
[2024-11-13 09:00:33,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:33,866][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 0.8824345469474792, acc: 0.8148148059844971)
[2024-11-13 09:00:33,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:34,547][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.34880343079566956, acc: 0.9200000166893005)
[2024-11-13 09:00:34,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:35,225][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.2984757721424103, acc: 0.9166666865348816)
[2024-11-13 09:00:35,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:35,898][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.515743613243103, acc: 0.8148148059844971)
[2024-11-13 09:00:35,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:36,571][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.478310227394104, acc: 0.8461538553237915)
[2024-11-13 09:00:36,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:37,248][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 1.1303341388702393, acc: 0.7241379022598267)
[2024-11-13 09:00:37,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:37,919][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.40824365615844727, acc: 0.9285714030265808)
[2024-11-13 09:00:38,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:38,592][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.9157373309135437, acc: 0.7666666507720947)
[2024-11-13 09:00:38,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:39,265][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.6035841107368469, acc: 0.8484848737716675)
[2024-11-13 09:00:39,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:39,949][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.4060359001159668, acc: 0.8636363744735718)
[2024-11-13 09:00:40,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:40,644][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 1.541046142578125, acc: 0.5686274766921997)
[2024-11-13 09:00:40,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:41,319][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 1.1268986463546753, acc: 0.7692307829856873)
[2024-11-13 09:00:41,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:41,991][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 1.125956416130066, acc: 0.7222222089767456)
[2024-11-13 09:00:42,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:42,671][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 1.268079400062561, acc: 0.675000011920929)
[2024-11-13 09:00:42,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:43,341][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 1.4320590496063232, acc: 0.6499999761581421)
[2024-11-13 09:00:43,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:44,014][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.12069658190011978, acc: 1.0)
[2024-11-13 09:00:44,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:44,685][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 0.6553454995155334, acc: 0.800000011920929)
[2024-11-13 09:00:44,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:45,360][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 0.6067574620246887, acc: 0.84375)
[2024-11-13 09:00:45,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:46,034][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.0645499229431152, acc: 0.6666666865348816)
[2024-11-13 09:00:46,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:46,706][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 1.0163393020629883, acc: 0.7777777910232544)
[2024-11-13 09:00:47,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:48,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:48,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:49,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:49,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:50,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:50,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:51,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:52,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:52,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:53,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:53,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:54,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:55,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:55,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:56,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:57,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:57,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:58,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:58,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:59,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:00:59,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:00,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:01,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:01,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:02,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:02,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:03,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:03,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:04,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:05,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:05,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:06,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:06,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:07,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:07,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:08,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:09,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:09,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:10,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:10,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:11,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:11,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:12,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:13,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:13,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:14,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:14,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:15,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:15,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:16,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:17,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:17,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:18,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:18,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:19,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:20,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:20,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:21,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:21,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:22,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:22,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:24,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:24,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:25,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:25,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:26,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:26,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:27,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:28,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:28,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:29,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:29,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:30,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:30,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:31,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:32,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:32,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:33,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:33,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:34,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:35,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:35,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:36,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:37,048][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.4156, device='cuda:0') eval_epoch_loss=tensor(1.4851, device='cuda:0') eval_epoch_acc=tensor(0.6020, device='cuda:0')
[2024-11-13 09:01:37,050][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:01:37,050][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:01:37,418][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_3_step_425_loss_1.4851435422897339/model.pt
[2024-11-13 09:01:37,421][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:01:37,422][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.4851435422897339
[2024-11-13 09:01:37,422][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.6019508838653564
[2024-11-13 09:01:37,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:38,110][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 0.581343948841095, acc: 0.8787878751754761)
[2024-11-13 09:01:38,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:38,781][root][INFO] - Training Epoch: 3/10, step 426/574 completed (loss: 0.21312204003334045, acc: 0.95652174949646)
[2024-11-13 09:01:38,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:39,456][root][INFO] - Training Epoch: 3/10, step 427/574 completed (loss: 0.6119276881217957, acc: 0.837837815284729)
[2024-11-13 09:01:39,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:40,130][root][INFO] - Training Epoch: 3/10, step 428/574 completed (loss: 0.3811681270599365, acc: 0.8888888955116272)
[2024-11-13 09:01:40,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:40,801][root][INFO] - Training Epoch: 3/10, step 429/574 completed (loss: 0.8523118495941162, acc: 0.695652186870575)
[2024-11-13 09:01:40,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:41,472][root][INFO] - Training Epoch: 3/10, step 430/574 completed (loss: 0.3885570466518402, acc: 0.8518518805503845)
[2024-11-13 09:01:41,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:42,154][root][INFO] - Training Epoch: 3/10, step 431/574 completed (loss: 0.1569543182849884, acc: 0.9259259104728699)
[2024-11-13 09:01:42,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:42,825][root][INFO] - Training Epoch: 3/10, step 432/574 completed (loss: 0.48767223954200745, acc: 0.8695651888847351)
[2024-11-13 09:01:42,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:43,503][root][INFO] - Training Epoch: 3/10, step 433/574 completed (loss: 0.8723984956741333, acc: 0.7222222089767456)
[2024-11-13 09:01:43,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:44,175][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.16937901079654694, acc: 0.9599999785423279)
[2024-11-13 09:01:44,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:44,847][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 0.6370556354522705, acc: 0.8181818127632141)
[2024-11-13 09:01:44,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:45,532][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 0.8041433095932007, acc: 0.8055555820465088)
[2024-11-13 09:01:45,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:46,211][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 0.9959174990653992, acc: 0.7272727489471436)
[2024-11-13 09:01:46,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:46,893][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.44513607025146484, acc: 0.9523809552192688)
[2024-11-13 09:01:46,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:47,567][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 1.5546413660049438, acc: 0.6410256624221802)
[2024-11-13 09:01:47,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:48,252][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 1.963371753692627, acc: 0.5151515007019043)
[2024-11-13 09:01:48,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:48,960][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 2.226905584335327, acc: 0.4320000112056732)
[2024-11-13 09:01:49,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:49,649][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 2.0226213932037354, acc: 0.45967742800712585)
[2024-11-13 09:01:49,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:50,357][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 2.054231643676758, acc: 0.4378109574317932)
[2024-11-13 09:01:50,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:51,038][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 1.5260851383209229, acc: 0.6226415038108826)
[2024-11-13 09:01:51,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:51,721][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 0.831477701663971, acc: 0.7954545617103577)
[2024-11-13 09:01:51,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:52,391][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 0.37905600666999817, acc: 0.8695651888847351)
[2024-11-13 09:01:52,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:53,061][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 0.8161596059799194, acc: 0.807692289352417)
[2024-11-13 09:01:53,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:53,731][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.5358577966690063, acc: 0.8571428656578064)
[2024-11-13 09:01:53,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:54,404][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 1.5677992105484009, acc: 0.5820895433425903)
[2024-11-13 09:01:54,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:55,094][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 1.281300663948059, acc: 0.6527777910232544)
[2024-11-13 09:01:55,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:55,776][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 1.3871212005615234, acc: 0.54347825050354)
[2024-11-13 09:01:55,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:56,456][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 1.5502450466156006, acc: 0.5769230723381042)
[2024-11-13 09:01:56,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:57,135][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 1.5883406400680542, acc: 0.6052631735801697)
[2024-11-13 09:01:57,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:57,812][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 1.2297923564910889, acc: 0.6734693646430969)
[2024-11-13 09:01:57,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:58,487][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 0.8173356652259827, acc: 0.7878788113594055)
[2024-11-13 09:01:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:59,180][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 1.7444571256637573, acc: 0.5257731676101685)
[2024-11-13 09:01:59,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:01:59,861][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 1.3830229043960571, acc: 0.6142857074737549)
[2024-11-13 09:01:59,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:00,582][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.810761570930481, acc: 0.5058139562606812)
[2024-11-13 09:02:00,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:01,274][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 1.767504334449768, acc: 0.5892857313156128)
[2024-11-13 09:02:01,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:01,965][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 1.72877836227417, acc: 0.5061728358268738)
[2024-11-13 09:02:02,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:02,649][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 1.1582980155944824, acc: 0.6944444179534912)
[2024-11-13 09:02:02,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:03,323][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 0.9118704199790955, acc: 0.71875)
[2024-11-13 09:02:03,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:03,994][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 0.7845331430435181, acc: 0.8461538553237915)
[2024-11-13 09:02:04,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:04,674][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 1.343228816986084, acc: 0.6739130616188049)
[2024-11-13 09:02:04,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:05,355][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 1.3762155771255493, acc: 0.5952380895614624)
[2024-11-13 09:02:05,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:06,037][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 1.5706487894058228, acc: 0.5903614163398743)
[2024-11-13 09:02:06,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:06,749][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 1.476249098777771, acc: 0.5765765905380249)
[2024-11-13 09:02:06,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:07,436][root][INFO] - Training Epoch: 3/10, step 468/574 completed (loss: 1.5368919372558594, acc: 0.5728155374526978)
[2024-11-13 09:02:07,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:08,145][root][INFO] - Training Epoch: 3/10, step 469/574 completed (loss: 1.3264703750610352, acc: 0.6585366129875183)
[2024-11-13 09:02:08,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:08,816][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 0.5247094631195068, acc: 0.875)
[2024-11-13 09:02:08,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:09,487][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 1.2224730253219604, acc: 0.5357142686843872)
[2024-11-13 09:02:09,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:10,196][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 2.0191516876220703, acc: 0.44117647409439087)
[2024-11-13 09:02:10,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:10,906][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 2.0464022159576416, acc: 0.4628821015357971)
[2024-11-13 09:02:10,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:11,597][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 1.7544656991958618, acc: 0.5208333134651184)
[2024-11-13 09:02:11,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:12,291][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 1.7803198099136353, acc: 0.5153374075889587)
[2024-11-13 09:02:12,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:12,982][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 1.8976249694824219, acc: 0.5179855823516846)
[2024-11-13 09:02:13,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:13,691][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 2.020473003387451, acc: 0.4422110617160797)
[2024-11-13 09:02:13,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:14,367][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 0.6240667104721069, acc: 0.8333333134651184)
[2024-11-13 09:02:14,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:15,045][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 0.9294747114181519, acc: 0.7272727489471436)
[2024-11-13 09:02:15,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:15,726][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 0.46811842918395996, acc: 0.8518518805503845)
[2024-11-13 09:02:15,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:16,397][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 0.7445761561393738, acc: 0.6000000238418579)
[2024-11-13 09:02:16,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:17,066][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 0.5207574367523193, acc: 0.8999999761581421)
[2024-11-13 09:02:17,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:17,764][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 1.303277611732483, acc: 0.6551724076271057)
[2024-11-13 09:02:17,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:18,440][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 0.6272595524787903, acc: 0.8387096524238586)
[2024-11-13 09:02:18,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:19,124][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.821832001209259, acc: 0.7894737124443054)
[2024-11-13 09:02:19,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:19,807][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 1.6876435279846191, acc: 0.5185185074806213)
[2024-11-13 09:02:19,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:20,479][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 1.2938793897628784, acc: 0.5714285969734192)
[2024-11-13 09:02:20,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:21,151][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 0.6578587889671326, acc: 0.7727272510528564)
[2024-11-13 09:02:21,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:21,831][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.5741581916809082, acc: 0.5538461804389954)
[2024-11-13 09:02:21,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:22,507][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 0.6774940490722656, acc: 0.8333333134651184)
[2024-11-13 09:02:22,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:23,187][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 0.85475754737854, acc: 0.7586206793785095)
[2024-11-13 09:02:23,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:23,865][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 1.3083678483963013, acc: 0.5686274766921997)
[2024-11-13 09:02:23,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:24,544][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 1.0378459692001343, acc: 0.7586206793785095)
[2024-11-13 09:02:24,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:25,216][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.4783600866794586, acc: 0.8947368264198303)
[2024-11-13 09:02:25,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:25,887][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 1.8423781394958496, acc: 0.5789473652839661)
[2024-11-13 09:02:25,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:26,582][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.5714731216430664, acc: 0.6428571343421936)
[2024-11-13 09:02:26,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:27,270][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 1.4705936908721924, acc: 0.617977499961853)
[2024-11-13 09:02:27,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:27,957][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 1.755477786064148, acc: 0.550561785697937)
[2024-11-13 09:02:28,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:28,656][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.094442844390869, acc: 0.45390069484710693)
[2024-11-13 09:02:28,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:29,356][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 1.824744701385498, acc: 0.489130437374115)
[2024-11-13 09:02:29,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:30,033][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.25058138370513916, acc: 0.8799999952316284)
[2024-11-13 09:02:30,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:30,703][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.3242013156414032, acc: 0.8846153616905212)
[2024-11-13 09:02:30,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:31,375][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.2075212299823761, acc: 0.9629629850387573)
[2024-11-13 09:02:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:32,050][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 0.7044288516044617, acc: 0.7777777910232544)
[2024-11-13 09:02:32,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:32,735][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 0.9491524696350098, acc: 0.7924528121948242)
[2024-11-13 09:02:32,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:33,411][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 0.5704270601272583, acc: 0.8275862336158752)
[2024-11-13 09:02:33,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:34,099][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.4853066205978394, acc: 0.6036036014556885)
[2024-11-13 09:02:34,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:34,785][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.2273261547088623, acc: 0.6338028311729431)
[2024-11-13 09:02:34,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:35,455][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.09967364370822906, acc: 0.949999988079071)
[2024-11-13 09:02:35,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:36,126][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.2175394594669342, acc: 0.9333333373069763)
[2024-11-13 09:02:36,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:36,799][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.5963531136512756, acc: 0.8461538553237915)
[2024-11-13 09:02:36,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:37,544][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 2.0291850566864014, acc: 0.4642857015132904)
[2024-11-13 09:02:37,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:38,261][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 1.5219218730926514, acc: 0.6111111044883728)
[2024-11-13 09:02:38,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:38,932][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 0.8175446391105652, acc: 0.75)
[2024-11-13 09:02:39,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:39,625][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 0.9101216793060303, acc: 0.6666666865348816)
[2024-11-13 09:02:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:40,330][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 1.3140233755111694, acc: 0.6805555820465088)
[2024-11-13 09:02:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:41,002][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.1636328399181366, acc: 0.9615384340286255)
[2024-11-13 09:02:41,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:41,675][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 1.0251195430755615, acc: 0.6451612710952759)
[2024-11-13 09:02:41,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:42,342][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 0.826564610004425, acc: 0.699999988079071)
[2024-11-13 09:02:42,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:43,014][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 1.3812081813812256, acc: 0.6296296119689941)
[2024-11-13 09:02:43,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:43,947][root][INFO] - Training Epoch: 3/10, step 521/574 completed (loss: 2.0015251636505127, acc: 0.4576271176338196)
[2024-11-13 09:02:44,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:44,650][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 1.8059215545654297, acc: 0.5149253606796265)
[2024-11-13 09:02:44,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:45,336][root][INFO] - Training Epoch: 3/10, step 523/574 completed (loss: 1.7668302059173584, acc: 0.5036496520042419)
[2024-11-13 09:02:45,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:46,056][root][INFO] - Training Epoch: 3/10, step 524/574 completed (loss: 1.6602739095687866, acc: 0.5400000214576721)
[2024-11-13 09:02:46,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:46,760][root][INFO] - Training Epoch: 3/10, step 525/574 completed (loss: 0.9852885603904724, acc: 0.7407407164573669)
[2024-11-13 09:02:46,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:47,442][root][INFO] - Training Epoch: 3/10, step 526/574 completed (loss: 1.001649022102356, acc: 0.7307692170143127)
[2024-11-13 09:02:47,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:48,113][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 1.3918352127075195, acc: 0.7142857313156128)
[2024-11-13 09:02:48,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:48,797][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 2.424942970275879, acc: 0.24590164422988892)
[2024-11-13 09:02:48,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:49,476][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 1.0956416130065918, acc: 0.694915235042572)
[2024-11-13 09:02:49,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:50,152][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 1.5848389863967896, acc: 0.5813953280448914)
[2024-11-13 09:02:50,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:50,826][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 1.66510009765625, acc: 0.5454545617103577)
[2024-11-13 09:02:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:51,513][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 1.6954491138458252, acc: 0.49056604504585266)
[2024-11-13 09:02:51,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:52,189][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 1.148025393486023, acc: 0.7045454382896423)
[2024-11-13 09:02:52,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:52,863][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 0.8071361780166626, acc: 0.7200000286102295)
[2024-11-13 09:02:52,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:53,535][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 0.6752792596817017, acc: 0.800000011920929)
[2024-11-13 09:02:53,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:54,218][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 0.6815024018287659, acc: 0.7272727489471436)
[2024-11-13 09:02:54,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:54,899][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.2084636688232422, acc: 0.6461538672447205)
[2024-11-13 09:02:54,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:55,595][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 1.168188214302063, acc: 0.6875)
[2024-11-13 09:02:55,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:56,272][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 0.9080332517623901, acc: 0.6875)
[2024-11-13 09:02:56,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:56,947][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 0.7380879521369934, acc: 0.7878788113594055)
[2024-11-13 09:02:57,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:57,626][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.3717844486236572, acc: 0.9375)
[2024-11-13 09:02:57,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:58,310][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.477658212184906, acc: 0.8387096524238586)
[2024-11-13 09:02:58,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:58,980][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.2713238298892975, acc: 0.95652174949646)
[2024-11-13 09:02:59,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:02:59,654][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 1.4140721559524536, acc: 0.6666666865348816)
[2024-11-13 09:02:59,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:00,329][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 0.6752448678016663, acc: 0.7804877758026123)
[2024-11-13 09:03:00,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:01,004][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 0.6033173203468323, acc: 0.7714285850524902)
[2024-11-13 09:03:01,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:01,679][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 0.705842912197113, acc: 0.8157894611358643)
[2024-11-13 09:03:01,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:02,358][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 0.65947026014328, acc: 0.7419354915618896)
[2024-11-13 09:03:02,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:03,032][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.18391063809394836, acc: 0.9200000166893005)
[2024-11-13 09:03:03,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:03,707][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 0.6787804365158081, acc: 0.7878788113594055)
[2024-11-13 09:03:03,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:04,381][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.4973506033420563, acc: 0.8500000238418579)
[2024-11-13 09:03:04,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:05,061][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 0.7714568376541138, acc: 0.7857142686843872)
[2024-11-13 09:03:05,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:05,767][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 1.720635175704956, acc: 0.5328466892242432)
[2024-11-13 09:03:05,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:06,489][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 1.1915844678878784, acc: 0.6482758522033691)
[2024-11-13 09:03:06,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:07,176][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 2.0450260639190674, acc: 0.48571428656578064)
[2024-11-13 09:03:07,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:07,862][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 1.5802477598190308, acc: 0.5695364475250244)
[2024-11-13 09:03:07,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:08,549][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 1.0848387479782104, acc: 0.6837607026100159)
[2024-11-13 09:03:08,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:09,221][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.10928957164287567, acc: 0.9599999785423279)
[2024-11-13 09:03:09,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:09,892][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.6551327109336853, acc: 0.8461538553237915)
[2024-11-13 09:03:09,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:10,563][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.2959752082824707, acc: 0.9230769276618958)
[2024-11-13 09:03:10,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:11,239][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 0.7942895889282227, acc: 0.7179487347602844)
[2024-11-13 09:03:11,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:11,945][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 1.2313473224639893, acc: 0.6333333253860474)
[2024-11-13 09:03:12,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:12,626][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 1.057373285293579, acc: 0.701298713684082)
[2024-11-13 09:03:12,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:13,303][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 0.9481858611106873, acc: 0.7708333134651184)
[2024-11-13 09:03:13,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:13,980][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 0.6280810236930847, acc: 0.8103448152542114)
[2024-11-13 09:03:14,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:14,665][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 0.985453724861145, acc: 0.75)
[2024-11-13 09:03:14,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:15,339][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 0.600411593914032, acc: 0.7631579041481018)
[2024-11-13 09:03:16,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:16,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:17,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:17,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:18,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:19,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:19,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:20,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:20,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:21,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:22,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:23,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:23,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:24,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:25,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:25,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:26,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:26,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:27,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:27,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:28,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:29,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:29,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:30,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:30,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:31,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:31,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:32,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:33,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:33,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:34,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:34,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:35,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:36,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:36,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:37,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:37,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:38,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:39,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:39,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:40,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:40,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:41,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:41,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:42,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:43,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:43,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:44,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:45,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:45,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:46,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:47,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:47,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:48,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:49,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:49,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:50,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:50,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:51,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:51,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:52,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:53,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:53,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:54,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:54,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:55,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:56,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:56,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:57,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:57,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:58,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:58,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:03:59,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:00,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:00,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:01,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:01,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:02,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:03,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:03,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:04,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:04,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:05,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:06,277][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.3192, device='cuda:0') eval_epoch_loss=tensor(1.1997, device='cuda:0') eval_epoch_acc=tensor(0.6934, device='cuda:0')
[2024-11-13 09:04:06,278][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:04:06,279][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:04:06,645][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_3_step_568_loss_1.199726939201355/model.pt
[2024-11-13 09:04:06,648][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:04:06,649][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.199726939201355
[2024-11-13 09:04:06,649][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.6933718919754028
[2024-11-13 09:04:06,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:07,336][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 0.48296424746513367, acc: 0.8518518805503845)
[2024-11-13 09:04:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:08,058][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 1.443820595741272, acc: 0.614973247051239)
[2024-11-13 09:04:08,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:08,741][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 0.4552299380302429, acc: 0.8709677457809448)
[2024-11-13 09:04:08,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:09,436][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 1.2089264392852783, acc: 0.6581196784973145)
[2024-11-13 09:04:09,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:10,144][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 1.7817976474761963, acc: 0.5255101919174194)
[2024-11-13 09:04:10,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:10,854][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 1.5834107398986816, acc: 0.5220125913619995)
[2024-11-13 09:04:11,262][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=4.0525, train_epoch_loss=1.3993, epoch time 600.802354009822s
[2024-11-13 09:04:11,262][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 09:04:11,262][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 09:04:11,262][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 09:04:11,263][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 3
[2024-11-13 09:04:11,263][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 09:04:12,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:12,602][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 0.6147594451904297, acc: 0.8148148059844971)
[2024-11-13 09:04:12,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:13,287][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 1.0024150609970093, acc: 0.7200000286102295)
[2024-11-13 09:04:13,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:13,973][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 1.5516618490219116, acc: 0.5945945978164673)
[2024-11-13 09:04:14,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:14,670][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 1.0522674322128296, acc: 0.6052631735801697)
[2024-11-13 09:04:14,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:15,359][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 1.292594313621521, acc: 0.6486486196517944)
[2024-11-13 09:04:15,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:16,043][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 0.962562084197998, acc: 0.6785714030265808)
[2024-11-13 09:04:16,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:16,728][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 1.1109451055526733, acc: 0.8163265585899353)
[2024-11-13 09:04:16,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:17,414][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 1.0758488178253174, acc: 0.800000011920929)
[2024-11-13 09:04:17,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:18,106][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.03891334682703018, acc: 1.0)
[2024-11-13 09:04:18,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:18,796][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.11541818827390671, acc: 0.9615384340286255)
[2024-11-13 09:04:18,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:19,481][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.37497326731681824, acc: 0.8888888955116272)
[2024-11-13 09:04:19,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:20,166][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 1.4025243520736694, acc: 0.6153846383094788)
[2024-11-13 09:04:20,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:20,863][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 0.7398306727409363, acc: 0.7575757503509521)
[2024-11-13 09:04:20,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:21,550][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 0.9747204184532166, acc: 0.6521739363670349)
[2024-11-13 09:04:21,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:22,238][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 0.9286088943481445, acc: 0.7450980544090271)
[2024-11-13 09:04:22,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:22,929][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 1.1312259435653687, acc: 0.7551020383834839)
[2024-11-13 09:04:23,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:23,608][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.3170648515224457, acc: 0.8947368264198303)
[2024-11-13 09:04:23,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:24,289][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 0.5880913138389587, acc: 0.7916666865348816)
[2024-11-13 09:04:24,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:24,973][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.112199306488037, acc: 0.7222222089767456)
[2024-11-13 09:04:25,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:25,654][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 0.46580013632774353, acc: 0.8421052694320679)
[2024-11-13 09:04:25,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:26,338][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 0.750398576259613, acc: 0.807692289352417)
[2024-11-13 09:04:26,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:27,020][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 0.9995437860488892, acc: 0.7586206793785095)
[2024-11-13 09:04:27,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:27,704][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 0.8264092803001404, acc: 0.800000011920929)
[2024-11-13 09:04:27,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:28,388][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.4761531949043274, acc: 0.9047619104385376)
[2024-11-13 09:04:28,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:29,071][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 0.7489453554153442, acc: 0.75)
[2024-11-13 09:04:29,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:29,767][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 1.4240527153015137, acc: 0.5849056839942932)
[2024-11-13 09:04:29,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:30,456][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 1.6428852081298828, acc: 0.5753424763679504)
[2024-11-13 09:04:30,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:31,260][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 2.142235517501831, acc: 0.4426877498626709)
[2024-11-13 09:04:31,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:31,946][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 0.9570314884185791, acc: 0.6744186282157898)
[2024-11-13 09:04:32,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:32,651][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 1.308165431022644, acc: 0.6987951993942261)
[2024-11-13 09:04:32,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:33,361][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 1.5429389476776123, acc: 0.5679012537002563)
[2024-11-13 09:04:33,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:34,048][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 1.267099380493164, acc: 0.6428571343421936)
[2024-11-13 09:04:34,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:34,729][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 0.9108502864837646, acc: 0.7407407164573669)
[2024-11-13 09:04:34,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:35,434][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.47472983598709106, acc: 0.8695651888847351)
[2024-11-13 09:04:35,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:36,136][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 1.3805118799209595, acc: 0.6638655662536621)
[2024-11-13 09:04:36,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:36,826][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 1.1424002647399902, acc: 0.7213114500045776)
[2024-11-13 09:04:36,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:37,521][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 1.2905337810516357, acc: 0.6507936716079712)
[2024-11-13 09:04:37,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:38,210][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 1.2572236061096191, acc: 0.7118644118309021)
[2024-11-13 09:04:38,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:38,903][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 0.9021033644676208, acc: 0.7471264600753784)
[2024-11-13 09:04:38,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:39,586][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.36444318294525146, acc: 0.8571428656578064)
[2024-11-13 09:04:39,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:40,271][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 1.2374215126037598, acc: 0.692307710647583)
[2024-11-13 09:04:40,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:40,977][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 1.5321578979492188, acc: 0.6081081032752991)
[2024-11-13 09:04:41,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:41,670][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 0.8613848090171814, acc: 0.692307710647583)
[2024-11-13 09:04:41,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:42,362][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 1.3054265975952148, acc: 0.6565656661987305)
[2024-11-13 09:04:42,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:43,070][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 1.3246796131134033, acc: 0.6185566782951355)
[2024-11-13 09:04:43,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:43,773][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 1.4376167058944702, acc: 0.6176470518112183)
[2024-11-13 09:04:43,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:44,462][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.17587034404277802, acc: 0.9615384340286255)
[2024-11-13 09:04:44,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:45,143][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.2994518578052521, acc: 0.9629629850387573)
[2024-11-13 09:04:45,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:45,822][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 0.8449582457542419, acc: 0.6785714030265808)
[2024-11-13 09:04:45,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:46,506][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.3629542291164398, acc: 0.8333333134651184)
[2024-11-13 09:04:46,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:47,209][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 0.8570334315299988, acc: 0.7543859481811523)
[2024-11-13 09:04:47,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:47,919][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.3252227306365967, acc: 0.682539701461792)
[2024-11-13 09:04:48,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:48,618][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.5759079456329346, acc: 0.577464759349823)
[2024-11-13 09:04:48,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:49,344][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 1.894371747970581, acc: 0.4933333396911621)
[2024-11-13 09:04:49,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:50,039][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 0.8494484424591064, acc: 0.8108108043670654)
[2024-11-13 09:04:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:50,726][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.2661604583263397, acc: 0.9230769276618958)
[2024-11-13 09:04:50,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:51,580][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.7949254512786865, acc: 0.5631399154663086)
[2024-11-13 09:04:51,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:52,358][root][INFO] - Training Epoch: 4/10, step 57/574 completed (loss: 2.1515085697174072, acc: 0.4270152449607849)
[2024-11-13 09:04:52,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:53,089][root][INFO] - Training Epoch: 4/10, step 58/574 completed (loss: 1.5093823671340942, acc: 0.6420454382896423)
[2024-11-13 09:04:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:53,801][root][INFO] - Training Epoch: 4/10, step 59/574 completed (loss: 1.6016045808792114, acc: 0.5735294222831726)
[2024-11-13 09:04:53,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:54,534][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 1.4103388786315918, acc: 0.5507246255874634)
[2024-11-13 09:04:54,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:55,289][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 1.187476396560669, acc: 0.675000011920929)
[2024-11-13 09:04:55,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:55,977][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 0.7559472918510437, acc: 0.7352941036224365)
[2024-11-13 09:04:56,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:56,672][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 0.6581318378448486, acc: 0.7777777910232544)
[2024-11-13 09:04:56,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:57,383][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 0.8294718861579895, acc: 0.78125)
[2024-11-13 09:04:57,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:58,071][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.3335343599319458, acc: 0.8965517282485962)
[2024-11-13 09:04:58,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:58,760][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 1.295452356338501, acc: 0.6607142686843872)
[2024-11-13 09:04:58,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:04:59,454][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 1.0404404401779175, acc: 0.75)
[2024-11-13 09:04:59,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:00,138][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.2523549795150757, acc: 0.8799999952316284)
[2024-11-13 09:05:00,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:00,822][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 0.7705003023147583, acc: 0.75)
[2024-11-13 09:05:00,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:01,551][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 1.0980796813964844, acc: 0.7272727489471436)
[2024-11-13 09:05:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:02,273][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 1.5874134302139282, acc: 0.5441176295280457)
[2024-11-13 09:05:02,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:02,984][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 1.3837380409240723, acc: 0.5952380895614624)
[2024-11-13 09:05:03,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:03,712][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 1.9778709411621094, acc: 0.446153849363327)
[2024-11-13 09:05:03,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:04,410][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 1.4648059606552124, acc: 0.5918367505073547)
[2024-11-13 09:05:04,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:05,113][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 1.6922043561935425, acc: 0.5)
[2024-11-13 09:05:05,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:05,854][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 1.9124984741210938, acc: 0.47445255517959595)
[2024-11-13 09:05:05,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:06,539][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.3010348379611969, acc: 0.9047619104385376)
[2024-11-13 09:05:06,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:07,233][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.19675429165363312, acc: 0.9583333134651184)
[2024-11-13 09:05:07,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:07,925][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.5226053595542908, acc: 0.8787878751754761)
[2024-11-13 09:05:08,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:08,610][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.26645514369010925, acc: 0.9230769276618958)
[2024-11-13 09:05:08,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:09,303][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 1.054050087928772, acc: 0.7115384340286255)
[2024-11-13 09:05:09,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:09,995][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 1.3232979774475098, acc: 0.6730769276618958)
[2024-11-13 09:05:10,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:10,693][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 0.7475600838661194, acc: 0.78125)
[2024-11-13 09:05:10,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:11,400][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 0.7949024438858032, acc: 0.7971014380455017)
[2024-11-13 09:05:11,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:12,095][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 0.7547203898429871, acc: 0.800000011920929)
[2024-11-13 09:05:12,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:12,782][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 0.4718482494354248, acc: 0.8260869383811951)
[2024-11-13 09:05:12,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:13,490][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.4141016006469727, acc: 0.6200000047683716)
[2024-11-13 09:05:13,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:14,197][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.117297887802124, acc: 0.708737850189209)
[2024-11-13 09:05:14,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:14,919][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.3624556064605713, acc: 0.6359223127365112)
[2024-11-13 09:05:15,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:15,652][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.7034424543380737, acc: 0.5376344323158264)
[2024-11-13 09:05:15,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:16,391][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.3139958381652832, acc: 0.6982758641242981)
[2024-11-13 09:05:16,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:17,091][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.2302759885787964, acc: 0.621052622795105)
[2024-11-13 09:05:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:17,813][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 1.8350346088409424, acc: 0.4752475321292877)
[2024-11-13 09:05:17,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:18,506][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 1.267885684967041, acc: 0.5806451439857483)
[2024-11-13 09:05:18,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:19,199][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 1.380969762802124, acc: 0.6376811861991882)
[2024-11-13 09:05:19,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:19,898][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 1.665013074874878, acc: 0.529411792755127)
[2024-11-13 09:05:19,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:20,606][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 1.592352032661438, acc: 0.5288461446762085)
[2024-11-13 09:05:20,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:21,311][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 1.750258445739746, acc: 0.540145993232727)
[2024-11-13 09:05:21,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:22,001][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 1.73350191116333, acc: 0.447761207818985)
[2024-11-13 09:05:22,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:22,686][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.46363991498947144, acc: 0.8500000238418579)
[2024-11-13 09:05:22,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:23,379][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.08615141361951828, acc: 0.9545454382896423)
[2024-11-13 09:05:23,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:24,061][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.11994820088148117, acc: 1.0)
[2024-11-13 09:05:24,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:24,747][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 0.28031492233276367, acc: 0.9318181872367859)
[2024-11-13 09:05:24,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:25,435][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 0.8299569487571716, acc: 0.7413793206214905)
[2024-11-13 09:05:25,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:26,123][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 0.6235860586166382, acc: 0.8139534592628479)
[2024-11-13 09:05:26,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:26,805][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 0.30368536710739136, acc: 0.9599999785423279)
[2024-11-13 09:05:26,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:27,485][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.048735473304986954, acc: 1.0)
[2024-11-13 09:05:27,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:28,166][root][INFO] - Training Epoch: 4/10, step 108/574 completed (loss: 0.08503358066082001, acc: 1.0)
[2024-11-13 09:05:28,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:28,853][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 0.7802172899246216, acc: 0.761904776096344)
[2024-11-13 09:05:28,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:29,562][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 0.6480072140693665, acc: 0.7692307829856873)
[2024-11-13 09:05:29,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:30,250][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 0.791337788105011, acc: 0.7543859481811523)
[2024-11-13 09:05:30,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:30,939][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 1.0179626941680908, acc: 0.719298243522644)
[2024-11-13 09:05:31,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:31,626][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 0.5340282917022705, acc: 0.7948718070983887)
[2024-11-13 09:05:31,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:32,331][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 0.5846964716911316, acc: 0.8367347121238708)
[2024-11-13 09:05:32,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:33,028][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.08013703674077988, acc: 1.0)
[2024-11-13 09:05:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:33,727][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 1.3821074962615967, acc: 0.6507936716079712)
[2024-11-13 09:05:33,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:34,424][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 1.1428027153015137, acc: 0.6910569071769714)
[2024-11-13 09:05:34,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:35,127][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 1.018026351928711, acc: 0.7419354915618896)
[2024-11-13 09:05:35,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:35,890][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.4574800729751587, acc: 0.608364999294281)
[2024-11-13 09:05:35,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:36,585][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 0.9364795088768005, acc: 0.7333333492279053)
[2024-11-13 09:05:36,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:37,277][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 0.8648414611816406, acc: 0.807692289352417)
[2024-11-13 09:05:37,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:37,959][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.1795779913663864, acc: 0.9166666865348816)
[2024-11-13 09:05:38,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:38,640][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.27583977580070496, acc: 0.8947368264198303)
[2024-11-13 09:05:38,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:39,344][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 1.4651095867156982, acc: 0.5950919985771179)
[2024-11-13 09:05:39,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:40,064][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.4721423387527466, acc: 0.6319444179534912)
[2024-11-13 09:05:40,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:40,764][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 1.6096030473709106, acc: 0.5249999761581421)
[2024-11-13 09:05:40,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:41,504][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 1.722224235534668, acc: 0.5178571343421936)
[2024-11-13 09:05:41,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:42,224][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.2701756954193115, acc: 0.6461538672447205)
[2024-11-13 09:05:42,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:42,963][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.496440052986145, acc: 0.5661764740943909)
[2024-11-13 09:05:43,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:43,659][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 0.4110632538795471, acc: 0.9230769276618958)
[2024-11-13 09:05:43,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:44,344][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.030980030074715614, acc: 1.0)
[2024-11-13 09:05:44,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:45,043][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 0.7362140417098999, acc: 0.75)
[2024-11-13 09:05:45,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:45,727][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 0.8761234879493713, acc: 0.782608687877655)
[2024-11-13 09:05:45,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:46,412][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 1.0108038187026978, acc: 0.6285714507102966)
[2024-11-13 09:05:46,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:47,097][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.7430291771888733, acc: 0.807692289352417)
[2024-11-13 09:05:47,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:47,782][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 1.0112950801849365, acc: 0.7142857313156128)
[2024-11-13 09:05:48,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:49,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:50,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:51,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:52,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:52,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:53,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:54,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:54,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:55,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:55,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:56,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:56,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:57,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:58,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:58,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:59,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:05:59,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:00,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:00,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:01,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:02,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:02,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:03,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:03,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:04,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:05,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:05,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:06,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:06,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:07,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:08,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:08,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:09,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:09,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:10,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:10,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:11,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:12,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:12,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:13,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:13,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:14,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:15,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:15,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:16,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:16,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:17,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:18,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:19,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:19,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:20,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:20,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:21,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:22,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:22,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:23,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:23,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:24,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:25,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:25,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:26,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:26,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:27,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:28,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:28,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:29,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:30,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:30,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:31,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:32,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:32,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:33,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:33,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:34,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:35,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:35,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:36,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:36,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:37,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:37,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:38,964][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4325, device='cuda:0') eval_epoch_loss=tensor(0.8889, device='cuda:0') eval_epoch_acc=tensor(0.7517, device='cuda:0')
[2024-11-13 09:06:38,965][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:06:38,965][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:06:39,397][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_4_step_137_loss_0.8889079689979553/model.pt
[2024-11-13 09:06:39,402][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:06:39,402][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 0.8889079689979553
[2024-11-13 09:06:39,403][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.7517057061195374
[2024-11-13 09:06:39,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:40,091][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 0.7375481724739075, acc: 0.800000011920929)
[2024-11-13 09:06:40,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:40,759][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 1.0022372007369995, acc: 0.6521739363670349)
[2024-11-13 09:06:40,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:41,430][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 0.575965404510498, acc: 0.8571428656578064)
[2024-11-13 09:06:41,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:42,103][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 0.8153668642044067, acc: 0.7307692170143127)
[2024-11-13 09:06:42,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:42,777][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 1.1633751392364502, acc: 0.6451612710952759)
[2024-11-13 09:06:42,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:43,462][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 1.0216751098632812, acc: 0.6216216087341309)
[2024-11-13 09:06:43,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:44,170][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 1.0125494003295898, acc: 0.6315789222717285)
[2024-11-13 09:06:44,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:44,864][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 1.090705156326294, acc: 0.6865671873092651)
[2024-11-13 09:06:44,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:45,554][root][INFO] - Training Epoch: 4/10, step 145/574 completed (loss: 1.2359957695007324, acc: 0.6530612111091614)
[2024-11-13 09:06:45,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:46,254][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 1.3707956075668335, acc: 0.563829779624939)
[2024-11-13 09:06:46,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:46,933][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 1.384884238243103, acc: 0.6571428775787354)
[2024-11-13 09:06:47,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:47,615][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 1.5785434246063232, acc: 0.5)
[2024-11-13 09:06:47,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:48,287][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 0.9837730526924133, acc: 0.782608687877655)
[2024-11-13 09:06:48,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:48,960][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 1.468185305595398, acc: 0.48275861144065857)
[2024-11-13 09:06:49,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:49,635][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 1.332136869430542, acc: 0.5652173757553101)
[2024-11-13 09:06:49,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:50,318][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 1.2628401517868042, acc: 0.694915235042572)
[2024-11-13 09:06:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:50,997][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 1.3923735618591309, acc: 0.6140350699424744)
[2024-11-13 09:06:51,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:51,681][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 1.1730209589004517, acc: 0.6891891956329346)
[2024-11-13 09:06:51,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:52,352][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 0.7433834075927734, acc: 0.75)
[2024-11-13 09:06:52,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:53,024][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 0.38958483934402466, acc: 0.8695651888847351)
[2024-11-13 09:06:53,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:53,700][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 1.2077621221542358, acc: 0.7368420958518982)
[2024-11-13 09:06:53,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:54,386][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.0705136060714722, acc: 0.6756756901741028)
[2024-11-13 09:06:54,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:55,065][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 1.2792022228240967, acc: 0.5555555820465088)
[2024-11-13 09:06:55,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:55,746][root][INFO] - Training Epoch: 4/10, step 160/574 completed (loss: 0.9224860668182373, acc: 0.7441860437393188)
[2024-11-13 09:06:55,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:56,427][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 0.7623298168182373, acc: 0.7882353067398071)
[2024-11-13 09:06:56,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:57,110][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 1.532524585723877, acc: 0.6067415475845337)
[2024-11-13 09:06:57,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:57,792][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 0.9497373700141907, acc: 0.7727272510528564)
[2024-11-13 09:06:57,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:58,462][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 1.0658793449401855, acc: 0.6190476417541504)
[2024-11-13 09:06:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:59,147][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 0.9194620847702026, acc: 0.7931034564971924)
[2024-11-13 09:06:59,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:06:59,829][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 0.5643935203552246, acc: 0.795918345451355)
[2024-11-13 09:06:59,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:00,512][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 0.5149980187416077, acc: 0.7799999713897705)
[2024-11-13 09:07:00,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:01,196][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 0.8472573757171631, acc: 0.7361111044883728)
[2024-11-13 09:07:01,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:01,884][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 1.3007004261016846, acc: 0.6960784196853638)
[2024-11-13 09:07:01,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:02,612][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 1.815961241722107, acc: 0.5136986374855042)
[2024-11-13 09:07:02,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:03,285][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.5331659317016602, acc: 0.9166666865348816)
[2024-11-13 09:07:03,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:03,968][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.4691879153251648, acc: 0.8148148059844971)
[2024-11-13 09:07:04,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:04,643][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 0.8269290924072266, acc: 0.75)
[2024-11-13 09:07:04,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:05,348][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.124132513999939, acc: 0.7079645991325378)
[2024-11-13 09:07:05,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:06,026][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 0.869748592376709, acc: 0.7681159377098083)
[2024-11-13 09:07:06,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:06,711][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 0.6620919108390808, acc: 0.7840909361839294)
[2024-11-13 09:07:06,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:07,420][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 1.6534979343414307, acc: 0.5267175436019897)
[2024-11-13 09:07:07,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:08,122][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 1.224488377571106, acc: 0.6296296119689941)
[2024-11-13 09:07:08,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:08,800][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 0.7601102590560913, acc: 0.7213114500045776)
[2024-11-13 09:07:08,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:09,484][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.12695623934268951, acc: 1.0)
[2024-11-13 09:07:09,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:10,157][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 0.7734211683273315, acc: 0.8799999952316284)
[2024-11-13 09:07:10,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:10,830][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.2581597864627838, acc: 0.9285714030265808)
[2024-11-13 09:07:10,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:11,522][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 0.8714319467544556, acc: 0.7560975551605225)
[2024-11-13 09:07:11,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:12,253][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 1.4038772583007812, acc: 0.6042296290397644)
[2024-11-13 09:07:12,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:12,983][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 1.4682044982910156, acc: 0.590778112411499)
[2024-11-13 09:07:13,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:13,705][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 1.5510388612747192, acc: 0.550000011920929)
[2024-11-13 09:07:13,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:14,478][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 1.5211031436920166, acc: 0.5872420072555542)
[2024-11-13 09:07:14,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:15,218][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 1.3263158798217773, acc: 0.6049821972846985)
[2024-11-13 09:07:15,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:15,944][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 0.9269003868103027, acc: 0.7599999904632568)
[2024-11-13 09:07:16,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:16,630][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 1.8479280471801758, acc: 0.4883720874786377)
[2024-11-13 09:07:16,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:17,329][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.4916890859603882, acc: 0.5873016119003296)
[2024-11-13 09:07:17,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:18,023][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.5545756816864014, acc: 0.5227272510528564)
[2024-11-13 09:07:18,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:18,705][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 1.038905143737793, acc: 0.658823549747467)
[2024-11-13 09:07:18,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:19,416][root][INFO] - Training Epoch: 4/10, step 194/574 completed (loss: 1.2862160205841064, acc: 0.6419752836227417)
[2024-11-13 09:07:19,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:20,102][root][INFO] - Training Epoch: 4/10, step 195/574 completed (loss: 0.8781346082687378, acc: 0.7419354915618896)
[2024-11-13 09:07:20,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:20,777][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.2740868031978607, acc: 0.9285714030265808)
[2024-11-13 09:07:20,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:21,451][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 1.194643497467041, acc: 0.75)
[2024-11-13 09:07:21,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:22,130][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 0.7969728708267212, acc: 0.7352941036224365)
[2024-11-13 09:07:22,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:22,816][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 1.2139472961425781, acc: 0.7132353186607361)
[2024-11-13 09:07:22,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:23,503][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 1.3250854015350342, acc: 0.6355932354927063)
[2024-11-13 09:07:23,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:24,190][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 1.2497854232788086, acc: 0.6492537260055542)
[2024-11-13 09:07:24,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:24,878][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 1.2123897075653076, acc: 0.6310679316520691)
[2024-11-13 09:07:24,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:25,568][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 1.0636777877807617, acc: 0.7142857313156128)
[2024-11-13 09:07:25,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:26,258][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 0.7496952414512634, acc: 0.7802197933197021)
[2024-11-13 09:07:26,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:26,979][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 1.173219919204712, acc: 0.6726457476615906)
[2024-11-13 09:07:27,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:27,702][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 1.2703303098678589, acc: 0.6692913174629211)
[2024-11-13 09:07:27,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:28,418][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 0.8814316987991333, acc: 0.7801724076271057)
[2024-11-13 09:07:28,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:29,131][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 1.0172765254974365, acc: 0.7536231875419617)
[2024-11-13 09:07:29,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:29,848][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 1.0216246843338013, acc: 0.6926069855690002)
[2024-11-13 09:07:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:30,565][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 1.1464656591415405, acc: 0.6521739363670349)
[2024-11-13 09:07:30,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:31,237][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 0.20405307412147522, acc: 0.9130434989929199)
[2024-11-13 09:07:31,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:31,908][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 0.4897916615009308, acc: 0.8571428656578064)
[2024-11-13 09:07:31,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:32,587][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 0.28577399253845215, acc: 0.8723404407501221)
[2024-11-13 09:07:32,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:33,290][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 0.6854901909828186, acc: 0.7769230604171753)
[2024-11-13 09:07:33,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:33,967][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 0.58953458070755, acc: 0.8513513803482056)
[2024-11-13 09:07:34,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:34,663][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 0.27566611766815186, acc: 0.9069767594337463)
[2024-11-13 09:07:34,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:35,350][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 0.5782570242881775, acc: 0.8648648858070374)
[2024-11-13 09:07:35,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:36,038][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 0.4527413249015808, acc: 0.8444444537162781)
[2024-11-13 09:07:36,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:36,712][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.3283255398273468, acc: 0.9090909361839294)
[2024-11-13 09:07:36,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:37,384][root][INFO] - Training Epoch: 4/10, step 220/574 completed (loss: 0.03910909593105316, acc: 1.0)
[2024-11-13 09:07:37,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:38,067][root][INFO] - Training Epoch: 4/10, step 221/574 completed (loss: 0.15358667075634003, acc: 0.9599999785423279)
[2024-11-13 09:07:38,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:38,751][root][INFO] - Training Epoch: 4/10, step 222/574 completed (loss: 1.2808820009231567, acc: 0.6153846383094788)
[2024-11-13 09:07:38,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:39,464][root][INFO] - Training Epoch: 4/10, step 223/574 completed (loss: 0.8597651124000549, acc: 0.77173912525177)
[2024-11-13 09:07:39,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:40,173][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 0.9580997824668884, acc: 0.7386363744735718)
[2024-11-13 09:07:40,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:40,878][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 1.3447813987731934, acc: 0.6063829660415649)
[2024-11-13 09:07:40,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:41,568][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 0.6106007695198059, acc: 0.8113207817077637)
[2024-11-13 09:07:41,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:42,248][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 0.46853378415107727, acc: 0.8666666746139526)
[2024-11-13 09:07:42,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:42,927][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.41535311937332153, acc: 0.9069767594337463)
[2024-11-13 09:07:43,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:43,604][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 0.57680344581604, acc: 0.8999999761581421)
[2024-11-13 09:07:43,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:44,291][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 1.8555622100830078, acc: 0.5473684072494507)
[2024-11-13 09:07:44,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:44,979][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 1.0867573022842407, acc: 0.7444444298744202)
[2024-11-13 09:07:45,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:45,690][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 1.266567349433899, acc: 0.6388888955116272)
[2024-11-13 09:07:45,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:46,399][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 1.4558732509613037, acc: 0.6009174585342407)
[2024-11-13 09:07:46,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:47,105][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 1.3139368295669556, acc: 0.6461538672447205)
[2024-11-13 09:07:47,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:47,774][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 0.3507128357887268, acc: 0.8947368264198303)
[2024-11-13 09:07:47,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:48,445][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.35941872000694275, acc: 0.9166666865348816)
[2024-11-13 09:07:48,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:49,115][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 0.7833254337310791, acc: 0.8181818127632141)
[2024-11-13 09:07:49,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:49,787][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 0.5355755090713501, acc: 0.7777777910232544)
[2024-11-13 09:07:49,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:50,461][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 0.7225476503372192, acc: 0.7714285850524902)
[2024-11-13 09:07:50,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:51,145][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 0.6405705809593201, acc: 0.8181818127632141)
[2024-11-13 09:07:51,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:51,818][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 0.5683401823043823, acc: 0.8181818127632141)
[2024-11-13 09:07:51,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:52,504][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.6107479333877563, acc: 0.5161290168762207)
[2024-11-13 09:07:52,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:53,183][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 1.0303902626037598, acc: 0.7045454382896423)
[2024-11-13 09:07:53,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:53,854][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.013772903010249138, acc: 1.0)
[2024-11-13 09:07:53,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:54,525][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 0.09271827340126038, acc: 1.0)
[2024-11-13 09:07:54,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:55,196][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.13708312809467316, acc: 0.9677419066429138)
[2024-11-13 09:07:55,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:55,878][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.3534395098686218, acc: 0.949999988079071)
[2024-11-13 09:07:55,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:56,555][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 0.5745683908462524, acc: 0.7837837934494019)
[2024-11-13 09:07:56,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:57,228][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 0.3955753743648529, acc: 0.8918918967247009)
[2024-11-13 09:07:57,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:57,901][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 0.41845396161079407, acc: 0.8918918967247009)
[2024-11-13 09:07:57,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:58,581][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 0.6874611377716064, acc: 0.779411792755127)
[2024-11-13 09:07:58,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:59,260][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.16770116984844208, acc: 0.9268292784690857)
[2024-11-13 09:07:59,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:07:59,935][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.0359642393887043, acc: 1.0)
[2024-11-13 09:08:00,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:00,607][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.04636580869555473, acc: 1.0)
[2024-11-13 09:08:00,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:01,277][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.17792446911334991, acc: 0.9032257795333862)
[2024-11-13 09:08:01,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:01,955][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 0.5483437776565552, acc: 0.8245614171028137)
[2024-11-13 09:08:02,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:02,632][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 0.4082959294319153, acc: 0.8571428656578064)
[2024-11-13 09:08:02,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:03,325][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 0.28941428661346436, acc: 0.9078947305679321)
[2024-11-13 09:08:03,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:04,032][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 0.8003972172737122, acc: 0.7924528121948242)
[2024-11-13 09:08:04,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:04,746][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 0.9516260027885437, acc: 0.7583333253860474)
[2024-11-13 09:08:04,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:05,420][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 0.3732646107673645, acc: 0.8888888955116272)
[2024-11-13 09:08:05,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:06,094][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 0.7249186635017395, acc: 0.774193525314331)
[2024-11-13 09:08:06,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:06,784][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 1.7737375497817993, acc: 0.6399999856948853)
[2024-11-13 09:08:06,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:07,461][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 0.8886873722076416, acc: 0.7708333134651184)
[2024-11-13 09:08:07,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:08,178][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 1.7742239236831665, acc: 0.4880000054836273)
[2024-11-13 09:08:08,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:08,861][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 1.6518152952194214, acc: 0.5280898809432983)
[2024-11-13 09:08:08,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:09,555][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 1.1305214166641235, acc: 0.6351351141929626)
[2024-11-13 09:08:09,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:10,241][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 0.8019818663597107, acc: 0.8103448152542114)
[2024-11-13 09:08:10,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:10,913][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.31970635056495667, acc: 0.9545454382896423)
[2024-11-13 09:08:10,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:11,585][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.4346849322319031, acc: 0.8181818127632141)
[2024-11-13 09:08:11,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:12,258][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.29948073625564575, acc: 0.875)
[2024-11-13 09:08:12,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:12,929][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 0.13346083462238312, acc: 0.9666666388511658)
[2024-11-13 09:08:13,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:13,609][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 0.7158568501472473, acc: 0.800000011920929)
[2024-11-13 09:08:13,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:14,285][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 0.32953834533691406, acc: 0.90625)
[2024-11-13 09:08:14,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:14,956][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.2506030201911926, acc: 0.9666666388511658)
[2024-11-13 09:08:15,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:15,628][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 0.7583737373352051, acc: 0.8275862336158752)
[2024-11-13 09:08:15,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:16,298][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 0.42999568581581116, acc: 0.8799999952316284)
[2024-11-13 09:08:16,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:16,974][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 1.1222909688949585, acc: 0.6170212626457214)
[2024-11-13 09:08:17,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:17,651][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 0.6360895037651062, acc: 0.8541666865348816)
[2024-11-13 09:08:18,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:19,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:19,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:20,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:20,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:22,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:22,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:23,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:23,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:24,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:24,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:26,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:26,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:27,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:27,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:28,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:29,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:29,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:30,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:30,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:31,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:31,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:32,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:33,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:33,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:34,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:34,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:35,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:36,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:36,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:37,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:37,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:38,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:38,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:39,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:40,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:40,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:41,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:41,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:42,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:43,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:43,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:44,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:44,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:45,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:45,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:46,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:47,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:47,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:48,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:48,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:49,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:50,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:50,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:51,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:51,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:52,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:53,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:53,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:54,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:54,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:55,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:56,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:56,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:57,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:57,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:58,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:08:59,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:00,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:01,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:01,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:02,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:03,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:03,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:04,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:04,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:05,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:06,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:06,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:07,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:07,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:08,724][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.5132, device='cuda:0') eval_epoch_loss=tensor(0.9216, device='cuda:0') eval_epoch_acc=tensor(0.7419, device='cuda:0')
[2024-11-13 09:09:08,725][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:09:08,725][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:09:09,100][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_4_step_280_loss_0.9215673208236694/model.pt
[2024-11-13 09:09:09,104][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:09:09,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:09,808][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 0.31030452251434326, acc: 0.8636363744735718)
[2024-11-13 09:09:09,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:10,493][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 1.310907006263733, acc: 0.6024096608161926)
[2024-11-13 09:09:10,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:11,187][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 1.1409687995910645, acc: 0.7037037014961243)
[2024-11-13 09:09:11,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:11,862][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 0.9459670186042786, acc: 0.7631579041481018)
[2024-11-13 09:09:11,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:12,550][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 0.9061552286148071, acc: 0.6764705777168274)
[2024-11-13 09:09:12,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:13,227][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 0.40494710206985474, acc: 0.925000011920929)
[2024-11-13 09:09:13,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:13,913][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 0.9158040285110474, acc: 0.7578125)
[2024-11-13 09:09:13,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:14,615][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 0.938397228717804, acc: 0.7519999742507935)
[2024-11-13 09:09:14,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:15,298][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 0.6809109449386597, acc: 0.8131868243217468)
[2024-11-13 09:09:15,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:15,986][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 0.9878625273704529, acc: 0.739130437374115)
[2024-11-13 09:09:16,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:16,696][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 1.1819616556167603, acc: 0.6701030731201172)
[2024-11-13 09:09:16,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:17,373][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.05275503545999527, acc: 1.0)
[2024-11-13 09:09:17,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:18,050][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 1.0155918598175049, acc: 0.6428571343421936)
[2024-11-13 09:09:18,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:18,730][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 0.7755008339881897, acc: 0.8103448152542114)
[2024-11-13 09:09:18,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:19,413][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 0.7204230427742004, acc: 0.7272727489471436)
[2024-11-13 09:09:19,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:20,139][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.1540329456329346, acc: 0.6804123520851135)
[2024-11-13 09:09:20,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:20,823][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 0.8960543274879456, acc: 0.7758620977401733)
[2024-11-13 09:09:20,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:21,508][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 0.2812664210796356, acc: 0.9629629850387573)
[2024-11-13 09:09:21,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:22,184][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 0.6050630807876587, acc: 0.8157894611358643)
[2024-11-13 09:09:22,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:22,862][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 0.5999293327331543, acc: 0.8928571343421936)
[2024-11-13 09:09:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:23,536][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 0.444568932056427, acc: 0.90625)
[2024-11-13 09:09:23,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:24,261][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 0.6446460485458374, acc: 0.8113207817077637)
[2024-11-13 09:09:24,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:24,939][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.12386342138051987, acc: 0.9811320900917053)
[2024-11-13 09:09:25,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:25,623][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 0.12838102877140045, acc: 1.0)
[2024-11-13 09:09:25,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:26,298][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 0.7035054564476013, acc: 0.78125)
[2024-11-13 09:09:26,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:26,984][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 0.40592262148857117, acc: 0.9180327653884888)
[2024-11-13 09:09:27,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:27,659][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.42261263728141785, acc: 0.8666666746139526)
[2024-11-13 09:09:27,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:28,329][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.15764079988002777, acc: 0.9473684430122375)
[2024-11-13 09:09:28,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:29,021][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 0.6920706033706665, acc: 0.7971014380455017)
[2024-11-13 09:09:29,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:29,710][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 0.5224097967147827, acc: 0.8472222089767456)
[2024-11-13 09:09:29,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:30,406][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 0.6199257373809814, acc: 0.8433734774589539)
[2024-11-13 09:09:30,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:31,103][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 0.8345304727554321, acc: 0.7435897588729858)
[2024-11-13 09:09:31,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:31,806][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 0.9790006279945374, acc: 0.7653061151504517)
[2024-11-13 09:09:31,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:32,479][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.05282355844974518, acc: 1.0)
[2024-11-13 09:09:32,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:33,150][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.18396109342575073, acc: 0.9583333134651184)
[2024-11-13 09:09:33,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:33,824][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.34358829259872437, acc: 0.9354838728904724)
[2024-11-13 09:09:33,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:34,497][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 0.05698533356189728, acc: 0.9677419066429138)
[2024-11-13 09:09:34,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:35,192][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 0.632858157157898, acc: 0.8358209133148193)
[2024-11-13 09:09:35,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:35,888][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 0.3704400062561035, acc: 0.8653846383094788)
[2024-11-13 09:09:35,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:36,572][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 0.6387090086936951, acc: 0.8444444537162781)
[2024-11-13 09:09:36,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:37,251][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 0.4606288969516754, acc: 0.8870967626571655)
[2024-11-13 09:09:37,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:37,930][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.08755207061767578, acc: 1.0)
[2024-11-13 09:09:38,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:38,615][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 0.6103096008300781, acc: 0.7407407164573669)
[2024-11-13 09:09:38,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:39,290][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 1.6333211660385132, acc: 0.5714285969734192)
[2024-11-13 09:09:39,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:39,966][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.0530182123184204, acc: 0.692307710647583)
[2024-11-13 09:09:40,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:40,651][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 1.1645997762680054, acc: 0.6341463327407837)
[2024-11-13 09:09:40,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:41,334][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.257832407951355, acc: 0.6052631735801697)
[2024-11-13 09:09:41,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:42,008][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.1655571013689041, acc: 0.9473684430122375)
[2024-11-13 09:09:42,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:42,681][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.043963897973299026, acc: 1.0)
[2024-11-13 09:09:42,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:43,353][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 0.6206897497177124, acc: 0.8148148059844971)
[2024-11-13 09:09:43,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:44,026][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.017075425013899803, acc: 1.0)
[2024-11-13 09:09:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:44,708][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 0.47867780923843384, acc: 0.8709677457809448)
[2024-11-13 09:09:44,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:45,387][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 0.2779739499092102, acc: 0.9649122953414917)
[2024-11-13 09:09:45,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:46,059][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 0.656233549118042, acc: 0.84375)
[2024-11-13 09:09:46,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:46,742][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 0.13972297310829163, acc: 0.9666666388511658)
[2024-11-13 09:09:46,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:47,417][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 0.521712064743042, acc: 0.7368420958518982)
[2024-11-13 09:09:47,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:48,108][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 1.4481106996536255, acc: 0.5799999833106995)
[2024-11-13 09:09:48,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:48,796][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 1.417405128479004, acc: 0.5287356376647949)
[2024-11-13 09:09:48,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:49,474][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 1.5424238443374634, acc: 0.542553186416626)
[2024-11-13 09:09:49,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:50,156][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 1.4462347030639648, acc: 0.6265060305595398)
[2024-11-13 09:09:50,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:50,838][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.09313260763883591, acc: 0.95652174949646)
[2024-11-13 09:09:50,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:51,512][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 0.87611323595047, acc: 0.7435897588729858)
[2024-11-13 09:09:51,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:52,193][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 1.2670843601226807, acc: 0.7349397540092468)
[2024-11-13 09:09:52,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:52,877][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 0.7189146280288696, acc: 0.7735849022865295)
[2024-11-13 09:09:52,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:53,555][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 0.7122102975845337, acc: 0.7848101258277893)
[2024-11-13 09:09:53,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:54,232][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 0.4679605960845947, acc: 0.8627451062202454)
[2024-11-13 09:09:54,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:54,913][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 1.0196956396102905, acc: 0.746268630027771)
[2024-11-13 09:09:54,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:55,590][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.022823404520750046, acc: 1.0)
[2024-11-13 09:09:55,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:56,262][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 0.46574175357818604, acc: 0.8799999952316284)
[2024-11-13 09:09:56,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:56,948][root][INFO] - Training Epoch: 4/10, step 349/574 completed (loss: 0.9380015134811401, acc: 0.7222222089767456)
[2024-11-13 09:09:57,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:57,634][root][INFO] - Training Epoch: 4/10, step 350/574 completed (loss: 0.7239733338356018, acc: 0.7674418687820435)
[2024-11-13 09:09:57,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:58,311][root][INFO] - Training Epoch: 4/10, step 351/574 completed (loss: 0.5204670429229736, acc: 0.8974359035491943)
[2024-11-13 09:09:58,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:58,990][root][INFO] - Training Epoch: 4/10, step 352/574 completed (loss: 0.9932891130447388, acc: 0.6666666865348816)
[2024-11-13 09:09:59,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:09:59,665][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.07392500340938568, acc: 1.0)
[2024-11-13 09:09:59,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:00,338][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 0.8285902738571167, acc: 0.7307692170143127)
[2024-11-13 09:10:00,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:01,019][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 1.23870849609375, acc: 0.6483516693115234)
[2024-11-13 09:10:01,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:01,736][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 1.1153525114059448, acc: 0.686956524848938)
[2024-11-13 09:10:01,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:02,416][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 0.7053402066230774, acc: 0.782608687877655)
[2024-11-13 09:10:02,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:03,091][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 0.9203097820281982, acc: 0.7346938848495483)
[2024-11-13 09:10:03,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:03,764][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.010044585913419724, acc: 1.0)
[2024-11-13 09:10:03,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:04,436][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.2336423397064209, acc: 0.8846153616905212)
[2024-11-13 09:10:04,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:05,110][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 0.5499687790870667, acc: 0.8536585569381714)
[2024-11-13 09:10:05,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:05,785][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 0.5456173419952393, acc: 0.8444444537162781)
[2024-11-13 09:10:05,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:06,465][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 0.7177694439888, acc: 0.8157894611358643)
[2024-11-13 09:10:06,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:07,151][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 0.42580023407936096, acc: 0.9024389982223511)
[2024-11-13 09:10:07,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:07,822][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 0.5136518478393555, acc: 0.8787878751754761)
[2024-11-13 09:10:07,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:08,491][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.03003862500190735, acc: 1.0)
[2024-11-13 09:10:08,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:09,163][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.010581971146166325, acc: 1.0)
[2024-11-13 09:10:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:09,844][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.08428704738616943, acc: 0.9642857313156128)
[2024-11-13 09:10:09,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:10,532][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 0.45375585556030273, acc: 0.84375)
[2024-11-13 09:10:10,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:11,246][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 1.0296381711959839, acc: 0.7333333492279053)
[2024-11-13 09:10:11,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:11,950][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 0.48546984791755676, acc: 0.8679245114326477)
[2024-11-13 09:10:12,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:12,632][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 0.5511518716812134, acc: 0.8222222328186035)
[2024-11-13 09:10:12,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:13,313][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 0.3398118317127228, acc: 0.9285714030265808)
[2024-11-13 09:10:13,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:13,997][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.1435217261314392, acc: 1.0)
[2024-11-13 09:10:14,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:14,674][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.09391294419765472, acc: 0.9599999785423279)
[2024-11-13 09:10:14,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:15,343][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.13203133642673492, acc: 0.95652174949646)
[2024-11-13 09:10:15,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:16,021][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 0.3546406924724579, acc: 0.875)
[2024-11-13 09:10:16,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:16,702][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 0.3052206039428711, acc: 0.9368420839309692)
[2024-11-13 09:10:16,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:17,414][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 0.6793994307518005, acc: 0.8203592896461487)
[2024-11-13 09:10:17,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:18,101][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 0.4756351411342621, acc: 0.8796992301940918)
[2024-11-13 09:10:18,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:18,825][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 0.9895356297492981, acc: 0.7486631274223328)
[2024-11-13 09:10:18,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:19,527][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 0.3771793842315674, acc: 0.9009009003639221)
[2024-11-13 09:10:19,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:20,196][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.0783708244562149, acc: 0.9642857313156128)
[2024-11-13 09:10:20,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:20,866][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.06626801192760468, acc: 0.9642857313156128)
[2024-11-13 09:10:20,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:21,535][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 0.06395063549280167, acc: 1.0)
[2024-11-13 09:10:21,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:22,206][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.13368172943592072, acc: 0.9444444179534912)
[2024-11-13 09:10:22,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:22,876][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.0497371144592762, acc: 1.0)
[2024-11-13 09:10:22,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:23,553][root][INFO] - Training Epoch: 4/10, step 388/574 completed (loss: 0.012499088421463966, acc: 1.0)
[2024-11-13 09:10:23,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:24,226][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.09734422713518143, acc: 0.949999988079071)
[2024-11-13 09:10:24,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:24,899][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.0816420465707779, acc: 1.0)
[2024-11-13 09:10:24,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:25,576][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 1.2205442190170288, acc: 0.6851851940155029)
[2024-11-13 09:10:25,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:26,258][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 1.1342352628707886, acc: 0.6407766938209534)
[2024-11-13 09:10:26,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:26,967][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 1.366083025932312, acc: 0.6838235259056091)
[2024-11-13 09:10:27,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:27,656][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 1.4436275959014893, acc: 0.6200000047683716)
[2024-11-13 09:10:27,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:28,343][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 1.078006625175476, acc: 0.6666666865348816)
[2024-11-13 09:10:28,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:29,017][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 0.6042375564575195, acc: 0.7674418687820435)
[2024-11-13 09:10:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:29,689][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.13479973375797272, acc: 0.9583333134651184)
[2024-11-13 09:10:29,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:30,374][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 0.39126071333885193, acc: 0.8372092843055725)
[2024-11-13 09:10:30,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:31,044][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 0.2850261628627777, acc: 0.8799999952316284)
[2024-11-13 09:10:31,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:31,732][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 0.6229382753372192, acc: 0.7941176295280457)
[2024-11-13 09:10:31,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:32,412][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 0.8322396874427795, acc: 0.7733333110809326)
[2024-11-13 09:10:32,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:33,088][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 0.3571191728115082, acc: 0.8787878751754761)
[2024-11-13 09:10:33,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:33,773][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 0.6992477178573608, acc: 0.8787878751754761)
[2024-11-13 09:10:33,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:34,445][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.00645303912460804, acc: 1.0)
[2024-11-13 09:10:34,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:35,115][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.3091903626918793, acc: 0.8888888955116272)
[2024-11-13 09:10:35,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:35,783][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.10980203002691269, acc: 0.9599999785423279)
[2024-11-13 09:10:35,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:36,459][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.08253046870231628, acc: 0.9722222089767456)
[2024-11-13 09:10:36,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:37,131][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.0811491310596466, acc: 0.9629629850387573)
[2024-11-13 09:10:37,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:37,802][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.04500385746359825, acc: 1.0)
[2024-11-13 09:10:37,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:38,481][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 0.12497144192457199, acc: 0.982758641242981)
[2024-11-13 09:10:38,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:39,155][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.1704632192850113, acc: 0.9642857313156128)
[2024-11-13 09:10:39,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:39,839][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.3854942321777344, acc: 0.8666666746139526)
[2024-11-13 09:10:39,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:40,514][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.43806296586990356, acc: 0.8787878751754761)
[2024-11-13 09:10:40,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:41,185][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.21951411664485931, acc: 0.8636363744735718)
[2024-11-13 09:10:41,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:41,864][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 0.7451220750808716, acc: 0.8235294222831726)
[2024-11-13 09:10:41,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:42,549][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 0.16199538111686707, acc: 0.9615384340286255)
[2024-11-13 09:10:42,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:43,224][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 0.3058657646179199, acc: 0.8333333134651184)
[2024-11-13 09:10:43,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:43,904][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 0.23547880351543427, acc: 0.925000011920929)
[2024-11-13 09:10:43,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:44,573][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 0.18969979882240295, acc: 0.949999988079071)
[2024-11-13 09:10:44,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:45,246][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.13811129331588745, acc: 0.9523809552192688)
[2024-11-13 09:10:45,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:45,918][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.21392609179019928, acc: 0.9333333373069763)
[2024-11-13 09:10:46,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:46,590][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.398523211479187, acc: 0.90625)
[2024-11-13 09:10:47,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:48,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:48,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:49,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:49,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:50,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:51,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:51,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:52,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:52,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:53,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:54,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:54,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:55,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:55,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:56,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:56,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:57,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:58,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:58,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:59,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:10:59,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:00,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:01,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:01,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:02,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:02,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:03,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:04,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:04,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:05,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:05,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:06,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:06,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:07,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:08,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:08,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:09,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:09,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:10,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:11,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:11,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:12,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:12,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:13,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:13,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:14,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:15,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:15,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:16,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:16,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:17,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:18,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:18,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:19,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:19,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:20,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:20,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:21,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:22,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:22,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:23,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:23,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:24,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:25,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:25,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:26,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:27,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:27,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:28,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:28,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:29,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:30,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:30,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:31,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:31,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:32,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:33,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:33,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:34,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:34,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:35,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:35,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:36,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:37,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:38,159][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2154, device='cuda:0') eval_epoch_loss=tensor(0.7954, device='cuda:0') eval_epoch_acc=tensor(0.7898, device='cuda:0')
[2024-11-13 09:11:38,160][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:11:38,160][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:11:38,486][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_4_step_423_loss_0.7954196929931641/model.pt
[2024-11-13 09:11:38,492][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:11:38,492][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 0.7954196929931641
[2024-11-13 09:11:38,493][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.7898158431053162
[2024-11-13 09:11:38,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:39,183][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 0.31326526403427124, acc: 0.9166666865348816)
[2024-11-13 09:11:39,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:39,858][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 0.2923545837402344, acc: 0.8888888955116272)
[2024-11-13 09:11:39,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:40,532][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 0.1977519392967224, acc: 0.939393937587738)
[2024-11-13 09:11:40,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:41,213][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 0.12407869100570679, acc: 1.0)
[2024-11-13 09:11:41,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:41,888][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 0.1888016015291214, acc: 0.9189189076423645)
[2024-11-13 09:11:41,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:42,559][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 0.049930498003959656, acc: 1.0)
[2024-11-13 09:11:42,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:43,230][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.13995924592018127, acc: 0.95652174949646)
[2024-11-13 09:11:43,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:43,903][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.02230871096253395, acc: 1.0)
[2024-11-13 09:11:43,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:44,573][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.007433069869875908, acc: 1.0)
[2024-11-13 09:11:44,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:45,254][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.08085234463214874, acc: 0.95652174949646)
[2024-11-13 09:11:45,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:45,928][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 0.28708815574645996, acc: 0.8888888955116272)
[2024-11-13 09:11:46,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:46,598][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.017529582604765892, acc: 1.0)
[2024-11-13 09:11:46,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:47,272][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 0.10184592753648758, acc: 0.939393937587738)
[2024-11-13 09:11:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:47,944][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 0.36676883697509766, acc: 0.8333333134651184)
[2024-11-13 09:11:48,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:48,622][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 0.4292115867137909, acc: 0.8409090638160706)
[2024-11-13 09:11:48,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:49,292][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.059709105640649796, acc: 1.0)
[2024-11-13 09:11:49,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:49,969][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 0.599956750869751, acc: 0.8717948794364929)
[2024-11-13 09:11:50,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:50,654][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 0.8453434705734253, acc: 0.8181818127632141)
[2024-11-13 09:11:50,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:51,360][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 1.2526912689208984, acc: 0.6079999804496765)
[2024-11-13 09:11:51,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:52,047][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 1.2459889650344849, acc: 0.6370967626571655)
[2024-11-13 09:11:52,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:52,756][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 0.9937770962715149, acc: 0.7164179086685181)
[2024-11-13 09:11:52,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:53,440][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 0.6086230278015137, acc: 0.8113207817077637)
[2024-11-13 09:11:53,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:54,120][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 0.2616354525089264, acc: 0.8863636255264282)
[2024-11-13 09:11:54,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:54,792][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 0.1163114458322525, acc: 0.95652174949646)
[2024-11-13 09:11:54,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:55,463][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 0.37001723051071167, acc: 0.9230769276618958)
[2024-11-13 09:11:55,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:56,134][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.12467267364263535, acc: 0.9285714030265808)
[2024-11-13 09:11:56,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:56,810][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 0.24520885944366455, acc: 0.9701492786407471)
[2024-11-13 09:11:56,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:57,489][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 0.28130224347114563, acc: 0.9027777910232544)
[2024-11-13 09:11:57,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:58,168][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 0.17801035940647125, acc: 0.95652174949646)
[2024-11-13 09:11:58,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:58,844][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 0.31651806831359863, acc: 0.9102563858032227)
[2024-11-13 09:11:58,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:11:59,533][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 0.6052442789077759, acc: 0.8157894611358643)
[2024-11-13 09:11:59,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:00,210][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 0.34683850407600403, acc: 0.9387755393981934)
[2024-11-13 09:12:00,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:00,884][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 0.257690966129303, acc: 0.9090909361839294)
[2024-11-13 09:12:00,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:01,579][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 1.026633858680725, acc: 0.7422680258750916)
[2024-11-13 09:12:01,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:02,271][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 0.5618066787719727, acc: 0.8571428656578064)
[2024-11-13 09:12:02,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:02,990][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 0.9334495067596436, acc: 0.7441860437393188)
[2024-11-13 09:12:03,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:03,666][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 0.40398886799812317, acc: 0.8928571343421936)
[2024-11-13 09:12:03,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:04,355][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 0.7844569087028503, acc: 0.7777777910232544)
[2024-11-13 09:12:04,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:05,030][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 0.5364603996276855, acc: 0.8055555820465088)
[2024-11-13 09:12:05,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:05,717][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 0.19132360816001892, acc: 0.9375)
[2024-11-13 09:12:05,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:06,389][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 0.512563943862915, acc: 0.8846153616905212)
[2024-11-13 09:12:06,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:07,067][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 0.4443154036998749, acc: 0.8695651888847351)
[2024-11-13 09:12:07,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:07,749][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 0.5944531559944153, acc: 0.8571428656578064)
[2024-11-13 09:12:07,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:08,433][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 0.6397446990013123, acc: 0.8313252925872803)
[2024-11-13 09:12:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:09,142][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 0.606574296951294, acc: 0.8468468189239502)
[2024-11-13 09:12:09,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:09,829][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.0335605144500732, acc: 0.7475728392601013)
[2024-11-13 09:12:09,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:10,542][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 0.8849930763244629, acc: 0.7398374080657959)
[2024-11-13 09:12:10,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:11,232][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 0.1281331479549408, acc: 0.9583333134651184)
[2024-11-13 09:12:11,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:11,918][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 0.5194177031517029, acc: 0.8928571343421936)
[2024-11-13 09:12:12,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:12,632][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 1.2001808881759644, acc: 0.6176470518112183)
[2024-11-13 09:12:12,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:13,340][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 1.2522753477096558, acc: 0.6288209557533264)
[2024-11-13 09:12:13,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:14,023][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 0.8518550992012024, acc: 0.6979166865348816)
[2024-11-13 09:12:14,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:14,712][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 0.6295812129974365, acc: 0.8343558311462402)
[2024-11-13 09:12:14,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:15,400][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 0.5903081297874451, acc: 0.7841726541519165)
[2024-11-13 09:12:15,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:16,107][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 1.1937764883041382, acc: 0.6532663106918335)
[2024-11-13 09:12:16,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:16,782][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 0.22659632563591003, acc: 0.9166666865348816)
[2024-11-13 09:12:16,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:17,456][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 0.5011225938796997, acc: 0.8484848737716675)
[2024-11-13 09:12:17,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:18,129][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.2474997490644455, acc: 0.8888888955116272)
[2024-11-13 09:12:18,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:18,800][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 0.23589786887168884, acc: 0.8999999761581421)
[2024-11-13 09:12:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:19,474][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 0.07202044129371643, acc: 1.0)
[2024-11-13 09:12:19,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:20,162][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 0.7305931448936462, acc: 0.8103448152542114)
[2024-11-13 09:12:20,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:20,834][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.14951694011688232, acc: 0.9354838728904724)
[2024-11-13 09:12:20,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:21,512][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.21047626435756683, acc: 0.9473684430122375)
[2024-11-13 09:12:21,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:22,187][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 0.7982391119003296, acc: 0.8148148059844971)
[2024-11-13 09:12:22,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:22,857][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 0.31306231021881104, acc: 0.9047619104385376)
[2024-11-13 09:12:22,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:23,539][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 0.46282070875167847, acc: 0.8181818127632141)
[2024-11-13 09:12:23,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:24,231][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 0.7366688251495361, acc: 0.7846153974533081)
[2024-11-13 09:12:24,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:24,907][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 0.19533301889896393, acc: 0.9333333373069763)
[2024-11-13 09:12:24,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:25,579][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 0.236209899187088, acc: 0.9655172228813171)
[2024-11-13 09:12:25,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:26,252][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 0.5334722399711609, acc: 0.8235294222831726)
[2024-11-13 09:12:26,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:26,923][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 0.2851875424385071, acc: 0.8620689511299133)
[2024-11-13 09:12:27,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:27,591][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.02322383038699627, acc: 1.0)
[2024-11-13 09:12:27,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:28,271][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 0.9906625151634216, acc: 0.7894737124443054)
[2024-11-13 09:12:28,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:28,959][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 1.1600942611694336, acc: 0.7410714030265808)
[2024-11-13 09:12:29,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:29,643][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 0.7024733424186707, acc: 0.7977527976036072)
[2024-11-13 09:12:29,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:30,330][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 1.1463274955749512, acc: 0.6966292262077332)
[2024-11-13 09:12:30,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:31,029][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 1.5915735960006714, acc: 0.5602836608886719)
[2024-11-13 09:12:31,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:31,717][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 1.1631572246551514, acc: 0.70652174949646)
[2024-11-13 09:12:31,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:32,387][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.028802981600165367, acc: 1.0)
[2024-11-13 09:12:32,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:33,057][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.06798005849123001, acc: 1.0)
[2024-11-13 09:12:33,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:33,728][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.09072713553905487, acc: 0.9629629850387573)
[2024-11-13 09:12:33,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:34,401][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 0.19191478192806244, acc: 0.9629629850387573)
[2024-11-13 09:12:34,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:35,077][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 0.5583224892616272, acc: 0.9056603908538818)
[2024-11-13 09:12:35,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:35,747][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 0.09300540387630463, acc: 0.931034505367279)
[2024-11-13 09:12:35,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:36,435][root][INFO] - Training Epoch: 4/10, step 507/574 completed (loss: 1.0676277875900269, acc: 0.7297297120094299)
[2024-11-13 09:12:36,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:37,118][root][INFO] - Training Epoch: 4/10, step 508/574 completed (loss: 0.6867849230766296, acc: 0.8591549396514893)
[2024-11-13 09:12:37,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:37,788][root][INFO] - Training Epoch: 4/10, step 509/574 completed (loss: 0.21188297867774963, acc: 0.8999999761581421)
[2024-11-13 09:12:37,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:38,460][root][INFO] - Training Epoch: 4/10, step 510/574 completed (loss: 0.07322348654270172, acc: 1.0)
[2024-11-13 09:12:38,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:39,130][root][INFO] - Training Epoch: 4/10, step 511/574 completed (loss: 0.23612695932388306, acc: 0.9615384340286255)
[2024-11-13 09:12:39,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:39,871][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 1.6294633150100708, acc: 0.5857142806053162)
[2024-11-13 09:12:39,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:40,575][root][INFO] - Training Epoch: 4/10, step 513/574 completed (loss: 0.6666659712791443, acc: 0.8333333134651184)
[2024-11-13 09:12:40,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:41,250][root][INFO] - Training Epoch: 4/10, step 514/574 completed (loss: 0.2676163613796234, acc: 0.9285714030265808)
[2024-11-13 09:12:41,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:41,931][root][INFO] - Training Epoch: 4/10, step 515/574 completed (loss: 0.2701365351676941, acc: 0.9333333373069763)
[2024-11-13 09:12:42,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:42,627][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 0.8471189737319946, acc: 0.7638888955116272)
[2024-11-13 09:12:42,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:43,299][root][INFO] - Training Epoch: 4/10, step 517/574 completed (loss: 0.02517029456794262, acc: 1.0)
[2024-11-13 09:12:43,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:43,970][root][INFO] - Training Epoch: 4/10, step 518/574 completed (loss: 0.1172991693019867, acc: 1.0)
[2024-11-13 09:12:44,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:44,634][root][INFO] - Training Epoch: 4/10, step 519/574 completed (loss: 0.12512992322444916, acc: 0.949999988079071)
[2024-11-13 09:12:44,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:45,306][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 0.2024288922548294, acc: 0.9629629850387573)
[2024-11-13 09:12:45,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:46,218][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 1.5613038539886475, acc: 0.5466101765632629)
[2024-11-13 09:12:46,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:46,929][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 0.7954800128936768, acc: 0.8059701323509216)
[2024-11-13 09:12:47,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:47,610][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 0.8047948479652405, acc: 0.7956204414367676)
[2024-11-13 09:12:47,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:48,327][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 1.0414119958877563, acc: 0.699999988079071)
[2024-11-13 09:12:48,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:49,006][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 0.0965852215886116, acc: 1.0)
[2024-11-13 09:12:49,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:49,683][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 0.34226182103157043, acc: 0.9038461446762085)
[2024-11-13 09:12:49,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:50,353][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 0.45523199439048767, acc: 0.9047619104385376)
[2024-11-13 09:12:50,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:51,037][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 1.6086915731430054, acc: 0.5081967115402222)
[2024-11-13 09:12:51,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:51,716][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 0.3491627275943756, acc: 0.8813559412956238)
[2024-11-13 09:12:51,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:52,392][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 0.6762201189994812, acc: 0.8139534592628479)
[2024-11-13 09:12:52,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:53,066][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 0.6819944977760315, acc: 0.8181818127632141)
[2024-11-13 09:12:53,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:53,744][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 0.9970427751541138, acc: 0.7169811129570007)
[2024-11-13 09:12:53,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:54,429][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 0.62774658203125, acc: 0.7954545617103577)
[2024-11-13 09:12:54,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:55,108][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 0.2982463538646698, acc: 0.8799999952316284)
[2024-11-13 09:12:55,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:55,783][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.38799089193344116, acc: 0.8500000238418579)
[2024-11-13 09:12:55,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:56,466][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.04493634030222893, acc: 1.0)
[2024-11-13 09:12:56,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:57,149][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 0.44272252917289734, acc: 0.8615384697914124)
[2024-11-13 09:12:57,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:57,829][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 0.36004212498664856, acc: 0.890625)
[2024-11-13 09:12:57,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:58,503][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 0.37438076734542847, acc: 0.9375)
[2024-11-13 09:12:58,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:59,174][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 0.28940942883491516, acc: 0.9090909361839294)
[2024-11-13 09:12:59,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:12:59,855][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.2864869236946106, acc: 0.875)
[2024-11-13 09:12:59,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:00,532][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.026747984811663628, acc: 1.0)
[2024-11-13 09:13:00,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:01,203][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.009897955693304539, acc: 1.0)
[2024-11-13 09:13:01,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:01,873][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 0.2635175287723541, acc: 0.9666666388511658)
[2024-11-13 09:13:01,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:02,547][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 0.15579985082149506, acc: 0.9512194991111755)
[2024-11-13 09:13:02,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:03,221][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.097379170358181, acc: 0.9714285731315613)
[2024-11-13 09:13:03,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:03,906][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.09343124181032181, acc: 0.9736841917037964)
[2024-11-13 09:13:04,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:04,592][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.17847801744937897, acc: 0.9354838728904724)
[2024-11-13 09:13:04,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:05,271][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.11068779975175858, acc: 0.9599999785423279)
[2024-11-13 09:13:05,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:05,947][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.29838088154792786, acc: 0.8787878751754761)
[2024-11-13 09:13:06,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:06,625][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.1570950746536255, acc: 0.8999999761581421)
[2024-11-13 09:13:06,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:07,301][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 0.2676553726196289, acc: 0.8857142925262451)
[2024-11-13 09:13:07,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:08,008][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 0.7185869812965393, acc: 0.7883211970329285)
[2024-11-13 09:13:08,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:08,715][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 0.5178367495536804, acc: 0.8413792848587036)
[2024-11-13 09:13:08,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:09,407][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 0.7780536413192749, acc: 0.7857142686843872)
[2024-11-13 09:13:09,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:10,090][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 0.5859928727149963, acc: 0.8344370722770691)
[2024-11-13 09:13:10,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:10,774][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 0.3486979603767395, acc: 0.8803418874740601)
[2024-11-13 09:13:10,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:11,444][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.15625621378421783, acc: 0.9200000166893005)
[2024-11-13 09:13:11,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:12,114][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.24019058048725128, acc: 0.9615384340286255)
[2024-11-13 09:13:12,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:12,796][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.04389429837465286, acc: 1.0)
[2024-11-13 09:13:12,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:13,472][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 0.2185412496328354, acc: 0.9230769276618958)
[2024-11-13 09:13:13,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:14,176][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 0.6258680820465088, acc: 0.800000011920929)
[2024-11-13 09:13:14,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:14,855][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 0.41034334897994995, acc: 0.8701298832893372)
[2024-11-13 09:13:14,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:15,542][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 0.4375494420528412, acc: 0.875)
[2024-11-13 09:13:15,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:16,218][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 0.40026286244392395, acc: 0.8620689511299133)
[2024-11-13 09:13:17,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:17,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:18,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:18,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:19,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:20,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:20,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:21,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:21,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:22,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:23,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:24,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:24,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:25,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:25,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:26,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:27,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:27,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:28,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:28,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:29,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:30,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:30,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:31,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:31,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:32,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:32,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:33,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:34,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:34,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:35,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:35,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:36,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:37,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:37,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:38,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:38,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:39,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:40,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:41,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:41,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:42,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:42,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:43,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:44,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:44,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:45,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:45,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:46,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:47,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:47,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:48,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:49,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:49,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:50,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:51,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:51,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:52,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:52,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:53,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:54,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:54,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:55,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:55,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:56,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:57,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:57,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:58,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:58,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:59,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:13:59,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:00,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:01,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:01,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:02,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:02,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:03,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:04,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:04,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:05,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:05,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:06,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:07,508][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1351, device='cuda:0') eval_epoch_loss=tensor(0.7585, device='cuda:0') eval_epoch_acc=tensor(0.7910, device='cuda:0')
[2024-11-13 09:14:07,509][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:14:07,509][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:14:08,065][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_4_step_566_loss_0.7585353255271912/model.pt
[2024-11-13 09:14:08,071][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:14:08,072][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 0.7585353255271912
[2024-11-13 09:14:08,072][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.7910245060920715
[2024-11-13 09:14:08,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:08,794][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 0.36417949199676514, acc: 0.8690476417541504)
[2024-11-13 09:14:08,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:09,465][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 0.1157175749540329, acc: 0.9210526347160339)
[2024-11-13 09:14:09,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:10,137][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.08862165361642838, acc: 1.0)
[2024-11-13 09:14:10,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:10,863][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 0.7078417539596558, acc: 0.7967914342880249)
[2024-11-13 09:14:10,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:11,547][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 0.07056014984846115, acc: 1.0)
[2024-11-13 09:14:11,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:12,234][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 0.4664002060890198, acc: 0.8547008633613586)
[2024-11-13 09:14:12,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:12,938][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 0.8636857867240906, acc: 0.75)
[2024-11-13 09:14:13,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:13,651][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 0.7528572082519531, acc: 0.7610062956809998)
[2024-11-13 09:14:14,102][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=2.0333, train_epoch_loss=0.7097, epoch time 602.8379813898355s
[2024-11-13 09:14:14,102][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 09:14:14,102][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 09:14:14,103][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 09:14:14,103][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 4
[2024-11-13 09:14:14,103][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 09:14:14,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:15,607][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 0.2117428481578827, acc: 0.9259259104728699)
[2024-11-13 09:14:15,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:16,292][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 0.14230604469776154, acc: 0.9599999785423279)
[2024-11-13 09:14:16,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:16,977][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 0.7378072738647461, acc: 0.7567567825317383)
[2024-11-13 09:14:17,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:17,661][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 0.340771347284317, acc: 0.8684210777282715)
[2024-11-13 09:14:17,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:18,347][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 0.43140584230422974, acc: 0.837837815284729)
[2024-11-13 09:14:18,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:19,044][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 0.29120558500289917, acc: 0.8928571343421936)
[2024-11-13 09:14:19,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:19,732][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 0.5813217759132385, acc: 0.8367347121238708)
[2024-11-13 09:14:19,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:20,412][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 0.4850768744945526, acc: 0.800000011920929)
[2024-11-13 09:14:20,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:21,093][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.05735974386334419, acc: 0.9545454382896423)
[2024-11-13 09:14:21,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:21,776][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.014373996295034885, acc: 1.0)
[2024-11-13 09:14:21,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:22,472][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.045053575187921524, acc: 1.0)
[2024-11-13 09:14:22,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:23,157][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 0.356503427028656, acc: 0.9230769276618958)
[2024-11-13 09:14:23,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:23,840][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 0.15619215369224548, acc: 0.9696969985961914)
[2024-11-13 09:14:23,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:24,526][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 0.21841277182102203, acc: 0.9347826242446899)
[2024-11-13 09:14:24,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:25,213][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 0.17442771792411804, acc: 0.9607843160629272)
[2024-11-13 09:14:25,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:25,902][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 0.6155316829681396, acc: 0.8775510191917419)
[2024-11-13 09:14:25,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:26,583][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.1184614971280098, acc: 0.9473684430122375)
[2024-11-13 09:14:26,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:27,268][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 0.13262704014778137, acc: 0.9166666865348816)
[2024-11-13 09:14:27,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:27,959][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 0.3418506681919098, acc: 0.8333333134651184)
[2024-11-13 09:14:28,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:28,643][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.2482832819223404, acc: 0.9473684430122375)
[2024-11-13 09:14:28,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:29,332][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 0.05287504196166992, acc: 1.0)
[2024-11-13 09:14:29,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:30,018][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 0.5012229681015015, acc: 0.8275862336158752)
[2024-11-13 09:14:30,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:30,744][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.5065539479255676, acc: 0.800000011920929)
[2024-11-13 09:14:30,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:31,425][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.3317376375198364, acc: 0.9047619104385376)
[2024-11-13 09:14:31,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:32,106][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 0.3090546131134033, acc: 0.9375)
[2024-11-13 09:14:32,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:32,801][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 0.68227219581604, acc: 0.7924528121948242)
[2024-11-13 09:14:32,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:33,492][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 0.8686894774436951, acc: 0.7534246444702148)
[2024-11-13 09:14:33,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:34,296][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 1.631446361541748, acc: 0.5335968136787415)
[2024-11-13 09:14:34,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:34,982][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 0.5518859624862671, acc: 0.8604651093482971)
[2024-11-13 09:14:35,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:35,674][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 0.695534348487854, acc: 0.8313252925872803)
[2024-11-13 09:14:35,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:36,378][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 1.0365158319473267, acc: 0.7530864477157593)
[2024-11-13 09:14:36,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:37,063][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 0.42759180068969727, acc: 0.8928571343421936)
[2024-11-13 09:14:37,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:37,745][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.45685875415802, acc: 0.8888888955116272)
[2024-11-13 09:14:37,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:38,438][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.06735445559024811, acc: 1.0)
[2024-11-13 09:14:38,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:39,146][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 0.765538215637207, acc: 0.7731092572212219)
[2024-11-13 09:14:39,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:39,839][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 0.36042094230651855, acc: 0.8360655903816223)
[2024-11-13 09:14:39,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:40,538][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 0.8764844536781311, acc: 0.7460317611694336)
[2024-11-13 09:14:40,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:41,238][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 0.6655617952346802, acc: 0.8305084705352783)
[2024-11-13 09:14:41,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:41,944][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 0.40730422735214233, acc: 0.8850574493408203)
[2024-11-13 09:14:42,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:42,640][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.019965600222349167, acc: 1.0)
[2024-11-13 09:14:42,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:43,328][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 0.34125253558158875, acc: 0.8846153616905212)
[2024-11-13 09:14:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:44,021][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 0.6784995198249817, acc: 0.8108108043670654)
[2024-11-13 09:14:44,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:44,711][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 0.5430176258087158, acc: 0.8615384697914124)
[2024-11-13 09:14:44,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:45,406][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 0.583494246006012, acc: 0.7878788113594055)
[2024-11-13 09:14:45,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:46,108][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 0.5166686177253723, acc: 0.8041236996650696)
[2024-11-13 09:14:46,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:46,811][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 0.6457183957099915, acc: 0.7867646813392639)
[2024-11-13 09:14:46,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:47,492][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.17011356353759766, acc: 0.9230769276618958)
[2024-11-13 09:14:47,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:48,175][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.11276926100254059, acc: 0.9629629850387573)
[2024-11-13 09:14:48,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:48,859][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.2701907455921173, acc: 0.9285714030265808)
[2024-11-13 09:14:48,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:49,557][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.060997433960437775, acc: 1.0)
[2024-11-13 09:14:49,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:50,248][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 0.4349352717399597, acc: 0.859649121761322)
[2024-11-13 09:14:50,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:50,943][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 0.7888990640640259, acc: 0.7777777910232544)
[2024-11-13 09:14:51,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:51,644][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 0.9323412179946899, acc: 0.7183098793029785)
[2024-11-13 09:14:51,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:52,365][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 1.3233393430709839, acc: 0.6333333253860474)
[2024-11-13 09:14:52,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:53,051][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.4448912739753723, acc: 0.8918918967247009)
[2024-11-13 09:14:53,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:53,735][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.09744804352521896, acc: 0.9615384340286255)
[2024-11-13 09:14:53,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:54,577][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 1.4540181159973145, acc: 0.6279863715171814)
[2024-11-13 09:14:54,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:55,356][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 1.6539132595062256, acc: 0.5468409657478333)
[2024-11-13 09:14:55,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:56,081][root][INFO] - Training Epoch: 5/10, step 58/574 completed (loss: 0.9015616774559021, acc: 0.7386363744735718)
[2024-11-13 09:14:56,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:56,781][root][INFO] - Training Epoch: 5/10, step 59/574 completed (loss: 0.6682530045509338, acc: 0.7941176295280457)
[2024-11-13 09:14:56,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:57,502][root][INFO] - Training Epoch: 5/10, step 60/574 completed (loss: 0.8202887773513794, acc: 0.7681159377098083)
[2024-11-13 09:14:57,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:58,220][root][INFO] - Training Epoch: 5/10, step 61/574 completed (loss: 0.7144109606742859, acc: 0.7875000238418579)
[2024-11-13 09:14:58,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:58,906][root][INFO] - Training Epoch: 5/10, step 62/574 completed (loss: 0.2510323226451874, acc: 0.9117646813392639)
[2024-11-13 09:14:58,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:14:59,601][root][INFO] - Training Epoch: 5/10, step 63/574 completed (loss: 0.3204661011695862, acc: 0.8888888955116272)
[2024-11-13 09:14:59,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:00,297][root][INFO] - Training Epoch: 5/10, step 64/574 completed (loss: 0.4437769055366516, acc: 0.84375)
[2024-11-13 09:15:00,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:00,982][root][INFO] - Training Epoch: 5/10, step 65/574 completed (loss: 0.16424906253814697, acc: 1.0)
[2024-11-13 09:15:01,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:01,673][root][INFO] - Training Epoch: 5/10, step 66/574 completed (loss: 0.5329318642616272, acc: 0.875)
[2024-11-13 09:15:01,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:02,361][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 0.44497057795524597, acc: 0.8500000238418579)
[2024-11-13 09:15:02,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:03,048][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.10219399631023407, acc: 0.9599999785423279)
[2024-11-13 09:15:03,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:03,737][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 0.2917235791683197, acc: 0.9722222089767456)
[2024-11-13 09:15:03,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:04,421][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 0.34352540969848633, acc: 0.939393937587738)
[2024-11-13 09:15:04,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:05,134][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 0.981475830078125, acc: 0.7058823704719543)
[2024-11-13 09:15:05,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:05,833][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 0.7138924598693848, acc: 0.7936508059501648)
[2024-11-13 09:15:05,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:06,560][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 1.45553719997406, acc: 0.620512843132019)
[2024-11-13 09:15:06,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:07,253][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.1060248613357544, acc: 0.6836734414100647)
[2024-11-13 09:15:07,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:07,958][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 1.3178417682647705, acc: 0.6268656849861145)
[2024-11-13 09:15:08,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:08,698][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 1.6801308393478394, acc: 0.525547444820404)
[2024-11-13 09:15:08,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:09,395][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.01707012951374054, acc: 1.0)
[2024-11-13 09:15:09,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:10,078][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.0194422397762537, acc: 1.0)
[2024-11-13 09:15:10,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:10,761][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.10911698639392853, acc: 0.9696969985961914)
[2024-11-13 09:15:10,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:11,446][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.038436874747276306, acc: 1.0)
[2024-11-13 09:15:11,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:12,136][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 0.5487039089202881, acc: 0.807692289352417)
[2024-11-13 09:15:12,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:12,824][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 0.6423739790916443, acc: 0.8269230723381042)
[2024-11-13 09:15:12,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:13,506][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 0.3271157741546631, acc: 0.90625)
[2024-11-13 09:15:13,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:14,197][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 0.48969656229019165, acc: 0.8550724387168884)
[2024-11-13 09:15:14,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:14,888][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 0.5064905881881714, acc: 0.8199999928474426)
[2024-11-13 09:15:14,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:15,571][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 0.10278616845607758, acc: 0.95652174949646)
[2024-11-13 09:15:15,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:16,265][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 0.8162896633148193, acc: 0.7599999904632568)
[2024-11-13 09:15:16,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:16,964][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 0.653713047504425, acc: 0.7961165308952332)
[2024-11-13 09:15:17,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:17,683][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 0.9652731418609619, acc: 0.7475728392601013)
[2024-11-13 09:15:17,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:18,408][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 1.3313976526260376, acc: 0.6344085931777954)
[2024-11-13 09:15:18,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:19,148][root][INFO] - Training Epoch: 5/10, step 91/574 completed (loss: 1.075934648513794, acc: 0.7370689511299133)
[2024-11-13 09:15:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:19,850][root][INFO] - Training Epoch: 5/10, step 92/574 completed (loss: 0.8333271145820618, acc: 0.7684210538864136)
[2024-11-13 09:15:19,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:20,573][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 1.3312453031539917, acc: 0.5841584205627441)
[2024-11-13 09:15:20,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:21,264][root][INFO] - Training Epoch: 5/10, step 94/574 completed (loss: 0.609285295009613, acc: 0.7903226017951965)
[2024-11-13 09:15:21,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:21,953][root][INFO] - Training Epoch: 5/10, step 95/574 completed (loss: 0.7179298996925354, acc: 0.7971014380455017)
[2024-11-13 09:15:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:22,661][root][INFO] - Training Epoch: 5/10, step 96/574 completed (loss: 1.0212152004241943, acc: 0.6974790096282959)
[2024-11-13 09:15:22,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:23,360][root][INFO] - Training Epoch: 5/10, step 97/574 completed (loss: 0.9483757615089417, acc: 0.7692307829856873)
[2024-11-13 09:15:23,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:24,070][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 1.254190444946289, acc: 0.5985401272773743)
[2024-11-13 09:15:24,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:24,762][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 1.1876248121261597, acc: 0.6268656849861145)
[2024-11-13 09:15:24,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:25,455][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.10067936033010483, acc: 1.0)
[2024-11-13 09:15:25,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:26,138][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.03224056959152222, acc: 1.0)
[2024-11-13 09:15:26,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:26,820][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.018560944125056267, acc: 1.0)
[2024-11-13 09:15:26,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:27,517][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 0.03849397227168083, acc: 1.0)
[2024-11-13 09:15:27,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:28,208][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 0.2791864573955536, acc: 0.931034505367279)
[2024-11-13 09:15:28,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:28,898][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 0.23310543596744537, acc: 0.930232584476471)
[2024-11-13 09:15:28,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:29,590][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 0.03054019622504711, acc: 1.0)
[2024-11-13 09:15:29,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:30,270][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.006380871403962374, acc: 1.0)
[2024-11-13 09:15:30,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:30,954][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.03263109177350998, acc: 1.0)
[2024-11-13 09:15:31,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:31,641][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 0.2681875228881836, acc: 0.9523809552192688)
[2024-11-13 09:15:31,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:32,344][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 0.16658146679401398, acc: 0.9384615421295166)
[2024-11-13 09:15:32,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:33,035][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 0.34700918197631836, acc: 0.9298245906829834)
[2024-11-13 09:15:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:33,718][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 0.45266202092170715, acc: 0.9122806787490845)
[2024-11-13 09:15:33,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:34,402][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 0.23605091869831085, acc: 0.9487179517745972)
[2024-11-13 09:15:34,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:35,090][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 0.295830637216568, acc: 0.8775510191917419)
[2024-11-13 09:15:35,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:35,772][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.006123174447566271, acc: 1.0)
[2024-11-13 09:15:35,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:36,470][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 0.5353721976280212, acc: 0.841269850730896)
[2024-11-13 09:15:36,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:37,164][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 0.4484378397464752, acc: 0.8373983502388)
[2024-11-13 09:15:37,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:37,855][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 0.43833205103874207, acc: 0.8225806355476379)
[2024-11-13 09:15:37,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:38,624][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.0941272974014282, acc: 0.7072243094444275)
[2024-11-13 09:15:38,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:39,318][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 0.3736996054649353, acc: 0.9066666960716248)
[2024-11-13 09:15:39,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:40,009][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 0.21182085573673248, acc: 0.9230769276618958)
[2024-11-13 09:15:40,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:40,692][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.02851087599992752, acc: 1.0)
[2024-11-13 09:15:40,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:41,375][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.11901575326919556, acc: 1.0)
[2024-11-13 09:15:41,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:42,078][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 0.9538756608963013, acc: 0.7361963391304016)
[2024-11-13 09:15:42,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:42,798][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.092820644378662, acc: 0.7152777910232544)
[2024-11-13 09:15:42,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:43,495][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 1.0252251625061035, acc: 0.7250000238418579)
[2024-11-13 09:15:43,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:44,228][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 1.189180850982666, acc: 0.6666666865348816)
[2024-11-13 09:15:44,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:44,946][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 0.775367796421051, acc: 0.7846153974533081)
[2024-11-13 09:15:45,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:45,682][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 0.9409156441688538, acc: 0.7573529481887817)
[2024-11-13 09:15:45,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:46,367][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.19603358209133148, acc: 0.9230769276618958)
[2024-11-13 09:15:46,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:47,062][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.023068852722644806, acc: 1.0)
[2024-11-13 09:15:47,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:47,755][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.24531938135623932, acc: 0.90625)
[2024-11-13 09:15:47,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:48,437][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.3664015829563141, acc: 0.8260869383811951)
[2024-11-13 09:15:48,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:49,121][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 0.21290642023086548, acc: 0.9428571462631226)
[2024-11-13 09:15:50,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:50,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:51,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:52,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:52,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:53,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:53,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:54,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:54,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:55,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:56,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:56,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:57,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:57,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:58,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:59,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:15:59,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:00,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:00,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:01,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:02,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:02,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:03,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:03,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:04,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:04,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:05,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:06,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:06,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:07,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:07,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:08,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:08,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:09,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:10,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:10,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:11,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:12,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:13,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:13,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:14,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:14,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:15,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:16,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:16,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:17,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:18,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:18,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:19,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:20,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:20,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:21,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:21,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:22,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:23,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:23,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:24,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:24,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:25,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:25,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:26,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:27,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:27,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:28,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:28,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:29,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:30,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:30,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:31,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:31,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:32,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:33,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:33,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:34,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:34,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:35,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:35,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:36,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:37,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:37,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:38,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:38,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:39,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:40,492][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.0170, device='cuda:0') eval_epoch_loss=tensor(0.7016, device='cuda:0') eval_epoch_acc=tensor(0.8155, device='cuda:0')
[2024-11-13 09:16:40,496][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:16:40,497][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:16:40,951][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_5_step_135_loss_0.7015925645828247/model.pt
[2024-11-13 09:16:40,956][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:16:40,957][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 5 is 0.7015925645828247
[2024-11-13 09:16:40,957][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.815542995929718
[2024-11-13 09:16:41,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:41,663][root][INFO] - Training Epoch: 5/10, step 135/574 completed (loss: 0.2365596890449524, acc: 0.8846153616905212)
[2024-11-13 09:16:41,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:42,338][root][INFO] - Training Epoch: 5/10, step 136/574 completed (loss: 0.26235583424568176, acc: 0.9523809552192688)
[2024-11-13 09:16:42,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:43,022][root][INFO] - Training Epoch: 5/10, step 137/574 completed (loss: 0.36394864320755005, acc: 0.8333333134651184)
[2024-11-13 09:16:43,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:43,693][root][INFO] - Training Epoch: 5/10, step 138/574 completed (loss: 0.14416325092315674, acc: 0.95652174949646)
[2024-11-13 09:16:43,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:44,364][root][INFO] - Training Epoch: 5/10, step 139/574 completed (loss: 0.02264050394296646, acc: 1.0)
[2024-11-13 09:16:44,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:45,035][root][INFO] - Training Epoch: 5/10, step 140/574 completed (loss: 0.04334668815135956, acc: 1.0)
[2024-11-13 09:16:45,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:45,711][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 0.49095937609672546, acc: 0.8709677457809448)
[2024-11-13 09:16:45,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:46,386][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 0.27648743987083435, acc: 0.9459459185600281)
[2024-11-13 09:16:46,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:47,095][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 0.702663242816925, acc: 0.7719298005104065)
[2024-11-13 09:16:47,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:47,784][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 0.9693989753723145, acc: 0.7313432693481445)
[2024-11-13 09:16:47,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:48,476][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 0.6761894822120667, acc: 0.7857142686843872)
[2024-11-13 09:16:48,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:49,177][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 0.9860830307006836, acc: 0.6808510422706604)
[2024-11-13 09:16:49,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:49,858][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 0.6556031107902527, acc: 0.800000011920929)
[2024-11-13 09:16:49,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:50,534][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 0.17261268198490143, acc: 0.9642857313156128)
[2024-11-13 09:16:50,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:51,205][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 0.644001841545105, acc: 0.8260869383811951)
[2024-11-13 09:16:51,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:51,877][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 0.3383013606071472, acc: 0.8620689511299133)
[2024-11-13 09:16:51,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:52,559][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 0.6877544522285461, acc: 0.804347813129425)
[2024-11-13 09:16:52,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:53,241][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 0.7216005325317383, acc: 0.7966101765632629)
[2024-11-13 09:16:53,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:53,931][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 0.7547649145126343, acc: 0.7719298005104065)
[2024-11-13 09:16:54,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:54,611][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 0.5749452710151672, acc: 0.8243243098258972)
[2024-11-13 09:16:54,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:55,282][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 0.1739395707845688, acc: 0.9285714030265808)
[2024-11-13 09:16:55,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:55,955][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 0.03314998745918274, acc: 1.0)
[2024-11-13 09:16:56,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:56,623][root][INFO] - Training Epoch: 5/10, step 157/574 completed (loss: 0.29842859506607056, acc: 0.9473684430122375)
[2024-11-13 09:16:56,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:57,302][root][INFO] - Training Epoch: 5/10, step 158/574 completed (loss: 0.9527534246444702, acc: 0.7297297120094299)
[2024-11-13 09:16:57,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:57,981][root][INFO] - Training Epoch: 5/10, step 159/574 completed (loss: 0.9093292951583862, acc: 0.7222222089767456)
[2024-11-13 09:16:58,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:58,663][root][INFO] - Training Epoch: 5/10, step 160/574 completed (loss: 0.40916261076927185, acc: 0.9069767594337463)
[2024-11-13 09:16:58,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:16:59,351][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 0.3371792435646057, acc: 0.8588235378265381)
[2024-11-13 09:16:59,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:00,035][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 0.994326114654541, acc: 0.7640449404716492)
[2024-11-13 09:17:00,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:00,716][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 0.4252582788467407, acc: 0.9545454382896423)
[2024-11-13 09:17:00,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:01,388][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 0.39161446690559387, acc: 0.9047619104385376)
[2024-11-13 09:17:01,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:02,062][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 0.09412844479084015, acc: 1.0)
[2024-11-13 09:17:02,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:02,743][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 0.1948305070400238, acc: 0.9387755393981934)
[2024-11-13 09:17:02,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:03,423][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 0.16566956043243408, acc: 0.9599999785423279)
[2024-11-13 09:17:03,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:04,116][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 0.7492578029632568, acc: 0.7638888955116272)
[2024-11-13 09:17:04,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:04,804][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 0.8200828433036804, acc: 0.7549019455909729)
[2024-11-13 09:17:04,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:05,523][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 1.3983992338180542, acc: 0.5958904027938843)
[2024-11-13 09:17:05,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:06,198][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.2289540022611618, acc: 0.9166666865348816)
[2024-11-13 09:17:06,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:06,871][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.12958228588104248, acc: 0.9629629850387573)
[2024-11-13 09:17:06,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:07,546][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.32190653681755066, acc: 0.8928571343421936)
[2024-11-13 09:17:07,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:08,259][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 0.7711347341537476, acc: 0.7964601516723633)
[2024-11-13 09:17:08,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:08,941][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 0.4266674518585205, acc: 0.8695651888847351)
[2024-11-13 09:17:09,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:09,627][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 0.40598487854003906, acc: 0.8863636255264282)
[2024-11-13 09:17:09,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:10,337][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 1.226488709449768, acc: 0.6335877776145935)
[2024-11-13 09:17:10,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:11,037][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 0.8383558392524719, acc: 0.7407407164573669)
[2024-11-13 09:17:11,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:11,717][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 0.32108601927757263, acc: 0.868852436542511)
[2024-11-13 09:17:11,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:12,389][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.0519225150346756, acc: 0.9583333134651184)
[2024-11-13 09:17:12,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:13,067][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.16104324162006378, acc: 0.9200000166893005)
[2024-11-13 09:17:13,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:13,739][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.03463800251483917, acc: 1.0)
[2024-11-13 09:17:13,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:14,423][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 0.2610299289226532, acc: 0.9024389982223511)
[2024-11-13 09:17:14,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:15,155][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 0.8294793963432312, acc: 0.773413896560669)
[2024-11-13 09:17:15,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:15,884][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 0.9552397131919861, acc: 0.7319884896278381)
[2024-11-13 09:17:15,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:16,605][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 0.9068450927734375, acc: 0.706250011920929)
[2024-11-13 09:17:16,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:17,369][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 0.9539074897766113, acc: 0.7298311591148376)
[2024-11-13 09:17:17,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:18,107][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 0.768330991268158, acc: 0.7935943007469177)
[2024-11-13 09:17:18,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:18,780][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 0.34940239787101746, acc: 0.9200000166893005)
[2024-11-13 09:17:18,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:19,468][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 1.148607611656189, acc: 0.6279069781303406)
[2024-11-13 09:17:19,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:20,154][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 1.23916757106781, acc: 0.658730149269104)
[2024-11-13 09:17:20,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:20,842][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 1.0591728687286377, acc: 0.6818181872367859)
[2024-11-13 09:17:20,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:21,537][root][INFO] - Training Epoch: 5/10, step 193/574 completed (loss: 0.5824818015098572, acc: 0.7882353067398071)
[2024-11-13 09:17:21,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:22,245][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 0.9760725498199463, acc: 0.6851851940155029)
[2024-11-13 09:17:22,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:22,931][root][INFO] - Training Epoch: 5/10, step 195/574 completed (loss: 0.6286786794662476, acc: 0.774193525314331)
[2024-11-13 09:17:23,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:23,606][root][INFO] - Training Epoch: 5/10, step 196/574 completed (loss: 0.12583206593990326, acc: 0.9642857313156128)
[2024-11-13 09:17:23,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:24,286][root][INFO] - Training Epoch: 5/10, step 197/574 completed (loss: 0.7749672532081604, acc: 0.800000011920929)
[2024-11-13 09:17:24,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:24,965][root][INFO] - Training Epoch: 5/10, step 198/574 completed (loss: 0.5793349146842957, acc: 0.8382353186607361)
[2024-11-13 09:17:25,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:25,654][root][INFO] - Training Epoch: 5/10, step 199/574 completed (loss: 0.9785768985748291, acc: 0.7352941036224365)
[2024-11-13 09:17:25,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:26,341][root][INFO] - Training Epoch: 5/10, step 200/574 completed (loss: 0.8772748708724976, acc: 0.7118644118309021)
[2024-11-13 09:17:26,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:27,038][root][INFO] - Training Epoch: 5/10, step 201/574 completed (loss: 0.7695974707603455, acc: 0.7910447716712952)
[2024-11-13 09:17:27,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:27,729][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 0.7408649325370789, acc: 0.8155339956283569)
[2024-11-13 09:17:27,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:28,414][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 0.6148613691329956, acc: 0.7777777910232544)
[2024-11-13 09:17:28,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:29,109][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 0.34778305888175964, acc: 0.9120879173278809)
[2024-11-13 09:17:29,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:29,828][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 0.65284264087677, acc: 0.8071748614311218)
[2024-11-13 09:17:29,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:30,557][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 0.7858986258506775, acc: 0.7795275449752808)
[2024-11-13 09:17:30,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:31,273][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 0.44550156593322754, acc: 0.8663793206214905)
[2024-11-13 09:17:31,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:31,987][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 0.6679707169532776, acc: 0.8224637508392334)
[2024-11-13 09:17:32,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:32,704][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 0.5423281192779541, acc: 0.8287937641143799)
[2024-11-13 09:17:32,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:33,416][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 0.507749080657959, acc: 0.8586956262588501)
[2024-11-13 09:17:33,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:34,094][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.04200780764222145, acc: 1.0)
[2024-11-13 09:17:34,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:34,766][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 0.10353301465511322, acc: 0.9642857313156128)
[2024-11-13 09:17:34,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:35,446][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.06834708899259567, acc: 1.0)
[2024-11-13 09:17:35,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:36,153][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 0.30472901463508606, acc: 0.9153845906257629)
[2024-11-13 09:17:36,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:36,836][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 0.13551180064678192, acc: 0.9864864945411682)
[2024-11-13 09:17:36,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:37,513][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 0.15406714379787445, acc: 0.9651162624359131)
[2024-11-13 09:17:37,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:38,199][root][INFO] - Training Epoch: 5/10, step 217/574 completed (loss: 0.32644006609916687, acc: 0.9099099040031433)
[2024-11-13 09:17:38,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:38,881][root][INFO] - Training Epoch: 5/10, step 218/574 completed (loss: 0.13035382330417633, acc: 0.9555555582046509)
[2024-11-13 09:17:38,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:39,564][root][INFO] - Training Epoch: 5/10, step 219/574 completed (loss: 0.06726519763469696, acc: 0.9696969985961914)
[2024-11-13 09:17:39,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:40,238][root][INFO] - Training Epoch: 5/10, step 220/574 completed (loss: 0.04541878402233124, acc: 0.9629629850387573)
[2024-11-13 09:17:40,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:40,909][root][INFO] - Training Epoch: 5/10, step 221/574 completed (loss: 0.15897566080093384, acc: 0.9599999785423279)
[2024-11-13 09:17:40,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:41,593][root][INFO] - Training Epoch: 5/10, step 222/574 completed (loss: 0.4531116783618927, acc: 0.8269230723381042)
[2024-11-13 09:17:41,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:42,306][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 0.6015843152999878, acc: 0.85326087474823)
[2024-11-13 09:17:42,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:43,016][root][INFO] - Training Epoch: 5/10, step 224/574 completed (loss: 0.586502194404602, acc: 0.8352272510528564)
[2024-11-13 09:17:43,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:43,727][root][INFO] - Training Epoch: 5/10, step 225/574 completed (loss: 0.8469494581222534, acc: 0.7127659320831299)
[2024-11-13 09:17:43,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:44,404][root][INFO] - Training Epoch: 5/10, step 226/574 completed (loss: 0.2720993757247925, acc: 0.9433962106704712)
[2024-11-13 09:17:44,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:45,079][root][INFO] - Training Epoch: 5/10, step 227/574 completed (loss: 0.20430852472782135, acc: 0.9333333373069763)
[2024-11-13 09:17:45,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:45,762][root][INFO] - Training Epoch: 5/10, step 228/574 completed (loss: 0.08130879700183868, acc: 0.9767441749572754)
[2024-11-13 09:17:45,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:46,440][root][INFO] - Training Epoch: 5/10, step 229/574 completed (loss: 0.29826027154922485, acc: 0.8999999761581421)
[2024-11-13 09:17:46,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:47,138][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 1.3425788879394531, acc: 0.6526315808296204)
[2024-11-13 09:17:47,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:47,817][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 0.7456883192062378, acc: 0.7777777910232544)
[2024-11-13 09:17:47,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:48,521][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 0.9186909794807434, acc: 0.7333333492279053)
[2024-11-13 09:17:48,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:49,233][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 1.2932509183883667, acc: 0.6330274939537048)
[2024-11-13 09:17:49,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:49,943][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 1.1625735759735107, acc: 0.6846153736114502)
[2024-11-13 09:17:50,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:50,631][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 0.13135968148708344, acc: 1.0)
[2024-11-13 09:17:50,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:51,306][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.1047012135386467, acc: 1.0)
[2024-11-13 09:17:51,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:51,991][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 0.12048829346895218, acc: 0.9545454382896423)
[2024-11-13 09:17:52,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:52,677][root][INFO] - Training Epoch: 5/10, step 238/574 completed (loss: 0.10232838243246078, acc: 1.0)
[2024-11-13 09:17:52,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:53,362][root][INFO] - Training Epoch: 5/10, step 239/574 completed (loss: 0.3681792616844177, acc: 0.8571428656578064)
[2024-11-13 09:17:53,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:54,038][root][INFO] - Training Epoch: 5/10, step 240/574 completed (loss: 0.3724115490913391, acc: 0.9090909361839294)
[2024-11-13 09:17:54,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:54,709][root][INFO] - Training Epoch: 5/10, step 241/574 completed (loss: 0.21757054328918457, acc: 0.9545454382896423)
[2024-11-13 09:17:54,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:55,388][root][INFO] - Training Epoch: 5/10, step 242/574 completed (loss: 0.9133105874061584, acc: 0.6612903475761414)
[2024-11-13 09:17:55,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:56,065][root][INFO] - Training Epoch: 5/10, step 243/574 completed (loss: 0.5359394550323486, acc: 0.8409090638160706)
[2024-11-13 09:17:56,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:56,735][root][INFO] - Training Epoch: 5/10, step 244/574 completed (loss: 0.0015878395643085241, acc: 1.0)
[2024-11-13 09:17:56,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:57,413][root][INFO] - Training Epoch: 5/10, step 245/574 completed (loss: 0.08819654583930969, acc: 0.9615384340286255)
[2024-11-13 09:17:57,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:58,085][root][INFO] - Training Epoch: 5/10, step 246/574 completed (loss: 0.014102818444371223, acc: 1.0)
[2024-11-13 09:17:58,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:58,756][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.047661472111940384, acc: 1.0)
[2024-11-13 09:17:58,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:17:59,434][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 0.1818818747997284, acc: 0.9729729890823364)
[2024-11-13 09:17:59,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:00,107][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 0.10020094364881516, acc: 0.9459459185600281)
[2024-11-13 09:18:00,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:00,782][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 0.03109719231724739, acc: 1.0)
[2024-11-13 09:18:00,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:01,466][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 0.29907339811325073, acc: 0.8529411554336548)
[2024-11-13 09:18:01,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:02,156][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.027499904856085777, acc: 1.0)
[2024-11-13 09:18:02,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:02,827][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.0024564513005316257, acc: 1.0)
[2024-11-13 09:18:02,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:03,506][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.054421547800302505, acc: 0.9599999785423279)
[2024-11-13 09:18:03,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:04,192][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.14786922931671143, acc: 0.9677419066429138)
[2024-11-13 09:18:04,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:04,871][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 0.13600270450115204, acc: 0.9298245906829834)
[2024-11-13 09:18:04,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:05,552][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 0.18812592327594757, acc: 0.9428571462631226)
[2024-11-13 09:18:05,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:06,248][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 0.09616073966026306, acc: 0.9868420958518982)
[2024-11-13 09:18:06,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:06,951][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 0.46151286363601685, acc: 0.9150943160057068)
[2024-11-13 09:18:07,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:07,662][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 0.5046430230140686, acc: 0.9083333611488342)
[2024-11-13 09:18:07,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:08,337][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.41420936584472656, acc: 0.8888888955116272)
[2024-11-13 09:18:08,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:09,020][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 0.2893359959125519, acc: 0.8709677457809448)
[2024-11-13 09:18:09,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:09,717][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 1.126617193222046, acc: 0.746666669845581)
[2024-11-13 09:18:09,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:10,394][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 0.4280339777469635, acc: 0.8958333134651184)
[2024-11-13 09:18:10,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:11,105][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 1.4337259531021118, acc: 0.5600000023841858)
[2024-11-13 09:18:11,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:11,789][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 1.0332814455032349, acc: 0.6629213690757751)
[2024-11-13 09:18:11,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:12,471][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 0.6061959862709045, acc: 0.7837837934494019)
[2024-11-13 09:18:12,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:13,154][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 0.5185484886169434, acc: 0.8448275923728943)
[2024-11-13 09:18:13,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:13,826][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.047137822955846786, acc: 1.0)
[2024-11-13 09:18:13,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:14,497][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.06161320209503174, acc: 0.9545454382896423)
[2024-11-13 09:18:14,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:15,174][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.06623844802379608, acc: 0.96875)
[2024-11-13 09:18:15,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:15,846][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.014741865918040276, acc: 1.0)
[2024-11-13 09:18:15,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:16,524][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 0.4639153778553009, acc: 0.8333333134651184)
[2024-11-13 09:18:16,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:17,198][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.20596346259117126, acc: 0.9375)
[2024-11-13 09:18:17,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:17,870][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.07504968345165253, acc: 0.9666666388511658)
[2024-11-13 09:18:17,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:18,549][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 0.27340272068977356, acc: 0.931034505367279)
[2024-11-13 09:18:18,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:19,220][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.08090977370738983, acc: 0.9599999785423279)
[2024-11-13 09:18:20,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:20,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:21,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:21,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:22,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:22,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:23,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:24,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:24,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:25,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:25,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:26,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:27,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:28,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:28,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:29,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:29,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:30,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:31,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:31,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:32,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:32,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:33,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:33,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:34,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:35,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:35,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:36,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:37,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:38,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:39,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:39,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:40,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:40,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:41,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:42,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:42,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:43,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:43,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:44,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:46,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:46,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:47,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:47,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:48,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:49,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:49,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:50,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:50,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:51,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:51,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:52,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:53,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:53,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:54,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:54,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:55,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:56,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:56,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:57,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:57,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:58,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:59,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:18:59,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:00,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:00,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:01,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:01,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:02,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:03,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:03,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:04,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:04,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:05,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:06,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:06,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:07,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:09,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:10,060][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1206, device='cuda:0') eval_epoch_loss=tensor(0.7517, device='cuda:0') eval_epoch_acc=tensor(0.8138, device='cuda:0')
[2024-11-13 09:19:10,062][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:19:10,062][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:19:10,371][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_5_step_278_loss_0.7516945004463196/model.pt
[2024-11-13 09:19:10,375][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:19:10,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:11,067][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 0.5189873576164246, acc: 0.8085106611251831)
[2024-11-13 09:19:11,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:11,747][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 0.31724321842193604, acc: 0.9166666865348816)
[2024-11-13 09:19:11,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:12,424][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 0.07088139653205872, acc: 0.9772727489471436)
[2024-11-13 09:19:12,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:13,113][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 0.9037918448448181, acc: 0.7951807379722595)
[2024-11-13 09:19:13,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:13,799][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 0.7115479111671448, acc: 0.7685185074806213)
[2024-11-13 09:19:13,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:14,472][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 0.0759807601571083, acc: 0.9736841917037964)
[2024-11-13 09:19:14,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:15,158][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 0.3122616708278656, acc: 0.9117646813392639)
[2024-11-13 09:19:15,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:15,846][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 0.17968717217445374, acc: 0.925000011920929)
[2024-11-13 09:19:15,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:16,541][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 0.7106205821037292, acc: 0.828125)
[2024-11-13 09:19:16,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:17,246][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 0.6201891899108887, acc: 0.8240000009536743)
[2024-11-13 09:19:17,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:17,929][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 0.4394190013408661, acc: 0.8791208863258362)
[2024-11-13 09:19:18,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:18,622][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 0.5962401032447815, acc: 0.8447204828262329)
[2024-11-13 09:19:18,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:19,330][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 0.8078715801239014, acc: 0.7525773048400879)
[2024-11-13 09:19:19,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:20,004][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.008872544392943382, acc: 1.0)
[2024-11-13 09:19:20,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:20,678][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 0.5128394365310669, acc: 0.8571428656578064)
[2024-11-13 09:19:20,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:21,361][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 0.25052380561828613, acc: 0.9482758641242981)
[2024-11-13 09:19:21,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:22,054][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 0.3938769996166229, acc: 0.8363636136054993)
[2024-11-13 09:19:22,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:22,780][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 0.9379155039787292, acc: 0.7474226951599121)
[2024-11-13 09:19:22,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:23,464][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 0.7042561769485474, acc: 0.8275862336158752)
[2024-11-13 09:19:23,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:24,147][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 0.14453016221523285, acc: 0.9259259104728699)
[2024-11-13 09:19:24,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:24,827][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 0.230030819773674, acc: 0.9473684430122375)
[2024-11-13 09:19:24,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:25,506][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 0.18987300992012024, acc: 0.9642857313156128)
[2024-11-13 09:19:25,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:26,181][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.244516521692276, acc: 0.9375)
[2024-11-13 09:19:26,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:26,898][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 0.1255302131175995, acc: 0.9811320900917053)
[2024-11-13 09:19:26,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:27,577][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.031880125403404236, acc: 1.0)
[2024-11-13 09:19:27,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:28,250][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.033405520021915436, acc: 1.0)
[2024-11-13 09:19:28,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:28,923][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 0.040711794048547745, acc: 1.0)
[2024-11-13 09:19:29,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:29,603][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 0.0840761736035347, acc: 0.9836065769195557)
[2024-11-13 09:19:29,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:30,277][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.09915824234485626, acc: 0.9666666388511658)
[2024-11-13 09:19:30,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:30,945][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.0018751968163996935, acc: 1.0)
[2024-11-13 09:19:31,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:31,626][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 0.33822107315063477, acc: 0.9130434989929199)
[2024-11-13 09:19:31,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:32,314][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 0.13597579300403595, acc: 0.9722222089767456)
[2024-11-13 09:19:32,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:33,003][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 0.26620590686798096, acc: 0.9156626462936401)
[2024-11-13 09:19:33,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:33,690][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 0.2993789315223694, acc: 0.9102563858032227)
[2024-11-13 09:19:33,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:34,392][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 0.3104446828365326, acc: 0.918367326259613)
[2024-11-13 09:19:34,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:35,065][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.010888167656958103, acc: 1.0)
[2024-11-13 09:19:35,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:35,749][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.010922583751380444, acc: 1.0)
[2024-11-13 09:19:35,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:36,425][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.13658250868320465, acc: 0.9354838728904724)
[2024-11-13 09:19:36,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:37,097][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 0.005677171982824802, acc: 1.0)
[2024-11-13 09:19:37,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:37,779][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 0.29053863883018494, acc: 0.9402984976768494)
[2024-11-13 09:19:37,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:38,468][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 0.17833933234214783, acc: 0.9519230723381042)
[2024-11-13 09:19:38,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:39,155][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 0.27300208806991577, acc: 0.8888888955116272)
[2024-11-13 09:19:39,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:39,835][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 0.09953445196151733, acc: 0.9838709831237793)
[2024-11-13 09:19:39,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:40,522][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.037247080355882645, acc: 0.9800000190734863)
[2024-11-13 09:19:40,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:41,196][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 0.3662809431552887, acc: 0.8888888955116272)
[2024-11-13 09:19:41,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:41,880][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 0.6435957551002502, acc: 0.7714285850524902)
[2024-11-13 09:19:41,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:42,563][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 0.4992057681083679, acc: 0.8461538553237915)
[2024-11-13 09:19:42,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:43,242][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 0.6044414639472961, acc: 0.8536585569381714)
[2024-11-13 09:19:43,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:43,921][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 0.5973876714706421, acc: 0.8421052694320679)
[2024-11-13 09:19:44,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:44,597][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.1309359073638916, acc: 0.9473684430122375)
[2024-11-13 09:19:44,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:45,269][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.020618531852960587, acc: 1.0)
[2024-11-13 09:19:45,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:45,941][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 0.08725827187299728, acc: 0.9259259104728699)
[2024-11-13 09:19:46,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:46,622][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.00565171567723155, acc: 1.0)
[2024-11-13 09:19:46,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:47,302][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 0.15496692061424255, acc: 0.9677419066429138)
[2024-11-13 09:19:47,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:47,985][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 0.1576768159866333, acc: 0.9649122953414917)
[2024-11-13 09:19:48,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:48,656][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 0.3802027106285095, acc: 0.96875)
[2024-11-13 09:19:48,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:49,329][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.17535458505153656, acc: 0.9333333373069763)
[2024-11-13 09:19:49,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:50,002][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.16817976534366608, acc: 0.9473684430122375)
[2024-11-13 09:19:50,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:50,688][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 0.8968381285667419, acc: 0.7200000286102295)
[2024-11-13 09:19:50,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:51,376][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 0.9324902892112732, acc: 0.6666666865348816)
[2024-11-13 09:19:51,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:52,058][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 1.059370517730713, acc: 0.6914893388748169)
[2024-11-13 09:19:52,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:52,743][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 1.1225249767303467, acc: 0.6867470145225525)
[2024-11-13 09:19:52,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:53,416][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 0.08994556218385696, acc: 0.95652174949646)
[2024-11-13 09:19:53,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:54,089][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 0.18005098402500153, acc: 0.9230769276618958)
[2024-11-13 09:19:54,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:54,769][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 0.5948850512504578, acc: 0.8192771077156067)
[2024-11-13 09:19:54,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:55,450][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 0.25518491864204407, acc: 0.9056603908538818)
[2024-11-13 09:19:55,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:56,131][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 0.2609969675540924, acc: 0.9240506291389465)
[2024-11-13 09:19:56,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:56,806][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 0.2223736196756363, acc: 0.9215686321258545)
[2024-11-13 09:19:56,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:57,486][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 0.5405252575874329, acc: 0.7910447716712952)
[2024-11-13 09:19:57,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:58,157][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.31458184123039246, acc: 0.949999988079071)
[2024-11-13 09:19:58,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:58,830][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 0.09345916658639908, acc: 1.0)
[2024-11-13 09:19:58,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:19:59,504][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 0.6461946368217468, acc: 0.7777777910232544)
[2024-11-13 09:19:59,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:00,180][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 0.32910728454589844, acc: 0.9069767594337463)
[2024-11-13 09:20:00,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:00,855][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 0.23982705175876617, acc: 0.8461538553237915)
[2024-11-13 09:20:00,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:01,542][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 0.39733436703681946, acc: 0.8444444537162781)
[2024-11-13 09:20:01,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:02,214][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.049767158925533295, acc: 1.0)
[2024-11-13 09:20:02,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:02,887][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.0746145099401474, acc: 1.0)
[2024-11-13 09:20:02,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:03,584][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 0.8573665618896484, acc: 0.7362637519836426)
[2024-11-13 09:20:03,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:04,291][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 0.8520846366882324, acc: 0.7652173638343811)
[2024-11-13 09:20:04,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:04,972][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 0.6174260973930359, acc: 0.8369565010070801)
[2024-11-13 09:20:05,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:05,657][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 0.642829418182373, acc: 0.795918345451355)
[2024-11-13 09:20:05,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:06,333][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.005296738818287849, acc: 1.0)
[2024-11-13 09:20:06,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:07,004][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.12452239543199539, acc: 0.9615384340286255)
[2024-11-13 09:20:07,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:07,679][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.16510145366191864, acc: 0.9512194991111755)
[2024-11-13 09:20:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:08,354][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 0.29083171486854553, acc: 0.9111111164093018)
[2024-11-13 09:20:08,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:09,036][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 0.21685321629047394, acc: 0.9473684430122375)
[2024-11-13 09:20:09,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:09,725][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 0.2582184374332428, acc: 0.9756097793579102)
[2024-11-13 09:20:09,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:10,412][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 0.08586655557155609, acc: 0.9696969985961914)
[2024-11-13 09:20:10,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:11,099][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.02239544689655304, acc: 1.0)
[2024-11-13 09:20:11,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:11,772][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.00820311438292265, acc: 1.0)
[2024-11-13 09:20:11,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:12,444][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.029757002368569374, acc: 1.0)
[2024-11-13 09:20:12,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:13,119][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.1813557893037796, acc: 0.9375)
[2024-11-13 09:20:13,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:13,830][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 0.876232922077179, acc: 0.7454545497894287)
[2024-11-13 09:20:13,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:14,534][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 0.34481340646743774, acc: 0.9339622855186462)
[2024-11-13 09:20:14,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:15,215][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 0.3406910002231598, acc: 0.9111111164093018)
[2024-11-13 09:20:15,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:15,892][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 0.2234695702791214, acc: 0.9642857313156128)
[2024-11-13 09:20:15,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:16,579][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.030418386682868004, acc: 1.0)
[2024-11-13 09:20:16,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:17,253][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.021567964926362038, acc: 1.0)
[2024-11-13 09:20:17,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:17,924][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.007319942582398653, acc: 1.0)
[2024-11-13 09:20:18,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:18,610][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 0.03545328602194786, acc: 1.0)
[2024-11-13 09:20:18,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:19,295][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 0.09102167934179306, acc: 0.9578947424888611)
[2024-11-13 09:20:19,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:20,000][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 0.3670644164085388, acc: 0.9041916131973267)
[2024-11-13 09:20:20,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:20,699][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 0.26460251212120056, acc: 0.9473684430122375)
[2024-11-13 09:20:20,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:21,417][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 0.7970585823059082, acc: 0.8074866533279419)
[2024-11-13 09:20:21,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:22,121][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 0.15819589793682098, acc: 0.954954981803894)
[2024-11-13 09:20:22,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:22,793][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.049574803560972214, acc: 0.9642857313156128)
[2024-11-13 09:20:22,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:23,466][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.02387887053191662, acc: 1.0)
[2024-11-13 09:20:23,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:24,140][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 0.16231265664100647, acc: 0.96875)
[2024-11-13 09:20:24,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:24,813][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.02716856077313423, acc: 1.0)
[2024-11-13 09:20:24,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:25,485][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.02420262061059475, acc: 1.0)
[2024-11-13 09:20:25,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:26,156][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.02342415601015091, acc: 1.0)
[2024-11-13 09:20:26,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:26,831][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.02471045032143593, acc: 1.0)
[2024-11-13 09:20:26,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:27,503][root][INFO] - Training Epoch: 5/10, step 390/574 completed (loss: 0.07602852582931519, acc: 0.9523809552192688)
[2024-11-13 09:20:27,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:28,182][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 0.8576855063438416, acc: 0.7592592835426331)
[2024-11-13 09:20:28,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:28,863][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 0.6618075966835022, acc: 0.7961165308952332)
[2024-11-13 09:20:28,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:29,573][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 0.9577303528785706, acc: 0.7647058963775635)
[2024-11-13 09:20:29,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:30,262][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 0.7382725477218628, acc: 0.7733333110809326)
[2024-11-13 09:20:30,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:30,950][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 0.6685869693756104, acc: 0.8125)
[2024-11-13 09:20:31,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:31,627][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 0.2801017463207245, acc: 0.9069767594337463)
[2024-11-13 09:20:31,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:32,302][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.17153239250183105, acc: 0.9583333134651184)
[2024-11-13 09:20:32,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:32,979][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 0.1906488984823227, acc: 0.930232584476471)
[2024-11-13 09:20:33,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:33,652][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 0.02286587469279766, acc: 1.0)
[2024-11-13 09:20:33,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:34,338][root][INFO] - Training Epoch: 5/10, step 400/574 completed (loss: 0.2722826898097992, acc: 0.9117646813392639)
[2024-11-13 09:20:34,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:35,021][root][INFO] - Training Epoch: 5/10, step 401/574 completed (loss: 0.4104737639427185, acc: 0.8799999952316284)
[2024-11-13 09:20:35,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:35,700][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 0.025710495188832283, acc: 1.0)
[2024-11-13 09:20:35,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:36,374][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 0.13267187774181366, acc: 0.939393937587738)
[2024-11-13 09:20:36,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:37,048][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.011319560930132866, acc: 1.0)
[2024-11-13 09:20:37,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:37,723][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 0.023917337879538536, acc: 1.0)
[2024-11-13 09:20:37,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:38,396][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.0053095584735274315, acc: 1.0)
[2024-11-13 09:20:38,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:39,071][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.011613325215876102, acc: 1.0)
[2024-11-13 09:20:39,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:39,753][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.11567683517932892, acc: 0.9259259104728699)
[2024-11-13 09:20:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:40,428][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.005193505901843309, acc: 1.0)
[2024-11-13 09:20:40,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:41,106][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 0.18636885285377502, acc: 0.9482758641242981)
[2024-11-13 09:20:41,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:41,780][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.023100441321730614, acc: 1.0)
[2024-11-13 09:20:41,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:42,456][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.15432633459568024, acc: 0.9666666388511658)
[2024-11-13 09:20:42,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:43,142][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.14795947074890137, acc: 0.939393937587738)
[2024-11-13 09:20:43,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:43,815][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.028665833175182343, acc: 1.0)
[2024-11-13 09:20:43,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:44,494][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 0.358735591173172, acc: 0.8823529481887817)
[2024-11-13 09:20:44,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:45,168][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 0.030401121824979782, acc: 1.0)
[2024-11-13 09:20:45,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:45,838][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 0.10200457274913788, acc: 0.9444444179534912)
[2024-11-13 09:20:45,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:46,522][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 0.21841879189014435, acc: 0.925000011920929)
[2024-11-13 09:20:46,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:47,211][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 0.11519918590784073, acc: 1.0)
[2024-11-13 09:20:47,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:47,885][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.036351580172777176, acc: 1.0)
[2024-11-13 09:20:48,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:49,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:49,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:50,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:50,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:51,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:52,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:52,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:53,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:53,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:54,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:55,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:55,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:56,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:56,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:57,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:57,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:58,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:20:59,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:00,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:00,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:01,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:02,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:02,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:03,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:03,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:04,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:05,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:06,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:06,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:07,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:08,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:08,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:09,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:09,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:10,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:11,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:11,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:12,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:12,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:13,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:13,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:14,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:15,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:15,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:16,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:17,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:17,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:18,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:18,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:19,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:20,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:21,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:22,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:22,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:23,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:24,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:24,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:25,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:25,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:26,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:26,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:27,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:28,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:28,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:29,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:29,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:30,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:31,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:31,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:32,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:32,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:33,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:34,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:34,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:35,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:36,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:36,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:37,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:37,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:38,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:39,330][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2870, device='cuda:0') eval_epoch_loss=tensor(0.8272, device='cuda:0') eval_epoch_acc=tensor(0.7980, device='cuda:0')
[2024-11-13 09:21:39,332][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:21:39,332][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:21:39,681][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_5_step_421_loss_0.8272319436073303/model.pt
[2024-11-13 09:21:39,685][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:21:39,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:40,384][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.06702210009098053, acc: 0.9666666388511658)
[2024-11-13 09:21:40,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:41,060][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.1404271423816681, acc: 0.9375)
[2024-11-13 09:21:41,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:41,734][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.0480332225561142, acc: 1.0)
[2024-11-13 09:21:41,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:42,406][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.08701566606760025, acc: 0.9629629850387573)
[2024-11-13 09:21:42,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:43,081][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.15259949862957, acc: 0.939393937587738)
[2024-11-13 09:21:43,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:43,752][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 0.014064387418329716, acc: 1.0)
[2024-11-13 09:21:43,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:44,438][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 0.05580419301986694, acc: 0.9729729890823364)
[2024-11-13 09:21:44,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:45,111][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.12088765949010849, acc: 0.9629629850387573)
[2024-11-13 09:21:45,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:45,795][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.008499355055391788, acc: 1.0)
[2024-11-13 09:21:45,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:46,480][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.0013486039824783802, acc: 1.0)
[2024-11-13 09:21:46,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:47,160][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.0017751752166077495, acc: 1.0)
[2024-11-13 09:21:47,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:47,844][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.01101144403219223, acc: 1.0)
[2024-11-13 09:21:47,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:48,520][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 0.03678781911730766, acc: 1.0)
[2024-11-13 09:21:48,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:49,190][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.001911941566504538, acc: 1.0)
[2024-11-13 09:21:49,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:49,864][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.1909581869840622, acc: 0.9696969985961914)
[2024-11-13 09:21:49,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:50,549][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 0.12479330599308014, acc: 0.9444444179534912)
[2024-11-13 09:21:50,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:51,228][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 0.13915541768074036, acc: 0.9772727489471436)
[2024-11-13 09:21:51,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:51,906][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.0033407900482416153, acc: 1.0)
[2024-11-13 09:21:51,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:52,581][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 0.17931383848190308, acc: 0.9230769276618958)
[2024-11-13 09:21:52,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:53,266][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 0.6759166121482849, acc: 0.8636363744735718)
[2024-11-13 09:21:53,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:53,977][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 1.0936306715011597, acc: 0.6800000071525574)
[2024-11-13 09:21:54,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:54,664][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 0.897861659526825, acc: 0.7903226017951965)
[2024-11-13 09:21:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:55,373][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 0.7299513816833496, acc: 0.8159204125404358)
[2024-11-13 09:21:55,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:56,049][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 0.13797686994075775, acc: 0.9622641801834106)
[2024-11-13 09:21:56,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:56,729][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 0.1383238583803177, acc: 0.9318181872367859)
[2024-11-13 09:21:56,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:57,401][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 0.054892539978027344, acc: 1.0)
[2024-11-13 09:21:57,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:58,072][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 0.13429953157901764, acc: 0.9230769276618958)
[2024-11-13 09:21:58,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:58,742][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.0847233310341835, acc: 0.9642857313156128)
[2024-11-13 09:21:58,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:21:59,422][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 0.07159282267093658, acc: 0.9850746393203735)
[2024-11-13 09:21:59,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:00,102][root][INFO] - Training Epoch: 5/10, step 450/574 completed (loss: 0.09641578048467636, acc: 0.9722222089767456)
[2024-11-13 09:22:00,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:00,794][root][INFO] - Training Epoch: 5/10, step 451/574 completed (loss: 0.08480491489171982, acc: 0.97826087474823)
[2024-11-13 09:22:00,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:01,476][root][INFO] - Training Epoch: 5/10, step 452/574 completed (loss: 0.16470104455947876, acc: 0.9615384340286255)
[2024-11-13 09:22:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:02,158][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 0.3070616126060486, acc: 0.8815789222717285)
[2024-11-13 09:22:02,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:02,833][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 0.03531917184591293, acc: 1.0)
[2024-11-13 09:22:02,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:03,515][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 0.09023872762918472, acc: 0.9696969985961914)
[2024-11-13 09:22:03,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:04,198][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 0.5423892140388489, acc: 0.8453608155250549)
[2024-11-13 09:22:04,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:04,884][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 0.14523200690746307, acc: 0.9714285731315613)
[2024-11-13 09:22:04,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:05,605][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 0.5760795474052429, acc: 0.8255813717842102)
[2024-11-13 09:22:05,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:06,279][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 0.169284388422966, acc: 0.9464285969734192)
[2024-11-13 09:22:06,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:06,979][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 0.374188631772995, acc: 0.9012345671653748)
[2024-11-13 09:22:07,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:07,656][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 0.19024282693862915, acc: 0.9722222089767456)
[2024-11-13 09:22:07,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:08,330][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.008570775389671326, acc: 1.0)
[2024-11-13 09:22:08,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:09,001][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.06138799339532852, acc: 1.0)
[2024-11-13 09:22:09,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:09,679][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 0.20526213943958282, acc: 0.95652174949646)
[2024-11-13 09:22:09,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:10,360][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 0.30224934220314026, acc: 0.9166666865348816)
[2024-11-13 09:22:10,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:11,040][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 0.2501903474330902, acc: 0.9156626462936401)
[2024-11-13 09:22:11,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:11,754][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 0.3161650002002716, acc: 0.9009009003639221)
[2024-11-13 09:22:11,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:12,440][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 0.6500293612480164, acc: 0.8349514603614807)
[2024-11-13 09:22:12,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:13,149][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 0.5418838262557983, acc: 0.8617886304855347)
[2024-11-13 09:22:13,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:13,822][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.015443463809788227, acc: 1.0)
[2024-11-13 09:22:13,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:14,494][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.23107290267944336, acc: 0.9285714030265808)
[2024-11-13 09:22:14,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:15,207][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 0.742473304271698, acc: 0.7254902124404907)
[2024-11-13 09:22:15,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:15,914][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 0.8857004642486572, acc: 0.7074235677719116)
[2024-11-13 09:22:15,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:16,605][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 0.48701611161231995, acc: 0.8541666865348816)
[2024-11-13 09:22:16,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:17,296][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 0.46127548813819885, acc: 0.8711656332015991)
[2024-11-13 09:22:17,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:17,987][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 0.37954282760620117, acc: 0.8992805480957031)
[2024-11-13 09:22:18,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:18,695][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 0.865997314453125, acc: 0.7537688612937927)
[2024-11-13 09:22:18,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:19,367][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.0521664135158062, acc: 1.0)
[2024-11-13 09:22:19,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:20,037][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.12616820633411407, acc: 1.0)
[2024-11-13 09:22:20,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:20,707][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.0390901044011116, acc: 1.0)
[2024-11-13 09:22:20,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:21,375][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 0.21372056007385254, acc: 0.949999988079071)
[2024-11-13 09:22:21,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:22,047][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 0.03096747398376465, acc: 1.0)
[2024-11-13 09:22:22,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:22,732][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 0.4069466292858124, acc: 0.8793103694915771)
[2024-11-13 09:22:22,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:23,405][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.02455838955938816, acc: 1.0)
[2024-11-13 09:22:23,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:24,076][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.12833969295024872, acc: 0.9473684430122375)
[2024-11-13 09:22:24,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:24,759][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 0.3065199553966522, acc: 0.9259259104728699)
[2024-11-13 09:22:24,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:25,430][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 0.11339302361011505, acc: 0.9523809552192688)
[2024-11-13 09:22:25,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:26,101][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 0.11299226433038712, acc: 0.9545454382896423)
[2024-11-13 09:22:26,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:26,793][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 0.375072717666626, acc: 0.9230769276618958)
[2024-11-13 09:22:26,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:27,469][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 0.02297365479171276, acc: 1.0)
[2024-11-13 09:22:27,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:28,145][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 0.06638747453689575, acc: 0.9655172228813171)
[2024-11-13 09:22:28,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:28,823][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 0.26515498757362366, acc: 0.9411764740943909)
[2024-11-13 09:22:28,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:29,493][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 0.1601978987455368, acc: 0.9655172228813171)
[2024-11-13 09:22:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:30,162][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.04853251576423645, acc: 1.0)
[2024-11-13 09:22:30,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:30,835][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 0.8262988924980164, acc: 0.8947368264198303)
[2024-11-13 09:22:30,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:31,523][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 0.6640623211860657, acc: 0.8303571343421936)
[2024-11-13 09:22:31,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:32,214][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 0.32869476079940796, acc: 0.932584285736084)
[2024-11-13 09:22:32,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:32,908][root][INFO] - Training Epoch: 5/10, step 498/574 completed (loss: 0.6447585225105286, acc: 0.7865168452262878)
[2024-11-13 09:22:32,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:33,616][root][INFO] - Training Epoch: 5/10, step 499/574 completed (loss: 1.0367504358291626, acc: 0.6595744490623474)
[2024-11-13 09:22:33,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:34,304][root][INFO] - Training Epoch: 5/10, step 500/574 completed (loss: 0.6978978514671326, acc: 0.79347825050354)
[2024-11-13 09:22:34,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:34,977][root][INFO] - Training Epoch: 5/10, step 501/574 completed (loss: 0.0244608037173748, acc: 1.0)
[2024-11-13 09:22:35,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:35,653][root][INFO] - Training Epoch: 5/10, step 502/574 completed (loss: 0.02039753645658493, acc: 1.0)
[2024-11-13 09:22:35,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:36,325][root][INFO] - Training Epoch: 5/10, step 503/574 completed (loss: 0.013132303021848202, acc: 1.0)
[2024-11-13 09:22:36,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:36,998][root][INFO] - Training Epoch: 5/10, step 504/574 completed (loss: 0.04271175339818001, acc: 1.0)
[2024-11-13 09:22:37,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:37,676][root][INFO] - Training Epoch: 5/10, step 505/574 completed (loss: 0.2680602967739105, acc: 0.9245283007621765)
[2024-11-13 09:22:37,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:38,349][root][INFO] - Training Epoch: 5/10, step 506/574 completed (loss: 0.11320516467094421, acc: 0.931034505367279)
[2024-11-13 09:22:38,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:39,038][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 0.6492593288421631, acc: 0.837837815284729)
[2024-11-13 09:22:39,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:39,725][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 0.26759761571884155, acc: 0.9436619877815247)
[2024-11-13 09:22:39,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:40,400][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.03540005534887314, acc: 1.0)
[2024-11-13 09:22:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:41,072][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.07493330538272858, acc: 0.9666666388511658)
[2024-11-13 09:22:41,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:41,752][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.046570830047130585, acc: 0.9615384340286255)
[2024-11-13 09:22:41,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:42,491][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.5304608345031738, acc: 0.6214285492897034)
[2024-11-13 09:22:42,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:43,197][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 0.4229658246040344, acc: 0.8809523582458496)
[2024-11-13 09:22:43,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:43,873][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.06988746672868729, acc: 0.9642857313156128)
[2024-11-13 09:22:43,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:44,565][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 0.07582548260688782, acc: 0.9833333492279053)
[2024-11-13 09:22:44,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:45,255][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 0.5736436247825623, acc: 0.7916666865348816)
[2024-11-13 09:22:45,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:45,925][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.0970143973827362, acc: 0.9615384340286255)
[2024-11-13 09:22:46,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:46,603][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 0.01838880032300949, acc: 1.0)
[2024-11-13 09:22:46,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:47,268][root][INFO] - Training Epoch: 5/10, step 519/574 completed (loss: 0.009164487943053246, acc: 1.0)
[2024-11-13 09:22:47,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:47,939][root][INFO] - Training Epoch: 5/10, step 520/574 completed (loss: 0.03817698359489441, acc: 1.0)
[2024-11-13 09:22:48,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:48,883][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 1.3083574771881104, acc: 0.6398305296897888)
[2024-11-13 09:22:48,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:49,592][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 0.4743514657020569, acc: 0.8656716346740723)
[2024-11-13 09:22:49,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:50,282][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 0.4815796911716461, acc: 0.8686131238937378)
[2024-11-13 09:22:50,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:51,004][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 0.7578533887863159, acc: 0.8199999928474426)
[2024-11-13 09:22:51,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:51,685][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 0.04737291485071182, acc: 0.9814814925193787)
[2024-11-13 09:22:51,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:52,366][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 0.1743239313364029, acc: 0.942307710647583)
[2024-11-13 09:22:52,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:53,038][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 0.46936529874801636, acc: 0.8571428656578064)
[2024-11-13 09:22:53,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:53,721][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 0.8200318813323975, acc: 0.7213114500045776)
[2024-11-13 09:22:53,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:54,407][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 0.17195914685726166, acc: 0.9491525292396545)
[2024-11-13 09:22:54,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:55,084][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 0.24538084864616394, acc: 0.9069767594337463)
[2024-11-13 09:22:55,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:55,770][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 0.4041571617126465, acc: 0.8863636255264282)
[2024-11-13 09:22:55,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:56,449][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 0.47339141368865967, acc: 0.9056603908538818)
[2024-11-13 09:22:56,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:57,124][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 0.16803717613220215, acc: 0.9545454382896423)
[2024-11-13 09:22:57,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:57,795][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.075286865234375, acc: 0.9599999785423279)
[2024-11-13 09:22:57,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:58,467][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.046346720308065414, acc: 1.0)
[2024-11-13 09:22:58,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:59,149][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.030627669766545296, acc: 1.0)
[2024-11-13 09:22:59,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:22:59,831][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 0.1916462779045105, acc: 0.9538461565971375)
[2024-11-13 09:22:59,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:00,523][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 0.1662745326757431, acc: 0.921875)
[2024-11-13 09:23:00,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:01,210][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.26889657974243164, acc: 0.9375)
[2024-11-13 09:23:01,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:01,889][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.11138082295656204, acc: 0.9696969985961914)
[2024-11-13 09:23:01,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:02,569][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.018585635349154472, acc: 1.0)
[2024-11-13 09:23:02,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:03,244][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.05902593582868576, acc: 0.9677419066429138)
[2024-11-13 09:23:03,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:03,915][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.005353259388357401, acc: 1.0)
[2024-11-13 09:23:04,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:04,597][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.037173379212617874, acc: 1.0)
[2024-11-13 09:23:04,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:05,271][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 0.026883499696850777, acc: 1.0)
[2024-11-13 09:23:05,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:05,948][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.09509081393480301, acc: 0.9714285731315613)
[2024-11-13 09:23:06,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:06,638][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.01773335598409176, acc: 1.0)
[2024-11-13 09:23:06,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:07,312][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.05016619712114334, acc: 1.0)
[2024-11-13 09:23:07,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:07,983][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.0026512315962463617, acc: 1.0)
[2024-11-13 09:23:08,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:08,657][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.3864365220069885, acc: 0.9696969985961914)
[2024-11-13 09:23:08,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:09,332][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.016663450747728348, acc: 1.0)
[2024-11-13 09:23:09,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:10,011][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 0.07153993844985962, acc: 0.9714285731315613)
[2024-11-13 09:23:10,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:10,715][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 0.4903147220611572, acc: 0.8832116723060608)
[2024-11-13 09:23:10,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:11,417][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 0.23199225962162018, acc: 0.9379310607910156)
[2024-11-13 09:23:11,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:12,105][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 0.37050992250442505, acc: 0.9142857193946838)
[2024-11-13 09:23:12,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:12,802][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 0.340344101190567, acc: 0.9006622433662415)
[2024-11-13 09:23:12,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:13,490][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 0.08818169683218002, acc: 0.9743589758872986)
[2024-11-13 09:23:13,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:14,162][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.022993410006165504, acc: 1.0)
[2024-11-13 09:23:14,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:14,843][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.16628924012184143, acc: 0.9230769276618958)
[2024-11-13 09:23:14,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:15,514][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.009531834162771702, acc: 1.0)
[2024-11-13 09:23:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:16,191][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 0.016404783353209496, acc: 1.0)
[2024-11-13 09:23:16,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:16,893][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 0.30422133207321167, acc: 0.8999999761581421)
[2024-11-13 09:23:16,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:17,572][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 0.14978589117527008, acc: 0.9610389471054077)
[2024-11-13 09:23:18,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:19,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:19,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:20,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:21,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:22,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:22,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:23,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:23,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:25,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:25,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:26,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:26,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:27,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:27,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:28,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:29,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:29,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:30,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:30,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:31,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:32,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:32,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:33,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:33,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:34,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:35,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:35,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:36,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:36,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:37,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:37,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:38,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:39,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:39,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:40,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:40,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:41,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:42,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:42,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:43,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:43,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:44,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:44,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:45,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:46,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:46,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:47,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:48,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:49,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:49,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:50,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:50,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:51,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:52,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:52,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:53,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:53,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:54,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:55,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:55,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:56,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:56,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:57,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:58,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:58,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:59,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:23:59,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:00,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:01,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:01,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:02,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:02,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:03,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:04,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:04,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:05,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:05,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:06,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:06,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:07,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:08,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:09,063][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1670, device='cuda:0') eval_epoch_loss=tensor(0.7733, device='cuda:0') eval_epoch_acc=tensor(0.8131, device='cuda:0')
[2024-11-13 09:24:09,064][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:24:09,064][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:24:09,410][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_5_step_564_loss_0.7733426690101624/model.pt
[2024-11-13 09:24:09,415][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:24:09,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:10,103][root][INFO] - Training Epoch: 5/10, step 564/574 completed (loss: 0.06673050671815872, acc: 0.9791666865348816)
[2024-11-13 09:24:10,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:10,779][root][INFO] - Training Epoch: 5/10, step 565/574 completed (loss: 0.11065171658992767, acc: 0.9655172228813171)
[2024-11-13 09:24:10,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:11,464][root][INFO] - Training Epoch: 5/10, step 566/574 completed (loss: 0.22926807403564453, acc: 0.9404761791229248)
[2024-11-13 09:24:11,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:12,137][root][INFO] - Training Epoch: 5/10, step 567/574 completed (loss: 0.04178163409233093, acc: 0.9736841917037964)
[2024-11-13 09:24:12,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:12,807][root][INFO] - Training Epoch: 5/10, step 568/574 completed (loss: 0.08195799589157104, acc: 0.9629629850387573)
[2024-11-13 09:24:12,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:13,537][root][INFO] - Training Epoch: 5/10, step 569/574 completed (loss: 0.4544624388217926, acc: 0.866310179233551)
[2024-11-13 09:24:13,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:14,224][root][INFO] - Training Epoch: 5/10, step 570/574 completed (loss: 0.0253854151815176, acc: 1.0)
[2024-11-13 09:24:14,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:14,914][root][INFO] - Training Epoch: 5/10, step 571/574 completed (loss: 0.2013435661792755, acc: 0.9230769276618958)
[2024-11-13 09:24:14,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:15,621][root][INFO] - Training Epoch: 5/10, step 572/574 completed (loss: 0.662987232208252, acc: 0.8265306353569031)
[2024-11-13 09:24:15,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:16,337][root][INFO] - Training Epoch: 5/10, step 573/574 completed (loss: 0.4473389983177185, acc: 0.8616352081298828)
[2024-11-13 09:24:16,721][slam_llm.utils.train_utils][INFO] - Epoch 5: train_perplexity=1.4506, train_epoch_loss=0.3720, epoch time 602.617788977921s
[2024-11-13 09:24:16,722][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 09:24:16,722][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 09:24:16,722][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 09:24:16,722][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 5
[2024-11-13 09:24:16,722][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 09:24:17,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:18,080][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 0.03475383669137955, acc: 1.0)
[2024-11-13 09:24:18,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:18,764][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.07227443158626556, acc: 1.0)
[2024-11-13 09:24:18,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:19,451][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 0.24079662561416626, acc: 0.9189189076423645)
[2024-11-13 09:24:19,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:20,141][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 0.1098177433013916, acc: 0.9473684430122375)
[2024-11-13 09:24:20,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:20,838][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 0.12171097099781036, acc: 0.9459459185600281)
[2024-11-13 09:24:20,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:21,531][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.019720887765288353, acc: 1.0)
[2024-11-13 09:24:21,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:22,233][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 0.1867155134677887, acc: 0.9591836929321289)
[2024-11-13 09:24:22,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:22,915][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.06370404362678528, acc: 0.9666666388511658)
[2024-11-13 09:24:23,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:23,603][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.0022513456642627716, acc: 1.0)
[2024-11-13 09:24:23,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:24,286][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.006691974122077227, acc: 1.0)
[2024-11-13 09:24:24,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:24,972][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.002318290062248707, acc: 1.0)
[2024-11-13 09:24:25,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:25,659][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 0.1457156091928482, acc: 0.9743589758872986)
[2024-11-13 09:24:25,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:26,344][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.06870994716882706, acc: 0.9696969985961914)
[2024-11-13 09:24:26,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:27,029][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 0.09822573512792587, acc: 0.95652174949646)
[2024-11-13 09:24:27,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:27,728][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 0.0855037271976471, acc: 0.9607843160629272)
[2024-11-13 09:24:27,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:28,417][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 0.1854175478219986, acc: 0.918367326259613)
[2024-11-13 09:24:28,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:29,109][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.012025000527501106, acc: 1.0)
[2024-11-13 09:24:29,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:29,808][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.03767187520861626, acc: 1.0)
[2024-11-13 09:24:29,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:30,497][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.03673134744167328, acc: 0.9722222089767456)
[2024-11-13 09:24:30,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:31,184][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 0.005419490858912468, acc: 1.0)
[2024-11-13 09:24:31,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:31,879][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 0.17044688761234283, acc: 0.9615384340286255)
[2024-11-13 09:24:31,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:32,573][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.1114778220653534, acc: 0.9655172228813171)
[2024-11-13 09:24:32,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:33,255][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.021458592265844345, acc: 1.0)
[2024-11-13 09:24:33,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:33,935][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.0915612131357193, acc: 0.9047619104385376)
[2024-11-13 09:24:34,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:34,625][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 0.0014510836917907, acc: 1.0)
[2024-11-13 09:24:34,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:35,320][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 0.5730069279670715, acc: 0.8301886916160583)
[2024-11-13 09:24:35,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:36,010][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 0.40586650371551514, acc: 0.8767123222351074)
[2024-11-13 09:24:36,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:36,811][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 1.392040491104126, acc: 0.6284584999084473)
[2024-11-13 09:24:36,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:37,505][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 0.36192232370376587, acc: 0.9069767594337463)
[2024-11-13 09:24:37,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:38,203][root][INFO] - Training Epoch: 6/10, step 29/574 completed (loss: 0.37921199202537537, acc: 0.8795180916786194)
[2024-11-13 09:24:38,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:38,906][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 0.46488645672798157, acc: 0.8765432238578796)
[2024-11-13 09:24:38,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:39,604][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 0.10978672653436661, acc: 0.9642857313156128)
[2024-11-13 09:24:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:40,298][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 0.025615433230996132, acc: 1.0)
[2024-11-13 09:24:40,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:40,980][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.21584062278270721, acc: 0.95652174949646)
[2024-11-13 09:24:41,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:41,678][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 0.5860349535942078, acc: 0.8655462265014648)
[2024-11-13 09:24:41,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:42,368][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 0.28023597598075867, acc: 0.9344262480735779)
[2024-11-13 09:24:42,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:43,077][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 0.607512354850769, acc: 0.841269850730896)
[2024-11-13 09:24:43,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:43,763][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 0.3228183686733246, acc: 0.9152542352676392)
[2024-11-13 09:24:43,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:44,456][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 0.18754200637340546, acc: 0.931034505367279)
[2024-11-13 09:24:44,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:45,147][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.5748116970062256, acc: 0.9523809552192688)
[2024-11-13 09:24:45,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:45,832][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.0583258680999279, acc: 0.9615384340286255)
[2024-11-13 09:24:45,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:46,524][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 0.2624521851539612, acc: 0.9054054021835327)
[2024-11-13 09:24:46,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:47,217][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 0.16547106206417084, acc: 0.9538461565971375)
[2024-11-13 09:24:47,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:47,907][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 0.2282366156578064, acc: 0.9292929172515869)
[2024-11-13 09:24:48,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:48,612][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 0.2760739326477051, acc: 0.9175257682800293)
[2024-11-13 09:24:48,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:49,317][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 0.3835551142692566, acc: 0.8602941036224365)
[2024-11-13 09:24:49,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:49,999][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.011950219981372356, acc: 1.0)
[2024-11-13 09:24:50,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:50,684][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.012166137807071209, acc: 1.0)
[2024-11-13 09:24:50,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:51,368][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.029948709532618523, acc: 1.0)
[2024-11-13 09:24:51,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:52,056][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.008124252781271935, acc: 1.0)
[2024-11-13 09:24:52,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:52,757][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 0.23957933485507965, acc: 0.9122806787490845)
[2024-11-13 09:24:52,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:53,455][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 0.4714091122150421, acc: 0.8253968358039856)
[2024-11-13 09:24:53,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:54,160][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 0.5247692465782166, acc: 0.8591549396514893)
[2024-11-13 09:24:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:54,880][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.2000101804733276, acc: 0.6733333468437195)
[2024-11-13 09:24:54,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:55,562][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.28043875098228455, acc: 0.9459459185600281)
[2024-11-13 09:24:55,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:56,253][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.01564679853618145, acc: 1.0)
[2024-11-13 09:24:56,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:57,096][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 1.3717758655548096, acc: 0.6279863715171814)
[2024-11-13 09:24:57,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:57,878][root][INFO] - Training Epoch: 6/10, step 57/574 completed (loss: 1.4706056118011475, acc: 0.5947712659835815)
[2024-11-13 09:24:57,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:58,604][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 0.6456233859062195, acc: 0.7954545617103577)
[2024-11-13 09:24:58,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:24:59,304][root][INFO] - Training Epoch: 6/10, step 59/574 completed (loss: 0.47507864236831665, acc: 0.8823529481887817)
[2024-11-13 09:24:59,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:00,024][root][INFO] - Training Epoch: 6/10, step 60/574 completed (loss: 0.6951920986175537, acc: 0.760869562625885)
[2024-11-13 09:25:00,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:00,738][root][INFO] - Training Epoch: 6/10, step 61/574 completed (loss: 0.4415460228919983, acc: 0.875)
[2024-11-13 09:25:00,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:01,423][root][INFO] - Training Epoch: 6/10, step 62/574 completed (loss: 0.26190289855003357, acc: 0.8823529481887817)
[2024-11-13 09:25:01,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:02,109][root][INFO] - Training Epoch: 6/10, step 63/574 completed (loss: 0.08421337604522705, acc: 0.9722222089767456)
[2024-11-13 09:25:02,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:02,813][root][INFO] - Training Epoch: 6/10, step 64/574 completed (loss: 0.16852478682994843, acc: 0.921875)
[2024-11-13 09:25:02,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:03,497][root][INFO] - Training Epoch: 6/10, step 65/574 completed (loss: 0.02882440574467182, acc: 1.0)
[2024-11-13 09:25:03,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:04,192][root][INFO] - Training Epoch: 6/10, step 66/574 completed (loss: 0.2646086513996124, acc: 0.9107142686843872)
[2024-11-13 09:25:04,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:04,893][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 0.23280294239521027, acc: 0.9333333373069763)
[2024-11-13 09:25:05,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:05,579][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.006370412185788155, acc: 1.0)
[2024-11-13 09:25:05,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:06,263][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.09428028762340546, acc: 0.9722222089767456)
[2024-11-13 09:25:06,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:06,949][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.05623739957809448, acc: 1.0)
[2024-11-13 09:25:07,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:07,669][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 0.7739176750183105, acc: 0.7647058963775635)
[2024-11-13 09:25:07,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:08,364][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 0.6847635507583618, acc: 0.8571428656578064)
[2024-11-13 09:25:08,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:09,088][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 1.2488511800765991, acc: 0.6256410479545593)
[2024-11-13 09:25:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:09,780][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 0.7813263535499573, acc: 0.7755101919174194)
[2024-11-13 09:25:09,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:10,481][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 0.982751190662384, acc: 0.7238805890083313)
[2024-11-13 09:25:10,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:11,224][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 1.400589942932129, acc: 0.5912408828735352)
[2024-11-13 09:25:11,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:11,904][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.007071304135024548, acc: 1.0)
[2024-11-13 09:25:11,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:12,596][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.024455206468701363, acc: 1.0)
[2024-11-13 09:25:12,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:13,281][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.07239444553852081, acc: 0.9696969985961914)
[2024-11-13 09:25:13,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:13,965][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.02050853706896305, acc: 1.0)
[2024-11-13 09:25:14,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:14,655][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 0.17178113758563995, acc: 0.9230769276618958)
[2024-11-13 09:25:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:15,344][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 0.3113430142402649, acc: 0.942307710647583)
[2024-11-13 09:25:15,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:16,028][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.4514063000679016, acc: 0.90625)
[2024-11-13 09:25:16,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:16,732][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 0.2803233861923218, acc: 0.8985507488250732)
[2024-11-13 09:25:16,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:17,426][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 0.2788597643375397, acc: 0.8799999952316284)
[2024-11-13 09:25:17,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:18,108][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 0.028499405831098557, acc: 1.0)
[2024-11-13 09:25:18,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:18,800][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 0.29292675852775574, acc: 0.9399999976158142)
[2024-11-13 09:25:18,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:19,499][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 0.42804262042045593, acc: 0.8737863898277283)
[2024-11-13 09:25:19,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:20,216][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 0.7914724349975586, acc: 0.7766990065574646)
[2024-11-13 09:25:20,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:20,938][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.1171795129776, acc: 0.6935483813285828)
[2024-11-13 09:25:21,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:21,675][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 0.8728924989700317, acc: 0.7801724076271057)
[2024-11-13 09:25:21,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:22,386][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 0.46151694655418396, acc: 0.8631578683853149)
[2024-11-13 09:25:22,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:23,110][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 0.9395390152931213, acc: 0.7029703259468079)
[2024-11-13 09:25:23,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:23,803][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 0.31778815388679504, acc: 0.9193548560142517)
[2024-11-13 09:25:23,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:24,493][root][INFO] - Training Epoch: 6/10, step 95/574 completed (loss: 0.2353561520576477, acc: 0.9420289993286133)
[2024-11-13 09:25:24,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:25,203][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 0.7021368145942688, acc: 0.7983193397521973)
[2024-11-13 09:25:25,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:25,903][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 0.6591224670410156, acc: 0.7692307829856873)
[2024-11-13 09:25:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:26,611][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 0.8999942541122437, acc: 0.7372262477874756)
[2024-11-13 09:25:26,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:27,304][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 0.4804370403289795, acc: 0.7910447716712952)
[2024-11-13 09:25:27,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:27,986][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.0035642043221741915, acc: 1.0)
[2024-11-13 09:25:28,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:28,668][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.010806926526129246, acc: 1.0)
[2024-11-13 09:25:28,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:29,349][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.004039532970637083, acc: 1.0)
[2024-11-13 09:25:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:30,037][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.021921874955296516, acc: 1.0)
[2024-11-13 09:25:30,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:30,727][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 0.11908603459596634, acc: 0.9482758641242981)
[2024-11-13 09:25:30,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:31,414][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.03170493617653847, acc: 1.0)
[2024-11-13 09:25:31,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:32,093][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 0.007154473569244146, acc: 1.0)
[2024-11-13 09:25:32,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:32,773][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.008861160837113857, acc: 1.0)
[2024-11-13 09:25:32,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:33,455][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.0035668944474309683, acc: 1.0)
[2024-11-13 09:25:33,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:34,140][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.2140945941209793, acc: 0.9523809552192688)
[2024-11-13 09:25:34,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:34,831][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 0.061761341989040375, acc: 0.9692307710647583)
[2024-11-13 09:25:34,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:35,522][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 0.13928435742855072, acc: 0.9473684430122375)
[2024-11-13 09:25:35,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:36,207][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 0.24868929386138916, acc: 0.9298245906829834)
[2024-11-13 09:25:36,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:36,892][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 0.19220022857189178, acc: 0.9487179517745972)
[2024-11-13 09:25:36,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:37,580][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 0.08802883327007294, acc: 0.9795918464660645)
[2024-11-13 09:25:37,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:38,262][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.00980056170374155, acc: 1.0)
[2024-11-13 09:25:38,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:38,960][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 0.25429588556289673, acc: 0.920634925365448)
[2024-11-13 09:25:39,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:39,655][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 0.2665056586265564, acc: 0.9268292784690857)
[2024-11-13 09:25:39,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:40,347][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 0.13600806891918182, acc: 0.9516128897666931)
[2024-11-13 09:25:40,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:41,107][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 0.7849290370941162, acc: 0.7908745408058167)
[2024-11-13 09:25:41,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:41,805][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 0.08174093812704086, acc: 0.9733333587646484)
[2024-11-13 09:25:41,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:42,496][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 0.06295972317457199, acc: 0.9807692170143127)
[2024-11-13 09:25:42,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:43,183][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.017342301085591316, acc: 1.0)
[2024-11-13 09:25:43,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:43,865][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.011412645690143108, acc: 1.0)
[2024-11-13 09:25:43,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:44,568][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 0.8140378594398499, acc: 0.7791411280632019)
[2024-11-13 09:25:44,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:45,290][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 0.7564039826393127, acc: 0.8472222089767456)
[2024-11-13 09:25:45,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:45,983][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 0.8754367232322693, acc: 0.7333333492279053)
[2024-11-13 09:25:46,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:46,720][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 0.803208589553833, acc: 0.773809552192688)
[2024-11-13 09:25:46,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:47,442][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 0.579246461391449, acc: 0.8358974456787109)
[2024-11-13 09:25:47,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:48,181][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 0.6636447310447693, acc: 0.8235294222831726)
[2024-11-13 09:25:48,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:48,869][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.09182428568601608, acc: 0.9615384340286255)
[2024-11-13 09:25:48,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:49,566][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.12326556444168091, acc: 0.95652174949646)
[2024-11-13 09:25:49,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:50,252][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.225540891289711, acc: 0.9375)
[2024-11-13 09:25:51,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:51,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:52,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:53,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:53,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:54,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:54,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:55,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:56,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:56,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:57,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:57,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:58,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:58,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:25:59,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:00,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:00,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:01,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:01,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:02,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:03,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:03,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:04,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:04,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:05,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:05,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:06,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:07,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:07,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:08,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:08,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:09,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:10,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:10,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:11,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:12,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:12,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:13,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:13,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:14,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:14,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:15,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:16,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:16,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:17,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:17,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:18,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:19,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:19,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:20,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:20,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:21,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:22,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:23,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:23,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:24,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:24,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:25,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:26,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:26,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:27,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:27,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:28,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:28,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:29,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:30,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:30,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:31,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:31,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:32,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:33,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:33,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:34,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:34,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:35,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:35,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:36,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:37,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:37,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:38,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:38,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:39,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:40,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:40,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:41,532][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.9472, device='cuda:0') eval_epoch_loss=tensor(0.6664, device='cuda:0') eval_epoch_acc=tensor(0.8332, device='cuda:0')
[2024-11-13 09:26:41,533][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:26:41,533][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:26:41,846][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_133_loss_0.6664179563522339/model.pt
[2024-11-13 09:26:41,850][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:26:41,850][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 6 is 0.6664179563522339
[2024-11-13 09:26:41,851][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.8332341313362122
[2024-11-13 09:26:41,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:42,536][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.04335799068212509, acc: 1.0)
[2024-11-13 09:26:42,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:43,209][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.15485092997550964, acc: 0.9428571462631226)
[2024-11-13 09:26:43,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:43,892][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.024926282465457916, acc: 1.0)
[2024-11-13 09:26:43,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:44,576][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 0.13513469696044922, acc: 0.976190447807312)
[2024-11-13 09:26:44,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:45,255][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 0.12061507999897003, acc: 0.9666666388511658)
[2024-11-13 09:26:45,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:45,926][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.27019137144088745, acc: 0.95652174949646)
[2024-11-13 09:26:46,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:46,597][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.013722242787480354, acc: 1.0)
[2024-11-13 09:26:46,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:47,269][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 0.07069694995880127, acc: 1.0)
[2024-11-13 09:26:47,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:47,955][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 0.26545360684394836, acc: 0.9032257795333862)
[2024-11-13 09:26:48,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:48,628][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 0.4327230751514435, acc: 0.8648648858070374)
[2024-11-13 09:26:48,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:49,332][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 0.5378736853599548, acc: 0.7894737124443054)
[2024-11-13 09:26:49,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:50,018][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 0.8330497145652771, acc: 0.7761194109916687)
[2024-11-13 09:26:50,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:50,709][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 0.4618873596191406, acc: 0.8775510191917419)
[2024-11-13 09:26:50,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:51,410][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 0.8364298939704895, acc: 0.7446808218955994)
[2024-11-13 09:26:51,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:52,093][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 0.5089713931083679, acc: 0.8428571224212646)
[2024-11-13 09:26:52,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:52,763][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 0.14839054644107819, acc: 0.8928571343421936)
[2024-11-13 09:26:52,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:53,433][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 1.0702435970306396, acc: 0.8695651888847351)
[2024-11-13 09:26:53,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:54,118][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.09266238659620285, acc: 0.9655172228813171)
[2024-11-13 09:26:54,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:54,795][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 0.1923423707485199, acc: 0.95652174949646)
[2024-11-13 09:26:54,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:55,478][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 0.4579582214355469, acc: 0.8474576473236084)
[2024-11-13 09:26:55,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:56,166][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 0.3777202069759369, acc: 0.9122806787490845)
[2024-11-13 09:26:56,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:56,862][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 0.23468028008937836, acc: 0.9594594836235046)
[2024-11-13 09:26:56,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:57,534][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.14708587527275085, acc: 0.9285714030265808)
[2024-11-13 09:26:57,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:58,217][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.004039471037685871, acc: 1.0)
[2024-11-13 09:26:58,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:58,890][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 0.1467936784029007, acc: 0.9473684430122375)
[2024-11-13 09:26:58,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:26:59,574][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 0.6212438344955444, acc: 0.8108108043670654)
[2024-11-13 09:26:59,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:00,254][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 0.4908622205257416, acc: 0.8333333134651184)
[2024-11-13 09:27:00,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:00,936][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 0.18394389748573303, acc: 0.9418604373931885)
[2024-11-13 09:27:01,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:01,620][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 0.24513359367847443, acc: 0.929411768913269)
[2024-11-13 09:27:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:02,302][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 0.6857284307479858, acc: 0.7977527976036072)
[2024-11-13 09:27:02,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:02,978][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.27777722477912903, acc: 0.8863636255264282)
[2024-11-13 09:27:03,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:03,651][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.42891934514045715, acc: 0.9047619104385376)
[2024-11-13 09:27:03,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:04,324][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 0.03710566833615303, acc: 1.0)
[2024-11-13 09:27:04,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:05,004][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.1556502729654312, acc: 0.9591836929321289)
[2024-11-13 09:27:05,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:05,679][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 0.06489460170269012, acc: 0.9800000190734863)
[2024-11-13 09:27:05,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:06,361][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 0.4817028045654297, acc: 0.875)
[2024-11-13 09:27:06,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:07,046][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 0.7923681735992432, acc: 0.7745097875595093)
[2024-11-13 09:27:07,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:07,768][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 1.1867300271987915, acc: 0.6301369667053223)
[2024-11-13 09:27:07,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:08,437][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.1352146416902542, acc: 0.9583333134651184)
[2024-11-13 09:27:08,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:09,107][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.14394886791706085, acc: 0.9629629850387573)
[2024-11-13 09:27:09,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:09,777][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.2821062207221985, acc: 0.9642857313156128)
[2024-11-13 09:27:09,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:10,483][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 0.5680809617042542, acc: 0.8407079577445984)
[2024-11-13 09:27:10,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:11,161][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 0.25125834345817566, acc: 0.9130434989929199)
[2024-11-13 09:27:11,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:11,854][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 0.3633187711238861, acc: 0.8863636255264282)
[2024-11-13 09:27:11,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:12,564][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 0.8967483043670654, acc: 0.7633587718009949)
[2024-11-13 09:27:12,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:13,277][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 0.6479573249816895, acc: 0.8222222328186035)
[2024-11-13 09:27:13,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:13,956][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 0.352003812789917, acc: 0.8524590134620667)
[2024-11-13 09:27:14,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:14,626][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.29464712738990784, acc: 0.9583333134651184)
[2024-11-13 09:27:14,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:15,298][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.2106570303440094, acc: 0.8799999952316284)
[2024-11-13 09:27:15,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:15,968][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.016870897263288498, acc: 1.0)
[2024-11-13 09:27:16,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:16,662][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 0.23327769339084625, acc: 0.9268292784690857)
[2024-11-13 09:27:16,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:17,390][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 0.5762513279914856, acc: 0.8338368535041809)
[2024-11-13 09:27:17,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:18,116][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 0.6712281107902527, acc: 0.8155619502067566)
[2024-11-13 09:27:18,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:18,838][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 0.6686920523643494, acc: 0.8031250238418579)
[2024-11-13 09:27:18,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:19,609][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 0.8716155290603638, acc: 0.7485928535461426)
[2024-11-13 09:27:19,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:20,346][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 0.6771718859672546, acc: 0.8149465918540955)
[2024-11-13 09:27:20,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:21,023][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.11955401301383972, acc: 0.9599999785423279)
[2024-11-13 09:27:21,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:21,706][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 0.5026823282241821, acc: 0.8255813717842102)
[2024-11-13 09:27:21,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:22,392][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 0.9167584776878357, acc: 0.7539682388305664)
[2024-11-13 09:27:22,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:23,088][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 0.7204407453536987, acc: 0.7575757503509521)
[2024-11-13 09:27:23,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:23,771][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 0.3580995500087738, acc: 0.8588235378265381)
[2024-11-13 09:27:23,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:24,476][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 0.686261773109436, acc: 0.790123462677002)
[2024-11-13 09:27:24,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:25,172][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 0.4484981894493103, acc: 0.8387096524238586)
[2024-11-13 09:27:25,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:25,857][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.08249979466199875, acc: 0.9642857313156128)
[2024-11-13 09:27:25,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:26,531][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.37874463200569153, acc: 0.875)
[2024-11-13 09:27:26,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:27,209][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 0.44106221199035645, acc: 0.8676470518112183)
[2024-11-13 09:27:27,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:27,902][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 0.5224626660346985, acc: 0.8308823704719543)
[2024-11-13 09:27:27,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:28,591][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 0.7351527810096741, acc: 0.7711864113807678)
[2024-11-13 09:27:28,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:29,279][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 0.48430389165878296, acc: 0.888059675693512)
[2024-11-13 09:27:29,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:29,966][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 0.5190529227256775, acc: 0.844660222530365)
[2024-11-13 09:27:30,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:30,653][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 0.4207476079463959, acc: 0.8571428656578064)
[2024-11-13 09:27:30,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:31,338][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 0.17019739747047424, acc: 0.9450549483299255)
[2024-11-13 09:27:31,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:32,058][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 0.3444083631038666, acc: 0.8968609571456909)
[2024-11-13 09:27:32,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:32,784][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 0.5106778740882874, acc: 0.8425197005271912)
[2024-11-13 09:27:32,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:33,494][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 0.2712916433811188, acc: 0.9051724076271057)
[2024-11-13 09:27:33,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:34,207][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 0.421944260597229, acc: 0.8768116235733032)
[2024-11-13 09:27:34,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:34,923][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 0.3625096380710602, acc: 0.8793774247169495)
[2024-11-13 09:27:35,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:35,640][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 0.26087307929992676, acc: 0.9130434989929199)
[2024-11-13 09:27:35,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:36,312][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.016101723536849022, acc: 1.0)
[2024-11-13 09:27:36,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:36,984][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.018360991030931473, acc: 1.0)
[2024-11-13 09:27:37,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:37,665][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.011686797253787518, acc: 1.0)
[2024-11-13 09:27:37,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:38,372][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 0.20749954879283905, acc: 0.9230769276618958)
[2024-11-13 09:27:38,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:39,050][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 0.15533466637134552, acc: 0.9459459185600281)
[2024-11-13 09:27:39,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:39,730][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 0.09493625909090042, acc: 0.9767441749572754)
[2024-11-13 09:27:39,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:40,415][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 0.1481204777956009, acc: 0.954954981803894)
[2024-11-13 09:27:40,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:41,104][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 0.09360572695732117, acc: 0.9777777791023254)
[2024-11-13 09:27:41,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:41,779][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.02531474456191063, acc: 1.0)
[2024-11-13 09:27:41,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:42,458][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.22172445058822632, acc: 0.9259259104728699)
[2024-11-13 09:27:42,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:43,143][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.009534049779176712, acc: 1.0)
[2024-11-13 09:27:43,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:43,832][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 0.3786173462867737, acc: 0.9230769276618958)
[2024-11-13 09:27:43,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:44,550][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 0.5091124176979065, acc: 0.875)
[2024-11-13 09:27:44,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:45,261][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 0.4821738302707672, acc: 0.875)
[2024-11-13 09:27:45,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:45,970][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 0.42237764596939087, acc: 0.8404255509376526)
[2024-11-13 09:27:46,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:46,644][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.14340804517269135, acc: 0.9433962106704712)
[2024-11-13 09:27:46,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:47,323][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 0.09940488636493683, acc: 0.9666666388511658)
[2024-11-13 09:27:47,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:48,002][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.1348029226064682, acc: 0.9534883499145508)
[2024-11-13 09:27:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:48,677][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.05724841356277466, acc: 1.0)
[2024-11-13 09:27:48,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:49,366][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 1.0931828022003174, acc: 0.6842105388641357)
[2024-11-13 09:27:49,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:50,048][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 0.54954993724823, acc: 0.855555534362793)
[2024-11-13 09:27:50,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:50,761][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 0.7042617201805115, acc: 0.7777777910232544)
[2024-11-13 09:27:50,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:51,470][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 1.1799196004867554, acc: 0.6788991093635559)
[2024-11-13 09:27:51,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:52,186][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 0.8716092109680176, acc: 0.7461538314819336)
[2024-11-13 09:27:52,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:52,870][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.017830584198236465, acc: 1.0)
[2024-11-13 09:27:52,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:53,542][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.053001660853624344, acc: 0.9583333134651184)
[2024-11-13 09:27:53,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:54,214][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 0.21717463433742523, acc: 0.9090909361839294)
[2024-11-13 09:27:54,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:54,897][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.14170175790786743, acc: 0.9629629850387573)
[2024-11-13 09:27:54,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:55,585][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.12629321217536926, acc: 0.9714285731315613)
[2024-11-13 09:27:55,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:56,263][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.10867574065923691, acc: 0.9772727489471436)
[2024-11-13 09:27:56,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:56,941][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.08312255144119263, acc: 0.9772727489471436)
[2024-11-13 09:27:57,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:57,622][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 0.5814318060874939, acc: 0.8225806355476379)
[2024-11-13 09:27:57,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:58,299][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 0.2785326838493347, acc: 0.9090909361839294)
[2024-11-13 09:27:58,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:58,972][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.002288033487275243, acc: 1.0)
[2024-11-13 09:27:59,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:27:59,655][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.005475256126374006, acc: 1.0)
[2024-11-13 09:27:59,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:00,329][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.027534201741218567, acc: 1.0)
[2024-11-13 09:28:00,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:01,000][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.008292550221085548, acc: 1.0)
[2024-11-13 09:28:01,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:01,676][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.08705729991197586, acc: 0.9459459185600281)
[2024-11-13 09:28:01,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:02,349][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.024577081203460693, acc: 1.0)
[2024-11-13 09:28:02,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:03,024][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.005263508763164282, acc: 1.0)
[2024-11-13 09:28:03,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:03,713][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 0.18013601005077362, acc: 0.9558823704719543)
[2024-11-13 09:28:03,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:04,390][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.024137068539857864, acc: 1.0)
[2024-11-13 09:28:04,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:05,061][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.03453692048788071, acc: 1.0)
[2024-11-13 09:28:05,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:05,744][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.0035171001218259335, acc: 1.0)
[2024-11-13 09:28:05,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:06,431][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.039484914392232895, acc: 0.9677419066429138)
[2024-11-13 09:28:06,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:07,121][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.018030613660812378, acc: 1.0)
[2024-11-13 09:28:07,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:07,797][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 0.0481799840927124, acc: 0.9857142567634583)
[2024-11-13 09:28:07,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:08,478][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 0.02495568059384823, acc: 1.0)
[2024-11-13 09:28:08,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:09,186][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 0.24883811175823212, acc: 0.9339622855186462)
[2024-11-13 09:28:09,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:09,895][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 0.3533138930797577, acc: 0.8999999761581421)
[2024-11-13 09:28:10,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:10,583][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.019122306257486343, acc: 1.0)
[2024-11-13 09:28:10,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:11,260][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.1210181936621666, acc: 1.0)
[2024-11-13 09:28:11,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:11,947][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 0.596722424030304, acc: 0.8399999737739563)
[2024-11-13 09:28:12,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:12,634][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 0.2689409554004669, acc: 0.9375)
[2024-11-13 09:28:12,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:13,349][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 1.1445913314819336, acc: 0.6959999799728394)
[2024-11-13 09:28:13,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:14,040][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 0.8039116859436035, acc: 0.7415730357170105)
[2024-11-13 09:28:14,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:14,722][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 0.4338662922382355, acc: 0.8648648858070374)
[2024-11-13 09:28:14,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:15,404][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 0.2543593645095825, acc: 0.931034505367279)
[2024-11-13 09:28:15,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:16,082][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.005175730679184198, acc: 1.0)
[2024-11-13 09:28:16,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:16,755][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.03492505103349686, acc: 1.0)
[2024-11-13 09:28:16,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:17,431][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.05932294577360153, acc: 0.96875)
[2024-11-13 09:28:17,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:18,107][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.022780943661928177, acc: 1.0)
[2024-11-13 09:28:18,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:18,785][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 0.27548229694366455, acc: 0.9333333373069763)
[2024-11-13 09:28:18,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:19,457][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.035147473216056824, acc: 0.96875)
[2024-11-13 09:28:19,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:20,131][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.006098335608839989, acc: 1.0)
[2024-11-13 09:28:21,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:21,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:22,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:22,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:23,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:23,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:24,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:25,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:25,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:26,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:26,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:27,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:28,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:28,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:29,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:30,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:30,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:31,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:32,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:32,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:33,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:34,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:35,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:35,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:36,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:36,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:37,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:38,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:38,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:39,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:40,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:40,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:41,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:42,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:42,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:43,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:44,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:44,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:45,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:45,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:46,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:47,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:47,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:48,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:48,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:49,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:49,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:50,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:51,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:51,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:52,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:53,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:54,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:55,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:55,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:56,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:57,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:57,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:58,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:58,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:59,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:28:59,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:00,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:01,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:01,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:02,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:03,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:03,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:04,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:04,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:05,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:06,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:06,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:07,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:07,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:08,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:08,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:09,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:09,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:10,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:11,585][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1793, device='cuda:0') eval_epoch_loss=tensor(0.7790, device='cuda:0') eval_epoch_acc=tensor(0.8232, device='cuda:0')
[2024-11-13 09:29:11,587][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:29:11,587][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:29:11,977][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_276_loss_0.7790111899375916/model.pt
[2024-11-13 09:29:11,981][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:29:12,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:12,667][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 0.07156994193792343, acc: 0.9655172228813171)
[2024-11-13 09:29:12,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:13,336][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.014121358282864094, acc: 1.0)
[2024-11-13 09:29:13,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:14,011][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 0.14146141707897186, acc: 0.936170220375061)
[2024-11-13 09:29:14,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:14,690][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 0.1335114985704422, acc: 0.9583333134651184)
[2024-11-13 09:29:14,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:15,367][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.004979830700904131, acc: 1.0)
[2024-11-13 09:29:15,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:16,059][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 0.4042840898036957, acc: 0.8313252925872803)
[2024-11-13 09:29:16,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:16,745][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 0.5742045640945435, acc: 0.8425925970077515)
[2024-11-13 09:29:16,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:17,419][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.2121022343635559, acc: 0.9473684430122375)
[2024-11-13 09:29:17,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:18,091][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 0.18078473210334778, acc: 0.9117646813392639)
[2024-11-13 09:29:18,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:18,766][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.07975734025239944, acc: 0.9750000238418579)
[2024-11-13 09:29:18,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:19,456][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 0.2651151716709137, acc: 0.890625)
[2024-11-13 09:29:19,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:20,161][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 0.3638835549354553, acc: 0.8799999952316284)
[2024-11-13 09:29:20,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:20,842][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 0.2114388793706894, acc: 0.9120879173278809)
[2024-11-13 09:29:20,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:21,534][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 0.3295291066169739, acc: 0.9068322777748108)
[2024-11-13 09:29:21,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:22,248][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 0.47931721806526184, acc: 0.8659793734550476)
[2024-11-13 09:29:22,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:22,918][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.2841174900531769, acc: 0.9545454382896423)
[2024-11-13 09:29:22,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:23,592][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 0.17776909470558167, acc: 0.9285714030265808)
[2024-11-13 09:29:23,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:24,272][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 0.061052266508340836, acc: 0.982758641242981)
[2024-11-13 09:29:24,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:24,954][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.1823568493127823, acc: 0.9454545378684998)
[2024-11-13 09:29:25,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:25,674][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 0.6830528378486633, acc: 0.8298969268798828)
[2024-11-13 09:29:25,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:26,359][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 0.2680422365665436, acc: 0.9137930870056152)
[2024-11-13 09:29:26,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:27,032][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.1927507221698761, acc: 0.9629629850387573)
[2024-11-13 09:29:27,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:27,708][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.23098589479923248, acc: 0.9473684430122375)
[2024-11-13 09:29:27,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:28,388][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.09102366119623184, acc: 0.9642857313156128)
[2024-11-13 09:29:28,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:29,062][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.15513314306735992, acc: 0.90625)
[2024-11-13 09:29:29,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:29,744][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.14081653952598572, acc: 0.9622641801834106)
[2024-11-13 09:29:29,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:30,420][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.06056991592049599, acc: 0.9811320900917053)
[2024-11-13 09:29:30,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:31,090][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.021426262333989143, acc: 1.0)
[2024-11-13 09:29:31,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:31,762][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.017406132072210312, acc: 1.0)
[2024-11-13 09:29:31,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:32,445][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.19859735667705536, acc: 0.9344262480735779)
[2024-11-13 09:29:32,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:33,119][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.06625660508871078, acc: 0.9666666388511658)
[2024-11-13 09:29:33,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:33,790][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.009225203655660152, acc: 1.0)
[2024-11-13 09:29:33,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:34,484][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 0.35394802689552307, acc: 0.9130434989929199)
[2024-11-13 09:29:34,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:35,179][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 0.26876676082611084, acc: 0.9305555820465088)
[2024-11-13 09:29:35,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:35,865][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 0.18254372477531433, acc: 0.9518072009086609)
[2024-11-13 09:29:35,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:36,549][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 0.16001495718955994, acc: 0.9358974099159241)
[2024-11-13 09:29:36,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:37,257][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 0.21135088801383972, acc: 0.9387755393981934)
[2024-11-13 09:29:37,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:37,928][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.03547973930835724, acc: 1.0)
[2024-11-13 09:29:38,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:38,597][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.01078608725219965, acc: 1.0)
[2024-11-13 09:29:38,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:39,267][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.02026047371327877, acc: 1.0)
[2024-11-13 09:29:39,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:39,940][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 0.01421467773616314, acc: 1.0)
[2024-11-13 09:29:40,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:40,621][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 0.25273481011390686, acc: 0.9253731369972229)
[2024-11-13 09:29:40,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:41,308][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 0.2708776891231537, acc: 0.942307710647583)
[2024-11-13 09:29:41,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:41,994][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 0.05718193203210831, acc: 0.9777777791023254)
[2024-11-13 09:29:42,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:42,675][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 0.19254204630851746, acc: 0.9677419066429138)
[2024-11-13 09:29:42,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:43,352][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.12023364752531052, acc: 0.9599999785423279)
[2024-11-13 09:29:43,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:44,028][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 0.23271533846855164, acc: 0.9629629850387573)
[2024-11-13 09:29:44,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:44,702][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 0.19669608771800995, acc: 0.9714285731315613)
[2024-11-13 09:29:44,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:45,375][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.3999406695365906, acc: 0.8461538553237915)
[2024-11-13 09:29:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:46,054][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 0.27277106046676636, acc: 0.8780487775802612)
[2024-11-13 09:29:46,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:46,731][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.4152286946773529, acc: 0.8684210777282715)
[2024-11-13 09:29:46,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:47,402][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.045210134238004684, acc: 0.9473684430122375)
[2024-11-13 09:29:47,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:48,074][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.00703324843198061, acc: 1.0)
[2024-11-13 09:29:48,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:48,748][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.027125941589474678, acc: 1.0)
[2024-11-13 09:29:48,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:49,419][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.005209553055465221, acc: 1.0)
[2024-11-13 09:29:49,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:50,100][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.1655513495206833, acc: 0.9516128897666931)
[2024-11-13 09:29:50,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:50,780][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.14869239926338196, acc: 0.9298245906829834)
[2024-11-13 09:29:50,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:51,455][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 0.2528824806213379, acc: 0.96875)
[2024-11-13 09:29:51,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:52,132][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.02800680510699749, acc: 1.0)
[2024-11-13 09:29:52,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:52,806][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.2509322464466095, acc: 0.9473684430122375)
[2024-11-13 09:29:52,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:53,487][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 0.38041287660598755, acc: 0.8999999761581421)
[2024-11-13 09:29:53,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:54,174][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 0.8384630084037781, acc: 0.7471264600753784)
[2024-11-13 09:29:54,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:54,872][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 0.8548563718795776, acc: 0.7553191781044006)
[2024-11-13 09:29:54,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:55,556][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 0.6982676386833191, acc: 0.8072289228439331)
[2024-11-13 09:29:55,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:56,243][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.0017552693607285619, acc: 1.0)
[2024-11-13 09:29:56,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:56,919][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 0.04089818894863129, acc: 0.9743589758872986)
[2024-11-13 09:29:57,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:57,599][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 0.3902882933616638, acc: 0.9036144614219666)
[2024-11-13 09:29:57,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:58,279][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 0.09253071248531342, acc: 0.9622641801834106)
[2024-11-13 09:29:58,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:58,958][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 0.10772794485092163, acc: 0.9620253443717957)
[2024-11-13 09:29:59,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:29:59,645][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 0.13290782272815704, acc: 0.9803921580314636)
[2024-11-13 09:29:59,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:00,332][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 0.3374802768230438, acc: 0.8805969953536987)
[2024-11-13 09:30:00,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:01,003][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.07753345370292664, acc: 0.949999988079071)
[2024-11-13 09:30:01,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:01,675][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.2848294973373413, acc: 0.8799999952316284)
[2024-11-13 09:30:01,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:02,351][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 0.5005108118057251, acc: 0.8055555820465088)
[2024-11-13 09:30:02,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:03,025][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 0.310313880443573, acc: 0.8604651093482971)
[2024-11-13 09:30:03,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:03,700][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.19639363884925842, acc: 0.9487179517745972)
[2024-11-13 09:30:03,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:04,379][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 0.29827943444252014, acc: 0.8888888955116272)
[2024-11-13 09:30:04,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:05,052][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.038258183747529984, acc: 1.0)
[2024-11-13 09:30:05,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:05,725][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.13825345039367676, acc: 0.9615384340286255)
[2024-11-13 09:30:05,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:06,412][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 0.5804581046104431, acc: 0.8021978139877319)
[2024-11-13 09:30:06,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:07,120][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 0.582724392414093, acc: 0.8173912763595581)
[2024-11-13 09:30:07,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:07,801][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 0.41518616676330566, acc: 0.8586956262588501)
[2024-11-13 09:30:07,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:08,478][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 0.241012305021286, acc: 0.9387755393981934)
[2024-11-13 09:30:08,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:09,150][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.015617269091308117, acc: 1.0)
[2024-11-13 09:30:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:09,821][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.16296571493148804, acc: 0.9230769276618958)
[2024-11-13 09:30:09,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:10,494][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.4525432586669922, acc: 0.8536585569381714)
[2024-11-13 09:30:10,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:11,179][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 0.10781840234994888, acc: 0.9777777791023254)
[2024-11-13 09:30:11,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:11,861][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 0.12199311703443527, acc: 0.9605262875556946)
[2024-11-13 09:30:11,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:12,539][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 0.05628831312060356, acc: 1.0)
[2024-11-13 09:30:12,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:13,217][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.07079751789569855, acc: 0.939393937587738)
[2024-11-13 09:30:13,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:13,889][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.004511249717324972, acc: 1.0)
[2024-11-13 09:30:13,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:14,561][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.003838686505332589, acc: 1.0)
[2024-11-13 09:30:14,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:15,232][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.014395647682249546, acc: 1.0)
[2024-11-13 09:30:15,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:15,906][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.3001278340816498, acc: 0.9375)
[2024-11-13 09:30:15,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:16,618][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 0.6114702224731445, acc: 0.800000011920929)
[2024-11-13 09:30:16,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:17,328][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 0.34331074357032776, acc: 0.8962264060974121)
[2024-11-13 09:30:17,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:18,021][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 0.1839282214641571, acc: 0.9333333373069763)
[2024-11-13 09:30:18,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:18,699][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.1269526183605194, acc: 0.9464285969734192)
[2024-11-13 09:30:18,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:19,415][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.04361920431256294, acc: 1.0)
[2024-11-13 09:30:19,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:20,088][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.0016509357374161482, acc: 1.0)
[2024-11-13 09:30:20,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:20,759][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.011154145933687687, acc: 1.0)
[2024-11-13 09:30:20,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:21,437][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.07857886701822281, acc: 0.9791666865348816)
[2024-11-13 09:30:21,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:22,118][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 0.03497381880879402, acc: 0.9894737005233765)
[2024-11-13 09:30:22,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:22,834][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 0.33375900983810425, acc: 0.8742514848709106)
[2024-11-13 09:30:22,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:23,521][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 0.3315114974975586, acc: 0.9172932505607605)
[2024-11-13 09:30:23,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:24,253][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 0.6920157670974731, acc: 0.8288770318031311)
[2024-11-13 09:30:24,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:24,959][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 0.1066308543086052, acc: 0.9639639854431152)
[2024-11-13 09:30:25,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:25,630][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.07334049046039581, acc: 0.9642857313156128)
[2024-11-13 09:30:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:26,300][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.001252377056516707, acc: 1.0)
[2024-11-13 09:30:26,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:26,975][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.01943618804216385, acc: 1.0)
[2024-11-13 09:30:27,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:27,648][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.1955033242702484, acc: 0.9722222089767456)
[2024-11-13 09:30:27,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:28,323][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.02780795656144619, acc: 1.0)
[2024-11-13 09:30:28,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:28,995][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.0026527922600507736, acc: 1.0)
[2024-11-13 09:30:29,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:29,666][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.0038680986035615206, acc: 1.0)
[2024-11-13 09:30:29,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:30,336][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.27016377449035645, acc: 0.9523809552192688)
[2024-11-13 09:30:30,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:31,010][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 0.36146795749664307, acc: 0.8888888955116272)
[2024-11-13 09:30:31,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:31,692][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 0.5493641495704651, acc: 0.8058252334594727)
[2024-11-13 09:30:31,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:32,407][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 0.7543469667434692, acc: 0.7941176295280457)
[2024-11-13 09:30:32,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:33,097][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 0.5043287873268127, acc: 0.8533333539962769)
[2024-11-13 09:30:33,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:33,787][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 0.5764272212982178, acc: 0.8541666865348816)
[2024-11-13 09:30:33,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:34,463][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.041341572999954224, acc: 0.9767441749572754)
[2024-11-13 09:30:34,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:35,140][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.07133191078901291, acc: 0.9583333134651184)
[2024-11-13 09:30:35,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:35,816][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.15369608998298645, acc: 0.930232584476471)
[2024-11-13 09:30:35,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:36,488][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.08083090931177139, acc: 0.9599999785423279)
[2024-11-13 09:30:36,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:37,174][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 0.27291885018348694, acc: 0.9117646813392639)
[2024-11-13 09:30:37,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:37,855][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 0.3482479453086853, acc: 0.8933333158493042)
[2024-11-13 09:30:37,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:38,542][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.03354102373123169, acc: 1.0)
[2024-11-13 09:30:38,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:39,230][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.20177967846393585, acc: 0.9696969985961914)
[2024-11-13 09:30:39,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:39,904][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.0023544069845229387, acc: 1.0)
[2024-11-13 09:30:39,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:40,576][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.002518957946449518, acc: 1.0)
[2024-11-13 09:30:40,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:41,244][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.0029426151886582375, acc: 1.0)
[2024-11-13 09:30:41,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:41,919][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.00423926766961813, acc: 1.0)
[2024-11-13 09:30:42,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:42,602][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.01188439130783081, acc: 1.0)
[2024-11-13 09:30:42,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:43,277][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.004800688941031694, acc: 1.0)
[2024-11-13 09:30:43,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:43,951][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.01103902980685234, acc: 1.0)
[2024-11-13 09:30:44,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:44,631][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.03396172448992729, acc: 1.0)
[2024-11-13 09:30:44,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:45,306][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.22476717829704285, acc: 0.9666666388511658)
[2024-11-13 09:30:45,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:45,987][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.27554455399513245, acc: 0.939393937587738)
[2024-11-13 09:30:46,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:46,659][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.07926955819129944, acc: 1.0)
[2024-11-13 09:30:46,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:47,341][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 0.1974961757659912, acc: 0.9411764740943909)
[2024-11-13 09:30:47,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:48,015][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 0.027146078646183014, acc: 1.0)
[2024-11-13 09:30:48,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:48,685][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.028518071398139, acc: 1.0)
[2024-11-13 09:30:48,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:49,370][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.20849530398845673, acc: 0.925000011920929)
[2024-11-13 09:30:50,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:50,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:51,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:52,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:52,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:53,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:53,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:54,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:54,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:55,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:56,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:56,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:57,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:57,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:58,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:59,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:30:59,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:00,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:00,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:01,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:02,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:02,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:03,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:03,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:04,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:04,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:05,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:06,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:06,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:07,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:07,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:08,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:08,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:09,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:10,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:10,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:11,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:11,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:12,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:13,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:13,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:14,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:14,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:15,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:15,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:16,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:17,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:17,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:18,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:18,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:19,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:20,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:20,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:21,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:21,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:22,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:23,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:24,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:24,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:25,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:25,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:26,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:27,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:27,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:28,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:28,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:29,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:30,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:30,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:31,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:31,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:32,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:32,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:33,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:34,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:34,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:35,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:35,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:36,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:36,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:37,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:38,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:38,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:40,348][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1497, device='cuda:0') eval_epoch_loss=tensor(0.7653, device='cuda:0') eval_epoch_acc=tensor(0.8182, device='cuda:0')
[2024-11-13 09:31:40,350][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:31:40,350][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:31:40,863][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_419_loss_0.765311062335968/model.pt
[2024-11-13 09:31:40,866][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:31:40,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:41,563][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.012090833857655525, acc: 1.0)
[2024-11-13 09:31:41,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:42,234][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.005366047378629446, acc: 1.0)
[2024-11-13 09:31:42,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:42,922][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.16711537539958954, acc: 0.9333333373069763)
[2024-11-13 09:31:43,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:43,595][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.25347885489463806, acc: 0.96875)
[2024-11-13 09:31:43,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:44,273][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.07930855453014374, acc: 0.9722222089767456)
[2024-11-13 09:31:44,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:44,946][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.019048642367124557, acc: 1.0)
[2024-11-13 09:31:45,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:45,618][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.028186623007059097, acc: 1.0)
[2024-11-13 09:31:45,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:46,288][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.006540485192090273, acc: 1.0)
[2024-11-13 09:31:46,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:46,963][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.024093858897686005, acc: 1.0)
[2024-11-13 09:31:47,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:47,638][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.016008973121643066, acc: 1.0)
[2024-11-13 09:31:47,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:48,310][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.04771346598863602, acc: 0.95652174949646)
[2024-11-13 09:31:48,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:48,985][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.15945813059806824, acc: 0.9629629850387573)
[2024-11-13 09:31:49,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:49,658][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.011216729879379272, acc: 1.0)
[2024-11-13 09:31:49,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:50,328][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.003490578616037965, acc: 1.0)
[2024-11-13 09:31:50,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:51,002][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.058389827609062195, acc: 1.0)
[2024-11-13 09:31:51,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:51,687][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.06040596961975098, acc: 0.9599999785423279)
[2024-11-13 09:31:51,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:52,361][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.17480623722076416, acc: 0.939393937587738)
[2024-11-13 09:31:52,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:53,033][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 0.03339094668626785, acc: 1.0)
[2024-11-13 09:31:53,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:53,711][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.020396731793880463, acc: 1.0)
[2024-11-13 09:31:53,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:54,378][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.03555738553404808, acc: 1.0)
[2024-11-13 09:31:54,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:55,053][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 0.1414988487958908, acc: 0.9743589758872986)
[2024-11-13 09:31:55,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:55,744][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 0.5337731838226318, acc: 0.8939393758773804)
[2024-11-13 09:31:55,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:56,458][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 0.7375919222831726, acc: 0.7680000066757202)
[2024-11-13 09:31:56,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:57,158][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 0.7322928309440613, acc: 0.8145161271095276)
[2024-11-13 09:31:57,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:57,868][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 0.6413364410400391, acc: 0.8208954930305481)
[2024-11-13 09:31:57,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:58,548][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 0.21948884427547455, acc: 0.9433962106704712)
[2024-11-13 09:31:58,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:59,228][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.02185867540538311, acc: 1.0)
[2024-11-13 09:31:59,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:31:59,902][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.007384778931736946, acc: 1.0)
[2024-11-13 09:31:59,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:00,572][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.012350890785455704, acc: 1.0)
[2024-11-13 09:32:00,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:01,241][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.040065158158540726, acc: 1.0)
[2024-11-13 09:32:01,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:01,918][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 0.07833248376846313, acc: 0.9552238583564758)
[2024-11-13 09:32:01,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:02,599][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 0.08094117045402527, acc: 0.9722222089767456)
[2024-11-13 09:32:02,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:03,281][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 0.1561238318681717, acc: 0.9347826242446899)
[2024-11-13 09:32:03,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:03,963][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 0.1310899704694748, acc: 0.9487179517745972)
[2024-11-13 09:32:04,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:04,646][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 0.14377012848854065, acc: 0.9736841917037964)
[2024-11-13 09:32:04,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:05,328][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 0.043971430510282516, acc: 1.0)
[2024-11-13 09:32:05,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:06,000][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.08342210203409195, acc: 0.9696969985961914)
[2024-11-13 09:32:06,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:06,683][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 0.39384976029396057, acc: 0.8969072103500366)
[2024-11-13 09:32:06,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:07,361][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 0.1360669881105423, acc: 0.9571428298950195)
[2024-11-13 09:32:07,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:08,085][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 0.5191525220870972, acc: 0.8430232405662537)
[2024-11-13 09:32:08,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:08,761][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 0.16790036857128143, acc: 0.9464285969734192)
[2024-11-13 09:32:08,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:09,448][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 0.27606526017189026, acc: 0.9012345671653748)
[2024-11-13 09:32:09,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:10,122][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.17099617421627045, acc: 0.9722222089767456)
[2024-11-13 09:32:10,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:10,795][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.015951236709952354, acc: 1.0)
[2024-11-13 09:32:10,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:11,468][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.09829188883304596, acc: 0.9230769276618958)
[2024-11-13 09:32:11,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:12,153][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.03338072448968887, acc: 1.0)
[2024-11-13 09:32:12,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:12,840][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 0.15917986631393433, acc: 0.9642857313156128)
[2024-11-13 09:32:12,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:13,530][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 0.15661931037902832, acc: 0.9638554453849792)
[2024-11-13 09:32:13,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:14,238][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 0.21533262729644775, acc: 0.9189189076423645)
[2024-11-13 09:32:14,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:14,921][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 0.4141280949115753, acc: 0.893203854560852)
[2024-11-13 09:32:15,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:15,629][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 0.4055792987346649, acc: 0.8861788511276245)
[2024-11-13 09:32:15,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:16,301][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.019383223727345467, acc: 1.0)
[2024-11-13 09:32:16,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:16,972][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.07108522951602936, acc: 0.9642857313156128)
[2024-11-13 09:32:17,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:17,686][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 0.5750722289085388, acc: 0.8333333134651184)
[2024-11-13 09:32:17,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:18,396][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 0.8134426474571228, acc: 0.7379912734031677)
[2024-11-13 09:32:18,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:19,077][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 0.23379091918468475, acc: 0.8958333134651184)
[2024-11-13 09:32:19,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:19,766][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 0.3545537292957306, acc: 0.8773006200790405)
[2024-11-13 09:32:19,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:20,461][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 0.21013736724853516, acc: 0.9424460530281067)
[2024-11-13 09:32:20,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:21,166][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 0.666692316532135, acc: 0.8090452551841736)
[2024-11-13 09:32:21,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:21,842][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.12688356637954712, acc: 0.9444444179534912)
[2024-11-13 09:32:21,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:22,512][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.04178681969642639, acc: 1.0)
[2024-11-13 09:32:22,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:23,195][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.009819171391427517, acc: 1.0)
[2024-11-13 09:32:23,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:23,868][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.39815306663513184, acc: 0.949999988079071)
[2024-11-13 09:32:23,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:24,547][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.008327221497893333, acc: 1.0)
[2024-11-13 09:32:24,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:25,233][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 0.30412557721138, acc: 0.8965517282485962)
[2024-11-13 09:32:25,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:25,915][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.013092485256493092, acc: 1.0)
[2024-11-13 09:32:26,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:26,589][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.01626105234026909, acc: 1.0)
[2024-11-13 09:32:26,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:27,273][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 0.0476391464471817, acc: 0.9629629850387573)
[2024-11-13 09:32:27,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:27,945][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.05970204994082451, acc: 1.0)
[2024-11-13 09:32:28,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:28,617][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 0.0064733815379440784, acc: 1.0)
[2024-11-13 09:32:28,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:29,305][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 0.32077476382255554, acc: 0.9384615421295166)
[2024-11-13 09:32:29,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:29,980][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.05761364474892616, acc: 0.9666666388511658)
[2024-11-13 09:32:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:30,652][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 0.03959397226572037, acc: 0.9655172228813171)
[2024-11-13 09:32:30,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:31,334][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 0.17395645380020142, acc: 0.9215686321258545)
[2024-11-13 09:32:31,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:32,008][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 0.02120000496506691, acc: 1.0)
[2024-11-13 09:32:32,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:32,680][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.014552599750459194, acc: 1.0)
[2024-11-13 09:32:32,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:33,365][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.15902593731880188, acc: 0.8947368264198303)
[2024-11-13 09:32:33,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:34,054][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 0.3736083507537842, acc: 0.8839285969734192)
[2024-11-13 09:32:34,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:34,739][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 0.21258984506130219, acc: 0.898876428604126)
[2024-11-13 09:32:34,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:35,425][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 0.47666966915130615, acc: 0.8314606547355652)
[2024-11-13 09:32:35,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:36,125][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 0.8367473483085632, acc: 0.73758864402771)
[2024-11-13 09:32:36,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:36,814][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 0.3685828447341919, acc: 0.8804348111152649)
[2024-11-13 09:32:36,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:37,485][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.002542957430705428, acc: 1.0)
[2024-11-13 09:32:37,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:38,155][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.008972013369202614, acc: 1.0)
[2024-11-13 09:32:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:38,826][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.0023596985265612602, acc: 1.0)
[2024-11-13 09:32:38,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:39,498][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.07249817252159119, acc: 0.9259259104728699)
[2024-11-13 09:32:39,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:40,172][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.26147693395614624, acc: 0.9433962106704712)
[2024-11-13 09:32:40,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:40,845][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.004511857870966196, acc: 1.0)
[2024-11-13 09:32:40,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:41,541][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 0.482699990272522, acc: 0.8738738894462585)
[2024-11-13 09:32:41,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:42,229][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 0.15725335478782654, acc: 0.9436619877815247)
[2024-11-13 09:32:42,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:42,898][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.0007398569141514599, acc: 1.0)
[2024-11-13 09:32:42,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:43,583][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.0824069082736969, acc: 0.9666666388511658)
[2024-11-13 09:32:43,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:44,258][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.04867939278483391, acc: 0.9615384340286255)
[2024-11-13 09:32:44,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:45,108][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 1.5600868463516235, acc: 0.6214285492897034)
[2024-11-13 09:32:45,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:45,818][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 0.3246172368526459, acc: 0.9285714030265808)
[2024-11-13 09:32:45,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:46,488][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.00894854124635458, acc: 1.0)
[2024-11-13 09:32:46,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:47,165][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 0.14620321989059448, acc: 0.9666666388511658)
[2024-11-13 09:32:47,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:47,856][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 0.39316290616989136, acc: 0.9027777910232544)
[2024-11-13 09:32:47,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:48,528][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.02422085590660572, acc: 1.0)
[2024-11-13 09:32:48,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:49,201][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.056269075721502304, acc: 1.0)
[2024-11-13 09:32:49,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:49,864][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.26305311918258667, acc: 0.949999988079071)
[2024-11-13 09:32:49,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:50,538][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.09157810360193253, acc: 0.9629629850387573)
[2024-11-13 09:32:50,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:51,306][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 1.1900829076766968, acc: 0.6779661178588867)
[2024-11-13 09:32:51,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:52,007][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 0.2638854384422302, acc: 0.9253731369972229)
[2024-11-13 09:32:52,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:52,694][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 0.25789326429367065, acc: 0.9124087691307068)
[2024-11-13 09:32:52,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:53,416][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 0.5417988300323486, acc: 0.8700000047683716)
[2024-11-13 09:32:53,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:54,103][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 0.027582557871937752, acc: 1.0)
[2024-11-13 09:32:54,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:54,782][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 0.04531438648700714, acc: 1.0)
[2024-11-13 09:32:54,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:55,454][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.1988351047039032, acc: 0.9523809552192688)
[2024-11-13 09:32:55,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:56,138][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 0.479342520236969, acc: 0.8360655903816223)
[2024-11-13 09:32:56,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:56,814][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 0.09414524585008621, acc: 1.0)
[2024-11-13 09:32:56,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:57,491][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 0.11525706201791763, acc: 0.9767441749572754)
[2024-11-13 09:32:57,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:58,165][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 0.1698785275220871, acc: 0.9318181872367859)
[2024-11-13 09:32:58,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:58,845][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 0.3292161524295807, acc: 0.9245283007621765)
[2024-11-13 09:32:58,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:32:59,529][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.0823797658085823, acc: 0.9772727489471436)
[2024-11-13 09:32:59,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:00,213][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.015512757003307343, acc: 1.0)
[2024-11-13 09:33:00,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:00,890][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.014629204757511616, acc: 1.0)
[2024-11-13 09:33:00,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:01,561][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.05087900534272194, acc: 1.0)
[2024-11-13 09:33:01,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:02,241][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 0.05103311687707901, acc: 1.0)
[2024-11-13 09:33:02,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:02,938][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 0.1595449298620224, acc: 0.9375)
[2024-11-13 09:33:03,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:03,624][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.07699599117040634, acc: 0.96875)
[2024-11-13 09:33:03,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:04,305][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.015090709552168846, acc: 1.0)
[2024-11-13 09:33:04,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:04,976][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.01197857316583395, acc: 1.0)
[2024-11-13 09:33:05,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:05,649][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.03167913854122162, acc: 0.9677419066429138)
[2024-11-13 09:33:05,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:06,320][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.002022855682298541, acc: 1.0)
[2024-11-13 09:33:06,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:06,990][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.042630329728126526, acc: 0.9666666388511658)
[2024-11-13 09:33:07,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:07,664][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 0.0844515860080719, acc: 0.9512194991111755)
[2024-11-13 09:33:07,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:08,339][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.04709735885262489, acc: 0.9714285731315613)
[2024-11-13 09:33:08,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:09,015][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.019009731709957123, acc: 1.0)
[2024-11-13 09:33:09,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:09,689][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.009120078757405281, acc: 1.0)
[2024-11-13 09:33:09,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:10,360][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.00515937153249979, acc: 1.0)
[2024-11-13 09:33:10,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:11,039][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.09415451437234879, acc: 0.9696969985961914)
[2024-11-13 09:33:11,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:11,714][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.011564348824322224, acc: 1.0)
[2024-11-13 09:33:11,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:12,393][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.09527982771396637, acc: 0.9285714030265808)
[2024-11-13 09:33:12,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:13,095][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 0.28825533390045166, acc: 0.9197080135345459)
[2024-11-13 09:33:13,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:13,794][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 0.15231962502002716, acc: 0.9586206674575806)
[2024-11-13 09:33:13,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:14,484][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 0.2336694449186325, acc: 0.9214285612106323)
[2024-11-13 09:33:14,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:15,179][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 0.20119191706180573, acc: 0.9271523356437683)
[2024-11-13 09:33:15,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:15,864][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 0.07249157130718231, acc: 0.9743589758872986)
[2024-11-13 09:33:15,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:16,534][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.04630802944302559, acc: 1.0)
[2024-11-13 09:33:16,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:17,205][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.00858556292951107, acc: 1.0)
[2024-11-13 09:33:17,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:17,877][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.0040902793407440186, acc: 1.0)
[2024-11-13 09:33:17,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:18,563][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.09489433467388153, acc: 0.9487179517745972)
[2024-11-13 09:33:19,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:20,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:20,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:21,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:21,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:22,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:23,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:23,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:24,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:24,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:25,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:25,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:26,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:27,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:27,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:28,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:29,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:29,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:30,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:31,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:31,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:32,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:32,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:33,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:34,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:34,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:35,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:35,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:36,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:37,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:37,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:38,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:39,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:40,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:40,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:41,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:41,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:42,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:43,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:43,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:44,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:44,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:45,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:46,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:46,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:47,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:47,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:48,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:48,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:49,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:50,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:50,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:51,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:51,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:52,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:53,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:53,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:54,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:54,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:55,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:56,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:56,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:57,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:57,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:58,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:58,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:33:59,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:00,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:00,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:01,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:01,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:02,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:03,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:03,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:04,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:04,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:05,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:05,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:06,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:07,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:07,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:09,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:09,983][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1888, device='cuda:0') eval_epoch_loss=tensor(0.7833, device='cuda:0') eval_epoch_acc=tensor(0.8188, device='cuda:0')
[2024-11-13 09:34:09,986][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:34:09,986][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:34:10,602][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_562_loss_0.7833470106124878/model.pt
[2024-11-13 09:34:10,608][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:34:10,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:11,337][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 0.21400666236877441, acc: 0.9222221970558167)
[2024-11-13 09:34:11,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:12,016][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.10559184849262238, acc: 0.9740259647369385)
[2024-11-13 09:34:12,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:12,689][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.04349079728126526, acc: 0.9791666865348816)
[2024-11-13 09:34:12,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:13,363][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.1812230795621872, acc: 0.9655172228813171)
[2024-11-13 09:34:13,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:14,046][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 0.12376628816127777, acc: 0.976190447807312)
[2024-11-13 09:34:14,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:14,724][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.04166318103671074, acc: 0.9736841917037964)
[2024-11-13 09:34:14,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:15,395][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.01729465462267399, acc: 1.0)
[2024-11-13 09:34:15,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:16,124][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 0.26488015055656433, acc: 0.9251337051391602)
[2024-11-13 09:34:16,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:16,801][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.0206722691655159, acc: 0.9838709831237793)
[2024-11-13 09:34:16,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:17,485][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 0.2017335295677185, acc: 0.94017094373703)
[2024-11-13 09:34:17,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:18,189][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 0.5349845290184021, acc: 0.8571428656578064)
[2024-11-13 09:34:18,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:18,898][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 0.23544572293758392, acc: 0.9182389974594116)
[2024-11-13 09:34:19,323][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=1.2824, train_epoch_loss=0.2487, epoch time 602.5994154438376s
[2024-11-13 09:34:19,323][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 09:34:19,323][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 09:34:19,323][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 09:34:19,323][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-11-13 09:34:19,323][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 09:34:20,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:20,735][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.08442085236310959, acc: 0.9629629850387573)
[2024-11-13 09:34:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:21,420][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.007311567664146423, acc: 1.0)
[2024-11-13 09:34:21,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:22,119][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 0.0276970062404871, acc: 1.0)
[2024-11-13 09:34:22,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:22,810][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 0.04624028503894806, acc: 1.0)
[2024-11-13 09:34:22,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:23,494][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.09611762315034866, acc: 0.9729729890823364)
[2024-11-13 09:34:23,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:24,178][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.09789402782917023, acc: 0.9642857313156128)
[2024-11-13 09:34:24,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:24,866][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 0.35321125388145447, acc: 0.918367326259613)
[2024-11-13 09:34:24,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:25,564][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.05382683500647545, acc: 1.0)
[2024-11-13 09:34:25,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:26,251][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.016366668045520782, acc: 1.0)
[2024-11-13 09:34:26,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:26,943][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.007913799956440926, acc: 1.0)
[2024-11-13 09:34:27,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:27,642][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.008596131578087807, acc: 1.0)
[2024-11-13 09:34:27,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:28,353][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.06913328915834427, acc: 0.9743589758872986)
[2024-11-13 09:34:28,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:29,040][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.02177174761891365, acc: 1.0)
[2024-11-13 09:34:29,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:29,737][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.10997714847326279, acc: 0.95652174949646)
[2024-11-13 09:34:29,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:30,424][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 0.015685955062508583, acc: 1.0)
[2024-11-13 09:34:30,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:31,118][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.25118401646614075, acc: 0.918367326259613)
[2024-11-13 09:34:31,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:31,800][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.03487076237797737, acc: 1.0)
[2024-11-13 09:34:31,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:32,483][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.014859259128570557, acc: 1.0)
[2024-11-13 09:34:32,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:33,168][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 0.2524038553237915, acc: 0.9444444179534912)
[2024-11-13 09:34:33,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:33,853][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.024164503440260887, acc: 1.0)
[2024-11-13 09:34:33,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:34,538][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.006715205032378435, acc: 1.0)
[2024-11-13 09:34:34,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:35,225][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.21230508387088776, acc: 0.9655172228813171)
[2024-11-13 09:34:35,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:35,919][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.1229517012834549, acc: 0.9599999785423279)
[2024-11-13 09:34:36,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:36,603][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.07646197080612183, acc: 0.9523809552192688)
[2024-11-13 09:34:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:37,298][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.018685434013605118, acc: 1.0)
[2024-11-13 09:34:37,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:37,995][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 0.4564340114593506, acc: 0.8301886916160583)
[2024-11-13 09:34:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:38,694][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 0.20863975584506989, acc: 0.9589040875434875)
[2024-11-13 09:34:38,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:39,500][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 1.1804507970809937, acc: 0.6482213735580444)
[2024-11-13 09:34:39,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:40,189][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.18467944860458374, acc: 0.9534883499145508)
[2024-11-13 09:34:40,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:40,886][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 0.2223634570837021, acc: 0.9156626462936401)
[2024-11-13 09:34:40,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:41,590][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 0.3059537410736084, acc: 0.9012345671653748)
[2024-11-13 09:34:41,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:42,286][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.050762224942445755, acc: 1.0)
[2024-11-13 09:34:42,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:42,978][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.1917891800403595, acc: 0.9259259104728699)
[2024-11-13 09:34:43,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:43,667][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.027040692046284676, acc: 1.0)
[2024-11-13 09:34:43,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:44,368][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 0.39502009749412537, acc: 0.8403361439704895)
[2024-11-13 09:34:44,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:45,070][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.24741369485855103, acc: 0.9180327653884888)
[2024-11-13 09:34:45,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:45,773][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 0.30106502771377563, acc: 0.920634925365448)
[2024-11-13 09:34:45,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:46,469][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 0.1713438332080841, acc: 0.9152542352676392)
[2024-11-13 09:34:46,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:47,172][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 0.26708176732063293, acc: 0.931034505367279)
[2024-11-13 09:34:47,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:47,858][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.009698580019176006, acc: 1.0)
[2024-11-13 09:34:47,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:48,554][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.40688446164131165, acc: 0.9230769276618958)
[2024-11-13 09:34:48,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:49,251][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 0.08396366983652115, acc: 0.9864864945411682)
[2024-11-13 09:34:49,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:49,941][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 0.14871004223823547, acc: 0.9538461565971375)
[2024-11-13 09:34:50,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:50,636][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 0.2743035852909088, acc: 0.8989899158477783)
[2024-11-13 09:34:50,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:51,334][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 0.2664221227169037, acc: 0.9484536051750183)
[2024-11-13 09:34:51,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:52,033][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 0.18962454795837402, acc: 0.9338235259056091)
[2024-11-13 09:34:52,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:52,723][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.011078410781919956, acc: 1.0)
[2024-11-13 09:34:52,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:53,418][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.05360252410173416, acc: 0.9629629850387573)
[2024-11-13 09:34:53,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:54,116][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.02954859659075737, acc: 1.0)
[2024-11-13 09:34:54,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:54,804][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.11433234810829163, acc: 0.9444444179534912)
[2024-11-13 09:34:54,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:55,493][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.1812983751296997, acc: 0.9122806787490845)
[2024-11-13 09:34:55,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:56,188][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.2548317313194275, acc: 0.9523809552192688)
[2024-11-13 09:34:56,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:56,884][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 0.37319546937942505, acc: 0.8732394576072693)
[2024-11-13 09:34:56,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:57,604][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 0.9842504858970642, acc: 0.753333330154419)
[2024-11-13 09:34:57,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:58,286][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.20222744345664978, acc: 0.9459459185600281)
[2024-11-13 09:34:58,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:58,977][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.02120756357908249, acc: 1.0)
[2024-11-13 09:34:59,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:34:59,822][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 1.4194133281707764, acc: 0.6348122954368591)
[2024-11-13 09:34:59,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:00,606][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 1.480802059173584, acc: 0.5904139280319214)
[2024-11-13 09:35:00,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:01,329][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 0.5119332671165466, acc: 0.8806818127632141)
[2024-11-13 09:35:01,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:02,032][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 0.26124659180641174, acc: 0.9117646813392639)
[2024-11-13 09:35:02,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:02,760][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 0.5222052335739136, acc: 0.8478260636329651)
[2024-11-13 09:35:02,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:03,478][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 0.4172070622444153, acc: 0.887499988079071)
[2024-11-13 09:35:03,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:04,163][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.0601266548037529, acc: 1.0)
[2024-11-13 09:35:04,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:04,850][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 0.13714487850666046, acc: 0.9722222089767456)
[2024-11-13 09:35:04,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:05,553][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.1703600138425827, acc: 0.96875)
[2024-11-13 09:35:05,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:06,250][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.04182871803641319, acc: 1.0)
[2024-11-13 09:35:06,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:06,937][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 0.11445554345846176, acc: 0.9642857313156128)
[2024-11-13 09:35:07,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:07,626][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 0.1770865023136139, acc: 0.9333333373069763)
[2024-11-13 09:35:07,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:08,307][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.11893139779567719, acc: 0.9200000166893005)
[2024-11-13 09:35:08,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:08,992][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.13105863332748413, acc: 0.9722222089767456)
[2024-11-13 09:35:09,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:09,680][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.06895706057548523, acc: 0.9696969985961914)
[2024-11-13 09:35:09,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:10,403][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 0.5733022093772888, acc: 0.8529411554336548)
[2024-11-13 09:35:10,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:11,103][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 0.41747573018074036, acc: 0.89682537317276)
[2024-11-13 09:35:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:11,842][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 0.9840367436408997, acc: 0.7025641202926636)
[2024-11-13 09:35:11,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:12,544][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 0.49546170234680176, acc: 0.8571428656578064)
[2024-11-13 09:35:12,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:13,245][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 0.7412428855895996, acc: 0.8134328126907349)
[2024-11-13 09:35:13,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:13,986][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 1.2303212881088257, acc: 0.6496350169181824)
[2024-11-13 09:35:14,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:14,670][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.1006544753909111, acc: 0.9523809552192688)
[2024-11-13 09:35:14,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:15,354][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.04990064725279808, acc: 0.9583333134651184)
[2024-11-13 09:35:15,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:16,039][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.043857213109731674, acc: 1.0)
[2024-11-13 09:35:16,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:16,722][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.004330472555011511, acc: 1.0)
[2024-11-13 09:35:16,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:17,423][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.20155523717403412, acc: 0.9230769276618958)
[2024-11-13 09:35:17,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:18,115][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 0.22546924650669098, acc: 0.9230769276618958)
[2024-11-13 09:35:18,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:18,807][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.0551893375813961, acc: 0.96875)
[2024-11-13 09:35:18,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:19,500][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 0.1260291039943695, acc: 0.9710144996643066)
[2024-11-13 09:35:19,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:20,191][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.06858908385038376, acc: 1.0)
[2024-11-13 09:35:20,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:20,876][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.022337080910801888, acc: 1.0)
[2024-11-13 09:35:20,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:21,570][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 0.10473983734846115, acc: 0.9599999785423279)
[2024-11-13 09:35:21,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:22,266][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 0.3423115909099579, acc: 0.9126213788986206)
[2024-11-13 09:35:22,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:22,984][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 0.6586002707481384, acc: 0.8398058414459229)
[2024-11-13 09:35:23,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:23,715][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.0064438581466675, acc: 0.7096773982048035)
[2024-11-13 09:35:23,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:24,451][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 0.7172560095787048, acc: 0.7974137663841248)
[2024-11-13 09:35:24,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:25,150][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 0.42928627133369446, acc: 0.8736842274665833)
[2024-11-13 09:35:25,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:25,874][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 0.5270863771438599, acc: 0.8514851331710815)
[2024-11-13 09:35:25,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:26,563][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 0.18725243210792542, acc: 0.9354838728904724)
[2024-11-13 09:35:26,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:27,259][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 0.1381906419992447, acc: 0.9420289993286133)
[2024-11-13 09:35:27,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:27,967][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 0.5295101404190063, acc: 0.8403361439704895)
[2024-11-13 09:35:28,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:28,677][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 0.42538580298423767, acc: 0.8557692170143127)
[2024-11-13 09:35:28,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:29,377][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 0.5972468256950378, acc: 0.8102189898490906)
[2024-11-13 09:35:29,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:30,081][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 0.39377114176750183, acc: 0.8656716346740723)
[2024-11-13 09:35:30,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:30,767][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.01217074878513813, acc: 1.0)
[2024-11-13 09:35:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:31,449][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.016901230439543724, acc: 1.0)
[2024-11-13 09:35:31,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:32,133][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.04790287837386131, acc: 1.0)
[2024-11-13 09:35:32,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:32,820][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.017190618440508842, acc: 1.0)
[2024-11-13 09:35:32,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:33,521][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 0.08326350897550583, acc: 0.9482758641242981)
[2024-11-13 09:35:33,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:34,209][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.08214148879051208, acc: 0.9534883499145508)
[2024-11-13 09:35:34,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:34,895][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.014110174030065536, acc: 1.0)
[2024-11-13 09:35:34,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:35,575][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.006400495767593384, acc: 1.0)
[2024-11-13 09:35:35,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:36,259][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.001852658693678677, acc: 1.0)
[2024-11-13 09:35:36,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:36,946][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.09669401496648788, acc: 0.976190447807312)
[2024-11-13 09:35:37,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:37,643][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 0.05737537145614624, acc: 0.9846153855323792)
[2024-11-13 09:35:37,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:38,335][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 0.06837169826030731, acc: 1.0)
[2024-11-13 09:35:38,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:39,020][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.23478983342647552, acc: 0.9473684430122375)
[2024-11-13 09:35:39,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:39,714][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.04402758181095123, acc: 1.0)
[2024-11-13 09:35:39,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:40,412][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.06077324226498604, acc: 0.9795918464660645)
[2024-11-13 09:35:40,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:41,096][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.002841866808012128, acc: 1.0)
[2024-11-13 09:35:41,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:41,804][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 0.1748964786529541, acc: 0.9365079402923584)
[2024-11-13 09:35:41,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:42,497][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 0.12834404408931732, acc: 0.9512194991111755)
[2024-11-13 09:35:42,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:43,198][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.031462594866752625, acc: 1.0)
[2024-11-13 09:35:43,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:43,966][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 0.5299410820007324, acc: 0.8250950574874878)
[2024-11-13 09:35:44,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:44,660][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 0.06597142666578293, acc: 0.9733333587646484)
[2024-11-13 09:35:44,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:45,353][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.32067397236824036, acc: 0.8846153616905212)
[2024-11-13 09:35:45,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:46,034][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.010748696513473988, acc: 1.0)
[2024-11-13 09:35:46,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:46,727][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.005518327932804823, acc: 1.0)
[2024-11-13 09:35:46,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:47,437][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 0.5798550248146057, acc: 0.8282208442687988)
[2024-11-13 09:35:47,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:48,166][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 0.6812705993652344, acc: 0.8333333134651184)
[2024-11-13 09:35:48,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:48,872][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 0.5899066925048828, acc: 0.8416666388511658)
[2024-11-13 09:35:48,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:49,612][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 0.5553354620933533, acc: 0.8035714030265808)
[2024-11-13 09:35:49,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:50,334][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 0.5153453350067139, acc: 0.8410256505012512)
[2024-11-13 09:35:50,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:51,071][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 0.5905358791351318, acc: 0.8161764740943909)
[2024-11-13 09:35:51,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:51,757][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.10587633401155472, acc: 0.9615384340286255)
[2024-11-13 09:35:52,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:53,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:53,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:54,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:55,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:55,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:56,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:56,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:57,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:58,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:59,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:35:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:00,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:00,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:01,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:02,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:02,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:03,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:03,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:04,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:04,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:05,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:06,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:06,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:07,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:07,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:08,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:09,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:09,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:10,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:10,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:11,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:12,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:12,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:13,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:13,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:14,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:14,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:15,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:16,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:16,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:17,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:17,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:18,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:18,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:19,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:20,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:20,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:21,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:21,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:22,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:22,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:23,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:24,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:24,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:25,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:25,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:26,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:27,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:27,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:28,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:29,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:30,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:30,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:31,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:31,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:32,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:33,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:33,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:34,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:34,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:35,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:35,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:36,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:37,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:37,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:38,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:38,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:39,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:40,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:40,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:41,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:41,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:42,726][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.0842, device='cuda:0') eval_epoch_loss=tensor(0.7344, device='cuda:0') eval_epoch_acc=tensor(0.8257, device='cuda:0')
[2024-11-13 09:36:42,727][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:36:42,727][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:36:43,143][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_131_loss_0.7343969941139221/model.pt
[2024-11-13 09:36:43,147][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:36:43,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:43,830][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.008663870394229889, acc: 1.0)
[2024-11-13 09:36:43,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:44,500][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.020820528268814087, acc: 1.0)
[2024-11-13 09:36:44,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:45,170][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.05192826688289642, acc: 1.0)
[2024-11-13 09:36:45,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:45,843][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.10513477027416229, acc: 0.9714285731315613)
[2024-11-13 09:36:45,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:46,527][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.11235533654689789, acc: 0.9230769276618958)
[2024-11-13 09:36:46,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:47,205][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.08528243005275726, acc: 0.976190447807312)
[2024-11-13 09:36:47,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:47,877][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.08629222959280014, acc: 0.9666666388511658)
[2024-11-13 09:36:47,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:48,550][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.02893378771841526, acc: 1.0)
[2024-11-13 09:36:48,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:49,230][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.016583183780312538, acc: 1.0)
[2024-11-13 09:36:49,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:49,899][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.016023484990000725, acc: 1.0)
[2024-11-13 09:36:49,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:50,570][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.04868963360786438, acc: 1.0)
[2024-11-13 09:36:50,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:51,245][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.11774367094039917, acc: 0.9729729890823364)
[2024-11-13 09:36:51,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:51,951][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 0.37048912048339844, acc: 0.8771929740905762)
[2024-11-13 09:36:52,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:52,640][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 0.5225440859794617, acc: 0.888059675693512)
[2024-11-13 09:36:52,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:53,337][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 0.2536832392215729, acc: 0.9081632494926453)
[2024-11-13 09:36:53,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:54,039][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 0.5517644286155701, acc: 0.8510638475418091)
[2024-11-13 09:36:54,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:54,733][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 0.3501660227775574, acc: 0.8857142925262451)
[2024-11-13 09:36:54,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:55,404][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.1834455281496048, acc: 0.9285714030265808)
[2024-11-13 09:36:55,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:56,074][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.1550997942686081, acc: 0.95652174949646)
[2024-11-13 09:36:56,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:56,746][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.047685373574495316, acc: 1.0)
[2024-11-13 09:36:56,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:57,420][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 0.18600252270698547, acc: 0.9130434989929199)
[2024-11-13 09:36:57,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:58,103][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 0.2627961039543152, acc: 0.9322034120559692)
[2024-11-13 09:36:58,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:58,792][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 0.21335071325302124, acc: 0.9473684430122375)
[2024-11-13 09:36:58,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:36:59,479][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 0.19831320643424988, acc: 0.9459459185600281)
[2024-11-13 09:36:59,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:00,151][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.0874442532658577, acc: 0.9642857313156128)
[2024-11-13 09:37:00,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:00,822][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.004158568102866411, acc: 1.0)
[2024-11-13 09:37:00,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:01,492][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.08806286752223969, acc: 0.9473684430122375)
[2024-11-13 09:37:01,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:02,171][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 0.4477061331272125, acc: 0.8918918967247009)
[2024-11-13 09:37:02,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:02,850][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 0.24719174206256866, acc: 0.9074074029922485)
[2024-11-13 09:37:02,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:03,544][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 0.12408383190631866, acc: 0.9534883499145508)
[2024-11-13 09:37:03,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:04,224][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 0.2311546951532364, acc: 0.9176470637321472)
[2024-11-13 09:37:04,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:04,909][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 0.5745443105697632, acc: 0.8089887499809265)
[2024-11-13 09:37:04,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:05,587][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.16058561205863953, acc: 0.9318181872367859)
[2024-11-13 09:37:05,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:06,257][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.09647596627473831, acc: 0.9523809552192688)
[2024-11-13 09:37:06,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:06,931][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 0.004478180781006813, acc: 1.0)
[2024-11-13 09:37:07,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:07,611][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.12696370482444763, acc: 0.9387755393981934)
[2024-11-13 09:37:07,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:08,286][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.047947514802217484, acc: 0.9800000190734863)
[2024-11-13 09:37:08,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:08,971][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 0.3096284568309784, acc: 0.9166666865348816)
[2024-11-13 09:37:09,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:09,662][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 0.6371143460273743, acc: 0.7941176295280457)
[2024-11-13 09:37:09,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:10,385][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 1.0576858520507812, acc: 0.6849315166473389)
[2024-11-13 09:37:10,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:11,058][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.036961719393730164, acc: 0.9583333134651184)
[2024-11-13 09:37:11,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:11,737][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.3678582012653351, acc: 0.9259259104728699)
[2024-11-13 09:37:11,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:12,408][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.17826567590236664, acc: 0.9285714030265808)
[2024-11-13 09:37:12,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:13,113][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 0.6211556792259216, acc: 0.7876105904579163)
[2024-11-13 09:37:13,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:13,804][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 0.28356117010116577, acc: 0.9275362491607666)
[2024-11-13 09:37:13,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:14,491][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 0.29591041803359985, acc: 0.9090909361839294)
[2024-11-13 09:37:14,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:15,203][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 0.6798378825187683, acc: 0.7862595319747925)
[2024-11-13 09:37:15,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:15,908][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 0.5618305802345276, acc: 0.8370370268821716)
[2024-11-13 09:37:15,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:16,599][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.1191086545586586, acc: 0.9672130942344666)
[2024-11-13 09:37:16,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:17,274][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.1227729320526123, acc: 0.9166666865348816)
[2024-11-13 09:37:17,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:17,948][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.014404676854610443, acc: 1.0)
[2024-11-13 09:37:18,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:18,621][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.02742811106145382, acc: 1.0)
[2024-11-13 09:37:18,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:19,305][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 0.2376497983932495, acc: 0.9024389982223511)
[2024-11-13 09:37:19,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:20,033][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 0.5437127351760864, acc: 0.8549848794937134)
[2024-11-13 09:37:20,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:20,759][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 0.5814797878265381, acc: 0.8097983002662659)
[2024-11-13 09:37:20,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:21,477][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 0.5452849268913269, acc: 0.8374999761581421)
[2024-11-13 09:37:21,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:22,241][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 0.7991014122962952, acc: 0.7823639512062073)
[2024-11-13 09:37:22,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:22,978][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 0.4312089681625366, acc: 0.8861209750175476)
[2024-11-13 09:37:23,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:23,651][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.2167329043149948, acc: 0.9599999785423279)
[2024-11-13 09:37:23,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:24,342][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 0.3170245289802551, acc: 0.8837209343910217)
[2024-11-13 09:37:24,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:25,033][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 0.6739206910133362, acc: 0.8095238208770752)
[2024-11-13 09:37:25,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:25,726][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 0.6279667019844055, acc: 0.7954545617103577)
[2024-11-13 09:37:25,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:26,410][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 0.2784883379936218, acc: 0.9176470637321472)
[2024-11-13 09:37:26,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:27,117][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 0.5615862011909485, acc: 0.8395061492919922)
[2024-11-13 09:37:27,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:27,805][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 0.2664559483528137, acc: 0.9193548560142517)
[2024-11-13 09:37:27,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:28,477][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.07889407128095627, acc: 0.9642857313156128)
[2024-11-13 09:37:28,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:29,151][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.1792360246181488, acc: 0.949999988079071)
[2024-11-13 09:37:29,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:29,831][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 0.28407323360443115, acc: 0.9264705777168274)
[2024-11-13 09:37:29,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:30,520][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 0.6262880563735962, acc: 0.7867646813392639)
[2024-11-13 09:37:30,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:31,208][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 0.5224177241325378, acc: 0.8728813529014587)
[2024-11-13 09:37:31,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:31,898][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 0.29757440090179443, acc: 0.9104477763175964)
[2024-11-13 09:37:31,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:32,598][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 0.45113372802734375, acc: 0.844660222530365)
[2024-11-13 09:37:32,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:33,286][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 0.36978062987327576, acc: 0.8730158805847168)
[2024-11-13 09:37:33,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:33,970][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 0.0875108391046524, acc: 0.9780219793319702)
[2024-11-13 09:37:34,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:34,690][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 0.20626793801784515, acc: 0.9417040348052979)
[2024-11-13 09:37:34,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:35,420][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 0.44430670142173767, acc: 0.8622047305107117)
[2024-11-13 09:37:35,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:36,130][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 0.2209024876356125, acc: 0.9137930870056152)
[2024-11-13 09:37:36,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:36,847][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 0.423066109418869, acc: 0.9057971239089966)
[2024-11-13 09:37:36,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:37,568][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 0.2821190357208252, acc: 0.9027237296104431)
[2024-11-13 09:37:37,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:38,280][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 0.15315793454647064, acc: 0.95652174949646)
[2024-11-13 09:37:38,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:38,952][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.1925177425146103, acc: 0.95652174949646)
[2024-11-13 09:37:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:39,635][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.2322094440460205, acc: 0.9285714030265808)
[2024-11-13 09:37:39,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:40,317][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.009551222436130047, acc: 1.0)
[2024-11-13 09:37:40,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:41,018][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 0.2710997462272644, acc: 0.9307692050933838)
[2024-11-13 09:37:41,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:41,700][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 0.05625685304403305, acc: 0.9864864945411682)
[2024-11-13 09:37:41,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:42,379][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 0.07138741761445999, acc: 0.9767441749572754)
[2024-11-13 09:37:42,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:43,076][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 0.11898299306631088, acc: 0.9459459185600281)
[2024-11-13 09:37:43,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:43,762][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 0.059126149863004684, acc: 0.9777777791023254)
[2024-11-13 09:37:43,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:44,443][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.011317410506308079, acc: 1.0)
[2024-11-13 09:37:44,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:45,115][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.06177501007914543, acc: 0.9629629850387573)
[2024-11-13 09:37:45,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:45,787][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.005351508967578411, acc: 1.0)
[2024-11-13 09:37:45,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:46,469][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 0.30030500888824463, acc: 0.8653846383094788)
[2024-11-13 09:37:46,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:47,185][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 0.46838557720184326, acc: 0.8804348111152649)
[2024-11-13 09:37:47,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:47,890][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 0.35676848888397217, acc: 0.8863636255264282)
[2024-11-13 09:37:47,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:48,603][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 0.3958379030227661, acc: 0.9042553305625916)
[2024-11-13 09:37:48,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:49,326][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.1752520203590393, acc: 0.9245283007621765)
[2024-11-13 09:37:49,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:50,006][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.1255764216184616, acc: 0.9666666388511658)
[2024-11-13 09:37:50,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:50,697][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.12311681360006332, acc: 0.930232584476471)
[2024-11-13 09:37:50,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:51,374][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 0.0992659404873848, acc: 0.9333333373069763)
[2024-11-13 09:37:51,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:52,062][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 0.8985500335693359, acc: 0.75789475440979)
[2024-11-13 09:37:52,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:52,772][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 0.28280460834503174, acc: 0.9333333373069763)
[2024-11-13 09:37:52,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:53,480][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 0.5696747899055481, acc: 0.7944444417953491)
[2024-11-13 09:37:53,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:54,190][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 1.0506142377853394, acc: 0.71100914478302)
[2024-11-13 09:37:54,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:54,897][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 0.5531126260757446, acc: 0.807692289352417)
[2024-11-13 09:37:54,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:55,578][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.17588311433792114, acc: 0.9473684430122375)
[2024-11-13 09:37:55,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:56,250][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.015504592098295689, acc: 1.0)
[2024-11-13 09:37:56,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:56,921][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.06181592121720314, acc: 1.0)
[2024-11-13 09:37:57,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:57,597][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.1585700362920761, acc: 0.9259259104728699)
[2024-11-13 09:37:57,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:58,273][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.12704089283943176, acc: 0.9714285731315613)
[2024-11-13 09:37:58,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:58,949][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.0377437025308609, acc: 1.0)
[2024-11-13 09:37:59,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:37:59,622][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.07786235213279724, acc: 0.9772727489471436)
[2024-11-13 09:37:59,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:00,303][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 0.3498431146144867, acc: 0.9032257795333862)
[2024-11-13 09:38:00,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:00,983][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.20194321870803833, acc: 0.9318181872367859)
[2024-11-13 09:38:01,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:01,664][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.005319179967045784, acc: 1.0)
[2024-11-13 09:38:01,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:02,339][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.01859748177230358, acc: 1.0)
[2024-11-13 09:38:02,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:03,015][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.06928647309541702, acc: 0.9677419066429138)
[2024-11-13 09:38:03,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:03,685][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.07324440777301788, acc: 0.949999988079071)
[2024-11-13 09:38:03,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:04,363][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.04050580784678459, acc: 1.0)
[2024-11-13 09:38:04,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:05,036][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.038791827857494354, acc: 0.9729729890823364)
[2024-11-13 09:38:05,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:05,711][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.011421878822147846, acc: 1.0)
[2024-11-13 09:38:05,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:06,395][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 0.21424582600593567, acc: 0.9264705777168274)
[2024-11-13 09:38:06,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:07,083][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.051050059497356415, acc: 0.9756097793579102)
[2024-11-13 09:38:07,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:07,758][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.0029140568803995848, acc: 1.0)
[2024-11-13 09:38:07,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:08,431][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.0029741383623331785, acc: 1.0)
[2024-11-13 09:38:08,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:09,103][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.009954232722520828, acc: 1.0)
[2024-11-13 09:38:09,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:09,782][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.1043338030576706, acc: 0.9649122953414917)
[2024-11-13 09:38:09,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:10,470][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.02204780839383602, acc: 1.0)
[2024-11-13 09:38:10,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:11,161][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.030338456854224205, acc: 0.9868420958518982)
[2024-11-13 09:38:11,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:11,865][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 0.17720338702201843, acc: 0.9528301954269409)
[2024-11-13 09:38:11,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:12,581][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 0.2284424751996994, acc: 0.9583333134651184)
[2024-11-13 09:38:12,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:13,256][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.01505504734814167, acc: 1.0)
[2024-11-13 09:38:13,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:13,935][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.06102917343378067, acc: 1.0)
[2024-11-13 09:38:14,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:14,631][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 0.5030285120010376, acc: 0.7866666913032532)
[2024-11-13 09:38:14,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:15,306][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 0.31644123792648315, acc: 0.9166666865348816)
[2024-11-13 09:38:15,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:16,017][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 0.8592579960823059, acc: 0.7440000176429749)
[2024-11-13 09:38:16,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:16,699][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 0.5165262818336487, acc: 0.8651685118675232)
[2024-11-13 09:38:16,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:17,378][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 0.3128306567668915, acc: 0.8918918967247009)
[2024-11-13 09:38:17,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:18,063][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.08707443624734879, acc: 0.982758641242981)
[2024-11-13 09:38:18,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:18,738][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.011076558381319046, acc: 1.0)
[2024-11-13 09:38:18,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:19,410][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.006904312875121832, acc: 1.0)
[2024-11-13 09:38:19,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:20,082][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.04804936796426773, acc: 0.96875)
[2024-11-13 09:38:20,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:20,753][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.09528812021017075, acc: 0.9666666388511658)
[2024-11-13 09:38:20,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:21,438][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.6393412351608276, acc: 0.800000011920929)
[2024-11-13 09:38:22,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:22,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:23,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:24,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:24,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:25,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:25,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:26,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:27,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:27,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:28,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:28,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:29,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:29,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:30,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:30,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:31,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:32,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:32,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:33,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:34,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:34,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:35,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:35,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:36,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:37,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:37,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:38,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:38,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:39,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:39,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:40,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:41,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:41,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:42,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:42,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:43,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:43,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:44,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:45,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:45,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:46,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:46,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:47,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:48,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:48,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:49,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:49,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:50,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:50,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:52,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:52,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:53,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:53,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:54,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:55,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:55,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:56,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:56,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:57,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:58,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:58,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:59,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:38:59,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:00,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:01,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:01,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:02,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:02,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:03,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:03,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:04,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:05,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:05,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:06,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:06,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:07,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:07,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:08,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:09,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:09,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:10,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:10,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:11,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:12,425][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1743, device='cuda:0') eval_epoch_loss=tensor(0.7767, device='cuda:0') eval_epoch_acc=tensor(0.8222, device='cuda:0')
[2024-11-13 09:39:12,426][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:39:12,426][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:39:12,745][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_274_loss_0.7767143845558167/model.pt
[2024-11-13 09:39:12,756][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:39:12,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:13,450][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.18899984657764435, acc: 0.96875)
[2024-11-13 09:39:13,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:14,123][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.0023636084515601397, acc: 1.0)
[2024-11-13 09:39:14,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:14,795][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.06927021592855453, acc: 0.9655172228813171)
[2024-11-13 09:39:14,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:15,470][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.001217614859342575, acc: 1.0)
[2024-11-13 09:39:15,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:16,148][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.18904995918273926, acc: 0.914893627166748)
[2024-11-13 09:39:16,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:16,832][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.08462220430374146, acc: 0.9791666865348816)
[2024-11-13 09:39:16,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:17,510][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.1635262668132782, acc: 0.9772727489471436)
[2024-11-13 09:39:17,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:18,198][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 0.37303397059440613, acc: 0.8433734774589539)
[2024-11-13 09:39:18,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:18,897][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 0.48886096477508545, acc: 0.8333333134651184)
[2024-11-13 09:39:19,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:19,572][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.3072080910205841, acc: 0.9210526347160339)
[2024-11-13 09:39:19,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:20,246][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.13303357362747192, acc: 0.9411764740943909)
[2024-11-13 09:39:20,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:20,919][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.05786029249429703, acc: 0.9750000238418579)
[2024-11-13 09:39:21,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:21,603][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 0.22622233629226685, acc: 0.9296875)
[2024-11-13 09:39:21,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:22,312][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 0.2717885971069336, acc: 0.9120000004768372)
[2024-11-13 09:39:22,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:22,996][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 0.12394928187131882, acc: 0.9670329689979553)
[2024-11-13 09:39:23,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:23,685][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 0.2801998555660248, acc: 0.9378882050514221)
[2024-11-13 09:39:23,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:24,399][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 0.37825703620910645, acc: 0.9020618796348572)
[2024-11-13 09:39:24,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:25,083][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.015868712216615677, acc: 1.0)
[2024-11-13 09:39:25,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:25,759][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.21823489665985107, acc: 0.9285714030265808)
[2024-11-13 09:39:25,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:26,442][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.10715824365615845, acc: 0.9655172228813171)
[2024-11-13 09:39:26,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:27,138][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.08060611039400101, acc: 0.9818181991577148)
[2024-11-13 09:39:27,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:27,865][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 0.5383443236351013, acc: 0.8505154848098755)
[2024-11-13 09:39:27,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:28,550][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 0.13867506384849548, acc: 0.9482758641242981)
[2024-11-13 09:39:28,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:29,227][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.07462704926729202, acc: 0.9629629850387573)
[2024-11-13 09:39:29,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:29,910][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.32374417781829834, acc: 0.8947368264198303)
[2024-11-13 09:39:29,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:30,589][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.12998774647712708, acc: 0.9464285969734192)
[2024-11-13 09:39:30,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:31,264][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.0037189507856965065, acc: 1.0)
[2024-11-13 09:39:31,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:31,956][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.05171652138233185, acc: 0.9811320900917053)
[2024-11-13 09:39:32,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:32,635][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.011032424867153168, acc: 1.0)
[2024-11-13 09:39:32,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:33,306][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.09774914383888245, acc: 0.970588207244873)
[2024-11-13 09:39:33,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:33,978][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.11220759153366089, acc: 0.96875)
[2024-11-13 09:39:34,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:34,660][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.3488413393497467, acc: 0.9344262480735779)
[2024-11-13 09:39:34,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:35,334][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.033944837749004364, acc: 1.0)
[2024-11-13 09:39:35,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:36,003][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.22950080037117004, acc: 0.9473684430122375)
[2024-11-13 09:39:36,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:36,683][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 0.1922711879014969, acc: 0.9130434989929199)
[2024-11-13 09:39:36,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:37,370][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 0.042268719524145126, acc: 0.9861111044883728)
[2024-11-13 09:39:37,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:38,061][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.10728556662797928, acc: 0.9879518151283264)
[2024-11-13 09:39:38,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:38,750][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 0.08100312203168869, acc: 0.9871794581413269)
[2024-11-13 09:39:38,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:39,453][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 0.2884330451488495, acc: 0.9285714030265808)
[2024-11-13 09:39:39,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:40,123][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.0030226793605834246, acc: 1.0)
[2024-11-13 09:39:40,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:40,805][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.05326063558459282, acc: 0.9583333134651184)
[2024-11-13 09:39:40,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:41,484][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.10818608105182648, acc: 0.9677419066429138)
[2024-11-13 09:39:41,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:42,158][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.18623967468738556, acc: 0.9677419066429138)
[2024-11-13 09:39:42,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:42,842][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.08271658420562744, acc: 0.9850746393203735)
[2024-11-13 09:39:42,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:43,543][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.044521264731884, acc: 0.9903846383094788)
[2024-11-13 09:39:43,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:44,218][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.04245388135313988, acc: 0.9777777791023254)
[2024-11-13 09:39:44,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:44,899][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.1038174256682396, acc: 0.9838709831237793)
[2024-11-13 09:39:44,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:45,573][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.09411131590604782, acc: 0.9800000190734863)
[2024-11-13 09:39:45,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:46,261][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.10044500231742859, acc: 0.9629629850387573)
[2024-11-13 09:39:46,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:46,941][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 0.06671590358018875, acc: 1.0)
[2024-11-13 09:39:47,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:47,616][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.44445961713790894, acc: 0.8461538553237915)
[2024-11-13 09:39:47,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:48,297][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 0.19030287861824036, acc: 0.9268292784690857)
[2024-11-13 09:39:48,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:48,979][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.3900144398212433, acc: 0.9210526347160339)
[2024-11-13 09:39:49,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:49,661][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.05578914284706116, acc: 1.0)
[2024-11-13 09:39:49,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:50,333][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.02140939235687256, acc: 1.0)
[2024-11-13 09:39:50,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:51,006][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.052065178751945496, acc: 0.9629629850387573)
[2024-11-13 09:39:51,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:51,679][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.0023815790191292763, acc: 1.0)
[2024-11-13 09:39:51,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:52,358][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 0.14334313571453094, acc: 0.9354838728904724)
[2024-11-13 09:39:52,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:53,050][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 0.059221066534519196, acc: 0.9824561476707458)
[2024-11-13 09:39:53,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:53,723][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 0.22620415687561035, acc: 0.9375)
[2024-11-13 09:39:53,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:54,395][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.23490627110004425, acc: 0.9666666388511658)
[2024-11-13 09:39:54,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:55,067][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.04215492680668831, acc: 1.0)
[2024-11-13 09:39:55,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:55,746][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 0.14070330560207367, acc: 0.9399999976158142)
[2024-11-13 09:39:55,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:56,431][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 0.5942931771278381, acc: 0.8275862336158752)
[2024-11-13 09:39:56,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:57,117][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 0.738648533821106, acc: 0.7446808218955994)
[2024-11-13 09:39:57,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:57,801][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 0.598530113697052, acc: 0.759036123752594)
[2024-11-13 09:39:57,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:58,473][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.003890163963660598, acc: 1.0)
[2024-11-13 09:39:58,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:59,164][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.06968122720718384, acc: 1.0)
[2024-11-13 09:39:59,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:39:59,843][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 0.3702487349510193, acc: 0.9156626462936401)
[2024-11-13 09:39:59,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:00,524][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.1216912791132927, acc: 0.9433962106704712)
[2024-11-13 09:40:00,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:01,203][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 0.2024053931236267, acc: 0.949367105960846)
[2024-11-13 09:40:01,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:01,874][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.08432576060295105, acc: 0.9803921580314636)
[2024-11-13 09:40:01,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:02,565][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 0.32187753915786743, acc: 0.8805969953536987)
[2024-11-13 09:40:02,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:03,239][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.012828308157622814, acc: 1.0)
[2024-11-13 09:40:03,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:03,923][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.13555613160133362, acc: 0.9200000166893005)
[2024-11-13 09:40:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:04,600][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.13728472590446472, acc: 0.9444444179534912)
[2024-11-13 09:40:04,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:05,285][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 0.22726546227931976, acc: 0.9534883499145508)
[2024-11-13 09:40:05,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:05,963][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.030655045062303543, acc: 1.0)
[2024-11-13 09:40:06,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:06,641][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 0.12503963708877563, acc: 0.9333333373069763)
[2024-11-13 09:40:06,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:07,313][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.005173531826585531, acc: 1.0)
[2024-11-13 09:40:07,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:07,985][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.06931774318218231, acc: 0.9615384340286255)
[2024-11-13 09:40:08,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:08,668][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 0.46998855471611023, acc: 0.8681318759918213)
[2024-11-13 09:40:08,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:09,373][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 0.5446564555168152, acc: 0.843478262424469)
[2024-11-13 09:40:09,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:10,051][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 0.16091583669185638, acc: 0.945652186870575)
[2024-11-13 09:40:10,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:10,728][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 0.28429415822029114, acc: 0.8979591727256775)
[2024-11-13 09:40:10,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:11,403][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.0028180971276015043, acc: 1.0)
[2024-11-13 09:40:11,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:12,077][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.014861331321299076, acc: 1.0)
[2024-11-13 09:40:12,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:12,752][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.3576323688030243, acc: 0.8780487775802612)
[2024-11-13 09:40:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:13,425][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.0826483964920044, acc: 0.9333333373069763)
[2024-11-13 09:40:13,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:14,117][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 0.052084337919950485, acc: 0.9736841917037964)
[2024-11-13 09:40:14,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:14,801][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.07103344798088074, acc: 0.9756097793579102)
[2024-11-13 09:40:14,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:15,478][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.014869092963635921, acc: 1.0)
[2024-11-13 09:40:15,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:16,150][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.0045434944331645966, acc: 1.0)
[2024-11-13 09:40:16,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:16,824][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.0014147224137559533, acc: 1.0)
[2024-11-13 09:40:16,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:17,496][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.028627121821045876, acc: 1.0)
[2024-11-13 09:40:17,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:18,170][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.01712793856859207, acc: 1.0)
[2024-11-13 09:40:18,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:18,878][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 0.6274296641349792, acc: 0.842424213886261)
[2024-11-13 09:40:18,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:19,583][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 0.4776780903339386, acc: 0.8773584961891174)
[2024-11-13 09:40:19,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:20,264][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 0.19857382774353027, acc: 0.9333333373069763)
[2024-11-13 09:40:20,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:20,946][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.14115826785564423, acc: 0.9107142686843872)
[2024-11-13 09:40:21,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:21,637][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.17258481681346893, acc: 0.9142857193946838)
[2024-11-13 09:40:21,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:22,311][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.003432763274759054, acc: 1.0)
[2024-11-13 09:40:22,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:22,982][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.0031448951922357082, acc: 1.0)
[2024-11-13 09:40:23,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:23,659][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.03196683153510094, acc: 1.0)
[2024-11-13 09:40:23,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:24,351][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 0.031720928847789764, acc: 1.0)
[2024-11-13 09:40:24,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:25,055][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 0.29373133182525635, acc: 0.9041916131973267)
[2024-11-13 09:40:25,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:25,742][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 0.2842695713043213, acc: 0.932330846786499)
[2024-11-13 09:40:25,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:26,466][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 0.6316377520561218, acc: 0.8181818127632141)
[2024-11-13 09:40:26,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:27,180][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.12961290776729584, acc: 0.954954981803894)
[2024-11-13 09:40:27,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:27,853][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.04511628672480583, acc: 0.9642857313156128)
[2024-11-13 09:40:27,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:28,529][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.0036801323294639587, acc: 1.0)
[2024-11-13 09:40:28,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:29,222][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.10773605853319168, acc: 0.9375)
[2024-11-13 09:40:29,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:29,908][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.012387183494865894, acc: 1.0)
[2024-11-13 09:40:30,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:30,584][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.03675076365470886, acc: 1.0)
[2024-11-13 09:40:30,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:31,255][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.014441544190049171, acc: 1.0)
[2024-11-13 09:40:31,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:31,938][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.0068313246592879295, acc: 1.0)
[2024-11-13 09:40:32,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:32,611][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.27044469118118286, acc: 0.9523809552192688)
[2024-11-13 09:40:32,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:33,287][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.3296802043914795, acc: 0.8703703880310059)
[2024-11-13 09:40:33,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:33,972][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 0.39276570081710815, acc: 0.9029126167297363)
[2024-11-13 09:40:34,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:34,689][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 0.5983333587646484, acc: 0.845588207244873)
[2024-11-13 09:40:34,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:35,380][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 0.43926599621772766, acc: 0.8733333349227905)
[2024-11-13 09:40:35,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:36,083][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 0.5774537324905396, acc: 0.8333333134651184)
[2024-11-13 09:40:36,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:36,760][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.12057971954345703, acc: 0.9534883499145508)
[2024-11-13 09:40:36,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:37,434][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.015933649614453316, acc: 1.0)
[2024-11-13 09:40:37,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:38,108][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.06424137949943542, acc: 0.9767441749572754)
[2024-11-13 09:40:38,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:38,780][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.03263199329376221, acc: 1.0)
[2024-11-13 09:40:38,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:39,466][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 0.3235686421394348, acc: 0.8823529481887817)
[2024-11-13 09:40:39,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:40,160][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 0.13446345925331116, acc: 0.9599999785423279)
[2024-11-13 09:40:40,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:40,833][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.013212998397648335, acc: 1.0)
[2024-11-13 09:40:40,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:41,507][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.09803156554698944, acc: 1.0)
[2024-11-13 09:40:41,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:42,179][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.011783930473029613, acc: 1.0)
[2024-11-13 09:40:42,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:42,852][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.007604419253766537, acc: 1.0)
[2024-11-13 09:40:42,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:43,536][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.025444526225328445, acc: 1.0)
[2024-11-13 09:40:43,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:44,212][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.00537136010825634, acc: 1.0)
[2024-11-13 09:40:44,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:44,881][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.004915154539048672, acc: 1.0)
[2024-11-13 09:40:44,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:45,569][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.0027067374903708696, acc: 1.0)
[2024-11-13 09:40:45,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:46,250][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.0331629179418087, acc: 0.982758641242981)
[2024-11-13 09:40:46,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:46,926][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.028762230649590492, acc: 0.9642857313156128)
[2024-11-13 09:40:47,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:47,602][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.00969694647938013, acc: 1.0)
[2024-11-13 09:40:47,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:48,277][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.19643740355968475, acc: 0.9090909361839294)
[2024-11-13 09:40:48,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:48,961][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.028369581326842308, acc: 1.0)
[2024-11-13 09:40:49,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:49,640][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 0.08440040796995163, acc: 0.9607843160629272)
[2024-11-13 09:40:49,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:50,313][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 0.048201486468315125, acc: 1.0)
[2024-11-13 09:40:51,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:51,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:52,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:52,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:53,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:54,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:54,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:55,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:55,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:56,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:56,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:57,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:58,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:59,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:40:59,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:01,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:01,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:02,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:03,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:04,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:04,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:05,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:05,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:06,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:07,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:07,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:08,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:08,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:09,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:10,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:10,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:11,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:11,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:12,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:13,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:13,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:14,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:15,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:15,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:16,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:16,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:17,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:17,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:18,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:19,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:19,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:20,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:20,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:21,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:22,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:22,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:23,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:23,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:24,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:24,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:25,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:26,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:26,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:27,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:27,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:28,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:29,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:29,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:30,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:30,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:31,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:31,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:32,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:33,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:33,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:34,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:34,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:35,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:36,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:37,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:37,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:38,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:39,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:39,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:40,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:40,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:41,787][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3089, device='cuda:0') eval_epoch_loss=tensor(0.8368, device='cuda:0') eval_epoch_acc=tensor(0.8192, device='cuda:0')
[2024-11-13 09:41:41,788][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:41:41,788][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:41:42,127][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_417_loss_0.8367676734924316/model.pt
[2024-11-13 09:41:42,130][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:41:42,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:42,815][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.013103650882840157, acc: 1.0)
[2024-11-13 09:41:42,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:43,491][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.1876547783613205, acc: 0.9750000238418579)
[2024-11-13 09:41:43,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:44,161][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.040651239454746246, acc: 1.0)
[2024-11-13 09:41:44,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:44,835][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.004022188019007444, acc: 1.0)
[2024-11-13 09:41:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:45,519][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.14626851677894592, acc: 0.9666666388511658)
[2024-11-13 09:41:45,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:46,192][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.11555987596511841, acc: 0.90625)
[2024-11-13 09:41:46,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:46,866][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.28311121463775635, acc: 0.9722222089767456)
[2024-11-13 09:41:46,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:47,539][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.001594707602635026, acc: 1.0)
[2024-11-13 09:41:47,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:48,212][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.42749565839767456, acc: 0.9090909361839294)
[2024-11-13 09:41:48,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:48,883][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.012800071388483047, acc: 1.0)
[2024-11-13 09:41:48,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:49,567][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 0.15172545611858368, acc: 0.9729729890823364)
[2024-11-13 09:41:49,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:50,243][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.017299583181738853, acc: 1.0)
[2024-11-13 09:41:50,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:50,925][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.5356781482696533, acc: 0.95652174949646)
[2024-11-13 09:41:51,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:51,598][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.0020317803137004375, acc: 1.0)
[2024-11-13 09:41:51,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:52,272][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.009937699884176254, acc: 1.0)
[2024-11-13 09:41:52,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:52,956][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.0014317829627543688, acc: 1.0)
[2024-11-13 09:41:53,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:53,631][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.008058896288275719, acc: 1.0)
[2024-11-13 09:41:53,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:54,301][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.0016032785642892122, acc: 1.0)
[2024-11-13 09:41:54,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:54,975][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.02292879857122898, acc: 1.0)
[2024-11-13 09:41:55,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:55,646][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.04538911208510399, acc: 0.9722222089767456)
[2024-11-13 09:41:55,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:56,327][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.11124023795127869, acc: 0.9772727489471436)
[2024-11-13 09:41:56,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:57,001][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.10865703970193863, acc: 0.9523809552192688)
[2024-11-13 09:41:57,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:57,677][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.24875344336032867, acc: 0.9230769276618958)
[2024-11-13 09:41:57,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:58,367][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 0.28005558252334595, acc: 0.939393937587738)
[2024-11-13 09:41:58,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:59,073][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 0.6584336757659912, acc: 0.8159999847412109)
[2024-11-13 09:41:59,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:41:59,761][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 0.522004246711731, acc: 0.8709677457809448)
[2024-11-13 09:41:59,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:00,469][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 0.38310131430625916, acc: 0.8756219148635864)
[2024-11-13 09:42:00,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:01,150][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 0.07519827038049698, acc: 0.9622641801834106)
[2024-11-13 09:42:01,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:01,829][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.049554917961359024, acc: 1.0)
[2024-11-13 09:42:01,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:02,498][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.001665158779360354, acc: 1.0)
[2024-11-13 09:42:02,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:03,182][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.17387916147708893, acc: 0.9230769276618958)
[2024-11-13 09:42:03,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:03,855][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.012735453434288502, acc: 1.0)
[2024-11-13 09:42:03,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:04,539][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 0.13823524117469788, acc: 0.9552238583564758)
[2024-11-13 09:42:04,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:05,220][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 0.04691452533006668, acc: 0.9861111044883728)
[2024-11-13 09:42:05,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:05,900][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 0.026066847145557404, acc: 1.0)
[2024-11-13 09:42:05,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:06,575][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 0.08209236711263657, acc: 0.9615384340286255)
[2024-11-13 09:42:06,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:07,254][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.166154146194458, acc: 0.9473684430122375)
[2024-11-13 09:42:07,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:07,937][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.1334412544965744, acc: 0.9795918464660645)
[2024-11-13 09:42:08,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:08,610][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.08703584223985672, acc: 0.939393937587738)
[2024-11-13 09:42:08,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:09,295][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 0.25182411074638367, acc: 0.8865979313850403)
[2024-11-13 09:42:09,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:09,972][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 0.14184387028217316, acc: 0.9571428298950195)
[2024-11-13 09:42:10,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:10,698][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 0.3543878197669983, acc: 0.895348846912384)
[2024-11-13 09:42:10,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:11,375][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.18159465491771698, acc: 0.9642857313156128)
[2024-11-13 09:42:11,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:12,069][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 0.20858411490917206, acc: 0.9506173133850098)
[2024-11-13 09:42:12,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:12,742][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.06104153394699097, acc: 1.0)
[2024-11-13 09:42:12,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:13,418][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.014028926379978657, acc: 1.0)
[2024-11-13 09:42:13,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:14,090][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.035974349826574326, acc: 1.0)
[2024-11-13 09:42:14,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:14,768][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.06023343652486801, acc: 0.97826087474823)
[2024-11-13 09:42:14,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:15,449][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.08988623321056366, acc: 0.9523809552192688)
[2024-11-13 09:42:15,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:16,131][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 0.06942567974328995, acc: 0.9759036302566528)
[2024-11-13 09:42:16,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:16,837][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 0.1955268234014511, acc: 0.9189189076423645)
[2024-11-13 09:42:16,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:17,533][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 0.31691882014274597, acc: 0.9417475461959839)
[2024-11-13 09:42:17,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:18,242][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 0.35045039653778076, acc: 0.8943089246749878)
[2024-11-13 09:42:18,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:18,915][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.017386076971888542, acc: 1.0)
[2024-11-13 09:42:19,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:19,603][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.02511543035507202, acc: 1.0)
[2024-11-13 09:42:19,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:20,319][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 0.379049152135849, acc: 0.8627451062202454)
[2024-11-13 09:42:20,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:21,030][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 0.7093082070350647, acc: 0.8034934401512146)
[2024-11-13 09:42:21,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:21,711][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 0.1822480410337448, acc: 0.9166666865348816)
[2024-11-13 09:42:21,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:22,407][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 0.1899203062057495, acc: 0.9447852969169617)
[2024-11-13 09:42:22,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:23,097][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 0.11300983279943466, acc: 0.9640287756919861)
[2024-11-13 09:42:23,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:23,802][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 0.480439156293869, acc: 0.8542713522911072)
[2024-11-13 09:42:23,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:24,477][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.0649082362651825, acc: 0.9722222089767456)
[2024-11-13 09:42:24,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:25,152][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.035255856812000275, acc: 1.0)
[2024-11-13 09:42:25,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:25,824][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.04228278994560242, acc: 1.0)
[2024-11-13 09:42:25,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:26,496][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.025911767035722733, acc: 1.0)
[2024-11-13 09:42:26,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:27,166][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.011556442826986313, acc: 1.0)
[2024-11-13 09:42:27,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:27,851][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.2906426191329956, acc: 0.8793103694915771)
[2024-11-13 09:42:27,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:28,538][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.0074510229751467705, acc: 1.0)
[2024-11-13 09:42:28,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:29,211][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.06758157908916473, acc: 0.9473684430122375)
[2024-11-13 09:42:29,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:29,895][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.13694646954536438, acc: 0.9629629850387573)
[2024-11-13 09:42:29,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:30,580][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.012630884535610676, acc: 1.0)
[2024-11-13 09:42:30,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:31,255][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.10291846096515656, acc: 1.0)
[2024-11-13 09:42:31,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:31,934][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 0.2633555829524994, acc: 0.9076923131942749)
[2024-11-13 09:42:32,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:32,606][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.03670972213149071, acc: 0.9666666388511658)
[2024-11-13 09:42:32,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:33,277][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.08226703852415085, acc: 0.9655172228813171)
[2024-11-13 09:42:33,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:33,959][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.07971198111772537, acc: 0.9607843160629272)
[2024-11-13 09:42:34,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:34,632][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.04725157842040062, acc: 1.0)
[2024-11-13 09:42:34,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:35,305][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.0056197503581643105, acc: 1.0)
[2024-11-13 09:42:35,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:35,977][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.009490570984780788, acc: 1.0)
[2024-11-13 09:42:36,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:36,664][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 0.3042497932910919, acc: 0.9107142686843872)
[2024-11-13 09:42:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:37,352][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 0.23167070746421814, acc: 0.9213483333587646)
[2024-11-13 09:42:37,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:38,036][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 0.3830859065055847, acc: 0.8876404762268066)
[2024-11-13 09:42:38,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:38,735][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 0.5757097005844116, acc: 0.8368794322013855)
[2024-11-13 09:42:38,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:39,425][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 0.2929191291332245, acc: 0.9021739363670349)
[2024-11-13 09:42:39,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:40,095][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.001323728240095079, acc: 1.0)
[2024-11-13 09:42:40,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:40,775][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.0016732608200982213, acc: 1.0)
[2024-11-13 09:42:40,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:41,448][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.0010325066978111863, acc: 1.0)
[2024-11-13 09:42:41,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:42,122][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.010701875202357769, acc: 1.0)
[2024-11-13 09:42:42,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:42,799][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.18357595801353455, acc: 0.9622641801834106)
[2024-11-13 09:42:42,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:43,482][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.14767387509346008, acc: 0.9655172228813171)
[2024-11-13 09:42:43,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:44,169][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 0.3407048285007477, acc: 0.8828828930854797)
[2024-11-13 09:42:44,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:44,856][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 0.11386056244373322, acc: 0.9718309640884399)
[2024-11-13 09:42:44,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:45,537][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.0006647682748734951, acc: 1.0)
[2024-11-13 09:42:45,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:46,210][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.0028709149919450283, acc: 1.0)
[2024-11-13 09:42:46,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:46,883][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.07768453657627106, acc: 0.9615384340286255)
[2024-11-13 09:42:46,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:47,624][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 1.1684339046478271, acc: 0.6785714030265808)
[2024-11-13 09:42:47,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:48,331][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 0.31475749611854553, acc: 0.9047619104385376)
[2024-11-13 09:42:48,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:49,008][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.007498231250792742, acc: 1.0)
[2024-11-13 09:42:49,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:49,686][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.025090020149946213, acc: 0.9833333492279053)
[2024-11-13 09:42:49,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:50,381][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.38068923354148865, acc: 0.8194444179534912)
[2024-11-13 09:42:50,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:51,053][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.0013143459800630808, acc: 1.0)
[2024-11-13 09:42:51,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:51,724][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.010414576157927513, acc: 1.0)
[2024-11-13 09:42:51,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:52,392][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.08901526778936386, acc: 0.949999988079071)
[2024-11-13 09:42:52,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:53,067][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.022899746894836426, acc: 1.0)
[2024-11-13 09:42:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:53,977][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 1.0559207201004028, acc: 0.7033898234367371)
[2024-11-13 09:42:54,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:54,680][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 0.20661945641040802, acc: 0.9402984976768494)
[2024-11-13 09:42:54,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:55,364][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 0.11868610233068466, acc: 0.970802903175354)
[2024-11-13 09:42:55,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:56,082][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 0.5196386575698853, acc: 0.8650000095367432)
[2024-11-13 09:42:56,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:56,759][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 0.011182956397533417, acc: 1.0)
[2024-11-13 09:42:56,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:57,438][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.07741273194551468, acc: 0.9615384340286255)
[2024-11-13 09:42:57,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:58,111][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.13231982290744781, acc: 0.9047619104385376)
[2024-11-13 09:42:58,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:58,795][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 0.18052595853805542, acc: 0.9508196711540222)
[2024-11-13 09:42:58,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:42:59,470][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 0.08922617137432098, acc: 0.9830508232116699)
[2024-11-13 09:42:59,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:00,144][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 0.2086898386478424, acc: 0.9069767594337463)
[2024-11-13 09:43:00,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:00,821][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.2189071774482727, acc: 0.9545454382896423)
[2024-11-13 09:43:00,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:01,495][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.23649880290031433, acc: 0.9056603908538818)
[2024-11-13 09:43:01,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:02,167][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.10085958987474442, acc: 0.9545454382896423)
[2024-11-13 09:43:02,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:02,834][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.013470593839883804, acc: 1.0)
[2024-11-13 09:43:02,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:03,516][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.08565398305654526, acc: 0.8999999761581421)
[2024-11-13 09:43:03,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:04,187][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.008130460046231747, acc: 1.0)
[2024-11-13 09:43:04,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:04,876][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.08888647705316544, acc: 0.9692307710647583)
[2024-11-13 09:43:04,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:05,558][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.14400909841060638, acc: 0.984375)
[2024-11-13 09:43:05,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:06,234][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.10189025104045868, acc: 0.9375)
[2024-11-13 09:43:06,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:06,912][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.038953714072704315, acc: 0.9696969985961914)
[2024-11-13 09:43:07,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:07,598][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.0013114396715536714, acc: 1.0)
[2024-11-13 09:43:07,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:08,271][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.004384291358292103, acc: 1.0)
[2024-11-13 09:43:08,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:08,941][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.04367351904511452, acc: 0.95652174949646)
[2024-11-13 09:43:09,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:09,624][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.016017790883779526, acc: 1.0)
[2024-11-13 09:43:09,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:10,299][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.03978905826807022, acc: 0.9756097793579102)
[2024-11-13 09:43:10,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:10,975][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.057774290442466736, acc: 0.9714285731315613)
[2024-11-13 09:43:11,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:11,651][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.026202527806162834, acc: 1.0)
[2024-11-13 09:43:11,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:12,336][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.037281330674886703, acc: 1.0)
[2024-11-13 09:43:12,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:13,010][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.0029280453454703093, acc: 1.0)
[2024-11-13 09:43:13,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:13,685][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.13902053236961365, acc: 0.9090909361839294)
[2024-11-13 09:43:13,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:14,365][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.04651840403676033, acc: 0.9750000238418579)
[2024-11-13 09:43:14,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:15,044][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.03210235387086868, acc: 0.9857142567634583)
[2024-11-13 09:43:15,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:15,746][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 0.17910903692245483, acc: 0.956204354763031)
[2024-11-13 09:43:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:16,451][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 0.17748895287513733, acc: 0.9241379499435425)
[2024-11-13 09:43:16,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:17,139][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 0.21485939621925354, acc: 0.9357143044471741)
[2024-11-13 09:43:17,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:17,843][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 0.231072336435318, acc: 0.9470198750495911)
[2024-11-13 09:43:17,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:18,541][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 0.10237936675548553, acc: 0.9658119678497314)
[2024-11-13 09:43:18,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:19,214][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.009187839925289154, acc: 1.0)
[2024-11-13 09:43:19,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:19,885][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.050049956887960434, acc: 1.0)
[2024-11-13 09:43:20,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:21,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:22,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:22,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:23,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:23,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:24,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:25,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:25,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:26,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:26,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:27,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:27,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:28,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:29,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:29,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:30,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:30,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:31,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:32,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:32,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:33,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:33,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:34,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:34,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:35,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:36,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:37,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:37,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:38,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:38,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:39,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:40,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:40,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:41,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:42,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:42,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:43,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:43,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:44,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:44,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:45,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:46,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:46,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:47,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:47,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:48,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:48,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:49,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:50,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:50,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:51,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:51,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:52,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:53,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:53,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:54,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:54,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:55,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:56,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:56,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:57,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:57,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:58,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:59,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:43:59,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:00,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:01,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:01,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:02,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:03,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:03,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:04,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:04,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:05,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:05,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:06,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:07,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:07,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:08,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:08,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:09,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:09,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:11,005][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3075, device='cuda:0') eval_epoch_loss=tensor(0.8362, device='cuda:0') eval_epoch_acc=tensor(0.8185, device='cuda:0')
[2024-11-13 09:44:11,006][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:44:11,007][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:44:11,324][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_560_loss_0.8361748456954956/model.pt
[2024-11-13 09:44:11,328][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:44:11,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:12,014][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.012535338290035725, acc: 1.0)
[2024-11-13 09:44:12,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:12,698][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.06641217321157455, acc: 0.9743589758872986)
[2024-11-13 09:44:12,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:13,399][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 0.18556533753871918, acc: 0.9222221970558167)
[2024-11-13 09:44:13,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:14,083][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.16148851811885834, acc: 0.948051929473877)
[2024-11-13 09:44:14,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:14,754][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.06687191873788834, acc: 0.9791666865348816)
[2024-11-13 09:44:14,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:15,429][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.03646395355463028, acc: 1.0)
[2024-11-13 09:44:15,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:16,120][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 0.039973147213459015, acc: 0.988095223903656)
[2024-11-13 09:44:16,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:16,806][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.01854792796075344, acc: 1.0)
[2024-11-13 09:44:16,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:17,478][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.01217047218233347, acc: 1.0)
[2024-11-13 09:44:17,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:18,201][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 0.19280868768692017, acc: 0.9358288645744324)
[2024-11-13 09:44:18,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:18,889][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.003657212946563959, acc: 1.0)
[2024-11-13 09:44:18,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:19,575][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 0.10314752906560898, acc: 0.9572649598121643)
[2024-11-13 09:44:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:20,278][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 0.5766043663024902, acc: 0.8724489808082581)
[2024-11-13 09:44:20,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:20,995][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 0.2392672896385193, acc: 0.9245283007621765)
[2024-11-13 09:44:21,378][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=1.2160, train_epoch_loss=0.1955, epoch time 602.0532924626023s
[2024-11-13 09:44:21,378][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 09:44:21,378][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 09:44:21,378][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 09:44:21,378][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 7
[2024-11-13 09:44:21,378][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 09:44:22,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:22,739][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.053990840911865234, acc: 0.9629629850387573)
[2024-11-13 09:44:22,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:23,425][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.05708206817507744, acc: 0.9599999785423279)
[2024-11-13 09:44:23,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:24,116][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.23801648616790771, acc: 0.8918918967247009)
[2024-11-13 09:44:24,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:24,808][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.07289546728134155, acc: 0.9736841917037964)
[2024-11-13 09:44:24,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:25,492][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.06796195358037949, acc: 0.9729729890823364)
[2024-11-13 09:44:25,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:26,175][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.05091530457139015, acc: 1.0)
[2024-11-13 09:44:26,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:26,861][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.11975675821304321, acc: 0.918367326259613)
[2024-11-13 09:44:26,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:27,558][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.05375297740101814, acc: 0.9666666388511658)
[2024-11-13 09:44:27,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:28,239][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.04526596888899803, acc: 0.9545454382896423)
[2024-11-13 09:44:28,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:28,931][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.0017097836825996637, acc: 1.0)
[2024-11-13 09:44:29,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:29,631][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.028101181611418724, acc: 1.0)
[2024-11-13 09:44:29,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:30,321][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 0.023119887337088585, acc: 1.0)
[2024-11-13 09:44:30,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:31,017][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.0027772444300353527, acc: 1.0)
[2024-11-13 09:44:31,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:31,703][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.07270611077547073, acc: 0.97826087474823)
[2024-11-13 09:44:31,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:32,387][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.016155771911144257, acc: 1.0)
[2024-11-13 09:44:32,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:33,085][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.07078102231025696, acc: 0.9795918464660645)
[2024-11-13 09:44:33,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:33,767][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.03575741872191429, acc: 1.0)
[2024-11-13 09:44:33,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:34,451][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.35023602843284607, acc: 0.9583333134651184)
[2024-11-13 09:44:34,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:35,141][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.10089793801307678, acc: 0.9722222089767456)
[2024-11-13 09:44:35,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:35,824][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.0036068076733499765, acc: 1.0)
[2024-11-13 09:44:35,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:36,508][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.009222861379384995, acc: 1.0)
[2024-11-13 09:44:36,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:37,191][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.02332353964447975, acc: 1.0)
[2024-11-13 09:44:37,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:37,873][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.28645026683807373, acc: 0.9200000166893005)
[2024-11-13 09:44:38,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:38,559][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.0011287222150713205, acc: 1.0)
[2024-11-13 09:44:38,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:39,290][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.029265303164720535, acc: 1.0)
[2024-11-13 09:44:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:39,984][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 0.19433483481407166, acc: 0.9245283007621765)
[2024-11-13 09:44:40,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:40,682][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 0.10170998424291611, acc: 0.9589040875434875)
[2024-11-13 09:44:40,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:41,492][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 0.8937596082687378, acc: 0.731225311756134)
[2024-11-13 09:44:41,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:42,188][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.0657157301902771, acc: 0.9767441749572754)
[2024-11-13 09:44:42,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:42,881][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 0.08898554742336273, acc: 0.9879518151283264)
[2024-11-13 09:44:42,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:43,592][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 0.09099115431308746, acc: 0.9753086566925049)
[2024-11-13 09:44:43,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:44,291][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.027230480685830116, acc: 1.0)
[2024-11-13 09:44:44,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:44,974][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.0047133853659033775, acc: 1.0)
[2024-11-13 09:44:45,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:45,655][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.0027354343328624964, acc: 1.0)
[2024-11-13 09:44:45,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:46,355][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 0.21967515349388123, acc: 0.9495798349380493)
[2024-11-13 09:44:46,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:47,044][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.07019330561161041, acc: 0.9836065769195557)
[2024-11-13 09:44:47,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:47,753][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.1991642415523529, acc: 0.9523809552192688)
[2024-11-13 09:44:47,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:48,442][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 0.17174114286899567, acc: 0.9152542352676392)
[2024-11-13 09:44:48,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:49,133][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.19112025201320648, acc: 0.931034505367279)
[2024-11-13 09:44:49,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:49,815][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.0029238464776426554, acc: 1.0)
[2024-11-13 09:44:49,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:50,499][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.0999608188867569, acc: 0.9230769276618958)
[2024-11-13 09:44:50,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:51,195][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 0.08950202167034149, acc: 0.9594594836235046)
[2024-11-13 09:44:51,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:51,886][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 0.16580884158611298, acc: 0.9384615421295166)
[2024-11-13 09:44:52,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:52,579][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 0.14188674092292786, acc: 0.9595959782600403)
[2024-11-13 09:44:52,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:53,277][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 0.23829296231269836, acc: 0.907216489315033)
[2024-11-13 09:44:53,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:53,977][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 0.16380782425403595, acc: 0.9264705777168274)
[2024-11-13 09:44:54,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:54,658][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.011673390865325928, acc: 1.0)
[2024-11-13 09:44:54,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:55,343][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.0037101113703101873, acc: 1.0)
[2024-11-13 09:44:55,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:56,028][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.2277151346206665, acc: 0.9642857313156128)
[2024-11-13 09:44:56,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:56,715][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.0947834849357605, acc: 0.9722222089767456)
[2024-11-13 09:44:56,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:57,406][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.20980148017406464, acc: 0.9649122953414917)
[2024-11-13 09:44:57,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:58,116][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.13884727656841278, acc: 0.9841269850730896)
[2024-11-13 09:44:58,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:58,811][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.20503251254558563, acc: 0.9436619877815247)
[2024-11-13 09:44:58,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:44:59,545][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 0.6990474462509155, acc: 0.7733333110809326)
[2024-11-13 09:44:59,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:00,236][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.02252439595758915, acc: 1.0)
[2024-11-13 09:45:00,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:00,921][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.04109564796090126, acc: 1.0)
[2024-11-13 09:45:01,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:01,763][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.1252509355545044, acc: 0.6928327679634094)
[2024-11-13 09:45:01,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:02,547][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 1.300925374031067, acc: 0.6274510025978088)
[2024-11-13 09:45:02,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:03,272][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 0.5101142525672913, acc: 0.8579545617103577)
[2024-11-13 09:45:03,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:03,974][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 0.2392590194940567, acc: 0.9264705777168274)
[2024-11-13 09:45:04,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:04,693][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 0.41758817434310913, acc: 0.8478260636329651)
[2024-11-13 09:45:04,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:05,408][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 0.3091470003128052, acc: 0.949999988079071)
[2024-11-13 09:45:05,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:06,105][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.08856543153524399, acc: 0.970588207244873)
[2024-11-13 09:45:06,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:06,791][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 0.12510928511619568, acc: 0.9722222089767456)
[2024-11-13 09:45:06,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:07,485][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.04119767248630524, acc: 1.0)
[2024-11-13 09:45:07,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:08,169][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.006557640619575977, acc: 1.0)
[2024-11-13 09:45:08,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:08,861][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.14785133302211761, acc: 0.9821428656578064)
[2024-11-13 09:45:08,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:09,559][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 0.02832568623125553, acc: 1.0)
[2024-11-13 09:45:09,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:10,242][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.005500174127519131, acc: 1.0)
[2024-11-13 09:45:10,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:10,930][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.05845358595252037, acc: 1.0)
[2024-11-13 09:45:11,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:11,616][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.023274285718798637, acc: 1.0)
[2024-11-13 09:45:11,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:12,337][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 0.4681481420993805, acc: 0.875)
[2024-11-13 09:45:12,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:13,033][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 0.25802743434906006, acc: 0.89682537317276)
[2024-11-13 09:45:13,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:13,756][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 0.8111595511436462, acc: 0.7692307829856873)
[2024-11-13 09:45:13,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:14,448][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 0.4781331419944763, acc: 0.8673469424247742)
[2024-11-13 09:45:14,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:15,153][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 0.5766778588294983, acc: 0.7686567306518555)
[2024-11-13 09:45:15,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:15,896][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.108942985534668, acc: 0.6970803141593933)
[2024-11-13 09:45:15,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:16,576][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.059990815818309784, acc: 0.9523809552192688)
[2024-11-13 09:45:16,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:17,262][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.0598524808883667, acc: 0.9583333134651184)
[2024-11-13 09:45:17,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:17,952][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.015811549499630928, acc: 1.0)
[2024-11-13 09:45:18,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:18,638][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.014858249574899673, acc: 1.0)
[2024-11-13 09:45:18,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:19,336][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.22839850187301636, acc: 0.942307710647583)
[2024-11-13 09:45:19,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:20,026][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 0.1473999172449112, acc: 0.9615384340286255)
[2024-11-13 09:45:20,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:20,709][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.041832488030195236, acc: 0.96875)
[2024-11-13 09:45:20,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:21,399][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 0.07858923822641373, acc: 0.9855072498321533)
[2024-11-13 09:45:21,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:22,101][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.07782600075006485, acc: 0.9800000190734863)
[2024-11-13 09:45:22,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:22,785][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.05852397158741951, acc: 1.0)
[2024-11-13 09:45:22,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:23,489][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 0.18577739596366882, acc: 0.9200000166893005)
[2024-11-13 09:45:23,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:24,187][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 0.19887329638004303, acc: 0.9223300814628601)
[2024-11-13 09:45:24,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:24,906][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 0.5978243350982666, acc: 0.8300970792770386)
[2024-11-13 09:45:24,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:25,629][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 0.7450120449066162, acc: 0.7956989407539368)
[2024-11-13 09:45:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:26,366][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 0.6840323805809021, acc: 0.818965494632721)
[2024-11-13 09:45:26,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:27,062][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 0.2810257077217102, acc: 0.8947368264198303)
[2024-11-13 09:45:27,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:27,783][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 0.3361450731754303, acc: 0.9009901285171509)
[2024-11-13 09:45:27,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:28,471][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 0.11016663163900375, acc: 0.9516128897666931)
[2024-11-13 09:45:28,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:29,161][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 0.0999690592288971, acc: 0.9855072498321533)
[2024-11-13 09:45:29,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:29,871][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 0.36240604519844055, acc: 0.9075630307197571)
[2024-11-13 09:45:29,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:30,569][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 0.1939103603363037, acc: 0.932692289352417)
[2024-11-13 09:45:30,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:31,270][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 0.5016445517539978, acc: 0.8467153310775757)
[2024-11-13 09:45:31,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:31,958][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 0.21041308343410492, acc: 0.89552241563797)
[2024-11-13 09:45:32,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:32,641][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.06826759874820709, acc: 0.949999988079071)
[2024-11-13 09:45:32,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:33,322][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.002577970502898097, acc: 1.0)
[2024-11-13 09:45:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:34,003][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.0017075414070859551, acc: 1.0)
[2024-11-13 09:45:34,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:34,690][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.058826204389333725, acc: 0.9545454382896423)
[2024-11-13 09:45:34,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:35,387][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.01698640175163746, acc: 1.0)
[2024-11-13 09:45:35,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:36,073][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.013743885792791843, acc: 1.0)
[2024-11-13 09:45:36,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:36,755][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.0737968310713768, acc: 0.9599999785423279)
[2024-11-13 09:45:36,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:37,435][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.002173260785639286, acc: 1.0)
[2024-11-13 09:45:37,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:38,132][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.009519767947494984, acc: 1.0)
[2024-11-13 09:45:38,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:38,820][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.14775985479354858, acc: 0.9285714030265808)
[2024-11-13 09:45:38,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:39,522][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.02857741340994835, acc: 1.0)
[2024-11-13 09:45:39,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:40,224][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.03963292017579079, acc: 0.9824561476707458)
[2024-11-13 09:45:40,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:40,914][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.15549731254577637, acc: 0.9649122953414917)
[2024-11-13 09:45:41,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:41,600][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.007843629457056522, acc: 1.0)
[2024-11-13 09:45:41,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:42,290][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.02068750187754631, acc: 1.0)
[2024-11-13 09:45:42,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:42,973][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.0007984409458003938, acc: 1.0)
[2024-11-13 09:45:43,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:43,671][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.15872043371200562, acc: 0.920634925365448)
[2024-11-13 09:45:43,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:44,370][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 0.11050218343734741, acc: 0.9512194991111755)
[2024-11-13 09:45:44,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:45,060][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.05348726361989975, acc: 0.9838709831237793)
[2024-11-13 09:45:45,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:45,821][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 0.457454115152359, acc: 0.8669201731681824)
[2024-11-13 09:45:45,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:46,516][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.08870147168636322, acc: 0.9599999785423279)
[2024-11-13 09:45:46,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:47,216][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.04549653083086014, acc: 0.9807692170143127)
[2024-11-13 09:45:47,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:47,898][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.002429322339594364, acc: 1.0)
[2024-11-13 09:45:47,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:48,578][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.0830136314034462, acc: 0.9473684430122375)
[2024-11-13 09:45:48,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:49,281][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 0.49519091844558716, acc: 0.8773006200790405)
[2024-11-13 09:45:49,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:50,006][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 0.3782115578651428, acc: 0.875)
[2024-11-13 09:45:50,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:50,714][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 0.2620869576931, acc: 0.8833333253860474)
[2024-11-13 09:45:50,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:51,449][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 0.3470388948917389, acc: 0.9047619104385376)
[2024-11-13 09:45:51,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:52,172][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 0.35476356744766235, acc: 0.9076923131942749)
[2024-11-13 09:45:53,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:53,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:54,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:55,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:55,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:56,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:56,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:57,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:57,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:58,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:59,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:45:59,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:00,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:00,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:01,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:02,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:02,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:03,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:03,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:04,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:04,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:05,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:06,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:06,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:07,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:08,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:09,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:10,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:10,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:11,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:12,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:12,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:13,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:13,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:14,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:15,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:15,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:16,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:16,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:17,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:18,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:18,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:19,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:19,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:20,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:21,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:21,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:22,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:22,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:23,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:24,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:24,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:25,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:25,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:26,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:26,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:27,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:27,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:28,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:29,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:29,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:30,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:30,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:31,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:32,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:32,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:33,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:33,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:34,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:35,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:35,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:36,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:36,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:37,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:37,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:38,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:39,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:39,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:40,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:40,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:41,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:42,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:43,499][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1292, device='cuda:0') eval_epoch_loss=tensor(0.7557, device='cuda:0') eval_epoch_acc=tensor(0.8370, device='cuda:0')
[2024-11-13 09:46:43,501][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:46:43,501][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:46:43,850][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_129_loss_0.7557291388511658/model.pt
[2024-11-13 09:46:43,853][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:46:43,854][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.8369908332824707
[2024-11-13 09:46:43,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:44,589][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 0.4579751789569855, acc: 0.8382353186607361)
[2024-11-13 09:46:44,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:45,267][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.1577656865119934, acc: 0.9615384340286255)
[2024-11-13 09:46:45,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:45,937][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.002164694247767329, acc: 1.0)
[2024-11-13 09:46:46,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:46,611][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.1458459198474884, acc: 0.96875)
[2024-11-13 09:46:46,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:47,319][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.1269901543855667, acc: 0.95652174949646)
[2024-11-13 09:46:47,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:47,992][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.10834746062755585, acc: 0.9714285731315613)
[2024-11-13 09:46:48,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:48,663][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.06341412663459778, acc: 1.0)
[2024-11-13 09:46:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:49,340][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.06810624897480011, acc: 0.976190447807312)
[2024-11-13 09:46:49,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:50,011][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.08722281455993652, acc: 0.9666666388511658)
[2024-11-13 09:46:50,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:50,680][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.015972958877682686, acc: 1.0)
[2024-11-13 09:46:50,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:51,349][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.01845322735607624, acc: 1.0)
[2024-11-13 09:46:51,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:52,021][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.14649690687656403, acc: 0.9230769276618958)
[2024-11-13 09:46:52,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:52,693][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.08530347049236298, acc: 0.9677419066429138)
[2024-11-13 09:46:52,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:53,366][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.40361449122428894, acc: 0.8648648858070374)
[2024-11-13 09:46:53,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:54,076][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 0.2970621585845947, acc: 0.9122806787490845)
[2024-11-13 09:46:54,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:54,759][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 0.5280809998512268, acc: 0.8283582329750061)
[2024-11-13 09:46:54,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:55,446][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 0.14464247226715088, acc: 0.9693877696990967)
[2024-11-13 09:46:55,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:56,146][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 0.3072478175163269, acc: 0.8617021441459656)
[2024-11-13 09:46:56,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:56,841][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.19405129551887512, acc: 0.9428571462631226)
[2024-11-13 09:46:56,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:57,514][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.025177014991641045, acc: 1.0)
[2024-11-13 09:46:57,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:58,183][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.1134306937456131, acc: 0.95652174949646)
[2024-11-13 09:46:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:58,866][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.24887926876544952, acc: 0.8620689511299133)
[2024-11-13 09:46:58,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:46:59,540][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.4115530550479889, acc: 0.8695651888847351)
[2024-11-13 09:46:59,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:00,221][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.30872854590415955, acc: 0.8983050584793091)
[2024-11-13 09:47:00,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:00,901][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.22432482242584229, acc: 0.9473684430122375)
[2024-11-13 09:47:00,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:01,585][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 0.24797005951404572, acc: 0.9054054021835327)
[2024-11-13 09:47:01,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:02,257][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.011309708468616009, acc: 1.0)
[2024-11-13 09:47:02,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:02,938][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.0828947126865387, acc: 0.95652174949646)
[2024-11-13 09:47:03,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:03,606][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.0888945460319519, acc: 0.9473684430122375)
[2024-11-13 09:47:03,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:04,283][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 0.21818462014198303, acc: 0.9189189076423645)
[2024-11-13 09:47:04,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:04,960][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 0.11719542741775513, acc: 0.9629629850387573)
[2024-11-13 09:47:05,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:05,638][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 0.08930286765098572, acc: 0.9767441749572754)
[2024-11-13 09:47:05,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:06,317][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 0.1411147564649582, acc: 0.929411768913269)
[2024-11-13 09:47:06,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:07,003][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 0.3179442584514618, acc: 0.8764045238494873)
[2024-11-13 09:47:07,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:07,678][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.09082958102226257, acc: 0.9772727489471436)
[2024-11-13 09:47:07,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:08,349][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.5969778895378113, acc: 0.8571428656578064)
[2024-11-13 09:47:08,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:09,020][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.06050145998597145, acc: 0.9655172228813171)
[2024-11-13 09:47:09,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:09,705][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.07744758576154709, acc: 0.9795918464660645)
[2024-11-13 09:47:09,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:10,379][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.04798676073551178, acc: 0.9800000190734863)
[2024-11-13 09:47:10,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:11,072][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.19883590936660767, acc: 0.9166666865348816)
[2024-11-13 09:47:11,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:11,770][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 0.5195363163948059, acc: 0.8921568393707275)
[2024-11-13 09:47:11,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:12,502][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.043419599533081, acc: 0.6712328791618347)
[2024-11-13 09:47:12,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:13,186][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.007535887882113457, acc: 1.0)
[2024-11-13 09:47:13,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:13,856][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.09723488241434097, acc: 0.9629629850387573)
[2024-11-13 09:47:13,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:14,524][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.22802023589611053, acc: 0.8928571343421936)
[2024-11-13 09:47:14,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:15,234][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 0.33686473965644836, acc: 0.8849557638168335)
[2024-11-13 09:47:15,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:15,913][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 0.04992055892944336, acc: 0.9855072498321533)
[2024-11-13 09:47:16,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:16,596][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 0.10728207230567932, acc: 0.9659090638160706)
[2024-11-13 09:47:16,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:17,303][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 0.5568249821662903, acc: 0.8167939186096191)
[2024-11-13 09:47:17,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:18,006][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 0.3919805884361267, acc: 0.8592592477798462)
[2024-11-13 09:47:18,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:18,686][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.04552863538265228, acc: 0.9836065769195557)
[2024-11-13 09:47:18,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:19,356][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.1639070063829422, acc: 0.9583333134651184)
[2024-11-13 09:47:19,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:20,029][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.004296632017940283, acc: 1.0)
[2024-11-13 09:47:20,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:20,702][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.26187893748283386, acc: 0.9642857313156128)
[2024-11-13 09:47:20,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:21,397][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 0.16961921751499176, acc: 0.9634146094322205)
[2024-11-13 09:47:21,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:22,124][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 0.4972829222679138, acc: 0.8549848794937134)
[2024-11-13 09:47:22,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:22,848][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 0.5128746628761292, acc: 0.8559077978134155)
[2024-11-13 09:47:22,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:23,573][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 0.47817888855934143, acc: 0.862500011920929)
[2024-11-13 09:47:23,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:24,338][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 0.7769272923469543, acc: 0.7936210036277771)
[2024-11-13 09:47:24,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:25,077][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 0.352522611618042, acc: 0.8967971801757812)
[2024-11-13 09:47:25,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:25,754][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.028664054349064827, acc: 1.0)
[2024-11-13 09:47:25,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:26,438][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 0.24462613463401794, acc: 0.9418604373931885)
[2024-11-13 09:47:26,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:27,136][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 0.5888819694519043, acc: 0.8253968358039856)
[2024-11-13 09:47:27,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:27,826][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 0.49872779846191406, acc: 0.8333333134651184)
[2024-11-13 09:47:27,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:28,506][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 0.18619409203529358, acc: 0.9529411792755127)
[2024-11-13 09:47:28,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:29,210][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 0.48684245347976685, acc: 0.8518518805503845)
[2024-11-13 09:47:29,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:29,900][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 0.23851461708545685, acc: 0.9032257795333862)
[2024-11-13 09:47:29,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:30,576][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.2807665169239044, acc: 0.9642857313156128)
[2024-11-13 09:47:30,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:31,250][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.14835381507873535, acc: 0.949999988079071)
[2024-11-13 09:47:31,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:31,930][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 0.11533911526203156, acc: 0.970588207244873)
[2024-11-13 09:47:32,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:32,631][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 0.22934021055698395, acc: 0.904411792755127)
[2024-11-13 09:47:32,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:33,317][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 0.3509266972541809, acc: 0.8983050584793091)
[2024-11-13 09:47:33,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:34,006][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 0.17446668446063995, acc: 0.9552238583564758)
[2024-11-13 09:47:34,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:34,705][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 0.31563252210617065, acc: 0.9029126167297363)
[2024-11-13 09:47:34,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:35,389][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 0.23383654654026031, acc: 0.9365079402923584)
[2024-11-13 09:47:35,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:36,087][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 0.035658106207847595, acc: 0.9890109896659851)
[2024-11-13 09:47:36,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:36,806][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 0.16752298176288605, acc: 0.9327354431152344)
[2024-11-13 09:47:36,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:37,532][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 0.26687270402908325, acc: 0.9212598204612732)
[2024-11-13 09:47:37,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:38,239][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 0.08624114096164703, acc: 0.982758641242981)
[2024-11-13 09:47:38,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:38,949][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 0.26374009251594543, acc: 0.9275362491607666)
[2024-11-13 09:47:39,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:39,668][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 0.20599913597106934, acc: 0.9377431869506836)
[2024-11-13 09:47:39,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:40,377][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 0.04485384747385979, acc: 0.989130437374115)
[2024-11-13 09:47:40,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:41,053][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.149286687374115, acc: 0.95652174949646)
[2024-11-13 09:47:41,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:41,729][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.00792383961379528, acc: 1.0)
[2024-11-13 09:47:41,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:42,407][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.010554724372923374, acc: 1.0)
[2024-11-13 09:47:42,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:43,105][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 0.09698998183012009, acc: 0.9692307710647583)
[2024-11-13 09:47:43,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:43,785][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.07306642830371857, acc: 0.9729729890823364)
[2024-11-13 09:47:43,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:44,464][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.07045760750770569, acc: 0.9883720874786377)
[2024-11-13 09:47:44,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:45,163][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 0.07344915717840195, acc: 0.9819819927215576)
[2024-11-13 09:47:45,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:45,847][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.02106054313480854, acc: 0.9888888597488403)
[2024-11-13 09:47:45,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:46,524][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.017372626811265945, acc: 1.0)
[2024-11-13 09:47:46,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:47,194][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.004908195696771145, acc: 1.0)
[2024-11-13 09:47:47,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:47,865][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.00380271440371871, acc: 1.0)
[2024-11-13 09:47:47,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:48,545][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.14141498506069183, acc: 0.942307710647583)
[2024-11-13 09:47:48,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:49,257][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 0.34992334246635437, acc: 0.885869562625885)
[2024-11-13 09:47:49,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:49,962][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 0.33727696537971497, acc: 0.9261363744735718)
[2024-11-13 09:47:50,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:50,667][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 0.29277950525283813, acc: 0.8829787373542786)
[2024-11-13 09:47:50,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:51,344][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.2133210003376007, acc: 0.9245283007621765)
[2024-11-13 09:47:51,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:52,020][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.2004999816417694, acc: 0.9333333373069763)
[2024-11-13 09:47:52,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:52,702][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.02770949713885784, acc: 0.9767441749572754)
[2024-11-13 09:47:52,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:53,375][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 0.13729621469974518, acc: 0.9333333373069763)
[2024-11-13 09:47:53,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:54,068][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 0.4510653018951416, acc: 0.8736842274665833)
[2024-11-13 09:47:54,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:54,742][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 0.24787959456443787, acc: 0.9111111164093018)
[2024-11-13 09:47:54,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:55,448][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 0.41832488775253296, acc: 0.8833333253860474)
[2024-11-13 09:47:55,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:56,159][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.011526346206665, acc: 0.7339449524879456)
[2024-11-13 09:47:56,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:56,872][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 0.5665968060493469, acc: 0.7923076748847961)
[2024-11-13 09:47:56,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:57,543][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.010026119649410248, acc: 1.0)
[2024-11-13 09:47:57,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:58,210][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.01109478622674942, acc: 1.0)
[2024-11-13 09:47:58,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:58,877][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.01424440834671259, acc: 1.0)
[2024-11-13 09:47:58,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:47:59,559][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.0296707134693861, acc: 1.0)
[2024-11-13 09:47:59,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:00,234][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.029430504888296127, acc: 1.0)
[2024-11-13 09:48:00,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:00,910][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.0947709009051323, acc: 0.9772727489471436)
[2024-11-13 09:48:00,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:01,579][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.06161528453230858, acc: 1.0)
[2024-11-13 09:48:01,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:02,258][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.4061526954174042, acc: 0.9032257795333862)
[2024-11-13 09:48:02,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:02,934][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.36661168932914734, acc: 0.8863636255264282)
[2024-11-13 09:48:03,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:03,603][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.009617676958441734, acc: 1.0)
[2024-11-13 09:48:03,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:04,274][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.010055264458060265, acc: 1.0)
[2024-11-13 09:48:04,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:04,944][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.004486134275794029, acc: 1.0)
[2024-11-13 09:48:05,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:05,612][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.012643462046980858, acc: 1.0)
[2024-11-13 09:48:05,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:06,288][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.06400782614946365, acc: 0.9729729890823364)
[2024-11-13 09:48:06,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:06,955][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.02362576499581337, acc: 1.0)
[2024-11-13 09:48:07,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:07,627][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.006400227081030607, acc: 1.0)
[2024-11-13 09:48:07,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:08,310][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.1988711953163147, acc: 0.9264705777168274)
[2024-11-13 09:48:08,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:08,984][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.02562250755727291, acc: 1.0)
[2024-11-13 09:48:09,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:09,654][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.012469513341784477, acc: 1.0)
[2024-11-13 09:48:09,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:10,323][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.002436696784570813, acc: 1.0)
[2024-11-13 09:48:10,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:11,007][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.004237181507050991, acc: 1.0)
[2024-11-13 09:48:11,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:11,684][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.0447949580848217, acc: 0.9824561476707458)
[2024-11-13 09:48:11,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:12,359][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.019672896713018417, acc: 1.0)
[2024-11-13 09:48:12,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:13,049][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.06291989237070084, acc: 0.9868420958518982)
[2024-11-13 09:48:13,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:13,759][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 0.22128114104270935, acc: 0.9528301954269409)
[2024-11-13 09:48:13,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:14,467][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 0.16978782415390015, acc: 0.9583333134651184)
[2024-11-13 09:48:14,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:15,143][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.019565524533391, acc: 1.0)
[2024-11-13 09:48:15,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:15,816][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.03147009760141373, acc: 1.0)
[2024-11-13 09:48:15,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:16,513][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 0.2746860384941101, acc: 0.8933333158493042)
[2024-11-13 09:48:16,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:17,187][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.23063014447689056, acc: 0.9375)
[2024-11-13 09:48:17,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:17,898][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 0.6966041326522827, acc: 0.7919999957084656)
[2024-11-13 09:48:17,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:18,576][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 0.42671114206314087, acc: 0.8876404762268066)
[2024-11-13 09:48:18,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:19,255][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 0.40683165192604065, acc: 0.8648648858070374)
[2024-11-13 09:48:19,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:19,937][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.22376367449760437, acc: 0.931034505367279)
[2024-11-13 09:48:20,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:20,606][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.014604538679122925, acc: 1.0)
[2024-11-13 09:48:20,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:21,277][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.0018311963649466634, acc: 1.0)
[2024-11-13 09:48:21,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:21,948][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.05462087318301201, acc: 0.96875)
[2024-11-13 09:48:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:23,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:24,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:24,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:25,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:25,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:26,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:27,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:27,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:28,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:29,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:30,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:30,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:31,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:31,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:32,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:33,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:33,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:34,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:34,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:35,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:35,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:36,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:37,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:37,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:38,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:38,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:39,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:40,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:40,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:41,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:42,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:42,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:43,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:43,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:44,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:44,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:46,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:46,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:47,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:48,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:49,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:49,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:50,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:50,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:51,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:51,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:52,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:53,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:53,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:54,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:54,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:55,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:56,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:56,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:57,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:57,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:58,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:59,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:48:59,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:00,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:00,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:01,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:02,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:02,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:03,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:03,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:04,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:04,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:05,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:06,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:06,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:07,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:07,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:08,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:09,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:10,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:10,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:11,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:11,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:12,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:13,500][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1141, device='cuda:0') eval_epoch_loss=tensor(0.7486, device='cuda:0') eval_epoch_acc=tensor(0.8299, device='cuda:0')
[2024-11-13 09:49:13,501][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:49:13,501][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:49:13,841][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_272_loss_0.7486421465873718/model.pt
[2024-11-13 09:49:13,845][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:49:13,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:14,570][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.0016805813647806644, acc: 1.0)
[2024-11-13 09:49:14,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:15,264][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.3034239411354065, acc: 0.9333333373069763)
[2024-11-13 09:49:15,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:15,937][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.02515352889895439, acc: 1.0)
[2024-11-13 09:49:16,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:16,608][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.0014100545085966587, acc: 1.0)
[2024-11-13 09:49:16,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:17,280][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.04568149149417877, acc: 0.9655172228813171)
[2024-11-13 09:49:17,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:17,963][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.0034814930986613035, acc: 1.0)
[2024-11-13 09:49:18,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:18,641][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.05718544125556946, acc: 0.978723406791687)
[2024-11-13 09:49:18,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:19,368][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.2427559494972229, acc: 0.9166666865348816)
[2024-11-13 09:49:19,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:20,043][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.02094080112874508, acc: 1.0)
[2024-11-13 09:49:20,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:20,727][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 0.277997761964798, acc: 0.9156626462936401)
[2024-11-13 09:49:20,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:21,413][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 0.28605014085769653, acc: 0.8981481194496155)
[2024-11-13 09:49:21,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:22,084][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.024742117151618004, acc: 1.0)
[2024-11-13 09:49:22,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:22,755][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.027457717806100845, acc: 1.0)
[2024-11-13 09:49:22,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:23,440][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.07237298786640167, acc: 0.949999988079071)
[2024-11-13 09:49:23,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:24,138][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 0.1268990933895111, acc: 0.9453125)
[2024-11-13 09:49:24,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:24,839][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 0.230572909116745, acc: 0.9279999732971191)
[2024-11-13 09:49:24,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:25,531][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 0.0984540656208992, acc: 0.9780219793319702)
[2024-11-13 09:49:25,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:26,218][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 0.11816118657588959, acc: 0.9627329111099243)
[2024-11-13 09:49:26,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:26,926][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 0.24703869223594666, acc: 0.9278350472450256)
[2024-11-13 09:49:27,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:27,610][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.029587555676698685, acc: 1.0)
[2024-11-13 09:49:27,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:28,285][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.03767921403050423, acc: 1.0)
[2024-11-13 09:49:28,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:28,966][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.0029340425971895456, acc: 1.0)
[2024-11-13 09:49:29,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:29,648][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.07232650369405746, acc: 0.9636363387107849)
[2024-11-13 09:49:29,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:30,369][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 0.366366446018219, acc: 0.8814433217048645)
[2024-11-13 09:49:30,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:31,051][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.08568543195724487, acc: 0.9655172228813171)
[2024-11-13 09:49:31,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:31,721][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.003597165457904339, acc: 1.0)
[2024-11-13 09:49:31,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:32,397][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.13334590196609497, acc: 0.9473684430122375)
[2024-11-13 09:49:32,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:33,072][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.02257605455815792, acc: 1.0)
[2024-11-13 09:49:33,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:33,744][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.0019105869578197598, acc: 1.0)
[2024-11-13 09:49:33,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:34,428][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.02896316722035408, acc: 0.9811320900917053)
[2024-11-13 09:49:34,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:35,103][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.025270264595746994, acc: 1.0)
[2024-11-13 09:49:35,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:35,774][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.002257721032947302, acc: 1.0)
[2024-11-13 09:49:35,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:36,447][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.16738715767860413, acc: 0.96875)
[2024-11-13 09:49:36,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:37,133][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.1217261329293251, acc: 0.9180327653884888)
[2024-11-13 09:49:37,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:37,804][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.01055870484560728, acc: 1.0)
[2024-11-13 09:49:37,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:38,472][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.0016357465647161007, acc: 1.0)
[2024-11-13 09:49:38,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:39,165][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.06959414482116699, acc: 0.9710144996643066)
[2024-11-13 09:49:39,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:39,851][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 0.19751250743865967, acc: 0.9444444179534912)
[2024-11-13 09:49:39,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:40,542][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.1809362918138504, acc: 0.9277108311653137)
[2024-11-13 09:49:40,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:41,227][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 0.05867647007107735, acc: 0.9871794581413269)
[2024-11-13 09:49:41,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:41,932][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 0.047989875078201294, acc: 0.9897959232330322)
[2024-11-13 09:49:42,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:42,616][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.0013588235015049577, acc: 1.0)
[2024-11-13 09:49:42,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:43,288][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.0030694345477968454, acc: 1.0)
[2024-11-13 09:49:43,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:43,963][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.004319005645811558, acc: 1.0)
[2024-11-13 09:49:44,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:44,638][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.0027107284404337406, acc: 1.0)
[2024-11-13 09:49:44,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:45,317][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.046943504363298416, acc: 0.9701492786407471)
[2024-11-13 09:49:45,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:46,002][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.048509299755096436, acc: 0.9807692170143127)
[2024-11-13 09:49:46,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:46,674][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.04513174667954445, acc: 0.9555555582046509)
[2024-11-13 09:49:46,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:47,352][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.028522713109850883, acc: 1.0)
[2024-11-13 09:49:47,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:48,031][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.013096148148179054, acc: 1.0)
[2024-11-13 09:49:48,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:48,703][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.029769130051136017, acc: 1.0)
[2024-11-13 09:49:48,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:49,376][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 0.05427227541804314, acc: 1.0)
[2024-11-13 09:49:49,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:50,053][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.10526277124881744, acc: 0.9743589758872986)
[2024-11-13 09:49:50,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:50,732][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 0.0986783355474472, acc: 0.9756097793579102)
[2024-11-13 09:49:50,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:51,406][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.08230474591255188, acc: 0.9473684430122375)
[2024-11-13 09:49:51,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:52,075][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.016563111916184425, acc: 1.0)
[2024-11-13 09:49:52,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:52,745][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.0071626813150942326, acc: 1.0)
[2024-11-13 09:49:52,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:53,415][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.004643100779503584, acc: 1.0)
[2024-11-13 09:49:53,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:54,087][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.0072992476634681225, acc: 1.0)
[2024-11-13 09:49:54,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:54,767][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.05576249957084656, acc: 0.9838709831237793)
[2024-11-13 09:49:54,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:55,448][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.006604956462979317, acc: 1.0)
[2024-11-13 09:49:55,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:56,126][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.027399051934480667, acc: 1.0)
[2024-11-13 09:49:56,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:56,801][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.005209656897932291, acc: 1.0)
[2024-11-13 09:49:56,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:57,473][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.07477257400751114, acc: 0.9473684430122375)
[2024-11-13 09:49:57,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:58,153][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.04805130511522293, acc: 1.0)
[2024-11-13 09:49:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:58,839][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 0.3102782368659973, acc: 0.8965517282485962)
[2024-11-13 09:49:58,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:49:59,523][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 0.5120161175727844, acc: 0.8510638475418091)
[2024-11-13 09:49:59,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:00,207][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 0.42898184061050415, acc: 0.8674699068069458)
[2024-11-13 09:50:00,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:00,881][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.0019843396730720997, acc: 1.0)
[2024-11-13 09:50:00,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:01,572][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.010872012935578823, acc: 1.0)
[2024-11-13 09:50:01,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:02,251][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 0.1318574696779251, acc: 0.9759036302566528)
[2024-11-13 09:50:02,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:02,930][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.0536111518740654, acc: 0.9811320900917053)
[2024-11-13 09:50:03,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:03,606][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.07632318139076233, acc: 0.9873417615890503)
[2024-11-13 09:50:03,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:04,327][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.04076169431209564, acc: 0.9803921580314636)
[2024-11-13 09:50:04,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:05,011][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 0.12275506556034088, acc: 0.9701492786407471)
[2024-11-13 09:50:05,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:05,681][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.01598609797656536, acc: 1.0)
[2024-11-13 09:50:05,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:06,352][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.03724044933915138, acc: 1.0)
[2024-11-13 09:50:06,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:07,025][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.24554960429668427, acc: 0.9166666865348816)
[2024-11-13 09:50:07,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:07,706][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.05784081295132637, acc: 1.0)
[2024-11-13 09:50:07,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:08,382][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.009251016192138195, acc: 1.0)
[2024-11-13 09:50:08,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:09,062][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.21633709967136383, acc: 0.9333333373069763)
[2024-11-13 09:50:09,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:09,732][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.0014192168600857258, acc: 1.0)
[2024-11-13 09:50:09,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:10,416][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.007760218810290098, acc: 1.0)
[2024-11-13 09:50:10,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:11,110][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 0.15755899250507355, acc: 0.9560439586639404)
[2024-11-13 09:50:11,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:11,821][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 0.2817671298980713, acc: 0.9130434989929199)
[2024-11-13 09:50:11,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:12,503][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 0.1840810328722, acc: 0.945652186870575)
[2024-11-13 09:50:12,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:13,177][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.23613139986991882, acc: 0.918367326259613)
[2024-11-13 09:50:13,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:13,869][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.0004151157627347857, acc: 1.0)
[2024-11-13 09:50:13,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:14,553][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.004562553483992815, acc: 1.0)
[2024-11-13 09:50:14,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:15,228][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.051564112305641174, acc: 0.9756097793579102)
[2024-11-13 09:50:15,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:15,903][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.02472173422574997, acc: 1.0)
[2024-11-13 09:50:15,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:16,596][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 0.029348963871598244, acc: 1.0)
[2024-11-13 09:50:16,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:17,274][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.04371378570795059, acc: 1.0)
[2024-11-13 09:50:17,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:17,949][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.016900237649679184, acc: 1.0)
[2024-11-13 09:50:18,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:18,628][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.0008368580602109432, acc: 1.0)
[2024-11-13 09:50:18,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:19,298][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.00031960918568074703, acc: 1.0)
[2024-11-13 09:50:19,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:19,971][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.03726765885949135, acc: 0.9642857313156128)
[2024-11-13 09:50:20,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:20,647][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.007135777268558741, acc: 1.0)
[2024-11-13 09:50:20,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:21,363][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 0.23538954555988312, acc: 0.939393937587738)
[2024-11-13 09:50:21,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:22,068][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 0.21907824277877808, acc: 0.9245283007621765)
[2024-11-13 09:50:22,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:22,757][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.019945017993450165, acc: 1.0)
[2024-11-13 09:50:22,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:23,451][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.03612348809838295, acc: 1.0)
[2024-11-13 09:50:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:24,131][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.02457878179848194, acc: 1.0)
[2024-11-13 09:50:24,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:24,805][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.00045305286766961217, acc: 1.0)
[2024-11-13 09:50:24,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:25,473][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.0025016998406499624, acc: 1.0)
[2024-11-13 09:50:25,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:26,149][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.033062566071748734, acc: 1.0)
[2024-11-13 09:50:26,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:26,832][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 0.03340596705675125, acc: 0.9894737005233765)
[2024-11-13 09:50:26,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:27,543][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 0.20302696526050568, acc: 0.946107804775238)
[2024-11-13 09:50:27,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:28,232][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.19856233894824982, acc: 0.9624060392379761)
[2024-11-13 09:50:28,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:28,951][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 0.5576987266540527, acc: 0.8395721912384033)
[2024-11-13 09:50:29,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:29,653][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.12886333465576172, acc: 0.9819819927215576)
[2024-11-13 09:50:29,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:30,334][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.0042396122589707375, acc: 1.0)
[2024-11-13 09:50:30,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:31,005][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.0009770509786903858, acc: 1.0)
[2024-11-13 09:50:31,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:31,679][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.07999340444803238, acc: 0.96875)
[2024-11-13 09:50:31,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:32,350][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.007080228067934513, acc: 1.0)
[2024-11-13 09:50:32,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:33,030][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.09468620270490646, acc: 0.9210526347160339)
[2024-11-13 09:50:33,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:33,700][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.015898263081908226, acc: 1.0)
[2024-11-13 09:50:33,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:34,369][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.0006133307470008731, acc: 1.0)
[2024-11-13 09:50:34,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:35,086][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.09388986229896545, acc: 0.9523809552192688)
[2024-11-13 09:50:35,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:35,772][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.20657247304916382, acc: 0.9629629850387573)
[2024-11-13 09:50:35,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:36,469][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 0.2311972826719284, acc: 0.9320388436317444)
[2024-11-13 09:50:36,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:37,182][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 0.574834406375885, acc: 0.8382353186607361)
[2024-11-13 09:50:37,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:37,867][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 0.382232666015625, acc: 0.8600000143051147)
[2024-11-13 09:50:37,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:38,556][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 0.3142716884613037, acc: 0.9236111044883728)
[2024-11-13 09:50:38,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:39,229][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.028011692687869072, acc: 0.9767441749572754)
[2024-11-13 09:50:39,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:39,909][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.0026667325291782618, acc: 1.0)
[2024-11-13 09:50:40,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:40,586][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.18113642930984497, acc: 0.9534883499145508)
[2024-11-13 09:50:40,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:41,253][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.0027959796134382486, acc: 1.0)
[2024-11-13 09:50:41,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:41,950][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.13596859574317932, acc: 0.9411764740943909)
[2024-11-13 09:50:42,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:42,635][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.2813676595687866, acc: 0.9066666960716248)
[2024-11-13 09:50:42,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:43,307][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.004462013486772776, acc: 1.0)
[2024-11-13 09:50:43,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:43,982][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.008445818908512592, acc: 1.0)
[2024-11-13 09:50:44,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:44,652][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.004446611274033785, acc: 1.0)
[2024-11-13 09:50:44,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:45,324][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.0016991038573905826, acc: 1.0)
[2024-11-13 09:50:45,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:45,995][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.0038409826811403036, acc: 1.0)
[2024-11-13 09:50:46,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:46,715][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.0018948265351355076, acc: 1.0)
[2024-11-13 09:50:46,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:47,389][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.006002782844007015, acc: 1.0)
[2024-11-13 09:50:47,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:48,079][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.02508429065346718, acc: 1.0)
[2024-11-13 09:50:48,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:48,760][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.019902881234884262, acc: 1.0)
[2024-11-13 09:50:48,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:49,431][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.0017689393134787679, acc: 1.0)
[2024-11-13 09:50:49,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:50,104][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.007385663688182831, acc: 1.0)
[2024-11-13 09:50:50,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:50,774][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.08147373050451279, acc: 0.9696969985961914)
[2024-11-13 09:50:50,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:51,441][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.008888360112905502, acc: 1.0)
[2024-11-13 09:50:52,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:52,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:53,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:54,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:54,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:55,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:55,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:56,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:56,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:57,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:58,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:58,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:59,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:50:59,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:00,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:01,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:01,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:02,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:02,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:03,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:03,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:04,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:05,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:05,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:06,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:06,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:07,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:08,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:08,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:09,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:09,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:10,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:11,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:11,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:12,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:12,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:13,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:14,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:14,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:15,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:15,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:16,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:16,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:17,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:18,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:18,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:19,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:20,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:20,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:21,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:21,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:22,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:22,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:23,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:24,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:24,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:25,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:26,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:26,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:27,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:27,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:28,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:29,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:29,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:30,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:30,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:31,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:31,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:32,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:33,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:33,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:34,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:34,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:35,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:36,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:36,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:37,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:37,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:38,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:39,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:39,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:40,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:40,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:41,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:41,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:42,785][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1840, device='cuda:0') eval_epoch_loss=tensor(0.7811, device='cuda:0') eval_epoch_acc=tensor(0.8203, device='cuda:0')
[2024-11-13 09:51:42,787][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:51:42,787][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:51:43,373][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_415_loss_0.7811367511749268/model.pt
[2024-11-13 09:51:43,377][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:51:43,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:44,077][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.0647028312087059, acc: 0.9607843160629272)
[2024-11-13 09:51:44,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:44,747][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.04793207347393036, acc: 0.9615384340286255)
[2024-11-13 09:51:44,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:45,414][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.010670801624655724, acc: 1.0)
[2024-11-13 09:51:45,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:46,090][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.048290178179740906, acc: 0.949999988079071)
[2024-11-13 09:51:46,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:46,762][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.006309374235570431, acc: 1.0)
[2024-11-13 09:51:46,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:47,430][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.0015210489509627223, acc: 1.0)
[2024-11-13 09:51:47,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:48,102][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.03755416348576546, acc: 1.0)
[2024-11-13 09:51:48,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:48,771][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.004500524140894413, acc: 1.0)
[2024-11-13 09:51:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:49,442][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.11643774062395096, acc: 0.9722222089767456)
[2024-11-13 09:51:49,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:50,115][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.2134532779455185, acc: 0.9629629850387573)
[2024-11-13 09:51:50,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:50,792][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.02388645149767399, acc: 1.0)
[2024-11-13 09:51:50,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:51,471][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 0.012895270250737667, acc: 1.0)
[2024-11-13 09:51:51,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:52,149][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.047346096485853195, acc: 0.9729729890823364)
[2024-11-13 09:51:52,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:52,821][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.0012644308153539896, acc: 1.0)
[2024-11-13 09:51:52,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:53,492][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.004491242580115795, acc: 1.0)
[2024-11-13 09:51:53,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:54,164][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.0015197935281321406, acc: 1.0)
[2024-11-13 09:51:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:54,833][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.0016855155117809772, acc: 1.0)
[2024-11-13 09:51:54,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:55,510][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.0006773298955522478, acc: 1.0)
[2024-11-13 09:51:55,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:56,196][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.06756780296564102, acc: 0.9722222089767456)
[2024-11-13 09:51:56,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:56,866][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.005125758703798056, acc: 1.0)
[2024-11-13 09:51:56,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:57,537][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.0034937963355332613, acc: 1.0)
[2024-11-13 09:51:57,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:58,209][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.024520268663764, acc: 1.0)
[2024-11-13 09:51:58,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:58,883][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.05523620918393135, acc: 0.9545454382896423)
[2024-11-13 09:51:58,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:51:59,550][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.003137623891234398, acc: 1.0)
[2024-11-13 09:51:59,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:00,232][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.03230515494942665, acc: 0.9743589758872986)
[2024-11-13 09:52:00,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:00,919][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 0.027132144197821617, acc: 1.0)
[2024-11-13 09:52:01,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:01,627][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 0.6305542588233948, acc: 0.8240000009536743)
[2024-11-13 09:52:01,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:02,314][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 0.5031380653381348, acc: 0.8709677457809448)
[2024-11-13 09:52:02,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:03,030][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 0.31151044368743896, acc: 0.9154228568077087)
[2024-11-13 09:52:03,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:03,715][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.012638461776077747, acc: 1.0)
[2024-11-13 09:52:03,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:04,392][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.016461191698908806, acc: 1.0)
[2024-11-13 09:52:04,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:05,062][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.001916009234264493, acc: 1.0)
[2024-11-13 09:52:05,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:05,748][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.005247621797025204, acc: 1.0)
[2024-11-13 09:52:05,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:06,423][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.0022621932439506054, acc: 1.0)
[2024-11-13 09:52:06,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:07,106][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.11589954793453217, acc: 0.9701492786407471)
[2024-11-13 09:52:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:07,783][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.01726321130990982, acc: 1.0)
[2024-11-13 09:52:07,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:08,467][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.02985137701034546, acc: 0.989130437374115)
[2024-11-13 09:52:08,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:09,146][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.037308309227228165, acc: 1.0)
[2024-11-13 09:52:09,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:09,828][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.06442465633153915, acc: 0.9736841917037964)
[2024-11-13 09:52:09,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:10,502][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.005592622794210911, acc: 1.0)
[2024-11-13 09:52:10,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:11,174][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.04521910473704338, acc: 1.0)
[2024-11-13 09:52:11,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:11,857][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 0.15708890557289124, acc: 0.9484536051750183)
[2024-11-13 09:52:11,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:12,536][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.008039738051593304, acc: 1.0)
[2024-11-13 09:52:12,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:13,260][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 0.18525061011314392, acc: 0.9476743936538696)
[2024-11-13 09:52:13,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:13,940][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.05453374981880188, acc: 0.9821428656578064)
[2024-11-13 09:52:14,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:14,632][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 0.05442099645733833, acc: 0.9753086566925049)
[2024-11-13 09:52:14,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:15,311][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.01907944306731224, acc: 1.0)
[2024-11-13 09:52:15,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:15,987][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.005902259610593319, acc: 1.0)
[2024-11-13 09:52:16,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:16,656][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.017453940585255623, acc: 1.0)
[2024-11-13 09:52:16,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:17,333][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.01899387501180172, acc: 1.0)
[2024-11-13 09:52:17,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:18,012][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.10594972223043442, acc: 0.976190447807312)
[2024-11-13 09:52:18,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:18,692][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.04005458205938339, acc: 0.9879518151283264)
[2024-11-13 09:52:18,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:19,398][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.08028338849544525, acc: 0.9819819927215576)
[2024-11-13 09:52:19,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:20,090][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 0.1449103057384491, acc: 0.9708737730979919)
[2024-11-13 09:52:20,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:20,805][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.1912602335214615, acc: 0.9105691313743591)
[2024-11-13 09:52:20,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:21,479][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.013689079321920872, acc: 1.0)
[2024-11-13 09:52:21,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:22,149][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.006965381093323231, acc: 1.0)
[2024-11-13 09:52:22,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:22,859][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 0.4424325227737427, acc: 0.8627451062202454)
[2024-11-13 09:52:22,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:23,573][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 0.4911535382270813, acc: 0.847161591053009)
[2024-11-13 09:52:23,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:24,261][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 0.1176813542842865, acc: 0.9583333134651184)
[2024-11-13 09:52:24,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:24,957][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 0.11669433861970901, acc: 0.9570552110671997)
[2024-11-13 09:52:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:25,652][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 0.08442523330450058, acc: 0.9784172773361206)
[2024-11-13 09:52:25,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:26,360][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 0.33635079860687256, acc: 0.8743718862533569)
[2024-11-13 09:52:26,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:27,035][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.019222239032387733, acc: 1.0)
[2024-11-13 09:52:27,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:27,709][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.012645719572901726, acc: 1.0)
[2024-11-13 09:52:27,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:28,383][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.03580182418227196, acc: 0.9629629850387573)
[2024-11-13 09:52:28,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:29,058][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.10356428474187851, acc: 1.0)
[2024-11-13 09:52:29,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:29,732][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.011107871308922768, acc: 1.0)
[2024-11-13 09:52:29,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:30,416][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.14848490059375763, acc: 0.9482758641242981)
[2024-11-13 09:52:30,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:31,086][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.0013363962061703205, acc: 1.0)
[2024-11-13 09:52:31,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:31,762][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.17269307374954224, acc: 0.9473684430122375)
[2024-11-13 09:52:31,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:32,437][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.027308305725455284, acc: 1.0)
[2024-11-13 09:52:32,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:33,114][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.023271922022104263, acc: 1.0)
[2024-11-13 09:52:33,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:33,791][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.00733582628890872, acc: 1.0)
[2024-11-13 09:52:33,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:34,478][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.12845750153064728, acc: 0.9538461565971375)
[2024-11-13 09:52:34,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:35,166][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.004352058283984661, acc: 1.0)
[2024-11-13 09:52:35,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:35,842][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.28147780895233154, acc: 0.931034505367279)
[2024-11-13 09:52:35,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:36,517][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.10223554074764252, acc: 0.9607843160629272)
[2024-11-13 09:52:36,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:37,193][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.15315602719783783, acc: 0.931034505367279)
[2024-11-13 09:52:37,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:37,866][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.02962988242506981, acc: 1.0)
[2024-11-13 09:52:37,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:38,556][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.045215003192424774, acc: 1.0)
[2024-11-13 09:52:38,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:39,244][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 0.2789853513240814, acc: 0.9196428656578064)
[2024-11-13 09:52:39,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:39,943][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 0.21223406493663788, acc: 0.9550561904907227)
[2024-11-13 09:52:40,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:40,638][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 0.17129510641098022, acc: 0.9213483333587646)
[2024-11-13 09:52:40,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:41,344][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 0.4057255685329437, acc: 0.8936170339584351)
[2024-11-13 09:52:41,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:42,036][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 0.17717662453651428, acc: 0.945652186870575)
[2024-11-13 09:52:42,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:42,720][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.47947368025779724, acc: 0.9599999785423279)
[2024-11-13 09:52:42,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:43,391][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.0019621916580945253, acc: 1.0)
[2024-11-13 09:52:43,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:44,077][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.0025207099970430136, acc: 1.0)
[2024-11-13 09:52:44,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:44,757][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.0029453944880515337, acc: 1.0)
[2024-11-13 09:52:44,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:45,434][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.032894719392061234, acc: 0.9811320900917053)
[2024-11-13 09:52:45,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:46,104][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.009071283973753452, acc: 1.0)
[2024-11-13 09:52:46,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:46,799][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 0.30234476923942566, acc: 0.9099099040031433)
[2024-11-13 09:52:46,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:47,492][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 0.08740269392728806, acc: 0.9577465057373047)
[2024-11-13 09:52:47,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:48,167][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.0007328928331844509, acc: 1.0)
[2024-11-13 09:52:48,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:48,837][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.033183950930833817, acc: 1.0)
[2024-11-13 09:52:48,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:49,523][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.018959971144795418, acc: 1.0)
[2024-11-13 09:52:49,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:50,268][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 1.1829216480255127, acc: 0.6499999761581421)
[2024-11-13 09:52:50,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:50,974][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 0.2072155773639679, acc: 0.9444444179534912)
[2024-11-13 09:52:51,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:51,644][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.23744532465934753, acc: 0.9642857313156128)
[2024-11-13 09:52:51,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:52,320][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.04670758917927742, acc: 0.9833333492279053)
[2024-11-13 09:52:52,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:53,007][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.2501894235610962, acc: 0.9305555820465088)
[2024-11-13 09:52:53,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:53,678][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.0020674136467278004, acc: 1.0)
[2024-11-13 09:52:53,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:54,360][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.02666209265589714, acc: 1.0)
[2024-11-13 09:52:54,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:55,029][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.36584559082984924, acc: 0.8999999761581421)
[2024-11-13 09:52:55,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:55,711][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.11955150216817856, acc: 0.9259259104728699)
[2024-11-13 09:52:55,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:56,616][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 0.8451571464538574, acc: 0.7542372941970825)
[2024-11-13 09:52:56,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:57,320][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 0.12656082212924957, acc: 0.9477611780166626)
[2024-11-13 09:52:57,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:58,006][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 0.16462120413780212, acc: 0.9343065619468689)
[2024-11-13 09:52:58,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:58,727][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 0.3885332942008972, acc: 0.8999999761581421)
[2024-11-13 09:52:58,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:52:59,412][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.022220639511942863, acc: 1.0)
[2024-11-13 09:52:59,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:00,097][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.028960200026631355, acc: 1.0)
[2024-11-13 09:53:00,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:00,776][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.02804340049624443, acc: 1.0)
[2024-11-13 09:53:00,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:01,461][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 0.19974280893802643, acc: 0.9344262480735779)
[2024-11-13 09:53:01,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:02,141][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.060085736215114594, acc: 0.9661017060279846)
[2024-11-13 09:53:02,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:02,817][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 0.1010628491640091, acc: 0.9767441749572754)
[2024-11-13 09:53:02,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:03,490][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.168143630027771, acc: 0.9772727489471436)
[2024-11-13 09:53:03,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:04,175][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.23453626036643982, acc: 0.9433962106704712)
[2024-11-13 09:53:04,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:04,846][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.1391066014766693, acc: 0.9772727489471436)
[2024-11-13 09:53:04,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:05,518][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.01655702292919159, acc: 1.0)
[2024-11-13 09:53:05,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:06,185][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.1768484264612198, acc: 0.8999999761581421)
[2024-11-13 09:53:06,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:06,856][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.025515852496027946, acc: 1.0)
[2024-11-13 09:53:06,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:07,535][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.09348318725824356, acc: 0.9692307710647583)
[2024-11-13 09:53:07,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:08,213][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.17872761189937592, acc: 0.9375)
[2024-11-13 09:53:08,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:08,887][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.0629546269774437, acc: 1.0)
[2024-11-13 09:53:08,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:09,566][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.0755094587802887, acc: 0.9696969985961914)
[2024-11-13 09:53:09,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:10,239][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.07678914815187454, acc: 0.9375)
[2024-11-13 09:53:10,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:10,923][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.012298284098505974, acc: 1.0)
[2024-11-13 09:53:11,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:11,603][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.477984219789505, acc: 0.9130434989929199)
[2024-11-13 09:53:11,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:12,275][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.0359017513692379, acc: 1.0)
[2024-11-13 09:53:12,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:12,966][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.03625495359301567, acc: 1.0)
[2024-11-13 09:53:13,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:13,641][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.0015554430428892374, acc: 1.0)
[2024-11-13 09:53:13,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:14,315][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.009743773378431797, acc: 1.0)
[2024-11-13 09:53:14,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:14,985][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.06641775369644165, acc: 1.0)
[2024-11-13 09:53:15,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:15,653][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.0009959234157577157, acc: 1.0)
[2024-11-13 09:53:15,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:16,339][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.33111467957496643, acc: 0.8787878751754761)
[2024-11-13 09:53:16,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:17,022][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.05038867145776749, acc: 0.9750000238418579)
[2024-11-13 09:53:17,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:17,701][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.055536363273859024, acc: 0.9857142567634583)
[2024-11-13 09:53:17,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:18,408][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 0.19384731352329254, acc: 0.9343065619468689)
[2024-11-13 09:53:18,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:19,107][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 0.028576791286468506, acc: 1.0)
[2024-11-13 09:53:19,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:19,797][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 0.1074853464961052, acc: 0.9714285731315613)
[2024-11-13 09:53:19,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:20,481][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 0.23552536964416504, acc: 0.9139072895050049)
[2024-11-13 09:53:20,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:21,167][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.05936829373240471, acc: 0.9743589758872986)
[2024-11-13 09:53:22,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:22,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:23,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:23,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:24,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:25,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:26,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:26,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:27,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:27,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:28,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:29,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:29,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:30,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:30,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:31,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:31,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:32,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:33,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:33,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:34,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:34,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:35,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:35,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:36,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:37,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:37,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:38,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:38,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:39,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:40,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:40,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:41,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:41,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:43,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:43,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:44,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:44,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:45,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:45,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:46,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:47,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:47,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:48,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:49,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:49,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:50,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:50,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:51,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:52,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:52,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:53,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:53,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:54,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:55,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:55,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:56,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:56,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:57,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:57,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:58,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:59,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:53:59,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:00,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:00,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:01,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:02,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:02,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:03,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:03,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:04,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:05,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:05,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:06,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:06,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:07,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:08,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:08,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:09,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:09,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:10,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:11,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:11,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:12,533][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1995, device='cuda:0') eval_epoch_loss=tensor(0.7882, device='cuda:0') eval_epoch_acc=tensor(0.8237, device='cuda:0')
[2024-11-13 09:54:12,535][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:54:12,535][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:54:12,852][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_558_loss_0.7882441878318787/model.pt
[2024-11-13 09:54:12,859][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:54:12,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:13,555][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.06486888974905014, acc: 0.9599999785423279)
[2024-11-13 09:54:13,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:14,231][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.027619589120149612, acc: 1.0)
[2024-11-13 09:54:14,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:14,906][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.012008294463157654, acc: 1.0)
[2024-11-13 09:54:14,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:15,584][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.03159306198358536, acc: 1.0)
[2024-11-13 09:54:15,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:16,282][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.22191208600997925, acc: 0.9444444179534912)
[2024-11-13 09:54:16,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:16,963][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.12131921201944351, acc: 0.9610389471054077)
[2024-11-13 09:54:17,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:17,643][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.02070486731827259, acc: 1.0)
[2024-11-13 09:54:17,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:18,326][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.16113576292991638, acc: 0.9137930870056152)
[2024-11-13 09:54:18,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:19,020][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 0.10262725502252579, acc: 0.976190447807312)
[2024-11-13 09:54:19,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:19,696][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.045261990278959274, acc: 0.9736841917037964)
[2024-11-13 09:54:19,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:20,375][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.25959035754203796, acc: 0.9259259104728699)
[2024-11-13 09:54:20,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:21,104][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 0.19461983442306519, acc: 0.9465240836143494)
[2024-11-13 09:54:21,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:21,784][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.010201500728726387, acc: 1.0)
[2024-11-13 09:54:21,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:22,477][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.08421476185321808, acc: 0.9743589758872986)
[2024-11-13 09:54:22,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:23,195][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 0.354241281747818, acc: 0.8979591727256775)
[2024-11-13 09:54:23,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:23,905][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 0.25658029317855835, acc: 0.9245283007621765)
[2024-11-13 09:54:24,380][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=1.1545, train_epoch_loss=0.1437, epoch time 603.0007183831185s
[2024-11-13 09:54:24,380][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 09:54:24,380][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 09:54:24,380][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 09:54:24,381][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 8
[2024-11-13 09:54:24,381][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 09:54:25,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:25,825][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.0301484577357769, acc: 0.9629629850387573)
[2024-11-13 09:54:25,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:26,515][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.01949821040034294, acc: 1.0)
[2024-11-13 09:54:26,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:27,198][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.6016935110092163, acc: 0.9189189076423645)
[2024-11-13 09:54:27,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:27,890][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.030132876709103584, acc: 1.0)
[2024-11-13 09:54:27,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:28,578][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.3261982202529907, acc: 0.8918918967247009)
[2024-11-13 09:54:28,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:29,263][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.02840445376932621, acc: 1.0)
[2024-11-13 09:54:29,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:29,947][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.10294777899980545, acc: 0.9591836929321289)
[2024-11-13 09:54:30,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:30,631][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.03050306625664234, acc: 1.0)
[2024-11-13 09:54:30,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:31,312][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.005852365866303444, acc: 1.0)
[2024-11-13 09:54:31,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:31,991][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.016316570341587067, acc: 1.0)
[2024-11-13 09:54:32,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:32,685][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.004606954753398895, acc: 1.0)
[2024-11-13 09:54:32,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:33,376][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.15248695015907288, acc: 0.9230769276618958)
[2024-11-13 09:54:33,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:34,058][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.13923180103302002, acc: 0.9696969985961914)
[2024-11-13 09:54:34,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:34,759][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.0263329166918993, acc: 1.0)
[2024-11-13 09:54:34,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:35,457][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.11685804277658463, acc: 0.9607843160629272)
[2024-11-13 09:54:35,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:36,155][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.06322748959064484, acc: 1.0)
[2024-11-13 09:54:36,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:36,837][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.0030857643578201532, acc: 1.0)
[2024-11-13 09:54:36,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:37,523][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.019543003290891647, acc: 1.0)
[2024-11-13 09:54:37,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:38,208][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.05684883892536163, acc: 1.0)
[2024-11-13 09:54:38,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:38,890][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.007115647196769714, acc: 1.0)
[2024-11-13 09:54:38,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:39,577][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.24540814757347107, acc: 0.9230769276618958)
[2024-11-13 09:54:39,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:40,269][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.09009254723787308, acc: 0.931034505367279)
[2024-11-13 09:54:40,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:40,961][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.04517144709825516, acc: 1.0)
[2024-11-13 09:54:41,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:41,642][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.0021346297580748796, acc: 1.0)
[2024-11-13 09:54:41,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:42,321][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.005260607693344355, acc: 1.0)
[2024-11-13 09:54:42,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:43,011][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.16291913390159607, acc: 0.9433962106704712)
[2024-11-13 09:54:43,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:43,701][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.15476030111312866, acc: 0.9589040875434875)
[2024-11-13 09:54:43,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:44,504][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 0.8272061944007874, acc: 0.7707509994506836)
[2024-11-13 09:54:44,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:45,193][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.036804813891649246, acc: 1.0)
[2024-11-13 09:54:45,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:45,886][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.13278765976428986, acc: 0.9638554453849792)
[2024-11-13 09:54:45,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:46,591][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.13853317499160767, acc: 0.9382715821266174)
[2024-11-13 09:54:46,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:47,278][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.11993101984262466, acc: 0.9642857313156128)
[2024-11-13 09:54:47,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:47,955][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.04960926994681358, acc: 0.9629629850387573)
[2024-11-13 09:54:48,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:48,639][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.011877425014972687, acc: 1.0)
[2024-11-13 09:54:48,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:49,337][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 0.15181437134742737, acc: 0.9411764740943909)
[2024-11-13 09:54:49,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:50,029][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.13308459520339966, acc: 0.9344262480735779)
[2024-11-13 09:54:50,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:50,727][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.16222979128360748, acc: 0.9682539701461792)
[2024-11-13 09:54:50,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:51,416][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.06668239831924438, acc: 0.9661017060279846)
[2024-11-13 09:54:51,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:52,110][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.0950060561299324, acc: 0.977011501789093)
[2024-11-13 09:54:52,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:52,795][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.008238213136792183, acc: 1.0)
[2024-11-13 09:54:52,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:53,481][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.025309698656201363, acc: 1.0)
[2024-11-13 09:54:53,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:54,178][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 0.06440756469964981, acc: 0.9594594836235046)
[2024-11-13 09:54:54,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:54,873][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.10901782661676407, acc: 0.9538461565971375)
[2024-11-13 09:54:54,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:55,570][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 0.29223713278770447, acc: 0.9191918969154358)
[2024-11-13 09:54:55,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:56,269][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 0.16791774332523346, acc: 0.9278350472450256)
[2024-11-13 09:54:56,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:56,968][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 0.09476102888584137, acc: 0.9558823704719543)
[2024-11-13 09:54:57,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:57,652][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.03310098499059677, acc: 1.0)
[2024-11-13 09:54:57,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:58,340][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.013004006817936897, acc: 1.0)
[2024-11-13 09:54:58,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:59,025][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.17270363867282867, acc: 0.9285714030265808)
[2024-11-13 09:54:59,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:54:59,750][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.033049218356609344, acc: 1.0)
[2024-11-13 09:54:59,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:00,483][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.3244190216064453, acc: 0.9298245906829834)
[2024-11-13 09:55:00,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:01,187][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.15961991250514984, acc: 0.9365079402923584)
[2024-11-13 09:55:01,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:01,887][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.15576019883155823, acc: 0.9577465057373047)
[2024-11-13 09:55:01,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:02,611][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 0.5774498581886292, acc: 0.8133333325386047)
[2024-11-13 09:55:02,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:03,297][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.07771273702383041, acc: 0.9729729890823364)
[2024-11-13 09:55:03,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:03,989][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.024596188217401505, acc: 1.0)
[2024-11-13 09:55:04,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:04,841][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.1131911277770996, acc: 0.6928327679634094)
[2024-11-13 09:55:04,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:05,621][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 1.2820069789886475, acc: 0.6405228972434998)
[2024-11-13 09:55:05,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:06,341][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 0.4133286774158478, acc: 0.875)
[2024-11-13 09:55:06,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:07,049][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 0.19106422364711761, acc: 0.9191176295280457)
[2024-11-13 09:55:07,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:07,782][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 0.33007097244262695, acc: 0.8768116235733032)
[2024-11-13 09:55:07,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:08,502][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 0.21763662993907928, acc: 0.9125000238418579)
[2024-11-13 09:55:08,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:09,188][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.11992257833480835, acc: 0.9411764740943909)
[2024-11-13 09:55:09,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:09,873][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.11821699142456055, acc: 0.9722222089767456)
[2024-11-13 09:55:09,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:10,575][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.12325312942266464, acc: 0.96875)
[2024-11-13 09:55:10,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:11,264][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.11232218891382217, acc: 0.8965517282485962)
[2024-11-13 09:55:11,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:11,954][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.2587030231952667, acc: 0.8928571343421936)
[2024-11-13 09:55:12,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:12,650][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.055844664573669434, acc: 1.0)
[2024-11-13 09:55:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:13,334][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.004844272509217262, acc: 1.0)
[2024-11-13 09:55:13,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:14,021][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.03885742276906967, acc: 1.0)
[2024-11-13 09:55:14,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:14,707][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.02184167318046093, acc: 1.0)
[2024-11-13 09:55:14,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:15,426][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 0.356213241815567, acc: 0.8970588445663452)
[2024-11-13 09:55:15,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:16,128][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 0.23554018139839172, acc: 0.89682537317276)
[2024-11-13 09:55:16,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:16,851][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 0.7990792989730835, acc: 0.7589743733406067)
[2024-11-13 09:55:16,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:17,550][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 0.43436843156814575, acc: 0.8979591727256775)
[2024-11-13 09:55:17,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:18,258][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 0.4805021584033966, acc: 0.8731343150138855)
[2024-11-13 09:55:18,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:19,006][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 0.8898946642875671, acc: 0.7518247961997986)
[2024-11-13 09:55:19,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:19,701][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.0023994185030460358, acc: 1.0)
[2024-11-13 09:55:19,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:20,390][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.15568362176418304, acc: 0.9583333134651184)
[2024-11-13 09:55:20,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:21,078][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.004648841917514801, acc: 1.0)
[2024-11-13 09:55:21,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:21,765][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.01841779239475727, acc: 1.0)
[2024-11-13 09:55:21,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:22,459][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.16615454852581024, acc: 0.942307710647583)
[2024-11-13 09:55:22,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:23,158][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.037777382880449295, acc: 1.0)
[2024-11-13 09:55:23,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:23,844][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.040306441485881805, acc: 1.0)
[2024-11-13 09:55:23,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:24,545][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.09820053726434708, acc: 0.95652174949646)
[2024-11-13 09:55:24,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:25,239][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.08063694089651108, acc: 0.9800000190734863)
[2024-11-13 09:55:25,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:25,920][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.01787138730287552, acc: 1.0)
[2024-11-13 09:55:26,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:26,618][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.21535804867744446, acc: 0.9399999976158142)
[2024-11-13 09:55:26,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:27,316][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.18270884454250336, acc: 0.9417475461959839)
[2024-11-13 09:55:27,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:28,039][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 0.4725791811943054, acc: 0.844660222530365)
[2024-11-13 09:55:28,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:28,766][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 0.6316038370132446, acc: 0.7849462628364563)
[2024-11-13 09:55:28,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:29,502][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 0.4904310405254364, acc: 0.8793103694915771)
[2024-11-13 09:55:29,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:30,205][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.2056514322757721, acc: 0.9473684430122375)
[2024-11-13 09:55:30,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:30,932][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 0.290032297372818, acc: 0.9108911156654358)
[2024-11-13 09:55:31,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:31,633][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.13676872849464417, acc: 0.9516128897666931)
[2024-11-13 09:55:31,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:32,327][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.14040537178516388, acc: 0.9710144996643066)
[2024-11-13 09:55:32,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:33,027][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 0.3009953498840332, acc: 0.9075630307197571)
[2024-11-13 09:55:33,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:33,729][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 0.27775290608406067, acc: 0.8942307829856873)
[2024-11-13 09:55:33,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:34,438][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 0.38878315687179565, acc: 0.8613138794898987)
[2024-11-13 09:55:34,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:35,129][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.2204921394586563, acc: 0.9253731369972229)
[2024-11-13 09:55:35,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:35,823][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.16552838683128357, acc: 0.949999988079071)
[2024-11-13 09:55:35,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:36,517][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.000921144091989845, acc: 1.0)
[2024-11-13 09:55:36,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:37,203][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.02675640396773815, acc: 1.0)
[2024-11-13 09:55:37,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:37,891][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.06743937730789185, acc: 0.9772727489471436)
[2024-11-13 09:55:37,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:38,586][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.029351593926548958, acc: 0.982758641242981)
[2024-11-13 09:55:38,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:39,272][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.004886809270828962, acc: 1.0)
[2024-11-13 09:55:39,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:39,964][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.007172751240432262, acc: 1.0)
[2024-11-13 09:55:40,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:40,655][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.009794698096811771, acc: 1.0)
[2024-11-13 09:55:40,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:41,353][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.004038731101900339, acc: 1.0)
[2024-11-13 09:55:41,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:42,043][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.018275652080774307, acc: 1.0)
[2024-11-13 09:55:42,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:42,734][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.05952049046754837, acc: 0.9692307710647583)
[2024-11-13 09:55:42,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:43,424][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.12643985450267792, acc: 0.9649122953414917)
[2024-11-13 09:55:43,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:44,108][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.09245936572551727, acc: 0.9649122953414917)
[2024-11-13 09:55:44,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:44,794][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.04708385095000267, acc: 1.0)
[2024-11-13 09:55:44,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:45,488][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.06131753325462341, acc: 0.9795918464660645)
[2024-11-13 09:55:45,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:46,173][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.003064272692427039, acc: 1.0)
[2024-11-13 09:55:46,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:46,871][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 0.1272146999835968, acc: 0.9365079402923584)
[2024-11-13 09:55:46,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:47,566][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 0.09291283786296844, acc: 0.9674796462059021)
[2024-11-13 09:55:47,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:48,256][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.11350949853658676, acc: 0.9516128897666931)
[2024-11-13 09:55:48,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:49,026][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 0.3873440623283386, acc: 0.8707224130630493)
[2024-11-13 09:55:49,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:49,724][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.024166371673345566, acc: 1.0)
[2024-11-13 09:55:49,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:50,415][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.033938147127628326, acc: 1.0)
[2024-11-13 09:55:50,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:51,099][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.07945019751787186, acc: 0.9583333134651184)
[2024-11-13 09:55:51,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:51,781][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.4855855703353882, acc: 0.9473684430122375)
[2024-11-13 09:55:51,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:52,484][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 0.31417253613471985, acc: 0.9263803958892822)
[2024-11-13 09:55:52,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:53,204][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 0.35049593448638916, acc: 0.9236111044883728)
[2024-11-13 09:55:53,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:53,905][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 0.23841412365436554, acc: 0.9416666626930237)
[2024-11-13 09:55:54,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:55,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:56,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:56,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:57,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:57,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:58,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:59,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:55:59,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:00,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:00,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:01,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:01,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:02,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:03,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:03,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:04,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:04,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:05,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:06,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:06,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:07,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:07,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:08,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:09,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:09,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:10,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:10,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:11,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:11,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:12,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:13,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:13,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:14,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:14,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:16,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:16,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:17,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:17,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:18,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:19,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:19,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:20,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:20,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:21,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:21,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:22,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:22,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:23,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:24,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:24,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:25,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:25,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:26,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:27,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:27,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:28,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:28,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:29,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:30,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:30,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:31,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:31,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:32,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:32,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:33,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:34,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:34,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:35,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:35,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:36,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:36,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:37,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:38,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:38,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:39,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:39,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:40,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:41,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:41,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:42,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:42,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:43,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:43,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:44,851][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1968, device='cuda:0') eval_epoch_loss=tensor(0.7870, device='cuda:0') eval_epoch_acc=tensor(0.8299, device='cuda:0')
[2024-11-13 09:56:44,853][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:56:44,853][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:56:45,171][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_127_loss_0.7870200872421265/model.pt
[2024-11-13 09:56:45,176][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:56:45,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:45,911][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 0.2562701404094696, acc: 0.9226190447807312)
[2024-11-13 09:56:45,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:46,620][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 0.2940311133861542, acc: 0.8974359035491943)
[2024-11-13 09:56:46,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:47,343][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 0.37215715646743774, acc: 0.8823529481887817)
[2024-11-13 09:56:47,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:48,015][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.14203554391860962, acc: 0.9615384340286255)
[2024-11-13 09:56:48,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:48,694][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.10516471415758133, acc: 0.95652174949646)
[2024-11-13 09:56:48,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:49,366][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.023060254752635956, acc: 1.0)
[2024-11-13 09:56:49,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:50,036][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.24988068640232086, acc: 0.8695651888847351)
[2024-11-13 09:56:50,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:50,719][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.02679377980530262, acc: 1.0)
[2024-11-13 09:56:50,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:51,396][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.5885180234909058, acc: 0.8846153616905212)
[2024-11-13 09:56:51,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:52,071][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.18385836482048035, acc: 0.9523809552192688)
[2024-11-13 09:56:52,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:52,741][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.13721631467342377, acc: 0.9666666388511658)
[2024-11-13 09:56:52,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:53,411][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.28780999779701233, acc: 0.9130434989929199)
[2024-11-13 09:56:53,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:54,082][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.026766164228320122, acc: 1.0)
[2024-11-13 09:56:54,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:54,751][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.13075858354568481, acc: 0.9230769276618958)
[2024-11-13 09:56:54,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:55,422][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.1977577954530716, acc: 0.9354838728904724)
[2024-11-13 09:56:55,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:56,093][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.36806049942970276, acc: 0.8648648858070374)
[2024-11-13 09:56:56,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:56,804][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 0.28271484375, acc: 0.8859649300575256)
[2024-11-13 09:56:56,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:57,494][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 0.3956633508205414, acc: 0.8731343150138855)
[2024-11-13 09:56:57,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:58,183][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 0.2208566516637802, acc: 0.9489796161651611)
[2024-11-13 09:56:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:58,888][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 0.23727084696292877, acc: 0.914893627166748)
[2024-11-13 09:56:58,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:56:59,571][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.30242013931274414, acc: 0.9142857193946838)
[2024-11-13 09:56:59,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:00,242][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.21098840236663818, acc: 0.9642857313156128)
[2024-11-13 09:57:00,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:00,919][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.06764711439609528, acc: 0.95652174949646)
[2024-11-13 09:57:01,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:01,600][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.17591704428195953, acc: 0.9655172228813171)
[2024-11-13 09:57:01,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:02,277][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.44347813725471497, acc: 0.8695651888847351)
[2024-11-13 09:57:02,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:02,960][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 0.21766720712184906, acc: 0.9491525292396545)
[2024-11-13 09:57:03,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:03,638][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.18185444176197052, acc: 0.8947368264198303)
[2024-11-13 09:57:03,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:04,321][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.16361966729164124, acc: 0.9324324131011963)
[2024-11-13 09:57:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:04,994][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.10182740539312363, acc: 0.9642857313156128)
[2024-11-13 09:57:05,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:05,665][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.0928112342953682, acc: 0.95652174949646)
[2024-11-13 09:57:05,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:06,334][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.20306546986103058, acc: 0.8947368264198303)
[2024-11-13 09:57:06,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:07,012][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.3120705485343933, acc: 0.9189189076423645)
[2024-11-13 09:57:07,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:07,690][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 0.29371896386146545, acc: 0.8703703880310059)
[2024-11-13 09:57:07,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:08,410][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 0.05441524088382721, acc: 0.9883720874786377)
[2024-11-13 09:57:08,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:09,092][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.0906684622168541, acc: 0.9647058844566345)
[2024-11-13 09:57:09,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:09,775][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 0.2878214716911316, acc: 0.8876404762268066)
[2024-11-13 09:57:09,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:10,454][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.11900322139263153, acc: 0.9772727489471436)
[2024-11-13 09:57:10,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:11,140][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.03463530167937279, acc: 1.0)
[2024-11-13 09:57:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:11,813][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.08812867105007172, acc: 0.9655172228813171)
[2024-11-13 09:57:11,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:12,492][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.04247887432575226, acc: 1.0)
[2024-11-13 09:57:12,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:13,175][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.08004392683506012, acc: 0.9800000190734863)
[2024-11-13 09:57:13,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:13,855][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.22892363369464874, acc: 0.9027777910232544)
[2024-11-13 09:57:13,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:14,539][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 0.4501085877418518, acc: 0.8725489974021912)
[2024-11-13 09:57:14,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:15,263][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 0.8933979272842407, acc: 0.767123281955719)
[2024-11-13 09:57:15,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:15,934][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.0034381020814180374, acc: 1.0)
[2024-11-13 09:57:16,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:16,616][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.03566943109035492, acc: 1.0)
[2024-11-13 09:57:16,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:17,287][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.08009333163499832, acc: 0.9642857313156128)
[2024-11-13 09:57:17,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:17,990][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 0.299446165561676, acc: 0.8938053250312805)
[2024-11-13 09:57:18,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:18,666][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.09569668769836426, acc: 0.9710144996643066)
[2024-11-13 09:57:18,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:19,349][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 0.13643616437911987, acc: 0.9659090638160706)
[2024-11-13 09:57:19,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:20,061][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 0.5004864931106567, acc: 0.8625954389572144)
[2024-11-13 09:57:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:20,771][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 0.268417626619339, acc: 0.9185185432434082)
[2024-11-13 09:57:20,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:21,447][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.12918487191200256, acc: 0.9672130942344666)
[2024-11-13 09:57:21,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:22,119][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.0030956557020545006, acc: 1.0)
[2024-11-13 09:57:22,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:22,788][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.19718360900878906, acc: 0.9599999785423279)
[2024-11-13 09:57:22,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:23,458][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.026546359062194824, acc: 1.0)
[2024-11-13 09:57:23,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:24,142][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 0.10825914144515991, acc: 0.9756097793579102)
[2024-11-13 09:57:24,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:24,863][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 0.4452148675918579, acc: 0.8912386894226074)
[2024-11-13 09:57:24,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:25,590][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 0.4865359365940094, acc: 0.8530259132385254)
[2024-11-13 09:57:25,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:26,313][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 0.367374449968338, acc: 0.878125011920929)
[2024-11-13 09:57:26,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:27,079][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 0.7140198945999146, acc: 0.8292682766914368)
[2024-11-13 09:57:27,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:27,817][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 0.27732333540916443, acc: 0.918149471282959)
[2024-11-13 09:57:27,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:28,498][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.020464226603507996, acc: 1.0)
[2024-11-13 09:57:28,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:29,183][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 0.32572779059410095, acc: 0.9069767594337463)
[2024-11-13 09:57:29,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:29,870][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 0.5923992395401001, acc: 0.8333333134651184)
[2024-11-13 09:57:29,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:30,560][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 0.41681206226348877, acc: 0.8560606241226196)
[2024-11-13 09:57:30,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:31,244][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 0.13525675237178802, acc: 0.9411764740943909)
[2024-11-13 09:57:31,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:31,955][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 0.32546913623809814, acc: 0.895061731338501)
[2024-11-13 09:57:32,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:32,642][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.24702253937721252, acc: 0.9193548560142517)
[2024-11-13 09:57:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:33,312][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.05873185023665428, acc: 0.9642857313156128)
[2024-11-13 09:57:33,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:33,985][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.10314686596393585, acc: 0.9750000238418579)
[2024-11-13 09:57:34,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:34,678][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.04673675820231438, acc: 1.0)
[2024-11-13 09:57:34,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:35,365][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 0.17555271089076996, acc: 0.9338235259056091)
[2024-11-13 09:57:35,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:36,050][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 0.3457677364349365, acc: 0.8898305296897888)
[2024-11-13 09:57:36,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:36,749][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 0.2493460327386856, acc: 0.9253731369972229)
[2024-11-13 09:57:36,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:37,435][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 0.2891267240047455, acc: 0.9223300814628601)
[2024-11-13 09:57:37,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:38,119][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.13245649635791779, acc: 0.9682539701461792)
[2024-11-13 09:57:38,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:38,799][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.05892385169863701, acc: 0.9780219793319702)
[2024-11-13 09:57:38,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:39,518][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 0.14284715056419373, acc: 0.9506726264953613)
[2024-11-13 09:57:39,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:40,241][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 0.18704275786876678, acc: 0.9370078444480896)
[2024-11-13 09:57:40,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:40,951][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 0.13478030264377594, acc: 0.9612069129943848)
[2024-11-13 09:57:41,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:41,663][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 0.14509189128875732, acc: 0.967391312122345)
[2024-11-13 09:57:41,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:42,378][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 0.1109171211719513, acc: 0.957198441028595)
[2024-11-13 09:57:42,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:43,082][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 0.07293637096881866, acc: 0.97826087474823)
[2024-11-13 09:57:43,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:43,754][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.004158054944127798, acc: 1.0)
[2024-11-13 09:57:43,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:44,423][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.001978300977498293, acc: 1.0)
[2024-11-13 09:57:44,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:45,101][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.0056396652944386005, acc: 1.0)
[2024-11-13 09:57:45,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:45,800][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 0.09852371364831924, acc: 0.9692307710647583)
[2024-11-13 09:57:45,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:46,485][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.034802116453647614, acc: 0.9864864945411682)
[2024-11-13 09:57:46,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:47,165][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.017301421612501144, acc: 0.9883720874786377)
[2024-11-13 09:57:47,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:47,852][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 0.03871791437268257, acc: 0.9819819927215576)
[2024-11-13 09:57:47,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:48,541][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.03705437853932381, acc: 0.9777777791023254)
[2024-11-13 09:57:48,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:49,217][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.013514094054698944, acc: 1.0)
[2024-11-13 09:57:49,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:49,889][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.004917472135275602, acc: 1.0)
[2024-11-13 09:57:49,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:50,564][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.0016715580131858587, acc: 1.0)
[2024-11-13 09:57:50,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:51,245][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.23866507411003113, acc: 0.9038461446762085)
[2024-11-13 09:57:51,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:51,955][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 0.2957003116607666, acc: 0.91847825050354)
[2024-11-13 09:57:52,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:52,661][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 0.21979717910289764, acc: 0.9204545617103577)
[2024-11-13 09:57:52,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:53,367][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 0.2343401461839676, acc: 0.9255319237709045)
[2024-11-13 09:57:53,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:54,054][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.11130679398775101, acc: 0.9245283007621765)
[2024-11-13 09:57:54,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:54,733][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.06179343909025192, acc: 0.9833333492279053)
[2024-11-13 09:57:54,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:55,411][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.0719095841050148, acc: 0.9534883499145508)
[2024-11-13 09:57:55,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:56,081][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.04121846333146095, acc: 0.9666666388511658)
[2024-11-13 09:57:56,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:56,768][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 0.36895495653152466, acc: 0.8842105269432068)
[2024-11-13 09:57:56,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:57,447][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 0.23658044636249542, acc: 0.9333333373069763)
[2024-11-13 09:57:57,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:58,151][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 0.3178286552429199, acc: 0.9166666865348816)
[2024-11-13 09:57:58,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:58,855][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 0.6805737018585205, acc: 0.7660550475120544)
[2024-11-13 09:57:58,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:57:59,568][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 0.3524191677570343, acc: 0.9153845906257629)
[2024-11-13 09:57:59,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:00,251][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.05966567248106003, acc: 0.9473684430122375)
[2024-11-13 09:58:00,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:00,921][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.006850427482277155, acc: 1.0)
[2024-11-13 09:58:01,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:01,594][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.03357464820146561, acc: 1.0)
[2024-11-13 09:58:01,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:02,265][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.01970868930220604, acc: 1.0)
[2024-11-13 09:58:02,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:02,940][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.0858326330780983, acc: 0.9714285731315613)
[2024-11-13 09:58:03,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:03,615][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.01604122295975685, acc: 1.0)
[2024-11-13 09:58:03,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:04,288][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.02177531272172928, acc: 1.0)
[2024-11-13 09:58:04,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:04,967][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.17815913259983063, acc: 0.9354838728904724)
[2024-11-13 09:58:05,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:05,643][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.18871131539344788, acc: 0.9090909361839294)
[2024-11-13 09:58:05,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:06,312][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.0007909041596576571, acc: 1.0)
[2024-11-13 09:58:06,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:06,982][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.008541308343410492, acc: 1.0)
[2024-11-13 09:58:07,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:07,651][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.0123450867831707, acc: 1.0)
[2024-11-13 09:58:07,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:08,322][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.006491471081972122, acc: 1.0)
[2024-11-13 09:58:08,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:08,999][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.014256744645535946, acc: 1.0)
[2024-11-13 09:58:09,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:09,670][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.05154729634523392, acc: 0.9729729890823364)
[2024-11-13 09:58:09,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:10,343][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.011473444290459156, acc: 1.0)
[2024-11-13 09:58:10,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:11,036][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.12114419788122177, acc: 0.9558823704719543)
[2024-11-13 09:58:11,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:11,711][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.09588833153247833, acc: 0.9756097793579102)
[2024-11-13 09:58:11,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:12,381][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.0021329789888113737, acc: 1.0)
[2024-11-13 09:58:12,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:13,048][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.05820415914058685, acc: 0.9599999785423279)
[2024-11-13 09:58:13,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:13,722][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.034893326461315155, acc: 1.0)
[2024-11-13 09:58:13,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:14,398][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.020933225750923157, acc: 0.9824561476707458)
[2024-11-13 09:58:14,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:15,085][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.01747295632958412, acc: 1.0)
[2024-11-13 09:58:15,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:15,766][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.042904943227767944, acc: 0.9736841917037964)
[2024-11-13 09:58:15,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:16,467][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 0.09951252490282059, acc: 0.9622641801834106)
[2024-11-13 09:58:16,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:17,172][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 0.15779688954353333, acc: 0.9666666388511658)
[2024-11-13 09:58:17,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:17,856][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.0728951022028923, acc: 0.9722222089767456)
[2024-11-13 09:58:17,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:18,539][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.025052174925804138, acc: 1.0)
[2024-11-13 09:58:18,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:19,223][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 0.2449185997247696, acc: 0.9066666960716248)
[2024-11-13 09:58:19,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:19,896][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.09733650833368301, acc: 0.9791666865348816)
[2024-11-13 09:58:19,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:20,607][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 0.6425451040267944, acc: 0.7919999957084656)
[2024-11-13 09:58:20,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:21,291][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 0.27791255712509155, acc: 0.8876404762268066)
[2024-11-13 09:58:21,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:21,969][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.10889327526092529, acc: 0.9729729890823364)
[2024-11-13 09:58:22,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:22,648][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.2941206097602844, acc: 0.9482758641242981)
[2024-11-13 09:58:22,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:23,317][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.013494890183210373, acc: 1.0)
[2024-11-13 09:58:24,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:24,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:25,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:26,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:26,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:27,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:27,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:28,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:28,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:30,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:30,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:31,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:31,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:32,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:33,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:33,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:34,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:34,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:35,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:35,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:36,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:37,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:37,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:38,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:38,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:39,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:40,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:40,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:41,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:41,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:43,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:43,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:44,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:44,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:45,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:45,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:46,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:47,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:47,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:48,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:48,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:49,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:50,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:50,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:51,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:51,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:52,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:52,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:53,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:54,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:54,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:55,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:55,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:56,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:57,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:57,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:58,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:59,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:58:59,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:00,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:00,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:01,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:01,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:02,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:03,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:03,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:04,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:04,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:05,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:06,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:06,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:07,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:07,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:09,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:09,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:10,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:10,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:11,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:12,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:12,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:13,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:13,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:14,856][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2167, device='cuda:0') eval_epoch_loss=tensor(0.7960, device='cuda:0') eval_epoch_acc=tensor(0.8326, device='cuda:0')
[2024-11-13 09:59:14,858][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 09:59:14,858][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 09:59:15,456][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_270_loss_0.7960119247436523/model.pt
[2024-11-13 09:59:15,464][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 09:59:15,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:16,198][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.03985052555799484, acc: 1.0)
[2024-11-13 09:59:16,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:16,875][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.02455144003033638, acc: 1.0)
[2024-11-13 09:59:16,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:17,559][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.02011057920753956, acc: 1.0)
[2024-11-13 09:59:17,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:18,241][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.18446418642997742, acc: 0.949999988079071)
[2024-11-13 09:59:18,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:18,911][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.03567354008555412, acc: 1.0)
[2024-11-13 09:59:18,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:19,592][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.00973519403487444, acc: 1.0)
[2024-11-13 09:59:19,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:20,276][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.18742644786834717, acc: 0.9655172228813171)
[2024-11-13 09:59:20,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:20,947][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.036644186824560165, acc: 1.0)
[2024-11-13 09:59:21,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:21,623][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.08013979345560074, acc: 0.978723406791687)
[2024-11-13 09:59:21,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:22,303][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.024541230872273445, acc: 1.0)
[2024-11-13 09:59:22,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:22,975][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.019378380849957466, acc: 1.0)
[2024-11-13 09:59:23,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:23,658][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.4727596044540405, acc: 0.8795180916786194)
[2024-11-13 09:59:23,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:24,339][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 0.6283264756202698, acc: 0.8888888955116272)
[2024-11-13 09:59:24,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:25,010][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.020449001342058182, acc: 1.0)
[2024-11-13 09:59:25,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:25,682][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.034582316875457764, acc: 1.0)
[2024-11-13 09:59:25,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:26,358][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.039115894585847855, acc: 0.9750000238418579)
[2024-11-13 09:59:26,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:27,038][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 0.2986867129802704, acc: 0.9375)
[2024-11-13 09:59:27,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:27,735][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 0.19510701298713684, acc: 0.9440000057220459)
[2024-11-13 09:59:27,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:28,422][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.0703544095158577, acc: 0.9780219793319702)
[2024-11-13 09:59:28,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:29,106][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 0.19462718069553375, acc: 0.9316770434379578)
[2024-11-13 09:59:29,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:29,815][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 0.28817445039749146, acc: 0.9123711585998535)
[2024-11-13 09:59:29,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:30,482][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.012443238869309425, acc: 1.0)
[2024-11-13 09:59:30,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:31,170][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.06499932706356049, acc: 0.976190447807312)
[2024-11-13 09:59:31,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:31,851][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.054718486964702606, acc: 0.982758641242981)
[2024-11-13 09:59:31,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:32,544][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.0980958342552185, acc: 0.9636363387107849)
[2024-11-13 09:59:32,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:33,267][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 0.4289136230945587, acc: 0.8917526006698608)
[2024-11-13 09:59:33,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:33,947][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.12797850370407104, acc: 0.931034505367279)
[2024-11-13 09:59:34,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:34,628][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.010161115787923336, acc: 1.0)
[2024-11-13 09:59:34,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:35,317][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.5116991996765137, acc: 0.9210526347160339)
[2024-11-13 09:59:35,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:35,998][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.11253680288791656, acc: 0.9464285969734192)
[2024-11-13 09:59:36,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:36,667][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.021471453830599785, acc: 1.0)
[2024-11-13 09:59:36,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:37,345][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.08031748980283737, acc: 0.9811320900917053)
[2024-11-13 09:59:37,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:38,020][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.0250842422246933, acc: 0.9811320900917053)
[2024-11-13 09:59:38,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:38,691][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.004018082283437252, acc: 1.0)
[2024-11-13 09:59:38,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:39,362][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.005307653918862343, acc: 1.0)
[2024-11-13 09:59:39,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:40,042][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.05482321232557297, acc: 0.9836065769195557)
[2024-11-13 09:59:40,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:40,712][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.002587687224149704, acc: 1.0)
[2024-11-13 09:59:40,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:41,380][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.0012519083684310317, acc: 1.0)
[2024-11-13 09:59:41,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:42,079][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.12029620260000229, acc: 0.9855072498321533)
[2024-11-13 09:59:42,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:42,777][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.2217404991388321, acc: 0.9722222089767456)
[2024-11-13 09:59:42,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:43,474][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.0778692215681076, acc: 0.9759036302566528)
[2024-11-13 09:59:43,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:44,164][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.19359488785266876, acc: 0.9230769276618958)
[2024-11-13 09:59:44,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:44,870][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 0.08192624151706696, acc: 0.9693877696990967)
[2024-11-13 09:59:44,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:45,541][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.0012959488667547703, acc: 1.0)
[2024-11-13 09:59:45,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:46,215][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.012398920953273773, acc: 1.0)
[2024-11-13 09:59:46,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:46,886][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.011718698777258396, acc: 1.0)
[2024-11-13 09:59:46,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:47,557][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.005037922877818346, acc: 1.0)
[2024-11-13 09:59:47,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:48,239][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.0742051750421524, acc: 0.9701492786407471)
[2024-11-13 09:59:48,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:48,926][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.050086233764886856, acc: 0.9903846383094788)
[2024-11-13 09:59:49,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:49,609][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.05614546313881874, acc: 0.9777777791023254)
[2024-11-13 09:59:49,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:50,286][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.07208588719367981, acc: 0.9838709831237793)
[2024-11-13 09:59:50,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:50,965][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.04852409288287163, acc: 0.9800000190734863)
[2024-11-13 09:59:51,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:51,639][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.1881641000509262, acc: 0.9259259104728699)
[2024-11-13 09:59:51,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:52,315][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.07778047025203705, acc: 1.0)
[2024-11-13 09:59:52,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:53,002][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.05458366498351097, acc: 1.0)
[2024-11-13 09:59:53,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:53,681][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 0.12052217125892639, acc: 0.9756097793579102)
[2024-11-13 09:59:53,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:54,359][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.15069077908992767, acc: 0.9210526347160339)
[2024-11-13 09:59:54,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:55,029][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.1716565489768982, acc: 0.9473684430122375)
[2024-11-13 09:59:55,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:55,698][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.014711876399815083, acc: 1.0)
[2024-11-13 09:59:55,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:56,369][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.0089121013879776, acc: 1.0)
[2024-11-13 09:59:56,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:57,040][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.0043289680033922195, acc: 1.0)
[2024-11-13 09:59:57,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:57,717][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.00860015768557787, acc: 1.0)
[2024-11-13 09:59:57,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:58,396][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.008476246148347855, acc: 1.0)
[2024-11-13 09:59:58,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:59,065][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.018546948209404945, acc: 1.0)
[2024-11-13 09:59:59,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 09:59:59,736][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.0998767837882042, acc: 0.9666666388511658)
[2024-11-13 09:59:59,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:00,422][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.008766102604568005, acc: 1.0)
[2024-11-13 10:00:00,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:01,111][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.09146077930927277, acc: 0.9599999785423279)
[2024-11-13 10:00:01,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:01,797][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 0.23664432764053345, acc: 0.9195402264595032)
[2024-11-13 10:00:01,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:02,475][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 0.3712303936481476, acc: 0.8723404407501221)
[2024-11-13 10:00:02,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:03,172][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 0.27092626690864563, acc: 0.9036144614219666)
[2024-11-13 10:00:03,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:03,844][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.00046456995187327266, acc: 1.0)
[2024-11-13 10:00:03,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:04,515][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.02501833252608776, acc: 1.0)
[2024-11-13 10:00:04,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:05,197][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.26750338077545166, acc: 0.9156626462936401)
[2024-11-13 10:00:05,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:05,877][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.17759132385253906, acc: 0.9811320900917053)
[2024-11-13 10:00:05,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:06,572][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.02380240336060524, acc: 1.0)
[2024-11-13 10:00:06,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:07,248][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.026116492226719856, acc: 0.9803921580314636)
[2024-11-13 10:00:07,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:07,930][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.02790013700723648, acc: 1.0)
[2024-11-13 10:00:08,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:08,600][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.0024529078509658575, acc: 1.0)
[2024-11-13 10:00:08,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:09,270][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.01564401388168335, acc: 1.0)
[2024-11-13 10:00:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:09,945][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.08328337967395782, acc: 0.9722222089767456)
[2024-11-13 10:00:10,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:10,618][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.1538003832101822, acc: 0.9534883499145508)
[2024-11-13 10:00:10,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:11,294][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.032956093549728394, acc: 1.0)
[2024-11-13 10:00:11,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:11,971][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.20329411327838898, acc: 0.9333333373069763)
[2024-11-13 10:00:12,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:12,638][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.004771952051669359, acc: 1.0)
[2024-11-13 10:00:12,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:13,307][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.004578550346195698, acc: 1.0)
[2024-11-13 10:00:13,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:13,987][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 0.3120197355747223, acc: 0.8791208863258362)
[2024-11-13 10:00:14,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:14,696][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 0.19638682901859283, acc: 0.95652174949646)
[2024-11-13 10:00:14,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:15,415][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 0.12600025534629822, acc: 0.945652186870575)
[2024-11-13 10:00:15,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:16,097][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.1997217833995819, acc: 0.9387755393981934)
[2024-11-13 10:00:16,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:16,786][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.00644741952419281, acc: 1.0)
[2024-11-13 10:00:16,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:17,460][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.06088775768876076, acc: 0.9615384340286255)
[2024-11-13 10:00:17,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:18,133][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.01380069088190794, acc: 1.0)
[2024-11-13 10:00:18,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:18,807][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.01787475124001503, acc: 1.0)
[2024-11-13 10:00:18,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:19,484][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.09844662994146347, acc: 0.9605262875556946)
[2024-11-13 10:00:19,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:20,163][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.009293889626860619, acc: 1.0)
[2024-11-13 10:00:20,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:20,845][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.00468071224167943, acc: 1.0)
[2024-11-13 10:00:20,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:21,519][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.0031666376162320375, acc: 1.0)
[2024-11-13 10:00:21,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:22,193][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.012297457084059715, acc: 1.0)
[2024-11-13 10:00:22,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:22,878][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.0018536101561039686, acc: 1.0)
[2024-11-13 10:00:22,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:23,555][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.0035917344503104687, acc: 1.0)
[2024-11-13 10:00:23,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:24,265][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 0.16601680219173431, acc: 0.939393937587738)
[2024-11-13 10:00:24,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:24,967][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 0.1585538387298584, acc: 0.9339622855186462)
[2024-11-13 10:00:25,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:25,648][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.08945982903242111, acc: 0.9666666388511658)
[2024-11-13 10:00:25,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:26,332][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.07466299086809158, acc: 0.9821428656578064)
[2024-11-13 10:00:26,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:27,020][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.0195182915776968, acc: 1.0)
[2024-11-13 10:00:27,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:27,695][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.019206197932362556, acc: 1.0)
[2024-11-13 10:00:27,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:28,367][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.0006041050655767322, acc: 1.0)
[2024-11-13 10:00:28,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:29,045][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.008405650965869427, acc: 1.0)
[2024-11-13 10:00:29,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:29,727][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.018854163587093353, acc: 1.0)
[2024-11-13 10:00:29,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:30,431][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 0.10140633583068848, acc: 0.9640718698501587)
[2024-11-13 10:00:30,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:31,132][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.10493379831314087, acc: 0.9774436354637146)
[2024-11-13 10:00:31,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:31,854][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 0.43305984139442444, acc: 0.8716577291488647)
[2024-11-13 10:00:31,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:32,559][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.04839755967259407, acc: 0.9909909963607788)
[2024-11-13 10:00:32,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:33,231][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.004974731244146824, acc: 1.0)
[2024-11-13 10:00:33,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:33,916][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.00046763839782215655, acc: 1.0)
[2024-11-13 10:00:34,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:34,599][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.10639319568872452, acc: 0.96875)
[2024-11-13 10:00:34,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:35,271][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.0032892704475671053, acc: 1.0)
[2024-11-13 10:00:35,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:35,944][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.020258314907550812, acc: 1.0)
[2024-11-13 10:00:36,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:36,613][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.0023658843711018562, acc: 1.0)
[2024-11-13 10:00:36,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:37,281][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.007472124882042408, acc: 1.0)
[2024-11-13 10:00:37,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:37,953][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.1578376591205597, acc: 0.9523809552192688)
[2024-11-13 10:00:38,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:38,629][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.23958294093608856, acc: 0.9259259104728699)
[2024-11-13 10:00:38,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:39,311][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 0.3388204872608185, acc: 0.9223300814628601)
[2024-11-13 10:00:39,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:40,024][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 0.2319585531949997, acc: 0.9191176295280457)
[2024-11-13 10:00:40,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:40,713][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 0.24599799513816833, acc: 0.9333333373069763)
[2024-11-13 10:00:40,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:41,403][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 0.2856764793395996, acc: 0.9236111044883728)
[2024-11-13 10:00:41,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:42,075][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.008275181986391544, acc: 1.0)
[2024-11-13 10:00:42,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:42,751][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.0015798244858160615, acc: 1.0)
[2024-11-13 10:00:42,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:43,429][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.01188486535102129, acc: 1.0)
[2024-11-13 10:00:43,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:44,114][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.014978582970798016, acc: 1.0)
[2024-11-13 10:00:44,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:44,800][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.07768851518630981, acc: 0.970588207244873)
[2024-11-13 10:00:44,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:45,481][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.06695879995822906, acc: 0.9733333587646484)
[2024-11-13 10:00:45,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:46,153][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.049223244190216064, acc: 0.9696969985961914)
[2024-11-13 10:00:46,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:46,823][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.05060776695609093, acc: 0.9696969985961914)
[2024-11-13 10:00:46,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:47,498][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.0005472772172652185, acc: 1.0)
[2024-11-13 10:00:47,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:48,170][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.0018394869985058904, acc: 1.0)
[2024-11-13 10:00:48,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:48,840][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.002199655631557107, acc: 1.0)
[2024-11-13 10:00:48,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:49,515][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.005319344811141491, acc: 1.0)
[2024-11-13 10:00:49,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:50,187][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.00335955573245883, acc: 1.0)
[2024-11-13 10:00:50,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:50,856][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.004140949808061123, acc: 1.0)
[2024-11-13 10:00:50,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:51,548][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.004474117420613766, acc: 1.0)
[2024-11-13 10:00:51,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:52,221][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.0031802791636437178, acc: 1.0)
[2024-11-13 10:00:52,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:52,897][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.004987380467355251, acc: 1.0)
[2024-11-13 10:00:53,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:54,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:55,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:55,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:56,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:56,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:57,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:58,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:58,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:59,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:00:59,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:00,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:01,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:02,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:02,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:03,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:04,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:04,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:05,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:06,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:07,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:07,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:08,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:08,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:09,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:10,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:10,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:11,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:11,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:12,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:12,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:13,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:14,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:14,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:15,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:15,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:16,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:17,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:18,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:18,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:19,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:20,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:20,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:21,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:21,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:22,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:23,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:23,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:24,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:24,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:25,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:25,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:26,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:27,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:27,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:28,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:28,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:29,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:29,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:30,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:31,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:31,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:32,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:32,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:33,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:34,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:34,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:35,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:35,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:36,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:37,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:37,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:38,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:38,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:39,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:40,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:40,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:41,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:42,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:43,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:43,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:44,542][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2820, device='cuda:0') eval_epoch_loss=tensor(0.8251, device='cuda:0') eval_epoch_acc=tensor(0.8223, device='cuda:0')
[2024-11-13 10:01:44,544][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:01:44,544][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:01:45,025][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_413_loss_0.8250625729560852/model.pt
[2024-11-13 10:01:45,035][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:01:45,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:45,748][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.0035865134559571743, acc: 1.0)
[2024-11-13 10:01:45,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:46,427][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.040652621537446976, acc: 0.9545454382896423)
[2024-11-13 10:01:46,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:47,116][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.08119091391563416, acc: 0.9803921580314636)
[2024-11-13 10:01:47,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:47,789][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.007860155776143074, acc: 1.0)
[2024-11-13 10:01:47,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:48,465][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.04772260785102844, acc: 0.9444444179534912)
[2024-11-13 10:01:48,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:49,148][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.011333880014717579, acc: 1.0)
[2024-11-13 10:01:49,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:49,818][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.0035033070016652346, acc: 1.0)
[2024-11-13 10:01:49,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:50,487][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.013262112624943256, acc: 1.0)
[2024-11-13 10:01:50,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:51,178][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.014593852683901787, acc: 1.0)
[2024-11-13 10:01:51,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:51,849][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.042789261788129807, acc: 1.0)
[2024-11-13 10:01:51,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:52,536][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.017351476475596428, acc: 1.0)
[2024-11-13 10:01:52,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:53,207][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.015773532912135124, acc: 1.0)
[2024-11-13 10:01:53,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:53,880][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.08256889134645462, acc: 0.9696969985961914)
[2024-11-13 10:01:53,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:54,549][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.0026430718135088682, acc: 1.0)
[2024-11-13 10:01:54,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:55,225][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.014706039801239967, acc: 1.0)
[2024-11-13 10:01:55,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:55,895][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.001634302083402872, acc: 1.0)
[2024-11-13 10:01:55,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:56,577][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.0068167694844305515, acc: 1.0)
[2024-11-13 10:01:56,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:57,248][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.0024249115958809853, acc: 1.0)
[2024-11-13 10:01:57,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:57,921][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.0007133603794500232, acc: 1.0)
[2024-11-13 10:01:58,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:58,590][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.0010491915745660663, acc: 1.0)
[2024-11-13 10:01:58,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:59,266][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.016498245298862457, acc: 1.0)
[2024-11-13 10:01:59,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:01:59,935][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.2353777289390564, acc: 0.9200000166893005)
[2024-11-13 10:02:00,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:00,606][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.001441359636373818, acc: 1.0)
[2024-11-13 10:02:00,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:01,276][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.012626679614186287, acc: 1.0)
[2024-11-13 10:02:01,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:01,952][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.007696956396102905, acc: 1.0)
[2024-11-13 10:02:02,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:02,621][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.001588510232977569, acc: 1.0)
[2024-11-13 10:02:02,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:03,329][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.045305583626031876, acc: 0.9743589758872986)
[2024-11-13 10:02:03,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:04,026][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.21317121386528015, acc: 0.939393937587738)
[2024-11-13 10:02:04,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:04,734][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 0.5189955234527588, acc: 0.871999979019165)
[2024-11-13 10:02:04,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:05,427][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 0.3206287622451782, acc: 0.9112903475761414)
[2024-11-13 10:02:05,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:06,137][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 0.27767089009284973, acc: 0.9253731369972229)
[2024-11-13 10:02:06,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:06,837][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.02356584370136261, acc: 1.0)
[2024-11-13 10:02:06,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:07,516][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.041331466287374496, acc: 0.9772727489471436)
[2024-11-13 10:02:07,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:08,187][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.0009066248894669116, acc: 1.0)
[2024-11-13 10:02:08,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:08,859][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.002988083753734827, acc: 1.0)
[2024-11-13 10:02:08,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:09,532][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.0024559292942285538, acc: 1.0)
[2024-11-13 10:02:09,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:10,209][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.009988384321331978, acc: 1.0)
[2024-11-13 10:02:10,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:10,887][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.013700413517653942, acc: 1.0)
[2024-11-13 10:02:10,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:11,565][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.015961304306983948, acc: 0.989130437374115)
[2024-11-13 10:02:11,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:12,243][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.01413766574114561, acc: 1.0)
[2024-11-13 10:02:12,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:12,920][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.10089650005102158, acc: 0.9868420958518982)
[2024-11-13 10:02:13,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:13,595][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.03403879329562187, acc: 0.9795918464660645)
[2024-11-13 10:02:13,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:14,269][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.0032927945721894503, acc: 1.0)
[2024-11-13 10:02:14,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:14,964][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 0.28373560309410095, acc: 0.9278350472450256)
[2024-11-13 10:02:15,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:15,658][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.016654126346111298, acc: 1.0)
[2024-11-13 10:02:15,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:16,374][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 0.11367775499820709, acc: 0.9651162624359131)
[2024-11-13 10:02:16,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:17,047][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.006085663102567196, acc: 1.0)
[2024-11-13 10:02:17,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:17,736][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 0.08062869310379028, acc: 0.9753086566925049)
[2024-11-13 10:02:17,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:18,417][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.07955050468444824, acc: 0.9722222089767456)
[2024-11-13 10:02:18,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:19,089][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.005303203593939543, acc: 1.0)
[2024-11-13 10:02:19,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:19,759][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.007560409139841795, acc: 1.0)
[2024-11-13 10:02:19,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:20,435][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.05235295742750168, acc: 0.97826087474823)
[2024-11-13 10:02:20,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:21,112][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.029771944507956505, acc: 1.0)
[2024-11-13 10:02:21,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:21,795][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.0998067706823349, acc: 0.9759036302566528)
[2024-11-13 10:02:21,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:22,502][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.060801729559898376, acc: 0.9819819927215576)
[2024-11-13 10:02:22,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:23,183][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 0.17629475891590118, acc: 0.9417475461959839)
[2024-11-13 10:02:23,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:23,894][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.13037517666816711, acc: 0.9512194991111755)
[2024-11-13 10:02:23,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:24,562][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.00648821284994483, acc: 1.0)
[2024-11-13 10:02:24,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:25,234][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.2392406016588211, acc: 0.9642857313156128)
[2024-11-13 10:02:25,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:25,942][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 0.32055988907814026, acc: 0.9607843160629272)
[2024-11-13 10:02:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:26,649][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 0.4290318489074707, acc: 0.8602620363235474)
[2024-11-13 10:02:26,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:27,331][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 0.06938997656106949, acc: 0.9791666865348816)
[2024-11-13 10:02:27,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:28,028][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 0.09710375964641571, acc: 0.9754601120948792)
[2024-11-13 10:02:28,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:28,716][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 0.15733151137828827, acc: 0.9424460530281067)
[2024-11-13 10:02:28,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:29,418][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 0.3615856468677521, acc: 0.8944723606109619)
[2024-11-13 10:02:29,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:30,105][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.21304814517498016, acc: 0.9166666865348816)
[2024-11-13 10:02:30,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:30,779][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.02152104489505291, acc: 1.0)
[2024-11-13 10:02:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:31,446][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.13630501925945282, acc: 0.9629629850387573)
[2024-11-13 10:02:31,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:32,114][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.0061855134554207325, acc: 1.0)
[2024-11-13 10:02:32,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:32,783][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.008799426257610321, acc: 1.0)
[2024-11-13 10:02:32,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:33,466][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.10328705608844757, acc: 0.9655172228813171)
[2024-11-13 10:02:33,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:34,149][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.033912237733602524, acc: 1.0)
[2024-11-13 10:02:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:34,819][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.015637630596756935, acc: 1.0)
[2024-11-13 10:02:34,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:35,491][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.02792731299996376, acc: 1.0)
[2024-11-13 10:02:35,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:36,160][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.0269687008112669, acc: 1.0)
[2024-11-13 10:02:36,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:36,834][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.022488925606012344, acc: 1.0)
[2024-11-13 10:02:36,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:37,514][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.05203883349895477, acc: 0.9846153855323792)
[2024-11-13 10:02:37,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:38,185][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.016322283074259758, acc: 1.0)
[2024-11-13 10:02:38,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:38,868][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.19307829439640045, acc: 0.9655172228813171)
[2024-11-13 10:02:38,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:39,547][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.2076084464788437, acc: 0.9411764740943909)
[2024-11-13 10:02:39,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:40,214][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.004203834570944309, acc: 1.0)
[2024-11-13 10:02:40,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:40,882][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.0076714446768164635, acc: 1.0)
[2024-11-13 10:02:40,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:41,553][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.07965391129255295, acc: 0.9473684430122375)
[2024-11-13 10:02:41,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:42,239][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.2603779435157776, acc: 0.9375)
[2024-11-13 10:02:42,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:42,923][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.11379744857549667, acc: 0.966292142868042)
[2024-11-13 10:02:43,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:43,612][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 0.24620091915130615, acc: 0.8876404762268066)
[2024-11-13 10:02:43,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:44,312][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 0.4894620180130005, acc: 0.8510638475418091)
[2024-11-13 10:02:44,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:45,000][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.20196998119354248, acc: 0.9347826242446899)
[2024-11-13 10:02:45,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:45,669][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.01829797402024269, acc: 1.0)
[2024-11-13 10:02:45,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:46,365][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.06247420608997345, acc: 0.9615384340286255)
[2024-11-13 10:02:46,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:47,037][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.0013915558811277151, acc: 1.0)
[2024-11-13 10:02:47,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:47,718][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.00530521385371685, acc: 1.0)
[2024-11-13 10:02:47,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:48,395][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.008164675906300545, acc: 1.0)
[2024-11-13 10:02:48,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:49,061][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.0011804529931396246, acc: 1.0)
[2024-11-13 10:02:49,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:49,747][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 0.28647762537002563, acc: 0.9189189076423645)
[2024-11-13 10:02:49,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:50,433][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.07815591990947723, acc: 0.9718309640884399)
[2024-11-13 10:02:50,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:51,112][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.0005115636740811169, acc: 1.0)
[2024-11-13 10:02:51,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:51,784][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.0010232300264760852, acc: 1.0)
[2024-11-13 10:02:51,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:52,453][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.001997802872210741, acc: 1.0)
[2024-11-13 10:02:52,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:53,349][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 0.9535897374153137, acc: 0.7142857313156128)
[2024-11-13 10:02:53,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:54,056][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 0.2877263128757477, acc: 0.9126983880996704)
[2024-11-13 10:02:54,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:54,731][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.03083021007478237, acc: 1.0)
[2024-11-13 10:02:54,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:55,406][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.14027459919452667, acc: 0.9833333492279053)
[2024-11-13 10:02:55,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:56,090][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.12592151761054993, acc: 0.9722222089767456)
[2024-11-13 10:02:56,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:56,812][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.0011559284757822752, acc: 1.0)
[2024-11-13 10:02:56,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:57,488][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.0020327316597104073, acc: 1.0)
[2024-11-13 10:02:57,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:58,160][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.0017007933929562569, acc: 1.0)
[2024-11-13 10:02:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:58,835][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.04047185927629471, acc: 0.9629629850387573)
[2024-11-13 10:02:58,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:02:59,612][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 0.8851268291473389, acc: 0.75)
[2024-11-13 10:02:59,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:00,319][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 0.06705066561698914, acc: 0.9850746393203735)
[2024-11-13 10:03:00,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:01,007][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 0.0713149830698967, acc: 0.9781022071838379)
[2024-11-13 10:03:01,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:01,726][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 0.35949623584747314, acc: 0.8999999761581421)
[2024-11-13 10:03:01,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:02,402][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.006286436691880226, acc: 1.0)
[2024-11-13 10:03:02,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:03,080][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.061892684549093246, acc: 0.9807692170143127)
[2024-11-13 10:03:03,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:03,760][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.0012698909267783165, acc: 1.0)
[2024-11-13 10:03:03,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:04,441][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.18546205759048462, acc: 0.9344262480735779)
[2024-11-13 10:03:04,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:05,117][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.0577232800424099, acc: 0.9830508232116699)
[2024-11-13 10:03:05,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:05,790][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.1342981904745102, acc: 0.9767441749572754)
[2024-11-13 10:03:05,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:06,466][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.10640168935060501, acc: 0.9318181872367859)
[2024-11-13 10:03:06,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:07,154][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.06991828978061676, acc: 1.0)
[2024-11-13 10:03:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:07,828][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.009865962900221348, acc: 1.0)
[2024-11-13 10:03:07,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:08,499][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.005286114290356636, acc: 1.0)
[2024-11-13 10:03:08,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:09,168][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.006884673144668341, acc: 1.0)
[2024-11-13 10:03:09,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:09,839][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.002777951769530773, acc: 1.0)
[2024-11-13 10:03:09,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:10,521][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.10128874331712723, acc: 0.9846153855323792)
[2024-11-13 10:03:10,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:11,202][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.05054634064435959, acc: 0.96875)
[2024-11-13 10:03:11,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:11,882][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.015171241946518421, acc: 1.0)
[2024-11-13 10:03:11,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:12,557][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.0033306109253317118, acc: 1.0)
[2024-11-13 10:03:12,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:13,222][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.007807197980582714, acc: 1.0)
[2024-11-13 10:03:13,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:13,891][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.0030803075060248375, acc: 1.0)
[2024-11-13 10:03:13,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:14,564][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.00046905127237550914, acc: 1.0)
[2024-11-13 10:03:14,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:15,234][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.006904915440827608, acc: 1.0)
[2024-11-13 10:03:15,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:15,908][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.003275279887020588, acc: 1.0)
[2024-11-13 10:03:15,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:16,580][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.03945727273821831, acc: 1.0)
[2024-11-13 10:03:16,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:17,256][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.0015540174208581448, acc: 1.0)
[2024-11-13 10:03:17,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:17,922][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.01865764893591404, acc: 1.0)
[2024-11-13 10:03:18,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:18,590][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.0009832638315856457, acc: 1.0)
[2024-11-13 10:03:18,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:19,263][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.04695716127753258, acc: 0.9696969985961914)
[2024-11-13 10:03:19,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:19,936][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.03386543318629265, acc: 0.9750000238418579)
[2024-11-13 10:03:20,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:20,614][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.05244315043091774, acc: 0.9857142567634583)
[2024-11-13 10:03:20,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:21,315][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 0.09700486809015274, acc: 0.9781022071838379)
[2024-11-13 10:03:21,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:22,018][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 0.10474437475204468, acc: 0.9793103337287903)
[2024-11-13 10:03:22,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:22,703][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 0.09752284735441208, acc: 0.9571428298950195)
[2024-11-13 10:03:23,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:24,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:24,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:25,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:25,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:26,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:27,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:27,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:28,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:28,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:29,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:30,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:31,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:31,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:32,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:33,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:33,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:34,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:34,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:35,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:36,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:36,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:37,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:37,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:38,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:39,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:39,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:40,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:40,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:41,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:42,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:42,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:43,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:43,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:44,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:44,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:45,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:46,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:46,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:47,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:47,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:48,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:49,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:49,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:50,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:51,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:51,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:52,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:53,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:53,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:54,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:54,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:55,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:56,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:56,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:57,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:57,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:58,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:58,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:03:59,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:00,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:00,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:01,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:01,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:02,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:03,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:03,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:04,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:05,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:06,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:06,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:07,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:07,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:08,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:09,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:10,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:10,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:11,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:12,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:13,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:14,233][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2334, device='cuda:0') eval_epoch_loss=tensor(0.8035, device='cuda:0') eval_epoch_acc=tensor(0.8338, device='cuda:0')
[2024-11-13 10:04:14,234][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:04:14,234][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:04:14,680][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_556_loss_0.8035098314285278/model.pt
[2024-11-13 10:04:14,683][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:04:14,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:15,391][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 0.13369648158550262, acc: 0.9735099077224731)
[2024-11-13 10:04:15,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:16,074][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.009562580846250057, acc: 1.0)
[2024-11-13 10:04:16,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:16,749][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.028622601181268692, acc: 1.0)
[2024-11-13 10:04:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:17,419][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.005451972130686045, acc: 1.0)
[2024-11-13 10:04:17,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:18,090][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.008115863427519798, acc: 1.0)
[2024-11-13 10:04:18,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:18,766][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.004539957735687494, acc: 1.0)
[2024-11-13 10:04:18,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:19,468][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.11189825087785721, acc: 0.9555555582046509)
[2024-11-13 10:04:19,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:20,161][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.05141814053058624, acc: 0.9740259647369385)
[2024-11-13 10:04:20,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:20,836][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.01041430700570345, acc: 1.0)
[2024-11-13 10:04:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:21,512][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.058990564197301865, acc: 0.982758641242981)
[2024-11-13 10:04:21,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:22,196][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.05110381916165352, acc: 0.988095223903656)
[2024-11-13 10:04:22,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:22,870][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.007575006689876318, acc: 1.0)
[2024-11-13 10:04:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:23,541][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.11422378569841385, acc: 0.9629629850387573)
[2024-11-13 10:04:23,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:24,266][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 0.1514860838651657, acc: 0.9625668525695801)
[2024-11-13 10:04:24,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:24,941][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.0028716532979160547, acc: 1.0)
[2024-11-13 10:04:25,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:25,640][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.08332899212837219, acc: 0.9743589758872986)
[2024-11-13 10:04:25,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:26,344][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 0.20771858096122742, acc: 0.9438775777816772)
[2024-11-13 10:04:26,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:27,050][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 0.12264859676361084, acc: 0.9622641801834106)
[2024-11-13 10:04:27,467][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.1356, train_epoch_loss=0.1272, epoch time 603.0847706124187s
[2024-11-13 10:04:27,467][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 10:04:27,467][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 10:04:27,468][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 10:04:27,468][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-11-13 10:04:27,468][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 10:04:28,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:28,917][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.0050364467315375805, acc: 1.0)
[2024-11-13 10:04:28,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:29,614][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.04976518452167511, acc: 1.0)
[2024-11-13 10:04:29,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:30,313][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.24129259586334229, acc: 0.9459459185600281)
[2024-11-13 10:04:30,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:31,014][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.0261898972094059, acc: 1.0)
[2024-11-13 10:04:31,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:31,698][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.15909899771213531, acc: 0.9729729890823364)
[2024-11-13 10:04:31,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:32,381][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.03637460991740227, acc: 1.0)
[2024-11-13 10:04:32,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:33,064][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.014404522255063057, acc: 1.0)
[2024-11-13 10:04:33,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:33,747][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.026916921138763428, acc: 0.9666666388511658)
[2024-11-13 10:04:33,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:34,436][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.00029276841087266803, acc: 1.0)
[2024-11-13 10:04:34,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:35,124][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.0024889963679015636, acc: 1.0)
[2024-11-13 10:04:35,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:35,808][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.0013729287311434746, acc: 1.0)
[2024-11-13 10:04:35,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:36,502][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.21869617700576782, acc: 0.9743589758872986)
[2024-11-13 10:04:36,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:37,183][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.13822060823440552, acc: 0.9696969985961914)
[2024-11-13 10:04:37,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:37,870][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.011352763511240482, acc: 1.0)
[2024-11-13 10:04:37,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:38,569][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.015259221196174622, acc: 1.0)
[2024-11-13 10:04:38,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:39,259][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.01566419005393982, acc: 1.0)
[2024-11-13 10:04:39,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:39,939][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.009527698159217834, acc: 1.0)
[2024-11-13 10:04:40,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:40,621][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.010258759371936321, acc: 1.0)
[2024-11-13 10:04:40,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:41,305][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.038340553641319275, acc: 1.0)
[2024-11-13 10:04:41,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:41,985][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.00083508575335145, acc: 1.0)
[2024-11-13 10:04:42,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:42,670][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.027542678639292717, acc: 1.0)
[2024-11-13 10:04:42,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:43,354][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.02477990835905075, acc: 1.0)
[2024-11-13 10:04:43,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:44,036][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.22378137707710266, acc: 0.9599999785423279)
[2024-11-13 10:04:44,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:44,717][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.002293902449309826, acc: 1.0)
[2024-11-13 10:04:44,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:45,397][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.006757944822311401, acc: 1.0)
[2024-11-13 10:04:45,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:46,095][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.1830461472272873, acc: 0.9622641801834106)
[2024-11-13 10:04:46,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:46,785][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.24798014760017395, acc: 0.9178082346916199)
[2024-11-13 10:04:46,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:47,586][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 0.7321706414222717, acc: 0.7549406886100769)
[2024-11-13 10:04:47,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:48,283][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.05606687441468239, acc: 0.9767441749572754)
[2024-11-13 10:04:48,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:48,977][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.06486248224973679, acc: 0.9879518151283264)
[2024-11-13 10:04:49,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:49,685][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.08994154632091522, acc: 0.9753086566925049)
[2024-11-13 10:04:49,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:50,372][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.13631102442741394, acc: 0.9642857313156128)
[2024-11-13 10:04:50,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:51,056][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.016368268057703972, acc: 1.0)
[2024-11-13 10:04:51,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:51,737][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.0007790676318109035, acc: 1.0)
[2024-11-13 10:04:51,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:52,437][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 0.11275771260261536, acc: 0.9327731132507324)
[2024-11-13 10:04:52,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:53,127][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.09532640129327774, acc: 0.9672130942344666)
[2024-11-13 10:04:53,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:53,829][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.2768186926841736, acc: 0.9047619104385376)
[2024-11-13 10:04:53,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:54,531][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.0585615374147892, acc: 0.9661017060279846)
[2024-11-13 10:04:54,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:55,230][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.03231631591916084, acc: 0.9885057210922241)
[2024-11-13 10:04:55,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:55,928][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.001388503354974091, acc: 1.0)
[2024-11-13 10:04:56,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:56,612][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.037018366158008575, acc: 0.9615384340286255)
[2024-11-13 10:04:56,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:57,307][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.1731976866722107, acc: 0.9729729890823364)
[2024-11-13 10:04:57,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:58,000][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.05348837375640869, acc: 0.9846153855323792)
[2024-11-13 10:04:58,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:58,692][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.11374476552009583, acc: 0.9797979593276978)
[2024-11-13 10:04:58,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:04:59,387][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.1197689101099968, acc: 0.9484536051750183)
[2024-11-13 10:04:59,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:00,089][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 0.1333850622177124, acc: 0.970588207244873)
[2024-11-13 10:05:00,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:00,774][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.009249760769307613, acc: 1.0)
[2024-11-13 10:05:00,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:01,459][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.004166794940829277, acc: 1.0)
[2024-11-13 10:05:01,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:02,144][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.004539735149592161, acc: 1.0)
[2024-11-13 10:05:02,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:02,828][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.01843957044184208, acc: 1.0)
[2024-11-13 10:05:02,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:03,524][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.02983574941754341, acc: 1.0)
[2024-11-13 10:05:03,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:04,221][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.025702696293592453, acc: 1.0)
[2024-11-13 10:05:04,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:04,916][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.2917507290840149, acc: 0.9014084339141846)
[2024-11-13 10:05:04,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:05,638][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 0.5128227472305298, acc: 0.8399999737739563)
[2024-11-13 10:05:05,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:06,323][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.12204387038946152, acc: 0.9459459185600281)
[2024-11-13 10:05:06,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:07,007][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.4886060357093811, acc: 0.9230769276618958)
[2024-11-13 10:05:07,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:07,854][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.0118907690048218, acc: 0.703071653842926)
[2024-11-13 10:05:07,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:08,634][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 1.185275912284851, acc: 0.6470588445663452)
[2024-11-13 10:05:08,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:09,356][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 0.30483344197273254, acc: 0.8977272510528564)
[2024-11-13 10:05:09,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:10,064][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 0.15370245277881622, acc: 0.9411764740943909)
[2024-11-13 10:05:10,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:10,783][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 0.3043239116668701, acc: 0.8840579986572266)
[2024-11-13 10:05:10,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:11,501][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.11890088021755219, acc: 0.9750000238418579)
[2024-11-13 10:05:11,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:12,182][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.10953380167484283, acc: 0.9411764740943909)
[2024-11-13 10:05:12,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:12,872][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.0066372426226735115, acc: 1.0)
[2024-11-13 10:05:12,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:13,574][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.008145834319293499, acc: 1.0)
[2024-11-13 10:05:13,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:14,259][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.0067787012085318565, acc: 1.0)
[2024-11-13 10:05:14,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:14,948][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.053483571857213974, acc: 0.9821428656578064)
[2024-11-13 10:05:15,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:15,637][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.06239013001322746, acc: 0.9666666388511658)
[2024-11-13 10:05:15,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:16,317][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.0018650469137355685, acc: 1.0)
[2024-11-13 10:05:16,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:17,002][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.0744214579463005, acc: 0.9722222089767456)
[2024-11-13 10:05:17,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:17,684][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.0822763592004776, acc: 0.939393937587738)
[2024-11-13 10:05:17,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:18,399][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 0.3110887408256531, acc: 0.8823529481887817)
[2024-11-13 10:05:18,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:19,095][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 0.21923352777957916, acc: 0.9444444179534912)
[2024-11-13 10:05:19,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:19,818][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 0.509870707988739, acc: 0.8512820601463318)
[2024-11-13 10:05:19,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:20,523][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.31288859248161316, acc: 0.918367326259613)
[2024-11-13 10:05:20,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:21,220][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 0.46766841411590576, acc: 0.8731343150138855)
[2024-11-13 10:05:21,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:21,962][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 0.8486857414245605, acc: 0.7700729966163635)
[2024-11-13 10:05:22,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:22,641][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.0032961233519017696, acc: 1.0)
[2024-11-13 10:05:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:23,326][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.004965159576386213, acc: 1.0)
[2024-11-13 10:05:23,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:24,017][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.0059564984403550625, acc: 1.0)
[2024-11-13 10:05:24,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:24,706][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.0033349532168358564, acc: 1.0)
[2024-11-13 10:05:24,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:25,398][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.0414520762860775, acc: 0.9807692170143127)
[2024-11-13 10:05:25,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:26,088][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.13213202357292175, acc: 0.9615384340286255)
[2024-11-13 10:05:26,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:26,772][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.014407776296138763, acc: 1.0)
[2024-11-13 10:05:26,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:27,462][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.030193211510777473, acc: 0.9855072498321533)
[2024-11-13 10:05:27,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:28,166][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.047076910734176636, acc: 1.0)
[2024-11-13 10:05:28,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:28,855][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.048635855317115784, acc: 1.0)
[2024-11-13 10:05:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:29,556][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.08140768110752106, acc: 1.0)
[2024-11-13 10:05:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:30,256][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.2287304401397705, acc: 0.9223300814628601)
[2024-11-13 10:05:30,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:30,972][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 0.41158291697502136, acc: 0.8737863898277283)
[2024-11-13 10:05:31,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:31,694][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 0.5322113633155823, acc: 0.8440860509872437)
[2024-11-13 10:05:31,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:32,429][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 0.46690747141838074, acc: 0.875)
[2024-11-13 10:05:32,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:33,128][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.20141765475273132, acc: 0.9263157844543457)
[2024-11-13 10:05:33,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:33,862][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 0.28229159116744995, acc: 0.9405940771102905)
[2024-11-13 10:05:33,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:34,565][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.22917281091213226, acc: 0.9516128897666931)
[2024-11-13 10:05:34,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:35,263][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.0617491751909256, acc: 0.9710144996643066)
[2024-11-13 10:05:35,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:35,961][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 0.25539350509643555, acc: 0.9411764740943909)
[2024-11-13 10:05:36,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:36,658][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 0.25003936886787415, acc: 0.9134615659713745)
[2024-11-13 10:05:36,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:37,359][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 0.33718180656433105, acc: 0.9051094651222229)
[2024-11-13 10:05:37,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:38,058][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.24482686817646027, acc: 0.9402984976768494)
[2024-11-13 10:05:38,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:38,741][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.0022176229394972324, acc: 1.0)
[2024-11-13 10:05:38,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:39,425][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.0075690229423344135, acc: 1.0)
[2024-11-13 10:05:39,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:40,103][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.002583425957709551, acc: 1.0)
[2024-11-13 10:05:40,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:40,787][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.005269589368253946, acc: 1.0)
[2024-11-13 10:05:40,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:41,477][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.025255780667066574, acc: 1.0)
[2024-11-13 10:05:41,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:42,160][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.007623828947544098, acc: 1.0)
[2024-11-13 10:05:42,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:42,841][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.0009342235862277448, acc: 1.0)
[2024-11-13 10:05:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:43,519][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.0006180335767567158, acc: 1.0)
[2024-11-13 10:05:43,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:44,201][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.004273820668458939, acc: 1.0)
[2024-11-13 10:05:44,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:44,890][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.006876904517412186, acc: 1.0)
[2024-11-13 10:05:44,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:45,591][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.010491851717233658, acc: 1.0)
[2024-11-13 10:05:45,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:46,283][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.013331963680684566, acc: 1.0)
[2024-11-13 10:05:46,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:46,969][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.22505974769592285, acc: 0.9122806787490845)
[2024-11-13 10:05:47,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:47,652][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.01848379522562027, acc: 1.0)
[2024-11-13 10:05:47,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:48,337][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.01135504711419344, acc: 1.0)
[2024-11-13 10:05:48,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:49,018][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.0903601348400116, acc: 0.9545454382896423)
[2024-11-13 10:05:49,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:49,720][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.08681740611791611, acc: 0.9523809552192688)
[2024-11-13 10:05:49,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:50,414][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.16172194480895996, acc: 0.934959352016449)
[2024-11-13 10:05:50,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:51,103][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.04659554362297058, acc: 0.9838709831237793)
[2024-11-13 10:05:51,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:51,863][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 0.32093876600265503, acc: 0.8897338509559631)
[2024-11-13 10:05:51,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:52,561][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.09637926518917084, acc: 0.9733333587646484)
[2024-11-13 10:05:52,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:53,254][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.0055046784691512585, acc: 1.0)
[2024-11-13 10:05:53,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:53,938][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.008731585927307606, acc: 1.0)
[2024-11-13 10:05:54,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:54,620][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.006948897615075111, acc: 1.0)
[2024-11-13 10:05:54,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:55,320][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 0.19196045398712158, acc: 0.9447852969169617)
[2024-11-13 10:05:56,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:56,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:57,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:58,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:58,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:59,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:05:59,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:00,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:01,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:01,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:02,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:02,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:03,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:03,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:04,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:05,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:05,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:06,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:06,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:07,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:08,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:08,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:09,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:09,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:10,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:10,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:11,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:12,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:12,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:14,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:14,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:15,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:15,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:16,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:16,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:17,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:18,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:18,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:19,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:19,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:20,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:20,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:21,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:22,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:22,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:23,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:23,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:24,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:25,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:25,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:26,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:26,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:27,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:28,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:28,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:29,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:29,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:30,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:31,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:31,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:32,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:32,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:33,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:34,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:34,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:35,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:35,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:36,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:36,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:37,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:38,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:38,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:39,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:40,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:40,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:41,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:41,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:42,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:42,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:43,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:44,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:44,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:45,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:45,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:46,885][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2905, device='cuda:0') eval_epoch_loss=tensor(0.8288, device='cuda:0') eval_epoch_acc=tensor(0.8315, device='cuda:0')
[2024-11-13 10:06:46,886][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:06:46,887][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:06:47,298][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_125_loss_0.8287546038627625/model.pt
[2024-11-13 10:06:47,302][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:06:47,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:48,033][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 0.20215244591236115, acc: 0.9513888955116272)
[2024-11-13 10:06:48,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:48,716][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 0.1859176754951477, acc: 0.949999988079071)
[2024-11-13 10:06:48,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:49,446][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 0.15385814011096954, acc: 0.9583333134651184)
[2024-11-13 10:06:49,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:50,156][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 0.27187561988830566, acc: 0.9333333373069763)
[2024-11-13 10:06:50,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:50,879][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 0.3526136875152588, acc: 0.904411792755127)
[2024-11-13 10:06:50,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:51,550][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.037773992866277695, acc: 1.0)
[2024-11-13 10:06:51,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:52,216][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.18130433559417725, acc: 0.95652174949646)
[2024-11-13 10:06:52,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:52,886][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.014992787502706051, acc: 1.0)
[2024-11-13 10:06:52,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:53,566][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.05164087936282158, acc: 1.0)
[2024-11-13 10:06:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:54,239][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.02872062660753727, acc: 1.0)
[2024-11-13 10:06:54,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:54,908][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.06537698209285736, acc: 0.9615384340286255)
[2024-11-13 10:06:54,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:55,584][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.11937624961137772, acc: 0.9523809552192688)
[2024-11-13 10:06:55,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:56,253][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.02552684210240841, acc: 1.0)
[2024-11-13 10:06:56,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:56,923][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.01271566841751337, acc: 1.0)
[2024-11-13 10:06:57,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:57,591][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.007476030848920345, acc: 1.0)
[2024-11-13 10:06:57,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:58,260][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.01328753586858511, acc: 1.0)
[2024-11-13 10:06:58,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:58,928][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.3254547119140625, acc: 0.9354838728904724)
[2024-11-13 10:06:59,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:06:59,600][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.11362835019826889, acc: 0.9459459185600281)
[2024-11-13 10:06:59,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:00,305][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 0.2360449731349945, acc: 0.9298245906829834)
[2024-11-13 10:07:00,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:00,987][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.21196706593036652, acc: 0.9179104566574097)
[2024-11-13 10:07:01,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:01,689][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 0.10744516551494598, acc: 0.9795918464660645)
[2024-11-13 10:07:01,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:02,391][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 0.17245280742645264, acc: 0.957446813583374)
[2024-11-13 10:07:02,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:03,082][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.24055717885494232, acc: 0.8857142925262451)
[2024-11-13 10:07:03,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:03,761][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.04524075984954834, acc: 0.9642857313156128)
[2024-11-13 10:07:03,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:04,433][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.32937851548194885, acc: 0.95652174949646)
[2024-11-13 10:07:04,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:05,100][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.04599739611148834, acc: 0.9655172228813171)
[2024-11-13 10:07:05,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:05,774][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.2073204070329666, acc: 0.95652174949646)
[2024-11-13 10:07:05,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:06,455][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.11936641484498978, acc: 0.9661017060279846)
[2024-11-13 10:07:06,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:07,153][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.06902395188808441, acc: 0.9649122953414917)
[2024-11-13 10:07:07,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:07,835][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.2762487232685089, acc: 0.9189189076423645)
[2024-11-13 10:07:07,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:08,517][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.4185362160205841, acc: 0.9642857313156128)
[2024-11-13 10:07:08,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:09,184][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.03872690349817276, acc: 0.95652174949646)
[2024-11-13 10:07:09,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:09,854][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.018361316993832588, acc: 1.0)
[2024-11-13 10:07:09,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:10,540][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 0.0725194439291954, acc: 0.9864864945411682)
[2024-11-13 10:07:10,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:11,217][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.1360398381948471, acc: 0.9444444179534912)
[2024-11-13 10:07:11,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:11,902][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 0.07424623519182205, acc: 0.9767441749572754)
[2024-11-13 10:07:11,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:12,594][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 0.12527623772621155, acc: 0.9529411792755127)
[2024-11-13 10:07:12,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:13,277][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 0.15060685575008392, acc: 0.966292142868042)
[2024-11-13 10:07:13,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:13,961][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.13525766134262085, acc: 0.9772727489471436)
[2024-11-13 10:07:14,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:14,634][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.0267369095236063, acc: 1.0)
[2024-11-13 10:07:14,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:15,341][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 0.08606895804405212, acc: 0.9655172228813171)
[2024-11-13 10:07:15,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:16,026][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.0024269726127386093, acc: 1.0)
[2024-11-13 10:07:16,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:16,697][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.005298706702888012, acc: 1.0)
[2024-11-13 10:07:16,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:17,382][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.09369324892759323, acc: 0.9722222089767456)
[2024-11-13 10:07:17,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:18,069][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 0.2830617427825928, acc: 0.9215686321258545)
[2024-11-13 10:07:18,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:18,800][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 0.7563369274139404, acc: 0.801369845867157)
[2024-11-13 10:07:18,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:19,472][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.001517392578534782, acc: 1.0)
[2024-11-13 10:07:19,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:20,138][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.007418928202241659, acc: 1.0)
[2024-11-13 10:07:20,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:20,808][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.03345774859189987, acc: 1.0)
[2024-11-13 10:07:20,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:21,511][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 0.16819489002227783, acc: 0.9380530714988708)
[2024-11-13 10:07:21,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:22,188][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.0822812169790268, acc: 0.9855072498321533)
[2024-11-13 10:07:22,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:22,870][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.0900096595287323, acc: 0.9545454382896423)
[2024-11-13 10:07:22,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:23,588][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 0.2692638039588928, acc: 0.9312977194786072)
[2024-11-13 10:07:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:24,290][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 0.3427567183971405, acc: 0.8666666746139526)
[2024-11-13 10:07:24,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:24,969][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.05128100886940956, acc: 1.0)
[2024-11-13 10:07:25,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:25,638][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.014526802115142345, acc: 1.0)
[2024-11-13 10:07:25,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:26,321][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.004010086879134178, acc: 1.0)
[2024-11-13 10:07:26,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:26,999][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.0054695927537977695, acc: 1.0)
[2024-11-13 10:07:27,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:27,682][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.022020621225237846, acc: 1.0)
[2024-11-13 10:07:27,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:28,416][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 0.3193492889404297, acc: 0.9003021121025085)
[2024-11-13 10:07:28,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:29,141][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 0.2992327809333801, acc: 0.9193083643913269)
[2024-11-13 10:07:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:29,867][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 0.19861674308776855, acc: 0.940625011920929)
[2024-11-13 10:07:29,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:30,637][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 0.48850110173225403, acc: 0.8592870831489563)
[2024-11-13 10:07:30,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:31,374][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 0.2834053039550781, acc: 0.9039145708084106)
[2024-11-13 10:07:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:32,058][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.011166725307703018, acc: 1.0)
[2024-11-13 10:07:32,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:32,740][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 0.23206110298633575, acc: 0.9069767594337463)
[2024-11-13 10:07:32,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:33,425][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 0.31186947226524353, acc: 0.9047619104385376)
[2024-11-13 10:07:33,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:34,114][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 0.24118316173553467, acc: 0.9015151262283325)
[2024-11-13 10:07:34,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:34,805][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 0.07882274687290192, acc: 0.9764705896377563)
[2024-11-13 10:07:34,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:35,523][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 0.33535972237586975, acc: 0.8765432238578796)
[2024-11-13 10:07:35,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:36,220][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.1764809936285019, acc: 0.9516128897666931)
[2024-11-13 10:07:36,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:36,891][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.037587158381938934, acc: 1.0)
[2024-11-13 10:07:36,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:37,563][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.0996527150273323, acc: 0.949999988079071)
[2024-11-13 10:07:37,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:38,242][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.07763613015413284, acc: 0.9558823704719543)
[2024-11-13 10:07:38,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:38,929][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 0.17279160022735596, acc: 0.9411764740943909)
[2024-11-13 10:07:39,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:39,616][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 0.2592873275279999, acc: 0.9237288236618042)
[2024-11-13 10:07:39,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:40,316][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 0.12101110816001892, acc: 0.9850746393203735)
[2024-11-13 10:07:40,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:41,015][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 0.15333543717861176, acc: 0.9708737730979919)
[2024-11-13 10:07:41,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:41,702][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.15074312686920166, acc: 0.9365079402923584)
[2024-11-13 10:07:41,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:42,387][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.05356258526444435, acc: 0.9780219793319702)
[2024-11-13 10:07:42,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:43,104][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 0.18341219425201416, acc: 0.9461883306503296)
[2024-11-13 10:07:43,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:43,827][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 0.1620510369539261, acc: 0.9527559280395508)
[2024-11-13 10:07:43,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:44,542][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 0.1412392109632492, acc: 0.9482758641242981)
[2024-11-13 10:07:44,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:45,254][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 0.17873388528823853, acc: 0.945652186870575)
[2024-11-13 10:07:45,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:45,969][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 0.09846481680870056, acc: 0.9649805426597595)
[2024-11-13 10:07:46,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:46,673][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 0.08684752136468887, acc: 0.97826087474823)
[2024-11-13 10:07:46,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:47,345][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.0015587646048516035, acc: 1.0)
[2024-11-13 10:07:47,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:48,013][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.0036864413414150476, acc: 1.0)
[2024-11-13 10:07:48,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:48,697][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.0009570781840011477, acc: 1.0)
[2024-11-13 10:07:48,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:49,403][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.13090215623378754, acc: 0.9615384340286255)
[2024-11-13 10:07:49,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:50,081][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.0018964629853144288, acc: 1.0)
[2024-11-13 10:07:50,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:50,764][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.04560329020023346, acc: 0.9883720874786377)
[2024-11-13 10:07:50,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:51,451][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.05000979080796242, acc: 0.9909909963607788)
[2024-11-13 10:07:51,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:52,135][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.05832016095519066, acc: 0.9777777791023254)
[2024-11-13 10:07:52,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:52,809][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.04379655420780182, acc: 1.0)
[2024-11-13 10:07:52,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:53,484][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.01798059232532978, acc: 1.0)
[2024-11-13 10:07:53,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:54,160][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.058594342321157455, acc: 0.9599999785423279)
[2024-11-13 10:07:54,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:54,845][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.22649574279785156, acc: 0.9230769276618958)
[2024-11-13 10:07:54,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:55,560][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.3115709722042084, acc: 0.9130434989929199)
[2024-11-13 10:07:55,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:56,264][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 0.17202118039131165, acc: 0.9431818127632141)
[2024-11-13 10:07:56,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:56,971][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.23340950906276703, acc: 0.9468085169792175)
[2024-11-13 10:07:57,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:57,649][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.11592831462621689, acc: 0.9433962106704712)
[2024-11-13 10:07:57,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:58,327][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.17510806024074554, acc: 0.9666666388511658)
[2024-11-13 10:07:58,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:59,025][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.05496310070157051, acc: 0.9767441749572754)
[2024-11-13 10:07:59,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:07:59,702][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.0041831424459815025, acc: 1.0)
[2024-11-13 10:07:59,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:00,390][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 0.4984642565250397, acc: 0.8421052694320679)
[2024-11-13 10:08:00,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:01,070][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.13076519966125488, acc: 0.9555555582046509)
[2024-11-13 10:08:01,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:01,777][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 0.31364259123802185, acc: 0.9055555462837219)
[2024-11-13 10:08:01,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:02,490][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 0.7806962132453918, acc: 0.7706422209739685)
[2024-11-13 10:08:02,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:03,197][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 0.32937830686569214, acc: 0.8999999761581421)
[2024-11-13 10:08:03,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:03,867][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.006928680930286646, acc: 1.0)
[2024-11-13 10:08:03,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:04,533][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.003947105724364519, acc: 1.0)
[2024-11-13 10:08:04,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:05,201][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.14149688184261322, acc: 0.9545454382896423)
[2024-11-13 10:08:05,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:05,903][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.005736048799008131, acc: 1.0)
[2024-11-13 10:08:06,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:06,591][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.028900299221277237, acc: 1.0)
[2024-11-13 10:08:06,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:07,272][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.02920047752559185, acc: 1.0)
[2024-11-13 10:08:07,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:07,948][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.06676305085420609, acc: 0.9772727489471436)
[2024-11-13 10:08:08,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:08,627][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 0.07190687954425812, acc: 0.9838709831237793)
[2024-11-13 10:08:08,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:09,308][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.19666814804077148, acc: 0.9545454382896423)
[2024-11-13 10:08:09,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:09,978][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.0002722541394177824, acc: 1.0)
[2024-11-13 10:08:10,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:10,650][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.10008592158555984, acc: 0.9615384340286255)
[2024-11-13 10:08:10,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:11,322][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.07195276767015457, acc: 0.9677419066429138)
[2024-11-13 10:08:11,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:12,006][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.001291630556806922, acc: 1.0)
[2024-11-13 10:08:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:12,692][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.004968906752765179, acc: 1.0)
[2024-11-13 10:08:12,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:13,385][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.026524720713496208, acc: 1.0)
[2024-11-13 10:08:13,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:14,067][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.0014637075364589691, acc: 1.0)
[2024-11-13 10:08:14,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:14,751][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.015785083174705505, acc: 1.0)
[2024-11-13 10:08:14,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:15,424][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.002253857674077153, acc: 1.0)
[2024-11-13 10:08:15,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:16,110][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.014361191540956497, acc: 1.0)
[2024-11-13 10:08:16,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:16,783][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.0029513442423194647, acc: 1.0)
[2024-11-13 10:08:16,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:17,472][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.016527872532606125, acc: 1.0)
[2024-11-13 10:08:17,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:18,152][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.007634664420038462, acc: 1.0)
[2024-11-13 10:08:18,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:18,828][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.0162111297249794, acc: 1.0)
[2024-11-13 10:08:18,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:19,520][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.02712073177099228, acc: 0.9868420958518982)
[2024-11-13 10:08:19,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:20,225][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.04967708885669708, acc: 0.9811320900917053)
[2024-11-13 10:08:20,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:20,932][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 0.12093761563301086, acc: 0.9583333134651184)
[2024-11-13 10:08:21,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:21,609][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.009629491716623306, acc: 1.0)
[2024-11-13 10:08:21,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:22,283][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.022609980776906013, acc: 1.0)
[2024-11-13 10:08:22,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:22,967][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.177984356880188, acc: 0.9733333587646484)
[2024-11-13 10:08:23,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:23,640][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.09396324306726456, acc: 0.9583333134651184)
[2024-11-13 10:08:23,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:24,355][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 0.4959483742713928, acc: 0.8399999737739563)
[2024-11-13 10:08:24,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:25,033][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.30959537625312805, acc: 0.8539325594902039)
[2024-11-13 10:08:25,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:25,712][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.1891457587480545, acc: 0.9324324131011963)
[2024-11-13 10:08:26,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:27,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:27,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:28,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:29,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:29,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:30,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:30,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:31,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:32,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:32,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:33,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:33,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:34,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:34,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:35,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:36,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:36,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:37,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:38,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:38,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:39,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:39,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:40,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:40,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:41,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:42,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:42,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:43,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:44,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:44,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:45,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:45,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:46,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:46,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:47,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:48,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:48,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:49,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:49,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:50,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:51,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:51,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:52,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:52,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:53,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:54,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:54,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:55,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:55,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:56,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:56,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:57,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:57,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:58,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:59,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:08:59,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:00,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:00,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:01,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:02,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:02,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:03,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:04,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:04,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:05,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:05,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:06,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:06,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:07,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:08,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:08,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:09,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:09,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:10,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:11,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:11,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:12,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:12,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:13,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:14,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:14,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:15,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:15,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:16,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:17,356][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1569, device='cuda:0') eval_epoch_loss=tensor(0.7687, device='cuda:0') eval_epoch_acc=tensor(0.8346, device='cuda:0')
[2024-11-13 10:09:17,358][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:09:17,358][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:09:17,696][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_268_loss_0.7686601877212524/model.pt
[2024-11-13 10:09:17,701][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:09:17,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:18,410][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.037053290754556656, acc: 1.0)
[2024-11-13 10:09:18,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:19,093][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.025226254016160965, acc: 1.0)
[2024-11-13 10:09:19,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:19,766][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.0006297664367593825, acc: 1.0)
[2024-11-13 10:09:19,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:20,447][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.015365025028586388, acc: 1.0)
[2024-11-13 10:09:20,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:21,132][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.0021092284005135298, acc: 1.0)
[2024-11-13 10:09:21,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:21,810][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.2127862572669983, acc: 0.9166666865348816)
[2024-11-13 10:09:21,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:22,482][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.009249532595276833, acc: 1.0)
[2024-11-13 10:09:22,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:23,162][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.0021418293472379446, acc: 1.0)
[2024-11-13 10:09:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:23,835][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.32038605213165283, acc: 0.931034505367279)
[2024-11-13 10:09:23,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:24,516][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.012349152937531471, acc: 1.0)
[2024-11-13 10:09:24,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:25,194][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.06305360049009323, acc: 0.957446813583374)
[2024-11-13 10:09:25,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:25,870][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.11307772994041443, acc: 0.9791666865348816)
[2024-11-13 10:09:25,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:26,545][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.028274891898036003, acc: 0.9772727489471436)
[2024-11-13 10:09:26,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:27,230][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.16804297268390656, acc: 0.9277108311653137)
[2024-11-13 10:09:27,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:27,913][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 0.13267077505588531, acc: 0.9537037014961243)
[2024-11-13 10:09:27,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:28,585][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.11907825618982315, acc: 0.9473684430122375)
[2024-11-13 10:09:28,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:29,259][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.03667188808321953, acc: 1.0)
[2024-11-13 10:09:29,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:29,937][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.040903713554143906, acc: 0.9750000238418579)
[2024-11-13 10:09:30,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:30,622][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 0.07004968076944351, acc: 0.984375)
[2024-11-13 10:09:30,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:31,322][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 0.11281690746545792, acc: 0.9760000109672546)
[2024-11-13 10:09:31,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:32,003][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.03774995729327202, acc: 0.9890109896659851)
[2024-11-13 10:09:32,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:32,696][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 0.1028730720281601, acc: 0.9627329111099243)
[2024-11-13 10:09:32,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:33,405][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 0.1619870811700821, acc: 0.9432989954948425)
[2024-11-13 10:09:33,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:34,074][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.0005247273948043585, acc: 1.0)
[2024-11-13 10:09:34,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:34,749][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.03723707050085068, acc: 0.976190447807312)
[2024-11-13 10:09:34,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:35,432][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.10228744149208069, acc: 0.982758641242981)
[2024-11-13 10:09:35,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:36,120][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.14668263494968414, acc: 0.9818181991577148)
[2024-11-13 10:09:36,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:36,843][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 0.29701483249664307, acc: 0.8969072103500366)
[2024-11-13 10:09:36,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:37,533][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.03578715771436691, acc: 0.982758641242981)
[2024-11-13 10:09:37,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:38,207][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.022643527016043663, acc: 1.0)
[2024-11-13 10:09:38,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:38,884][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.20478962361812592, acc: 0.9210526347160339)
[2024-11-13 10:09:38,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:39,561][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.28045403957366943, acc: 0.9821428656578064)
[2024-11-13 10:09:39,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:40,238][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.012482065707445145, acc: 1.0)
[2024-11-13 10:09:40,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:40,917][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.06061650067567825, acc: 0.9622641801834106)
[2024-11-13 10:09:40,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:41,606][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.010988863185048103, acc: 1.0)
[2024-11-13 10:09:41,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:42,285][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.004010148346424103, acc: 1.0)
[2024-11-13 10:09:42,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:42,968][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.004502030089497566, acc: 1.0)
[2024-11-13 10:09:43,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:43,652][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.01852559484541416, acc: 0.9836065769195557)
[2024-11-13 10:09:43,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:44,323][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.011210758239030838, acc: 1.0)
[2024-11-13 10:09:44,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:44,994][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.00020915607456117868, acc: 1.0)
[2024-11-13 10:09:45,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:45,675][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.023003390058875084, acc: 0.9855072498321533)
[2024-11-13 10:09:45,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:46,360][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.10876838117837906, acc: 0.9722222089767456)
[2024-11-13 10:09:46,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:47,042][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.05604081600904465, acc: 0.9759036302566528)
[2024-11-13 10:09:47,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:47,725][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.20331141352653503, acc: 0.9743589758872986)
[2024-11-13 10:09:47,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:48,424][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.032012563198804855, acc: 1.0)
[2024-11-13 10:09:48,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:49,095][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.0018932664534077048, acc: 1.0)
[2024-11-13 10:09:49,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:49,775][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.024223843589425087, acc: 1.0)
[2024-11-13 10:09:49,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:50,449][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.015866050496697426, acc: 1.0)
[2024-11-13 10:09:50,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:51,128][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.002676401985809207, acc: 1.0)
[2024-11-13 10:09:51,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:51,810][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.019922690466046333, acc: 1.0)
[2024-11-13 10:09:51,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:52,497][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.09101676940917969, acc: 0.9807692170143127)
[2024-11-13 10:09:52,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:53,208][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.015003714710474014, acc: 1.0)
[2024-11-13 10:09:53,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:53,917][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.1003127247095108, acc: 0.9677419066429138)
[2024-11-13 10:09:54,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:54,591][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.015799563378095627, acc: 1.0)
[2024-11-13 10:09:54,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:55,260][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.5699673891067505, acc: 0.9259259104728699)
[2024-11-13 10:09:55,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:55,933][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.08452001214027405, acc: 0.9714285731315613)
[2024-11-13 10:09:56,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:56,608][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.06398327648639679, acc: 0.9743589758872986)
[2024-11-13 10:09:56,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:57,285][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.13375237584114075, acc: 0.9512194991111755)
[2024-11-13 10:09:57,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:57,964][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.12615595757961273, acc: 0.9736841917037964)
[2024-11-13 10:09:58,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:58,634][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.003830115543678403, acc: 1.0)
[2024-11-13 10:09:58,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:59,316][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.01292349211871624, acc: 1.0)
[2024-11-13 10:09:59,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:09:59,991][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.010260711424052715, acc: 1.0)
[2024-11-13 10:10:00,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:00,662][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.0016474630683660507, acc: 1.0)
[2024-11-13 10:10:00,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:01,355][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.024230316281318665, acc: 0.9838709831237793)
[2024-11-13 10:10:01,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:02,043][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.01619097962975502, acc: 1.0)
[2024-11-13 10:10:02,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:02,722][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.005815444979816675, acc: 1.0)
[2024-11-13 10:10:02,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:03,401][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.14443105459213257, acc: 0.9333333373069763)
[2024-11-13 10:10:03,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:04,078][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.013491605408489704, acc: 1.0)
[2024-11-13 10:10:04,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:04,759][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.08951014280319214, acc: 0.9800000190734863)
[2024-11-13 10:10:04,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:05,443][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.1539141833782196, acc: 0.931034505367279)
[2024-11-13 10:10:05,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:06,134][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.45467880368232727, acc: 0.8085106611251831)
[2024-11-13 10:10:06,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:06,829][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 0.26302656531333923, acc: 0.8795180916786194)
[2024-11-13 10:10:06,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:07,500][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.0005226890207268298, acc: 1.0)
[2024-11-13 10:10:07,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:08,171][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.016132446005940437, acc: 1.0)
[2024-11-13 10:10:08,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:08,850][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.10758215188980103, acc: 0.9879518151283264)
[2024-11-13 10:10:08,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:09,532][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.15414884686470032, acc: 0.9622641801834106)
[2024-11-13 10:10:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:10,211][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.06871181726455688, acc: 0.9746835231781006)
[2024-11-13 10:10:10,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:10,885][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.012120954692363739, acc: 1.0)
[2024-11-13 10:10:10,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:11,568][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.08939624577760696, acc: 0.9850746393203735)
[2024-11-13 10:10:11,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:12,237][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.0025335687678307295, acc: 1.0)
[2024-11-13 10:10:12,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:12,913][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.005110720172524452, acc: 1.0)
[2024-11-13 10:10:13,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:13,602][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.47900062799453735, acc: 0.8888888955116272)
[2024-11-13 10:10:13,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:14,291][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.03511032462120056, acc: 0.9767441749572754)
[2024-11-13 10:10:14,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:14,968][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.01548727322369814, acc: 1.0)
[2024-11-13 10:10:15,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:15,647][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.06451145559549332, acc: 0.9777777791023254)
[2024-11-13 10:10:15,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:16,323][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.0010832861298695207, acc: 1.0)
[2024-11-13 10:10:16,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:16,993][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.02910599857568741, acc: 1.0)
[2024-11-13 10:10:17,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:17,675][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 0.254779577255249, acc: 0.9230769276618958)
[2024-11-13 10:10:17,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:18,377][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 0.2019120752811432, acc: 0.939130425453186)
[2024-11-13 10:10:18,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:19,071][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.12981665134429932, acc: 0.989130437374115)
[2024-11-13 10:10:19,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:19,748][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.15456408262252808, acc: 0.9591836929321289)
[2024-11-13 10:10:19,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:20,427][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.0013822335749864578, acc: 1.0)
[2024-11-13 10:10:20,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:21,113][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.005400467198342085, acc: 1.0)
[2024-11-13 10:10:21,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:21,786][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.044384319335222244, acc: 0.9756097793579102)
[2024-11-13 10:10:21,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:22,460][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.16578823328018188, acc: 0.9555555582046509)
[2024-11-13 10:10:22,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:23,155][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.08079393953084946, acc: 0.9736841917037964)
[2024-11-13 10:10:23,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:23,835][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.02238479256629944, acc: 1.0)
[2024-11-13 10:10:23,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:24,512][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.006316973827779293, acc: 1.0)
[2024-11-13 10:10:24,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:25,183][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.001733370590955019, acc: 1.0)
[2024-11-13 10:10:25,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:25,867][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.003619642462581396, acc: 1.0)
[2024-11-13 10:10:25,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:26,541][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.0051879798993468285, acc: 1.0)
[2024-11-13 10:10:26,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:27,215][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.006549007259309292, acc: 1.0)
[2024-11-13 10:10:27,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:27,925][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 0.11645899713039398, acc: 0.9696969985961914)
[2024-11-13 10:10:28,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:28,627][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.11578543484210968, acc: 0.9716981053352356)
[2024-11-13 10:10:28,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:29,307][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.029162362217903137, acc: 0.9888888597488403)
[2024-11-13 10:10:29,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:29,984][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.04491924121975899, acc: 0.9642857313156128)
[2024-11-13 10:10:30,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:30,661][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.02665039524435997, acc: 1.0)
[2024-11-13 10:10:30,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:31,343][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.0006922637112438679, acc: 1.0)
[2024-11-13 10:10:31,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:32,017][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.018276574090123177, acc: 1.0)
[2024-11-13 10:10:32,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:32,695][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.02743043750524521, acc: 0.9791666865348816)
[2024-11-13 10:10:32,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:33,379][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.018925124779343605, acc: 1.0)
[2024-11-13 10:10:33,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:34,088][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 0.09585458040237427, acc: 0.9640718698501587)
[2024-11-13 10:10:34,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:34,773][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.058990199118852615, acc: 0.9774436354637146)
[2024-11-13 10:10:34,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:35,491][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 0.3567962348461151, acc: 0.866310179233551)
[2024-11-13 10:10:35,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:36,198][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.0959830954670906, acc: 0.9639639854431152)
[2024-11-13 10:10:36,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:36,870][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.01875695027410984, acc: 1.0)
[2024-11-13 10:10:36,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:37,554][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.0018013251246884465, acc: 1.0)
[2024-11-13 10:10:37,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:38,230][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.01818249002099037, acc: 1.0)
[2024-11-13 10:10:38,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:38,901][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.005560280755162239, acc: 1.0)
[2024-11-13 10:10:38,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:39,593][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.003452157136052847, acc: 1.0)
[2024-11-13 10:10:39,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:40,265][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.00933480728417635, acc: 1.0)
[2024-11-13 10:10:40,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:40,937][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.0014738126192241907, acc: 1.0)
[2024-11-13 10:10:41,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:41,607][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.19490137696266174, acc: 0.9523809552192688)
[2024-11-13 10:10:41,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:42,281][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.18614867329597473, acc: 0.9259259104728699)
[2024-11-13 10:10:42,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:42,965][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 0.1993117779493332, acc: 0.9417475461959839)
[2024-11-13 10:10:43,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:43,672][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 0.3031228482723236, acc: 0.9117646813392639)
[2024-11-13 10:10:43,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:44,369][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 0.22067983448505402, acc: 0.9466666579246521)
[2024-11-13 10:10:44,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:45,058][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 0.3525133430957794, acc: 0.8888888955116272)
[2024-11-13 10:10:45,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:45,733][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.034717705100774765, acc: 1.0)
[2024-11-13 10:10:45,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:46,406][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.0009378049871884286, acc: 1.0)
[2024-11-13 10:10:46,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:47,082][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.05391265079379082, acc: 0.9767441749572754)
[2024-11-13 10:10:47,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:47,755][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.008766827173531055, acc: 1.0)
[2024-11-13 10:10:47,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:48,442][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.02986106462776661, acc: 0.9852941036224365)
[2024-11-13 10:10:48,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:49,132][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.13685965538024902, acc: 0.9733333587646484)
[2024-11-13 10:10:49,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:49,809][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.005204338580369949, acc: 1.0)
[2024-11-13 10:10:49,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:50,483][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.010019524954259396, acc: 1.0)
[2024-11-13 10:10:50,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:51,167][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.0005182811873964965, acc: 1.0)
[2024-11-13 10:10:51,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:51,841][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.0038697251584380865, acc: 1.0)
[2024-11-13 10:10:51,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:52,510][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.0012618377804756165, acc: 1.0)
[2024-11-13 10:10:52,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:53,186][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.0019115371396765113, acc: 1.0)
[2024-11-13 10:10:53,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:53,859][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.0011388324201107025, acc: 1.0)
[2024-11-13 10:10:53,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:54,532][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.03351999819278717, acc: 0.9615384340286255)
[2024-11-13 10:10:54,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:55,208][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.0035430199932307005, acc: 1.0)
[2024-11-13 10:10:56,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:56,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:57,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:57,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:58,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:59,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:10:59,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:00,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:00,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:01,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:01,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:02,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:03,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:03,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:04,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:04,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:05,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:06,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:06,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:07,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:07,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:08,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:09,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:09,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:10,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:10,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:11,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:11,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:12,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:13,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:13,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:14,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:14,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:15,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:15,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:16,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:17,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:17,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:18,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:18,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:19,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:20,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:20,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:21,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:21,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:22,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:23,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:23,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:24,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:24,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:25,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:26,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:27,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:27,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:28,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:28,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:29,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:30,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:30,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:31,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:32,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:32,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:33,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:33,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:34,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:35,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:35,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:36,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:36,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:37,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:37,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:38,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:39,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:39,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:40,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:41,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:41,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:42,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:42,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:43,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:43,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:44,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:45,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:45,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:46,700][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1581, device='cuda:0') eval_epoch_loss=tensor(0.7692, device='cuda:0') eval_epoch_acc=tensor(0.8339, device='cuda:0')
[2024-11-13 10:11:46,702][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:11:46,702][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:11:47,058][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_411_loss_0.7692229747772217/model.pt
[2024-11-13 10:11:47,064][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:11:47,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:47,778][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.016467979177832603, acc: 1.0)
[2024-11-13 10:11:47,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:48,495][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.07821962982416153, acc: 0.9666666388511658)
[2024-11-13 10:11:48,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:49,180][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.004150609020143747, acc: 1.0)
[2024-11-13 10:11:49,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:49,849][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.0009105436038225889, acc: 1.0)
[2024-11-13 10:11:49,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:50,528][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.12497895956039429, acc: 0.9607843160629272)
[2024-11-13 10:11:50,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:51,198][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.005625379271805286, acc: 1.0)
[2024-11-13 10:11:51,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:51,867][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.010753629729151726, acc: 1.0)
[2024-11-13 10:11:51,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:52,545][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.005327635910362005, acc: 1.0)
[2024-11-13 10:11:52,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:53,217][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.006506194360554218, acc: 1.0)
[2024-11-13 10:11:53,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:53,893][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.0017041777027770877, acc: 1.0)
[2024-11-13 10:11:53,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:54,566][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.008731088601052761, acc: 1.0)
[2024-11-13 10:11:54,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:55,237][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.00987576600164175, acc: 1.0)
[2024-11-13 10:11:55,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:55,910][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.030849609524011612, acc: 1.0)
[2024-11-13 10:11:56,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:56,579][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.06398031115531921, acc: 0.9629629850387573)
[2024-11-13 10:11:56,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:57,251][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.010634994134306908, acc: 1.0)
[2024-11-13 10:11:57,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:57,921][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.013544864021241665, acc: 1.0)
[2024-11-13 10:11:58,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:58,596][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.015873486176133156, acc: 1.0)
[2024-11-13 10:11:58,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:59,277][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.0015504234470427036, acc: 1.0)
[2024-11-13 10:11:59,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:11:59,949][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.003340385155752301, acc: 1.0)
[2024-11-13 10:12:00,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:00,628][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.0022203726693987846, acc: 1.0)
[2024-11-13 10:12:00,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:01,297][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.0008845757693052292, acc: 1.0)
[2024-11-13 10:12:01,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:01,973][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.0012383509892970324, acc: 1.0)
[2024-11-13 10:12:02,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:02,646][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.003316122805699706, acc: 1.0)
[2024-11-13 10:12:02,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:03,314][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.0025232306215912104, acc: 1.0)
[2024-11-13 10:12:03,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:03,992][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.0015923341270536184, acc: 1.0)
[2024-11-13 10:12:04,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:04,662][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.010260620154440403, acc: 1.0)
[2024-11-13 10:12:04,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:05,344][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.007939950563013554, acc: 1.0)
[2024-11-13 10:12:05,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:06,011][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.0008437394862994552, acc: 1.0)
[2024-11-13 10:12:06,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:06,686][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.03299383446574211, acc: 0.9743589758872986)
[2024-11-13 10:12:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:07,371][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.09408431500196457, acc: 0.9848484992980957)
[2024-11-13 10:12:07,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:08,094][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 0.39519837498664856, acc: 0.8560000061988831)
[2024-11-13 10:12:08,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:08,790][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 0.216244637966156, acc: 0.9193548560142517)
[2024-11-13 10:12:08,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:09,506][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 0.2570735216140747, acc: 0.9203979969024658)
[2024-11-13 10:12:09,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:10,187][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.05969511717557907, acc: 0.9811320900917053)
[2024-11-13 10:12:10,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:10,865][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.0038287900388240814, acc: 1.0)
[2024-11-13 10:12:10,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:11,536][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.0006894307443872094, acc: 1.0)
[2024-11-13 10:12:11,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:12,205][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.08110398799180984, acc: 0.9615384340286255)
[2024-11-13 10:12:12,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:12,882][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.0011927869636565447, acc: 1.0)
[2024-11-13 10:12:12,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:13,557][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.10703302174806595, acc: 0.9850746393203735)
[2024-11-13 10:12:13,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:14,236][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.017441656440496445, acc: 0.9861111044883728)
[2024-11-13 10:12:14,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:14,915][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.017793357372283936, acc: 1.0)
[2024-11-13 10:12:14,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:15,601][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.045489996671676636, acc: 0.9871794581413269)
[2024-11-13 10:12:15,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:16,281][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.062489334493875504, acc: 0.9736841917037964)
[2024-11-13 10:12:16,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:16,955][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.008898611180484295, acc: 1.0)
[2024-11-13 10:12:17,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:17,629][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.006510150618851185, acc: 1.0)
[2024-11-13 10:12:17,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:18,313][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.07344186305999756, acc: 0.9896907210350037)
[2024-11-13 10:12:18,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:18,992][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.07291112095117569, acc: 0.9714285731315613)
[2024-11-13 10:12:19,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:19,706][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 0.12912355363368988, acc: 0.9476743936538696)
[2024-11-13 10:12:19,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:20,379][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.028699416667222977, acc: 0.9821428656578064)
[2024-11-13 10:12:20,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:21,064][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.053710076957941055, acc: 0.9876543283462524)
[2024-11-13 10:12:21,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:21,738][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.007429899647831917, acc: 1.0)
[2024-11-13 10:12:21,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:22,410][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.0026964638382196426, acc: 1.0)
[2024-11-13 10:12:22,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:23,082][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.001222151448018849, acc: 1.0)
[2024-11-13 10:12:23,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:23,759][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.0478547103703022, acc: 0.97826087474823)
[2024-11-13 10:12:23,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:24,440][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.057586733251810074, acc: 0.976190447807312)
[2024-11-13 10:12:24,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:25,125][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.09177970141172409, acc: 0.9518072009086609)
[2024-11-13 10:12:25,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:25,834][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.10568421334028244, acc: 0.9819819927215576)
[2024-11-13 10:12:25,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:26,527][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.12708662450313568, acc: 0.9611650705337524)
[2024-11-13 10:12:26,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:27,237][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.0692330077290535, acc: 0.9918699264526367)
[2024-11-13 10:12:27,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:27,910][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.004572251811623573, acc: 1.0)
[2024-11-13 10:12:27,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:28,580][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.09379652887582779, acc: 0.9642857313156128)
[2024-11-13 10:12:28,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:29,291][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 0.15195012092590332, acc: 0.970588207244873)
[2024-11-13 10:12:29,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:30,000][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 0.2753547132015228, acc: 0.903930127620697)
[2024-11-13 10:12:30,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:30,679][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.0700712576508522, acc: 0.9791666865348816)
[2024-11-13 10:12:30,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:31,372][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.12684805691242218, acc: 0.9815950989723206)
[2024-11-13 10:12:31,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:32,074][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.05228975787758827, acc: 0.9856114983558655)
[2024-11-13 10:12:32,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:32,785][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 0.2227405309677124, acc: 0.9246231317520142)
[2024-11-13 10:12:32,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:33,459][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.01730261743068695, acc: 1.0)
[2024-11-13 10:12:33,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:34,141][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.007975732907652855, acc: 1.0)
[2024-11-13 10:12:34,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:34,814][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.0051477691158652306, acc: 1.0)
[2024-11-13 10:12:34,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:35,489][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.014496183022856712, acc: 1.0)
[2024-11-13 10:12:35,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:36,173][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.028488701209425926, acc: 1.0)
[2024-11-13 10:12:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:36,866][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.034964557737112045, acc: 0.982758641242981)
[2024-11-13 10:12:36,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:37,542][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.0006902323802933097, acc: 1.0)
[2024-11-13 10:12:37,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:38,216][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.0519653744995594, acc: 0.9473684430122375)
[2024-11-13 10:12:38,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:38,890][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.004668685141950846, acc: 1.0)
[2024-11-13 10:12:38,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:39,563][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.012828057631850243, acc: 1.0)
[2024-11-13 10:12:39,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:40,233][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.003933240193873644, acc: 1.0)
[2024-11-13 10:12:40,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:40,913][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.013795125298202038, acc: 1.0)
[2024-11-13 10:12:40,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:41,586][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.0037176921032369137, acc: 1.0)
[2024-11-13 10:12:41,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:42,256][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.011013919487595558, acc: 1.0)
[2024-11-13 10:12:42,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:42,930][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.017021557316184044, acc: 1.0)
[2024-11-13 10:12:43,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:43,599][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.003908686805516481, acc: 1.0)
[2024-11-13 10:12:43,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:44,266][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.018828893080353737, acc: 1.0)
[2024-11-13 10:12:44,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:44,941][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.003174218349158764, acc: 1.0)
[2024-11-13 10:12:45,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:45,631][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.15471996366977692, acc: 0.9821428656578064)
[2024-11-13 10:12:45,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:46,316][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.041778430342674255, acc: 0.9887640476226807)
[2024-11-13 10:12:46,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:47,003][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.12931783497333527, acc: 0.9550561904907227)
[2024-11-13 10:12:47,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:47,700][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 0.2516758441925049, acc: 0.9290780425071716)
[2024-11-13 10:12:47,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:48,391][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.09029655903577805, acc: 0.967391312122345)
[2024-11-13 10:12:48,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:49,062][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.00028180296067148447, acc: 1.0)
[2024-11-13 10:12:49,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:49,729][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.00021361754625104368, acc: 1.0)
[2024-11-13 10:12:49,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:50,400][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.002467443933710456, acc: 1.0)
[2024-11-13 10:12:50,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:51,071][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.0026303839404135942, acc: 1.0)
[2024-11-13 10:12:51,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:51,747][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.01168722566217184, acc: 1.0)
[2024-11-13 10:12:51,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:52,428][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.0029677485581487417, acc: 1.0)
[2024-11-13 10:12:52,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:53,116][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.08836296200752258, acc: 0.9819819927215576)
[2024-11-13 10:12:53,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:53,805][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.021543031558394432, acc: 1.0)
[2024-11-13 10:12:53,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:54,477][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.00017553406360093504, acc: 1.0)
[2024-11-13 10:12:54,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:55,165][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.00583425210788846, acc: 1.0)
[2024-11-13 10:12:55,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:55,836][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.0044242013245821, acc: 1.0)
[2024-11-13 10:12:55,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:56,747][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 0.800291895866394, acc: 0.7571428418159485)
[2024-11-13 10:12:56,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:57,461][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.15580670535564423, acc: 0.9365079402923584)
[2024-11-13 10:12:57,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:58,133][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.00361500377766788, acc: 1.0)
[2024-11-13 10:12:58,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:58,819][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.004642948042601347, acc: 1.0)
[2024-11-13 10:12:58,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:12:59,513][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.21769309043884277, acc: 0.9583333134651184)
[2024-11-13 10:12:59,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:00,196][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.00015429264749400318, acc: 1.0)
[2024-11-13 10:13:00,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:00,870][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.0008816160261631012, acc: 1.0)
[2024-11-13 10:13:00,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:01,533][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.0011742264032363892, acc: 1.0)
[2024-11-13 10:13:01,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:02,206][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.013299768790602684, acc: 1.0)
[2024-11-13 10:13:02,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:02,971][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 0.7483958601951599, acc: 0.8135592937469482)
[2024-11-13 10:13:03,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:03,674][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 0.04694277420639992, acc: 0.9776119589805603)
[2024-11-13 10:13:03,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:04,365][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 0.07819969952106476, acc: 0.970802903175354)
[2024-11-13 10:13:04,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:05,085][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 0.281259685754776, acc: 0.9300000071525574)
[2024-11-13 10:13:05,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:05,759][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.0008082747226580977, acc: 1.0)
[2024-11-13 10:13:05,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:06,436][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.00531072448939085, acc: 1.0)
[2024-11-13 10:13:06,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:07,103][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.0015885734464973211, acc: 1.0)
[2024-11-13 10:13:07,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:07,825][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.09088480472564697, acc: 0.9672130942344666)
[2024-11-13 10:13:07,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:08,509][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.006870166398584843, acc: 1.0)
[2024-11-13 10:13:08,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:09,186][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.007469892036169767, acc: 1.0)
[2024-11-13 10:13:09,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:09,864][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.04858525097370148, acc: 0.9772727489471436)
[2024-11-13 10:13:09,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:10,545][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.026794100180268288, acc: 1.0)
[2024-11-13 10:13:10,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:11,216][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.1181240975856781, acc: 0.9545454382896423)
[2024-11-13 10:13:11,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:11,891][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.0016449978575110435, acc: 1.0)
[2024-11-13 10:13:11,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:12,563][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.0009427241748198867, acc: 1.0)
[2024-11-13 10:13:12,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:13,246][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.004626525565981865, acc: 1.0)
[2024-11-13 10:13:13,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:13,930][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.02263728715479374, acc: 1.0)
[2024-11-13 10:13:14,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:14,616][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.037508487701416016, acc: 1.0)
[2024-11-13 10:13:14,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:15,309][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.0045402925461530685, acc: 1.0)
[2024-11-13 10:13:15,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:15,988][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.04280831664800644, acc: 0.9696969985961914)
[2024-11-13 10:13:16,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:16,656][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.0007080985815264285, acc: 1.0)
[2024-11-13 10:13:16,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:17,338][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.05045183002948761, acc: 0.9677419066429138)
[2024-11-13 10:13:17,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:18,009][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.00029755241121165454, acc: 1.0)
[2024-11-13 10:13:18,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:18,686][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.012593710795044899, acc: 1.0)
[2024-11-13 10:13:18,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:19,360][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.14843781292438507, acc: 0.9756097793579102)
[2024-11-13 10:13:19,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:20,033][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.007998007349669933, acc: 1.0)
[2024-11-13 10:13:20,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:20,709][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.00967212300747633, acc: 1.0)
[2024-11-13 10:13:20,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:21,379][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.005845991894602776, acc: 1.0)
[2024-11-13 10:13:21,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:22,051][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.006255706772208214, acc: 1.0)
[2024-11-13 10:13:22,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:22,741][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.00800961535423994, acc: 1.0)
[2024-11-13 10:13:22,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:23,419][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.002363532781600952, acc: 1.0)
[2024-11-13 10:13:23,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:24,100][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.04267803207039833, acc: 0.9857142567634583)
[2024-11-13 10:13:24,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:24,798][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 0.09900225698947906, acc: 0.9635036587715149)
[2024-11-13 10:13:25,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:26,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:26,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:27,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:28,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:28,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:29,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:29,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:30,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:30,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:31,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:32,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:32,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:33,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:33,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:34,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:35,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:35,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:36,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:36,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:37,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:38,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:38,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:39,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:39,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:40,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:41,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:41,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:42,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:42,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:43,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:44,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:44,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:45,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:45,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:46,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:46,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:47,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:48,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:48,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:49,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:50,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:50,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:51,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:52,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:52,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:53,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:53,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:54,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:55,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:55,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:56,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:56,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:57,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:57,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:58,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:59,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:13:59,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:00,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:00,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:01,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:02,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:02,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:03,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:03,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:04,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:05,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:05,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:06,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:06,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:07,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:08,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:08,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:09,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:09,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:10,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:10,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:11,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:12,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:12,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:13,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:14,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:14,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:15,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:16,148][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3415, device='cuda:0') eval_epoch_loss=tensor(0.8508, device='cuda:0') eval_epoch_acc=tensor(0.8219, device='cuda:0')
[2024-11-13 10:14:16,150][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:14:16,150][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:14:16,465][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_554_loss_0.8507750630378723/model.pt
[2024-11-13 10:14:16,470][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:14:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:17,206][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.04806366562843323, acc: 0.9862068891525269)
[2024-11-13 10:14:17,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:17,892][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 0.09512834995985031, acc: 0.9642857313156128)
[2024-11-13 10:14:17,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:18,578][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 0.2941044867038727, acc: 0.9139072895050049)
[2024-11-13 10:14:18,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:19,258][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.014762992970645428, acc: 1.0)
[2024-11-13 10:14:19,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:19,926][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.0009357863455079496, acc: 1.0)
[2024-11-13 10:14:20,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:20,599][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.0006023674504831433, acc: 1.0)
[2024-11-13 10:14:20,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:21,268][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.0020557588431984186, acc: 1.0)
[2024-11-13 10:14:21,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:21,946][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.004574221093207598, acc: 1.0)
[2024-11-13 10:14:22,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:22,644][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.10199195146560669, acc: 0.9666666388511658)
[2024-11-13 10:14:22,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:23,322][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.024442607536911964, acc: 1.0)
[2024-11-13 10:14:23,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:23,992][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.011370477266609669, acc: 1.0)
[2024-11-13 10:14:24,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:24,667][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.007795556914061308, acc: 1.0)
[2024-11-13 10:14:24,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:25,351][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.01133752427995205, acc: 1.0)
[2024-11-13 10:14:25,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:26,024][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.05063480883836746, acc: 0.9736841917037964)
[2024-11-13 10:14:26,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:26,698][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.11840473115444183, acc: 0.9629629850387573)
[2024-11-13 10:14:26,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:27,421][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 0.07889392226934433, acc: 0.9786096215248108)
[2024-11-13 10:14:27,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:28,092][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.03620123490691185, acc: 0.9838709831237793)
[2024-11-13 10:14:28,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:28,774][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.02156287617981434, acc: 0.9914529919624329)
[2024-11-13 10:14:28,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:29,482][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 0.21332500874996185, acc: 0.9387755393981934)
[2024-11-13 10:14:29,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:14:30,191][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 0.10071460902690887, acc: 0.9622641801834106)
[2024-11-13 10:14:30,660][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.1023, train_epoch_loss=0.0974, epoch time 603.1906213611364s
[2024-11-13 10:14:30,660][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 10:14:30,660][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 10:14:30,660][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 10:14:30,660][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 10
[2024-11-13 10:14:30,660][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 10:14:30,664][root][INFO] - Key: avg_train_prep, Value: 4.09474515914917
[2024-11-13 10:14:30,665][root][INFO] - Key: avg_train_loss, Value: 0.8216713070869446
[2024-11-13 10:14:30,665][root][INFO] - Key: avg_train_acc, Value: 0.7894958853721619
[2024-11-13 10:14:30,665][root][INFO] - Key: avg_eval_prep, Value: 4.109192848205566
[2024-11-13 10:14:30,665][root][INFO] - Key: avg_eval_loss, Value: 1.1613351106643677
[2024-11-13 10:14:30,666][root][INFO] - Key: avg_eval_acc, Value: 0.711711585521698
[2024-11-13 10:14:30,666][root][INFO] - Key: avg_epoch_time, Value: 603.7333748929202
[2024-11-13 10:14:30,666][root][INFO] - Key: avg_checkpoint_time, Value: 0.39906968832947315
[2024-11-13 10:23:32,620][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 133, 'resume_epoch': 6, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-13 10:23:32,622][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-13 10:23:32,622][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-13 10:23:32,622][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_whisper_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-13_10-23-32.txt', 'log_interval': 5}
[2024-11-13 10:24:13,285][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-13 10:24:13,288][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2024-11-13 10:24:13,290][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-13 10:24:13,291][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2024-11-13 10:24:17,685][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 10:24:17,686][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-13 10:24:17,686][slam_llm.models.slam_model][INFO] - setup peft...
[2024-11-13 10:24:17,808][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 10:24:17,810][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-11-13 10:24:18,022][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-13 10:24:18,022][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2024-11-13 10:24:18,022][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_133_loss_0.6664179563522339/model.pt
[2024-11-13 10:24:18,126][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-13 10:24:18,130][slam_llm.utils.train_utils][INFO] - --> asr has 22.941696 Million params

[2024-11-13 10:24:20,220][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2024-11-13 10:24:20,731][root][INFO] - --> Training Set Length = 2298
[2024-11-13 10:24:20,735][root][INFO] - --> Validation Set Length = 341
[2024-11-13 10:24:20,735][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 10:24:20,735][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 10:24:22,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:23,800][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.09933939576148987, acc: 0.9629629850387573)
[2024-11-13 10:24:23,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:24,483][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.01806817390024662, acc: 1.0)
[2024-11-13 10:24:24,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:25,704][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-13 10:24:26,943][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.16931942105293274, acc: 0.9459459185600281)
[2024-11-13 10:24:27,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:27,636][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 0.059289995580911636, acc: 1.0)
[2024-11-13 10:24:27,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:28,322][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 0.05797404795885086, acc: 1.0)
[2024-11-13 10:24:28,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:29,004][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.014815001748502254, acc: 1.0)
[2024-11-13 10:24:29,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:29,689][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.058661822229623795, acc: 0.9795918464660645)
[2024-11-13 10:24:29,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:30,373][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 0.027043184265494347, acc: 1.0)
[2024-11-13 10:24:30,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:31,055][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 0.0008472863701172173, acc: 1.0)
[2024-11-13 10:24:31,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:31,737][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 0.0015834870282560587, acc: 1.0)
[2024-11-13 10:24:31,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:32,420][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 0.012399165891110897, acc: 1.0)
[2024-11-13 10:24:32,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:33,136][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 0.0835265964269638, acc: 0.9743589758872986)
[2024-11-13 10:24:33,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:33,827][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 0.012605711817741394, acc: 1.0)
[2024-11-13 10:24:33,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:34,516][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 0.021410074084997177, acc: 1.0)
[2024-11-13 10:24:34,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:35,206][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 0.03165031224489212, acc: 1.0)
[2024-11-13 10:24:35,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:35,910][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 0.13698334991931915, acc: 0.9591836929321289)
[2024-11-13 10:24:36,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:36,593][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.01095576025545597, acc: 1.0)
[2024-11-13 10:24:36,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:37,281][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.005314012989401817, acc: 1.0)
[2024-11-13 10:24:37,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:37,968][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 0.08790367096662521, acc: 0.9722222089767456)
[2024-11-13 10:24:38,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:38,653][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 0.0066300928592681885, acc: 1.0)
[2024-11-13 10:24:38,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:39,335][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 0.03870030865073204, acc: 1.0)
[2024-11-13 10:24:39,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:40,022][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 0.20993204414844513, acc: 0.9655172228813171)
[2024-11-13 10:24:40,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:40,722][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.052174683660268784, acc: 0.9599999785423279)
[2024-11-13 10:24:40,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:41,404][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.01930502988398075, acc: 1.0)
[2024-11-13 10:24:41,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:42,086][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 0.016829194501042366, acc: 1.0)
[2024-11-13 10:24:42,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:42,788][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 0.23745213449001312, acc: 0.9622641801834106)
[2024-11-13 10:24:42,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:43,476][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 0.2531161904335022, acc: 0.931506872177124)
[2024-11-13 10:24:43,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:44,304][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 0.9677579402923584, acc: 0.747035562992096)
[2024-11-13 10:24:44,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:44,990][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 0.13221405446529388, acc: 0.9767441749572754)
[2024-11-13 10:24:45,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:45,683][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 0.30204859375953674, acc: 0.9036144614219666)
[2024-11-13 10:24:45,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:46,386][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.18187083303928375, acc: 0.9382715821266174)
[2024-11-13 10:24:46,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:47,067][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.03176049515604973, acc: 1.0)
[2024-11-13 10:24:47,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:47,751][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 0.0121582867577672, acc: 1.0)
[2024-11-13 10:24:47,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:48,433][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.06311214715242386, acc: 0.95652174949646)
[2024-11-13 10:24:48,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:49,134][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 0.2277097851037979, acc: 0.924369752407074)
[2024-11-13 10:24:49,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:49,819][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 0.09439823031425476, acc: 0.9508196711540222)
[2024-11-13 10:24:49,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:50,514][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 0.3028014600276947, acc: 0.9047619104385376)
[2024-11-13 10:24:50,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:51,200][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 0.0549185611307621, acc: 1.0)
[2024-11-13 10:24:51,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:51,902][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.20857049524784088, acc: 0.9425287246704102)
[2024-11-13 10:24:52,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:52,597][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.00703727500513196, acc: 1.0)
[2024-11-13 10:24:52,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:53,280][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.015427104197442532, acc: 1.0)
[2024-11-13 10:24:53,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:53,975][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 0.05404900386929512, acc: 0.9864864945411682)
[2024-11-13 10:24:54,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:54,665][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 0.06397055089473724, acc: 0.9692307710647583)
[2024-11-13 10:24:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:55,359][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 0.13800355792045593, acc: 0.9494949579238892)
[2024-11-13 10:24:55,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:56,097][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 0.19585251808166504, acc: 0.938144326210022)
[2024-11-13 10:24:56,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:56,806][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 0.24051392078399658, acc: 0.904411792755127)
[2024-11-13 10:24:56,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:57,484][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 0.001981156412512064, acc: 1.0)
[2024-11-13 10:24:57,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:58,172][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.0022725751623511314, acc: 1.0)
[2024-11-13 10:24:58,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:58,854][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.008058563806116581, acc: 1.0)
[2024-11-13 10:24:58,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:24:59,549][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.005597296636551619, acc: 1.0)
[2024-11-13 10:24:59,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:00,238][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 0.12965677678585052, acc: 0.9473684430122375)
[2024-11-13 10:25:00,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:00,931][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 0.17206917703151703, acc: 0.9682539701461792)
[2024-11-13 10:25:01,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:01,632][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 0.20733164250850677, acc: 0.9295774698257446)
[2024-11-13 10:25:01,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:02,362][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 0.7382175922393799, acc: 0.7933333516120911)
[2024-11-13 10:25:02,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:03,043][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 0.07974851131439209, acc: 0.9729729890823364)
[2024-11-13 10:25:03,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:03,729][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 0.00337763293646276, acc: 1.0)
[2024-11-13 10:25:03,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:04,569][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 1.0986990928649902, acc: 0.6757678985595703)
[2024-11-13 10:25:04,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:05,345][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 1.2669888734817505, acc: 0.6405228972434998)
[2024-11-13 10:25:05,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:06,067][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 0.46281349658966064, acc: 0.8579545617103577)
[2024-11-13 10:25:06,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:06,765][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 0.19525539875030518, acc: 0.9338235259056091)
[2024-11-13 10:25:06,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:07,481][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 0.35891056060791016, acc: 0.8985507488250732)
[2024-11-13 10:25:07,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:08,194][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 0.24557915329933167, acc: 0.9375)
[2024-11-13 10:25:08,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:08,867][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 0.10479772090911865, acc: 0.9411764740943909)
[2024-11-13 10:25:08,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:09,555][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.01095725316554308, acc: 1.0)
[2024-11-13 10:25:09,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:10,251][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.06333652138710022, acc: 0.984375)
[2024-11-13 10:25:10,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:10,932][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 0.00402547512203455, acc: 1.0)
[2024-11-13 10:25:11,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:11,633][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 0.026232630014419556, acc: 1.0)
[2024-11-13 10:25:11,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:12,328][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 0.016429288312792778, acc: 1.0)
[2024-11-13 10:25:12,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:13,007][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 0.002635195618495345, acc: 1.0)
[2024-11-13 10:25:13,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:13,694][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 0.21835187077522278, acc: 0.9166666865348816)
[2024-11-13 10:25:13,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:14,376][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 0.023249464109539986, acc: 1.0)
[2024-11-13 10:25:14,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:15,087][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 0.3543455898761749, acc: 0.8970588445663452)
[2024-11-13 10:25:15,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:15,781][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 0.20048421621322632, acc: 0.9523809552192688)
[2024-11-13 10:25:15,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:16,510][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 0.6055576801300049, acc: 0.8205128312110901)
[2024-11-13 10:25:16,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:17,212][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 0.20966340601444244, acc: 0.9591836929321289)
[2024-11-13 10:25:17,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:17,909][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 0.43672260642051697, acc: 0.8731343150138855)
[2024-11-13 10:25:17,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:18,648][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 0.8998996615409851, acc: 0.7554744482040405)
[2024-11-13 10:25:18,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:19,329][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 0.001319927629083395, acc: 1.0)
[2024-11-13 10:25:19,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:20,010][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.004803039133548737, acc: 1.0)
[2024-11-13 10:25:20,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:20,700][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.009359167888760567, acc: 1.0)
[2024-11-13 10:25:20,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:21,383][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.0019123244564980268, acc: 1.0)
[2024-11-13 10:25:21,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:22,091][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 0.024788441136479378, acc: 1.0)
[2024-11-13 10:25:22,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:22,793][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 0.031581513583660126, acc: 1.0)
[2024-11-13 10:25:22,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:23,477][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 0.20748570561408997, acc: 0.96875)
[2024-11-13 10:25:23,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:24,166][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 0.02637249045073986, acc: 1.0)
[2024-11-13 10:25:24,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:24,865][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 0.0700635239481926, acc: 0.9800000190734863)
[2024-11-13 10:25:24,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:25,553][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.003297235583886504, acc: 1.0)
[2024-11-13 10:25:25,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:26,247][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.03326520696282387, acc: 1.0)
[2024-11-13 10:25:26,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:26,954][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.14920224249362946, acc: 0.9611650705337524)
[2024-11-13 10:25:27,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:27,682][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 0.5359243750572205, acc: 0.8543689250946045)
[2024-11-13 10:25:27,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:28,415][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 0.678081214427948, acc: 0.7849462628364563)
[2024-11-13 10:25:28,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:29,152][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 0.5063783526420593, acc: 0.8793103694915771)
[2024-11-13 10:25:29,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:29,847][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 0.2009022980928421, acc: 0.9263157844543457)
[2024-11-13 10:25:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:30,574][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.4331754148006439, acc: 0.8910890817642212)
[2024-11-13 10:25:30,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:31,278][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 0.07095202803611755, acc: 0.9838709831237793)
[2024-11-13 10:25:31,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:31,972][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.05437896400690079, acc: 1.0)
[2024-11-13 10:25:32,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:32,670][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.32023710012435913, acc: 0.8823529481887817)
[2024-11-13 10:25:32,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:33,367][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 0.21506930887699127, acc: 0.942307710647583)
[2024-11-13 10:25:33,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:34,067][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 0.3889915347099304, acc: 0.9124087691307068)
[2024-11-13 10:25:34,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:34,762][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 0.3641239404678345, acc: 0.9253731369972229)
[2024-11-13 10:25:34,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:35,445][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 0.002311540534719825, acc: 1.0)
[2024-11-13 10:25:35,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:36,124][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 0.00140298658516258, acc: 1.0)
[2024-11-13 10:25:36,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:36,809][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.002975746290758252, acc: 1.0)
[2024-11-13 10:25:36,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:37,505][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.011990613304078579, acc: 1.0)
[2024-11-13 10:25:37,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:38,197][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 0.1067231148481369, acc: 0.982758641242981)
[2024-11-13 10:25:38,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:38,879][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.012213971465826035, acc: 1.0)
[2024-11-13 10:25:38,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:39,566][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.0032505211420357227, acc: 1.0)
[2024-11-13 10:25:39,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:40,256][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.0014434517361223698, acc: 1.0)
[2024-11-13 10:25:40,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:40,939][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.00145188276655972, acc: 1.0)
[2024-11-13 10:25:41,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:41,632][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 0.1543251872062683, acc: 0.9523809552192688)
[2024-11-13 10:25:41,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:42,334][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 0.0652909055352211, acc: 0.9846153855323792)
[2024-11-13 10:25:42,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:43,034][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.053447872400283813, acc: 0.9824561476707458)
[2024-11-13 10:25:43,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:43,726][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.18960070610046387, acc: 0.9649122953414917)
[2024-11-13 10:25:43,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:44,410][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.02811126597225666, acc: 1.0)
[2024-11-13 10:25:44,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:45,093][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.03782802075147629, acc: 0.9795918464660645)
[2024-11-13 10:25:45,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:45,778][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.0007172161713242531, acc: 1.0)
[2024-11-13 10:25:45,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:46,475][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.20968377590179443, acc: 0.9365079402923584)
[2024-11-13 10:25:46,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:47,164][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.10429687052965164, acc: 0.9837398529052734)
[2024-11-13 10:25:47,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:47,854][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 0.022999320179224014, acc: 1.0)
[2024-11-13 10:25:47,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:48,620][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.3842909038066864, acc: 0.9049429893493652)
[2024-11-13 10:25:48,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:49,317][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.023827657103538513, acc: 0.9866666793823242)
[2024-11-13 10:25:49,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:50,011][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.06256438791751862, acc: 0.9807692170143127)
[2024-11-13 10:25:50,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:50,705][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.0036378633230924606, acc: 1.0)
[2024-11-13 10:25:50,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:51,388][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.0014626430347561836, acc: 1.0)
[2024-11-13 10:25:51,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:52,088][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 0.4029896855354309, acc: 0.8773006200790405)
[2024-11-13 10:25:52,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:52,810][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 0.3558662533760071, acc: 0.9027777910232544)
[2024-11-13 10:25:52,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:53,507][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 0.5411674976348877, acc: 0.8500000238418579)
[2024-11-13 10:25:53,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:54,247][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 0.4291917681694031, acc: 0.8809523582458496)
[2024-11-13 10:25:54,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:54,972][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.3634014129638672, acc: 0.9025641083717346)
[2024-11-13 10:25:55,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:55,706][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.4056146442890167, acc: 0.875)
[2024-11-13 10:25:55,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:56,385][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 0.012585071846842766, acc: 1.0)
[2024-11-13 10:25:56,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:57,071][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 0.0031506468076258898, acc: 1.0)
[2024-11-13 10:25:57,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:57,761][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 0.03611765429377556, acc: 1.0)
[2024-11-13 10:25:57,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:58,445][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 0.02816605381667614, acc: 1.0)
[2024-11-13 10:25:58,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:59,138][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 0.20035409927368164, acc: 0.9428571462631226)
[2024-11-13 10:25:59,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:25:59,825][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 0.02878059260547161, acc: 1.0)
[2024-11-13 10:25:59,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:00,509][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.13639873266220093, acc: 0.9523809552192688)
[2024-11-13 10:26:00,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:01,191][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.06617859750986099, acc: 1.0)
[2024-11-13 10:26:01,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:01,870][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.1607430875301361, acc: 0.95652174949646)
[2024-11-13 10:26:01,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:02,564][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.00571643840521574, acc: 1.0)
[2024-11-13 10:26:02,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:03,246][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 0.04214140400290489, acc: 1.0)
[2024-11-13 10:26:03,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:03,940][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.1381448209285736, acc: 0.9677419066429138)
[2024-11-13 10:26:04,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:04,635][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.35142970085144043, acc: 0.9459459185600281)
[2024-11-13 10:26:05,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:06,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:06,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:07,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:07,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:08,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:09,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:09,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:10,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:10,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:11,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:12,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:12,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:13,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:14,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:14,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:15,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:16,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:17,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:17,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:18,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:18,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:19,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:20,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:20,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:21,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:21,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:22,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:23,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:23,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:24,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:25,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:25,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:26,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:27,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:27,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:28,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:28,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:29,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:30,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:30,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:31,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:31,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:32,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:33,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:33,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:34,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:34,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:35,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:36,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:36,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:37,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:38,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:38,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:39,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:39,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:40,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:41,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:41,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:42,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:42,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:43,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:43,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:44,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:45,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:45,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:46,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:47,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:47,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:48,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:49,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:49,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:50,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:51,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:51,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:52,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:53,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:53,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:54,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:54,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:55,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:55,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:57,066][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.9564, device='cuda:0') eval_epoch_loss=tensor(0.6711, device='cuda:0') eval_epoch_acc=tensor(0.8320, device='cuda:0')
[2024-11-13 10:26:57,067][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:26:57,068][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:26:57,446][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_276_loss_0.6710876822471619/model.pt
[2024-11-13 10:26:57,451][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:26:57,452][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 6 is 0.6710876822471619
[2024-11-13 10:26:57,453][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.8320015668869019
[2024-11-13 10:26:57,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:58,183][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 0.383969247341156, acc: 0.8508771657943726)
[2024-11-13 10:26:58,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:58,870][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.6580868363380432, acc: 0.8283582329750061)
[2024-11-13 10:26:58,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:26:59,556][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 0.27211835980415344, acc: 0.8979591727256775)
[2024-11-13 10:26:59,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:00,256][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 0.6929803490638733, acc: 0.7553191781044006)
[2024-11-13 10:27:00,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:00,940][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.4731628894805908, acc: 0.8142856955528259)
[2024-11-13 10:27:01,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:01,626][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 0.061564184725284576, acc: 1.0)
[2024-11-13 10:27:01,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:02,298][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 0.12952063977718353, acc: 0.9130434989929199)
[2024-11-13 10:27:02,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:02,969][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.02613494172692299, acc: 1.0)
[2024-11-13 10:27:03,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:03,643][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 0.20349958539009094, acc: 0.95652174949646)
[2024-11-13 10:27:03,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:04,325][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.4253895580768585, acc: 0.8813559412956238)
[2024-11-13 10:27:04,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:05,003][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 0.3081912398338318, acc: 0.9298245906829834)
[2024-11-13 10:27:05,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:05,687][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 0.19703799486160278, acc: 0.9324324131011963)
[2024-11-13 10:27:05,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:06,361][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 0.16107818484306335, acc: 0.9285714030265808)
[2024-11-13 10:27:06,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:07,037][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 0.0019441434415057302, acc: 1.0)
[2024-11-13 10:27:07,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:07,712][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 0.0816250741481781, acc: 0.9473684430122375)
[2024-11-13 10:27:07,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:08,390][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.5964189767837524, acc: 0.837837815284729)
[2024-11-13 10:27:08,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:09,073][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 0.3810921907424927, acc: 0.8888888955116272)
[2024-11-13 10:27:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:09,753][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 0.21974492073059082, acc: 0.9651162624359131)
[2024-11-13 10:27:09,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:10,433][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.25574687123298645, acc: 0.9529411792755127)
[2024-11-13 10:27:10,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:11,126][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 0.7264764904975891, acc: 0.8314606547355652)
[2024-11-13 10:27:11,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:11,803][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 0.22926758229732513, acc: 0.9090909361839294)
[2024-11-13 10:27:11,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:12,477][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.20863354206085205, acc: 0.9523809552192688)
[2024-11-13 10:27:12,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:13,146][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.007171757984906435, acc: 1.0)
[2024-11-13 10:27:13,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:13,823][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.06586311012506485, acc: 0.9795918464660645)
[2024-11-13 10:27:13,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:14,495][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.05875980854034424, acc: 0.9800000190734863)
[2024-11-13 10:27:14,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:15,177][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.2793055772781372, acc: 0.9166666865348816)
[2024-11-13 10:27:15,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:15,865][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.6770524978637695, acc: 0.7941176295280457)
[2024-11-13 10:27:15,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:16,587][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 1.0992741584777832, acc: 0.6849315166473389)
[2024-11-13 10:27:16,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:17,256][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.17631709575653076, acc: 0.9583333134651184)
[2024-11-13 10:27:17,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:17,928][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.010629252530634403, acc: 1.0)
[2024-11-13 10:27:18,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:18,598][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.011582178063690662, acc: 1.0)
[2024-11-13 10:27:18,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:19,306][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.5625560283660889, acc: 0.8230088353157043)
[2024-11-13 10:27:19,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:19,984][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 0.19384047389030457, acc: 0.95652174949646)
[2024-11-13 10:27:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:20,668][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 0.1831432431936264, acc: 0.9204545617103577)
[2024-11-13 10:27:20,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:21,379][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 0.8231213688850403, acc: 0.7709923386573792)
[2024-11-13 10:27:21,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:22,088][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 0.5451342463493347, acc: 0.8370370268821716)
[2024-11-13 10:27:22,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:22,779][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 0.12622320652008057, acc: 0.9508196711540222)
[2024-11-13 10:27:22,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:23,450][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.03497312590479851, acc: 1.0)
[2024-11-13 10:27:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:24,122][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.03691321983933449, acc: 1.0)
[2024-11-13 10:27:24,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:24,792][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.009153769351541996, acc: 1.0)
[2024-11-13 10:27:24,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:25,480][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 0.150929793715477, acc: 0.9390243887901306)
[2024-11-13 10:27:25,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:26,206][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 0.5018360614776611, acc: 0.8761329054832458)
[2024-11-13 10:27:26,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:26,929][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 0.5436824560165405, acc: 0.8472622632980347)
[2024-11-13 10:27:27,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:27,659][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 0.513108491897583, acc: 0.828125)
[2024-11-13 10:27:27,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:28,424][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 0.7523637413978577, acc: 0.7936210036277771)
[2024-11-13 10:27:28,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:29,157][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.5396353006362915, acc: 0.8505337834358215)
[2024-11-13 10:27:29,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:29,834][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 0.06460002809762955, acc: 0.9599999785423279)
[2024-11-13 10:27:29,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:30,525][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 0.44773373007774353, acc: 0.8488371968269348)
[2024-11-13 10:27:30,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:31,214][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.8002384901046753, acc: 0.7857142686843872)
[2024-11-13 10:27:31,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:31,912][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 0.727385401725769, acc: 0.75)
[2024-11-13 10:27:31,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:32,594][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.2903707027435303, acc: 0.9058823585510254)
[2024-11-13 10:27:32,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:33,298][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.6823393106460571, acc: 0.7716049551963806)
[2024-11-13 10:27:33,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:33,983][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.3391382396221161, acc: 0.9193548560142517)
[2024-11-13 10:27:34,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:34,657][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.05836661905050278, acc: 0.9642857313156128)
[2024-11-13 10:27:34,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:35,338][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.2710530757904053, acc: 0.949999988079071)
[2024-11-13 10:27:35,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:36,023][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.21231213212013245, acc: 0.9117646813392639)
[2024-11-13 10:27:36,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:36,713][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.5200537443161011, acc: 0.8382353186607361)
[2024-11-13 10:27:36,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:37,397][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 0.5624711513519287, acc: 0.8305084705352783)
[2024-11-13 10:27:37,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:38,085][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.43676507472991943, acc: 0.9029850959777832)
[2024-11-13 10:27:38,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:38,772][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.6303144097328186, acc: 0.7961165308952332)
[2024-11-13 10:27:38,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:39,459][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 0.4344862997531891, acc: 0.920634925365448)
[2024-11-13 10:27:39,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:40,143][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 0.09575233608484268, acc: 0.9670329689979553)
[2024-11-13 10:27:40,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:40,861][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 0.28184837102890015, acc: 0.8968609571456909)
[2024-11-13 10:27:40,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:41,583][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 0.4176783263683319, acc: 0.8897637724876404)
[2024-11-13 10:27:41,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:42,290][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.2318214327096939, acc: 0.9137930870056152)
[2024-11-13 10:27:42,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:43,003][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 0.4116489589214325, acc: 0.8731883764266968)
[2024-11-13 10:27:43,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:43,723][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 0.2811605930328369, acc: 0.9066147804260254)
[2024-11-13 10:27:43,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:44,432][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 0.16471588611602783, acc: 0.9347826242446899)
[2024-11-13 10:27:44,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:45,101][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 0.009563829749822617, acc: 1.0)
[2024-11-13 10:27:45,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:45,778][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 0.06839051842689514, acc: 0.9642857313156128)
[2024-11-13 10:27:45,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:46,459][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 0.02165558747947216, acc: 1.0)
[2024-11-13 10:27:46,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:47,168][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.17169170081615448, acc: 0.9461538195610046)
[2024-11-13 10:27:47,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:47,848][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.06932574510574341, acc: 0.9864864945411682)
[2024-11-13 10:27:47,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:48,530][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 0.0760558471083641, acc: 0.9651162624359131)
[2024-11-13 10:27:48,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:49,231][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 0.10584709793329239, acc: 0.954954981803894)
[2024-11-13 10:27:49,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:49,917][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.05278515815734863, acc: 0.9888888597488403)
[2024-11-13 10:27:50,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:50,598][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 0.054402247071266174, acc: 0.9696969985961914)
[2024-11-13 10:27:50,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:51,272][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.02604081854224205, acc: 1.0)
[2024-11-13 10:27:51,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:51,945][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.010223430581390858, acc: 1.0)
[2024-11-13 10:27:52,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:52,652][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 0.4729401469230652, acc: 0.8653846383094788)
[2024-11-13 10:27:52,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:53,367][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 0.47387486696243286, acc: 0.8695651888847351)
[2024-11-13 10:27:53,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:54,070][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 0.42437583208084106, acc: 0.875)
[2024-11-13 10:27:54,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:54,777][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 0.4149979054927826, acc: 0.8510638475418091)
[2024-11-13 10:27:54,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:55,456][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.1805008202791214, acc: 0.9433962106704712)
[2024-11-13 10:27:55,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:56,144][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.09310349822044373, acc: 0.949999988079071)
[2024-11-13 10:27:56,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:56,830][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.08642631024122238, acc: 0.9767441749572754)
[2024-11-13 10:27:56,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:57,500][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 0.016541989520192146, acc: 1.0)
[2024-11-13 10:27:57,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:58,194][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 1.0284180641174316, acc: 0.6947368383407593)
[2024-11-13 10:27:58,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:58,874][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 0.5153236389160156, acc: 0.8666666746139526)
[2024-11-13 10:27:58,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:27:59,586][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.6221351623535156, acc: 0.8277778029441833)
[2024-11-13 10:27:59,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:00,295][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 1.0999276638031006, acc: 0.6926605701446533)
[2024-11-13 10:28:00,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:01,002][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.7273024320602417, acc: 0.7923076748847961)
[2024-11-13 10:28:01,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:01,677][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.004977441392838955, acc: 1.0)
[2024-11-13 10:28:01,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:02,347][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.00757634500041604, acc: 1.0)
[2024-11-13 10:28:02,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:03,016][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 0.05463838949799538, acc: 1.0)
[2024-11-13 10:28:03,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:03,692][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 0.020991288125514984, acc: 1.0)
[2024-11-13 10:28:03,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:04,363][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 0.12359928339719772, acc: 0.9714285731315613)
[2024-11-13 10:28:04,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:05,035][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.061167482286691666, acc: 1.0)
[2024-11-13 10:28:05,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:05,718][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.06289121508598328, acc: 1.0)
[2024-11-13 10:28:05,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:06,399][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.5073138475418091, acc: 0.8387096524238586)
[2024-11-13 10:28:06,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:07,076][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.23335403203964233, acc: 0.8863636255264282)
[2024-11-13 10:28:07,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:07,757][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.0009347188170067966, acc: 1.0)
[2024-11-13 10:28:07,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:08,438][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 0.0010061906650662422, acc: 1.0)
[2024-11-13 10:28:08,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:09,122][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 0.008232077583670616, acc: 1.0)
[2024-11-13 10:28:09,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:09,793][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 0.00494524696841836, acc: 1.0)
[2024-11-13 10:28:09,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:10,469][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 0.04198195040225983, acc: 1.0)
[2024-11-13 10:28:10,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:11,141][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 0.006064956542104483, acc: 1.0)
[2024-11-13 10:28:11,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:11,813][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.006397968623787165, acc: 1.0)
[2024-11-13 10:28:11,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:12,500][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.17133450508117676, acc: 0.9411764740943909)
[2024-11-13 10:28:12,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:13,173][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.029979458078742027, acc: 1.0)
[2024-11-13 10:28:13,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:13,844][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.0015845843590795994, acc: 1.0)
[2024-11-13 10:28:13,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:14,518][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.001043773489072919, acc: 1.0)
[2024-11-13 10:28:14,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:15,187][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.0029875137843191624, acc: 1.0)
[2024-11-13 10:28:15,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:15,864][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.015203509479761124, acc: 1.0)
[2024-11-13 10:28:15,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:16,546][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.0322619192302227, acc: 0.9857142567634583)
[2024-11-13 10:28:16,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:17,229][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 0.02287234179675579, acc: 0.9868420958518982)
[2024-11-13 10:28:17,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:17,934][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 0.18319299817085266, acc: 0.9433962106704712)
[2024-11-13 10:28:18,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:18,655][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 0.24292363226413727, acc: 0.9416666626930237)
[2024-11-13 10:28:18,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:19,331][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 0.019237495958805084, acc: 1.0)
[2024-11-13 10:28:19,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:20,009][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 0.09958589822053909, acc: 1.0)
[2024-11-13 10:28:20,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:20,692][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.570340096950531, acc: 0.8133333325386047)
[2024-11-13 10:28:20,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:21,366][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.29925501346588135, acc: 0.9375)
[2024-11-13 10:28:21,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:22,082][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.9888013601303101, acc: 0.7440000176429749)
[2024-11-13 10:28:22,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:22,778][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.7147754430770874, acc: 0.7865168452262878)
[2024-11-13 10:28:22,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:23,464][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 0.36847949028015137, acc: 0.837837815284729)
[2024-11-13 10:28:23,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:24,147][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 0.19133628904819489, acc: 0.931034505367279)
[2024-11-13 10:28:24,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:24,816][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.002329754875972867, acc: 1.0)
[2024-11-13 10:28:24,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:25,486][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.01107572391629219, acc: 1.0)
[2024-11-13 10:28:25,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:26,159][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.017830578610301018, acc: 1.0)
[2024-11-13 10:28:26,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:26,831][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.0022400005254894495, acc: 1.0)
[2024-11-13 10:28:26,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:27,516][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.21427182853221893, acc: 0.949999988079071)
[2024-11-13 10:28:27,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:28,191][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.029682600870728493, acc: 0.96875)
[2024-11-13 10:28:28,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:28,871][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.002861444605514407, acc: 1.0)
[2024-11-13 10:28:28,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:29,557][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.12361239641904831, acc: 0.931034505367279)
[2024-11-13 10:28:29,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:30,235][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.003675672225654125, acc: 1.0)
[2024-11-13 10:28:30,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:30,911][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.15931867063045502, acc: 0.936170220375061)
[2024-11-13 10:28:30,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:31,594][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.1272854208946228, acc: 0.9375)
[2024-11-13 10:28:31,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:32,270][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.007688015699386597, acc: 1.0)
[2024-11-13 10:28:32,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:32,954][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.3128505051136017, acc: 0.9036144614219666)
[2024-11-13 10:28:33,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:33,649][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 0.38511499762535095, acc: 0.8981481194496155)
[2024-11-13 10:28:33,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:34,322][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 0.12242047488689423, acc: 0.9473684430122375)
[2024-11-13 10:28:34,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:34,998][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.06551748514175415, acc: 1.0)
[2024-11-13 10:28:35,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:35,670][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.051447153091430664, acc: 0.9750000238418579)
[2024-11-13 10:28:36,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:37,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:38,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:39,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:39,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:40,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:40,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:41,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:42,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:42,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:43,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:43,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:44,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:45,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:45,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:46,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:46,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:47,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:48,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:48,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:49,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:50,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:50,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:51,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:51,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:52,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:53,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:53,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:54,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:54,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:55,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:56,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:56,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:57,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:58,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:58,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:59,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:28:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:00,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:00,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:01,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:02,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:03,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:03,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:04,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:05,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:05,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:06,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:06,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:07,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:07,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:08,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:09,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:10,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:10,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:11,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:12,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:12,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:13,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:13,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:14,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:15,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:15,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:16,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:16,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:17,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:18,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:18,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:19,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:20,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:20,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:21,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:21,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:22,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:23,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:23,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:24,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:24,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:25,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:25,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:26,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:28,068][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.9909, device='cuda:0') eval_epoch_loss=tensor(0.6886, device='cuda:0') eval_epoch_acc=tensor(0.8379, device='cuda:0')
[2024-11-13 10:29:28,069][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:29:28,069][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:29:28,468][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_419_loss_0.6885700225830078/model.pt
[2024-11-13 10:29:28,472][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:29:28,473][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 6 is 0.8378909230232239
[2024-11-13 10:29:28,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:29,181][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.2640567719936371, acc: 0.921875)
[2024-11-13 10:29:29,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:29,888][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.3360339105129242, acc: 0.9039999842643738)
[2024-11-13 10:29:29,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:30,569][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.20733188092708588, acc: 0.9340659379959106)
[2024-11-13 10:29:30,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:31,256][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.2922036051750183, acc: 0.9068322777748108)
[2024-11-13 10:29:31,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:31,964][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.3785048723220825, acc: 0.876288652420044)
[2024-11-13 10:29:32,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:32,631][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.07445818930864334, acc: 0.9545454382896423)
[2024-11-13 10:29:32,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:33,305][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.1484585553407669, acc: 0.9523809552192688)
[2024-11-13 10:29:33,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:33,985][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.15716928243637085, acc: 0.9655172228813171)
[2024-11-13 10:29:34,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:34,665][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.11327064782381058, acc: 0.9636363387107849)
[2024-11-13 10:29:34,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:35,386][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.5773372054100037, acc: 0.8505154848098755)
[2024-11-13 10:29:35,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:36,065][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.23108349740505219, acc: 0.931034505367279)
[2024-11-13 10:29:36,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:36,745][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.004188520833849907, acc: 1.0)
[2024-11-13 10:29:36,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:37,434][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.03904367610812187, acc: 0.9736841917037964)
[2024-11-13 10:29:37,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:38,112][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.06020904332399368, acc: 0.9642857313156128)
[2024-11-13 10:29:38,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:38,789][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.016474181786179543, acc: 1.0)
[2024-11-13 10:29:38,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:39,470][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.0633673146367073, acc: 0.9811320900917053)
[2024-11-13 10:29:39,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:40,146][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.010711831972002983, acc: 1.0)
[2024-11-13 10:29:40,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:40,817][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 0.005028352607041597, acc: 1.0)
[2024-11-13 10:29:40,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:41,491][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.0028189814183861017, acc: 1.0)
[2024-11-13 10:29:41,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:42,171][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.049272485077381134, acc: 1.0)
[2024-11-13 10:29:42,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:42,844][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 0.015386820770800114, acc: 1.0)
[2024-11-13 10:29:42,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:43,515][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 0.0010723668383434415, acc: 1.0)
[2024-11-13 10:29:43,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:44,195][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 0.1705773025751114, acc: 0.9710144996643066)
[2024-11-13 10:29:44,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:44,881][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 0.2000582069158554, acc: 0.9305555820465088)
[2024-11-13 10:29:44,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:45,559][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 0.18160046637058258, acc: 0.9397590160369873)
[2024-11-13 10:29:45,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:46,257][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 0.19677616655826569, acc: 0.9358974099159241)
[2024-11-13 10:29:46,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:46,960][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.2120615839958191, acc: 0.918367326259613)
[2024-11-13 10:29:47,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:47,628][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.006037227809429169, acc: 1.0)
[2024-11-13 10:29:47,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:48,297][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.003720761276781559, acc: 1.0)
[2024-11-13 10:29:48,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:48,971][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.007461754139512777, acc: 1.0)
[2024-11-13 10:29:49,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:49,648][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 0.004414041060954332, acc: 1.0)
[2024-11-13 10:29:49,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:50,334][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 0.10404066741466522, acc: 0.9701492786407471)
[2024-11-13 10:29:50,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:51,022][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 0.03340282663702965, acc: 0.9903846383094788)
[2024-11-13 10:29:51,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:51,699][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 0.13428187370300293, acc: 0.9777777791023254)
[2024-11-13 10:29:51,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:52,375][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 0.04035497084259987, acc: 1.0)
[2024-11-13 10:29:52,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:53,053][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 0.018634770065546036, acc: 1.0)
[2024-11-13 10:29:53,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:53,736][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.17054112255573273, acc: 0.9629629850387573)
[2024-11-13 10:29:53,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:54,411][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 0.12993048131465912, acc: 0.9714285731315613)
[2024-11-13 10:29:54,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:55,085][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 0.1681973934173584, acc: 0.9487179517745972)
[2024-11-13 10:29:55,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:55,762][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 0.15977972745895386, acc: 0.9512194991111755)
[2024-11-13 10:29:55,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:56,438][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 0.2384115755558014, acc: 0.9473684430122375)
[2024-11-13 10:29:56,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:57,116][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 0.09159526228904724, acc: 0.9473684430122375)
[2024-11-13 10:29:57,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:57,786][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.0073654926382005215, acc: 1.0)
[2024-11-13 10:29:57,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:58,458][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.004325766582041979, acc: 1.0)
[2024-11-13 10:29:58,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:59,137][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.001566672814078629, acc: 1.0)
[2024-11-13 10:29:59,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:29:59,814][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.05698486045002937, acc: 0.9838709831237793)
[2024-11-13 10:29:59,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:00,496][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 0.015488938428461552, acc: 1.0)
[2024-11-13 10:30:00,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:01,166][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 0.1643584668636322, acc: 0.96875)
[2024-11-13 10:30:01,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:01,839][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 0.023252489045262337, acc: 1.0)
[2024-11-13 10:30:01,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:02,509][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 0.00368526135571301, acc: 1.0)
[2024-11-13 10:30:02,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:03,197][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 0.20187057554721832, acc: 0.9399999976158142)
[2024-11-13 10:30:03,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:03,885][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.5188559889793396, acc: 0.8505747318267822)
[2024-11-13 10:30:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:04,566][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.6468835473060608, acc: 0.7765957713127136)
[2024-11-13 10:30:04,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:05,249][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 0.5571371912956238, acc: 0.8072289228439331)
[2024-11-13 10:30:05,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:05,923][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 0.002959304256364703, acc: 1.0)
[2024-11-13 10:30:06,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:06,594][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 0.05563182756304741, acc: 0.9743589758872986)
[2024-11-13 10:30:06,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:07,280][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 0.22928491234779358, acc: 0.9277108311653137)
[2024-11-13 10:30:07,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:07,962][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 0.03750818595290184, acc: 0.9811320900917053)
[2024-11-13 10:30:08,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:08,640][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 0.07297664880752563, acc: 0.9620253443717957)
[2024-11-13 10:30:08,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:09,320][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.08919969946146011, acc: 0.9803921580314636)
[2024-11-13 10:30:09,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:10,003][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.1214611828327179, acc: 0.9701492786407471)
[2024-11-13 10:30:10,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:10,675][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.006410873029381037, acc: 1.0)
[2024-11-13 10:30:10,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:11,350][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.0070715053007006645, acc: 1.0)
[2024-11-13 10:30:11,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:12,032][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.2637886106967926, acc: 0.8888888955116272)
[2024-11-13 10:30:12,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:12,715][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 0.10897145420312881, acc: 0.9767441749572754)
[2024-11-13 10:30:12,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:13,391][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.014518477953970432, acc: 1.0)
[2024-11-13 10:30:13,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:14,070][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.08136570453643799, acc: 1.0)
[2024-11-13 10:30:14,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:14,740][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 0.004464625380933285, acc: 1.0)
[2024-11-13 10:30:14,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:15,410][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.008076058700680733, acc: 1.0)
[2024-11-13 10:30:15,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:16,095][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 0.49969470500946045, acc: 0.8461538553237915)
[2024-11-13 10:30:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:16,798][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 0.43687331676483154, acc: 0.8782608509063721)
[2024-11-13 10:30:16,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:17,475][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.3258872926235199, acc: 0.9021739363670349)
[2024-11-13 10:30:17,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:18,150][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 0.13319000601768494, acc: 0.9591836929321289)
[2024-11-13 10:30:18,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:18,826][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 0.021554553881287575, acc: 1.0)
[2024-11-13 10:30:18,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:19,496][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 0.028186138719320297, acc: 1.0)
[2024-11-13 10:30:19,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:20,177][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.1620025783777237, acc: 0.9512194991111755)
[2024-11-13 10:30:20,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:20,862][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.03324512019753456, acc: 0.9777777791023254)
[2024-11-13 10:30:20,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:21,544][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 0.04778221249580383, acc: 0.9868420958518982)
[2024-11-13 10:30:21,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:22,222][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 0.01286256592720747, acc: 1.0)
[2024-11-13 10:30:22,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:22,896][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 0.04879618063569069, acc: 0.9696969985961914)
[2024-11-13 10:30:22,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:23,569][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 0.00171666219830513, acc: 1.0)
[2024-11-13 10:30:23,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:24,241][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 0.0007700388669036329, acc: 1.0)
[2024-11-13 10:30:24,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:24,911][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.010581658221781254, acc: 1.0)
[2024-11-13 10:30:24,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:25,585][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.031963933259248734, acc: 0.96875)
[2024-11-13 10:30:25,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:26,293][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.4424082934856415, acc: 0.8666666746139526)
[2024-11-13 10:30:26,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:27,001][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.2887997031211853, acc: 0.8867924809455872)
[2024-11-13 10:30:27,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:27,679][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.09793777763843536, acc: 0.9666666388511658)
[2024-11-13 10:30:27,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:28,357][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.0881943553686142, acc: 0.9464285969734192)
[2024-11-13 10:30:28,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:29,034][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 0.07752064615488052, acc: 0.9714285731315613)
[2024-11-13 10:30:29,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:29,710][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 0.0006049825460650027, acc: 1.0)
[2024-11-13 10:30:29,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:30,381][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.0015462898882105947, acc: 1.0)
[2024-11-13 10:30:30,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:31,070][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.019208671525120735, acc: 1.0)
[2024-11-13 10:30:31,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:31,754][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.011483064852654934, acc: 1.0)
[2024-11-13 10:30:31,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:32,460][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 0.1944519728422165, acc: 0.946107804775238)
[2024-11-13 10:30:32,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:33,142][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 0.22292309999465942, acc: 0.932330846786499)
[2024-11-13 10:30:33,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:33,860][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.6151646971702576, acc: 0.8449198007583618)
[2024-11-13 10:30:33,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:34,567][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 0.10484955459833145, acc: 0.9639639854431152)
[2024-11-13 10:30:34,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:35,241][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 0.017085038125514984, acc: 1.0)
[2024-11-13 10:30:35,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:35,957][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.0008189641521312296, acc: 1.0)
[2024-11-13 10:30:36,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:36,636][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.008990357629954815, acc: 1.0)
[2024-11-13 10:30:36,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:37,325][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.10910269618034363, acc: 0.9722222089767456)
[2024-11-13 10:30:37,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:38,007][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.03442224860191345, acc: 0.9736841917037964)
[2024-11-13 10:30:38,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:38,685][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 0.006682132370769978, acc: 1.0)
[2024-11-13 10:30:38,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:39,369][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 0.0028873130213469267, acc: 1.0)
[2024-11-13 10:30:39,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:40,051][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 0.274220734834671, acc: 0.9523809552192688)
[2024-11-13 10:30:40,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:40,746][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 0.32998567819595337, acc: 0.8888888955116272)
[2024-11-13 10:30:40,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:41,434][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 0.42492586374282837, acc: 0.8543689250946045)
[2024-11-13 10:30:41,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:42,143][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 0.632902979850769, acc: 0.8529411554336548)
[2024-11-13 10:30:42,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:42,832][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.35459035634994507, acc: 0.9066666960716248)
[2024-11-13 10:30:42,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:43,521][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 0.46914127469062805, acc: 0.8819444179534912)
[2024-11-13 10:30:43,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:44,195][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 0.014989054761826992, acc: 1.0)
[2024-11-13 10:30:44,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:44,868][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 0.00563107430934906, acc: 1.0)
[2024-11-13 10:30:44,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:45,549][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 0.06225035339593887, acc: 1.0)
[2024-11-13 10:30:45,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:46,220][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 0.08123836666345596, acc: 0.9599999785423279)
[2024-11-13 10:30:46,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:46,903][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.1397835612297058, acc: 0.9411764740943909)
[2024-11-13 10:30:46,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:47,584][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.22707590460777283, acc: 0.9333333373069763)
[2024-11-13 10:30:47,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:48,257][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.007276252377778292, acc: 1.0)
[2024-11-13 10:30:48,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:48,929][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.09049061685800552, acc: 0.9696969985961914)
[2024-11-13 10:30:49,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:49,601][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 0.0014132547657936811, acc: 1.0)
[2024-11-13 10:30:49,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:50,274][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 0.001598083064891398, acc: 1.0)
[2024-11-13 10:30:50,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:50,945][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.000983796315267682, acc: 1.0)
[2024-11-13 10:30:51,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:51,617][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.004672406706959009, acc: 1.0)
[2024-11-13 10:30:51,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:52,289][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.05555488169193268, acc: 0.9629629850387573)
[2024-11-13 10:30:52,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:52,958][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.0038955286145210266, acc: 1.0)
[2024-11-13 10:30:53,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:53,640][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.006243269890546799, acc: 1.0)
[2024-11-13 10:30:53,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:54,323][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.0067289359867572784, acc: 1.0)
[2024-11-13 10:30:54,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:55,013][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 0.19205649197101593, acc: 0.9333333373069763)
[2024-11-13 10:30:55,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:55,684][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.21323657035827637, acc: 0.939393937587738)
[2024-11-13 10:30:55,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:56,358][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.1385384202003479, acc: 0.9545454382896423)
[2024-11-13 10:30:56,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:57,035][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.06780888140201569, acc: 0.9803921580314636)
[2024-11-13 10:30:57,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:57,706][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.01019227970391512, acc: 1.0)
[2024-11-13 10:30:57,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:58,377][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.014982516877353191, acc: 1.0)
[2024-11-13 10:30:58,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:59,059][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.0552070252597332, acc: 0.9750000238418579)
[2024-11-13 10:30:59,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:30:59,730][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.004496850073337555, acc: 1.0)
[2024-11-13 10:30:59,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:00,400][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 0.1598164290189743, acc: 0.9523809552192688)
[2024-11-13 10:31:00,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:01,074][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 0.11960779875516891, acc: 0.9666666388511658)
[2024-11-13 10:31:01,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:01,747][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 0.32244443893432617, acc: 0.9375)
[2024-11-13 10:31:01,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:02,418][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 0.1540687084197998, acc: 0.9722222089767456)
[2024-11-13 10:31:02,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:03,091][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 0.008665085770189762, acc: 1.0)
[2024-11-13 10:31:03,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:03,762][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.03294360637664795, acc: 1.0)
[2024-11-13 10:31:03,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:04,433][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.016852127388119698, acc: 1.0)
[2024-11-13 10:31:04,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:05,105][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.018193121999502182, acc: 1.0)
[2024-11-13 10:31:05,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:05,779][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.009402592666447163, acc: 1.0)
[2024-11-13 10:31:06,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:07,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:07,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:08,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:09,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:09,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:10,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:10,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:11,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:12,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:12,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:13,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:13,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:14,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:15,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:16,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:16,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:17,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:18,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:18,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:19,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:19,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:20,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:21,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:21,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:22,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:22,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:23,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:24,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:24,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:25,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:25,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:26,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:27,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:27,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:28,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:28,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:29,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:30,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:30,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:31,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:31,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:32,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:33,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:33,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:34,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:34,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:35,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:36,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:36,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:37,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:37,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:38,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:39,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:39,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:40,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:40,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:41,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:42,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:42,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:43,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:43,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:44,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:45,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:45,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:46,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:47,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:48,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:48,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:49,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:49,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:50,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:51,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:51,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:52,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:52,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:53,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:54,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:54,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:55,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:55,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:56,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:56,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:57,806][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.0441, device='cuda:0') eval_epoch_loss=tensor(0.7150, device='cuda:0') eval_epoch_acc=tensor(0.8264, device='cuda:0')
[2024-11-13 10:31:57,808][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:31:57,808][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:31:58,265][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_6_step_562_loss_0.7149558663368225/model.pt
[2024-11-13 10:31:58,269][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:31:58,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:58,961][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 0.014159244485199451, acc: 1.0)
[2024-11-13 10:31:59,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:31:59,630][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.02678838185966015, acc: 1.0)
[2024-11-13 10:31:59,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:00,300][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.004786727949976921, acc: 1.0)
[2024-11-13 10:32:00,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:00,970][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.0013877124292775989, acc: 1.0)
[2024-11-13 10:32:01,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:01,640][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 0.017546961084008217, acc: 1.0)
[2024-11-13 10:32:01,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:02,307][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.007497314363718033, acc: 1.0)
[2024-11-13 10:32:02,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:02,975][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.08126606047153473, acc: 0.9696969985961914)
[2024-11-13 10:32:03,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:03,645][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 0.07337251305580139, acc: 0.9722222089767456)
[2024-11-13 10:32:03,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:04,321][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.03186993673443794, acc: 1.0)
[2024-11-13 10:32:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:04,991][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 0.00794675201177597, acc: 1.0)
[2024-11-13 10:32:05,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:05,662][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 0.07364366948604584, acc: 1.0)
[2024-11-13 10:32:05,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:06,354][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 0.27471068501472473, acc: 0.9242424368858337)
[2024-11-13 10:32:06,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:07,059][root][INFO] - Training Epoch: 6/10, step 574/574 completed (loss: 0.5622637867927551, acc: 0.8240000009536743)
[2024-11-13 10:32:07,734][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=1.1454, train_epoch_loss=0.1357, epoch time 466.98917916603386s
[2024-11-13 10:32:07,734][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 16 GB
[2024-11-13 10:32:07,734][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 10:32:07,734][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 16 GB
[2024-11-13 10:32:07,734][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-13 10:32:07,734][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 10:32:08,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:09,115][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.045750781893730164, acc: 0.9629629850387573)
[2024-11-13 10:32:09,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:09,798][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.04700809344649315, acc: 0.9599999785423279)
[2024-11-13 10:32:09,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:10,489][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 0.27006974816322327, acc: 0.9189189076423645)
[2024-11-13 10:32:10,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:11,187][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 0.04400179162621498, acc: 1.0)
[2024-11-13 10:32:11,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:11,880][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.04290389642119408, acc: 1.0)
[2024-11-13 10:32:11,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:12,569][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.0307545755058527, acc: 1.0)
[2024-11-13 10:32:12,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:13,256][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 0.09880328923463821, acc: 0.9795918464660645)
[2024-11-13 10:32:13,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:13,941][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.05254088342189789, acc: 1.0)
[2024-11-13 10:32:14,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:14,622][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.0012523677432909608, acc: 1.0)
[2024-11-13 10:32:14,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:15,304][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.044082168489694595, acc: 0.9615384340286255)
[2024-11-13 10:32:15,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:15,986][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.008028454147279263, acc: 1.0)
[2024-11-13 10:32:16,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:16,673][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.03839987516403198, acc: 1.0)
[2024-11-13 10:32:16,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:17,366][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.008356345817446709, acc: 1.0)
[2024-11-13 10:32:17,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:18,052][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.017185013741254807, acc: 1.0)
[2024-11-13 10:32:18,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:18,736][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 0.01093646977096796, acc: 1.0)
[2024-11-13 10:32:18,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:19,428][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.06523039191961288, acc: 0.9795918464660645)
[2024-11-13 10:32:19,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:20,116][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.005626408848911524, acc: 1.0)
[2024-11-13 10:32:20,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:20,801][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.008008835837244987, acc: 1.0)
[2024-11-13 10:32:20,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:21,485][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 0.008137715049088001, acc: 1.0)
[2024-11-13 10:32:21,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:22,166][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.0020308331586420536, acc: 1.0)
[2024-11-13 10:32:22,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:22,849][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.0040297359228134155, acc: 1.0)
[2024-11-13 10:32:22,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:23,534][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.15616582334041595, acc: 0.9655172228813171)
[2024-11-13 10:32:23,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:24,226][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.03853437304496765, acc: 1.0)
[2024-11-13 10:32:24,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:24,910][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.013140047900378704, acc: 1.0)
[2024-11-13 10:32:24,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:25,600][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.1501040905714035, acc: 0.9375)
[2024-11-13 10:32:25,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:26,294][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 0.2182740569114685, acc: 0.9433962106704712)
[2024-11-13 10:32:26,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:26,986][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 0.17288702726364136, acc: 0.9452054500579834)
[2024-11-13 10:32:27,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:27,788][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 0.9052919745445251, acc: 0.7035573124885559)
[2024-11-13 10:32:27,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:28,475][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.26410967111587524, acc: 0.9534883499145508)
[2024-11-13 10:32:28,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:29,170][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 0.16495083272457123, acc: 0.9277108311653137)
[2024-11-13 10:32:29,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:29,866][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 0.13979801535606384, acc: 0.9876543283462524)
[2024-11-13 10:32:29,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:30,570][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.02887653186917305, acc: 1.0)
[2024-11-13 10:32:30,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:31,255][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.03666266053915024, acc: 0.9629629850387573)
[2024-11-13 10:32:31,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:31,936][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.01209039893001318, acc: 1.0)
[2024-11-13 10:32:32,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:32,635][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 0.20450669527053833, acc: 0.9411764740943909)
[2024-11-13 10:32:32,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:33,321][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.05196951702237129, acc: 0.9672130942344666)
[2024-11-13 10:32:33,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:34,014][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 0.10010368376970291, acc: 0.9841269850730896)
[2024-11-13 10:32:34,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:34,698][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 0.052571408450603485, acc: 0.9830508232116699)
[2024-11-13 10:32:34,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:35,401][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 0.09153822064399719, acc: 0.977011501789093)
[2024-11-13 10:32:35,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:36,084][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.021665962412953377, acc: 1.0)
[2024-11-13 10:32:36,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:36,767][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.013100399635732174, acc: 1.0)
[2024-11-13 10:32:36,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:37,462][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 0.015104113146662712, acc: 1.0)
[2024-11-13 10:32:37,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:38,164][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 0.056490447372198105, acc: 0.9846153855323792)
[2024-11-13 10:32:38,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:38,858][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 0.13771101832389832, acc: 0.9494949579238892)
[2024-11-13 10:32:38,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:39,570][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 0.14876911044120789, acc: 0.9587628841400146)
[2024-11-13 10:32:39,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:40,272][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 0.09439490735530853, acc: 0.9779411554336548)
[2024-11-13 10:32:40,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:40,954][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.0024437429383397102, acc: 1.0)
[2024-11-13 10:32:41,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:41,637][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.005695193074643612, acc: 1.0)
[2024-11-13 10:32:41,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:42,321][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.038348086178302765, acc: 1.0)
[2024-11-13 10:32:42,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:43,010][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.007093074265867472, acc: 1.0)
[2024-11-13 10:32:43,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:43,712][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.0397460050880909, acc: 1.0)
[2024-11-13 10:32:43,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:44,427][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.09319760650396347, acc: 0.9682539701461792)
[2024-11-13 10:32:44,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:45,126][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 0.17687055468559265, acc: 0.9154929518699646)
[2024-11-13 10:32:45,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:45,848][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 0.7460954189300537, acc: 0.800000011920929)
[2024-11-13 10:32:45,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:46,531][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.021542945876717567, acc: 1.0)
[2024-11-13 10:32:46,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:47,213][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.015480447560548782, acc: 1.0)
[2024-11-13 10:32:47,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:48,053][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 1.1788420677185059, acc: 0.7098976373672485)
[2024-11-13 10:32:48,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:48,830][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 1.26423180103302, acc: 0.6383442282676697)
[2024-11-13 10:32:48,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:49,558][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 0.32632726430892944, acc: 0.9204545617103577)
[2024-11-13 10:32:49,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:50,257][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 0.14585372805595398, acc: 0.9632353186607361)
[2024-11-13 10:32:50,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:50,989][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 0.3429262042045593, acc: 0.8840579986572266)
[2024-11-13 10:32:51,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:51,709][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 0.3156812787055969, acc: 0.8999999761581421)
[2024-11-13 10:32:51,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:52,398][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.0377567857503891, acc: 1.0)
[2024-11-13 10:32:52,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:53,096][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 0.5183294415473938, acc: 0.9722222089767456)
[2024-11-13 10:32:53,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:53,799][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.03889356553554535, acc: 0.984375)
[2024-11-13 10:32:53,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:54,488][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.0069350930862128735, acc: 1.0)
[2024-11-13 10:32:54,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:55,186][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 0.03832327201962471, acc: 0.9821428656578064)
[2024-11-13 10:32:55,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:55,879][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 0.03771194443106651, acc: 0.9833333492279053)
[2024-11-13 10:32:55,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:56,562][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.15932440757751465, acc: 0.9599999785423279)
[2024-11-13 10:32:56,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:57,248][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.10084095597267151, acc: 0.9722222089767456)
[2024-11-13 10:32:57,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:57,938][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.007587112486362457, acc: 1.0)
[2024-11-13 10:32:58,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:58,658][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 0.30658629536628723, acc: 0.9338235259056091)
[2024-11-13 10:32:58,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:32:59,359][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 0.254149854183197, acc: 0.9285714030265808)
[2024-11-13 10:32:59,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:00,078][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 0.6898912191390991, acc: 0.7948718070983887)
[2024-11-13 10:33:00,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:00,776][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 0.2731614410877228, acc: 0.9285714030265808)
[2024-11-13 10:33:00,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:01,477][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 0.5185553431510925, acc: 0.8358209133148193)
[2024-11-13 10:33:01,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:02,219][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 0.938399612903595, acc: 0.7189781069755554)
[2024-11-13 10:33:02,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:02,901][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.036604396998882294, acc: 0.9523809552192688)
[2024-11-13 10:33:02,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:03,584][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.006426607724279165, acc: 1.0)
[2024-11-13 10:33:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:04,277][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.0020372169092297554, acc: 1.0)
[2024-11-13 10:33:04,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:04,964][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.003864202881231904, acc: 1.0)
[2024-11-13 10:33:05,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:05,658][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.04794243350625038, acc: 0.9807692170143127)
[2024-11-13 10:33:05,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:06,354][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 0.07510098814964294, acc: 0.9807692170143127)
[2024-11-13 10:33:06,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:07,049][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.04011545330286026, acc: 0.96875)
[2024-11-13 10:33:07,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:07,752][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 0.03070581518113613, acc: 0.9855072498321533)
[2024-11-13 10:33:07,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:08,444][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.028631677851080894, acc: 1.0)
[2024-11-13 10:33:08,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:09,126][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.01193303894251585, acc: 1.0)
[2024-11-13 10:33:09,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:09,834][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 0.043921686708927155, acc: 1.0)
[2024-11-13 10:33:09,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:10,535][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 0.15987031161785126, acc: 0.9417475461959839)
[2024-11-13 10:33:10,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:11,266][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 0.5367493033409119, acc: 0.8640776872634888)
[2024-11-13 10:33:11,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:11,991][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 0.7232806086540222, acc: 0.7795698642730713)
[2024-11-13 10:33:12,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:12,727][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 0.6056925654411316, acc: 0.8146551847457886)
[2024-11-13 10:33:12,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:13,421][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 0.20780783891677856, acc: 0.9368420839309692)
[2024-11-13 10:33:13,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:14,145][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 0.32281026244163513, acc: 0.8712871074676514)
[2024-11-13 10:33:14,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:14,834][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 0.08683136105537415, acc: 0.9677419066429138)
[2024-11-13 10:33:14,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:15,524][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 0.0751466155052185, acc: 0.9710144996643066)
[2024-11-13 10:33:15,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:16,221][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 0.27710217237472534, acc: 0.9327731132507324)
[2024-11-13 10:33:16,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:16,922][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 0.13507568836212158, acc: 0.9711538553237915)
[2024-11-13 10:33:17,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:17,625][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 0.345855712890625, acc: 0.9051094651222229)
[2024-11-13 10:33:17,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:18,316][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 0.14483818411827087, acc: 0.9850746393203735)
[2024-11-13 10:33:18,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:19,006][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.011509313248097897, acc: 1.0)
[2024-11-13 10:33:19,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:19,690][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.0012747575528919697, acc: 1.0)
[2024-11-13 10:33:19,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:20,375][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.0019425277132540941, acc: 1.0)
[2024-11-13 10:33:20,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:21,069][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.006840644404292107, acc: 1.0)
[2024-11-13 10:33:21,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:21,761][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 0.029233461245894432, acc: 1.0)
[2024-11-13 10:33:21,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:22,450][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.004070238675922155, acc: 1.0)
[2024-11-13 10:33:22,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:23,133][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.002028030576184392, acc: 1.0)
[2024-11-13 10:33:23,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:23,813][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.0016953636659309268, acc: 1.0)
[2024-11-13 10:33:23,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:24,497][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.0013604109408333898, acc: 1.0)
[2024-11-13 10:33:24,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:25,182][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.007269059773534536, acc: 1.0)
[2024-11-13 10:33:25,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:25,876][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 0.03999299928545952, acc: 0.9846153855323792)
[2024-11-13 10:33:25,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:26,565][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 0.019043579697608948, acc: 1.0)
[2024-11-13 10:33:26,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:27,260][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.20726421475410461, acc: 0.9298245906829834)
[2024-11-13 10:33:27,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:27,951][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.010875442065298557, acc: 1.0)
[2024-11-13 10:33:28,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:28,641][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.03365849703550339, acc: 1.0)
[2024-11-13 10:33:28,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:29,322][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.009265701286494732, acc: 1.0)
[2024-11-13 10:33:29,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:30,019][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 0.17313948273658752, acc: 0.9682539701461792)
[2024-11-13 10:33:30,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:30,711][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 0.08444628864526749, acc: 0.9674796462059021)
[2024-11-13 10:33:30,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:31,407][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.011509268544614315, acc: 1.0)
[2024-11-13 10:33:31,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:32,173][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 0.40900832414627075, acc: 0.8859315514564514)
[2024-11-13 10:33:32,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:32,868][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 0.014757299795746803, acc: 1.0)
[2024-11-13 10:33:32,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:33,559][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.013128523714840412, acc: 1.0)
[2024-11-13 10:33:33,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:34,239][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.004019900690764189, acc: 1.0)
[2024-11-13 10:33:34,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:34,921][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.0009888241766020656, acc: 1.0)
[2024-11-13 10:33:35,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:35,630][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 0.3739624619483948, acc: 0.8895705342292786)
[2024-11-13 10:33:35,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:36,351][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 0.4600319266319275, acc: 0.8958333134651184)
[2024-11-13 10:33:36,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:37,049][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 0.4153464138507843, acc: 0.8500000238418579)
[2024-11-13 10:33:37,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:37,783][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 0.37654682993888855, acc: 0.9047619104385376)
[2024-11-13 10:33:37,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:38,509][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 0.3230213522911072, acc: 0.9128205180168152)
[2024-11-13 10:33:38,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:39,248][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 0.44278955459594727, acc: 0.8823529481887817)
[2024-11-13 10:33:39,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:39,935][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.11894367635250092, acc: 0.9615384340286255)
[2024-11-13 10:33:40,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:41,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:42,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:42,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:43,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:43,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:44,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:45,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:45,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:46,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:46,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:47,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:47,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:48,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:49,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:49,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:50,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:50,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:51,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:52,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:52,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:53,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:53,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:54,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:55,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:55,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:56,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:57,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:57,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:58,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:58,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:33:59,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:00,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:00,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:01,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:02,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:02,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:03,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:03,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:04,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:05,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:05,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:06,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:06,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:07,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:08,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:08,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:09,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:09,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:10,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:10,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:11,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:12,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:12,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:13,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:14,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:14,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:15,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:15,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:16,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:17,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:17,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:18,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:18,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:19,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:19,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:20,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:21,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:21,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:22,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:23,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:23,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:24,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:24,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:25,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:25,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:26,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:27,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:27,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:28,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:28,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:29,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:30,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:30,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:31,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:32,359][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.0908, device='cuda:0') eval_epoch_loss=tensor(0.7375, device='cuda:0') eval_epoch_acc=tensor(0.8381, device='cuda:0')
[2024-11-13 10:34:32,361][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:34:32,362][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:34:33,005][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_131_loss_0.737535834312439/model.pt
[2024-11-13 10:34:33,024][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:34:33,025][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.8380662202835083
[2024-11-13 10:34:33,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:33,732][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.027539797127246857, acc: 1.0)
[2024-11-13 10:34:33,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:34,404][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.19828760623931885, acc: 0.96875)
[2024-11-13 10:34:34,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:35,080][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.02794814668595791, acc: 1.0)
[2024-11-13 10:34:35,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:35,756][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.02704283595085144, acc: 1.0)
[2024-11-13 10:34:35,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:36,437][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.05582832545042038, acc: 0.9615384340286255)
[2024-11-13 10:34:36,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:37,131][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.06945954263210297, acc: 0.9523809552192688)
[2024-11-13 10:34:37,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:37,818][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.08075125515460968, acc: 0.9666666388511658)
[2024-11-13 10:34:37,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:38,488][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.02877665124833584, acc: 1.0)
[2024-11-13 10:34:38,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:39,160][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.010066203773021698, acc: 1.0)
[2024-11-13 10:34:39,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:39,832][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.006269417237490416, acc: 1.0)
[2024-11-13 10:34:39,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:40,516][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.0959797203540802, acc: 1.0)
[2024-11-13 10:34:40,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:41,191][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.17061011493206024, acc: 0.9189189076423645)
[2024-11-13 10:34:41,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:41,897][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 0.36046916246414185, acc: 0.8859649300575256)
[2024-11-13 10:34:41,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:42,584][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 0.550546407699585, acc: 0.858208954334259)
[2024-11-13 10:34:42,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:43,272][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 0.19132116436958313, acc: 0.9387755393981934)
[2024-11-13 10:34:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:43,974][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 0.41660580039024353, acc: 0.8829787373542786)
[2024-11-13 10:34:44,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:44,700][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 0.25280338525772095, acc: 0.9142857193946838)
[2024-11-13 10:34:44,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:45,375][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.17706799507141113, acc: 0.9642857313156128)
[2024-11-13 10:34:45,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:46,047][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.4162595868110657, acc: 0.95652174949646)
[2024-11-13 10:34:46,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:46,721][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.010853390209376812, acc: 1.0)
[2024-11-13 10:34:46,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:47,398][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 0.045047562569379807, acc: 1.0)
[2024-11-13 10:34:47,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:48,090][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 0.1890978068113327, acc: 0.9661017060279846)
[2024-11-13 10:34:48,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:48,774][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 0.11020494997501373, acc: 0.9824561476707458)
[2024-11-13 10:34:48,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:49,459][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 0.13164876401424408, acc: 0.9729729890823364)
[2024-11-13 10:34:49,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:50,135][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.029806798323988914, acc: 1.0)
[2024-11-13 10:34:50,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:50,810][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.0035526975989341736, acc: 1.0)
[2024-11-13 10:34:50,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:51,489][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.08572429418563843, acc: 1.0)
[2024-11-13 10:34:51,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:52,168][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 0.34205445647239685, acc: 0.9054054021835327)
[2024-11-13 10:34:52,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:52,863][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 0.2439039945602417, acc: 0.8888888955116272)
[2024-11-13 10:34:52,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:53,551][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 0.11902856826782227, acc: 0.9651162624359131)
[2024-11-13 10:34:53,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:54,280][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 0.10581550747156143, acc: 0.9529411792755127)
[2024-11-13 10:34:54,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:54,972][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 0.49337896704673767, acc: 0.8876404762268066)
[2024-11-13 10:34:55,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:55,656][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.09464500099420547, acc: 0.9545454382896423)
[2024-11-13 10:34:55,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:56,319][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.19011829793453217, acc: 0.9523809552192688)
[2024-11-13 10:34:56,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:56,994][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 0.05368705466389656, acc: 0.9655172228813171)
[2024-11-13 10:34:57,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:57,680][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.14566893875598907, acc: 0.9387755393981934)
[2024-11-13 10:34:57,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:58,361][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.014295058324933052, acc: 1.0)
[2024-11-13 10:34:58,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:59,047][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 0.1984202265739441, acc: 0.9166666865348816)
[2024-11-13 10:34:59,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:34:59,737][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 0.5518243312835693, acc: 0.8627451062202454)
[2024-11-13 10:34:59,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:00,503][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 0.9426932334899902, acc: 0.6917808055877686)
[2024-11-13 10:35:00,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:01,175][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.0049147699028253555, acc: 1.0)
[2024-11-13 10:35:01,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:01,850][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.03717632219195366, acc: 0.9629629850387573)
[2024-11-13 10:35:01,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:02,538][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.012458086013793945, acc: 1.0)
[2024-11-13 10:35:02,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:03,250][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 0.30022260546684265, acc: 0.9292035102844238)
[2024-11-13 10:35:03,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:03,928][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 0.09928388893604279, acc: 0.9855072498321533)
[2024-11-13 10:35:04,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:04,616][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 0.0863487645983696, acc: 0.9772727489471436)
[2024-11-13 10:35:04,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:05,328][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 0.6209930181503296, acc: 0.8015267252922058)
[2024-11-13 10:35:05,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:06,079][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 0.4471345543861389, acc: 0.8518518805503845)
[2024-11-13 10:35:06,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:06,764][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.05141026899218559, acc: 1.0)
[2024-11-13 10:35:06,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:07,435][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.05355757102370262, acc: 0.9583333134651184)
[2024-11-13 10:35:07,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:08,117][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.009138353168964386, acc: 1.0)
[2024-11-13 10:35:08,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:08,791][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.038406793028116226, acc: 0.9642857313156128)
[2024-11-13 10:35:08,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:09,480][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 0.10329505801200867, acc: 0.9878048896789551)
[2024-11-13 10:35:09,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:10,210][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 0.462043821811676, acc: 0.8912386894226074)
[2024-11-13 10:35:10,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:10,938][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 0.4433235824108124, acc: 0.8731988668441772)
[2024-11-13 10:35:11,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:11,660][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 0.443419873714447, acc: 0.862500011920929)
[2024-11-13 10:35:11,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:12,422][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 0.6958065032958984, acc: 0.8198874592781067)
[2024-11-13 10:35:12,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:13,158][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 0.4603053629398346, acc: 0.8683273792266846)
[2024-11-13 10:35:13,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:13,831][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.027822766453027725, acc: 1.0)
[2024-11-13 10:35:13,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:14,521][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 0.43725794553756714, acc: 0.8023256063461304)
[2024-11-13 10:35:14,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:15,216][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 0.7097116708755493, acc: 0.817460298538208)
[2024-11-13 10:35:15,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:15,913][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 0.5690008997917175, acc: 0.8181818127632141)
[2024-11-13 10:35:15,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:16,598][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 0.3201163709163666, acc: 0.8941176533699036)
[2024-11-13 10:35:16,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:17,310][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 0.6497527956962585, acc: 0.8333333134651184)
[2024-11-13 10:35:17,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:18,004][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 0.3115670680999756, acc: 0.8709677457809448)
[2024-11-13 10:35:18,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:18,678][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.09857801347970963, acc: 0.9642857313156128)
[2024-11-13 10:35:18,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:19,356][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.14314544200897217, acc: 0.949999988079071)
[2024-11-13 10:35:19,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:20,036][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 0.1951633244752884, acc: 0.9558823704719543)
[2024-11-13 10:35:20,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:20,723][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 0.40128466486930847, acc: 0.8970588445663452)
[2024-11-13 10:35:20,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:21,409][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 0.5039684772491455, acc: 0.8474576473236084)
[2024-11-13 10:35:21,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:22,100][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 0.3725333511829376, acc: 0.9029850959777832)
[2024-11-13 10:35:22,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:22,789][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 0.410957396030426, acc: 0.8543689250946045)
[2024-11-13 10:35:22,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:23,478][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 0.17301061749458313, acc: 0.9523809552192688)
[2024-11-13 10:35:23,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:24,168][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 0.0449690967798233, acc: 0.9890109896659851)
[2024-11-13 10:35:24,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:24,890][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 0.2765083611011505, acc: 0.9147982001304626)
[2024-11-13 10:35:24,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:25,617][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 0.4494069814682007, acc: 0.8464567065238953)
[2024-11-13 10:35:25,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:26,334][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 0.21752719581127167, acc: 0.9181034564971924)
[2024-11-13 10:35:26,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:27,055][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 0.37497058510780334, acc: 0.8949275612831116)
[2024-11-13 10:35:27,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:27,781][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 0.2560577988624573, acc: 0.9066147804260254)
[2024-11-13 10:35:27,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:28,489][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 0.06002318486571312, acc: 1.0)
[2024-11-13 10:35:28,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:29,162][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.010884271934628487, acc: 1.0)
[2024-11-13 10:35:29,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:29,840][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.005120087880641222, acc: 1.0)
[2024-11-13 10:35:29,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:30,520][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.0034858479630202055, acc: 1.0)
[2024-11-13 10:35:30,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:31,263][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 0.13628830015659332, acc: 0.9538461565971375)
[2024-11-13 10:35:31,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:31,943][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 0.08702352643013, acc: 0.9729729890823364)
[2024-11-13 10:35:32,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:32,625][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 0.04187193140387535, acc: 0.9883720874786377)
[2024-11-13 10:35:32,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:33,312][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 0.050850894302129745, acc: 0.9819819927215576)
[2024-11-13 10:35:33,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:34,003][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 0.041607946157455444, acc: 0.9888888597488403)
[2024-11-13 10:35:34,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:34,681][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.008833544328808784, acc: 1.0)
[2024-11-13 10:35:34,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:35,356][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.019180141389369965, acc: 1.0)
[2024-11-13 10:35:35,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:36,026][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.0016056409804150462, acc: 1.0)
[2024-11-13 10:35:36,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:36,709][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 0.21309956908226013, acc: 0.9038461446762085)
[2024-11-13 10:35:36,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:37,422][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 0.39399105310440063, acc: 0.89673912525177)
[2024-11-13 10:35:37,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:38,134][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 0.3154730498790741, acc: 0.9204545617103577)
[2024-11-13 10:35:38,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:38,860][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 0.2565550208091736, acc: 0.936170220375061)
[2024-11-13 10:35:38,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:39,540][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.06176929920911789, acc: 0.9811320900917053)
[2024-11-13 10:35:39,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:40,225][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.07114195078611374, acc: 0.9666666388511658)
[2024-11-13 10:35:40,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:40,918][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.12348466366529465, acc: 0.9534883499145508)
[2024-11-13 10:35:41,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:41,592][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 0.020745906978845596, acc: 1.0)
[2024-11-13 10:35:41,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:42,281][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 0.6860591173171997, acc: 0.7894737124443054)
[2024-11-13 10:35:42,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:42,961][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 0.30221953988075256, acc: 0.9222221970558167)
[2024-11-13 10:35:43,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:43,666][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 0.5289059281349182, acc: 0.8500000238418579)
[2024-11-13 10:35:43,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:44,374][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 1.0023990869522095, acc: 0.7018348574638367)
[2024-11-13 10:35:44,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:45,081][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 0.5290461778640747, acc: 0.8538461327552795)
[2024-11-13 10:35:45,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:45,751][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.0032135078217834234, acc: 1.0)
[2024-11-13 10:35:45,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:46,435][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.013041260652244091, acc: 1.0)
[2024-11-13 10:35:46,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:47,110][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.020527230575680733, acc: 1.0)
[2024-11-13 10:35:47,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:47,803][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.02477429062128067, acc: 1.0)
[2024-11-13 10:35:47,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:48,483][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.06282468885183334, acc: 1.0)
[2024-11-13 10:35:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:49,161][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.052818380296230316, acc: 1.0)
[2024-11-13 10:35:49,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:49,839][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.06146219000220299, acc: 0.9772727489471436)
[2024-11-13 10:35:49,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:50,534][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 0.3786581754684448, acc: 0.8709677457809448)
[2024-11-13 10:35:50,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:51,223][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.1750572919845581, acc: 0.9772727489471436)
[2024-11-13 10:35:51,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:51,913][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.0006850407226011157, acc: 1.0)
[2024-11-13 10:35:51,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:52,600][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.0019801717717200518, acc: 1.0)
[2024-11-13 10:35:52,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:53,292][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.003961097914725542, acc: 1.0)
[2024-11-13 10:35:53,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:53,967][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.008616439066827297, acc: 1.0)
[2024-11-13 10:35:54,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:54,646][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.07840020954608917, acc: 0.9459459185600281)
[2024-11-13 10:35:54,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:55,314][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.005558964796364307, acc: 1.0)
[2024-11-13 10:35:55,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:55,998][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.01358043309301138, acc: 1.0)
[2024-11-13 10:35:56,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:56,739][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 0.08853239566087723, acc: 0.970588207244873)
[2024-11-13 10:35:56,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:57,417][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.024513447657227516, acc: 0.9756097793579102)
[2024-11-13 10:35:57,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:58,090][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.012147000059485435, acc: 1.0)
[2024-11-13 10:35:58,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:58,764][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.00496378680691123, acc: 1.0)
[2024-11-13 10:35:58,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:35:59,449][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.008941082283854485, acc: 1.0)
[2024-11-13 10:35:59,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:00,133][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.02949482947587967, acc: 0.9824561476707458)
[2024-11-13 10:36:00,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:00,810][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.009408409707248211, acc: 1.0)
[2024-11-13 10:36:00,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:01,492][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.02907964400947094, acc: 0.9868420958518982)
[2024-11-13 10:36:01,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:02,200][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 0.1374613642692566, acc: 0.9622641801834106)
[2024-11-13 10:36:02,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:02,910][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 0.16850672662258148, acc: 0.949999988079071)
[2024-11-13 10:36:02,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:03,583][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.012326795607805252, acc: 1.0)
[2024-11-13 10:36:03,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:04,257][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.007925792597234249, acc: 1.0)
[2024-11-13 10:36:04,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:04,948][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 0.45304861664772034, acc: 0.8533333539962769)
[2024-11-13 10:36:05,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:05,633][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 0.0631965920329094, acc: 1.0)
[2024-11-13 10:36:05,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:06,349][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 0.9411523342132568, acc: 0.7440000176429749)
[2024-11-13 10:36:06,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:07,034][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 0.41133418679237366, acc: 0.8876404762268066)
[2024-11-13 10:36:07,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:07,720][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 0.14583565294742584, acc: 0.9324324131011963)
[2024-11-13 10:36:07,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:08,408][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.08797500282526016, acc: 0.982758641242981)
[2024-11-13 10:36:08,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:09,081][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.0017283528577536345, acc: 1.0)
[2024-11-13 10:36:09,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:09,763][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.0013920892961323261, acc: 1.0)
[2024-11-13 10:36:09,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:10,447][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.005601529497653246, acc: 1.0)
[2024-11-13 10:36:10,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:11,137][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.003580228192731738, acc: 1.0)
[2024-11-13 10:36:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:11,844][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.23487350344657898, acc: 0.9166666865348816)
[2024-11-13 10:36:13,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:13,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:14,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:14,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:15,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:16,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:16,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:17,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:17,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:18,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:19,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:19,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:20,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:20,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:21,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:22,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:22,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:23,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:24,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:24,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:25,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:25,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:26,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:26,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:27,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:28,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:28,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:29,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:29,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:30,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:31,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:31,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:32,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:32,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:33,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:33,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:34,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:35,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:35,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:36,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:36,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:37,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:37,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:38,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:39,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:39,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:40,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:41,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:41,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:42,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:42,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:44,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:44,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:45,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:46,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:46,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:47,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:47,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:48,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:48,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:49,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:50,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:50,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:51,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:51,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:52,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:53,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:53,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:54,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:54,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:55,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:56,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:56,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:57,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:57,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:58,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:59,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:36:59,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:00,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:00,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:01,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:01,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:02,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:03,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:04,185][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3400, device='cuda:0') eval_epoch_loss=tensor(0.8502, device='cuda:0') eval_epoch_acc=tensor(0.8197, device='cuda:0')
[2024-11-13 10:37:04,187][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:37:04,187][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:37:04,636][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_274_loss_0.8501667976379395/model.pt
[2024-11-13 10:37:04,643][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:37:04,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:05,333][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.006512328051030636, acc: 1.0)
[2024-11-13 10:37:05,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:06,006][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.20916682481765747, acc: 0.9666666388511658)
[2024-11-13 10:37:06,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:06,681][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.008979447185993195, acc: 1.0)
[2024-11-13 10:37:06,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:07,362][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.0019992045126855373, acc: 1.0)
[2024-11-13 10:37:07,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:08,045][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.05597184970974922, acc: 1.0)
[2024-11-13 10:37:08,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:08,723][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.17406173050403595, acc: 0.9375)
[2024-11-13 10:37:08,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:09,412][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.03094565123319626, acc: 1.0)
[2024-11-13 10:37:09,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:10,100][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 0.2705909013748169, acc: 0.9277108311653137)
[2024-11-13 10:37:10,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:10,801][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 0.3608299195766449, acc: 0.8796296119689941)
[2024-11-13 10:37:10,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:11,480][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.07672363519668579, acc: 0.9736841917037964)
[2024-11-13 10:37:11,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:12,162][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.016616664826869965, acc: 1.0)
[2024-11-13 10:37:12,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:12,847][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.010425219312310219, acc: 1.0)
[2024-11-13 10:37:12,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:13,549][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 0.14873474836349487, acc: 0.90625)
[2024-11-13 10:37:13,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:14,254][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 0.3564017713069916, acc: 0.9039999842643738)
[2024-11-13 10:37:14,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:14,974][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 0.19020333886146545, acc: 0.9450549483299255)
[2024-11-13 10:37:15,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:15,666][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 0.19323307275772095, acc: 0.9627329111099243)
[2024-11-13 10:37:15,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:16,384][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 0.4055178165435791, acc: 0.8969072103500366)
[2024-11-13 10:37:16,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:17,060][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.0024400644470006227, acc: 1.0)
[2024-11-13 10:37:17,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:17,744][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.00778487091884017, acc: 1.0)
[2024-11-13 10:37:17,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:18,427][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.08195469528436661, acc: 0.982758641242981)
[2024-11-13 10:37:18,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:19,118][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.10977651923894882, acc: 0.9636363387107849)
[2024-11-13 10:37:19,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:19,848][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 0.5991472005844116, acc: 0.8505154848098755)
[2024-11-13 10:37:19,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:20,536][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 0.05645345523953438, acc: 1.0)
[2024-11-13 10:37:20,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:21,212][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.013711891137063503, acc: 1.0)
[2024-11-13 10:37:21,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:21,891][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.13646797835826874, acc: 0.9473684430122375)
[2024-11-13 10:37:21,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:22,576][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.021193575114011765, acc: 1.0)
[2024-11-13 10:37:22,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:23,250][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.0025406312197446823, acc: 1.0)
[2024-11-13 10:37:23,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:23,934][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.08361860364675522, acc: 0.9622641801834106)
[2024-11-13 10:37:24,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:24,615][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.005929120350629091, acc: 1.0)
[2024-11-13 10:37:24,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:25,294][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.004060857463628054, acc: 1.0)
[2024-11-13 10:37:25,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:25,971][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.006766915787011385, acc: 1.0)
[2024-11-13 10:37:26,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:26,655][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.08322039246559143, acc: 0.9836065769195557)
[2024-11-13 10:37:26,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:27,327][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.005388611927628517, acc: 1.0)
[2024-11-13 10:37:27,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:28,003][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.0007713261293247342, acc: 1.0)
[2024-11-13 10:37:28,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:28,694][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 0.0627630278468132, acc: 0.9855072498321533)
[2024-11-13 10:37:28,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:29,382][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 0.1758115291595459, acc: 0.9444444179534912)
[2024-11-13 10:37:29,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:30,067][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.1694381684064865, acc: 0.9638554453849792)
[2024-11-13 10:37:30,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:30,756][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 0.1203954890370369, acc: 0.9487179517745972)
[2024-11-13 10:37:30,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:31,461][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 0.15453055500984192, acc: 0.9693877696990967)
[2024-11-13 10:37:31,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:32,132][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.014544003643095493, acc: 1.0)
[2024-11-13 10:37:32,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:32,805][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.01342779491096735, acc: 1.0)
[2024-11-13 10:37:32,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:33,486][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.008712433278560638, acc: 1.0)
[2024-11-13 10:37:33,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:34,160][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.002152584493160248, acc: 1.0)
[2024-11-13 10:37:34,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:34,841][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.16045716404914856, acc: 0.9402984976768494)
[2024-11-13 10:37:34,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:35,539][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.3296401798725128, acc: 0.942307710647583)
[2024-11-13 10:37:35,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:36,214][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.02157815359532833, acc: 1.0)
[2024-11-13 10:37:36,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:36,894][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.048494014889001846, acc: 0.9838709831237793)
[2024-11-13 10:37:36,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:37,573][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.28213730454444885, acc: 0.9599999785423279)
[2024-11-13 10:37:37,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:38,247][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.18475086987018585, acc: 0.8888888955116272)
[2024-11-13 10:37:38,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:38,923][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 0.07712560892105103, acc: 1.0)
[2024-11-13 10:37:39,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:39,597][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.07838345319032669, acc: 1.0)
[2024-11-13 10:37:39,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:40,274][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 0.14072081446647644, acc: 0.9512194991111755)
[2024-11-13 10:37:40,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:40,951][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.19391149282455444, acc: 0.9473684430122375)
[2024-11-13 10:37:41,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:41,628][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.007409382611513138, acc: 1.0)
[2024-11-13 10:37:41,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:42,311][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.003022949444130063, acc: 1.0)
[2024-11-13 10:37:42,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:42,987][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.020391277968883514, acc: 1.0)
[2024-11-13 10:37:43,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:43,660][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.0018813812639564276, acc: 1.0)
[2024-11-13 10:37:43,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:44,339][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 0.06244872137904167, acc: 0.9838709831237793)
[2024-11-13 10:37:44,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:45,020][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 0.09478936344385147, acc: 0.9649122953414917)
[2024-11-13 10:37:45,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:45,687][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 0.0716535821557045, acc: 0.96875)
[2024-11-13 10:37:45,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:46,355][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.005191596690565348, acc: 1.0)
[2024-11-13 10:37:46,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:47,030][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.027444636449217796, acc: 1.0)
[2024-11-13 10:37:47,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:47,714][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 0.18421947956085205, acc: 0.9599999785423279)
[2024-11-13 10:37:47,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:48,403][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 0.3974641263484955, acc: 0.8735632300376892)
[2024-11-13 10:37:48,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:49,091][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 0.5581372976303101, acc: 0.8297872543334961)
[2024-11-13 10:37:49,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:49,780][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 0.5171281695365906, acc: 0.891566276550293)
[2024-11-13 10:37:49,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:50,466][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.003938747104257345, acc: 1.0)
[2024-11-13 10:37:50,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:51,154][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.02894480712711811, acc: 1.0)
[2024-11-13 10:37:51,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:51,838][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 0.34996047616004944, acc: 0.9397590160369873)
[2024-11-13 10:37:51,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:52,520][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.1668073832988739, acc: 0.9433962106704712)
[2024-11-13 10:37:52,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:53,200][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 0.07141197472810745, acc: 0.9873417615890503)
[2024-11-13 10:37:53,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:53,883][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.12594102323055267, acc: 0.9607843160629272)
[2024-11-13 10:37:53,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:54,567][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 0.13071614503860474, acc: 0.9552238583564758)
[2024-11-13 10:37:54,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:55,243][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.02184404991567135, acc: 1.0)
[2024-11-13 10:37:55,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:55,918][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.26326826214790344, acc: 0.9599999785423279)
[2024-11-13 10:37:56,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:56,593][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.26442575454711914, acc: 0.9166666865348816)
[2024-11-13 10:37:56,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:57,269][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 0.2200181931257248, acc: 0.930232584476471)
[2024-11-13 10:37:57,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:57,942][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.18172124028205872, acc: 0.9487179517745972)
[2024-11-13 10:37:58,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:58,621][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 0.33713021874427795, acc: 0.8888888955116272)
[2024-11-13 10:37:58,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:59,293][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.004309074487537146, acc: 1.0)
[2024-11-13 10:37:59,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:37:59,968][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.1017717495560646, acc: 0.9615384340286255)
[2024-11-13 10:38:00,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:00,653][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 0.3540281057357788, acc: 0.8901098966598511)
[2024-11-13 10:38:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:01,356][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 0.6140647530555725, acc: 0.8086956739425659)
[2024-11-13 10:38:01,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:02,036][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 0.23122625052928925, acc: 0.9130434989929199)
[2024-11-13 10:38:02,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:02,725][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 0.15798728168010712, acc: 0.918367326259613)
[2024-11-13 10:38:02,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:03,401][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.08787386864423752, acc: 0.9583333134651184)
[2024-11-13 10:38:03,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:04,074][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.00792801845818758, acc: 1.0)
[2024-11-13 10:38:04,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:04,756][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.4457513689994812, acc: 0.9268292784690857)
[2024-11-13 10:38:04,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:05,438][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.14165546000003815, acc: 0.9555555582046509)
[2024-11-13 10:38:05,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:06,119][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 0.15304918587207794, acc: 0.9210526347160339)
[2024-11-13 10:38:06,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:06,796][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.02536790817975998, acc: 1.0)
[2024-11-13 10:38:06,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:07,474][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.16322340071201324, acc: 0.9696969985961914)
[2024-11-13 10:38:07,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:08,146][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.0032775327563285828, acc: 1.0)
[2024-11-13 10:38:08,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:08,819][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.001566635211929679, acc: 1.0)
[2024-11-13 10:38:08,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:09,490][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.004641131963580847, acc: 1.0)
[2024-11-13 10:38:09,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:10,164][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.4213089346885681, acc: 0.90625)
[2024-11-13 10:38:10,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:10,874][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 0.34074291586875916, acc: 0.903030276298523)
[2024-11-13 10:38:10,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:11,578][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 0.2437351942062378, acc: 0.9339622855186462)
[2024-11-13 10:38:11,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:12,260][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 0.10314232856035233, acc: 0.9666666388511658)
[2024-11-13 10:38:12,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:12,935][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.07140492647886276, acc: 0.9821428656578064)
[2024-11-13 10:38:13,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:13,624][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.029886167496442795, acc: 1.0)
[2024-11-13 10:38:13,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:14,306][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.0008884239941835403, acc: 1.0)
[2024-11-13 10:38:14,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:14,977][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.0023513215128332376, acc: 1.0)
[2024-11-13 10:38:15,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:15,659][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.0773424357175827, acc: 0.9791666865348816)
[2024-11-13 10:38:15,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:16,351][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 0.026982920244336128, acc: 1.0)
[2024-11-13 10:38:16,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:17,055][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 0.2986840009689331, acc: 0.8922155499458313)
[2024-11-13 10:38:17,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:17,752][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 0.23368442058563232, acc: 0.932330846786499)
[2024-11-13 10:38:17,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:18,470][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 0.613798975944519, acc: 0.8395721912384033)
[2024-11-13 10:38:18,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:19,179][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.08756840974092484, acc: 0.9639639854431152)
[2024-11-13 10:38:19,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:19,862][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.01937347836792469, acc: 1.0)
[2024-11-13 10:38:19,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:20,549][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.0034814116079360247, acc: 1.0)
[2024-11-13 10:38:20,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:21,233][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.30892413854599, acc: 0.9375)
[2024-11-13 10:38:21,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:21,909][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.03005942329764366, acc: 1.0)
[2024-11-13 10:38:21,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:22,591][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.016109289601445198, acc: 1.0)
[2024-11-13 10:38:22,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:23,279][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.029605751857161522, acc: 1.0)
[2024-11-13 10:38:23,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:23,957][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.06171785667538643, acc: 1.0)
[2024-11-13 10:38:24,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:24,630][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.084139883518219, acc: 0.9523809552192688)
[2024-11-13 10:38:24,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:25,310][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.362299382686615, acc: 0.9074074029922485)
[2024-11-13 10:38:25,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:25,994][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 0.5028848648071289, acc: 0.8155339956283569)
[2024-11-13 10:38:26,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:26,712][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 0.586909830570221, acc: 0.845588207244873)
[2024-11-13 10:38:26,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:27,401][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 0.3610464930534363, acc: 0.8799999952316284)
[2024-11-13 10:38:27,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:28,101][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 0.34733492136001587, acc: 0.9236111044883728)
[2024-11-13 10:38:28,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:28,777][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.07087474316358566, acc: 0.9767441749572754)
[2024-11-13 10:38:28,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:29,447][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.003228216664865613, acc: 1.0)
[2024-11-13 10:38:29,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:30,125][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.06820648908615112, acc: 0.9534883499145508)
[2024-11-13 10:38:30,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:30,796][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.013353176414966583, acc: 1.0)
[2024-11-13 10:38:30,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:31,480][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 0.11670875549316406, acc: 0.970588207244873)
[2024-11-13 10:38:31,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:32,160][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 0.1631508469581604, acc: 0.9200000166893005)
[2024-11-13 10:38:32,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:32,832][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.08528546243906021, acc: 0.939393937587738)
[2024-11-13 10:38:32,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:33,507][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.028910581022500992, acc: 1.0)
[2024-11-13 10:38:33,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:34,178][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.08820831030607224, acc: 0.9677419066429138)
[2024-11-13 10:38:34,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:34,860][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.12490331381559372, acc: 0.9629629850387573)
[2024-11-13 10:38:34,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:35,534][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.002230583457276225, acc: 1.0)
[2024-11-13 10:38:35,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:36,196][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.2586437165737152, acc: 0.9444444179534912)
[2024-11-13 10:38:36,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:36,867][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.005041731055825949, acc: 1.0)
[2024-11-13 10:38:36,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:37,539][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.018163533881306648, acc: 1.0)
[2024-11-13 10:38:37,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:38,216][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.02592725120484829, acc: 0.982758641242981)
[2024-11-13 10:38:38,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:38,887][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.04441819339990616, acc: 1.0)
[2024-11-13 10:38:38,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:39,565][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.04400681331753731, acc: 0.9666666388511658)
[2024-11-13 10:38:39,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:40,239][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.004908016417175531, acc: 1.0)
[2024-11-13 10:38:40,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:40,910][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.05112095922231674, acc: 0.9545454382896423)
[2024-11-13 10:38:40,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:41,605][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 0.2922743856906891, acc: 0.9411764740943909)
[2024-11-13 10:38:41,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:42,295][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 0.10965187847614288, acc: 0.9615384340286255)
[2024-11-13 10:38:43,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:43,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:44,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:45,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:45,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:46,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:46,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:47,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:48,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:48,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:49,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:49,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:50,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:51,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:51,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:52,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:53,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:54,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:54,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:55,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:55,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:56,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:57,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:58,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:59,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:38:59,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:00,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:00,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:01,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:02,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:02,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:03,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:03,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:04,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:04,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:05,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:06,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:06,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:07,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:07,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:08,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:09,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:09,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:10,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:10,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:11,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:12,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:12,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:13,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:13,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:14,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:15,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:15,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:16,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:16,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:17,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:18,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:18,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:19,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:19,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:20,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:20,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:21,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:22,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:22,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:23,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:24,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:25,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:25,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:26,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:27,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:27,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:28,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:28,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:29,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:30,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:30,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:31,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:31,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:32,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:32,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:33,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:34,619][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.6315, device='cuda:0') eval_epoch_loss=tensor(0.9676, device='cuda:0') eval_epoch_acc=tensor(0.7981, device='cuda:0')
[2024-11-13 10:39:34,620][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:39:34,620][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:39:35,182][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_417_loss_0.9675605297088623/model.pt
[2024-11-13 10:39:35,186][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:39:35,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:35,892][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.20502835512161255, acc: 0.9444444179534912)
[2024-11-13 10:39:35,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:36,569][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.031916890293359756, acc: 1.0)
[2024-11-13 10:39:36,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:37,245][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.02714608982205391, acc: 1.0)
[2024-11-13 10:39:37,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:37,922][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.0014267609221860766, acc: 1.0)
[2024-11-13 10:39:38,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:38,601][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.26498231291770935, acc: 0.9333333373069763)
[2024-11-13 10:39:38,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:39,277][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.06871306896209717, acc: 0.96875)
[2024-11-13 10:39:39,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:39,959][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.058524396270513535, acc: 0.9722222089767456)
[2024-11-13 10:39:40,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:40,633][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.0155559740960598, acc: 1.0)
[2024-11-13 10:39:40,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:41,305][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.24157235026359558, acc: 0.8787878751754761)
[2024-11-13 10:39:41,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:41,973][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.013697386719286442, acc: 1.0)
[2024-11-13 10:39:42,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:42,649][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 0.007010773289948702, acc: 1.0)
[2024-11-13 10:39:42,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:43,324][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.009608416818082333, acc: 1.0)
[2024-11-13 10:39:43,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:43,996][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.2505825161933899, acc: 0.95652174949646)
[2024-11-13 10:39:44,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:44,669][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.0038564864080399275, acc: 1.0)
[2024-11-13 10:39:44,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:45,340][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.0444047711789608, acc: 0.9629629850387573)
[2024-11-13 10:39:45,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:46,014][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.2511690557003021, acc: 0.95652174949646)
[2024-11-13 10:39:46,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:46,689][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.06491206586360931, acc: 1.0)
[2024-11-13 10:39:46,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:47,358][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.34637945890426636, acc: 0.9599999785423279)
[2024-11-13 10:39:47,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:48,033][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.08554626256227493, acc: 0.9696969985961914)
[2024-11-13 10:39:48,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:48,703][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.07156628370285034, acc: 0.9722222089767456)
[2024-11-13 10:39:48,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:49,381][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.03541255369782448, acc: 1.0)
[2024-11-13 10:39:49,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:50,051][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.3957085907459259, acc: 0.9523809552192688)
[2024-11-13 10:39:50,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:50,729][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.41460946202278137, acc: 0.8974359035491943)
[2024-11-13 10:39:50,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:51,414][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 0.1996956169605255, acc: 0.9696969985961914)
[2024-11-13 10:39:51,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:52,125][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 0.6384294033050537, acc: 0.8240000009536743)
[2024-11-13 10:39:52,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:52,828][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 0.7312425971031189, acc: 0.7903226017951965)
[2024-11-13 10:39:52,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:53,539][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 0.6392537355422974, acc: 0.8258706331253052)
[2024-11-13 10:39:53,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:54,226][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 0.15657562017440796, acc: 0.9433962106704712)
[2024-11-13 10:39:54,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:54,907][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.08254596590995789, acc: 0.9545454382896423)
[2024-11-13 10:39:54,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:55,584][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.00433293217793107, acc: 1.0)
[2024-11-13 10:39:55,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:56,258][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.00960485078394413, acc: 1.0)
[2024-11-13 10:39:56,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:56,928][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.0807589516043663, acc: 0.9642857313156128)
[2024-11-13 10:39:57,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:57,609][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 0.09581649303436279, acc: 0.9850746393203735)
[2024-11-13 10:39:57,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:58,288][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 0.08104828000068665, acc: 0.9861111044883728)
[2024-11-13 10:39:58,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:58,968][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 0.13318544626235962, acc: 0.967391312122345)
[2024-11-13 10:39:59,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:39:59,647][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 0.2715180814266205, acc: 0.9102563858032227)
[2024-11-13 10:39:59,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:00,328][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.23420070111751556, acc: 0.9210526347160339)
[2024-11-13 10:40:00,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:01,003][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.06334518641233444, acc: 0.9795918464660645)
[2024-11-13 10:40:01,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:01,676][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.131119966506958, acc: 0.939393937587738)
[2024-11-13 10:40:01,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:02,360][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 0.45128580927848816, acc: 0.907216489315033)
[2024-11-13 10:40:02,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:03,043][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 0.2166145145893097, acc: 0.9142857193946838)
[2024-11-13 10:40:03,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:03,769][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 0.6166590452194214, acc: 0.8255813717842102)
[2024-11-13 10:40:03,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:04,445][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.21232441067695618, acc: 0.9464285969734192)
[2024-11-13 10:40:04,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:05,131][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 0.24328036606311798, acc: 0.9259259104728699)
[2024-11-13 10:40:05,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:05,804][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.17382261157035828, acc: 0.9166666865348816)
[2024-11-13 10:40:05,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:06,477][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.09395419806241989, acc: 0.9375)
[2024-11-13 10:40:06,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:07,159][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.10891535878181458, acc: 0.9615384340286255)
[2024-11-13 10:40:07,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:07,843][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.1480405628681183, acc: 0.97826087474823)
[2024-11-13 10:40:07,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:08,529][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.3664594888687134, acc: 0.9285714030265808)
[2024-11-13 10:40:08,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:09,212][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 0.3534652888774872, acc: 0.8674699068069458)
[2024-11-13 10:40:09,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:09,926][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 0.2487805038690567, acc: 0.9279279112815857)
[2024-11-13 10:40:10,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:10,617][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 0.5695936679840088, acc: 0.8640776872634888)
[2024-11-13 10:40:10,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:11,346][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 0.4761406183242798, acc: 0.8373983502388)
[2024-11-13 10:40:11,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:12,020][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.13796301186084747, acc: 0.9583333134651184)
[2024-11-13 10:40:12,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:12,689][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.07050590217113495, acc: 1.0)
[2024-11-13 10:40:12,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:13,397][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 0.6281626224517822, acc: 0.7843137383460999)
[2024-11-13 10:40:13,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:14,107][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 0.897175669670105, acc: 0.7598253488540649)
[2024-11-13 10:40:14,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:14,792][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 0.4171815812587738, acc: 0.8541666865348816)
[2024-11-13 10:40:14,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:15,484][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 0.42560675740242004, acc: 0.8466257452964783)
[2024-11-13 10:40:15,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:16,172][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 0.3395356237888336, acc: 0.8992805480957031)
[2024-11-13 10:40:16,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:16,883][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 0.7719471454620361, acc: 0.7587939500808716)
[2024-11-13 10:40:16,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:17,564][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.3605421781539917, acc: 0.9166666865348816)
[2024-11-13 10:40:17,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:18,239][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.04832149296998978, acc: 1.0)
[2024-11-13 10:40:18,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:18,911][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.01715271919965744, acc: 1.0)
[2024-11-13 10:40:18,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:19,581][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.41851097345352173, acc: 0.8999999761581421)
[2024-11-13 10:40:19,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:20,252][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.05671053007245064, acc: 1.0)
[2024-11-13 10:40:20,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:20,936][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.39235812425613403, acc: 0.8793103694915771)
[2024-11-13 10:40:21,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:21,608][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.034747425466775894, acc: 1.0)
[2024-11-13 10:40:21,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:22,279][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.02713899314403534, acc: 1.0)
[2024-11-13 10:40:22,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:22,961][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.19980354607105255, acc: 0.9259259104728699)
[2024-11-13 10:40:23,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:23,648][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.6055832505226135, acc: 0.761904776096344)
[2024-11-13 10:40:23,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:24,325][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.06398412585258484, acc: 1.0)
[2024-11-13 10:40:24,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:25,053][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 0.3270355761051178, acc: 0.9230769276618958)
[2024-11-13 10:40:25,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:25,729][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.07948467135429382, acc: 1.0)
[2024-11-13 10:40:25,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:26,401][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.04451766982674599, acc: 1.0)
[2024-11-13 10:40:26,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:27,082][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.35419100522994995, acc: 0.9019607901573181)
[2024-11-13 10:40:27,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:27,759][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.04139259085059166, acc: 1.0)
[2024-11-13 10:40:27,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:28,439][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.16905297338962555, acc: 0.8947368264198303)
[2024-11-13 10:40:28,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:29,118][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.27269572019577026, acc: 0.8947368264198303)
[2024-11-13 10:40:29,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:29,806][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 0.6976204514503479, acc: 0.8125)
[2024-11-13 10:40:29,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:30,491][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 0.32684627175331116, acc: 0.898876428604126)
[2024-11-13 10:40:30,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:31,192][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 0.6349990367889404, acc: 0.8089887499809265)
[2024-11-13 10:40:31,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:31,921][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.0691088438034058, acc: 0.758865237236023)
[2024-11-13 10:40:32,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:32,608][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 0.5696864724159241, acc: 0.804347813129425)
[2024-11-13 10:40:32,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:33,278][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.007572545204311609, acc: 1.0)
[2024-11-13 10:40:33,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:33,948][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.019656646996736526, acc: 1.0)
[2024-11-13 10:40:34,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:34,617][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.4060177206993103, acc: 0.9629629850387573)
[2024-11-13 10:40:34,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:35,288][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.11513156443834305, acc: 0.9629629850387573)
[2024-11-13 10:40:35,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:35,974][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.2556733787059784, acc: 0.9245283007621765)
[2024-11-13 10:40:36,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:36,651][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.042602214962244034, acc: 0.9655172228813171)
[2024-11-13 10:40:36,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:37,344][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 0.7483318448066711, acc: 0.8018018007278442)
[2024-11-13 10:40:37,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:38,038][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 0.1910519301891327, acc: 0.9436619877815247)
[2024-11-13 10:40:38,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:38,708][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.007960968650877476, acc: 1.0)
[2024-11-13 10:40:38,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:39,384][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.15069222450256348, acc: 0.9666666388511658)
[2024-11-13 10:40:39,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:40,056][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.2174205183982849, acc: 0.9615384340286255)
[2024-11-13 10:40:40,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:40,790][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 1.613876461982727, acc: 0.6214285492897034)
[2024-11-13 10:40:40,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:41,495][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 0.4356808662414551, acc: 0.8650793433189392)
[2024-11-13 10:40:41,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:42,169][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.13203825056552887, acc: 0.9285714030265808)
[2024-11-13 10:40:42,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:42,855][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.23795771598815918, acc: 0.949999988079071)
[2024-11-13 10:40:42,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:43,544][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.4642716944217682, acc: 0.9027777910232544)
[2024-11-13 10:40:43,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:44,217][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.006592452060431242, acc: 1.0)
[2024-11-13 10:40:44,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:44,894][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.09897079318761826, acc: 0.9677419066429138)
[2024-11-13 10:40:44,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:45,559][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.3330081105232239, acc: 0.8999999761581421)
[2024-11-13 10:40:45,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:46,232][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.11097956448793411, acc: 0.9259259104728699)
[2024-11-13 10:40:46,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:47,143][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 1.4370622634887695, acc: 0.6144067645072937)
[2024-11-13 10:40:47,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:47,861][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 0.32620444893836975, acc: 0.89552241563797)
[2024-11-13 10:40:47,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:48,549][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 0.304094135761261, acc: 0.9124087691307068)
[2024-11-13 10:40:48,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:49,267][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 0.6838539242744446, acc: 0.8149999976158142)
[2024-11-13 10:40:49,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:49,956][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 0.039892762899398804, acc: 1.0)
[2024-11-13 10:40:50,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:50,636][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.11587747186422348, acc: 0.9807692170143127)
[2024-11-13 10:40:50,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:51,307][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.20508678257465363, acc: 0.9523809552192688)
[2024-11-13 10:40:51,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:51,989][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 0.7205877304077148, acc: 0.8032786846160889)
[2024-11-13 10:40:52,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:52,667][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 0.16931727528572083, acc: 0.9491525292396545)
[2024-11-13 10:40:52,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:53,344][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 0.3012235164642334, acc: 0.930232584476471)
[2024-11-13 10:40:53,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:54,019][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.28166940808296204, acc: 0.8409090638160706)
[2024-11-13 10:40:54,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:54,698][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.5192267894744873, acc: 0.849056601524353)
[2024-11-13 10:40:54,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:55,371][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.20231260359287262, acc: 0.9772727489471436)
[2024-11-13 10:40:55,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:56,042][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.1717493087053299, acc: 0.9599999785423279)
[2024-11-13 10:40:56,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:56,713][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.10176585614681244, acc: 1.0)
[2024-11-13 10:40:56,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:57,384][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.1859966367483139, acc: 0.9545454382896423)
[2024-11-13 10:40:57,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:58,061][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.18141379952430725, acc: 0.9384615421295166)
[2024-11-13 10:40:58,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:58,740][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.29550492763519287, acc: 0.9375)
[2024-11-13 10:40:58,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:40:59,413][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.23476563394069672, acc: 0.875)
[2024-11-13 10:40:59,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:00,095][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.10895346105098724, acc: 0.9696969985961914)
[2024-11-13 10:41:00,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:00,776][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.11675172299146652, acc: 0.9375)
[2024-11-13 10:41:00,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:01,456][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.14395426213741302, acc: 0.9677419066429138)
[2024-11-13 10:41:01,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:02,125][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.004088651388883591, acc: 1.0)
[2024-11-13 10:41:02,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:02,796][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.02380063384771347, acc: 1.0)
[2024-11-13 10:41:02,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:03,470][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.0223069004714489, acc: 1.0)
[2024-11-13 10:41:03,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:04,151][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.034757282584905624, acc: 0.9714285731315613)
[2024-11-13 10:41:04,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:04,839][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.09768842160701752, acc: 0.9736841917037964)
[2024-11-13 10:41:04,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:05,515][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.07755658030509949, acc: 0.9677419066429138)
[2024-11-13 10:41:05,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:06,197][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.003186184214428067, acc: 1.0)
[2024-11-13 10:41:06,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:06,882][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.13790090382099152, acc: 0.9696969985961914)
[2024-11-13 10:41:06,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:07,559][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.02958168461918831, acc: 1.0)
[2024-11-13 10:41:07,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:08,237][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.153031125664711, acc: 0.9428571462631226)
[2024-11-13 10:41:08,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:08,937][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 0.49417710304260254, acc: 0.8613138794898987)
[2024-11-13 10:41:09,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:09,638][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 0.3128488063812256, acc: 0.9034482836723328)
[2024-11-13 10:41:09,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:10,338][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 0.3737773001194, acc: 0.8999999761581421)
[2024-11-13 10:41:10,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:11,025][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 0.3837328553199768, acc: 0.8741722106933594)
[2024-11-13 10:41:11,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:11,710][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 0.09847389161586761, acc: 0.9658119678497314)
[2024-11-13 10:41:11,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:12,379][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.06316843628883362, acc: 0.9599999785423279)
[2024-11-13 10:41:12,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:13,048][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.08566653728485107, acc: 0.9615384340286255)
[2024-11-13 10:41:14,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:14,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:15,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:15,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:16,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:17,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:17,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:18,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:18,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:19,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:20,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:20,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:21,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:21,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:22,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:23,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:23,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:24,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:24,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:25,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:26,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:26,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:27,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:27,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:28,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:29,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:30,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:30,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:31,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:31,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:32,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:33,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:33,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:34,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:35,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:36,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:36,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:37,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:37,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:38,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:38,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:39,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:40,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:40,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:41,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:41,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:42,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:43,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:43,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:44,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:44,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:45,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:46,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:46,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:47,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:47,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:48,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:49,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:49,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:50,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:51,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:51,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:52,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:52,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:53,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:54,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:54,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:55,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:55,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:57,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:57,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:58,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:58,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:41:59,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:00,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:01,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:01,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:02,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:02,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:03,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:04,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:05,098][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3675, device='cuda:0') eval_epoch_loss=tensor(0.8618, device='cuda:0') eval_epoch_acc=tensor(0.8004, device='cuda:0')
[2024-11-13 10:42:05,099][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:42:05,099][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:42:05,526][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_7_step_560_loss_0.8618388772010803/model.pt
[2024-11-13 10:42:05,529][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:42:05,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:06,212][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.014640463516116142, acc: 1.0)
[2024-11-13 10:42:06,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:06,888][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.06500549614429474, acc: 0.9743589758872986)
[2024-11-13 10:42:06,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:07,587][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 0.38152000308036804, acc: 0.8888888955116272)
[2024-11-13 10:42:07,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:08,265][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.2406454235315323, acc: 0.9350649118423462)
[2024-11-13 10:42:08,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:08,938][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.1904994249343872, acc: 0.9583333134651184)
[2024-11-13 10:42:09,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:09,611][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.1435493379831314, acc: 0.9482758641242981)
[2024-11-13 10:42:09,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:10,305][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 0.20179831981658936, acc: 0.9642857313156128)
[2024-11-13 10:42:10,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:10,991][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.01380189135670662, acc: 1.0)
[2024-11-13 10:42:11,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:11,666][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.18292748928070068, acc: 0.9629629850387573)
[2024-11-13 10:42:11,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:12,396][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 0.4340724050998688, acc: 0.9090909361839294)
[2024-11-13 10:42:12,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:13,067][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.042410269379615784, acc: 0.9838709831237793)
[2024-11-13 10:42:13,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:13,752][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 0.20048470795154572, acc: 0.9316239356994629)
[2024-11-13 10:42:13,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:14,459][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 0.6194790601730347, acc: 0.7806122303009033)
[2024-11-13 10:42:14,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:15,167][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 0.46070319414138794, acc: 0.849056601524353)
[2024-11-13 10:42:15,558][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=1.2037, train_epoch_loss=0.1854, epoch time 607.8221207652241s
[2024-11-13 10:42:15,558][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 10:42:15,558][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 22 GB
[2024-11-13 10:42:15,558][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 10:42:15,558][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 1
[2024-11-13 10:42:15,558][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 10:42:16,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:16,929][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.0440545380115509, acc: 1.0)
[2024-11-13 10:42:17,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:17,614][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.031902506947517395, acc: 1.0)
[2024-11-13 10:42:17,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:18,298][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.34197771549224854, acc: 0.9459459185600281)
[2024-11-13 10:42:18,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:18,983][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.06943251937627792, acc: 0.9736841917037964)
[2024-11-13 10:42:19,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:19,669][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.2444717288017273, acc: 0.8918918967247009)
[2024-11-13 10:42:19,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:20,364][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.042315591126680374, acc: 1.0)
[2024-11-13 10:42:20,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:21,054][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.21607200801372528, acc: 0.9387755393981934)
[2024-11-13 10:42:21,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:21,738][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.0675835981965065, acc: 1.0)
[2024-11-13 10:42:21,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:22,418][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.005319227464497089, acc: 1.0)
[2024-11-13 10:42:22,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:23,100][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.008013743907213211, acc: 1.0)
[2024-11-13 10:42:23,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:23,793][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.09347473084926605, acc: 0.9629629850387573)
[2024-11-13 10:42:23,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:24,480][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 0.05258576571941376, acc: 0.9743589758872986)
[2024-11-13 10:42:24,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:25,176][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.011353395879268646, acc: 1.0)
[2024-11-13 10:42:25,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:25,861][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.06793136149644852, acc: 0.97826087474823)
[2024-11-13 10:42:25,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:26,546][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.09338335692882538, acc: 0.9803921580314636)
[2024-11-13 10:42:26,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:27,234][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.5323461294174194, acc: 0.8979591727256775)
[2024-11-13 10:42:27,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:27,920][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.07025185972452164, acc: 1.0)
[2024-11-13 10:42:28,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:28,605][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.12033361196517944, acc: 0.9583333134651184)
[2024-11-13 10:42:28,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:29,296][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.1194511353969574, acc: 0.9444444179534912)
[2024-11-13 10:42:29,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:29,989][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.005175217054784298, acc: 1.0)
[2024-11-13 10:42:30,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:30,681][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.10659121721982956, acc: 0.9230769276618958)
[2024-11-13 10:42:30,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:31,376][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.19818976521492004, acc: 0.931034505367279)
[2024-11-13 10:42:31,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:32,060][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.33069416880607605, acc: 0.9200000166893005)
[2024-11-13 10:42:32,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:32,740][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.08919835835695267, acc: 0.9523809552192688)
[2024-11-13 10:42:32,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:33,426][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.15123608708381653, acc: 0.9375)
[2024-11-13 10:42:33,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:34,136][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 0.4042469263076782, acc: 0.8867924809455872)
[2024-11-13 10:42:34,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:34,829][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 0.4129065275192261, acc: 0.8630136847496033)
[2024-11-13 10:42:34,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:35,635][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 1.165469765663147, acc: 0.6521739363670349)
[2024-11-13 10:42:35,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:36,318][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.4012218415737152, acc: 0.8837209343910217)
[2024-11-13 10:42:36,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:37,009][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 0.21855202317237854, acc: 0.9397590160369873)
[2024-11-13 10:42:37,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:37,715][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 0.2649480998516083, acc: 0.9012345671653748)
[2024-11-13 10:42:37,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:38,408][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.058405518531799316, acc: 0.9642857313156128)
[2024-11-13 10:42:38,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:39,102][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.33390966057777405, acc: 0.9259259104728699)
[2024-11-13 10:42:39,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:39,790][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.01153599563986063, acc: 1.0)
[2024-11-13 10:42:39,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:40,509][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 0.31011733412742615, acc: 0.9075630307197571)
[2024-11-13 10:42:40,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:41,213][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.09499122202396393, acc: 0.9836065769195557)
[2024-11-13 10:42:41,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:41,915][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.28601786494255066, acc: 0.8888888955116272)
[2024-11-13 10:42:41,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:42,605][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 0.1421978622674942, acc: 0.9661017060279846)
[2024-11-13 10:42:42,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:43,301][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.13055139780044556, acc: 0.977011501789093)
[2024-11-13 10:42:43,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:44,016][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.007001214195042849, acc: 1.0)
[2024-11-13 10:42:44,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:44,702][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.11095663160085678, acc: 1.0)
[2024-11-13 10:42:44,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:45,395][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 0.142058327794075, acc: 0.9594594836235046)
[2024-11-13 10:42:45,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:46,087][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 0.14357730746269226, acc: 0.9538461565971375)
[2024-11-13 10:42:46,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:46,778][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 0.25039437413215637, acc: 0.8787878751754761)
[2024-11-13 10:42:46,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:47,478][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 0.3679627478122711, acc: 0.876288652420044)
[2024-11-13 10:42:47,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:48,191][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 0.25227710604667664, acc: 0.9117646813392639)
[2024-11-13 10:42:48,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:48,874][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.24949434399604797, acc: 0.9230769276618958)
[2024-11-13 10:42:48,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:49,561][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.1560416966676712, acc: 0.9629629850387573)
[2024-11-13 10:42:49,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:50,247][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.09462612867355347, acc: 0.9642857313156128)
[2024-11-13 10:42:50,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:50,935][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.16350941359996796, acc: 0.9166666865348816)
[2024-11-13 10:42:51,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:51,625][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.1772809475660324, acc: 0.9473684430122375)
[2024-11-13 10:42:51,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:52,325][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.19044317305088043, acc: 0.920634925365448)
[2024-11-13 10:42:52,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:53,064][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.4772684872150421, acc: 0.8450704216957092)
[2024-11-13 10:42:53,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:53,786][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 0.8818196654319763, acc: 0.753333330154419)
[2024-11-13 10:42:53,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:54,472][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.18402217328548431, acc: 0.8648648858070374)
[2024-11-13 10:42:54,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:55,173][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.024451665580272675, acc: 1.0)
[2024-11-13 10:42:55,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:56,017][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.2652257680892944, acc: 0.6723549365997314)
[2024-11-13 10:42:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:56,791][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 1.4481384754180908, acc: 0.6056644916534424)
[2024-11-13 10:42:56,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:57,513][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 0.6234926581382751, acc: 0.7954545617103577)
[2024-11-13 10:42:57,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:58,218][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 0.3060714900493622, acc: 0.9264705777168274)
[2024-11-13 10:42:58,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:58,939][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 0.48048147559165955, acc: 0.8550724387168884)
[2024-11-13 10:42:59,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:42:59,661][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 0.39548444747924805, acc: 0.9125000238418579)
[2024-11-13 10:42:59,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:00,350][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.1553560048341751, acc: 0.9411764740943909)
[2024-11-13 10:43:00,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:01,038][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 0.16834384202957153, acc: 0.9166666865348816)
[2024-11-13 10:43:01,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:01,734][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.19118930399417877, acc: 0.921875)
[2024-11-13 10:43:01,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:02,423][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.0381305105984211, acc: 1.0)
[2024-11-13 10:43:02,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:03,123][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.21283601224422455, acc: 0.9285714030265808)
[2024-11-13 10:43:03,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:03,820][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 0.3063913881778717, acc: 0.8833333253860474)
[2024-11-13 10:43:03,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:04,511][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.06565102934837341, acc: 1.0)
[2024-11-13 10:43:04,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:05,198][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.0704522654414177, acc: 1.0)
[2024-11-13 10:43:05,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:05,887][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.3677963316440582, acc: 0.939393937587738)
[2024-11-13 10:43:05,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:06,618][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 0.7671697735786438, acc: 0.8014705777168274)
[2024-11-13 10:43:06,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:07,328][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 0.40540796518325806, acc: 0.8888888955116272)
[2024-11-13 10:43:07,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:08,056][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 0.7867172360420227, acc: 0.7538461685180664)
[2024-11-13 10:43:08,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:08,748][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 0.5418047308921814, acc: 0.8367347121238708)
[2024-11-13 10:43:08,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:09,458][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 0.7329993844032288, acc: 0.8059701323509216)
[2024-11-13 10:43:09,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:10,196][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.154502511024475, acc: 0.6751824617385864)
[2024-11-13 10:43:10,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:10,877][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.005850226618349552, acc: 1.0)
[2024-11-13 10:43:10,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:11,570][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.025493962690234184, acc: 1.0)
[2024-11-13 10:43:11,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:12,254][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.12134647369384766, acc: 0.9696969985961914)
[2024-11-13 10:43:12,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:12,937][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.017778335139155388, acc: 1.0)
[2024-11-13 10:43:13,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:13,630][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.13806425034999847, acc: 0.9807692170143127)
[2024-11-13 10:43:13,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:14,321][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 0.3768198788166046, acc: 0.9230769276618958)
[2024-11-13 10:43:14,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:15,011][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.05975624546408653, acc: 1.0)
[2024-11-13 10:43:15,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:15,703][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 0.07288983464241028, acc: 1.0)
[2024-11-13 10:43:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:16,395][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.10287830233573914, acc: 0.9800000190734863)
[2024-11-13 10:43:16,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:17,078][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.1626966893672943, acc: 0.9130434989929199)
[2024-11-13 10:43:17,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:17,772][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 0.08854573965072632, acc: 0.9800000190734863)
[2024-11-13 10:43:17,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:18,469][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 0.33990389108657837, acc: 0.8834951519966125)
[2024-11-13 10:43:18,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:19,193][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 0.6441155672073364, acc: 0.7864077687263489)
[2024-11-13 10:43:19,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:19,916][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 0.9621137976646423, acc: 0.7150537371635437)
[2024-11-13 10:43:19,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:20,650][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 0.8056567907333374, acc: 0.806034505367279)
[2024-11-13 10:43:20,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:21,348][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 0.47062182426452637, acc: 0.8315789699554443)
[2024-11-13 10:43:21,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:22,070][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 0.6383954286575317, acc: 0.8118811845779419)
[2024-11-13 10:43:22,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:22,764][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 0.20379725098609924, acc: 0.9354838728904724)
[2024-11-13 10:43:22,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:23,477][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 0.23094791173934937, acc: 0.9275362491607666)
[2024-11-13 10:43:23,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:24,197][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 0.4930045008659363, acc: 0.8235294222831726)
[2024-11-13 10:43:24,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:24,903][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 0.3459216356277466, acc: 0.8846153616905212)
[2024-11-13 10:43:25,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:25,621][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 0.5505483150482178, acc: 0.8029196858406067)
[2024-11-13 10:43:25,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:26,309][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 0.34371182322502136, acc: 0.89552241563797)
[2024-11-13 10:43:26,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:26,999][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.04755585640668869, acc: 1.0)
[2024-11-13 10:43:27,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:27,679][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.011836090125143528, acc: 1.0)
[2024-11-13 10:43:27,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:28,356][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.07559671252965927, acc: 0.95652174949646)
[2024-11-13 10:43:28,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:29,042][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.010148792527616024, acc: 1.0)
[2024-11-13 10:43:29,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:29,766][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.15337303280830383, acc: 0.9655172228813171)
[2024-11-13 10:43:29,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:30,473][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.04726840555667877, acc: 0.9767441749572754)
[2024-11-13 10:43:30,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:31,169][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.008361081592738628, acc: 1.0)
[2024-11-13 10:43:31,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:31,850][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.0018381287809461355, acc: 1.0)
[2024-11-13 10:43:31,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:32,539][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.01439095102250576, acc: 1.0)
[2024-11-13 10:43:32,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:33,230][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.07321519404649734, acc: 0.976190447807312)
[2024-11-13 10:43:33,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:33,923][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.10000522434711456, acc: 0.9538461565971375)
[2024-11-13 10:43:34,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:34,629][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.09041871875524521, acc: 0.9649122953414917)
[2024-11-13 10:43:34,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:35,319][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.17814600467681885, acc: 0.9122806787490845)
[2024-11-13 10:43:35,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:36,011][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.04178491234779358, acc: 1.0)
[2024-11-13 10:43:36,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:36,711][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.10287552326917648, acc: 0.9591836929321289)
[2024-11-13 10:43:36,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:37,445][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.04248635470867157, acc: 0.9545454382896423)
[2024-11-13 10:43:37,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:38,160][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.17928080260753632, acc: 0.9682539701461792)
[2024-11-13 10:43:38,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:38,862][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 0.10319539904594421, acc: 0.9837398529052734)
[2024-11-13 10:43:38,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:39,570][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.0955810695886612, acc: 0.9677419066429138)
[2024-11-13 10:43:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:40,335][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 0.5567260384559631, acc: 0.8136882185935974)
[2024-11-13 10:43:40,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:41,031][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.09267540276050568, acc: 0.9733333587646484)
[2024-11-13 10:43:41,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:41,722][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.28362318873405457, acc: 0.942307710647583)
[2024-11-13 10:43:41,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:42,408][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.010323570109903812, acc: 1.0)
[2024-11-13 10:43:42,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:43,090][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.035427600145339966, acc: 1.0)
[2024-11-13 10:43:43,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:43,793][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 0.528988242149353, acc: 0.8650306463241577)
[2024-11-13 10:43:43,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:44,522][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 0.6476886868476868, acc: 0.7777777910232544)
[2024-11-13 10:43:44,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:45,233][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 0.5168140530586243, acc: 0.8166666626930237)
[2024-11-13 10:43:45,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:45,967][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 0.5797785520553589, acc: 0.8095238208770752)
[2024-11-13 10:43:46,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:46,685][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 0.35045307874679565, acc: 0.9076923131942749)
[2024-11-13 10:43:47,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:48,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:48,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:49,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:50,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:50,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:51,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:51,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:52,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:53,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:53,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:54,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:54,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:55,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:56,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:56,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:57,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:57,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:58,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:59,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:43:59,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:00,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:00,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:01,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:02,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:02,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:03,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:04,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:04,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:05,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:05,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:06,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:07,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:07,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:08,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:08,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:09,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:09,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:10,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:11,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:11,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:12,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:13,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:13,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:14,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:14,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:15,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:16,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:16,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:17,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:18,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:18,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:19,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:19,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:20,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:21,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:21,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:22,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:22,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:23,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:24,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:24,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:25,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:25,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:26,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:27,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:27,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:28,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:28,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:29,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:30,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:30,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:31,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:32,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:32,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:33,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:33,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:34,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:34,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:35,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:36,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:36,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:38,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:38,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:39,671][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2187, device='cuda:0') eval_epoch_loss=tensor(0.7969, device='cuda:0') eval_epoch_acc=tensor(0.8159, device='cuda:0')
[2024-11-13 10:44:39,672][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:44:39,673][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:44:40,089][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_129_loss_0.7969423532485962/model.pt
[2024-11-13 10:44:40,093][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:44:40,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:40,837][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 0.5339092016220093, acc: 0.8382353186607361)
[2024-11-13 10:44:40,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:41,511][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.05367398262023926, acc: 1.0)
[2024-11-13 10:44:41,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:42,185][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.029888194054365158, acc: 1.0)
[2024-11-13 10:44:42,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:42,861][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.18221041560173035, acc: 0.96875)
[2024-11-13 10:44:42,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:43,530][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.1521998941898346, acc: 0.95652174949646)
[2024-11-13 10:44:43,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:44,211][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.24128755927085876, acc: 0.9142857193946838)
[2024-11-13 10:44:44,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:44,882][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.1098245307803154, acc: 0.9230769276618958)
[2024-11-13 10:44:44,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:45,563][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.15360906720161438, acc: 0.976190447807312)
[2024-11-13 10:44:45,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:46,236][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.08565155416727066, acc: 1.0)
[2024-11-13 10:44:46,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:46,904][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.2589135766029358, acc: 0.9130434989929199)
[2024-11-13 10:44:46,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:47,580][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.01718551106750965, acc: 1.0)
[2024-11-13 10:44:47,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:48,254][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.10428246855735779, acc: 0.9615384340286255)
[2024-11-13 10:44:48,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:48,924][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.08337067067623138, acc: 1.0)
[2024-11-13 10:44:49,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:49,601][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.2797372043132782, acc: 0.8918918967247009)
[2024-11-13 10:44:49,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:50,316][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 0.6413002014160156, acc: 0.780701756477356)
[2024-11-13 10:44:50,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:51,005][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 0.6289290189743042, acc: 0.7910447716712952)
[2024-11-13 10:44:51,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:51,699][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 0.35132965445518494, acc: 0.8775510191917419)
[2024-11-13 10:44:51,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:52,407][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 0.5904085040092468, acc: 0.8191489577293396)
[2024-11-13 10:44:52,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:53,098][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.34410014748573303, acc: 0.8857142925262451)
[2024-11-13 10:44:53,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:53,775][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.12665727734565735, acc: 0.9642857313156128)
[2024-11-13 10:44:53,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:54,450][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.9414094686508179, acc: 0.8695651888847351)
[2024-11-13 10:44:54,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:55,128][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.47580015659332275, acc: 0.8620689511299133)
[2024-11-13 10:44:55,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:55,806][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.38368967175483704, acc: 0.8913043737411499)
[2024-11-13 10:44:55,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:56,502][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.4411157965660095, acc: 0.8474576473236084)
[2024-11-13 10:44:56,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:57,189][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.3625425696372986, acc: 0.8947368264198303)
[2024-11-13 10:44:57,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:57,873][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 0.2055586874485016, acc: 0.9594594836235046)
[2024-11-13 10:44:57,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:58,551][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.04914540797472, acc: 1.0)
[2024-11-13 10:44:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:59,234][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.04084230214357376, acc: 1.0)
[2024-11-13 10:44:59,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:44:59,909][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.15132781863212585, acc: 1.0)
[2024-11-13 10:44:59,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:00,592][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 0.48819705843925476, acc: 0.8108108043670654)
[2024-11-13 10:45:00,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:01,281][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 0.4998905658721924, acc: 0.8333333134651184)
[2024-11-13 10:45:01,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:01,966][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 0.11306475847959518, acc: 0.9651162624359131)
[2024-11-13 10:45:02,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:02,658][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 0.12505662441253662, acc: 0.9647058844566345)
[2024-11-13 10:45:02,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:03,343][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 0.42675936222076416, acc: 0.8426966071128845)
[2024-11-13 10:45:03,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:04,022][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.09997191280126572, acc: 0.9318181872367859)
[2024-11-13 10:45:04,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:04,692][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.36651304364204407, acc: 0.9047619104385376)
[2024-11-13 10:45:04,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:05,374][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.2532356381416321, acc: 0.931034505367279)
[2024-11-13 10:45:05,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:06,054][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.03437415137887001, acc: 0.9795918464660645)
[2024-11-13 10:45:06,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:06,729][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.08217507600784302, acc: 0.9399999976158142)
[2024-11-13 10:45:06,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:07,445][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.20839601755142212, acc: 0.9166666865348816)
[2024-11-13 10:45:07,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:08,143][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 0.6101972460746765, acc: 0.8333333134651184)
[2024-11-13 10:45:08,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:08,865][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 0.9769375920295715, acc: 0.6575342416763306)
[2024-11-13 10:45:08,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:09,534][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.008076122030615807, acc: 1.0)
[2024-11-13 10:45:09,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:10,204][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.08919213712215424, acc: 0.9629629850387573)
[2024-11-13 10:45:10,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:10,876][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.3491792380809784, acc: 0.8571428656578064)
[2024-11-13 10:45:10,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:11,581][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 0.5865678191184998, acc: 0.8407079577445984)
[2024-11-13 10:45:11,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:12,268][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 0.19902583956718445, acc: 0.9130434989929199)
[2024-11-13 10:45:12,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:12,967][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 0.1663406640291214, acc: 0.9090909361839294)
[2024-11-13 10:45:13,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:13,675][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 0.6946859359741211, acc: 0.8091602921485901)
[2024-11-13 10:45:13,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:14,377][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 0.44506919384002686, acc: 0.8592592477798462)
[2024-11-13 10:45:14,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:15,057][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.20416630804538727, acc: 0.9180327653884888)
[2024-11-13 10:45:15,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:15,731][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.248740091919899, acc: 0.9166666865348816)
[2024-11-13 10:45:15,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:16,403][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.7206366658210754, acc: 0.9200000166893005)
[2024-11-13 10:45:16,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:17,078][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.5274971127510071, acc: 0.9285714030265808)
[2024-11-13 10:45:17,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:17,762][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 0.27006062865257263, acc: 0.9268292784690857)
[2024-11-13 10:45:17,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:18,490][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 0.47092553973197937, acc: 0.8640483617782593)
[2024-11-13 10:45:18,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:19,215][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 0.6287580132484436, acc: 0.8213256597518921)
[2024-11-13 10:45:19,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:19,934][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 0.5027977824211121, acc: 0.828125)
[2024-11-13 10:45:20,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:20,702][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 0.8102312684059143, acc: 0.7636022567749023)
[2024-11-13 10:45:20,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:21,438][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 0.48292219638824463, acc: 0.854092538356781)
[2024-11-13 10:45:21,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:22,109][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.17857776582241058, acc: 0.9200000166893005)
[2024-11-13 10:45:22,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:22,798][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 0.4324163496494293, acc: 0.8720930218696594)
[2024-11-13 10:45:22,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:23,500][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 0.6778948903083801, acc: 0.8492063283920288)
[2024-11-13 10:45:23,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:24,190][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 0.5725418329238892, acc: 0.810606062412262)
[2024-11-13 10:45:24,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:24,881][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 0.2744191884994507, acc: 0.9176470637321472)
[2024-11-13 10:45:24,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:25,588][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 0.5847602486610413, acc: 0.8148148059844971)
[2024-11-13 10:45:25,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:26,291][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 0.39178401231765747, acc: 0.9032257795333862)
[2024-11-13 10:45:26,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:26,963][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.04964614659547806, acc: 1.0)
[2024-11-13 10:45:27,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:27,647][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.363709032535553, acc: 0.8500000238418579)
[2024-11-13 10:45:27,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:28,328][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 0.32159578800201416, acc: 0.8970588445663452)
[2024-11-13 10:45:28,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:29,018][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 0.5934920907020569, acc: 0.8088235259056091)
[2024-11-13 10:45:29,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:29,702][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 0.43943139910697937, acc: 0.8559321761131287)
[2024-11-13 10:45:29,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:30,387][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 0.42221200466156006, acc: 0.888059675693512)
[2024-11-13 10:45:30,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:31,082][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 0.39270320534706116, acc: 0.8737863898277283)
[2024-11-13 10:45:31,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:31,770][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 0.3453432023525238, acc: 0.8888888955116272)
[2024-11-13 10:45:31,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:32,453][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 0.23380228877067566, acc: 0.9230769276618958)
[2024-11-13 10:45:32,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:33,187][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 0.2681501805782318, acc: 0.9327354431152344)
[2024-11-13 10:45:33,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:33,917][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 0.41954344511032104, acc: 0.8622047305107117)
[2024-11-13 10:45:33,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:34,644][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 0.1582973152399063, acc: 0.9525862336158752)
[2024-11-13 10:45:34,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:35,360][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 0.33730992674827576, acc: 0.9021739363670349)
[2024-11-13 10:45:35,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:36,080][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 0.2408890426158905, acc: 0.9143968820571899)
[2024-11-13 10:45:36,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:36,803][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 0.1688079684972763, acc: 0.9239130616188049)
[2024-11-13 10:45:36,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:37,479][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.07873453944921494, acc: 1.0)
[2024-11-13 10:45:37,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:38,158][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.0658693015575409, acc: 1.0)
[2024-11-13 10:45:38,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:38,844][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.012489395216107368, acc: 1.0)
[2024-11-13 10:45:38,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:39,547][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 0.19278599321842194, acc: 0.9307692050933838)
[2024-11-13 10:45:39,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:40,231][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.21120886504650116, acc: 0.9459459185600281)
[2024-11-13 10:45:40,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:40,924][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.0522487536072731, acc: 0.9883720874786377)
[2024-11-13 10:45:41,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:41,610][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 0.0862046629190445, acc: 0.9639639854431152)
[2024-11-13 10:45:41,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:42,293][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.0863301232457161, acc: 0.9666666388511658)
[2024-11-13 10:45:42,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:42,966][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.03277050331234932, acc: 1.0)
[2024-11-13 10:45:43,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:43,640][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.11172576993703842, acc: 0.9259259104728699)
[2024-11-13 10:45:43,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:44,314][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.04234448820352554, acc: 1.0)
[2024-11-13 10:45:44,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:44,999][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.388936847448349, acc: 0.8461538553237915)
[2024-11-13 10:45:45,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:45,705][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 0.3621845245361328, acc: 0.9130434989929199)
[2024-11-13 10:45:45,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:46,417][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 0.34402671456336975, acc: 0.8863636255264282)
[2024-11-13 10:45:46,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:47,130][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 0.40979498624801636, acc: 0.8723404407501221)
[2024-11-13 10:45:47,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:47,806][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.3456973433494568, acc: 0.8301886916160583)
[2024-11-13 10:45:47,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:48,488][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.296193391084671, acc: 0.9166666865348816)
[2024-11-13 10:45:48,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:49,168][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.0701039582490921, acc: 0.9767441749572754)
[2024-11-13 10:45:49,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:49,838][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 0.13878794014453888, acc: 0.9666666388511658)
[2024-11-13 10:45:49,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:50,526][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 0.9626194834709167, acc: 0.75789475440979)
[2024-11-13 10:45:50,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:51,207][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 0.3367604613304138, acc: 0.8999999761581421)
[2024-11-13 10:45:51,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:51,912][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 0.5885279774665833, acc: 0.8222222328186035)
[2024-11-13 10:45:51,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:52,633][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.1817244291305542, acc: 0.6834862232208252)
[2024-11-13 10:45:52,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:53,349][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 0.6697030663490295, acc: 0.8153846263885498)
[2024-11-13 10:45:53,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:54,023][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.05870209261775017, acc: 1.0)
[2024-11-13 10:45:54,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:54,694][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.047269176691770554, acc: 1.0)
[2024-11-13 10:45:54,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:55,363][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.10421113669872284, acc: 0.9545454382896423)
[2024-11-13 10:45:55,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:56,058][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.08314844220876694, acc: 0.9629629850387573)
[2024-11-13 10:45:56,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:56,732][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.33785706758499146, acc: 0.8571428656578064)
[2024-11-13 10:45:56,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:57,406][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.2216542661190033, acc: 0.9545454382896423)
[2024-11-13 10:45:57,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:58,080][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.13434478640556335, acc: 0.9318181872367859)
[2024-11-13 10:45:58,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:58,759][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.43283718824386597, acc: 0.8225806355476379)
[2024-11-13 10:45:58,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:45:59,438][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.19838052988052368, acc: 0.9545454382896423)
[2024-11-13 10:45:59,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:00,109][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.0030342312529683113, acc: 1.0)
[2024-11-13 10:46:00,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:00,782][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.018826134502887726, acc: 1.0)
[2024-11-13 10:46:00,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:01,451][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.031667012721300125, acc: 1.0)
[2024-11-13 10:46:01,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:02,131][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.052552394568920135, acc: 1.0)
[2024-11-13 10:46:02,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:02,814][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.07092267274856567, acc: 0.9729729890823364)
[2024-11-13 10:46:02,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:03,486][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.2561289072036743, acc: 0.9189189076423645)
[2024-11-13 10:46:03,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:04,160][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.053176477551460266, acc: 0.9729729890823364)
[2024-11-13 10:46:04,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:04,855][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.18184800446033478, acc: 0.9411764740943909)
[2024-11-13 10:46:04,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:05,535][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.00709544587880373, acc: 1.0)
[2024-11-13 10:46:05,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:06,206][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.018033625558018684, acc: 1.0)
[2024-11-13 10:46:06,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:06,877][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.19222497940063477, acc: 0.9599999785423279)
[2024-11-13 10:46:06,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:07,550][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.03602519631385803, acc: 0.9677419066429138)
[2024-11-13 10:46:07,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:08,226][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.13486550748348236, acc: 0.9473684430122375)
[2024-11-13 10:46:08,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:08,901][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.11019350588321686, acc: 0.9714285731315613)
[2024-11-13 10:46:08,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:09,591][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.06713399291038513, acc: 0.9736841917037964)
[2024-11-13 10:46:09,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:10,307][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 0.17246654629707336, acc: 0.9433962106704712)
[2024-11-13 10:46:10,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:11,019][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 0.3040115535259247, acc: 0.9083333611488342)
[2024-11-13 10:46:11,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:11,693][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.09611248224973679, acc: 0.9722222089767456)
[2024-11-13 10:46:11,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:12,362][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.37786418199539185, acc: 0.8387096524238586)
[2024-11-13 10:46:12,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:13,052][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 0.7134811878204346, acc: 0.7599999904632568)
[2024-11-13 10:46:13,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:13,732][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.23560208082199097, acc: 0.9375)
[2024-11-13 10:46:13,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:14,447][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 0.8261093497276306, acc: 0.7200000286102295)
[2024-11-13 10:46:14,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:15,143][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 0.7924239635467529, acc: 0.7640449404716492)
[2024-11-13 10:46:15,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:15,828][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 0.27299731969833374, acc: 0.9189189076423645)
[2024-11-13 10:46:15,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:16,526][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.13847699761390686, acc: 0.9655172228813171)
[2024-11-13 10:46:16,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:17,196][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.017669586464762688, acc: 1.0)
[2024-11-13 10:46:17,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:17,871][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.24893707036972046, acc: 0.9090909361839294)
[2024-11-13 10:46:17,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:18,555][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.06263992190361023, acc: 0.96875)
[2024-11-13 10:46:19,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:20,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:20,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:21,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:21,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:22,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:23,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:23,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:24,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:24,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:25,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:26,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:26,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:27,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:28,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:28,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:29,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:30,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:31,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:31,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:32,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:32,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:33,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:33,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:34,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:35,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:35,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:36,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:36,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:37,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:38,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:38,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:39,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:40,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:40,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:41,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:41,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:42,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:43,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:43,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:44,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:45,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:45,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:46,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:46,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:47,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:48,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:48,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:49,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:50,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:51,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:51,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:52,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:53,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:53,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:54,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:54,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:55,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:55,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:56,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:57,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:57,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:58,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:59,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:46:59,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:00,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:00,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:01,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:02,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:02,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:03,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:04,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:04,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:05,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:05,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:06,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:07,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:07,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:08,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:08,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:09,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:10,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:10,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:11,715][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3022, device='cuda:0') eval_epoch_loss=tensor(0.8339, device='cuda:0') eval_epoch_acc=tensor(0.8131, device='cuda:0')
[2024-11-13 10:47:11,716][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:47:11,716][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:47:12,268][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_272_loss_0.8338857293128967/model.pt
[2024-11-13 10:47:12,278][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:47:12,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:13,001][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.02200804091989994, acc: 1.0)
[2024-11-13 10:47:13,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:13,682][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.3605949580669403, acc: 0.8999999761581421)
[2024-11-13 10:47:13,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:14,365][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.10039138048887253, acc: 0.96875)
[2024-11-13 10:47:14,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:15,038][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.00809116754680872, acc: 1.0)
[2024-11-13 10:47:15,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:15,708][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.18832813203334808, acc: 0.9655172228813171)
[2024-11-13 10:47:15,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:16,383][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.03434592857956886, acc: 1.0)
[2024-11-13 10:47:16,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:17,062][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.17613933980464935, acc: 0.936170220375061)
[2024-11-13 10:47:17,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:17,738][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.11220944672822952, acc: 0.9375)
[2024-11-13 10:47:17,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:18,409][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.035063810646533966, acc: 0.9772727489471436)
[2024-11-13 10:47:18,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:19,093][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 0.5240854024887085, acc: 0.8192771077156067)
[2024-11-13 10:47:19,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:19,774][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 0.5371947288513184, acc: 0.8240740895271301)
[2024-11-13 10:47:19,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:20,446][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.12885461747646332, acc: 0.9473684430122375)
[2024-11-13 10:47:20,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:21,161][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.34758689999580383, acc: 0.8529411554336548)
[2024-11-13 10:47:21,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:21,839][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.05146440118551254, acc: 0.9750000238418579)
[2024-11-13 10:47:21,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:22,536][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 0.20856285095214844, acc: 0.9453125)
[2024-11-13 10:47:22,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:23,239][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 0.3621458113193512, acc: 0.8960000276565552)
[2024-11-13 10:47:23,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:23,919][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 0.19803504645824432, acc: 0.901098906993866)
[2024-11-13 10:47:24,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:24,623][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 0.27727293968200684, acc: 0.8944099545478821)
[2024-11-13 10:47:24,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:25,350][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 0.3079771101474762, acc: 0.9020618796348572)
[2024-11-13 10:47:25,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:26,022][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.05311274528503418, acc: 0.9545454382896423)
[2024-11-13 10:47:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:26,703][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.18655845522880554, acc: 0.9285714030265808)
[2024-11-13 10:47:26,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:27,390][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.14655587077140808, acc: 0.9482758641242981)
[2024-11-13 10:47:27,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:28,076][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.3283212184906006, acc: 0.9090909361839294)
[2024-11-13 10:47:28,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:28,800][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 0.6600908041000366, acc: 0.7938144207000732)
[2024-11-13 10:47:28,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:29,489][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.273011714220047, acc: 0.9137930870056152)
[2024-11-13 10:47:29,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:30,180][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.15649263560771942, acc: 0.9259259104728699)
[2024-11-13 10:47:30,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:30,865][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.20420759916305542, acc: 0.9736841917037964)
[2024-11-13 10:47:30,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:31,561][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.1918317973613739, acc: 0.9107142686843872)
[2024-11-13 10:47:31,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:32,237][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.0623343363404274, acc: 0.96875)
[2024-11-13 10:47:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:32,918][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.09417343139648438, acc: 0.9811320900917053)
[2024-11-13 10:47:33,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:33,607][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.052112121134996414, acc: 0.9622641801834106)
[2024-11-13 10:47:33,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:34,292][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.09066944569349289, acc: 0.970588207244873)
[2024-11-13 10:47:34,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:34,983][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.0829152911901474, acc: 1.0)
[2024-11-13 10:47:35,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:35,665][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.14080975949764252, acc: 0.9672130942344666)
[2024-11-13 10:47:35,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:36,336][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.020151210948824883, acc: 1.0)
[2024-11-13 10:47:36,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:37,010][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.0018013248918578029, acc: 1.0)
[2024-11-13 10:47:37,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:37,689][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.36916908621788025, acc: 0.9130434989929199)
[2024-11-13 10:47:37,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:38,372][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 0.25542840361595154, acc: 0.9444444179534912)
[2024-11-13 10:47:38,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:39,052][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.2052484005689621, acc: 0.9397590160369873)
[2024-11-13 10:47:39,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:39,742][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 0.18854571878910065, acc: 0.9487179517745972)
[2024-11-13 10:47:39,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:40,446][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 0.24209442734718323, acc: 0.9387755393981934)
[2024-11-13 10:47:40,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:41,123][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.0037536027375608683, acc: 1.0)
[2024-11-13 10:47:41,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:41,796][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.1265004426240921, acc: 0.9583333134651184)
[2024-11-13 10:47:41,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:42,469][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.02064119465649128, acc: 1.0)
[2024-11-13 10:47:42,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:43,147][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.006326867733150721, acc: 1.0)
[2024-11-13 10:47:43,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:43,831][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.19883082807064056, acc: 0.89552241563797)
[2024-11-13 10:47:43,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:44,517][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.11641991138458252, acc: 0.9711538553237915)
[2024-11-13 10:47:44,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:45,191][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.12437338382005692, acc: 0.9111111164093018)
[2024-11-13 10:47:45,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:45,871][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.06669105589389801, acc: 1.0)
[2024-11-13 10:47:45,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:46,547][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.2734651267528534, acc: 0.9599999785423279)
[2024-11-13 10:47:46,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:47,217][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.8321240544319153, acc: 0.8888888955116272)
[2024-11-13 10:47:47,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:47,892][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 0.35559192299842834, acc: 0.8857142925262451)
[2024-11-13 10:47:47,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:48,571][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.256894588470459, acc: 0.9487179517745972)
[2024-11-13 10:47:48,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:49,254][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 0.5111263990402222, acc: 0.8292682766914368)
[2024-11-13 10:47:49,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:49,930][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.4854951798915863, acc: 0.8684210777282715)
[2024-11-13 10:47:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:50,607][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.05014903470873833, acc: 1.0)
[2024-11-13 10:47:50,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:51,282][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.055436618626117706, acc: 1.0)
[2024-11-13 10:47:51,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:51,959][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.09942331165075302, acc: 0.9259259104728699)
[2024-11-13 10:47:52,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:52,630][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.0051341853104531765, acc: 1.0)
[2024-11-13 10:47:52,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:53,307][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.16050176322460175, acc: 0.9516128897666931)
[2024-11-13 10:47:53,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:53,987][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.034350622445344925, acc: 1.0)
[2024-11-13 10:47:54,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:54,656][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.09108659625053406, acc: 0.9375)
[2024-11-13 10:47:54,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:55,329][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.04084611311554909, acc: 1.0)
[2024-11-13 10:47:55,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:56,002][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.02420654706656933, acc: 1.0)
[2024-11-13 10:47:56,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:56,685][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.22618012130260468, acc: 0.9200000166893005)
[2024-11-13 10:47:56,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:57,372][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 0.6433755159378052, acc: 0.8045976758003235)
[2024-11-13 10:47:57,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:58,055][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 0.7133684158325195, acc: 0.7659574747085571)
[2024-11-13 10:47:58,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:58,738][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 0.6674295663833618, acc: 0.8072289228439331)
[2024-11-13 10:47:58,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:47:59,415][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.004966855980455875, acc: 1.0)
[2024-11-13 10:47:59,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:00,095][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.25009772181510925, acc: 0.9487179517745972)
[2024-11-13 10:48:00,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:00,775][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 0.2890266478061676, acc: 0.9156626462936401)
[2024-11-13 10:48:00,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:01,454][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.25309237837791443, acc: 0.9245283007621765)
[2024-11-13 10:48:01,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:02,133][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.11396793276071548, acc: 0.949367105960846)
[2024-11-13 10:48:02,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:02,807][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.0989106222987175, acc: 0.9803921580314636)
[2024-11-13 10:48:02,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:03,489][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 0.4032469391822815, acc: 0.8656716346740723)
[2024-11-13 10:48:03,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:04,168][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.07360494881868362, acc: 0.949999988079071)
[2024-11-13 10:48:04,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:04,839][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.03390097990632057, acc: 1.0)
[2024-11-13 10:48:04,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:05,519][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.32221347093582153, acc: 0.8888888955116272)
[2024-11-13 10:48:05,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:06,200][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.3123754560947418, acc: 0.9069767594337463)
[2024-11-13 10:48:06,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:06,876][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.16019535064697266, acc: 0.9487179517745972)
[2024-11-13 10:48:06,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:07,564][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.299869179725647, acc: 0.9111111164093018)
[2024-11-13 10:48:07,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:08,237][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.018816595897078514, acc: 1.0)
[2024-11-13 10:48:08,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:08,907][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.05442390963435173, acc: 1.0)
[2024-11-13 10:48:09,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:09,590][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 0.4925495684146881, acc: 0.8131868243217468)
[2024-11-13 10:48:09,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:10,292][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 0.5905221104621887, acc: 0.800000011920929)
[2024-11-13 10:48:10,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:10,975][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 0.31945228576660156, acc: 0.9021739363670349)
[2024-11-13 10:48:11,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:11,653][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.22370631992816925, acc: 0.918367326259613)
[2024-11-13 10:48:11,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:12,324][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.010395067743957043, acc: 1.0)
[2024-11-13 10:48:12,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:13,006][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.029603261500597, acc: 1.0)
[2024-11-13 10:48:13,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:13,678][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.14599353075027466, acc: 0.9756097793579102)
[2024-11-13 10:48:13,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:14,357][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.1706426441669464, acc: 0.9555555582046509)
[2024-11-13 10:48:14,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:15,047][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 0.2068788707256317, acc: 0.9605262875556946)
[2024-11-13 10:48:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:15,733][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.02836652286350727, acc: 1.0)
[2024-11-13 10:48:15,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:16,416][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.0821160152554512, acc: 1.0)
[2024-11-13 10:48:16,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:17,091][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.006559221539646387, acc: 1.0)
[2024-11-13 10:48:17,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:17,763][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.0011878840159624815, acc: 1.0)
[2024-11-13 10:48:17,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:18,438][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.03169051557779312, acc: 1.0)
[2024-11-13 10:48:18,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:19,119][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.13451722264289856, acc: 0.96875)
[2024-11-13 10:48:19,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:19,831][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 0.4830126166343689, acc: 0.8606060743331909)
[2024-11-13 10:48:19,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:20,534][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 0.4070877432823181, acc: 0.8867924809455872)
[2024-11-13 10:48:20,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:21,215][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.13054034113883972, acc: 0.9666666388511658)
[2024-11-13 10:48:21,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:21,891][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.06258239597082138, acc: 0.9642857313156128)
[2024-11-13 10:48:21,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:22,569][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.04878982529044151, acc: 1.0)
[2024-11-13 10:48:22,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:23,247][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.0026725693605840206, acc: 1.0)
[2024-11-13 10:48:23,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:23,923][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.07241823524236679, acc: 0.95652174949646)
[2024-11-13 10:48:24,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:24,601][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.031096473336219788, acc: 1.0)
[2024-11-13 10:48:24,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:25,283][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 0.0462324358522892, acc: 0.9789473414421082)
[2024-11-13 10:48:25,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:25,985][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 0.23741431534290314, acc: 0.9281437397003174)
[2024-11-13 10:48:26,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:26,680][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.30569952726364136, acc: 0.9248120188713074)
[2024-11-13 10:48:26,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:27,409][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 0.5609076619148254, acc: 0.8502673506736755)
[2024-11-13 10:48:27,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:28,114][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.14598259329795837, acc: 0.9279279112815857)
[2024-11-13 10:48:28,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:28,785][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.018812591210007668, acc: 1.0)
[2024-11-13 10:48:28,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:29,455][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.0022088519763201475, acc: 1.0)
[2024-11-13 10:48:29,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:30,127][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.07123447209596634, acc: 0.96875)
[2024-11-13 10:48:30,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:30,799][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.009314789436757565, acc: 1.0)
[2024-11-13 10:48:30,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:31,472][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.08579876273870468, acc: 0.9736841917037964)
[2024-11-13 10:48:31,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:32,141][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.0015880841528996825, acc: 1.0)
[2024-11-13 10:48:32,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:32,814][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.007377344183623791, acc: 1.0)
[2024-11-13 10:48:32,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:33,484][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.12432791292667389, acc: 0.9523809552192688)
[2024-11-13 10:48:33,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:34,157][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.35445231199264526, acc: 0.8518518805503845)
[2024-11-13 10:48:34,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:34,837][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 0.6697458028793335, acc: 0.7766990065574646)
[2024-11-13 10:48:34,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:35,552][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 0.46340763568878174, acc: 0.845588207244873)
[2024-11-13 10:48:35,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:36,244][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 0.4355563223361969, acc: 0.8533333539962769)
[2024-11-13 10:48:36,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:36,939][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 0.43246543407440186, acc: 0.875)
[2024-11-13 10:48:37,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:37,614][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.08845019340515137, acc: 0.9534883499145508)
[2024-11-13 10:48:37,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:38,288][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.053948625922203064, acc: 0.9583333134651184)
[2024-11-13 10:48:38,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:38,962][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.0832286849617958, acc: 0.9534883499145508)
[2024-11-13 10:48:39,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:39,632][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.09848666936159134, acc: 0.9599999785423279)
[2024-11-13 10:48:39,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:40,317][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.3460816442966461, acc: 0.8970588445663452)
[2024-11-13 10:48:40,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:40,995][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.1971312016248703, acc: 0.9466666579246521)
[2024-11-13 10:48:41,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:41,675][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.010440333746373653, acc: 1.0)
[2024-11-13 10:48:41,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:42,349][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.007394720334559679, acc: 1.0)
[2024-11-13 10:48:42,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:43,019][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.0024794861674308777, acc: 1.0)
[2024-11-13 10:48:43,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:43,691][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.02767665684223175, acc: 1.0)
[2024-11-13 10:48:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:44,359][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.0009759807726368308, acc: 1.0)
[2024-11-13 10:48:44,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:45,033][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.0026790511328727007, acc: 1.0)
[2024-11-13 10:48:45,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:45,703][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.0046663228422403336, acc: 1.0)
[2024-11-13 10:48:45,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:46,379][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.0013788254000246525, acc: 1.0)
[2024-11-13 10:48:46,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:47,058][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.038697101175785065, acc: 0.982758641242981)
[2024-11-13 10:48:47,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:47,726][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.16036055982112885, acc: 0.9642857313156128)
[2024-11-13 10:48:47,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:48,397][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.0272646714001894, acc: 1.0)
[2024-11-13 10:48:48,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:49,067][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.196726456284523, acc: 0.9090909361839294)
[2024-11-13 10:48:49,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:49,736][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.02121204137802124, acc: 1.0)
[2024-11-13 10:48:50,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:51,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:51,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:52,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:53,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:54,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:54,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:55,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:55,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:56,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:57,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:57,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:58,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:58,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:59,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:48:59,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:00,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:01,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:01,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:02,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:02,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:03,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:04,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:04,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:05,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:05,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:06,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:07,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:07,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:08,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:08,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:09,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:10,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:10,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:11,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:11,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:12,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:12,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:13,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:14,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:14,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:15,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:15,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:16,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:17,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:17,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:18,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:18,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:19,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:20,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:20,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:21,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:21,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:22,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:23,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:24,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:24,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:26,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:26,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:27,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:27,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:28,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:29,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:29,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:30,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:31,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:31,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:32,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:32,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:33,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:34,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:34,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:35,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:36,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:36,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:37,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:37,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:38,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:38,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:39,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:40,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:40,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:41,697][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4273, device='cuda:0') eval_epoch_loss=tensor(0.8868, device='cuda:0') eval_epoch_acc=tensor(0.8008, device='cuda:0')
[2024-11-13 10:49:41,698][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:49:41,698][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:49:42,021][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_415_loss_0.8867866396903992/model.pt
[2024-11-13 10:49:42,025][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:49:42,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:42,720][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.1866057962179184, acc: 0.9411764740943909)
[2024-11-13 10:49:42,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:43,401][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.04567022994160652, acc: 0.9615384340286255)
[2024-11-13 10:49:43,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:44,074][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.00983298197388649, acc: 1.0)
[2024-11-13 10:49:44,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:44,759][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.2548523545265198, acc: 0.9750000238418579)
[2024-11-13 10:49:44,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:45,442][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.009073769673705101, acc: 1.0)
[2024-11-13 10:49:45,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:46,115][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.005448461975902319, acc: 1.0)
[2024-11-13 10:49:46,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:46,799][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.040738046169281006, acc: 1.0)
[2024-11-13 10:49:46,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:47,470][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.14921657741069794, acc: 0.96875)
[2024-11-13 10:49:47,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:48,152][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.055873021483421326, acc: 0.9722222089767456)
[2024-11-13 10:49:48,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:48,824][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.00538399163633585, acc: 1.0)
[2024-11-13 10:49:48,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:49,496][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.019709842279553413, acc: 1.0)
[2024-11-13 10:49:49,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:50,166][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 0.008485236205160618, acc: 1.0)
[2024-11-13 10:49:50,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:50,847][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.019812270998954773, acc: 1.0)
[2024-11-13 10:49:50,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:51,523][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.0037342573050409555, acc: 1.0)
[2024-11-13 10:49:51,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:52,194][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.19365905225276947, acc: 0.9130434989929199)
[2024-11-13 10:49:52,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:52,870][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.0041174073703587055, acc: 1.0)
[2024-11-13 10:49:52,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:53,542][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.04219100996851921, acc: 0.9629629850387573)
[2024-11-13 10:49:53,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:54,210][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.0139906145632267, acc: 1.0)
[2024-11-13 10:49:54,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:54,884][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.0306282639503479, acc: 1.0)
[2024-11-13 10:49:54,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:55,561][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.213228240609169, acc: 0.9599999785423279)
[2024-11-13 10:49:55,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:56,237][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.024924367666244507, acc: 0.9696969985961914)
[2024-11-13 10:49:56,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:56,908][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.01738700643181801, acc: 1.0)
[2024-11-13 10:49:56,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:57,596][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.01536853238940239, acc: 1.0)
[2024-11-13 10:49:57,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:58,271][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.004660130478441715, acc: 1.0)
[2024-11-13 10:49:58,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:58,949][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.20955029129981995, acc: 0.9487179517745972)
[2024-11-13 10:49:59,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:49:59,635][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 0.13126251101493835, acc: 0.939393937587738)
[2024-11-13 10:49:59,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:00,344][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 0.6046887636184692, acc: 0.8159999847412109)
[2024-11-13 10:50:00,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:01,027][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 0.5233408808708191, acc: 0.8467742204666138)
[2024-11-13 10:50:01,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:01,736][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 0.4802454710006714, acc: 0.8706467747688293)
[2024-11-13 10:50:01,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:02,421][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.17083624005317688, acc: 0.9433962106704712)
[2024-11-13 10:50:02,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:03,105][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.06531917303800583, acc: 0.9772727489471436)
[2024-11-13 10:50:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:03,774][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.0015389720210805535, acc: 1.0)
[2024-11-13 10:50:03,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:04,457][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.014040214940905571, acc: 1.0)
[2024-11-13 10:50:04,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:05,129][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.021537920460104942, acc: 1.0)
[2024-11-13 10:50:05,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:05,805][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.08131103217601776, acc: 0.9701492786407471)
[2024-11-13 10:50:05,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:06,484][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.19685149192810059, acc: 0.9444444179534912)
[2024-11-13 10:50:06,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:07,161][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.02888759784400463, acc: 1.0)
[2024-11-13 10:50:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:07,834][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.08522289246320724, acc: 0.9487179517745972)
[2024-11-13 10:50:07,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:08,516][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.18623118102550507, acc: 0.9210526347160339)
[2024-11-13 10:50:08,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:09,192][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.058176007121801376, acc: 0.9591836929321289)
[2024-11-13 10:50:09,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:09,864][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.0899573415517807, acc: 0.9696969985961914)
[2024-11-13 10:50:09,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:10,561][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 0.26349955797195435, acc: 0.9175257682800293)
[2024-11-13 10:50:10,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:11,240][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.11564912647008896, acc: 0.9714285731315613)
[2024-11-13 10:50:11,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:11,962][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 0.48949113488197327, acc: 0.8604651093482971)
[2024-11-13 10:50:12,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:12,643][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.1526486873626709, acc: 0.9642857313156128)
[2024-11-13 10:50:12,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:13,338][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 0.335989385843277, acc: 0.8641975522041321)
[2024-11-13 10:50:13,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:14,031][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.4033600389957428, acc: 0.8888888955116272)
[2024-11-13 10:50:14,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:14,722][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.04504271224141121, acc: 1.0)
[2024-11-13 10:50:14,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:15,407][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.27477410435676575, acc: 0.8846153616905212)
[2024-11-13 10:50:15,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:16,091][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.05651319399476051, acc: 0.97826087474823)
[2024-11-13 10:50:16,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:16,779][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.32625722885131836, acc: 0.8928571343421936)
[2024-11-13 10:50:16,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:17,460][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.18106453120708466, acc: 0.9277108311653137)
[2024-11-13 10:50:17,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:18,176][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.17729733884334564, acc: 0.954954981803894)
[2024-11-13 10:50:18,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:18,864][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 0.33500051498413086, acc: 0.9223300814628601)
[2024-11-13 10:50:18,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:19,571][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.26565784215927124, acc: 0.9105691313743591)
[2024-11-13 10:50:19,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:20,242][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.10464799404144287, acc: 0.9583333134651184)
[2024-11-13 10:50:20,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:20,914][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.23650678992271423, acc: 0.9642857313156128)
[2024-11-13 10:50:20,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:21,637][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 0.3873988091945648, acc: 0.8921568393707275)
[2024-11-13 10:50:21,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:22,346][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 0.8357946276664734, acc: 0.72052401304245)
[2024-11-13 10:50:22,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:23,030][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 0.33695194125175476, acc: 0.8854166865348816)
[2024-11-13 10:50:23,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:23,720][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 0.2791975736618042, acc: 0.9141104221343994)
[2024-11-13 10:50:23,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:24,405][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 0.20050036907196045, acc: 0.9280575513839722)
[2024-11-13 10:50:24,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:25,112][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 0.628095269203186, acc: 0.8090452551841736)
[2024-11-13 10:50:25,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:25,785][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.12963443994522095, acc: 0.9444444179534912)
[2024-11-13 10:50:25,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:26,462][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.0844215527176857, acc: 0.9696969985961914)
[2024-11-13 10:50:26,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:27,144][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.05604485049843788, acc: 0.9629629850387573)
[2024-11-13 10:50:27,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:27,828][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.7127333283424377, acc: 0.8999999761581421)
[2024-11-13 10:50:27,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:28,500][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.2170780897140503, acc: 0.8999999761581421)
[2024-11-13 10:50:28,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:29,191][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.4414844810962677, acc: 0.8448275923728943)
[2024-11-13 10:50:29,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:29,873][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.02457485720515251, acc: 1.0)
[2024-11-13 10:50:29,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:30,561][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.3465964198112488, acc: 0.9473684430122375)
[2024-11-13 10:50:30,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:31,238][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.20535427331924438, acc: 0.8888888955116272)
[2024-11-13 10:50:31,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:31,913][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.10677415877580643, acc: 0.9523809552192688)
[2024-11-13 10:50:31,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:32,582][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.27349933981895447, acc: 0.9090909361839294)
[2024-11-13 10:50:32,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:33,260][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.41927868127822876, acc: 0.8615384697914124)
[2024-11-13 10:50:33,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:33,933][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.11583687365055084, acc: 0.9666666388511658)
[2024-11-13 10:50:34,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:34,602][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.23835071921348572, acc: 0.931034505367279)
[2024-11-13 10:50:34,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:35,276][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.1079917699098587, acc: 0.9607843160629272)
[2024-11-13 10:50:35,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:35,953][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.0182032510638237, acc: 1.0)
[2024-11-13 10:50:36,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:36,630][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.06594158709049225, acc: 0.9473684430122375)
[2024-11-13 10:50:36,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:37,305][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.13730958104133606, acc: 0.9473684430122375)
[2024-11-13 10:50:37,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:38,007][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 0.3771873116493225, acc: 0.8571428656578064)
[2024-11-13 10:50:38,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:38,691][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 0.2638549506664276, acc: 0.9101123809814453)
[2024-11-13 10:50:38,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:39,378][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 0.6190425157546997, acc: 0.8202247023582458)
[2024-11-13 10:50:39,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:40,078][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 0.8316687345504761, acc: 0.716312050819397)
[2024-11-13 10:50:40,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:40,774][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 0.4165438711643219, acc: 0.8695651888847351)
[2024-11-13 10:50:40,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:41,447][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.004803630989044905, acc: 1.0)
[2024-11-13 10:50:41,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:42,116][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.033980078995227814, acc: 1.0)
[2024-11-13 10:50:42,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:42,791][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.06745433807373047, acc: 0.9629629850387573)
[2024-11-13 10:50:42,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:43,463][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.016319865360856056, acc: 1.0)
[2024-11-13 10:50:43,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:44,135][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.2522958815097809, acc: 0.9622641801834106)
[2024-11-13 10:50:44,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:44,805][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.07141618430614471, acc: 0.9655172228813171)
[2024-11-13 10:50:44,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:45,493][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 0.4443157911300659, acc: 0.8738738894462585)
[2024-11-13 10:50:45,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:46,177][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 0.16097411513328552, acc: 0.9577465057373047)
[2024-11-13 10:50:46,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:46,845][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.25024837255477905, acc: 0.949999988079071)
[2024-11-13 10:50:46,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:47,514][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.2974188029766083, acc: 0.9333333373069763)
[2024-11-13 10:50:47,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:48,190][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.09863996505737305, acc: 0.9230769276618958)
[2024-11-13 10:50:48,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:48,928][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 1.2079321146011353, acc: 0.6857143044471741)
[2024-11-13 10:50:49,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:49,636][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 0.31182199716567993, acc: 0.9285714030265808)
[2024-11-13 10:50:49,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:50,306][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.09503867477178574, acc: 0.9642857313156128)
[2024-11-13 10:50:50,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:50,990][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.027011819183826447, acc: 0.9833333492279053)
[2024-11-13 10:50:51,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:51,677][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.3581821322441101, acc: 0.8611111044883728)
[2024-11-13 10:50:51,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:52,352][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.0010055453749373555, acc: 1.0)
[2024-11-13 10:50:52,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:53,022][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.0370325893163681, acc: 1.0)
[2024-11-13 10:50:53,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:53,686][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.014683617278933525, acc: 1.0)
[2024-11-13 10:50:53,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:54,356][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.023030607029795647, acc: 1.0)
[2024-11-13 10:50:54,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:55,259][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 1.0508910417556763, acc: 0.6779661178588867)
[2024-11-13 10:50:55,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:55,964][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 0.25054898858070374, acc: 0.9179104566574097)
[2024-11-13 10:50:56,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:56,650][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 0.2698986828327179, acc: 0.9270073175430298)
[2024-11-13 10:50:56,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:57,371][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 0.5186799168586731, acc: 0.8650000095367432)
[2024-11-13 10:50:57,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:58,052][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.03398427739739418, acc: 0.9814814925193787)
[2024-11-13 10:50:58,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:58,732][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.07009286433458328, acc: 0.9807692170143127)
[2024-11-13 10:50:58,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:50:59,401][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.022521015256643295, acc: 1.0)
[2024-11-13 10:50:59,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:00,087][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 0.3780539631843567, acc: 0.8524590134620667)
[2024-11-13 10:51:00,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:00,766][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.06203645095229149, acc: 1.0)
[2024-11-13 10:51:00,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:01,446][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 0.15738007426261902, acc: 0.9534883499145508)
[2024-11-13 10:51:01,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:02,128][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.26293790340423584, acc: 0.9318181872367859)
[2024-11-13 10:51:02,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:02,810][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.22518356144428253, acc: 0.9056603908538818)
[2024-11-13 10:51:02,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:03,488][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.22496093809604645, acc: 0.9318181872367859)
[2024-11-13 10:51:03,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:04,164][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.28002846240997314, acc: 0.8799999952316284)
[2024-11-13 10:51:04,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:04,836][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.008937036618590355, acc: 1.0)
[2024-11-13 10:51:04,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:05,508][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.004234223160892725, acc: 1.0)
[2024-11-13 10:51:05,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:06,190][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.15857602655887604, acc: 0.9692307710647583)
[2024-11-13 10:51:06,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:06,870][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.13758602738380432, acc: 0.953125)
[2024-11-13 10:51:06,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:07,543][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.026523927226662636, acc: 1.0)
[2024-11-13 10:51:07,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:08,216][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.21480362117290497, acc: 0.939393937587738)
[2024-11-13 10:51:08,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:08,888][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.005222043488174677, acc: 1.0)
[2024-11-13 10:51:08,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:09,567][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.014950813725590706, acc: 1.0)
[2024-11-13 10:51:09,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:10,241][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.003016181057319045, acc: 1.0)
[2024-11-13 10:51:10,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:10,914][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.17848308384418488, acc: 0.9666666388511658)
[2024-11-13 10:51:10,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:11,597][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.038575030863285065, acc: 1.0)
[2024-11-13 10:51:11,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:12,277][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.14867694675922394, acc: 0.9428571462631226)
[2024-11-13 10:51:12,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:12,952][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.06779263913631439, acc: 0.9473684430122375)
[2024-11-13 10:51:13,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:13,626][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.023226499557495117, acc: 1.0)
[2024-11-13 10:51:13,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:14,297][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.005918866489082575, acc: 1.0)
[2024-11-13 10:51:14,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:14,973][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.013391420245170593, acc: 1.0)
[2024-11-13 10:51:15,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:15,660][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.11106269061565399, acc: 0.9750000238418579)
[2024-11-13 10:51:15,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:16,347][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.17740371823310852, acc: 0.9428571462631226)
[2024-11-13 10:51:16,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:17,062][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 0.23683637380599976, acc: 0.9197080135345459)
[2024-11-13 10:51:17,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:17,767][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 0.11162318289279938, acc: 0.9448275566101074)
[2024-11-13 10:51:17,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:18,463][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 0.46343284845352173, acc: 0.8714285492897034)
[2024-11-13 10:51:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:19,151][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 0.25610870122909546, acc: 0.9139072895050049)
[2024-11-13 10:51:19,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:19,836][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.08620823174715042, acc: 0.9743589758872986)
[2024-11-13 10:51:20,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:21,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:21,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:22,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:23,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:23,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:24,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:24,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:26,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:26,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:27,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:28,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:28,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:29,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:29,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:30,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:31,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:32,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:32,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:33,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:34,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:35,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:35,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:36,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:37,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:37,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:38,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:38,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:39,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:40,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:40,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:41,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:42,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:42,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:43,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:43,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:44,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:45,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:45,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:46,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:47,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:47,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:48,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:48,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:49,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:50,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:50,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:51,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:51,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:52,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:52,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:53,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:54,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:54,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:55,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:55,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:56,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:57,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:57,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:58,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:58,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:59,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:51:59,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:00,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:01,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:01,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:02,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:03,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:03,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:04,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:04,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:05,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:06,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:06,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:07,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:08,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:08,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:09,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:09,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:10,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:10,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:11,862][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2560, device='cuda:0') eval_epoch_loss=tensor(0.8136, device='cuda:0') eval_epoch_acc=tensor(0.8133, device='cuda:0')
[2024-11-13 10:52:11,863][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:52:11,863][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:52:12,214][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_8_step_558_loss_0.813589870929718/model.pt
[2024-11-13 10:52:12,217][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:52:12,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:12,909][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.07498045265674591, acc: 0.9599999785423279)
[2024-11-13 10:52:12,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:13,576][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.00940790493041277, acc: 1.0)
[2024-11-13 10:52:13,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:14,249][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.03849250078201294, acc: 1.0)
[2024-11-13 10:52:14,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:14,927][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.2708808481693268, acc: 0.9487179517745972)
[2024-11-13 10:52:15,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:15,629][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.19776298105716705, acc: 0.9666666388511658)
[2024-11-13 10:52:15,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:16,308][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.15478120744228363, acc: 0.948051929473877)
[2024-11-13 10:52:16,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:16,982][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.3096899092197418, acc: 0.9166666865348816)
[2024-11-13 10:52:17,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:17,674][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.1940174251794815, acc: 0.9137930870056152)
[2024-11-13 10:52:17,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:18,366][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 0.14897173643112183, acc: 0.9285714030265808)
[2024-11-13 10:52:18,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:19,039][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.2173861265182495, acc: 0.9736841917037964)
[2024-11-13 10:52:19,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:19,709][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.19476652145385742, acc: 0.9629629850387573)
[2024-11-13 10:52:19,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:20,432][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 0.28068792819976807, acc: 0.9144384860992432)
[2024-11-13 10:52:20,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:21,113][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.01687191240489483, acc: 1.0)
[2024-11-13 10:52:21,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:21,815][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.13925139605998993, acc: 0.94017094373703)
[2024-11-13 10:52:21,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:22,526][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 0.458096444606781, acc: 0.8673469424247742)
[2024-11-13 10:52:22,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:23,235][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 0.28809744119644165, acc: 0.8993710875511169)
[2024-11-13 10:52:23,746][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=1.2577, train_epoch_loss=0.2293, epoch time 608.1868329476565s
[2024-11-13 10:52:23,746][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 10:52:23,746][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 10:52:23,747][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 10:52:23,747][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 2
[2024-11-13 10:52:23,747][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 10:52:24,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:25,077][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.010677246376872063, acc: 1.0)
[2024-11-13 10:52:25,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:25,762][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.03791618347167969, acc: 1.0)
[2024-11-13 10:52:25,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:26,456][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.3467676639556885, acc: 0.9189189076423645)
[2024-11-13 10:52:26,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:27,158][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.029259635135531425, acc: 1.0)
[2024-11-13 10:52:27,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:27,847][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.08931033313274384, acc: 0.9729729890823364)
[2024-11-13 10:52:27,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:28,535][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.17284449934959412, acc: 0.9285714030265808)
[2024-11-13 10:52:28,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:29,228][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.14620697498321533, acc: 0.9387755393981934)
[2024-11-13 10:52:29,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:29,913][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.04365810006856918, acc: 1.0)
[2024-11-13 10:52:29,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:30,595][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.028658496215939522, acc: 1.0)
[2024-11-13 10:52:30,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:31,274][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.003855746705085039, acc: 1.0)
[2024-11-13 10:52:31,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:31,963][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.042325228452682495, acc: 0.9629629850387573)
[2024-11-13 10:52:32,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:32,652][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.2836650311946869, acc: 0.9487179517745972)
[2024-11-13 10:52:32,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:33,336][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.026161402463912964, acc: 1.0)
[2024-11-13 10:52:33,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:34,023][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.04313594102859497, acc: 1.0)
[2024-11-13 10:52:34,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:34,714][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.12284628301858902, acc: 0.9607843160629272)
[2024-11-13 10:52:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:35,407][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.050211384892463684, acc: 1.0)
[2024-11-13 10:52:35,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:36,095][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.04900712892413139, acc: 1.0)
[2024-11-13 10:52:36,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:36,785][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.0299344751983881, acc: 1.0)
[2024-11-13 10:52:36,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:37,480][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.08462253212928772, acc: 0.9722222089767456)
[2024-11-13 10:52:37,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:38,170][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.016617054119706154, acc: 1.0)
[2024-11-13 10:52:38,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:38,860][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.044021546840667725, acc: 1.0)
[2024-11-13 10:52:38,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:39,554][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.40291106700897217, acc: 0.8620689511299133)
[2024-11-13 10:52:39,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:40,244][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.09150931239128113, acc: 1.0)
[2024-11-13 10:52:40,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:40,935][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.016323711723089218, acc: 1.0)
[2024-11-13 10:52:41,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:41,624][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.10028240829706192, acc: 0.9375)
[2024-11-13 10:52:41,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:42,318][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.2596684694290161, acc: 0.9433962106704712)
[2024-11-13 10:52:42,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:43,009][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.2361997365951538, acc: 0.9452054500579834)
[2024-11-13 10:52:43,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:43,811][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 0.8485718965530396, acc: 0.7588932514190674)
[2024-11-13 10:52:43,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:44,494][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.16721855103969574, acc: 0.9767441749572754)
[2024-11-13 10:52:44,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:45,196][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.2117312103509903, acc: 0.9397590160369873)
[2024-11-13 10:52:45,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:45,902][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.2656618654727936, acc: 0.8888888955116272)
[2024-11-13 10:52:46,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:46,593][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.371751993894577, acc: 0.9285714030265808)
[2024-11-13 10:52:46,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:47,277][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.36036840081214905, acc: 0.9259259104728699)
[2024-11-13 10:52:47,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:47,961][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.12493938207626343, acc: 0.95652174949646)
[2024-11-13 10:52:48,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:48,663][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 0.2059311419725418, acc: 0.924369752407074)
[2024-11-13 10:52:48,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:49,363][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.23065905272960663, acc: 0.9344262480735779)
[2024-11-13 10:52:49,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:50,061][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.15156683325767517, acc: 0.9682539701461792)
[2024-11-13 10:52:50,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:50,745][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.117782361805439, acc: 0.9661017060279846)
[2024-11-13 10:52:50,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:51,456][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.22484341263771057, acc: 0.954023003578186)
[2024-11-13 10:52:51,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:52,146][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.004923680797219276, acc: 1.0)
[2024-11-13 10:52:52,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:52,835][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.018050188198685646, acc: 1.0)
[2024-11-13 10:52:52,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:53,542][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 0.0676211267709732, acc: 1.0)
[2024-11-13 10:52:53,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:54,233][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.14843535423278809, acc: 0.9538461565971375)
[2024-11-13 10:52:54,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:54,931][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 0.36747726798057556, acc: 0.9292929172515869)
[2024-11-13 10:52:55,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:55,640][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 0.14404620230197906, acc: 0.9278350472450256)
[2024-11-13 10:52:55,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:56,350][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 0.1951245367527008, acc: 0.9411764740943909)
[2024-11-13 10:52:56,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:57,031][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.0661233514547348, acc: 0.9615384340286255)
[2024-11-13 10:52:57,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:57,715][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.021101661026477814, acc: 1.0)
[2024-11-13 10:52:57,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:58,397][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.08278422802686691, acc: 0.9642857313156128)
[2024-11-13 10:52:58,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:59,090][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.13082727789878845, acc: 0.9444444179534912)
[2024-11-13 10:52:59,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:52:59,782][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.1963725984096527, acc: 0.9649122953414917)
[2024-11-13 10:52:59,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:00,484][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.2264636754989624, acc: 0.9365079402923584)
[2024-11-13 10:53:00,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:01,190][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.31510210037231445, acc: 0.8873239159584045)
[2024-11-13 10:53:01,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:01,919][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 0.6874505281448364, acc: 0.8133333325386047)
[2024-11-13 10:53:02,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:02,609][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.11526646465063095, acc: 0.9729729890823364)
[2024-11-13 10:53:02,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:03,294][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.01612614467740059, acc: 1.0)
[2024-11-13 10:53:03,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:04,141][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.1550734043121338, acc: 0.6689419746398926)
[2024-11-13 10:53:04,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:04,925][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 1.2435472011566162, acc: 0.6383442282676697)
[2024-11-13 10:53:05,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:05,650][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 0.39107179641723633, acc: 0.8522727489471436)
[2024-11-13 10:53:05,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:06,351][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 0.3090941905975342, acc: 0.8897058963775635)
[2024-11-13 10:53:06,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:07,070][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 0.4007108807563782, acc: 0.8405796885490417)
[2024-11-13 10:53:07,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:07,787][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 0.25076478719711304, acc: 0.925000011920929)
[2024-11-13 10:53:07,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:08,475][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.2787029445171356, acc: 0.8823529481887817)
[2024-11-13 10:53:08,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:09,172][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.051439087837934494, acc: 0.9722222089767456)
[2024-11-13 10:53:09,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:09,869][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.048925600945949554, acc: 0.984375)
[2024-11-13 10:53:09,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:10,552][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.021009139716625214, acc: 1.0)
[2024-11-13 10:53:10,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:11,249][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.13710950314998627, acc: 0.9642857313156128)
[2024-11-13 10:53:11,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:11,951][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.08031925559043884, acc: 0.9666666388511658)
[2024-11-13 10:53:12,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:12,639][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.016311924904584885, acc: 1.0)
[2024-11-13 10:53:12,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:13,336][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.2334471046924591, acc: 0.8888888955116272)
[2024-11-13 10:53:13,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:14,021][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.1728847622871399, acc: 0.9090909361839294)
[2024-11-13 10:53:14,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:14,736][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 0.4110172390937805, acc: 0.8382353186607361)
[2024-11-13 10:53:14,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:15,431][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 0.38515034317970276, acc: 0.9126983880996704)
[2024-11-13 10:53:15,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:16,154][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 0.7948312759399414, acc: 0.7692307829856873)
[2024-11-13 10:53:16,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:16,845][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 0.5091899037361145, acc: 0.8163265585899353)
[2024-11-13 10:53:16,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:17,541][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 0.5527701377868652, acc: 0.8283582329750061)
[2024-11-13 10:53:17,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:18,279][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 1.1170382499694824, acc: 0.6970803141593933)
[2024-11-13 10:53:18,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:18,969][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.003289138665422797, acc: 1.0)
[2024-11-13 10:53:19,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:19,655][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.01428184937685728, acc: 1.0)
[2024-11-13 10:53:19,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:20,337][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.08326932042837143, acc: 0.9696969985961914)
[2024-11-13 10:53:20,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:21,019][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.030952125787734985, acc: 1.0)
[2024-11-13 10:53:21,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:21,710][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.191671222448349, acc: 0.9230769276618958)
[2024-11-13 10:53:21,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:22,400][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.13025687634944916, acc: 0.9615384340286255)
[2024-11-13 10:53:22,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:23,087][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.05525631830096245, acc: 0.96875)
[2024-11-13 10:53:23,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:23,782][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.11591115593910217, acc: 0.9710144996643066)
[2024-11-13 10:53:23,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:24,474][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.07720238715410233, acc: 0.9800000190734863)
[2024-11-13 10:53:24,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:25,157][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.05619774013757706, acc: 1.0)
[2024-11-13 10:53:25,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:25,854][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.31944653391838074, acc: 0.9200000166893005)
[2024-11-13 10:53:25,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:26,549][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.21924935281276703, acc: 0.9320388436317444)
[2024-11-13 10:53:26,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:27,271][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 0.5018124580383301, acc: 0.8640776872634888)
[2024-11-13 10:53:27,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:27,994][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 0.8282884359359741, acc: 0.7688171863555908)
[2024-11-13 10:53:28,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:28,729][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 0.6670991778373718, acc: 0.8275862336158752)
[2024-11-13 10:53:28,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:29,428][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.30611711740493774, acc: 0.8736842274665833)
[2024-11-13 10:53:29,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:30,155][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 0.41050708293914795, acc: 0.8613861203193665)
[2024-11-13 10:53:30,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:30,850][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.2161073386669159, acc: 0.9032257795333862)
[2024-11-13 10:53:30,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:31,542][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.2083469033241272, acc: 0.95652174949646)
[2024-11-13 10:53:31,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:32,242][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 0.4401830732822418, acc: 0.8655462265014648)
[2024-11-13 10:53:32,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:32,943][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 0.3778209090232849, acc: 0.9134615659713745)
[2024-11-13 10:53:33,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:33,659][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 0.4979318082332611, acc: 0.8540145754814148)
[2024-11-13 10:53:33,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:34,351][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.41486749053001404, acc: 0.8507462739944458)
[2024-11-13 10:53:34,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:35,034][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.0021297642961144447, acc: 1.0)
[2024-11-13 10:53:35,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:35,715][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.029013102874159813, acc: 1.0)
[2024-11-13 10:53:35,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:36,395][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.0025570830330252647, acc: 1.0)
[2024-11-13 10:53:36,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:37,080][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.006700012367218733, acc: 1.0)
[2024-11-13 10:53:37,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:37,772][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.10422630608081818, acc: 0.982758641242981)
[2024-11-13 10:53:37,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:38,464][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.0074263568967580795, acc: 1.0)
[2024-11-13 10:53:38,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:39,151][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.01766628585755825, acc: 1.0)
[2024-11-13 10:53:39,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:39,831][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.001521897385828197, acc: 1.0)
[2024-11-13 10:53:39,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:40,520][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.004991018213331699, acc: 1.0)
[2024-11-13 10:53:40,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:41,205][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.02822318859398365, acc: 1.0)
[2024-11-13 10:53:41,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:41,899][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.13860169053077698, acc: 0.9230769276618958)
[2024-11-13 10:53:41,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:42,595][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.07160229235887527, acc: 0.9824561476707458)
[2024-11-13 10:53:42,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:43,282][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.15254442393779755, acc: 0.9824561476707458)
[2024-11-13 10:53:43,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:43,966][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.01931695081293583, acc: 1.0)
[2024-11-13 10:53:44,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:44,654][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.10249502956867218, acc: 0.9387755393981934)
[2024-11-13 10:53:44,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:45,339][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.017802132293581963, acc: 1.0)
[2024-11-13 10:53:45,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:46,038][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 0.23042552173137665, acc: 0.920634925365448)
[2024-11-13 10:53:46,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:46,742][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 0.2422301173210144, acc: 0.9186992049217224)
[2024-11-13 10:53:46,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:47,441][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.16720058023929596, acc: 0.9354838728904724)
[2024-11-13 10:53:47,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:48,207][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 0.4786752462387085, acc: 0.8441064357757568)
[2024-11-13 10:53:48,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:48,903][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.0728297308087349, acc: 0.9733333587646484)
[2024-11-13 10:53:48,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:49,607][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.12158795446157455, acc: 0.9615384340286255)
[2024-11-13 10:53:49,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:50,301][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.09147614985704422, acc: 0.9583333134651184)
[2024-11-13 10:53:50,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:50,982][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.008779582567512989, acc: 1.0)
[2024-11-13 10:53:51,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:51,694][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 0.3887397348880768, acc: 0.9018405079841614)
[2024-11-13 10:53:51,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:52,415][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 0.44230595231056213, acc: 0.8819444179534912)
[2024-11-13 10:53:52,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:53,112][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 0.6099252700805664, acc: 0.8083333373069763)
[2024-11-13 10:53:54,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:54,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:55,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:55,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:56,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:57,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:57,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:58,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:58,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:53:59,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:00,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:00,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:01,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:01,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:02,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:03,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:03,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:04,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:04,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:05,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:06,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:06,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:07,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:08,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:09,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:09,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:11,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:11,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:12,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:12,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:13,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:14,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:14,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:15,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:15,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:16,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:16,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:18,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:18,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:19,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:19,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:20,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:21,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:21,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:22,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:22,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:23,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:24,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:24,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:25,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:25,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:26,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:26,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:27,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:28,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:28,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:29,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:29,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:30,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:31,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:31,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:32,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:32,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:33,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:33,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:34,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:35,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:35,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:36,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:36,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:37,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:38,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:38,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:39,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:39,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:40,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:41,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:42,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:42,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:43,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:44,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:45,044][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2692, device='cuda:0') eval_epoch_loss=tensor(0.8194, device='cuda:0') eval_epoch_acc=tensor(0.8260, device='cuda:0')
[2024-11-13 10:54:45,045][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:54:45,045][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:54:45,447][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_127_loss_0.8194413185119629/model.pt
[2024-11-13 10:54:45,453][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:54:45,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:46,187][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 0.28864285349845886, acc: 0.9226190447807312)
[2024-11-13 10:54:46,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:46,889][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 0.43329909443855286, acc: 0.8820512890815735)
[2024-11-13 10:54:46,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:47,618][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 0.574653148651123, acc: 0.8382353186607361)
[2024-11-13 10:54:47,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:48,289][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.23222024738788605, acc: 0.8846153616905212)
[2024-11-13 10:54:48,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:48,956][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.036700375378131866, acc: 1.0)
[2024-11-13 10:54:49,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:49,638][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.13976317644119263, acc: 0.96875)
[2024-11-13 10:54:49,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:50,306][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.041444454342126846, acc: 0.95652174949646)
[2024-11-13 10:54:50,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:50,980][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.35077694058418274, acc: 0.9428571462631226)
[2024-11-13 10:54:51,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:51,650][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.047259874641895294, acc: 1.0)
[2024-11-13 10:54:51,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:52,322][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.15724536776542664, acc: 0.9523809552192688)
[2024-11-13 10:54:52,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:52,996][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.2959362864494324, acc: 0.8999999761581421)
[2024-11-13 10:54:53,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:53,667][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.13622476160526276, acc: 0.95652174949646)
[2024-11-13 10:54:53,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:54,342][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.11149188131093979, acc: 0.9523809552192688)
[2024-11-13 10:54:54,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:55,020][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.4021901488304138, acc: 0.7692307829856873)
[2024-11-13 10:54:55,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:55,700][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.17926441133022308, acc: 0.9677419066429138)
[2024-11-13 10:54:55,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:56,373][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.39417552947998047, acc: 0.9459459185600281)
[2024-11-13 10:54:56,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:57,079][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 0.4377534091472626, acc: 0.8771929740905762)
[2024-11-13 10:54:57,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:57,764][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 0.4327912926673889, acc: 0.8507462739944458)
[2024-11-13 10:54:57,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:58,460][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 0.19098477065563202, acc: 0.9489796161651611)
[2024-11-13 10:54:58,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:59,178][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 0.30407044291496277, acc: 0.8723404407501221)
[2024-11-13 10:54:59,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:54:59,860][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.35499775409698486, acc: 0.9285714030265808)
[2024-11-13 10:54:59,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:00,540][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.09349168092012405, acc: 0.9642857313156128)
[2024-11-13 10:55:00,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:01,212][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.21078360080718994, acc: 0.9130434989929199)
[2024-11-13 10:55:01,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:01,883][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.1698099672794342, acc: 0.8965517282485962)
[2024-11-13 10:55:01,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:02,566][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.44267889857292175, acc: 0.8695651888847351)
[2024-11-13 10:55:02,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:03,250][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 0.33636632561683655, acc: 0.8983050584793091)
[2024-11-13 10:55:03,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:03,928][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.27908310294151306, acc: 0.9122806787490845)
[2024-11-13 10:55:04,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:04,609][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.3195665180683136, acc: 0.9054054021835327)
[2024-11-13 10:55:04,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:05,282][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.12670187652111053, acc: 0.9642857313156128)
[2024-11-13 10:55:05,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:05,958][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.526911199092865, acc: 0.95652174949646)
[2024-11-13 10:55:06,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:06,630][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.09062105417251587, acc: 1.0)
[2024-11-13 10:55:06,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:07,309][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.36437204480171204, acc: 0.8918918967247009)
[2024-11-13 10:55:07,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:07,994][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 0.4676799178123474, acc: 0.8888888955116272)
[2024-11-13 10:55:08,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:08,676][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 0.15849699079990387, acc: 0.9651162624359131)
[2024-11-13 10:55:08,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:09,359][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.18381044268608093, acc: 0.9529411792755127)
[2024-11-13 10:55:09,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:10,043][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 0.385769248008728, acc: 0.898876428604126)
[2024-11-13 10:55:10,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:10,720][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.10184679180383682, acc: 0.9772727489471436)
[2024-11-13 10:55:10,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:11,398][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.0572480708360672, acc: 1.0)
[2024-11-13 10:55:11,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:12,069][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.014672333374619484, acc: 1.0)
[2024-11-13 10:55:12,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:12,747][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.02814129739999771, acc: 1.0)
[2024-11-13 10:55:12,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:13,429][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.08916470408439636, acc: 0.9599999785423279)
[2024-11-13 10:55:13,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:14,111][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.532192587852478, acc: 0.8472222089767456)
[2024-11-13 10:55:14,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:14,797][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 0.46144914627075195, acc: 0.8333333134651184)
[2024-11-13 10:55:14,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:15,522][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 1.1390562057495117, acc: 0.6506849527359009)
[2024-11-13 10:55:15,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:16,194][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.042838212102651596, acc: 1.0)
[2024-11-13 10:55:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:16,865][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.14525221288204193, acc: 0.9629629850387573)
[2024-11-13 10:55:16,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:17,548][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.23228272795677185, acc: 0.9642857313156128)
[2024-11-13 10:55:17,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:18,252][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 0.29807358980178833, acc: 0.8584070801734924)
[2024-11-13 10:55:18,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:18,935][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.2144429087638855, acc: 0.9420289993286133)
[2024-11-13 10:55:19,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:19,617][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 0.10435405373573303, acc: 0.9772727489471436)
[2024-11-13 10:55:19,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:20,336][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 0.6813110113143921, acc: 0.7938931584358215)
[2024-11-13 10:55:20,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:21,041][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 0.30543750524520874, acc: 0.9037036895751953)
[2024-11-13 10:55:21,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:21,726][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.0419001504778862, acc: 1.0)
[2024-11-13 10:55:21,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:22,401][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.029343822970986366, acc: 1.0)
[2024-11-13 10:55:22,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:23,083][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.018233072012662888, acc: 1.0)
[2024-11-13 10:55:23,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:23,758][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.13772521913051605, acc: 0.9642857313156128)
[2024-11-13 10:55:23,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:24,444][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 0.12451919913291931, acc: 0.9634146094322205)
[2024-11-13 10:55:24,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:25,172][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 0.3857983946800232, acc: 0.8791540861129761)
[2024-11-13 10:55:25,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:25,904][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 0.44934186339378357, acc: 0.8645533323287964)
[2024-11-13 10:55:25,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:26,636][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 0.3582330346107483, acc: 0.8656250238418579)
[2024-11-13 10:55:26,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:27,409][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 0.7266603708267212, acc: 0.797373354434967)
[2024-11-13 10:55:27,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:28,154][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 0.4023933708667755, acc: 0.8505337834358215)
[2024-11-13 10:55:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:28,828][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.034328751266002655, acc: 1.0)
[2024-11-13 10:55:28,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:29,511][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 0.35715746879577637, acc: 0.8837209343910217)
[2024-11-13 10:55:29,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:30,197][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 0.46480369567871094, acc: 0.8650793433189392)
[2024-11-13 10:55:30,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:30,887][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 0.48712632060050964, acc: 0.8030303120613098)
[2024-11-13 10:55:30,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:31,576][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 0.19458694756031036, acc: 0.929411768913269)
[2024-11-13 10:55:31,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:32,293][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 0.5229539275169373, acc: 0.8271604776382446)
[2024-11-13 10:55:32,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:32,981][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.20649568736553192, acc: 0.9516128897666931)
[2024-11-13 10:55:33,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:33,652][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.03072957694530487, acc: 1.0)
[2024-11-13 10:55:33,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:34,324][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.11530883610248566, acc: 0.9750000238418579)
[2024-11-13 10:55:34,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:35,007][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.27743303775787354, acc: 0.9411764740943909)
[2024-11-13 10:55:35,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:35,694][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 0.26460471749305725, acc: 0.9191176295280457)
[2024-11-13 10:55:35,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:36,381][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 0.36614343523979187, acc: 0.8728813529014587)
[2024-11-13 10:55:36,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:37,079][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 0.30151990056037903, acc: 0.9104477763175964)
[2024-11-13 10:55:37,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:37,767][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 0.2553056478500366, acc: 0.9223300814628601)
[2024-11-13 10:55:37,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:38,452][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.21442462503910065, acc: 0.9365079402923584)
[2024-11-13 10:55:38,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:39,142][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.03705469146370888, acc: 0.9890109896659851)
[2024-11-13 10:55:39,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:39,861][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 0.28330013155937195, acc: 0.9058296084403992)
[2024-11-13 10:55:39,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:40,594][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 0.35168546438217163, acc: 0.8976377844810486)
[2024-11-13 10:55:40,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:41,304][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 0.17003366351127625, acc: 0.9353448152542114)
[2024-11-13 10:55:41,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:42,017][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 0.3199319839477539, acc: 0.9094203114509583)
[2024-11-13 10:55:42,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:42,750][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 0.19931967556476593, acc: 0.929961085319519)
[2024-11-13 10:55:42,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:43,461][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 0.3768860697746277, acc: 0.9239130616188049)
[2024-11-13 10:55:43,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:44,132][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.003323575481772423, acc: 1.0)
[2024-11-13 10:55:44,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:44,804][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.08848442137241364, acc: 0.9642857313156128)
[2024-11-13 10:55:44,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:45,484][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.009750417433679104, acc: 1.0)
[2024-11-13 10:55:45,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:46,202][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 0.17474520206451416, acc: 0.9307692050933838)
[2024-11-13 10:55:46,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:46,882][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.0265260748565197, acc: 0.9864864945411682)
[2024-11-13 10:55:46,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:47,577][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.06271235644817352, acc: 0.9651162624359131)
[2024-11-13 10:55:47,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:48,265][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 0.04803368076682091, acc: 0.9819819927215576)
[2024-11-13 10:55:48,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:48,955][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.06646622717380524, acc: 0.9777777791023254)
[2024-11-13 10:55:49,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:49,630][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.015268965624272823, acc: 1.0)
[2024-11-13 10:55:49,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:50,303][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.013603029772639275, acc: 1.0)
[2024-11-13 10:55:50,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:50,974][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.005324077792465687, acc: 1.0)
[2024-11-13 10:55:51,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:51,655][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.3773534595966339, acc: 0.9230769276618958)
[2024-11-13 10:55:51,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:52,367][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 0.3454021215438843, acc: 0.885869562625885)
[2024-11-13 10:55:52,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:53,072][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 0.2764842212200165, acc: 0.8977272510528564)
[2024-11-13 10:55:53,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:53,778][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 0.1993372142314911, acc: 0.957446813583374)
[2024-11-13 10:55:53,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:54,455][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.2122506946325302, acc: 0.9245283007621765)
[2024-11-13 10:55:54,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:55,138][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.17467743158340454, acc: 0.9666666388511658)
[2024-11-13 10:55:55,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:55,821][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.06622612476348877, acc: 0.9767441749572754)
[2024-11-13 10:55:55,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:56,500][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.028354616835713387, acc: 1.0)
[2024-11-13 10:55:56,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:57,189][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 0.5123459100723267, acc: 0.8105263113975525)
[2024-11-13 10:55:57,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:57,873][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 0.2491408735513687, acc: 0.8999999761581421)
[2024-11-13 10:55:57,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:58,584][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 0.3465005159378052, acc: 0.8888888955116272)
[2024-11-13 10:55:58,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:55:59,297][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 0.9324988722801208, acc: 0.7568807601928711)
[2024-11-13 10:55:59,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:00,006][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 0.3847425878047943, acc: 0.8461538553237915)
[2024-11-13 10:56:00,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:00,681][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.035475119948387146, acc: 1.0)
[2024-11-13 10:56:00,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:01,361][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.1816999316215515, acc: 0.9166666865348816)
[2024-11-13 10:56:01,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:02,035][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.05715494975447655, acc: 1.0)
[2024-11-13 10:56:02,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:02,708][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.04688398167490959, acc: 1.0)
[2024-11-13 10:56:02,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:03,382][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.2535201907157898, acc: 0.9142857193946838)
[2024-11-13 10:56:03,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:04,058][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.014191948808729649, acc: 1.0)
[2024-11-13 10:56:04,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:04,734][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.03609761223196983, acc: 1.0)
[2024-11-13 10:56:04,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:05,413][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.31930622458457947, acc: 0.8548387289047241)
[2024-11-13 10:56:05,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:06,090][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.18341851234436035, acc: 0.9090909361839294)
[2024-11-13 10:56:06,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:06,760][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.0009016215335577726, acc: 1.0)
[2024-11-13 10:56:06,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:07,433][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.011744274757802486, acc: 1.0)
[2024-11-13 10:56:07,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:08,104][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.008361725136637688, acc: 1.0)
[2024-11-13 10:56:08,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:08,773][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.016427401453256607, acc: 1.0)
[2024-11-13 10:56:08,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:09,451][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.040234897285699844, acc: 0.9729729890823364)
[2024-11-13 10:56:09,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:10,125][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.07004204392433167, acc: 0.9729729890823364)
[2024-11-13 10:56:10,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:10,799][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.005894512869417667, acc: 1.0)
[2024-11-13 10:56:10,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:11,486][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.3089210093021393, acc: 0.9411764740943909)
[2024-11-13 10:56:11,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:12,165][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.16037270426750183, acc: 0.9756097793579102)
[2024-11-13 10:56:12,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:12,839][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.0118185393512249, acc: 1.0)
[2024-11-13 10:56:12,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:13,512][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.03643019124865532, acc: 0.9599999785423279)
[2024-11-13 10:56:13,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:14,186][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.10616146773099899, acc: 0.9677419066429138)
[2024-11-13 10:56:14,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:14,865][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.07901561260223389, acc: 0.9824561476707458)
[2024-11-13 10:56:14,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:15,547][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.08959787338972092, acc: 0.9714285731315613)
[2024-11-13 10:56:15,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:16,232][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.06943141669034958, acc: 0.9868420958518982)
[2024-11-13 10:56:16,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:16,937][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 0.3392997682094574, acc: 0.8867924809455872)
[2024-11-13 10:56:17,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:17,656][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 0.2131999284029007, acc: 0.9416666626930237)
[2024-11-13 10:56:17,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:18,335][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.2992140054702759, acc: 0.8611111044883728)
[2024-11-13 10:56:18,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:19,015][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.39758095145225525, acc: 0.8709677457809448)
[2024-11-13 10:56:19,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:19,710][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 0.3112872540950775, acc: 0.8933333158493042)
[2024-11-13 10:56:19,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:20,385][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.4154808521270752, acc: 0.9583333134651184)
[2024-11-13 10:56:20,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:21,099][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 0.6611571311950684, acc: 0.8080000281333923)
[2024-11-13 10:56:21,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:21,783][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 0.5386875867843628, acc: 0.8764045238494873)
[2024-11-13 10:56:21,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:22,478][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.24512605369091034, acc: 0.9189189076423645)
[2024-11-13 10:56:22,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:23,181][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.28849032521247864, acc: 0.8965517282485962)
[2024-11-13 10:56:23,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:23,859][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.0026392959989607334, acc: 1.0)
[2024-11-13 10:56:24,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:25,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:25,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:26,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:27,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:28,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:28,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:29,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:29,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:30,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:31,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:31,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:32,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:32,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:33,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:34,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:34,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:35,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:35,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:36,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:37,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:37,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:38,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:38,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:39,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:39,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:40,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:41,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:41,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:43,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:43,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:44,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:45,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:46,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:46,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:47,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:47,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:48,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:49,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:49,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:50,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:51,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:51,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:52,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:52,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:53,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:53,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:54,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:55,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:55,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:56,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:57,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:57,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:58,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:58,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:56:59,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:00,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:00,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:01,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:01,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:02,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:03,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:03,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:04,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:04,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:05,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:06,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:06,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:07,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:07,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:08,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:09,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:09,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:10,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:11,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:11,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:12,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:12,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:13,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:13,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:14,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:15,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:16,212][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1926, device='cuda:0') eval_epoch_loss=tensor(0.7851, device='cuda:0') eval_epoch_acc=tensor(0.8174, device='cuda:0')
[2024-11-13 10:57:16,213][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:57:16,213][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:57:16,799][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_270_loss_0.7850853800773621/model.pt
[2024-11-13 10:57:16,803][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:57:16,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:17,492][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.290827214717865, acc: 0.9545454382896423)
[2024-11-13 10:57:17,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:18,169][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.07187337428331375, acc: 1.0)
[2024-11-13 10:57:18,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:18,845][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.026768218725919724, acc: 1.0)
[2024-11-13 10:57:18,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:19,523][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.2388535439968109, acc: 0.9333333373069763)
[2024-11-13 10:57:19,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:20,197][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.10507042706012726, acc: 0.96875)
[2024-11-13 10:57:20,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:20,875][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.023014871403574944, acc: 1.0)
[2024-11-13 10:57:20,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:21,553][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.05906257405877113, acc: 0.9655172228813171)
[2024-11-13 10:57:21,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:22,224][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.030301887542009354, acc: 1.0)
[2024-11-13 10:57:22,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:22,901][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.10587490350008011, acc: 0.957446813583374)
[2024-11-13 10:57:22,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:23,591][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.16411752998828888, acc: 0.9375)
[2024-11-13 10:57:23,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:24,272][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.011632866226136684, acc: 1.0)
[2024-11-13 10:57:24,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:24,960][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.4334917664527893, acc: 0.8795180916786194)
[2024-11-13 10:57:25,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:25,643][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 0.3479108214378357, acc: 0.8888888955116272)
[2024-11-13 10:57:25,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:26,318][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.27579280734062195, acc: 0.9210526347160339)
[2024-11-13 10:57:26,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:26,990][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.3519670069217682, acc: 0.9117646813392639)
[2024-11-13 10:57:27,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:27,669][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.07465623319149017, acc: 0.9750000238418579)
[2024-11-13 10:57:27,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:28,354][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 0.15887020528316498, acc: 0.9296875)
[2024-11-13 10:57:28,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:29,056][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 0.3076649606227875, acc: 0.9120000004768372)
[2024-11-13 10:57:29,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:29,737][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.08516845852136612, acc: 0.9670329689979553)
[2024-11-13 10:57:29,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:30,426][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 0.19341756403446198, acc: 0.9254658222198486)
[2024-11-13 10:57:30,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:31,133][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 0.37585580348968506, acc: 0.9020618796348572)
[2024-11-13 10:57:31,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:31,806][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.003774626413360238, acc: 1.0)
[2024-11-13 10:57:31,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:32,482][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.3155139982700348, acc: 0.9523809552192688)
[2024-11-13 10:57:32,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:33,167][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.07429154217243195, acc: 1.0)
[2024-11-13 10:57:33,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:33,855][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.10014677792787552, acc: 0.9818181991577148)
[2024-11-13 10:57:33,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:34,582][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 0.3883512318134308, acc: 0.876288652420044)
[2024-11-13 10:57:34,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:35,265][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.28452375531196594, acc: 0.9137930870056152)
[2024-11-13 10:57:35,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:35,940][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.06360580772161484, acc: 0.9629629850387573)
[2024-11-13 10:57:36,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:36,623][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.07766111940145493, acc: 0.9736841917037964)
[2024-11-13 10:57:36,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:37,303][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.03807860612869263, acc: 0.9821428656578064)
[2024-11-13 10:57:37,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:37,977][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.007436925079673529, acc: 1.0)
[2024-11-13 10:57:38,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:38,656][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.05696405842900276, acc: 0.9811320900917053)
[2024-11-13 10:57:38,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:39,331][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.012727249413728714, acc: 1.0)
[2024-11-13 10:57:39,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:40,004][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.036296382546424866, acc: 0.970588207244873)
[2024-11-13 10:57:40,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:40,675][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.010462922975420952, acc: 1.0)
[2024-11-13 10:57:40,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:41,356][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.12113621830940247, acc: 0.9508196711540222)
[2024-11-13 10:57:41,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:42,033][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.019794262945652008, acc: 1.0)
[2024-11-13 10:57:42,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:42,716][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.09882274270057678, acc: 0.9473684430122375)
[2024-11-13 10:57:42,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:43,407][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.09156769514083862, acc: 0.9710144996643066)
[2024-11-13 10:57:43,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:44,098][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.016067424789071083, acc: 1.0)
[2024-11-13 10:57:44,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:44,788][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.13886159658432007, acc: 0.9759036302566528)
[2024-11-13 10:57:44,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:45,474][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.17455194890499115, acc: 0.9487179517745972)
[2024-11-13 10:57:45,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:46,178][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 0.23864489793777466, acc: 0.9081632494926453)
[2024-11-13 10:57:46,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:46,856][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.02320667915046215, acc: 1.0)
[2024-11-13 10:57:46,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:47,530][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.15125223994255066, acc: 0.9583333134651184)
[2024-11-13 10:57:47,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:48,239][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.1156587228178978, acc: 0.9354838728904724)
[2024-11-13 10:57:48,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:48,913][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.010661061853170395, acc: 1.0)
[2024-11-13 10:57:48,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:49,598][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.030644476413726807, acc: 0.9850746393203735)
[2024-11-13 10:57:49,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:50,288][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.06601662933826447, acc: 0.9711538553237915)
[2024-11-13 10:57:50,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:50,970][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.018254082649946213, acc: 1.0)
[2024-11-13 10:57:51,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:51,658][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.04584789648652077, acc: 0.9838709831237793)
[2024-11-13 10:57:51,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:52,354][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.02453634701669216, acc: 0.9800000190734863)
[2024-11-13 10:57:52,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:53,029][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.0609191469848156, acc: 1.0)
[2024-11-13 10:57:53,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:53,705][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.19844192266464233, acc: 0.9142857193946838)
[2024-11-13 10:57:53,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:54,384][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.18433335423469543, acc: 0.9487179517745972)
[2024-11-13 10:57:54,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:55,061][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 0.21166199445724487, acc: 0.9024389982223511)
[2024-11-13 10:57:55,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:55,739][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.06556090712547302, acc: 0.9736841917037964)
[2024-11-13 10:57:55,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:56,409][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.07378647476434708, acc: 0.9473684430122375)
[2024-11-13 10:57:56,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:57,091][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.002119736047461629, acc: 1.0)
[2024-11-13 10:57:57,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:57,815][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.011424422264099121, acc: 1.0)
[2024-11-13 10:57:57,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:58,494][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.0030710892751812935, acc: 1.0)
[2024-11-13 10:57:58,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:59,176][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.061453789472579956, acc: 0.9677419066429138)
[2024-11-13 10:57:59,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:57:59,881][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.0425499863922596, acc: 0.9824561476707458)
[2024-11-13 10:57:59,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:00,554][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.10888367146253586, acc: 0.96875)
[2024-11-13 10:58:00,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:01,225][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.013554505072534084, acc: 1.0)
[2024-11-13 10:58:01,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:01,894][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.03300096094608307, acc: 1.0)
[2024-11-13 10:58:01,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:02,580][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.05956802889704704, acc: 1.0)
[2024-11-13 10:58:02,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:03,267][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 0.3471027612686157, acc: 0.8735632300376892)
[2024-11-13 10:58:03,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:03,951][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 0.46486738324165344, acc: 0.8510638475418091)
[2024-11-13 10:58:04,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:04,636][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 0.3797450363636017, acc: 0.8795180916786194)
[2024-11-13 10:58:04,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:05,320][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.004201571922749281, acc: 1.0)
[2024-11-13 10:58:05,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:05,995][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.11885019391775131, acc: 0.9487179517745972)
[2024-11-13 10:58:06,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:06,686][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.15918199717998505, acc: 0.9759036302566528)
[2024-11-13 10:58:06,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:07,369][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.013084026984870434, acc: 1.0)
[2024-11-13 10:58:07,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:08,049][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.10553649812936783, acc: 0.9620253443717957)
[2024-11-13 10:58:08,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:08,722][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.1301950216293335, acc: 0.9607843160629272)
[2024-11-13 10:58:08,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:09,405][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.10128124803304672, acc: 0.9850746393203735)
[2024-11-13 10:58:09,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:10,082][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.06302610039710999, acc: 0.949999988079071)
[2024-11-13 10:58:10,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:10,755][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.1857164055109024, acc: 0.9599999785423279)
[2024-11-13 10:58:10,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:11,429][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.5364866256713867, acc: 0.8333333134651184)
[2024-11-13 10:58:11,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:12,106][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.2579023540019989, acc: 0.9069767594337463)
[2024-11-13 10:58:12,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:12,814][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.1172170639038086, acc: 0.9743589758872986)
[2024-11-13 10:58:12,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:13,497][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.06615488231182098, acc: 1.0)
[2024-11-13 10:58:13,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:14,173][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.019465848803520203, acc: 1.0)
[2024-11-13 10:58:14,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:14,882][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.03315318375825882, acc: 1.0)
[2024-11-13 10:58:14,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:15,572][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 0.5115094184875488, acc: 0.8681318759918213)
[2024-11-13 10:58:15,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:16,276][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 0.32992419600486755, acc: 0.9130434989929199)
[2024-11-13 10:58:16,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:16,957][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 0.15225619077682495, acc: 0.95652174949646)
[2024-11-13 10:58:17,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:17,639][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.08647564798593521, acc: 0.9591836929321289)
[2024-11-13 10:58:17,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:18,310][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.09044232219457626, acc: 0.9583333134651184)
[2024-11-13 10:58:18,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:18,984][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.03021918796002865, acc: 1.0)
[2024-11-13 10:58:19,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:19,657][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.2702283263206482, acc: 0.9024389982223511)
[2024-11-13 10:58:19,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:20,329][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.18449397385120392, acc: 0.9333333373069763)
[2024-11-13 10:58:20,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:21,012][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.017655745148658752, acc: 1.0)
[2024-11-13 10:58:21,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:21,692][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.11701942980289459, acc: 0.9512194991111755)
[2024-11-13 10:58:21,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:22,375][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.005278086755424738, acc: 1.0)
[2024-11-13 10:58:22,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:23,060][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.004002088215202093, acc: 1.0)
[2024-11-13 10:58:23,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:23,742][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.009708773344755173, acc: 1.0)
[2024-11-13 10:58:23,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:24,421][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.023675886914134026, acc: 1.0)
[2024-11-13 10:58:24,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:25,103][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.0823313370347023, acc: 0.96875)
[2024-11-13 10:58:25,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:25,815][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 0.29127785563468933, acc: 0.9212121367454529)
[2024-11-13 10:58:25,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:26,529][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 0.26898467540740967, acc: 0.9245283007621765)
[2024-11-13 10:58:26,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:27,215][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.07533955574035645, acc: 0.9777777791023254)
[2024-11-13 10:58:27,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:27,900][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.05220293998718262, acc: 1.0)
[2024-11-13 10:58:27,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:28,600][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.11801494657993317, acc: 0.9714285731315613)
[2024-11-13 10:58:28,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:29,288][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.0007646817830391228, acc: 1.0)
[2024-11-13 10:58:29,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:29,977][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.00688012083992362, acc: 1.0)
[2024-11-13 10:58:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:30,664][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.03245759755373001, acc: 1.0)
[2024-11-13 10:58:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:31,401][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.012157529592514038, acc: 1.0)
[2024-11-13 10:58:31,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:32,111][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 0.22769729793071747, acc: 0.9281437397003174)
[2024-11-13 10:58:32,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:32,797][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.07785563170909882, acc: 0.9548872113227844)
[2024-11-13 10:58:32,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:33,519][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 0.46240171790122986, acc: 0.8449198007583618)
[2024-11-13 10:58:33,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:34,224][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.10297321528196335, acc: 0.954954981803894)
[2024-11-13 10:58:34,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:34,901][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.046484965831041336, acc: 1.0)
[2024-11-13 10:58:34,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:35,582][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.0029583661817014217, acc: 1.0)
[2024-11-13 10:58:35,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:36,258][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.011359456926584244, acc: 1.0)
[2024-11-13 10:58:36,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:36,930][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.011045590043067932, acc: 1.0)
[2024-11-13 10:58:37,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:37,601][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.010865680873394012, acc: 1.0)
[2024-11-13 10:58:37,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:38,272][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.001777352299541235, acc: 1.0)
[2024-11-13 10:58:38,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:38,942][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.01118255965411663, acc: 1.0)
[2024-11-13 10:58:39,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:39,615][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.07104893773794174, acc: 0.9523809552192688)
[2024-11-13 10:58:39,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:40,293][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.34259191155433655, acc: 0.9074074029922485)
[2024-11-13 10:58:40,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:40,984][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 0.3499148488044739, acc: 0.9029126167297363)
[2024-11-13 10:58:41,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:41,702][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 0.41293901205062866, acc: 0.8897058963775635)
[2024-11-13 10:58:41,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:42,389][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 0.2407638281583786, acc: 0.9266666769981384)
[2024-11-13 10:58:42,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:43,079][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 0.36591142416000366, acc: 0.8819444179534912)
[2024-11-13 10:58:43,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:43,762][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.0603904165327549, acc: 0.9767441749572754)
[2024-11-13 10:58:43,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:44,442][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.004158589988946915, acc: 1.0)
[2024-11-13 10:58:44,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:45,117][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.16744837164878845, acc: 0.9534883499145508)
[2024-11-13 10:58:45,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:45,791][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.016637645661830902, acc: 1.0)
[2024-11-13 10:58:45,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:46,476][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.19914524257183075, acc: 0.9264705777168274)
[2024-11-13 10:58:46,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:47,167][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.11370094120502472, acc: 0.9599999785423279)
[2024-11-13 10:58:47,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:47,851][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.011430022306740284, acc: 1.0)
[2024-11-13 10:58:47,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:48,525][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.061037518084049225, acc: 0.939393937587738)
[2024-11-13 10:58:48,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:49,196][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.0024646881502121687, acc: 1.0)
[2024-11-13 10:58:49,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:49,868][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.033295709639787674, acc: 0.9629629850387573)
[2024-11-13 10:58:49,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:50,550][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.013619688339531422, acc: 1.0)
[2024-11-13 10:58:50,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:51,223][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.0023406418040394783, acc: 1.0)
[2024-11-13 10:58:51,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:51,899][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.012631330639123917, acc: 1.0)
[2024-11-13 10:58:51,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:52,582][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.0035424421075731516, acc: 1.0)
[2024-11-13 10:58:52,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:53,261][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.0152005385607481, acc: 1.0)
[2024-11-13 10:58:53,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:53,939][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.02103830687701702, acc: 1.0)
[2024-11-13 10:58:54,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:54,618][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.1264151930809021, acc: 0.9333333373069763)
[2024-11-13 10:58:55,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:56,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:57,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:57,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:58,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:59,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:58:59,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:00,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:00,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:01,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:01,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:02,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:03,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:03,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:04,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:05,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:05,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:06,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:06,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:07,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:07,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:08,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:09,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:09,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:10,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:11,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:11,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:12,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:12,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:13,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:14,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:14,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:15,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:15,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:16,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:17,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:18,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:18,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:19,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:20,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:20,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:21,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:21,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:22,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:23,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:23,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:24,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:24,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:25,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:26,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:26,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:27,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:28,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:28,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:29,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:30,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:30,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:31,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:32,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:32,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:33,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:34,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:34,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:35,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:35,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:36,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:36,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:37,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:38,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:38,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:39,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:39,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:40,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:41,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:41,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:42,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:42,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:43,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:44,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:44,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:45,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:45,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:46,797][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2758, device='cuda:0') eval_epoch_loss=tensor(0.8223, device='cuda:0') eval_epoch_acc=tensor(0.8203, device='cuda:0')
[2024-11-13 10:59:46,798][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 10:59:46,799][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 10:59:47,111][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_413_loss_0.82232666015625/model.pt
[2024-11-13 10:59:47,114][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 10:59:47,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:47,808][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.020414145663380623, acc: 1.0)
[2024-11-13 10:59:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:48,492][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.07727599889039993, acc: 0.9545454382896423)
[2024-11-13 10:59:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:49,173][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.15146838128566742, acc: 0.9803921580314636)
[2024-11-13 10:59:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:49,855][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.024575579911470413, acc: 1.0)
[2024-11-13 10:59:49,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:50,534][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.07144530862569809, acc: 0.9444444179534912)
[2024-11-13 10:59:50,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:51,216][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.10407477617263794, acc: 0.9750000238418579)
[2024-11-13 10:59:51,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:51,895][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.039100442081689835, acc: 1.0)
[2024-11-13 10:59:51,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:52,568][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.0011107681784778833, acc: 1.0)
[2024-11-13 10:59:52,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:53,235][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.1757689267396927, acc: 0.9666666388511658)
[2024-11-13 10:59:53,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:53,916][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.136893630027771, acc: 0.9375)
[2024-11-13 10:59:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:54,589][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.033607613295316696, acc: 1.0)
[2024-11-13 10:59:54,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:55,258][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.016800660640001297, acc: 1.0)
[2024-11-13 10:59:55,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:55,930][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.007712442893534899, acc: 1.0)
[2024-11-13 10:59:56,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:56,598][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.07228690385818481, acc: 0.95652174949646)
[2024-11-13 10:59:56,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:57,271][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.00487078120931983, acc: 1.0)
[2024-11-13 10:59:57,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:57,941][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.012940676882863045, acc: 1.0)
[2024-11-13 10:59:58,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:58,610][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.003959232475608587, acc: 1.0)
[2024-11-13 10:59:58,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:59,280][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.00038830775883980095, acc: 1.0)
[2024-11-13 10:59:59,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 10:59:59,951][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.0005572544760070741, acc: 1.0)
[2024-11-13 11:00:00,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:00,619][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.021544363349676132, acc: 1.0)
[2024-11-13 11:00:00,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:01,291][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.020817101001739502, acc: 1.0)
[2024-11-13 11:00:01,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:01,960][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.014146734029054642, acc: 1.0)
[2024-11-13 11:00:02,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:02,675][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.230947807431221, acc: 0.9696969985961914)
[2024-11-13 11:00:02,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:03,348][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.0057711247354745865, acc: 1.0)
[2024-11-13 11:00:03,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:04,023][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.07461284846067429, acc: 0.9772727489471436)
[2024-11-13 11:00:04,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:04,697][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.008485502563416958, acc: 1.0)
[2024-11-13 11:00:04,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:05,372][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.19127918779850006, acc: 0.9230769276618958)
[2024-11-13 11:00:05,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:06,057][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.23952074348926544, acc: 0.9545454382896423)
[2024-11-13 11:00:06,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:06,763][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 0.577024519443512, acc: 0.7760000228881836)
[2024-11-13 11:00:06,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:07,453][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 0.467793732881546, acc: 0.8306451439857483)
[2024-11-13 11:00:07,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:08,171][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 0.4619300365447998, acc: 0.8606964945793152)
[2024-11-13 11:00:08,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:08,866][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.05446914583444595, acc: 0.9811320900917053)
[2024-11-13 11:00:08,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:09,551][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.03522458299994469, acc: 0.9772727489471436)
[2024-11-13 11:00:09,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:10,221][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.07809559255838394, acc: 0.95652174949646)
[2024-11-13 11:00:10,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:10,889][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.009048854932188988, acc: 1.0)
[2024-11-13 11:00:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:11,564][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.003999550361186266, acc: 1.0)
[2024-11-13 11:00:11,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:12,240][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.05451471358537674, acc: 0.9850746393203735)
[2024-11-13 11:00:12,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:12,917][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.03795638307929039, acc: 0.9861111044883728)
[2024-11-13 11:00:12,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:13,595][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.023078011348843575, acc: 1.0)
[2024-11-13 11:00:13,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:14,272][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.07225430756807327, acc: 0.9743589758872986)
[2024-11-13 11:00:14,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:14,968][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.30352839827537537, acc: 0.9078947305679321)
[2024-11-13 11:00:15,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:15,647][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.025815105065703392, acc: 1.0)
[2024-11-13 11:00:15,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:16,325][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.036591269075870514, acc: 1.0)
[2024-11-13 11:00:16,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:17,016][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 0.32758229970932007, acc: 0.907216489315033)
[2024-11-13 11:00:17,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:17,698][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.04932653531432152, acc: 0.9714285731315613)
[2024-11-13 11:00:17,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:18,421][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 0.19176314771175385, acc: 0.930232584476471)
[2024-11-13 11:00:18,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:19,092][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.10114170610904694, acc: 0.9642857313156128)
[2024-11-13 11:00:19,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:19,781][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 0.10817467421293259, acc: 0.9629629850387573)
[2024-11-13 11:00:19,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:20,458][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.13953210413455963, acc: 0.9444444179534912)
[2024-11-13 11:00:20,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:21,130][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.012473256327211857, acc: 1.0)
[2024-11-13 11:00:21,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:21,804][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.009760556742548943, acc: 1.0)
[2024-11-13 11:00:21,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:22,486][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.11934593319892883, acc: 0.95652174949646)
[2024-11-13 11:00:22,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:23,161][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.1957031637430191, acc: 0.9285714030265808)
[2024-11-13 11:00:23,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:23,839][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.09263240545988083, acc: 0.9879518151283264)
[2024-11-13 11:00:23,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:24,545][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.15696074068546295, acc: 0.9369369149208069)
[2024-11-13 11:00:24,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:25,228][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 0.31267163157463074, acc: 0.893203854560852)
[2024-11-13 11:00:25,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:25,934][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.3304867148399353, acc: 0.8943089246749878)
[2024-11-13 11:00:26,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:26,610][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.05912591889500618, acc: 0.9583333134651184)
[2024-11-13 11:00:26,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:27,282][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.04165211319923401, acc: 1.0)
[2024-11-13 11:00:27,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:27,990][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 0.6384689211845398, acc: 0.8039215803146362)
[2024-11-13 11:00:28,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:28,697][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 0.5296258330345154, acc: 0.8427947759628296)
[2024-11-13 11:00:28,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:29,376][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 0.14974500238895416, acc: 0.9583333134651184)
[2024-11-13 11:00:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:30,066][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 0.17466095089912415, acc: 0.9447852969169617)
[2024-11-13 11:00:30,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:30,751][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 0.1397177278995514, acc: 0.9568345546722412)
[2024-11-13 11:00:30,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:31,455][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 0.4474472999572754, acc: 0.8291457295417786)
[2024-11-13 11:00:31,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:32,128][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.19922582805156708, acc: 0.9444444179534912)
[2024-11-13 11:00:32,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:32,799][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.02926095575094223, acc: 1.0)
[2024-11-13 11:00:32,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:33,471][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.016306640580296516, acc: 1.0)
[2024-11-13 11:00:33,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:34,139][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.015896987169981003, acc: 1.0)
[2024-11-13 11:00:34,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:34,809][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.06154844909906387, acc: 0.949999988079071)
[2024-11-13 11:00:34,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:35,493][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.21368727087974548, acc: 0.9137930870056152)
[2024-11-13 11:00:35,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:36,164][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.046571265906095505, acc: 0.9677419066429138)
[2024-11-13 11:00:36,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:36,837][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.009140745736658573, acc: 1.0)
[2024-11-13 11:00:36,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:37,505][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.07247720658779144, acc: 1.0)
[2024-11-13 11:00:37,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:38,179][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.018155565485358238, acc: 1.0)
[2024-11-13 11:00:38,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:38,858][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.00626277644187212, acc: 1.0)
[2024-11-13 11:00:38,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:39,538][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.18634170293807983, acc: 0.9538461565971375)
[2024-11-13 11:00:39,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:40,210][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.008229022845625877, acc: 1.0)
[2024-11-13 11:00:40,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:40,888][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.007331210654228926, acc: 1.0)
[2024-11-13 11:00:40,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:41,569][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.031172627583146095, acc: 1.0)
[2024-11-13 11:00:41,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:42,246][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.019492924213409424, acc: 1.0)
[2024-11-13 11:00:42,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:42,922][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.0017705467762425542, acc: 1.0)
[2024-11-13 11:00:43,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:43,594][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.024685753509402275, acc: 1.0)
[2024-11-13 11:00:43,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:44,280][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.4549023509025574, acc: 0.8482142686843872)
[2024-11-13 11:00:44,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:44,963][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.15190497040748596, acc: 0.9550561904907227)
[2024-11-13 11:00:45,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:45,646][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 0.5669060349464417, acc: 0.8426966071128845)
[2024-11-13 11:00:45,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:46,346][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 0.7108392715454102, acc: 0.7872340679168701)
[2024-11-13 11:00:46,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:47,032][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.22765444219112396, acc: 0.9239130616188049)
[2024-11-13 11:00:47,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:47,700][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.0005753159057348967, acc: 1.0)
[2024-11-13 11:00:47,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:48,374][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.001124317292124033, acc: 1.0)
[2024-11-13 11:00:48,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:49,044][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.1135341078042984, acc: 0.9629629850387573)
[2024-11-13 11:00:49,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:49,727][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.006300425622612238, acc: 1.0)
[2024-11-13 11:00:49,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:50,401][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.15996034443378448, acc: 0.9245283007621765)
[2024-11-13 11:00:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:51,077][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.14586007595062256, acc: 0.931034505367279)
[2024-11-13 11:00:51,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:51,769][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 0.3143545389175415, acc: 0.9099099040031433)
[2024-11-13 11:00:51,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:52,453][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.1523013710975647, acc: 0.9577465057373047)
[2024-11-13 11:00:52,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:53,134][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.0013421907788142562, acc: 1.0)
[2024-11-13 11:00:53,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:53,807][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.0006155589944683015, acc: 1.0)
[2024-11-13 11:00:53,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:54,477][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.017151525244116783, acc: 1.0)
[2024-11-13 11:00:54,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:55,375][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 1.1734191179275513, acc: 0.6714285612106323)
[2024-11-13 11:00:55,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:56,082][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 0.32172712683677673, acc: 0.9047619104385376)
[2024-11-13 11:00:56,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:56,756][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.0376601442694664, acc: 1.0)
[2024-11-13 11:00:56,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:57,438][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.02199116349220276, acc: 1.0)
[2024-11-13 11:00:57,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:58,128][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.29489317536354065, acc: 0.8888888955116272)
[2024-11-13 11:00:58,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:58,799][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.0032999636605381966, acc: 1.0)
[2024-11-13 11:00:58,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:00:59,469][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.006163211539387703, acc: 1.0)
[2024-11-13 11:00:59,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:00,129][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.06918643414974213, acc: 0.949999988079071)
[2024-11-13 11:01:00,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:00,798][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.0176229327917099, acc: 1.0)
[2024-11-13 11:01:00,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:01,565][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 0.9621357321739197, acc: 0.7161017060279846)
[2024-11-13 11:01:01,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:02,267][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 0.2245369851589203, acc: 0.9552238583564758)
[2024-11-13 11:01:02,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:02,953][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 0.22884434461593628, acc: 0.9416058659553528)
[2024-11-13 11:01:03,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:03,670][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 0.42978227138519287, acc: 0.9150000214576721)
[2024-11-13 11:01:03,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:04,346][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.016289787366986275, acc: 1.0)
[2024-11-13 11:01:04,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:05,027][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.08468174934387207, acc: 0.9807692170143127)
[2024-11-13 11:01:05,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:05,698][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.0083927558735013, acc: 1.0)
[2024-11-13 11:01:05,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:06,385][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.12768973410129547, acc: 0.9836065769195557)
[2024-11-13 11:01:06,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:07,062][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.05358019098639488, acc: 1.0)
[2024-11-13 11:01:07,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:07,737][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.045214831829071045, acc: 1.0)
[2024-11-13 11:01:07,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:08,424][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.18304209411144257, acc: 0.9318181872367859)
[2024-11-13 11:01:08,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:09,113][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.13172924518585205, acc: 0.9811320900917053)
[2024-11-13 11:01:09,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:09,793][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.07105274498462677, acc: 0.9772727489471436)
[2024-11-13 11:01:09,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:10,463][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.006462821736931801, acc: 1.0)
[2024-11-13 11:01:10,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:11,145][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.11542467027902603, acc: 0.949999988079071)
[2024-11-13 11:01:11,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:11,824][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.0016996938502416015, acc: 1.0)
[2024-11-13 11:01:11,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:12,513][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.05475512892007828, acc: 0.9846153855323792)
[2024-11-13 11:01:12,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:13,207][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.11504378169775009, acc: 0.96875)
[2024-11-13 11:01:13,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:13,896][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.06088430434465408, acc: 0.96875)
[2024-11-13 11:01:13,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:14,575][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.034467488527297974, acc: 1.0)
[2024-11-13 11:01:14,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:15,246][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.013148030266165733, acc: 1.0)
[2024-11-13 11:01:15,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:15,924][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.03752443194389343, acc: 1.0)
[2024-11-13 11:01:16,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:16,596][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.0033465654123574495, acc: 1.0)
[2024-11-13 11:01:16,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:17,266][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.09317776560783386, acc: 0.9666666388511658)
[2024-11-13 11:01:17,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:17,952][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.12344729900360107, acc: 0.9756097793579102)
[2024-11-13 11:01:18,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:18,631][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.04701320827007294, acc: 0.9714285731315613)
[2024-11-13 11:01:18,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:19,303][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.037729661911726, acc: 0.9736841917037964)
[2024-11-13 11:01:19,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:19,978][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.2887597978115082, acc: 0.9032257795333862)
[2024-11-13 11:01:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:20,658][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.0016263042343780398, acc: 1.0)
[2024-11-13 11:01:20,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:21,337][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.11352688074111938, acc: 0.9696969985961914)
[2024-11-13 11:01:21,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:22,017][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.020609872415661812, acc: 1.0)
[2024-11-13 11:01:22,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:22,700][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.20429186522960663, acc: 0.9571428298950195)
[2024-11-13 11:01:22,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:23,405][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 0.13721022009849548, acc: 0.9635036587715149)
[2024-11-13 11:01:23,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:24,109][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 0.0803910419344902, acc: 0.9793103337287903)
[2024-11-13 11:01:24,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:24,795][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 0.16334564983844757, acc: 0.9571428298950195)
[2024-11-13 11:01:25,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:26,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:26,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:27,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:27,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:28,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:29,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:29,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:30,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:30,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:31,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:32,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:32,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:33,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:34,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:34,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:35,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:36,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:36,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:37,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:37,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:38,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:38,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:39,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:40,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:40,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:41,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:42,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:42,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:43,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:43,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:44,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:45,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:45,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:46,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:46,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:47,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:48,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:48,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:49,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:49,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:50,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:51,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:51,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:52,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:52,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:53,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:54,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:54,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:55,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:56,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:56,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:57,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:57,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:58,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:59,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:01:59,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:00,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:00,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:01,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:02,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:02,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:03,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:03,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:04,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:05,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:05,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:06,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:06,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:07,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:08,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:08,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:09,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:09,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:10,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:11,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:11,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:12,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:12,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:13,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:14,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:14,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:15,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:16,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:16,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:17,582][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3742, device='cuda:0') eval_epoch_loss=tensor(0.8646, device='cuda:0') eval_epoch_acc=tensor(0.8170, device='cuda:0')
[2024-11-13 11:02:17,584][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 11:02:17,584][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 11:02:17,937][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_9_step_556_loss_0.8646436333656311/model.pt
[2024-11-13 11:02:17,941][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 11:02:18,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:18,642][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 0.2807508707046509, acc: 0.9139072895050049)
[2024-11-13 11:02:18,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:19,328][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.10717349499464035, acc: 0.9829059839248657)
[2024-11-13 11:02:19,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:20,004][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.10016945004463196, acc: 0.9599999785423279)
[2024-11-13 11:02:20,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:20,677][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.1401013284921646, acc: 0.9615384340286255)
[2024-11-13 11:02:20,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:21,350][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.10775533318519592, acc: 0.9615384340286255)
[2024-11-13 11:02:21,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:22,026][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.09037220478057861, acc: 0.9743589758872986)
[2024-11-13 11:02:22,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:22,725][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.18025411665439606, acc: 0.9444444179534912)
[2024-11-13 11:02:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:23,403][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.11651202291250229, acc: 0.9740259647369385)
[2024-11-13 11:02:23,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:24,074][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.09450230747461319, acc: 0.9583333134651184)
[2024-11-13 11:02:24,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:24,755][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.13820329308509827, acc: 0.9655172228813171)
[2024-11-13 11:02:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:25,441][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.06719694286584854, acc: 0.988095223903656)
[2024-11-13 11:02:25,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:26,111][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.09609395265579224, acc: 0.9473684430122375)
[2024-11-13 11:02:26,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:26,783][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.005455345846712589, acc: 1.0)
[2024-11-13 11:02:26,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:27,507][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 0.19945330917835236, acc: 0.9572192430496216)
[2024-11-13 11:02:27,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:28,188][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.1439647376537323, acc: 0.9516128897666931)
[2024-11-13 11:02:28,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:28,875][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.0574176125228405, acc: 0.9914529919624329)
[2024-11-13 11:02:28,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:29,588][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 0.5003601908683777, acc: 0.8520408272743225)
[2024-11-13 11:02:29,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:30,298][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 0.2566235363483429, acc: 0.893081784248352)
[2024-11-13 11:02:30,797][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.1878, train_epoch_loss=0.1721, epoch time 607.0497358366847s
[2024-11-13 11:02:30,798][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 11:02:30,798][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 11:02:30,798][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 11:02:30,798][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 3
[2024-11-13 11:02:30,798][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 11:02:31,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:32,225][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.01930774748325348, acc: 1.0)
[2024-11-13 11:02:32,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:32,909][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.09313005208969116, acc: 0.9599999785423279)
[2024-11-13 11:02:32,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:33,604][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.06406436115503311, acc: 0.9729729890823364)
[2024-11-13 11:02:33,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:34,294][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.18875354528427124, acc: 0.9210526347160339)
[2024-11-13 11:02:34,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:34,976][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.10008673369884491, acc: 0.9459459185600281)
[2024-11-13 11:02:35,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:35,664][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.051504600793123245, acc: 0.9642857313156128)
[2024-11-13 11:02:35,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:36,352][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.07264398038387299, acc: 0.9795918464660645)
[2024-11-13 11:02:36,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:37,034][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.11267884075641632, acc: 0.9666666388511658)
[2024-11-13 11:02:37,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:37,714][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.004608113318681717, acc: 1.0)
[2024-11-13 11:02:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:38,404][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.0009867121698334813, acc: 1.0)
[2024-11-13 11:02:38,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:39,090][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.011524604633450508, acc: 1.0)
[2024-11-13 11:02:39,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:39,775][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.1171499490737915, acc: 0.9743589758872986)
[2024-11-13 11:02:39,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:40,455][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.0022456631995737553, acc: 1.0)
[2024-11-13 11:02:40,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:41,138][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.09924321621656418, acc: 0.97826087474823)
[2024-11-13 11:02:41,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:41,822][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.01364918239414692, acc: 1.0)
[2024-11-13 11:02:41,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:42,508][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.05577621981501579, acc: 0.9795918464660645)
[2024-11-13 11:02:42,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:43,194][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.005256751086562872, acc: 1.0)
[2024-11-13 11:02:43,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:43,880][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.00991352554410696, acc: 1.0)
[2024-11-13 11:02:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:44,563][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.015437941998243332, acc: 1.0)
[2024-11-13 11:02:44,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:45,243][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.06005379557609558, acc: 0.9473684430122375)
[2024-11-13 11:02:45,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:45,925][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.00347691448405385, acc: 1.0)
[2024-11-13 11:02:46,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:46,614][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.0686037614941597, acc: 0.9655172228813171)
[2024-11-13 11:02:46,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:47,299][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.024537015706300735, acc: 1.0)
[2024-11-13 11:02:47,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:47,983][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.019553080201148987, acc: 1.0)
[2024-11-13 11:02:48,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:48,666][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.006960171740502119, acc: 1.0)
[2024-11-13 11:02:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:49,367][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.3445436358451843, acc: 0.9056603908538818)
[2024-11-13 11:02:49,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:50,059][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.19559776782989502, acc: 0.931506872177124)
[2024-11-13 11:02:50,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:50,863][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 0.8052031993865967, acc: 0.7667984366416931)
[2024-11-13 11:02:50,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:51,554][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.12066600471735, acc: 0.9534883499145508)
[2024-11-13 11:02:51,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:52,250][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.06035172939300537, acc: 1.0)
[2024-11-13 11:02:52,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:52,950][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.2988947629928589, acc: 0.9259259104728699)
[2024-11-13 11:02:53,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:53,631][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.10696808993816376, acc: 0.9642857313156128)
[2024-11-13 11:02:53,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:54,313][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.4906429052352905, acc: 0.8888888955116272)
[2024-11-13 11:02:54,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:54,992][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.0015510233351960778, acc: 1.0)
[2024-11-13 11:02:55,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:55,701][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 0.15035806596279144, acc: 0.9579831957817078)
[2024-11-13 11:02:55,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:56,390][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.12975922226905823, acc: 0.9672130942344666)
[2024-11-13 11:02:56,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:57,097][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.16210007667541504, acc: 0.9523809552192688)
[2024-11-13 11:02:57,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:57,788][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.08094919472932816, acc: 0.9661017060279846)
[2024-11-13 11:02:57,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:58,494][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.12428485602140427, acc: 0.9425287246704102)
[2024-11-13 11:02:58,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:59,185][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.0033165004570037127, acc: 1.0)
[2024-11-13 11:02:59,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:02:59,869][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.0368804894387722, acc: 1.0)
[2024-11-13 11:02:59,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:00,573][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.11756303906440735, acc: 0.9594594836235046)
[2024-11-13 11:03:00,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:01,267][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.11940447241067886, acc: 0.9230769276618958)
[2024-11-13 11:03:01,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:01,959][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.07002908736467361, acc: 0.9797979593276978)
[2024-11-13 11:03:02,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:02,671][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.19098840653896332, acc: 0.938144326210022)
[2024-11-13 11:03:02,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:03,376][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 0.18549902737140656, acc: 0.9338235259056091)
[2024-11-13 11:03:03,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:04,059][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.06826519221067429, acc: 0.9615384340286255)
[2024-11-13 11:03:04,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:04,746][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.00549772335216403, acc: 1.0)
[2024-11-13 11:03:04,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:05,432][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.15318302810192108, acc: 0.9642857313156128)
[2024-11-13 11:03:05,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:06,118][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.019629664719104767, acc: 1.0)
[2024-11-13 11:03:06,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:06,807][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.04131561517715454, acc: 0.9824561476707458)
[2024-11-13 11:03:06,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:07,509][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.057092711329460144, acc: 0.9841269850730896)
[2024-11-13 11:03:07,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:08,217][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.1701563000679016, acc: 0.9436619877815247)
[2024-11-13 11:03:08,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:08,939][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 0.5420339703559875, acc: 0.8666666746139526)
[2024-11-13 11:03:09,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:09,629][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.13951259851455688, acc: 0.9189189076423645)
[2024-11-13 11:03:09,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:10,315][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.010439293459057808, acc: 1.0)
[2024-11-13 11:03:10,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:11,165][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.068281888961792, acc: 0.6996586918830872)
[2024-11-13 11:03:11,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:11,945][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 1.1898125410079956, acc: 0.6405228972434998)
[2024-11-13 11:03:12,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:12,667][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 0.3744156062602997, acc: 0.8693181872367859)
[2024-11-13 11:03:12,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:13,366][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 0.2004534751176834, acc: 0.9411764740943909)
[2024-11-13 11:03:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:14,084][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 0.2693884074687958, acc: 0.8913043737411499)
[2024-11-13 11:03:14,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:14,798][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.19040921330451965, acc: 0.925000011920929)
[2024-11-13 11:03:14,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:15,493][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.18119852244853973, acc: 0.9411764740943909)
[2024-11-13 11:03:15,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:16,180][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.02422778680920601, acc: 1.0)
[2024-11-13 11:03:16,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:16,879][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.12265557795763016, acc: 0.984375)
[2024-11-13 11:03:16,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:17,567][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.03220648318529129, acc: 1.0)
[2024-11-13 11:03:17,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:18,254][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.05911766365170479, acc: 0.9642857313156128)
[2024-11-13 11:03:18,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:18,956][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.09149976074695587, acc: 0.9666666388511658)
[2024-11-13 11:03:19,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:19,653][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.010080204345285892, acc: 1.0)
[2024-11-13 11:03:19,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:20,341][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.39095088839530945, acc: 0.8888888955116272)
[2024-11-13 11:03:20,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:21,024][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.39933377504348755, acc: 0.9090909361839294)
[2024-11-13 11:03:21,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:21,741][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 0.4008365869522095, acc: 0.875)
[2024-11-13 11:03:21,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:22,438][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 0.2657526731491089, acc: 0.89682537317276)
[2024-11-13 11:03:22,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:23,170][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 0.7546423673629761, acc: 0.7538461685180664)
[2024-11-13 11:03:23,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:23,864][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.3259519636631012, acc: 0.918367326259613)
[2024-11-13 11:03:23,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:24,573][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 0.4532466530799866, acc: 0.8432835936546326)
[2024-11-13 11:03:24,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:25,317][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 0.8359509110450745, acc: 0.7591241002082825)
[2024-11-13 11:03:25,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:26,001][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.03308526799082756, acc: 1.0)
[2024-11-13 11:03:26,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:26,689][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.007568616885691881, acc: 1.0)
[2024-11-13 11:03:26,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:27,384][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.02393193356692791, acc: 1.0)
[2024-11-13 11:03:27,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:28,068][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.011596852913498878, acc: 1.0)
[2024-11-13 11:03:28,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:28,759][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.11541000008583069, acc: 0.942307710647583)
[2024-11-13 11:03:28,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:29,449][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.16733349859714508, acc: 0.9230769276618958)
[2024-11-13 11:03:29,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:30,131][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.010089344345033169, acc: 1.0)
[2024-11-13 11:03:30,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:30,822][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.043037377297878265, acc: 1.0)
[2024-11-13 11:03:30,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:31,516][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.08306657522916794, acc: 0.9599999785423279)
[2024-11-13 11:03:31,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:32,204][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.07962681353092194, acc: 0.95652174949646)
[2024-11-13 11:03:32,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:32,899][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.12532228231430054, acc: 0.9800000190734863)
[2024-11-13 11:03:32,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:33,609][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.1840699464082718, acc: 0.9708737730979919)
[2024-11-13 11:03:33,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:34,328][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 0.42300811409950256, acc: 0.8640776872634888)
[2024-11-13 11:03:34,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:35,051][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 0.6189269423484802, acc: 0.801075279712677)
[2024-11-13 11:03:35,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:35,795][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 0.5140431523323059, acc: 0.857758641242981)
[2024-11-13 11:03:35,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:36,495][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.14402909576892853, acc: 0.9473684430122375)
[2024-11-13 11:03:36,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:37,232][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 0.39056646823883057, acc: 0.8712871074676514)
[2024-11-13 11:03:37,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:37,924][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.11854518204927444, acc: 0.9516128897666931)
[2024-11-13 11:03:38,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:38,614][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.13416257500648499, acc: 0.9420289993286133)
[2024-11-13 11:03:38,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:39,313][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 0.24316956102848053, acc: 0.924369752407074)
[2024-11-13 11:03:39,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:40,026][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 0.22601033747196198, acc: 0.932692289352417)
[2024-11-13 11:03:40,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:40,732][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 0.3945389688014984, acc: 0.8832116723060608)
[2024-11-13 11:03:40,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:41,424][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.3297974169254303, acc: 0.8507462739944458)
[2024-11-13 11:03:41,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:42,118][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.008154967799782753, acc: 1.0)
[2024-11-13 11:03:42,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:42,813][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.0013699471019208431, acc: 1.0)
[2024-11-13 11:03:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:43,495][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.007047303952276707, acc: 1.0)
[2024-11-13 11:03:43,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:44,180][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.008417612873017788, acc: 1.0)
[2024-11-13 11:03:44,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:44,876][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.06090077757835388, acc: 0.9655172228813171)
[2024-11-13 11:03:44,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:45,569][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.012510946951806545, acc: 1.0)
[2024-11-13 11:03:45,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:46,245][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.0035548419691622257, acc: 1.0)
[2024-11-13 11:03:46,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:46,941][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.004903413355350494, acc: 1.0)
[2024-11-13 11:03:47,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:47,631][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.0016363796312361956, acc: 1.0)
[2024-11-13 11:03:47,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:48,318][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.02442139945924282, acc: 0.976190447807312)
[2024-11-13 11:03:48,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:49,012][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.06093176454305649, acc: 0.9846153855323792)
[2024-11-13 11:03:49,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:49,705][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.01795487105846405, acc: 1.0)
[2024-11-13 11:03:49,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:50,398][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.2190927267074585, acc: 0.9649122953414917)
[2024-11-13 11:03:50,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:51,091][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.018429478630423546, acc: 1.0)
[2024-11-13 11:03:51,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:51,785][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.03777414187788963, acc: 0.9795918464660645)
[2024-11-13 11:03:51,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:52,468][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.000812905840575695, acc: 1.0)
[2024-11-13 11:03:52,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:53,173][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.14327961206436157, acc: 0.9523809552192688)
[2024-11-13 11:03:53,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:53,865][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.08426877856254578, acc: 0.9674796462059021)
[2024-11-13 11:03:53,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:54,570][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.11598165333271027, acc: 0.9516128897666931)
[2024-11-13 11:03:54,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:55,339][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 0.4438569247722626, acc: 0.8707224130630493)
[2024-11-13 11:03:55,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:56,040][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.049734681844711304, acc: 0.9866666793823242)
[2024-11-13 11:03:56,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:56,737][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.15191055834293365, acc: 0.942307710647583)
[2024-11-13 11:03:56,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:57,422][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.0012081440072506666, acc: 1.0)
[2024-11-13 11:03:57,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:58,103][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.010497153736650944, acc: 1.0)
[2024-11-13 11:03:58,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:03:58,806][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 0.34125852584838867, acc: 0.8834356069564819)
[2024-11-13 11:03:59,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:00,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:01,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:01,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:02,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:02,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:03,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:04,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:04,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:05,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:06,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:06,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:07,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:07,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:08,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:08,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:09,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:10,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:10,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:11,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:11,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:12,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:13,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:14,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:14,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:15,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:15,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:16,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:17,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:17,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:18,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:18,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:19,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:20,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:20,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:21,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:21,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:22,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:23,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:23,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:24,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:24,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:25,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:26,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:26,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:27,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:27,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:28,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:29,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:29,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:30,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:30,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:31,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:32,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:32,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:33,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:33,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:34,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:35,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:35,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:36,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:36,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:37,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:38,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:38,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:39,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:39,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:40,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:41,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:41,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:43,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:43,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:44,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:44,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:45,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:46,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:46,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:47,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:47,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:48,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:49,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:49,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:50,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:51,262][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1696, device='cuda:0') eval_epoch_loss=tensor(0.7746, device='cuda:0') eval_epoch_acc=tensor(0.8318, device='cuda:0')
[2024-11-13 11:04:51,263][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 11:04:51,263][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 11:04:51,660][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_125_loss_0.7745513319969177/model.pt
[2024-11-13 11:04:51,664][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 11:04:51,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:52,390][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 0.29020601511001587, acc: 0.9166666865348816)
[2024-11-13 11:04:52,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:53,075][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 0.35766738653182983, acc: 0.8999999761581421)
[2024-11-13 11:04:53,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:53,806][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 0.3377635180950165, acc: 0.875)
[2024-11-13 11:04:53,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:54,512][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 0.2727952301502228, acc: 0.9025641083717346)
[2024-11-13 11:04:54,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:55,248][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 0.28290611505508423, acc: 0.8970588445663452)
[2024-11-13 11:04:55,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:55,927][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.29736775159835815, acc: 0.8846153616905212)
[2024-11-13 11:04:56,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:56,599][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.011271449737250805, acc: 1.0)
[2024-11-13 11:04:56,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:57,272][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.10595580190420151, acc: 0.9375)
[2024-11-13 11:04:57,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:57,944][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.15229755640029907, acc: 0.95652174949646)
[2024-11-13 11:04:58,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:58,628][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.030861565843224525, acc: 1.0)
[2024-11-13 11:04:58,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:59,309][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.020871473476290703, acc: 1.0)
[2024-11-13 11:04:59,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:04:59,984][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.09812842309474945, acc: 0.976190447807312)
[2024-11-13 11:05:00,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:00,658][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.10070347785949707, acc: 0.9666666388511658)
[2024-11-13 11:05:00,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:01,333][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.04391130805015564, acc: 0.95652174949646)
[2024-11-13 11:05:01,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:02,007][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.04140971228480339, acc: 1.0)
[2024-11-13 11:05:02,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:02,685][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.012260072864592075, acc: 1.0)
[2024-11-13 11:05:02,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:03,360][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.06493956595659256, acc: 0.9677419066429138)
[2024-11-13 11:05:03,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:04,042][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.06687488406896591, acc: 0.9729729890823364)
[2024-11-13 11:05:04,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:04,755][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 0.4106518626213074, acc: 0.8333333134651184)
[2024-11-13 11:05:04,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:05,449][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.40091729164123535, acc: 0.858208954334259)
[2024-11-13 11:05:05,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:06,139][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 0.19132930040359497, acc: 0.9591836929321289)
[2024-11-13 11:05:06,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:06,845][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 0.24605655670166016, acc: 0.9255319237709045)
[2024-11-13 11:05:06,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:07,528][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.21636931598186493, acc: 0.9571428298950195)
[2024-11-13 11:05:07,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:08,198][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.13511553406715393, acc: 0.9285714030265808)
[2024-11-13 11:05:08,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:08,872][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.046832021325826645, acc: 1.0)
[2024-11-13 11:05:08,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:09,550][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.06652215123176575, acc: 1.0)
[2024-11-13 11:05:09,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:10,240][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.16282019019126892, acc: 0.95652174949646)
[2024-11-13 11:05:10,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:10,929][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.4202583134174347, acc: 0.9152542352676392)
[2024-11-13 11:05:11,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:11,621][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.09239058941602707, acc: 0.9824561476707458)
[2024-11-13 11:05:11,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:12,316][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.11975525319576263, acc: 0.9459459185600281)
[2024-11-13 11:05:12,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:12,994][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.026020687073469162, acc: 1.0)
[2024-11-13 11:05:13,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:13,671][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.009840436279773712, acc: 1.0)
[2024-11-13 11:05:13,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:14,351][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.07723765820264816, acc: 0.9473684430122375)
[2024-11-13 11:05:14,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:15,029][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 0.30805814266204834, acc: 0.9054054021835327)
[2024-11-13 11:05:15,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:15,717][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.09614871442317963, acc: 0.9629629850387573)
[2024-11-13 11:05:15,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:16,402][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 0.20039048790931702, acc: 0.9418604373931885)
[2024-11-13 11:05:16,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:17,082][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 0.10277292877435684, acc: 0.9529411792755127)
[2024-11-13 11:05:17,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:17,765][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 0.3265492618083954, acc: 0.8539325594902039)
[2024-11-13 11:05:17,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:18,446][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.05997641384601593, acc: 0.9772727489471436)
[2024-11-13 11:05:18,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:19,130][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.01329406350851059, acc: 1.0)
[2024-11-13 11:05:19,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:19,808][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 0.0038993381895124912, acc: 1.0)
[2024-11-13 11:05:19,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:20,488][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.022634172812104225, acc: 1.0)
[2024-11-13 11:05:20,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:21,162][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.01688317582011223, acc: 1.0)
[2024-11-13 11:05:21,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:21,846][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.15381060540676117, acc: 0.9583333134651184)
[2024-11-13 11:05:21,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:22,588][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 0.24119596183300018, acc: 0.9411764740943909)
[2024-11-13 11:05:22,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:23,322][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 0.7648065686225891, acc: 0.7465753555297852)
[2024-11-13 11:05:23,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:23,998][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.007570076733827591, acc: 1.0)
[2024-11-13 11:05:24,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:24,674][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.22492505609989166, acc: 0.9629629850387573)
[2024-11-13 11:05:24,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:25,352][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.02657776139676571, acc: 1.0)
[2024-11-13 11:05:25,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:26,061][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 0.24700549244880676, acc: 0.9203540086746216)
[2024-11-13 11:05:26,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:26,739][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.020238269120454788, acc: 1.0)
[2024-11-13 11:05:26,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:27,426][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.11734041571617126, acc: 0.9431818127632141)
[2024-11-13 11:05:27,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:28,140][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 0.6613426804542542, acc: 0.8244274854660034)
[2024-11-13 11:05:28,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:28,848][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 0.2628876566886902, acc: 0.9111111164093018)
[2024-11-13 11:05:28,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:29,527][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.055341098457574844, acc: 0.9836065769195557)
[2024-11-13 11:05:29,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:30,200][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.014672446995973587, acc: 1.0)
[2024-11-13 11:05:30,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:30,898][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.01650940254330635, acc: 1.0)
[2024-11-13 11:05:30,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:31,573][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.004146256949752569, acc: 1.0)
[2024-11-13 11:05:31,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:32,273][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.04892152547836304, acc: 0.9878048896789551)
[2024-11-13 11:05:32,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:33,001][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 0.3943205177783966, acc: 0.8882175087928772)
[2024-11-13 11:05:33,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:33,735][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 0.3907177448272705, acc: 0.8933717608451843)
[2024-11-13 11:05:33,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:34,462][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 0.22098514437675476, acc: 0.921875)
[2024-11-13 11:05:34,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:35,228][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 0.6242436170578003, acc: 0.8311444520950317)
[2024-11-13 11:05:35,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:35,971][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 0.26528221368789673, acc: 0.9217081665992737)
[2024-11-13 11:05:36,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:36,649][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.01866174302995205, acc: 1.0)
[2024-11-13 11:05:36,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:37,336][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 0.2447860687971115, acc: 0.930232584476471)
[2024-11-13 11:05:37,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:38,034][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 0.47139686346054077, acc: 0.8730158805847168)
[2024-11-13 11:05:38,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:38,721][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 0.3667169511318207, acc: 0.8939393758773804)
[2024-11-13 11:05:38,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:39,406][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 0.12121604382991791, acc: 0.9647058844566345)
[2024-11-13 11:05:39,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:40,113][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 0.4132016897201538, acc: 0.8827160596847534)
[2024-11-13 11:05:40,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:40,798][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.1892423778772354, acc: 0.9516128897666931)
[2024-11-13 11:05:40,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:41,472][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.030182266607880592, acc: 0.9642857313156128)
[2024-11-13 11:05:41,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:42,145][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.13476093113422394, acc: 0.9750000238418579)
[2024-11-13 11:05:42,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:42,824][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.10768497735261917, acc: 0.9558823704719543)
[2024-11-13 11:05:42,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:43,512][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 0.21244299411773682, acc: 0.9264705777168274)
[2024-11-13 11:05:43,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:44,198][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 0.2654664218425751, acc: 0.9406779408454895)
[2024-11-13 11:05:44,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:44,887][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 0.14465780556201935, acc: 0.9626865386962891)
[2024-11-13 11:05:44,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:45,577][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 0.1630372554063797, acc: 0.9320388436317444)
[2024-11-13 11:05:45,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:46,265][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.10728134214878082, acc: 0.9523809552192688)
[2024-11-13 11:05:46,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:46,973][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.036824312061071396, acc: 1.0)
[2024-11-13 11:05:47,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:47,691][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 0.1023583635687828, acc: 0.9730941653251648)
[2024-11-13 11:05:47,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:48,414][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 0.20059950649738312, acc: 0.9330708384513855)
[2024-11-13 11:05:48,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:49,126][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 0.09485819935798645, acc: 0.9784482717514038)
[2024-11-13 11:05:49,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:49,836][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 0.20064158737659454, acc: 0.9275362491607666)
[2024-11-13 11:05:49,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:50,550][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 0.13342009484767914, acc: 0.957198441028595)
[2024-11-13 11:05:50,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:51,259][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 0.10913629829883575, acc: 0.989130437374115)
[2024-11-13 11:05:51,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:51,928][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.0019894868601113558, acc: 1.0)
[2024-11-13 11:05:52,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:52,621][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.0009146397351287305, acc: 1.0)
[2024-11-13 11:05:52,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:53,314][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.03411153703927994, acc: 0.978723406791687)
[2024-11-13 11:05:53,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:54,016][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.06287826597690582, acc: 0.9846153855323792)
[2024-11-13 11:05:54,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:54,696][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.01937069743871689, acc: 0.9864864945411682)
[2024-11-13 11:05:54,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:55,377][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.01585543528199196, acc: 0.9883720874786377)
[2024-11-13 11:05:55,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:56,064][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.06145626679062843, acc: 0.9819819927215576)
[2024-11-13 11:05:56,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:56,746][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.05400468036532402, acc: 0.9777777791023254)
[2024-11-13 11:05:56,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:57,420][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.008540636859834194, acc: 1.0)
[2024-11-13 11:05:57,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:58,091][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.03887530788779259, acc: 0.9629629850387573)
[2024-11-13 11:05:58,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:58,771][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.0011066352017223835, acc: 1.0)
[2024-11-13 11:05:58,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:05:59,466][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.34381309151649475, acc: 0.8846153616905212)
[2024-11-13 11:05:59,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:00,183][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.24742475152015686, acc: 0.9021739363670349)
[2024-11-13 11:06:00,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:00,902][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 0.2274094969034195, acc: 0.9204545617103577)
[2024-11-13 11:06:00,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:01,609][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.21557016670703888, acc: 0.9255319237709045)
[2024-11-13 11:06:01,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:02,285][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.027607982978224754, acc: 1.0)
[2024-11-13 11:06:02,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:02,963][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.0536816269159317, acc: 0.9833333492279053)
[2024-11-13 11:06:03,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:03,641][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.11357464641332626, acc: 0.9767441749572754)
[2024-11-13 11:06:03,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:04,316][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.00825879443436861, acc: 1.0)
[2024-11-13 11:06:04,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:05,004][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 0.3255191743373871, acc: 0.8736842274665833)
[2024-11-13 11:06:05,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:05,690][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.15294651687145233, acc: 0.9666666388511658)
[2024-11-13 11:06:05,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:06,404][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 0.2546546757221222, acc: 0.9111111164093018)
[2024-11-13 11:06:06,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:07,123][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 0.6696405410766602, acc: 0.7981651425361633)
[2024-11-13 11:06:07,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:07,842][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 0.22894783318042755, acc: 0.9307692050933838)
[2024-11-13 11:06:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:08,528][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.005433151498436928, acc: 1.0)
[2024-11-13 11:06:08,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:09,203][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.014134238474071026, acc: 1.0)
[2024-11-13 11:06:09,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:09,875][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.03306981921195984, acc: 1.0)
[2024-11-13 11:06:09,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:10,548][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.0038723256438970566, acc: 1.0)
[2024-11-13 11:06:10,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:11,236][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.10880433768033981, acc: 0.9428571462631226)
[2024-11-13 11:06:11,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:11,912][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.011377292685210705, acc: 1.0)
[2024-11-13 11:06:11,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:12,585][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.12847073376178741, acc: 0.9545454382896423)
[2024-11-13 11:06:12,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:13,279][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 0.10559424757957458, acc: 0.9516128897666931)
[2024-11-13 11:06:13,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:13,959][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.13108699023723602, acc: 0.9545454382896423)
[2024-11-13 11:06:14,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:14,630][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.0006293461192399263, acc: 1.0)
[2024-11-13 11:06:14,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:15,307][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.0008072865894064307, acc: 1.0)
[2024-11-13 11:06:15,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:15,978][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.003741832450032234, acc: 1.0)
[2024-11-13 11:06:16,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:16,649][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.0009043843601830304, acc: 1.0)
[2024-11-13 11:06:16,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:17,325][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.0332677848637104, acc: 0.9729729890823364)
[2024-11-13 11:06:17,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:17,996][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.0034498460590839386, acc: 1.0)
[2024-11-13 11:06:18,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:18,678][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.006519501097500324, acc: 1.0)
[2024-11-13 11:06:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:19,371][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.30801233649253845, acc: 0.9117646813392639)
[2024-11-13 11:06:19,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:20,046][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.004175031092017889, acc: 1.0)
[2024-11-13 11:06:20,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:20,718][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.0012173153227195144, acc: 1.0)
[2024-11-13 11:06:20,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:21,393][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.0015878340927883983, acc: 1.0)
[2024-11-13 11:06:21,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:22,068][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.0076218945905566216, acc: 1.0)
[2024-11-13 11:06:22,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:22,743][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.035328857600688934, acc: 0.9824561476707458)
[2024-11-13 11:06:22,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:23,418][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.011934886686503887, acc: 1.0)
[2024-11-13 11:06:23,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:24,096][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.009170410223305225, acc: 1.0)
[2024-11-13 11:06:24,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:24,799][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.09890282899141312, acc: 0.9622641801834106)
[2024-11-13 11:06:24,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:25,509][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 0.10266990214586258, acc: 0.9666666388511658)
[2024-11-13 11:06:25,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:26,185][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.023275364190340042, acc: 1.0)
[2024-11-13 11:06:26,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:26,856][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.03729327768087387, acc: 1.0)
[2024-11-13 11:06:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:27,550][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.24107645452022552, acc: 0.9066666960716248)
[2024-11-13 11:06:27,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:28,230][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.13639385998249054, acc: 0.9375)
[2024-11-13 11:06:28,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:28,943][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 0.4704138934612274, acc: 0.8560000061988831)
[2024-11-13 11:06:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:29,623][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.3096576929092407, acc: 0.8539325594902039)
[2024-11-13 11:06:29,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:30,303][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.10532689839601517, acc: 0.9594594836235046)
[2024-11-13 11:06:31,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:31,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:32,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:32,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:33,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:34,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:34,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:35,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:35,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:36,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:37,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:37,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:38,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:38,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:39,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:40,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:40,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:41,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:41,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:42,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:43,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:43,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:44,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:44,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:45,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:46,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:46,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:47,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:47,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:48,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:49,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:49,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:50,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:50,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:51,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:51,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:52,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:53,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:53,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:54,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:54,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:55,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:56,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:57,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:57,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:58,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:59,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:06:59,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:00,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:00,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:01,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:01,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:02,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:03,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:03,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:04,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:04,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:05,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:06,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:06,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:07,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:07,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:08,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:09,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:09,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:10,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:10,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:11,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:12,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:12,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:13,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:13,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:14,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:15,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:15,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:16,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:16,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:17,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:18,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:18,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:19,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:19,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:20,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:20,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:21,948][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.0832, device='cuda:0') eval_epoch_loss=tensor(0.7339, device='cuda:0') eval_epoch_acc=tensor(0.8424, device='cuda:0')
[2024-11-13 11:07:21,949][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 11:07:21,949][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 11:07:22,370][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_268_loss_0.733900785446167/model.pt
[2024-11-13 11:07:22,375][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 11:07:22,376][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 10 is 0.8424360752105713
[2024-11-13 11:07:22,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:23,086][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.035854097455739975, acc: 1.0)
[2024-11-13 11:07:23,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:23,754][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.007708380930125713, acc: 1.0)
[2024-11-13 11:07:23,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:24,424][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.014801976270973682, acc: 1.0)
[2024-11-13 11:07:24,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:25,094][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.0661272406578064, acc: 0.96875)
[2024-11-13 11:07:25,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:25,760][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.001041077310219407, acc: 1.0)
[2024-11-13 11:07:25,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:26,443][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.2154611051082611, acc: 0.949999988079071)
[2024-11-13 11:07:26,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:27,127][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.038814231753349304, acc: 0.96875)
[2024-11-13 11:07:27,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:27,802][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.000689809094183147, acc: 1.0)
[2024-11-13 11:07:27,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:28,474][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.0029683306347578764, acc: 1.0)
[2024-11-13 11:07:28,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:29,141][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.0017872154712677002, acc: 1.0)
[2024-11-13 11:07:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:29,815][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.0469231978058815, acc: 0.978723406791687)
[2024-11-13 11:07:29,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:30,490][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.01820353977382183, acc: 1.0)
[2024-11-13 11:07:30,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:31,169][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.013663114048540592, acc: 1.0)
[2024-11-13 11:07:31,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:31,855][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.2840942144393921, acc: 0.9277108311653137)
[2024-11-13 11:07:31,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:32,549][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 0.2779877185821533, acc: 0.9351851940155029)
[2024-11-13 11:07:32,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:33,223][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.44298818707466125, acc: 0.9210526347160339)
[2024-11-13 11:07:33,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:33,895][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.00562492199242115, acc: 1.0)
[2024-11-13 11:07:33,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:34,580][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.1153625026345253, acc: 0.925000011920929)
[2024-11-13 11:07:34,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:35,274][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 0.115558922290802, acc: 0.953125)
[2024-11-13 11:07:35,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:35,980][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 0.1835891604423523, acc: 0.9520000219345093)
[2024-11-13 11:07:36,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:36,664][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.034303706139326096, acc: 0.9890109896659851)
[2024-11-13 11:07:36,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:37,352][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 0.08230135589838028, acc: 0.9689440727233887)
[2024-11-13 11:07:37,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:38,068][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 0.1999812126159668, acc: 0.9432989954948425)
[2024-11-13 11:07:38,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:38,743][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.00432891771197319, acc: 1.0)
[2024-11-13 11:07:38,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:39,418][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.01606694795191288, acc: 1.0)
[2024-11-13 11:07:39,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:40,097][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.01258615031838417, acc: 1.0)
[2024-11-13 11:07:40,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:40,779][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.06784924864768982, acc: 0.9818181991577148)
[2024-11-13 11:07:40,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:41,514][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 0.254205584526062, acc: 0.9226804375648499)
[2024-11-13 11:07:41,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:42,199][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.02979126200079918, acc: 0.982758641242981)
[2024-11-13 11:07:42,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:42,871][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.026112766936421394, acc: 1.0)
[2024-11-13 11:07:42,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:43,558][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.123457171022892, acc: 0.9736841917037964)
[2024-11-13 11:07:43,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:44,242][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.30728012323379517, acc: 0.9464285969734192)
[2024-11-13 11:07:44,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:44,915][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.33275216817855835, acc: 0.9375)
[2024-11-13 11:07:45,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:45,596][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.037407923489809036, acc: 0.9811320900917053)
[2024-11-13 11:07:45,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:46,276][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.035905301570892334, acc: 0.9811320900917053)
[2024-11-13 11:07:46,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:46,954][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.0018615089356899261, acc: 1.0)
[2024-11-13 11:07:47,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:47,627][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.033198557794094086, acc: 0.96875)
[2024-11-13 11:07:47,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:48,310][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.007491730153560638, acc: 1.0)
[2024-11-13 11:07:48,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:48,982][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.018653666600584984, acc: 1.0)
[2024-11-13 11:07:49,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:49,649][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.0009310836903750896, acc: 1.0)
[2024-11-13 11:07:49,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:50,329][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.031427495181560516, acc: 1.0)
[2024-11-13 11:07:50,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:51,018][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.010498054325580597, acc: 1.0)
[2024-11-13 11:07:51,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:51,700][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.09007507562637329, acc: 0.9759036302566528)
[2024-11-13 11:07:51,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:52,385][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.08048151433467865, acc: 0.9871794581413269)
[2024-11-13 11:07:52,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:53,086][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.05648161470890045, acc: 0.9897959232330322)
[2024-11-13 11:07:53,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:53,757][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.0007047702674753964, acc: 1.0)
[2024-11-13 11:07:53,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:54,425][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.0027876717504113913, acc: 1.0)
[2024-11-13 11:07:54,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:55,095][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.03993457183241844, acc: 1.0)
[2024-11-13 11:07:55,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:55,765][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.004188953433185816, acc: 1.0)
[2024-11-13 11:07:55,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:56,462][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.02894406020641327, acc: 0.9850746393203735)
[2024-11-13 11:07:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:57,148][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.11988724023103714, acc: 0.9615384340286255)
[2024-11-13 11:07:57,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:57,823][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.06377369165420532, acc: 0.9777777791023254)
[2024-11-13 11:07:57,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:58,505][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.038324590772390366, acc: 0.9838709831237793)
[2024-11-13 11:07:58,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:59,189][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.05185942351818085, acc: 0.9800000190734863)
[2024-11-13 11:07:59,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:07:59,869][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.02838914282619953, acc: 1.0)
[2024-11-13 11:07:59,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:00,540][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.02969028241932392, acc: 1.0)
[2024-11-13 11:08:00,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:01,217][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.09759572148323059, acc: 0.9487179517745972)
[2024-11-13 11:08:01,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:01,897][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.1754618138074875, acc: 0.9512194991111755)
[2024-11-13 11:08:01,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:02,575][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.07671356201171875, acc: 0.9473684430122375)
[2024-11-13 11:08:02,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:03,254][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.040810476988554, acc: 1.0)
[2024-11-13 11:08:03,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:03,925][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.005047950893640518, acc: 1.0)
[2024-11-13 11:08:04,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:04,605][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.014853758737444878, acc: 1.0)
[2024-11-13 11:08:04,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:05,285][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.0010527815902605653, acc: 1.0)
[2024-11-13 11:08:05,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:05,973][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.013435636647045612, acc: 1.0)
[2024-11-13 11:08:06,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:06,656][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.008990257047116756, acc: 1.0)
[2024-11-13 11:08:06,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:07,327][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.010674355551600456, acc: 1.0)
[2024-11-13 11:08:07,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:07,999][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.0205097496509552, acc: 1.0)
[2024-11-13 11:08:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:08,676][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.002392483875155449, acc: 1.0)
[2024-11-13 11:08:08,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:09,357][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.08160601556301117, acc: 0.9800000190734863)
[2024-11-13 11:08:09,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:10,043][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.2512487769126892, acc: 0.931034505367279)
[2024-11-13 11:08:10,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:10,729][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.5304045677185059, acc: 0.8297872543334961)
[2024-11-13 11:08:10,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:11,414][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 0.3048672676086426, acc: 0.9036144614219666)
[2024-11-13 11:08:11,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:12,084][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.0015355468494817615, acc: 1.0)
[2024-11-13 11:08:12,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:12,757][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.2847973108291626, acc: 0.9230769276618958)
[2024-11-13 11:08:12,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:13,434][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.12727007269859314, acc: 0.9518072009086609)
[2024-11-13 11:08:13,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:14,116][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.08363541960716248, acc: 0.9622641801834106)
[2024-11-13 11:08:14,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:14,795][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.04990095645189285, acc: 0.9746835231781006)
[2024-11-13 11:08:14,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:15,469][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.004554640501737595, acc: 1.0)
[2024-11-13 11:08:15,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:16,151][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.061002474278211594, acc: 0.9701492786407471)
[2024-11-13 11:08:16,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:16,819][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.15077388286590576, acc: 0.949999988079071)
[2024-11-13 11:08:16,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:17,498][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.00464238366112113, acc: 1.0)
[2024-11-13 11:08:17,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:18,172][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.08929096907377243, acc: 0.9722222089767456)
[2024-11-13 11:08:18,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:18,850][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.266798734664917, acc: 0.9069767594337463)
[2024-11-13 11:08:18,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:19,524][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.34773221611976624, acc: 0.9487179517745972)
[2024-11-13 11:08:19,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:20,202][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.14789053797721863, acc: 0.9777777791023254)
[2024-11-13 11:08:20,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:20,872][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.22767463326454163, acc: 0.95652174949646)
[2024-11-13 11:08:20,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:21,554][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.020101815462112427, acc: 1.0)
[2024-11-13 11:08:21,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:22,240][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 0.12366659194231033, acc: 0.9560439586639404)
[2024-11-13 11:08:22,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:22,942][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 0.1820690780878067, acc: 0.9130434989929199)
[2024-11-13 11:08:23,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:23,625][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.11728408932685852, acc: 0.95652174949646)
[2024-11-13 11:08:23,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:24,303][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.16434770822525024, acc: 0.9795918464660645)
[2024-11-13 11:08:24,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:24,973][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.004130335059016943, acc: 1.0)
[2024-11-13 11:08:25,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:25,642][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.004372459836304188, acc: 1.0)
[2024-11-13 11:08:25,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:26,317][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.024511685594916344, acc: 1.0)
[2024-11-13 11:08:26,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:26,999][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.01351065095514059, acc: 1.0)
[2024-11-13 11:08:27,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:27,682][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.012174391187727451, acc: 1.0)
[2024-11-13 11:08:27,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:28,356][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.31922802329063416, acc: 0.9512194991111755)
[2024-11-13 11:08:28,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:29,026][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.013664034195244312, acc: 1.0)
[2024-11-13 11:08:29,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:29,695][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.04652023687958717, acc: 0.9583333134651184)
[2024-11-13 11:08:29,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:30,363][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.010264174081385136, acc: 1.0)
[2024-11-13 11:08:30,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:31,033][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.0036372728645801544, acc: 1.0)
[2024-11-13 11:08:31,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:31,705][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.30192407965660095, acc: 0.96875)
[2024-11-13 11:08:31,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:32,414][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 0.45106378197669983, acc: 0.8909090757369995)
[2024-11-13 11:08:32,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:33,137][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.39845889806747437, acc: 0.8773584961891174)
[2024-11-13 11:08:33,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:33,817][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.10881800949573517, acc: 0.9888888597488403)
[2024-11-13 11:08:33,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:34,505][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.058994267135858536, acc: 0.9821428656578064)
[2024-11-13 11:08:34,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:35,184][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.025664275512099266, acc: 1.0)
[2024-11-13 11:08:35,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:35,865][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.0011979331029579043, acc: 1.0)
[2024-11-13 11:08:35,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:36,536][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.0014363162918016315, acc: 1.0)
[2024-11-13 11:08:36,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:37,212][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.028335869312286377, acc: 1.0)
[2024-11-13 11:08:37,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:37,895][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.09188385307788849, acc: 0.9578947424888611)
[2024-11-13 11:08:37,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:38,601][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 0.17451390624046326, acc: 0.9341317415237427)
[2024-11-13 11:08:38,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:39,286][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.09813141077756882, acc: 0.9624060392379761)
[2024-11-13 11:08:39,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:40,003][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 0.38510486483573914, acc: 0.8716577291488647)
[2024-11-13 11:08:40,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:40,702][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.09761764854192734, acc: 0.9639639854431152)
[2024-11-13 11:08:40,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:41,371][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.010693973861634731, acc: 1.0)
[2024-11-13 11:08:41,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:42,052][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.0023526449222117662, acc: 1.0)
[2024-11-13 11:08:42,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:42,723][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.05576002597808838, acc: 1.0)
[2024-11-13 11:08:42,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:43,401][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.005945809651166201, acc: 1.0)
[2024-11-13 11:08:43,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:44,084][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.030639460310339928, acc: 0.9736841917037964)
[2024-11-13 11:08:44,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:44,761][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.003960047382861376, acc: 1.0)
[2024-11-13 11:08:44,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:45,432][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.003955932799726725, acc: 1.0)
[2024-11-13 11:08:45,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:46,109][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.06539079546928406, acc: 0.9523809552192688)
[2024-11-13 11:08:46,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:46,799][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.13690783083438873, acc: 0.9259259104728699)
[2024-11-13 11:08:46,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:47,483][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 0.21096502244472504, acc: 0.9320388436317444)
[2024-11-13 11:08:47,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:48,193][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 0.2471504807472229, acc: 0.904411792755127)
[2024-11-13 11:08:48,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:48,888][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 0.25321900844573975, acc: 0.9066666960716248)
[2024-11-13 11:08:48,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:49,575][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 0.32211604714393616, acc: 0.9027777910232544)
[2024-11-13 11:08:49,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:50,249][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.029382096603512764, acc: 1.0)
[2024-11-13 11:08:50,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:50,922][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.00984176155179739, acc: 1.0)
[2024-11-13 11:08:51,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:51,596][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.04907070845365524, acc: 1.0)
[2024-11-13 11:08:51,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:52,270][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.003611254505813122, acc: 1.0)
[2024-11-13 11:08:52,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:52,966][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.06975340098142624, acc: 0.9852941036224365)
[2024-11-13 11:08:53,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:53,649][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.115643210709095, acc: 0.9733333587646484)
[2024-11-13 11:08:53,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:54,327][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.010304281488060951, acc: 1.0)
[2024-11-13 11:08:54,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:54,999][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.07950644940137863, acc: 0.9696969985961914)
[2024-11-13 11:08:55,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:55,672][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.0010236493544653058, acc: 1.0)
[2024-11-13 11:08:55,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:56,353][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.0013780652079731226, acc: 1.0)
[2024-11-13 11:08:56,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:57,023][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.0014376566978171468, acc: 1.0)
[2024-11-13 11:08:57,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:57,694][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.0020395363681018353, acc: 1.0)
[2024-11-13 11:08:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:58,376][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.0008184546022675931, acc: 1.0)
[2024-11-13 11:08:58,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:59,051][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.001987064490094781, acc: 1.0)
[2024-11-13 11:08:59,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:08:59,730][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.005604522302746773, acc: 1.0)
[2024-11-13 11:09:00,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:01,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:02,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:02,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:03,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:03,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:04,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:05,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:05,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:06,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:06,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:07,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:07,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:08,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:09,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:09,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:10,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:11,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:11,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:12,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:12,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:13,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:14,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:15,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:15,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:17,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:17,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:18,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:19,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:19,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:20,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:21,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:22,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:22,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:23,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:24,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:25,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:25,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:26,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:26,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:27,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:28,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:28,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:29,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:29,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:30,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:31,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:31,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:32,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:32,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:33,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:33,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:34,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:35,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:35,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:36,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:36,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:37,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:38,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:38,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:39,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:39,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:40,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:41,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:41,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:42,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:42,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:43,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:43,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:44,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:45,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:45,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:46,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:46,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:47,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:48,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:48,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:49,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:49,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:50,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:50,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:51,829][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2136, device='cuda:0') eval_epoch_loss=tensor(0.7946, device='cuda:0') eval_epoch_acc=tensor(0.8268, device='cuda:0')
[2024-11-13 11:09:51,831][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 11:09:51,832][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 11:09:52,187][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_411_loss_0.7946191430091858/model.pt
[2024-11-13 11:09:52,195][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 11:09:52,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:52,900][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.0015634838491678238, acc: 1.0)
[2024-11-13 11:09:52,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:53,584][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.21085748076438904, acc: 0.9666666388511658)
[2024-11-13 11:09:53,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:54,258][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.0024831530172377825, acc: 1.0)
[2024-11-13 11:09:54,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:54,932][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.00404198095202446, acc: 1.0)
[2024-11-13 11:09:55,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:55,613][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.053592052310705185, acc: 1.0)
[2024-11-13 11:09:55,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:56,284][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.010836128145456314, acc: 1.0)
[2024-11-13 11:09:56,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:56,954][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.15850792825222015, acc: 0.9444444179534912)
[2024-11-13 11:09:57,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:57,631][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.03408554568886757, acc: 0.9750000238418579)
[2024-11-13 11:09:57,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:58,299][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.09233908355236053, acc: 1.0)
[2024-11-13 11:09:58,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:58,967][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.001261692843399942, acc: 1.0)
[2024-11-13 11:09:59,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:09:59,643][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.016945326700806618, acc: 1.0)
[2024-11-13 11:09:59,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:00,317][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.006755445152521133, acc: 1.0)
[2024-11-13 11:10:00,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:00,997][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.03441900759935379, acc: 1.0)
[2024-11-13 11:10:01,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:01,679][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.06193393096327782, acc: 0.9629629850387573)
[2024-11-13 11:10:01,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:02,353][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.02354816347360611, acc: 1.0)
[2024-11-13 11:10:02,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:03,031][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.0031973314471542835, acc: 1.0)
[2024-11-13 11:10:03,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:03,715][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.015412494540214539, acc: 1.0)
[2024-11-13 11:10:03,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:04,393][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.0014946156879886985, acc: 1.0)
[2024-11-13 11:10:04,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:05,073][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.0008056922815740108, acc: 1.0)
[2024-11-13 11:10:05,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:05,748][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.00270294607616961, acc: 1.0)
[2024-11-13 11:10:05,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:06,422][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.003577635157853365, acc: 1.0)
[2024-11-13 11:10:06,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:07,100][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.0020970944315195084, acc: 1.0)
[2024-11-13 11:10:07,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:07,782][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.05746695026755333, acc: 0.9722222089767456)
[2024-11-13 11:10:07,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:08,454][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.0009205448441207409, acc: 1.0)
[2024-11-13 11:10:08,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:09,127][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.04879079759120941, acc: 0.9696969985961914)
[2024-11-13 11:10:09,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:09,803][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.014757748693227768, acc: 1.0)
[2024-11-13 11:10:09,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:10,494][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.016430599614977837, acc: 1.0)
[2024-11-13 11:10:10,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:11,167][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.014860508032143116, acc: 1.0)
[2024-11-13 11:10:11,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:11,857][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.09196104854345322, acc: 0.9487179517745972)
[2024-11-13 11:10:11,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:12,548][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.1223464161157608, acc: 0.9545454382896423)
[2024-11-13 11:10:12,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:13,261][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 0.4305879771709442, acc: 0.8399999737739563)
[2024-11-13 11:10:13,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:13,962][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 0.36953219771385193, acc: 0.8790322542190552)
[2024-11-13 11:10:14,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:14,674][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 0.30877482891082764, acc: 0.9104477763175964)
[2024-11-13 11:10:14,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:15,358][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.02110513113439083, acc: 0.9811320900917053)
[2024-11-13 11:10:15,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:16,042][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.008090753108263016, acc: 1.0)
[2024-11-13 11:10:16,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:16,714][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.0006630317657254636, acc: 1.0)
[2024-11-13 11:10:16,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:17,385][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.012684786692261696, acc: 1.0)
[2024-11-13 11:10:17,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:18,056][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.009260550141334534, acc: 1.0)
[2024-11-13 11:10:18,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:18,731][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.03399736434221268, acc: 0.9850746393203735)
[2024-11-13 11:10:18,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:19,407][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.008340608328580856, acc: 1.0)
[2024-11-13 11:10:19,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:20,085][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.01621920056641102, acc: 0.989130437374115)
[2024-11-13 11:10:20,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:20,766][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.06261081248521805, acc: 0.9615384340286255)
[2024-11-13 11:10:20,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:21,456][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.04973779618740082, acc: 0.9868420958518982)
[2024-11-13 11:10:21,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:22,131][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.02103181555867195, acc: 0.9795918464660645)
[2024-11-13 11:10:22,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:22,802][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.011118186637759209, acc: 1.0)
[2024-11-13 11:10:22,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:23,493][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.12427612394094467, acc: 0.969072163105011)
[2024-11-13 11:10:23,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:24,172][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.030323509126901627, acc: 0.9714285731315613)
[2024-11-13 11:10:24,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:24,886][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 0.14201773703098297, acc: 0.9767441749572754)
[2024-11-13 11:10:24,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:25,568][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.019065404310822487, acc: 1.0)
[2024-11-13 11:10:25,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:26,256][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.04407476633787155, acc: 0.9876543283462524)
[2024-11-13 11:10:26,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:26,930][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.03926574066281319, acc: 1.0)
[2024-11-13 11:10:27,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:27,611][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.0040644751861691475, acc: 1.0)
[2024-11-13 11:10:27,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:28,279][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.0004829633980989456, acc: 1.0)
[2024-11-13 11:10:28,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:28,956][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.018611446022987366, acc: 1.0)
[2024-11-13 11:10:29,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:29,636][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.08775868266820908, acc: 0.9642857313156128)
[2024-11-13 11:10:29,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:30,324][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.06429266929626465, acc: 0.9879518151283264)
[2024-11-13 11:10:30,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:31,032][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.06897804886102676, acc: 0.9729729890823364)
[2024-11-13 11:10:31,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:31,713][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.16918863356113434, acc: 0.9514563083648682)
[2024-11-13 11:10:31,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:32,420][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.10295523703098297, acc: 0.9674796462059021)
[2024-11-13 11:10:32,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:33,088][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.0335448756814003, acc: 1.0)
[2024-11-13 11:10:33,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:33,758][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.0075428681448102, acc: 1.0)
[2024-11-13 11:10:33,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:34,475][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 0.3950084149837494, acc: 0.9019607901573181)
[2024-11-13 11:10:34,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:35,190][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 0.3243919014930725, acc: 0.8908296823501587)
[2024-11-13 11:10:35,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:35,872][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.08825208991765976, acc: 0.9791666865348816)
[2024-11-13 11:10:35,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:36,563][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.13749335706233978, acc: 0.9509202241897583)
[2024-11-13 11:10:36,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:37,251][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.10269378125667572, acc: 0.9496402740478516)
[2024-11-13 11:10:37,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:37,957][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 0.2951841950416565, acc: 0.909547746181488)
[2024-11-13 11:10:38,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:38,632][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.07405641674995422, acc: 0.9722222089767456)
[2024-11-13 11:10:38,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:39,312][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.007207586895674467, acc: 1.0)
[2024-11-13 11:10:39,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:39,992][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.0009069101070053875, acc: 1.0)
[2024-11-13 11:10:40,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:40,662][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.004002327099442482, acc: 1.0)
[2024-11-13 11:10:40,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:41,336][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.008841296657919884, acc: 1.0)
[2024-11-13 11:10:41,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:42,021][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.5627912878990173, acc: 0.8965517282485962)
[2024-11-13 11:10:42,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:42,694][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.0010718072298914194, acc: 1.0)
[2024-11-13 11:10:42,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:43,374][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.003808741457760334, acc: 1.0)
[2024-11-13 11:10:43,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:44,047][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.014641379937529564, acc: 1.0)
[2024-11-13 11:10:44,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:44,717][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.019081786274909973, acc: 1.0)
[2024-11-13 11:10:44,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:45,387][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.02415912225842476, acc: 1.0)
[2024-11-13 11:10:45,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:46,065][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.0398729033768177, acc: 1.0)
[2024-11-13 11:10:46,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:46,738][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.11137129366397858, acc: 0.9666666388511658)
[2024-11-13 11:10:46,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:47,411][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.14290636777877808, acc: 0.9655172228813171)
[2024-11-13 11:10:47,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:48,094][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.07980342209339142, acc: 0.9607843160629272)
[2024-11-13 11:10:48,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:48,765][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.026971373707056046, acc: 1.0)
[2024-11-13 11:10:48,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:49,445][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.004908513743430376, acc: 1.0)
[2024-11-13 11:10:49,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:50,120][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.04086027294397354, acc: 1.0)
[2024-11-13 11:10:50,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:50,803][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.24365200102329254, acc: 0.9196428656578064)
[2024-11-13 11:10:50,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:51,495][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.07964884489774704, acc: 0.9775280952453613)
[2024-11-13 11:10:51,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:52,179][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.4858224391937256, acc: 0.8539325594902039)
[2024-11-13 11:10:52,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:52,881][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 0.3317163288593292, acc: 0.8723404407501221)
[2024-11-13 11:10:52,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:53,569][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.1841481626033783, acc: 0.967391312122345)
[2024-11-13 11:10:53,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:54,239][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.0003880580479744822, acc: 1.0)
[2024-11-13 11:10:54,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:54,908][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.0003196477482561022, acc: 1.0)
[2024-11-13 11:10:54,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:55,578][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.0007964693359099329, acc: 1.0)
[2024-11-13 11:10:55,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:56,248][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.032469045370817184, acc: 0.9629629850387573)
[2024-11-13 11:10:56,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:56,920][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.07821222394704819, acc: 0.9811320900917053)
[2024-11-13 11:10:57,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:57,588][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.0019124726532027125, acc: 1.0)
[2024-11-13 11:10:57,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:58,273][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.18414831161499023, acc: 0.954954981803894)
[2024-11-13 11:10:58,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:58,958][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.013774823397397995, acc: 1.0)
[2024-11-13 11:10:59,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:10:59,627][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.0007187892915681005, acc: 1.0)
[2024-11-13 11:10:59,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:00,299][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.08156512677669525, acc: 0.9666666388511658)
[2024-11-13 11:11:00,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:00,970][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.0012628287076950073, acc: 1.0)
[2024-11-13 11:11:01,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:01,884][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 1.075178861618042, acc: 0.7142857313156128)
[2024-11-13 11:11:01,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:02,590][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.158043771982193, acc: 0.9365079402923584)
[2024-11-13 11:11:02,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:03,261][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.0025507784448564053, acc: 1.0)
[2024-11-13 11:11:03,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:03,950][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.11121782660484314, acc: 0.9833333492279053)
[2024-11-13 11:11:04,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:04,641][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.08977997303009033, acc: 0.9861111044883728)
[2024-11-13 11:11:04,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:05,321][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.00046857306733727455, acc: 1.0)
[2024-11-13 11:11:05,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:06,002][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.007537956349551678, acc: 1.0)
[2024-11-13 11:11:06,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:06,668][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.005234376527369022, acc: 1.0)
[2024-11-13 11:11:06,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:07,350][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.012072897516191006, acc: 1.0)
[2024-11-13 11:11:07,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:08,264][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 0.886918306350708, acc: 0.7288135886192322)
[2024-11-13 11:11:08,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:08,979][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 0.17260825634002686, acc: 0.9477611780166626)
[2024-11-13 11:11:09,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:09,666][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 0.11768821626901627, acc: 0.9635036587715149)
[2024-11-13 11:11:09,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:10,386][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 0.5051655769348145, acc: 0.875)
[2024-11-13 11:11:10,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:11,062][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.003702078713104129, acc: 1.0)
[2024-11-13 11:11:11,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:11,739][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.013189734891057014, acc: 1.0)
[2024-11-13 11:11:11,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:12,412][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.0072975498624145985, acc: 1.0)
[2024-11-13 11:11:12,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:13,095][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.10264874994754791, acc: 0.9508196711540222)
[2024-11-13 11:11:13,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:13,770][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.049428705126047134, acc: 0.9830508232116699)
[2024-11-13 11:11:13,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:14,449][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.17152796685695648, acc: 0.9534883499145508)
[2024-11-13 11:11:14,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:15,117][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.14836658537387848, acc: 0.9772727489471436)
[2024-11-13 11:11:15,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:15,804][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.029664421454072, acc: 1.0)
[2024-11-13 11:11:15,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:16,481][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.10271622985601425, acc: 0.9545454382896423)
[2024-11-13 11:11:16,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:17,154][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.02936713956296444, acc: 1.0)
[2024-11-13 11:11:17,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:17,824][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.3260017931461334, acc: 0.949999988079071)
[2024-11-13 11:11:17,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:18,490][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.0022171682212501764, acc: 1.0)
[2024-11-13 11:11:18,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:19,170][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.03577413409948349, acc: 1.0)
[2024-11-13 11:11:19,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:19,857][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.07746431976556778, acc: 0.984375)
[2024-11-13 11:11:19,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:20,536][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.09529627859592438, acc: 0.96875)
[2024-11-13 11:11:20,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:21,209][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.00587492436170578, acc: 1.0)
[2024-11-13 11:11:21,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:21,883][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.4017108380794525, acc: 0.9375)
[2024-11-13 11:11:21,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:22,562][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.039906587451696396, acc: 0.9677419066429138)
[2024-11-13 11:11:22,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:23,245][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.04331861063838005, acc: 0.95652174949646)
[2024-11-13 11:11:23,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:23,917][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.035457827150821686, acc: 1.0)
[2024-11-13 11:11:23,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:24,592][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.04917486757040024, acc: 0.9756097793579102)
[2024-11-13 11:11:24,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:25,264][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.0974499061703682, acc: 0.9714285731315613)
[2024-11-13 11:11:25,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:25,939][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.0021619421895593405, acc: 1.0)
[2024-11-13 11:11:26,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:26,610][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.016805285587906837, acc: 1.0)
[2024-11-13 11:11:26,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:27,280][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.0021309670992195606, acc: 1.0)
[2024-11-13 11:11:27,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:27,961][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.08021162450313568, acc: 0.9696969985961914)
[2024-11-13 11:11:28,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:28,634][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.008674289099872112, acc: 1.0)
[2024-11-13 11:11:28,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:29,310][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.03003508970141411, acc: 0.9857142567634583)
[2024-11-13 11:11:29,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:30,010][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 0.13022609055042267, acc: 0.9489051103591919)
[2024-11-13 11:11:30,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:31,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:31,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:32,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:33,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:33,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:34,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:34,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:35,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:36,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:36,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:37,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:37,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:38,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:39,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:39,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:40,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:40,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:41,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:42,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:42,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:43,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:43,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:44,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:45,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:45,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:46,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:46,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:47,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:48,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:48,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:49,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:49,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:50,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:51,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:51,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:52,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:53,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:53,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:54,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:55,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:55,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:56,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:56,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:57,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:58,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:58,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:59,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:11:59,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:00,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:00,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:01,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:02,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:02,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:03,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:03,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:04,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:05,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:05,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:06,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:07,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:07,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:08,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:08,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:09,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:10,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:11,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:11,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:12,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:12,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:13,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:13,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:14,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:15,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:15,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:16,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:16,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:17,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:18,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:18,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:19,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:19,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:20,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:21,247][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3392, device='cuda:0') eval_epoch_loss=tensor(0.8498, device='cuda:0') eval_epoch_acc=tensor(0.8136, device='cuda:0')
[2024-11-13 11:12:21,248][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 11:12:21,249][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 11:12:21,567][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_554_loss_0.8498173356056213/model.pt
[2024-11-13 11:12:21,572][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft directory
[2024-11-13 11:12:21,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:22,317][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.13980691134929657, acc: 0.9655172228813171)
[2024-11-13 11:12:22,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:23,023][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 0.21635249257087708, acc: 0.9428571462631226)
[2024-11-13 11:12:23,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:23,709][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 0.1620888113975525, acc: 0.9271523356437683)
[2024-11-13 11:12:23,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:24,397][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.1289314478635788, acc: 0.9572649598121643)
[2024-11-13 11:12:24,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:25,070][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.052513763308525085, acc: 1.0)
[2024-11-13 11:12:25,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:25,739][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.0385429710149765, acc: 1.0)
[2024-11-13 11:12:25,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:26,406][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.0018600168405100703, acc: 1.0)
[2024-11-13 11:12:26,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:27,079][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.005752850789576769, acc: 1.0)
[2024-11-13 11:12:27,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:27,780][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.19338959455490112, acc: 0.9333333373069763)
[2024-11-13 11:12:27,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:28,460][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.05711166560649872, acc: 0.9870129823684692)
[2024-11-13 11:12:28,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:29,139][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.06808102875947952, acc: 0.9583333134651184)
[2024-11-13 11:12:29,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:29,820][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.012957089580595493, acc: 1.0)
[2024-11-13 11:12:29,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:30,505][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.09572643041610718, acc: 0.9642857313156128)
[2024-11-13 11:12:30,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:31,209][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.24739548563957214, acc: 0.9473684430122375)
[2024-11-13 11:12:31,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:31,879][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.020193621516227722, acc: 1.0)
[2024-11-13 11:12:31,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:32,602][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 0.12181498110294342, acc: 0.9732620120048523)
[2024-11-13 11:12:32,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:33,287][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.010680791921913624, acc: 1.0)
[2024-11-13 11:12:33,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:33,977][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.04435821250081062, acc: 0.9829059839248657)
[2024-11-13 11:12:34,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:34,694][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 0.26056012511253357, acc: 0.9285714030265808)
[2024-11-13 11:12:34,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 11:12:35,409][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 0.24749460816383362, acc: 0.9119496941566467)
[2024-11-13 11:12:35,907][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.1268, train_epoch_loss=0.1194, epoch time 605.107841193676s
[2024-11-13 11:12:35,907][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 17 GB
[2024-11-13 11:12:35,907][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 23 GB
[2024-11-13 11:12:35,907][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 17 GB
[2024-11-13 11:12:35,907][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 4
[2024-11-13 11:12:35,907][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-11-13 11:12:35,911][root][INFO] - Key: avg_train_prep, Value: 1.1842759847640991
[2024-11-13 11:12:35,911][root][INFO] - Key: avg_train_loss, Value: 0.16838158667087555
[2024-11-13 11:12:35,911][root][INFO] - Key: avg_train_acc, Value: 0.9041738510131836
[2024-11-13 11:12:35,911][root][INFO] - Key: avg_eval_prep, Value: 2.23909854888916
[2024-11-13 11:12:35,912][root][INFO] - Key: avg_eval_loss, Value: 0.8035425543785095
[2024-11-13 11:12:35,912][root][INFO] - Key: avg_eval_acc, Value: 0.8205795884132385
[2024-11-13 11:12:35,912][root][INFO] - Key: avg_epoch_time, Value: 579.0311419818551
[2024-11-13 11:12:35,912][root][INFO] - Key: avg_checkpoint_time, Value: 0.43269572652092103
