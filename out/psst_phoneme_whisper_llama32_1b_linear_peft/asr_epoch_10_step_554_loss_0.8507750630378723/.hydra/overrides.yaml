- ++model_config.llm_name=llama32_1b
- ++model_config.llm_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct
- ++model_config.llm_dim=2048
- ++model_config.encoder_name=whisper
- ++model_config.normalize=true
- ++dataset_config.normalize=true
- ++model_config.encoder_projector_ds_rate=5
- ++model_config.encoder_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt
- ++model_config.encoder_dim=1280
- ++model_config.encoder_projector=linear
- ++model_config.encoder2_name=
- ++model_config.encoder2_path=
- ++dataset_config.dataset=speech_dataset
- ++dataset_config.val_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl
- ++dataset_config.inference_mode=true
- ++dataset_config.file=src/slam_llm/datasets/speech_dataset.py:get_speech_dataset
- ++train_config.model_name=asr
- ++train_config.freeze_encoder=true
- ++train_config.freeze_llm=true
- ++train_config.batching_strategy=custom
- ++train_config.num_epochs=1
- ++train_config.val_batch_size=4
- ++train_config.num_workers_dataloader=1
- ++train_config.output_dir=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft
- ++decode_log=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/decode_test_beam4
- ++ckpt_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_whisper_llama32_1b_linear_peft/asr_epoch_10_step_554_loss_0.8507750630378723/model.pt
- ++log_config.wandb_exp_name=psst_phoneme_whisper_llama32_1b_linear_peft
- ++train_config.use_peft=true
- ++dataset_config.input_type=mel
- ++dataset_config.mel_size=128
